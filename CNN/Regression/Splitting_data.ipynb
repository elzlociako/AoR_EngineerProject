{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1329c18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:22:25.081475Z",
     "start_time": "2023-02-03T22:22:25.072293Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import open3d as o3d\n",
    "\n",
    "from Libraries.dataloader import DataLoader as DL\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6dfab",
   "metadata": {},
   "source": [
    "#  Inicjalizowane danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e02fc2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:22:25.480130Z",
     "start_time": "2023-02-03T22:22:25.477421Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68719e44",
   "metadata": {},
   "source": [
    "# Załadowanie danych\n",
    "Ładujemy dane do zmiennych a następnie odpowiednio przekształcamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "376f4b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:22:26.037259Z",
     "start_time": "2023-02-03T22:22:26.030478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, p=0.5, mean=[0.0, 0.5], std=[1.0, 1.0]):\n",
    "        self.p    = p\n",
    "        self.std  = np.random.uniform(std[0],std[1])\n",
    "        self.mean = np.random.uniform(mean[0],mean[1])\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        if random.random() < self.p:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            return tensor \n",
    "\n",
    "\n",
    "DataAug = transforms.Compose([\n",
    "    transforms.ColorJitter(\n",
    "        brightness=[0.5,1.5],\n",
    "        contrast=[0.5, 1.5],\n",
    "        saturation=[0.5, 1.5],\n",
    "        hue=[-0.1,0.1],\n",
    "    ),\n",
    "    transforms.GaussianBlur(\n",
    "        kernel_size=3,\n",
    "        sigma=(0.1, 9.0)\n",
    "    ),\n",
    "#     transforms.RandomErasing(\n",
    "#         p=0.1,\n",
    "#         scale=(0.01, 0.1),\n",
    "#         ratio=(0.01, 3.3),\n",
    "#         value=0,\n",
    "#     ),\n",
    "    GaussianNoise(\n",
    "        p=0.2,\n",
    "        mean=[0.0, 0.1],\n",
    "        std=[0.01, 0.3]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823deffa",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025b1d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:22:26.825326Z",
     "start_time": "2023-02-03T22:22:26.822013Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "# dl = DL()\n",
    "\n",
    "# X_trainA, y_trainA = dl.load(DATASET_ROOTDIR, 'files_ArUco/data_TRA.csv', 'R')\n",
    "# X_trainB, y_trainB = dl.load(DATASET_ROOTDIR, 'files/data_TRA.csv', 'R')\n",
    "\n",
    "# X_validationA, y_validationA = dl.load(DATASET_ROOTDIR, 'files_ArUco/data_VAL.csv', 'R')\n",
    "# X_validationB, y_validationB = dl.load(DATASET_ROOTDIR, 'files/data_VAL.csv', 'R')\n",
    "\n",
    "# X_train = torch.cat((X_trainA, X_trainB),axis=0)\n",
    "# y_train = torch.cat((y_trainA, y_trainB),axis=0)\n",
    "\n",
    "# X_validation = torch.cat((X_validationA, X_validationB),axis=0)\n",
    "# y_validation = torch.cat((y_validationA, y_validationB),axis=0)\n",
    "\n",
    "# # X_train, X_validation, y_train, y_validation = train_test_split(RGBD_input, axis_out, test_size=0.2)\n",
    "# print(X_validationA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "493832bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:22:59.459716Z",
     "start_time": "2023-02-03T22:22:51.707343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([132, 3, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "\n",
    "X, y = dl.load(DATASET_ROOTDIR, 'files/data.csv', 'R')\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "X_train_aug = X_train.clone()\n",
    "for i in range(X_train_aug.shape[0]):\n",
    "     X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "X_train = torch.cat((X_train, X_train_aug),axis=0)\n",
    "\n",
    "X_train, y_train = dl.load(DATASET_ROOTDIR, 'files/data_TRA.csv', 'R')\n",
    "X_validation, y_validation = dl.load(DATASET_ROOTDIR, 'files/data_VAL.csv', 'R')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d92a",
   "metadata": {},
   "source": [
    "# RGB + D \n",
    "Na wejście do modelu zostanie podany tensor zawieający kombinację RGB + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2280a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:23:08.618015Z",
     "start_time": "2023-02-03T22:23:07.771389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33, 3, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "\n",
    "X_validation, y_validation = dl.load(DATASET_ROOTDIR, 'files_Test/data_Test.csv', 'R')\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23db3ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:23:10.318264Z",
     "start_time": "2023-02-03T22:23:09.405436Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_aug = X_train.clone()\n",
    "\n",
    "for i in range(X_train_aug.shape[0]):\n",
    "     X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "y_train = torch.cat((y_train, y_train),axis=0)\n",
    "X_train = torch.cat((X_train, X_train_aug),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02996e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb1b812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:23:11.046083Z",
     "start_time": "2023-02-03T22:23:11.044181Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_trainDataset = TensorDataset(X_train, y_train)\n",
    "AoRD_validationDataset = TensorDataset(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:23:17.611273Z",
     "start_time": "2023-02-03T22:23:17.525660Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AoRD_trainDataset, batch_size=15, shuffle=False)\n",
    "validation_loader = DataLoader(AoRD_validationDataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159076ba",
   "metadata": {},
   "source": [
    "# Wyciąganie pojedyńczego elementu z batcha\n",
    "Można zrobić to na kilka sposobów, ale ten jest najszybszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab99ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T23:01:41.000137Z",
     "start_time": "2023-01-18T23:01:40.997941Z"
    }
   },
   "outputs": [],
   "source": [
    "# for b, (X_train, y_train) in enumerate(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "# Stworzenie modelu\n",
    "Nazwałem model AoRNet od angielsiego **A**xis **o**f **R**rotation oraz od nazwy modelu matki Res**Net**`u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e0db1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:01.379205Z",
     "start_time": "2023-02-03T22:26:01.372912Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=3, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9a67d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:03.553066Z",
     "start_time": "2023-02-03T22:26:01.570659Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = AoRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b0f079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:03.558181Z",
     "start_time": "2023-02-03T22:26:03.554849Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=10, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad777bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:16:08.597224Z",
     "start_time": "2023-01-17T22:42:51.716287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch: 1  loss: 1.06668711\n",
      "epoch:  1  batch: 2  loss: 9.56523228\n",
      "epoch:  1  batch: 3  loss: 0.73446572\n",
      "epoch:  1  batch: 4  loss: 0.70586127\n",
      "epoch:  1  batch: 5  loss: 0.91964579\n",
      "epoch:  1  batch: 6  loss: 0.53306264\n",
      "epoch:  1  batch: 7  loss: 0.31962752\n",
      "epoch:  1  batch: 8  loss: 0.30398750\n",
      "epoch:  1  batch: 9  loss: 0.50960398\n",
      "epoch:  1  batch: 10  loss: 0.21543100\n",
      "epoch:  1  batch: 11  loss: 0.22010711\n",
      "epoch:  1  batch: 12  loss: 0.52474064\n",
      "epoch:  1  batch: 13  loss: 1.31413782\n",
      "epoch:  1  batch: 14  loss: 0.23248927\n",
      "epoch:  1  batch: 15  loss: 0.41202676\n",
      "epoch:  1  batch: 16  loss: 0.14192414\n",
      "epoch:  1  batch: 17  loss: 0.36996761\n",
      "epoch:  1  batch: 18  loss: 1.62220871\n",
      "epoch:  1  batch: 19  loss: 0.08510237\n",
      "epoch:  1  batch: 20  loss: 0.25750417\n",
      "epoch:  1  batch: 21  loss: 0.37019435\n",
      "epoch:  1  batch: 22  loss: 0.57556850\n",
      "epoch:  1  batch: 23  loss: 0.53939646\n",
      "epoch:  1  batch: 24  loss: 0.57414198\n",
      "epoch:  1  batch: 25  loss: 0.15966067\n",
      "epoch:  1  batch: 26  loss: 0.33803493\n",
      "epoch:  1  batch: 27  loss: 0.61892742\n",
      "epoch:  1  batch: 28  loss: 0.37605152\n",
      "epoch:  1  batch: 29  loss: 0.40329149\n",
      "epoch:  1  batch: 30  loss: 0.31109011\n",
      "epoch:  1  batch: 31  loss: 0.45378771\n",
      "epoch:  1  batch: 32  loss: 0.27072605\n",
      "epoch:  1  batch: 33  loss: 0.22442414\n",
      "epoch:  1  batch: 34  loss: 0.23509997\n",
      "epoch:  1  batch: 35  loss: 0.33210886\n",
      "epoch:  1  batch: 36  loss: 0.53908169\n",
      "epoch:  1  batch: 37  loss: 0.35850263\n",
      "epoch:  1  batch: 38  loss: 0.14961578\n",
      "epoch:  1  batch: 39  loss: 0.40821472\n",
      "epoch:  1  batch: 40  loss: 0.14739887\n",
      "epoch:  1  batch: 41  loss: 0.42090181\n",
      "epoch:  1  batch: 42  loss: 0.31816584\n",
      "epoch:  1  batch: 43  loss: 0.25769174\n",
      "epoch:  1  batch: 44  loss: 0.11110272\n",
      "epoch:  1  batch: 45  loss: 0.07683591\n",
      "epoch:  1  batch: 46  loss: 0.99893379\n",
      "epoch:  1  batch: 47  loss: 1.08751643\n",
      "epoch:  1  batch: 48  loss: 0.45688275\n",
      "epoch:  1  batch: 49  loss: 0.10760469\n",
      "epoch:  1  batch: 50  loss: 0.21926105\n",
      "epoch:  1  batch: 51  loss: 0.33266729\n",
      "epoch:  1  batch: 52  loss: 0.31277847\n",
      "epoch:  1  batch: 53  loss: 0.34555691\n",
      "epoch:  1  batch: 54  loss: 0.96319580\n",
      "epoch:  1  batch: 55  loss: 0.49488023\n",
      "epoch:  1  batch: 56  loss: 0.27356508\n",
      "epoch:  1  batch: 57  loss: 0.25257698\n",
      "epoch:  1  batch: 58  loss: 0.63011473\n",
      "epoch:  1  batch: 59  loss: 0.48473567\n",
      "epoch:  1  batch: 60  loss: 0.89275903\n",
      "epoch:  1  batch: 61  loss: 1.55976188\n",
      "epoch:  1  batch: 62  loss: 0.36531764\n",
      "epoch:  1  batch: 63  loss: 0.49125972\n",
      "epoch:  1  batch: 64  loss: 0.33116278\n",
      "epoch:  1  batch: 65  loss: 0.43592900\n",
      "epoch:  1  batch: 66  loss: 0.40954384\n",
      "epoch:  1  batch: 67  loss: 0.47882950\n",
      "epoch:  1  batch: 68  loss: 0.44275689\n",
      "epoch:  2  batch: 1  loss: 0.49466181\n",
      "epoch:  2  batch: 2  loss: 0.37131816\n",
      "epoch:  2  batch: 3  loss: 0.47028819\n",
      "epoch:  2  batch: 4  loss: 0.21732654\n",
      "epoch:  2  batch: 5  loss: 0.14392827\n",
      "epoch:  2  batch: 6  loss: 0.17698678\n",
      "epoch:  2  batch: 7  loss: 0.34056026\n",
      "epoch:  2  batch: 8  loss: 0.17644572\n",
      "epoch:  2  batch: 9  loss: 0.15859438\n",
      "epoch:  2  batch: 10  loss: 0.10784364\n",
      "epoch:  2  batch: 11  loss: 0.10191020\n",
      "epoch:  2  batch: 12  loss: 0.35215273\n",
      "epoch:  2  batch: 13  loss: 0.72261220\n",
      "epoch:  2  batch: 14  loss: 0.38317287\n",
      "epoch:  2  batch: 15  loss: 0.21863273\n",
      "epoch:  2  batch: 16  loss: 0.36164594\n",
      "epoch:  2  batch: 17  loss: 0.56485331\n",
      "epoch:  2  batch: 18  loss: 0.24854439\n",
      "epoch:  2  batch: 19  loss: 0.30869013\n",
      "epoch:  2  batch: 20  loss: 0.51366830\n",
      "epoch:  2  batch: 21  loss: 0.48269442\n",
      "epoch:  2  batch: 22  loss: 0.22178818\n",
      "epoch:  2  batch: 23  loss: 0.10813168\n",
      "epoch:  2  batch: 24  loss: 0.24032916\n",
      "epoch:  2  batch: 25  loss: 0.26249680\n",
      "epoch:  2  batch: 26  loss: 0.51632553\n",
      "epoch:  2  batch: 27  loss: 0.62409073\n",
      "epoch:  2  batch: 28  loss: 0.31973961\n",
      "epoch:  2  batch: 29  loss: 0.24764451\n",
      "epoch:  2  batch: 30  loss: 0.13485345\n",
      "epoch:  2  batch: 31  loss: 0.11226190\n",
      "epoch:  2  batch: 32  loss: 0.18681963\n",
      "epoch:  2  batch: 33  loss: 0.23905225\n",
      "epoch:  2  batch: 34  loss: 0.22562163\n",
      "epoch:  2  batch: 35  loss: 0.51123017\n",
      "epoch:  2  batch: 36  loss: 0.22833320\n",
      "epoch:  2  batch: 37  loss: 0.19236654\n",
      "epoch:  2  batch: 38  loss: 0.05178356\n",
      "epoch:  2  batch: 39  loss: 0.35019490\n",
      "epoch:  2  batch: 40  loss: 0.10472579\n",
      "epoch:  2  batch: 41  loss: 0.23180449\n",
      "epoch:  2  batch: 42  loss: 0.20894280\n",
      "epoch:  2  batch: 43  loss: 0.13503452\n",
      "epoch:  2  batch: 44  loss: 0.23857813\n",
      "epoch:  2  batch: 45  loss: 0.14075188\n",
      "epoch:  2  batch: 46  loss: 0.47508642\n",
      "epoch:  2  batch: 47  loss: 0.56273448\n",
      "epoch:  2  batch: 48  loss: 0.31981578\n",
      "epoch:  2  batch: 49  loss: 0.21188575\n",
      "epoch:  2  batch: 50  loss: 0.50318784\n",
      "epoch:  2  batch: 51  loss: 0.43978408\n",
      "epoch:  2  batch: 52  loss: 0.12965848\n",
      "epoch:  2  batch: 53  loss: 0.26673457\n",
      "epoch:  2  batch: 54  loss: 0.54511631\n",
      "epoch:  2  batch: 55  loss: 0.37935191\n",
      "epoch:  2  batch: 56  loss: 0.15542918\n",
      "epoch:  2  batch: 57  loss: 0.09898160\n",
      "epoch:  2  batch: 58  loss: 0.81656605\n",
      "epoch:  2  batch: 59  loss: 0.22695795\n",
      "epoch:  2  batch: 60  loss: 0.63352698\n",
      "epoch:  2  batch: 61  loss: 1.02662706\n",
      "epoch:  2  batch: 62  loss: 0.31316054\n",
      "epoch:  2  batch: 63  loss: 0.27501786\n",
      "epoch:  2  batch: 64  loss: 0.20972472\n",
      "epoch:  2  batch: 65  loss: 0.11888101\n",
      "epoch:  2  batch: 66  loss: 0.20061201\n",
      "epoch:  2  batch: 67  loss: 0.17080571\n",
      "epoch:  2  batch: 68  loss: 0.42167529\n",
      "epoch:  3  batch: 1  loss: 0.63179219\n",
      "epoch:  3  batch: 2  loss: 0.07697301\n",
      "epoch:  3  batch: 3  loss: 0.34856004\n",
      "epoch:  3  batch: 4  loss: 0.21945459\n",
      "epoch:  3  batch: 5  loss: 0.41530001\n",
      "epoch:  3  batch: 6  loss: 0.34933287\n",
      "epoch:  3  batch: 7  loss: 0.34435463\n",
      "epoch:  3  batch: 8  loss: 0.12011757\n",
      "epoch:  3  batch: 9  loss: 0.14503078\n",
      "epoch:  3  batch: 10  loss: 0.14034039\n",
      "epoch:  3  batch: 11  loss: 0.09337902\n",
      "epoch:  3  batch: 12  loss: 0.65271753\n",
      "epoch:  3  batch: 13  loss: 1.18888319\n",
      "epoch:  3  batch: 14  loss: 0.44127157\n",
      "epoch:  3  batch: 15  loss: 0.28120524\n",
      "epoch:  3  batch: 16  loss: 0.25888249\n",
      "epoch:  3  batch: 17  loss: 0.69870007\n",
      "epoch:  3  batch: 18  loss: 0.19087340\n",
      "epoch:  3  batch: 19  loss: 0.32062191\n",
      "epoch:  3  batch: 20  loss: 0.88629347\n",
      "epoch:  3  batch: 21  loss: 0.68200177\n",
      "epoch:  3  batch: 22  loss: 0.27753383\n",
      "epoch:  3  batch: 23  loss: 0.28515416\n",
      "epoch:  3  batch: 24  loss: 0.38003665\n",
      "epoch:  3  batch: 25  loss: 0.36214885\n",
      "epoch:  3  batch: 26  loss: 0.66939855\n",
      "epoch:  3  batch: 27  loss: 0.94137120\n",
      "epoch:  3  batch: 28  loss: 0.45706686\n",
      "epoch:  3  batch: 29  loss: 0.33656994\n",
      "epoch:  3  batch: 30  loss: 0.21992184\n",
      "epoch:  3  batch: 31  loss: 0.34032145\n",
      "epoch:  3  batch: 32  loss: 0.30007714\n",
      "epoch:  3  batch: 33  loss: 0.53524178\n",
      "epoch:  3  batch: 34  loss: 0.33711952\n",
      "epoch:  3  batch: 35  loss: 0.65788519\n",
      "epoch:  3  batch: 36  loss: 0.16717178\n",
      "epoch:  3  batch: 37  loss: 0.20160091\n",
      "epoch:  3  batch: 38  loss: 0.23707043\n",
      "epoch:  3  batch: 39  loss: 0.10814147\n",
      "epoch:  3  batch: 40  loss: 0.12308808\n",
      "epoch:  3  batch: 41  loss: 0.21906175\n",
      "epoch:  3  batch: 42  loss: 0.10976485\n",
      "epoch:  3  batch: 43  loss: 0.17807212\n",
      "epoch:  3  batch: 44  loss: 0.15409517\n",
      "epoch:  3  batch: 45  loss: 0.10184862\n",
      "epoch:  3  batch: 46  loss: 0.51934457\n",
      "epoch:  3  batch: 47  loss: 0.60450739\n",
      "epoch:  3  batch: 48  loss: 0.35575074\n",
      "epoch:  3  batch: 49  loss: 0.18488723\n",
      "epoch:  3  batch: 50  loss: 0.38032970\n",
      "epoch:  3  batch: 51  loss: 0.38354349\n",
      "epoch:  3  batch: 52  loss: 0.14414620\n",
      "epoch:  3  batch: 53  loss: 0.19742291\n",
      "epoch:  3  batch: 54  loss: 0.59797561\n",
      "epoch:  3  batch: 55  loss: 0.36137119\n",
      "epoch:  3  batch: 56  loss: 0.18453878\n",
      "epoch:  3  batch: 57  loss: 0.08111423\n",
      "epoch:  3  batch: 58  loss: 0.46568468\n",
      "epoch:  3  batch: 59  loss: 0.38130665\n",
      "epoch:  3  batch: 60  loss: 0.45377034\n",
      "epoch:  3  batch: 61  loss: 0.81747878\n",
      "epoch:  3  batch: 62  loss: 0.22721390\n",
      "epoch:  3  batch: 63  loss: 0.27306843\n",
      "epoch:  3  batch: 64  loss: 0.12874824\n",
      "epoch:  3  batch: 65  loss: 0.24416491\n",
      "epoch:  3  batch: 66  loss: 0.51697361\n",
      "epoch:  3  batch: 67  loss: 0.20416307\n",
      "epoch:  3  batch: 68  loss: 0.49694875\n",
      "epoch:  4  batch: 1  loss: 0.44841161\n",
      "epoch:  4  batch: 2  loss: 0.14732412\n",
      "epoch:  4  batch: 3  loss: 0.11494049\n",
      "epoch:  4  batch: 4  loss: 0.10016324\n",
      "epoch:  4  batch: 5  loss: 0.20288628\n",
      "epoch:  4  batch: 6  loss: 0.15297045\n",
      "epoch:  4  batch: 7  loss: 0.23787066\n",
      "epoch:  4  batch: 8  loss: 0.07875828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4  batch: 9  loss: 0.05999782\n",
      "epoch:  4  batch: 10  loss: 0.07216310\n",
      "epoch:  4  batch: 11  loss: 0.06718153\n",
      "epoch:  4  batch: 12  loss: 0.43939304\n",
      "epoch:  4  batch: 13  loss: 0.84218115\n",
      "epoch:  4  batch: 14  loss: 0.28681472\n",
      "epoch:  4  batch: 15  loss: 0.15543585\n",
      "epoch:  4  batch: 16  loss: 0.27661842\n",
      "epoch:  4  batch: 17  loss: 0.33213997\n",
      "epoch:  4  batch: 18  loss: 0.15067542\n",
      "epoch:  4  batch: 19  loss: 0.14844562\n",
      "epoch:  4  batch: 20  loss: 0.60561073\n",
      "epoch:  4  batch: 21  loss: 0.47889447\n",
      "epoch:  4  batch: 22  loss: 0.13665348\n",
      "epoch:  4  batch: 23  loss: 0.15573990\n",
      "epoch:  4  batch: 24  loss: 0.22916476\n",
      "epoch:  4  batch: 25  loss: 0.15913332\n",
      "epoch:  4  batch: 26  loss: 0.46039471\n",
      "epoch:  4  batch: 27  loss: 0.85527074\n",
      "epoch:  4  batch: 28  loss: 0.42611942\n",
      "epoch:  4  batch: 29  loss: 0.26944241\n",
      "epoch:  4  batch: 30  loss: 0.16729744\n",
      "epoch:  4  batch: 31  loss: 0.11620615\n",
      "epoch:  4  batch: 32  loss: 0.26411849\n",
      "epoch:  4  batch: 33  loss: 0.23738635\n",
      "epoch:  4  batch: 34  loss: 0.23503251\n",
      "epoch:  4  batch: 35  loss: 0.25777948\n",
      "epoch:  4  batch: 36  loss: 0.06376857\n",
      "epoch:  4  batch: 37  loss: 0.04788593\n",
      "epoch:  4  batch: 38  loss: 0.04794438\n",
      "epoch:  4  batch: 39  loss: 0.17024414\n",
      "epoch:  4  batch: 40  loss: 0.07160904\n",
      "epoch:  4  batch: 41  loss: 0.19637206\n",
      "epoch:  4  batch: 42  loss: 0.20835610\n",
      "epoch:  4  batch: 43  loss: 0.19286405\n",
      "epoch:  4  batch: 44  loss: 0.17197345\n",
      "epoch:  4  batch: 45  loss: 0.12750013\n",
      "epoch:  4  batch: 46  loss: 0.42623901\n",
      "epoch:  4  batch: 47  loss: 0.55120319\n",
      "epoch:  4  batch: 48  loss: 0.28375199\n",
      "epoch:  4  batch: 49  loss: 0.20817716\n",
      "epoch:  4  batch: 50  loss: 0.42202064\n",
      "epoch:  4  batch: 51  loss: 0.37830108\n",
      "epoch:  4  batch: 52  loss: 0.12164413\n",
      "epoch:  4  batch: 53  loss: 0.21963751\n",
      "epoch:  4  batch: 54  loss: 0.47424924\n",
      "epoch:  4  batch: 55  loss: 0.35030252\n",
      "epoch:  4  batch: 56  loss: 0.16156340\n",
      "epoch:  4  batch: 57  loss: 0.09000270\n",
      "epoch:  4  batch: 58  loss: 0.26801938\n",
      "epoch:  4  batch: 59  loss: 0.23602882\n",
      "epoch:  4  batch: 60  loss: 0.33890781\n",
      "epoch:  4  batch: 61  loss: 0.70044565\n",
      "epoch:  4  batch: 62  loss: 0.23372835\n",
      "epoch:  4  batch: 63  loss: 0.18597341\n",
      "epoch:  4  batch: 64  loss: 0.14672558\n",
      "epoch:  4  batch: 65  loss: 0.06207997\n",
      "epoch:  4  batch: 66  loss: 0.21489814\n",
      "epoch:  4  batch: 67  loss: 0.27639914\n",
      "epoch:  4  batch: 68  loss: 0.26950616\n",
      "epoch:  5  batch: 1  loss: 0.39227059\n",
      "epoch:  5  batch: 2  loss: 0.05312258\n",
      "epoch:  5  batch: 3  loss: 0.21336946\n",
      "epoch:  5  batch: 4  loss: 0.05975482\n",
      "epoch:  5  batch: 5  loss: 0.23029511\n",
      "epoch:  5  batch: 6  loss: 0.12803529\n",
      "epoch:  5  batch: 7  loss: 0.33345780\n",
      "epoch:  5  batch: 8  loss: 0.06371703\n",
      "epoch:  5  batch: 9  loss: 0.17917189\n",
      "epoch:  5  batch: 10  loss: 0.08286013\n",
      "epoch:  5  batch: 11  loss: 0.08482324\n",
      "epoch:  5  batch: 12  loss: 0.54014748\n",
      "epoch:  5  batch: 13  loss: 0.86253136\n",
      "epoch:  5  batch: 14  loss: 0.37460375\n",
      "epoch:  5  batch: 15  loss: 0.23847856\n",
      "epoch:  5  batch: 16  loss: 0.35965800\n",
      "epoch:  5  batch: 17  loss: 0.60830098\n",
      "epoch:  5  batch: 18  loss: 0.11680655\n",
      "epoch:  5  batch: 19  loss: 0.14021583\n",
      "epoch:  5  batch: 20  loss: 0.50280368\n",
      "epoch:  5  batch: 21  loss: 0.49318197\n",
      "epoch:  5  batch: 22  loss: 0.17486630\n",
      "epoch:  5  batch: 23  loss: 0.12029222\n",
      "epoch:  5  batch: 24  loss: 0.16351816\n",
      "epoch:  5  batch: 25  loss: 0.37361923\n",
      "epoch:  5  batch: 26  loss: 0.36984941\n",
      "epoch:  5  batch: 27  loss: 0.40233833\n",
      "epoch:  5  batch: 28  loss: 0.29837614\n",
      "epoch:  5  batch: 29  loss: 0.17869386\n",
      "epoch:  5  batch: 30  loss: 0.11688288\n",
      "epoch:  5  batch: 31  loss: 0.08991178\n",
      "epoch:  5  batch: 32  loss: 0.06734601\n",
      "epoch:  5  batch: 33  loss: 0.14486715\n",
      "epoch:  5  batch: 34  loss: 0.13402377\n",
      "epoch:  5  batch: 35  loss: 0.25723538\n",
      "epoch:  5  batch: 36  loss: 0.07222526\n",
      "epoch:  5  batch: 37  loss: 0.06508493\n",
      "epoch:  5  batch: 38  loss: 0.03784666\n",
      "epoch:  5  batch: 39  loss: 0.25233391\n",
      "epoch:  5  batch: 40  loss: 0.09221084\n",
      "epoch:  5  batch: 41  loss: 0.28703436\n",
      "epoch:  5  batch: 42  loss: 0.16321710\n",
      "epoch:  5  batch: 43  loss: 0.15934713\n",
      "epoch:  5  batch: 44  loss: 0.22754151\n",
      "epoch:  5  batch: 45  loss: 0.18844563\n",
      "epoch:  5  batch: 46  loss: 0.36907336\n",
      "epoch:  5  batch: 47  loss: 0.48168260\n",
      "epoch:  5  batch: 48  loss: 0.26029080\n",
      "epoch:  5  batch: 49  loss: 0.20963135\n",
      "epoch:  5  batch: 50  loss: 0.39170787\n",
      "epoch:  5  batch: 51  loss: 0.33704314\n",
      "epoch:  5  batch: 52  loss: 0.13056920\n",
      "epoch:  5  batch: 53  loss: 0.17935506\n",
      "epoch:  5  batch: 54  loss: 0.42571497\n",
      "epoch:  5  batch: 55  loss: 0.27988720\n",
      "epoch:  5  batch: 56  loss: 0.12773737\n",
      "epoch:  5  batch: 57  loss: 0.10123054\n",
      "epoch:  5  batch: 58  loss: 0.17520647\n",
      "epoch:  5  batch: 59  loss: 0.13777591\n",
      "epoch:  5  batch: 60  loss: 0.46707433\n",
      "epoch:  5  batch: 61  loss: 0.67436755\n",
      "epoch:  5  batch: 62  loss: 0.20494436\n",
      "epoch:  5  batch: 63  loss: 0.15164125\n",
      "epoch:  5  batch: 64  loss: 0.22070818\n",
      "epoch:  5  batch: 65  loss: 0.06986513\n",
      "epoch:  5  batch: 66  loss: 0.17173599\n",
      "epoch:  5  batch: 67  loss: 0.28211507\n",
      "epoch:  5  batch: 68  loss: 0.38476709\n",
      "epoch:  6  batch: 1  loss: 0.90371960\n",
      "epoch:  6  batch: 2  loss: 0.06690460\n",
      "epoch:  6  batch: 3  loss: 0.12988056\n",
      "epoch:  6  batch: 4  loss: 0.03072532\n",
      "epoch:  6  batch: 5  loss: 0.16483070\n",
      "epoch:  6  batch: 6  loss: 0.10983773\n",
      "epoch:  6  batch: 7  loss: 0.31574458\n",
      "epoch:  6  batch: 8  loss: 0.08408578\n",
      "epoch:  6  batch: 9  loss: 0.13176103\n",
      "epoch:  6  batch: 10  loss: 0.12245083\n",
      "epoch:  6  batch: 11  loss: 0.16468920\n",
      "epoch:  6  batch: 12  loss: 0.16458656\n",
      "epoch:  6  batch: 13  loss: 0.80195940\n",
      "epoch:  6  batch: 14  loss: 0.35534596\n",
      "epoch:  6  batch: 15  loss: 0.27705321\n",
      "epoch:  6  batch: 16  loss: 0.34626248\n",
      "epoch:  6  batch: 17  loss: 0.77369750\n",
      "epoch:  6  batch: 18  loss: 0.24621865\n",
      "epoch:  6  batch: 19  loss: 0.14200339\n",
      "epoch:  6  batch: 20  loss: 0.46010095\n",
      "epoch:  6  batch: 21  loss: 0.51443392\n",
      "epoch:  6  batch: 22  loss: 0.18259554\n",
      "epoch:  6  batch: 23  loss: 0.10415490\n",
      "epoch:  6  batch: 24  loss: 0.16183335\n",
      "epoch:  6  batch: 25  loss: 0.11679883\n",
      "epoch:  6  batch: 26  loss: 0.47028902\n",
      "epoch:  6  batch: 27  loss: 0.66767102\n",
      "epoch:  6  batch: 28  loss: 0.49349672\n",
      "epoch:  6  batch: 29  loss: 0.26942015\n",
      "epoch:  6  batch: 30  loss: 0.16085775\n",
      "epoch:  6  batch: 31  loss: 0.10543453\n",
      "epoch:  6  batch: 32  loss: 0.08106861\n",
      "epoch:  6  batch: 33  loss: 0.14657180\n",
      "epoch:  6  batch: 34  loss: 0.36773688\n",
      "epoch:  6  batch: 35  loss: 0.27978405\n",
      "epoch:  6  batch: 36  loss: 0.11276819\n",
      "epoch:  6  batch: 37  loss: 0.08017574\n",
      "epoch:  6  batch: 38  loss: 0.04557683\n",
      "epoch:  6  batch: 39  loss: 0.18583196\n",
      "epoch:  6  batch: 40  loss: 0.07905156\n",
      "epoch:  6  batch: 41  loss: 0.26400065\n",
      "epoch:  6  batch: 42  loss: 0.18572286\n",
      "epoch:  6  batch: 43  loss: 0.18802221\n",
      "epoch:  6  batch: 44  loss: 0.24233711\n",
      "epoch:  6  batch: 45  loss: 0.18770434\n",
      "epoch:  6  batch: 46  loss: 0.29626876\n",
      "epoch:  6  batch: 47  loss: 0.38977417\n",
      "epoch:  6  batch: 48  loss: 0.21601622\n",
      "epoch:  6  batch: 49  loss: 0.23325263\n",
      "epoch:  6  batch: 50  loss: 0.39535359\n",
      "epoch:  6  batch: 51  loss: 0.27891636\n",
      "epoch:  6  batch: 52  loss: 0.14466961\n",
      "epoch:  6  batch: 53  loss: 0.14613277\n",
      "epoch:  6  batch: 54  loss: 0.37821785\n",
      "epoch:  6  batch: 55  loss: 0.22847138\n",
      "epoch:  6  batch: 56  loss: 0.08501039\n",
      "epoch:  6  batch: 57  loss: 0.08724321\n",
      "epoch:  6  batch: 58  loss: 0.18912828\n",
      "epoch:  6  batch: 59  loss: 0.17815344\n",
      "epoch:  6  batch: 60  loss: 0.49366558\n",
      "epoch:  6  batch: 61  loss: 0.62620741\n",
      "epoch:  6  batch: 62  loss: 0.28727257\n",
      "epoch:  6  batch: 63  loss: 0.21853887\n",
      "epoch:  6  batch: 64  loss: 0.17177150\n",
      "epoch:  6  batch: 65  loss: 0.06784642\n",
      "epoch:  6  batch: 66  loss: 0.11975160\n",
      "epoch:  6  batch: 67  loss: 0.26291665\n",
      "epoch:  6  batch: 68  loss: 0.58479410\n",
      "epoch:  7  batch: 1  loss: 0.77974975\n",
      "epoch:  7  batch: 2  loss: 0.06579866\n",
      "epoch:  7  batch: 3  loss: 0.18807314\n",
      "epoch:  7  batch: 4  loss: 0.05747570\n",
      "epoch:  7  batch: 5  loss: 0.20300853\n",
      "epoch:  7  batch: 6  loss: 0.18829826\n",
      "epoch:  7  batch: 7  loss: 0.32581168\n",
      "epoch:  7  batch: 8  loss: 0.11666936\n",
      "epoch:  7  batch: 9  loss: 0.11281078\n",
      "epoch:  7  batch: 10  loss: 0.18565093\n",
      "epoch:  7  batch: 11  loss: 0.16142543\n",
      "epoch:  7  batch: 12  loss: 0.50063378\n",
      "epoch:  7  batch: 13  loss: 0.83600497\n",
      "epoch:  7  batch: 14  loss: 0.31122276\n",
      "epoch:  7  batch: 15  loss: 0.30128059\n",
      "epoch:  7  batch: 16  loss: 0.46798581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7  batch: 17  loss: 0.73681813\n",
      "epoch:  7  batch: 18  loss: 0.23020957\n",
      "epoch:  7  batch: 19  loss: 0.19736888\n",
      "epoch:  7  batch: 20  loss: 0.39933139\n",
      "epoch:  7  batch: 21  loss: 0.40251186\n",
      "epoch:  7  batch: 22  loss: 0.12810956\n",
      "epoch:  7  batch: 23  loss: 0.07512070\n",
      "epoch:  7  batch: 24  loss: 0.10233276\n",
      "epoch:  7  batch: 25  loss: 0.11058415\n",
      "epoch:  7  batch: 26  loss: 0.56936234\n",
      "epoch:  7  batch: 27  loss: 0.80324954\n",
      "epoch:  7  batch: 28  loss: 0.35701466\n",
      "epoch:  7  batch: 29  loss: 0.12047467\n",
      "epoch:  7  batch: 30  loss: 0.05278700\n",
      "epoch:  7  batch: 31  loss: 0.11895305\n",
      "epoch:  7  batch: 32  loss: 0.13926420\n",
      "epoch:  7  batch: 33  loss: 0.27744827\n",
      "epoch:  7  batch: 34  loss: 0.22407335\n",
      "epoch:  7  batch: 35  loss: 0.26579958\n",
      "epoch:  7  batch: 36  loss: 0.04672844\n",
      "epoch:  7  batch: 37  loss: 0.11092166\n",
      "epoch:  7  batch: 38  loss: 0.05031622\n",
      "epoch:  7  batch: 39  loss: 0.23462702\n",
      "epoch:  7  batch: 40  loss: 0.09746787\n",
      "epoch:  7  batch: 41  loss: 0.22880457\n",
      "epoch:  7  batch: 42  loss: 0.16272815\n",
      "epoch:  7  batch: 43  loss: 0.20582440\n",
      "epoch:  7  batch: 44  loss: 0.16802178\n",
      "epoch:  7  batch: 45  loss: 0.19438185\n",
      "epoch:  7  batch: 46  loss: 0.41805413\n",
      "epoch:  7  batch: 47  loss: 0.49285516\n",
      "epoch:  7  batch: 48  loss: 0.39010927\n",
      "epoch:  7  batch: 49  loss: 0.21531068\n",
      "epoch:  7  batch: 50  loss: 0.41595203\n",
      "epoch:  7  batch: 51  loss: 0.39785615\n",
      "epoch:  7  batch: 52  loss: 0.13464375\n",
      "epoch:  7  batch: 53  loss: 0.30232868\n",
      "epoch:  7  batch: 54  loss: 0.53576660\n",
      "epoch:  7  batch: 55  loss: 0.35219508\n",
      "epoch:  7  batch: 56  loss: 0.16571584\n",
      "epoch:  7  batch: 57  loss: 0.09489011\n",
      "epoch:  7  batch: 58  loss: 0.09821926\n",
      "epoch:  7  batch: 59  loss: 0.20358434\n",
      "epoch:  7  batch: 60  loss: 0.38240975\n",
      "epoch:  7  batch: 61  loss: 0.66496229\n",
      "epoch:  7  batch: 62  loss: 0.16896157\n",
      "epoch:  7  batch: 63  loss: 0.22536568\n",
      "epoch:  7  batch: 64  loss: 0.12997082\n",
      "epoch:  7  batch: 65  loss: 0.08936293\n",
      "epoch:  7  batch: 66  loss: 0.19686513\n",
      "epoch:  7  batch: 67  loss: 0.22792825\n",
      "epoch:  7  batch: 68  loss: 0.36395332\n",
      "epoch:  8  batch: 1  loss: 0.38129035\n",
      "epoch:  8  batch: 2  loss: 0.07570038\n",
      "epoch:  8  batch: 3  loss: 0.05938546\n",
      "epoch:  8  batch: 4  loss: 0.08846525\n",
      "epoch:  8  batch: 5  loss: 0.13854265\n",
      "epoch:  8  batch: 6  loss: 0.21897316\n",
      "epoch:  8  batch: 7  loss: 0.29194054\n",
      "epoch:  8  batch: 8  loss: 0.10956969\n",
      "epoch:  8  batch: 9  loss: 0.12691638\n",
      "epoch:  8  batch: 10  loss: 0.14394040\n",
      "epoch:  8  batch: 11  loss: 0.16565457\n",
      "epoch:  8  batch: 12  loss: 0.37160060\n",
      "epoch:  8  batch: 13  loss: 0.59303617\n",
      "epoch:  8  batch: 14  loss: 0.31405306\n",
      "epoch:  8  batch: 15  loss: 0.29385063\n",
      "epoch:  8  batch: 16  loss: 0.34620211\n",
      "epoch:  8  batch: 17  loss: 0.49715754\n",
      "epoch:  8  batch: 18  loss: 0.21881092\n",
      "epoch:  8  batch: 19  loss: 0.15067837\n",
      "epoch:  8  batch: 20  loss: 0.31042472\n",
      "epoch:  8  batch: 21  loss: 0.35038891\n",
      "epoch:  8  batch: 22  loss: 0.12519540\n",
      "epoch:  8  batch: 23  loss: 0.05681220\n",
      "epoch:  8  batch: 24  loss: 0.18630755\n",
      "epoch:  8  batch: 25  loss: 0.21790208\n",
      "epoch:  8  batch: 26  loss: 0.25001597\n",
      "epoch:  8  batch: 27  loss: 0.60928863\n",
      "epoch:  8  batch: 28  loss: 0.22850311\n",
      "epoch:  8  batch: 29  loss: 0.14012057\n",
      "epoch:  8  batch: 30  loss: 0.11314921\n",
      "epoch:  8  batch: 31  loss: 0.15121619\n",
      "epoch:  8  batch: 32  loss: 0.21473250\n",
      "epoch:  8  batch: 33  loss: 0.38764301\n",
      "epoch:  8  batch: 34  loss: 0.33666903\n",
      "epoch:  8  batch: 35  loss: 0.35952544\n",
      "epoch:  8  batch: 36  loss: 0.06923740\n",
      "epoch:  8  batch: 37  loss: 0.05093639\n",
      "epoch:  8  batch: 38  loss: 0.05393123\n",
      "epoch:  8  batch: 39  loss: 0.15274315\n",
      "epoch:  8  batch: 40  loss: 0.07942687\n",
      "epoch:  8  batch: 41  loss: 0.22758478\n",
      "epoch:  8  batch: 42  loss: 0.09089712\n",
      "epoch:  8  batch: 43  loss: 0.08637127\n",
      "epoch:  8  batch: 44  loss: 0.12184699\n",
      "epoch:  8  batch: 45  loss: 0.10163124\n",
      "epoch:  8  batch: 46  loss: 0.44007647\n",
      "epoch:  8  batch: 47  loss: 0.55313104\n",
      "epoch:  8  batch: 48  loss: 0.31374255\n",
      "epoch:  8  batch: 49  loss: 0.20505568\n",
      "epoch:  8  batch: 50  loss: 0.44784021\n",
      "epoch:  8  batch: 51  loss: 0.37398157\n",
      "epoch:  8  batch: 52  loss: 0.11400522\n",
      "epoch:  8  batch: 53  loss: 0.19639893\n",
      "epoch:  8  batch: 54  loss: 0.42117107\n",
      "epoch:  8  batch: 55  loss: 0.29212028\n",
      "epoch:  8  batch: 56  loss: 0.11834674\n",
      "epoch:  8  batch: 57  loss: 0.09155664\n",
      "epoch:  8  batch: 58  loss: 0.15378837\n",
      "epoch:  8  batch: 59  loss: 0.18680085\n",
      "epoch:  8  batch: 60  loss: 0.27814382\n",
      "epoch:  8  batch: 61  loss: 0.66573215\n",
      "epoch:  8  batch: 62  loss: 0.13663070\n",
      "epoch:  8  batch: 63  loss: 0.25393072\n",
      "epoch:  8  batch: 64  loss: 0.09083194\n",
      "epoch:  8  batch: 65  loss: 0.05790118\n",
      "epoch:  8  batch: 66  loss: 0.21594010\n",
      "epoch:  8  batch: 67  loss: 0.29596350\n",
      "epoch:  8  batch: 68  loss: 0.26661986\n",
      "epoch:  9  batch: 1  loss: 0.34721994\n",
      "epoch:  9  batch: 2  loss: 0.18980086\n",
      "epoch:  9  batch: 3  loss: 0.06960593\n",
      "epoch:  9  batch: 4  loss: 0.03826468\n",
      "epoch:  9  batch: 5  loss: 0.21099332\n",
      "epoch:  9  batch: 6  loss: 0.12010458\n",
      "epoch:  9  batch: 7  loss: 0.22096573\n",
      "epoch:  9  batch: 8  loss: 0.06741922\n",
      "epoch:  9  batch: 9  loss: 0.14760442\n",
      "epoch:  9  batch: 10  loss: 0.16120207\n",
      "epoch:  9  batch: 11  loss: 0.13422751\n",
      "epoch:  9  batch: 12  loss: 0.33264387\n",
      "epoch:  9  batch: 13  loss: 0.64442497\n",
      "epoch:  9  batch: 14  loss: 0.34071857\n",
      "epoch:  9  batch: 15  loss: 0.29539257\n",
      "epoch:  9  batch: 16  loss: 0.39237592\n",
      "epoch:  9  batch: 17  loss: 0.61634898\n",
      "epoch:  9  batch: 18  loss: 0.19320363\n",
      "epoch:  9  batch: 19  loss: 0.16159546\n",
      "epoch:  9  batch: 20  loss: 0.32613185\n",
      "epoch:  9  batch: 21  loss: 0.35850722\n",
      "epoch:  9  batch: 22  loss: 0.09332382\n",
      "epoch:  9  batch: 23  loss: 0.07017732\n",
      "epoch:  9  batch: 24  loss: 0.08476864\n",
      "epoch:  9  batch: 25  loss: 0.17237458\n",
      "epoch:  9  batch: 26  loss: 0.20549022\n",
      "epoch:  9  batch: 27  loss: 0.59526563\n",
      "epoch:  9  batch: 28  loss: 0.19986153\n",
      "epoch:  9  batch: 29  loss: 0.12530443\n",
      "epoch:  9  batch: 30  loss: 0.08010181\n",
      "epoch:  9  batch: 31  loss: 0.11451735\n",
      "epoch:  9  batch: 32  loss: 0.28003141\n",
      "epoch:  9  batch: 33  loss: 0.23977880\n",
      "epoch:  9  batch: 34  loss: 0.12322571\n",
      "epoch:  9  batch: 35  loss: 0.30828968\n",
      "epoch:  9  batch: 36  loss: 0.10622905\n",
      "epoch:  9  batch: 37  loss: 0.11521643\n",
      "epoch:  9  batch: 38  loss: 0.06937488\n",
      "epoch:  9  batch: 39  loss: 0.32525510\n",
      "epoch:  9  batch: 40  loss: 0.09656635\n",
      "epoch:  9  batch: 41  loss: 0.24941210\n",
      "epoch:  9  batch: 42  loss: 0.11842211\n",
      "epoch:  9  batch: 43  loss: 0.10367171\n",
      "epoch:  9  batch: 44  loss: 0.16770943\n",
      "epoch:  9  batch: 45  loss: 0.15386699\n",
      "epoch:  9  batch: 46  loss: 0.40002698\n",
      "epoch:  9  batch: 47  loss: 0.53634262\n",
      "epoch:  9  batch: 48  loss: 0.36918998\n",
      "epoch:  9  batch: 49  loss: 0.22850473\n",
      "epoch:  9  batch: 50  loss: 0.47879174\n",
      "epoch:  9  batch: 51  loss: 0.39196146\n",
      "epoch:  9  batch: 52  loss: 0.19230105\n",
      "epoch:  9  batch: 53  loss: 0.23571604\n",
      "epoch:  9  batch: 54  loss: 0.37134147\n",
      "epoch:  9  batch: 55  loss: 0.24845548\n",
      "epoch:  9  batch: 56  loss: 0.09870283\n",
      "epoch:  9  batch: 57  loss: 0.07854744\n",
      "epoch:  9  batch: 58  loss: 0.10064153\n",
      "epoch:  9  batch: 59  loss: 0.14795567\n",
      "epoch:  9  batch: 60  loss: 0.40921208\n",
      "epoch:  9  batch: 61  loss: 0.74029273\n",
      "epoch:  9  batch: 62  loss: 0.17345834\n",
      "epoch:  9  batch: 63  loss: 0.28085241\n",
      "epoch:  9  batch: 64  loss: 0.09148015\n",
      "epoch:  9  batch: 65  loss: 0.11172166\n",
      "epoch:  9  batch: 66  loss: 0.21461770\n",
      "epoch:  9  batch: 67  loss: 0.25579634\n",
      "epoch:  9  batch: 68  loss: 0.37513393\n",
      "epoch: 10  batch: 1  loss: 0.31564230\n",
      "epoch: 10  batch: 2  loss: 0.19305092\n",
      "epoch: 10  batch: 3  loss: 0.13260041\n",
      "epoch: 10  batch: 4  loss: 0.05698233\n",
      "epoch: 10  batch: 5  loss: 0.19542974\n",
      "epoch: 10  batch: 6  loss: 0.13912214\n",
      "epoch: 10  batch: 7  loss: 0.31437862\n",
      "epoch: 10  batch: 8  loss: 0.08390700\n",
      "epoch: 10  batch: 9  loss: 0.14463590\n",
      "epoch: 10  batch: 10  loss: 0.12406122\n",
      "epoch: 10  batch: 11  loss: 0.12050179\n",
      "epoch: 10  batch: 12  loss: 0.28452489\n",
      "epoch: 10  batch: 13  loss: 0.66827071\n",
      "epoch: 10  batch: 14  loss: 0.41170561\n",
      "epoch: 10  batch: 15  loss: 0.18080987\n",
      "epoch: 10  batch: 16  loss: 0.44357219\n",
      "epoch: 10  batch: 17  loss: 0.61713159\n",
      "epoch: 10  batch: 18  loss: 0.20357087\n",
      "epoch: 10  batch: 19  loss: 0.20063956\n",
      "epoch: 10  batch: 20  loss: 0.38222605\n",
      "epoch: 10  batch: 21  loss: 0.43081132\n",
      "epoch: 10  batch: 22  loss: 0.10211336\n",
      "epoch: 10  batch: 23  loss: 0.07626511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10  batch: 24  loss: 0.05373032\n",
      "epoch: 10  batch: 25  loss: 0.11455397\n",
      "epoch: 10  batch: 26  loss: 0.25851691\n",
      "epoch: 10  batch: 27  loss: 0.81448102\n",
      "epoch: 10  batch: 28  loss: 0.26181433\n",
      "epoch: 10  batch: 29  loss: 0.21030720\n",
      "epoch: 10  batch: 30  loss: 0.12950009\n",
      "epoch: 10  batch: 31  loss: 0.07002777\n",
      "epoch: 10  batch: 32  loss: 0.18805432\n",
      "epoch: 10  batch: 33  loss: 0.25237793\n",
      "epoch: 10  batch: 34  loss: 0.20595628\n",
      "epoch: 10  batch: 35  loss: 0.39444453\n",
      "epoch: 10  batch: 36  loss: 0.09282320\n",
      "epoch: 10  batch: 37  loss: 0.10343486\n",
      "epoch: 10  batch: 38  loss: 0.18261181\n",
      "epoch: 10  batch: 39  loss: 0.27340695\n",
      "epoch: 10  batch: 40  loss: 0.13586743\n",
      "epoch: 10  batch: 41  loss: 0.26689366\n",
      "epoch: 10  batch: 42  loss: 0.25269276\n",
      "epoch: 10  batch: 43  loss: 0.18461604\n",
      "epoch: 10  batch: 44  loss: 0.21001142\n",
      "epoch: 10  batch: 45  loss: 0.23847723\n",
      "epoch: 10  batch: 46  loss: 0.28099933\n",
      "epoch: 10  batch: 47  loss: 0.37562740\n",
      "epoch: 10  batch: 48  loss: 0.26668465\n",
      "epoch: 10  batch: 49  loss: 0.19576433\n",
      "epoch: 10  batch: 50  loss: 0.38757342\n",
      "epoch: 10  batch: 51  loss: 0.34136030\n",
      "epoch: 10  batch: 52  loss: 0.19991536\n",
      "epoch: 10  batch: 53  loss: 0.28483984\n",
      "epoch: 10  batch: 54  loss: 0.44172809\n",
      "epoch: 10  batch: 55  loss: 0.25218895\n",
      "epoch: 10  batch: 56  loss: 0.10613060\n",
      "epoch: 10  batch: 57  loss: 0.10393647\n",
      "epoch: 10  batch: 58  loss: 0.11255695\n",
      "epoch: 10  batch: 59  loss: 0.13533033\n",
      "epoch: 10  batch: 60  loss: 0.37025651\n",
      "epoch: 10  batch: 61  loss: 0.78632593\n",
      "epoch: 10  batch: 62  loss: 0.20482977\n",
      "epoch: 10  batch: 63  loss: 0.28542596\n",
      "epoch: 10  batch: 64  loss: 0.11743785\n",
      "epoch: 10  batch: 65  loss: 0.05581502\n",
      "epoch: 10  batch: 66  loss: 0.32132378\n",
      "epoch: 10  batch: 67  loss: 0.38791454\n",
      "epoch: 10  batch: 68  loss: 0.42240825\n",
      "epoch: 11  batch: 1  loss: 0.27548155\n",
      "epoch: 11  batch: 2  loss: 0.07934873\n",
      "epoch: 11  batch: 3  loss: 0.08403097\n",
      "epoch: 11  batch: 4  loss: 0.03498290\n",
      "epoch: 11  batch: 5  loss: 0.11942592\n",
      "epoch: 11  batch: 6  loss: 0.10172918\n",
      "epoch: 11  batch: 7  loss: 0.26154697\n",
      "epoch: 11  batch: 8  loss: 0.07337928\n",
      "epoch: 11  batch: 9  loss: 0.09711232\n",
      "epoch: 11  batch: 10  loss: 0.11164763\n",
      "epoch: 11  batch: 11  loss: 0.14838792\n",
      "epoch: 11  batch: 12  loss: 0.32911533\n",
      "epoch: 11  batch: 13  loss: 0.72814858\n",
      "epoch: 11  batch: 14  loss: 0.31970054\n",
      "epoch: 11  batch: 15  loss: 0.17625432\n",
      "epoch: 11  batch: 16  loss: 0.30207729\n",
      "epoch: 11  batch: 17  loss: 0.41461399\n",
      "epoch: 11  batch: 18  loss: 0.08261149\n",
      "epoch: 11  batch: 19  loss: 0.07826302\n",
      "epoch: 11  batch: 20  loss: 0.39851278\n",
      "epoch: 11  batch: 21  loss: 0.46418077\n",
      "epoch: 11  batch: 22  loss: 0.15587555\n",
      "epoch: 11  batch: 23  loss: 0.08961619\n",
      "epoch: 11  batch: 24  loss: 0.13180241\n",
      "epoch: 11  batch: 25  loss: 0.20999832\n",
      "epoch: 11  batch: 26  loss: 0.12588531\n",
      "epoch: 11  batch: 27  loss: 0.34124961\n",
      "epoch: 11  batch: 28  loss: 0.19418415\n",
      "epoch: 11  batch: 29  loss: 0.11577615\n",
      "epoch: 11  batch: 30  loss: 0.06540248\n",
      "epoch: 11  batch: 31  loss: 0.05316858\n",
      "epoch: 11  batch: 32  loss: 0.12258549\n",
      "epoch: 11  batch: 33  loss: 0.16521543\n",
      "epoch: 11  batch: 34  loss: 0.19100128\n",
      "epoch: 11  batch: 35  loss: 0.29928836\n",
      "epoch: 11  batch: 36  loss: 0.10869249\n",
      "epoch: 11  batch: 37  loss: 0.12653458\n",
      "epoch: 11  batch: 38  loss: 0.04938554\n",
      "epoch: 11  batch: 39  loss: 0.24404284\n",
      "epoch: 11  batch: 40  loss: 0.08453690\n",
      "epoch: 11  batch: 41  loss: 0.27523294\n",
      "epoch: 11  batch: 42  loss: 0.13162506\n",
      "epoch: 11  batch: 43  loss: 0.12958489\n",
      "epoch: 11  batch: 44  loss: 0.14078158\n",
      "epoch: 11  batch: 45  loss: 0.06663677\n",
      "epoch: 11  batch: 46  loss: 0.42758346\n",
      "epoch: 11  batch: 47  loss: 0.53658170\n",
      "epoch: 11  batch: 48  loss: 0.42716214\n",
      "epoch: 11  batch: 49  loss: 0.17906906\n",
      "epoch: 11  batch: 50  loss: 0.33324251\n",
      "epoch: 11  batch: 51  loss: 0.22961451\n",
      "epoch: 11  batch: 52  loss: 0.09030668\n",
      "epoch: 11  batch: 53  loss: 0.08052681\n",
      "epoch: 11  batch: 54  loss: 0.34223291\n",
      "epoch: 11  batch: 55  loss: 0.23389448\n",
      "epoch: 11  batch: 56  loss: 0.13819815\n",
      "epoch: 11  batch: 57  loss: 0.05903046\n",
      "epoch: 11  batch: 58  loss: 0.28034276\n",
      "epoch: 11  batch: 59  loss: 0.22106074\n",
      "epoch: 11  batch: 60  loss: 0.30576846\n",
      "epoch: 11  batch: 61  loss: 0.66635215\n",
      "epoch: 11  batch: 62  loss: 0.14318089\n",
      "epoch: 11  batch: 63  loss: 0.19645412\n",
      "epoch: 11  batch: 64  loss: 0.07051209\n",
      "epoch: 11  batch: 65  loss: 0.12554450\n",
      "epoch: 11  batch: 66  loss: 0.25434300\n",
      "epoch: 11  batch: 67  loss: 0.31243634\n",
      "epoch: 11  batch: 68  loss: 0.35967621\n",
      "epoch: 12  batch: 1  loss: 0.43653363\n",
      "epoch: 12  batch: 2  loss: 0.09075902\n",
      "epoch: 12  batch: 3  loss: 0.14197604\n",
      "epoch: 12  batch: 4  loss: 0.05475849\n",
      "epoch: 12  batch: 5  loss: 0.14744502\n",
      "epoch: 12  batch: 6  loss: 0.09077528\n",
      "epoch: 12  batch: 7  loss: 0.26987132\n",
      "epoch: 12  batch: 8  loss: 0.07483611\n",
      "epoch: 12  batch: 9  loss: 0.11716542\n",
      "epoch: 12  batch: 10  loss: 0.10628147\n",
      "epoch: 12  batch: 11  loss: 0.10949131\n",
      "epoch: 12  batch: 12  loss: 0.44294235\n",
      "epoch: 12  batch: 13  loss: 0.82427132\n",
      "epoch: 12  batch: 14  loss: 0.49467358\n",
      "epoch: 12  batch: 15  loss: 0.32479560\n",
      "epoch: 12  batch: 16  loss: 0.33653048\n",
      "epoch: 12  batch: 17  loss: 0.51181686\n",
      "epoch: 12  batch: 18  loss: 0.13808045\n",
      "epoch: 12  batch: 19  loss: 0.16971630\n",
      "epoch: 12  batch: 20  loss: 0.39426038\n",
      "epoch: 12  batch: 21  loss: 0.50581503\n",
      "epoch: 12  batch: 22  loss: 0.14309447\n",
      "epoch: 12  batch: 23  loss: 0.07665204\n",
      "epoch: 12  batch: 24  loss: 0.08165675\n",
      "epoch: 12  batch: 25  loss: 0.17013940\n",
      "epoch: 12  batch: 26  loss: 0.14150299\n",
      "epoch: 12  batch: 27  loss: 0.46491483\n",
      "epoch: 12  batch: 28  loss: 0.17544441\n",
      "epoch: 12  batch: 29  loss: 0.11057188\n",
      "epoch: 12  batch: 30  loss: 0.06331546\n",
      "epoch: 12  batch: 31  loss: 0.10784427\n",
      "epoch: 12  batch: 32  loss: 0.19495150\n",
      "epoch: 12  batch: 33  loss: 0.30014068\n",
      "epoch: 12  batch: 34  loss: 0.21623389\n",
      "epoch: 12  batch: 35  loss: 0.36669651\n",
      "epoch: 12  batch: 36  loss: 0.14867081\n",
      "epoch: 12  batch: 37  loss: 0.11302426\n",
      "epoch: 12  batch: 38  loss: 0.03699931\n",
      "epoch: 12  batch: 39  loss: 0.24794909\n",
      "epoch: 12  batch: 40  loss: 0.06962758\n",
      "epoch: 12  batch: 41  loss: 0.23318304\n",
      "epoch: 12  batch: 42  loss: 0.16010317\n",
      "epoch: 12  batch: 43  loss: 0.10933221\n",
      "epoch: 12  batch: 44  loss: 0.14252353\n",
      "epoch: 12  batch: 45  loss: 0.06209785\n",
      "epoch: 12  batch: 46  loss: 0.43555939\n",
      "epoch: 12  batch: 47  loss: 0.98610961\n",
      "epoch: 12  batch: 48  loss: 0.30405116\n",
      "epoch: 12  batch: 49  loss: 0.20217192\n",
      "epoch: 12  batch: 50  loss: 0.41334069\n",
      "epoch: 12  batch: 51  loss: 0.34560165\n",
      "epoch: 12  batch: 52  loss: 0.12535979\n",
      "epoch: 12  batch: 53  loss: 0.15813647\n",
      "epoch: 12  batch: 54  loss: 0.35774991\n",
      "epoch: 12  batch: 55  loss: 0.22963110\n",
      "epoch: 12  batch: 56  loss: 0.10497491\n",
      "epoch: 12  batch: 57  loss: 0.04362996\n",
      "epoch: 12  batch: 58  loss: 0.19655423\n",
      "epoch: 12  batch: 59  loss: 0.23325586\n",
      "epoch: 12  batch: 60  loss: 0.29416123\n",
      "epoch: 12  batch: 61  loss: 0.64444619\n",
      "epoch: 12  batch: 62  loss: 0.13572305\n",
      "epoch: 12  batch: 63  loss: 0.16595332\n",
      "epoch: 12  batch: 64  loss: 0.05140151\n",
      "epoch: 12  batch: 65  loss: 0.20949544\n",
      "epoch: 12  batch: 66  loss: 0.26811990\n",
      "epoch: 12  batch: 67  loss: 0.32303119\n",
      "epoch: 12  batch: 68  loss: 0.41834995\n",
      "epoch: 13  batch: 1  loss: 0.44528377\n",
      "epoch: 13  batch: 2  loss: 0.10970508\n",
      "epoch: 13  batch: 3  loss: 0.08494701\n",
      "epoch: 13  batch: 4  loss: 0.06332868\n",
      "epoch: 13  batch: 5  loss: 0.09845224\n",
      "epoch: 13  batch: 6  loss: 0.11006212\n",
      "epoch: 13  batch: 7  loss: 0.23204337\n",
      "epoch: 13  batch: 8  loss: 0.05147294\n",
      "epoch: 13  batch: 9  loss: 0.07270534\n",
      "epoch: 13  batch: 10  loss: 0.08184081\n",
      "epoch: 13  batch: 11  loss: 0.07281704\n",
      "epoch: 13  batch: 12  loss: 0.50008285\n",
      "epoch: 13  batch: 13  loss: 1.01243818\n",
      "epoch: 13  batch: 14  loss: 0.36945745\n",
      "epoch: 13  batch: 15  loss: 0.20458788\n",
      "epoch: 13  batch: 16  loss: 0.25100261\n",
      "epoch: 13  batch: 17  loss: 0.43236205\n",
      "epoch: 13  batch: 18  loss: 0.12231011\n",
      "epoch: 13  batch: 19  loss: 0.10202152\n",
      "epoch: 13  batch: 20  loss: 0.45011470\n",
      "epoch: 13  batch: 21  loss: 0.41762000\n",
      "epoch: 13  batch: 22  loss: 0.16359834\n",
      "epoch: 13  batch: 23  loss: 0.08450355\n",
      "epoch: 13  batch: 24  loss: 0.11270033\n",
      "epoch: 13  batch: 25  loss: 0.17451042\n",
      "epoch: 13  batch: 26  loss: 0.24236542\n",
      "epoch: 13  batch: 27  loss: 0.42568856\n",
      "epoch: 13  batch: 28  loss: 0.23027815\n",
      "epoch: 13  batch: 29  loss: 0.22231679\n",
      "epoch: 13  batch: 30  loss: 0.17711122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13  batch: 31  loss: 0.06652821\n",
      "epoch: 13  batch: 32  loss: 0.10619435\n",
      "epoch: 13  batch: 33  loss: 0.23642881\n",
      "epoch: 13  batch: 34  loss: 0.13923372\n",
      "epoch: 13  batch: 35  loss: 0.24617209\n",
      "epoch: 13  batch: 36  loss: 0.16529161\n",
      "epoch: 13  batch: 37  loss: 0.11511940\n",
      "epoch: 13  batch: 38  loss: 0.08073137\n",
      "epoch: 13  batch: 39  loss: 0.27112982\n",
      "epoch: 13  batch: 40  loss: 0.08261190\n",
      "epoch: 13  batch: 41  loss: 0.27754965\n",
      "epoch: 13  batch: 42  loss: 0.18154030\n",
      "epoch: 13  batch: 43  loss: 0.25645754\n",
      "epoch: 13  batch: 44  loss: 0.23695382\n",
      "epoch: 13  batch: 45  loss: 0.19972906\n",
      "epoch: 13  batch: 46  loss: 0.30111408\n",
      "epoch: 13  batch: 47  loss: 0.51918364\n",
      "epoch: 13  batch: 48  loss: 0.29043666\n",
      "epoch: 13  batch: 49  loss: 0.20829612\n",
      "epoch: 13  batch: 50  loss: 0.52751768\n",
      "epoch: 13  batch: 51  loss: 0.51480991\n",
      "epoch: 13  batch: 52  loss: 0.25505877\n",
      "epoch: 13  batch: 53  loss: 0.30769765\n",
      "epoch: 13  batch: 54  loss: 0.42540035\n",
      "epoch: 13  batch: 55  loss: 0.27953506\n",
      "epoch: 13  batch: 56  loss: 0.13643974\n",
      "epoch: 13  batch: 57  loss: 0.11502235\n",
      "epoch: 13  batch: 58  loss: 0.08243728\n",
      "epoch: 13  batch: 59  loss: 0.13218895\n",
      "epoch: 13  batch: 60  loss: 0.47306931\n",
      "epoch: 13  batch: 61  loss: 0.80827522\n",
      "epoch: 13  batch: 62  loss: 0.26455936\n",
      "epoch: 13  batch: 63  loss: 0.39432323\n",
      "epoch: 13  batch: 64  loss: 0.23838435\n",
      "epoch: 13  batch: 65  loss: 0.05648015\n",
      "epoch: 13  batch: 66  loss: 0.09742936\n",
      "epoch: 13  batch: 67  loss: 0.24754247\n",
      "epoch: 13  batch: 68  loss: 0.28771776\n",
      "epoch: 14  batch: 1  loss: 0.34031674\n",
      "epoch: 14  batch: 2  loss: 0.17454161\n",
      "epoch: 14  batch: 3  loss: 0.12094153\n",
      "epoch: 14  batch: 4  loss: 0.11883569\n",
      "epoch: 14  batch: 5  loss: 0.36097708\n",
      "epoch: 14  batch: 6  loss: 0.18297461\n",
      "epoch: 14  batch: 7  loss: 0.38331047\n",
      "epoch: 14  batch: 8  loss: 0.13362870\n",
      "epoch: 14  batch: 9  loss: 0.21978603\n",
      "epoch: 14  batch: 10  loss: 0.20653597\n",
      "epoch: 14  batch: 11  loss: 0.21904799\n",
      "epoch: 14  batch: 12  loss: 0.25763854\n",
      "epoch: 14  batch: 13  loss: 0.61541325\n",
      "epoch: 14  batch: 14  loss: 0.32124627\n",
      "epoch: 14  batch: 15  loss: 0.20584674\n",
      "epoch: 14  batch: 16  loss: 0.37650740\n",
      "epoch: 14  batch: 17  loss: 0.55484813\n",
      "epoch: 14  batch: 18  loss: 0.21397159\n",
      "epoch: 14  batch: 19  loss: 0.27515846\n",
      "epoch: 14  batch: 20  loss: 0.34898537\n",
      "epoch: 14  batch: 21  loss: 0.38818568\n",
      "epoch: 14  batch: 22  loss: 0.10316447\n",
      "epoch: 14  batch: 23  loss: 0.10855725\n",
      "epoch: 14  batch: 24  loss: 0.06100259\n",
      "epoch: 14  batch: 25  loss: 0.08938535\n",
      "epoch: 14  batch: 26  loss: 0.30662185\n",
      "epoch: 14  batch: 27  loss: 0.61732084\n",
      "epoch: 14  batch: 28  loss: 0.27662525\n",
      "epoch: 14  batch: 29  loss: 0.21432696\n",
      "epoch: 14  batch: 30  loss: 0.11717733\n",
      "epoch: 14  batch: 31  loss: 0.06186829\n",
      "epoch: 14  batch: 32  loss: 0.17592674\n",
      "epoch: 14  batch: 33  loss: 0.36656284\n",
      "epoch: 14  batch: 34  loss: 0.13211796\n",
      "epoch: 14  batch: 35  loss: 0.25010207\n",
      "epoch: 14  batch: 36  loss: 0.07480236\n",
      "epoch: 14  batch: 37  loss: 0.04197823\n",
      "epoch: 14  batch: 38  loss: 0.06389533\n",
      "epoch: 14  batch: 39  loss: 0.29998586\n",
      "epoch: 14  batch: 40  loss: 0.08398660\n",
      "epoch: 14  batch: 41  loss: 0.35206738\n",
      "epoch: 14  batch: 42  loss: 0.27237517\n",
      "epoch: 14  batch: 43  loss: 0.32821259\n",
      "epoch: 14  batch: 44  loss: 0.36712310\n",
      "epoch: 14  batch: 45  loss: 0.24826339\n",
      "epoch: 14  batch: 46  loss: 0.20800668\n",
      "epoch: 14  batch: 47  loss: 0.29696161\n",
      "epoch: 14  batch: 48  loss: 0.21938445\n",
      "epoch: 14  batch: 49  loss: 0.17920206\n",
      "epoch: 14  batch: 50  loss: 0.30584812\n",
      "epoch: 14  batch: 51  loss: 0.27863759\n",
      "epoch: 14  batch: 52  loss: 0.13818783\n",
      "epoch: 14  batch: 53  loss: 0.28039798\n",
      "epoch: 14  batch: 54  loss: 0.36220416\n",
      "epoch: 14  batch: 55  loss: 0.24448194\n",
      "epoch: 14  batch: 56  loss: 0.09623640\n",
      "epoch: 14  batch: 57  loss: 0.12882209\n",
      "epoch: 14  batch: 58  loss: 0.12641187\n",
      "epoch: 14  batch: 59  loss: 0.12465687\n",
      "epoch: 14  batch: 60  loss: 0.46600005\n",
      "epoch: 14  batch: 61  loss: 0.98631495\n",
      "epoch: 14  batch: 62  loss: 0.22828072\n",
      "epoch: 14  batch: 63  loss: 0.45799395\n",
      "epoch: 14  batch: 64  loss: 0.14041328\n",
      "epoch: 14  batch: 65  loss: 0.05789018\n",
      "epoch: 14  batch: 66  loss: 0.07148374\n",
      "epoch: 14  batch: 67  loss: 0.17534496\n",
      "epoch: 14  batch: 68  loss: 0.33199278\n",
      "epoch: 15  batch: 1  loss: 0.29910541\n",
      "epoch: 15  batch: 2  loss: 0.11153092\n",
      "epoch: 15  batch: 3  loss: 0.10365769\n",
      "epoch: 15  batch: 4  loss: 0.15579580\n",
      "epoch: 15  batch: 5  loss: 0.18872672\n",
      "epoch: 15  batch: 6  loss: 0.12828122\n",
      "epoch: 15  batch: 7  loss: 0.31984594\n",
      "epoch: 15  batch: 8  loss: 0.06392523\n",
      "epoch: 15  batch: 9  loss: 0.18166128\n",
      "epoch: 15  batch: 10  loss: 0.18436556\n",
      "epoch: 15  batch: 11  loss: 0.16965193\n",
      "epoch: 15  batch: 12  loss: 0.26921439\n",
      "epoch: 15  batch: 13  loss: 0.91031820\n",
      "epoch: 15  batch: 14  loss: 0.25738159\n",
      "epoch: 15  batch: 15  loss: 0.18521143\n",
      "epoch: 15  batch: 16  loss: 0.25519359\n",
      "epoch: 15  batch: 17  loss: 0.53795016\n",
      "epoch: 15  batch: 18  loss: 0.13689645\n",
      "epoch: 15  batch: 19  loss: 0.13317738\n",
      "epoch: 15  batch: 20  loss: 0.30927673\n",
      "epoch: 15  batch: 21  loss: 0.38399145\n",
      "epoch: 15  batch: 22  loss: 0.08445391\n",
      "epoch: 15  batch: 23  loss: 0.06128719\n",
      "epoch: 15  batch: 24  loss: 0.05981738\n",
      "epoch: 15  batch: 25  loss: 0.14613268\n",
      "epoch: 15  batch: 26  loss: 0.22610196\n",
      "epoch: 15  batch: 27  loss: 0.62193352\n",
      "epoch: 15  batch: 28  loss: 0.26282743\n",
      "epoch: 15  batch: 29  loss: 0.16944312\n",
      "epoch: 15  batch: 30  loss: 0.10780145\n",
      "epoch: 15  batch: 31  loss: 0.05736722\n",
      "epoch: 15  batch: 32  loss: 0.16111408\n",
      "epoch: 15  batch: 33  loss: 0.18791917\n",
      "epoch: 15  batch: 34  loss: 0.28842360\n",
      "epoch: 15  batch: 35  loss: 0.38744509\n",
      "epoch: 15  batch: 36  loss: 0.11802083\n",
      "epoch: 15  batch: 37  loss: 0.11916491\n",
      "epoch: 15  batch: 38  loss: 0.06460070\n",
      "epoch: 15  batch: 39  loss: 0.34238902\n",
      "epoch: 15  batch: 40  loss: 0.10881549\n",
      "epoch: 15  batch: 41  loss: 0.27212521\n",
      "epoch: 15  batch: 42  loss: 0.17918676\n",
      "epoch: 15  batch: 43  loss: 0.21194747\n",
      "epoch: 15  batch: 44  loss: 0.28299612\n",
      "epoch: 15  batch: 45  loss: 0.23850504\n",
      "epoch: 15  batch: 46  loss: 0.26906151\n",
      "epoch: 15  batch: 47  loss: 0.41678375\n",
      "epoch: 15  batch: 48  loss: 0.30481014\n",
      "epoch: 15  batch: 49  loss: 0.25715366\n",
      "epoch: 15  batch: 50  loss: 0.44029644\n",
      "epoch: 15  batch: 51  loss: 0.40283620\n",
      "epoch: 15  batch: 52  loss: 0.17851779\n",
      "epoch: 15  batch: 53  loss: 0.24602136\n",
      "epoch: 15  batch: 54  loss: 0.39621785\n",
      "epoch: 15  batch: 55  loss: 0.25852650\n",
      "epoch: 15  batch: 56  loss: 0.12763536\n",
      "epoch: 15  batch: 57  loss: 0.09897082\n",
      "epoch: 15  batch: 58  loss: 0.08992574\n",
      "epoch: 15  batch: 59  loss: 0.11664303\n",
      "epoch: 15  batch: 60  loss: 0.42768836\n",
      "epoch: 15  batch: 61  loss: 0.86619437\n",
      "epoch: 15  batch: 62  loss: 0.19458899\n",
      "epoch: 15  batch: 63  loss: 0.31515598\n",
      "epoch: 15  batch: 64  loss: 0.20400207\n",
      "epoch: 15  batch: 65  loss: 0.07226536\n",
      "epoch: 15  batch: 66  loss: 0.10197345\n",
      "epoch: 15  batch: 67  loss: 0.16745016\n",
      "epoch: 15  batch: 68  loss: 0.19937693\n",
      "epoch: 16  batch: 1  loss: 0.27136689\n",
      "epoch: 16  batch: 2  loss: 0.13526401\n",
      "epoch: 16  batch: 3  loss: 0.12723136\n",
      "epoch: 16  batch: 4  loss: 0.09190638\n",
      "epoch: 16  batch: 5  loss: 0.21809585\n",
      "epoch: 16  batch: 6  loss: 0.21077091\n",
      "epoch: 16  batch: 7  loss: 0.42664006\n",
      "epoch: 16  batch: 8  loss: 0.18119478\n",
      "epoch: 16  batch: 9  loss: 0.29535601\n",
      "epoch: 16  batch: 10  loss: 0.20920567\n",
      "epoch: 16  batch: 11  loss: 0.33715269\n",
      "epoch: 16  batch: 12  loss: 0.20627865\n",
      "epoch: 16  batch: 13  loss: 0.32413426\n",
      "epoch: 16  batch: 14  loss: 0.22871347\n",
      "epoch: 16  batch: 15  loss: 0.18081382\n",
      "epoch: 16  batch: 16  loss: 0.23832695\n",
      "epoch: 16  batch: 17  loss: 0.44594452\n",
      "epoch: 16  batch: 18  loss: 0.23809205\n",
      "epoch: 16  batch: 19  loss: 0.21172567\n",
      "epoch: 16  batch: 20  loss: 0.33636519\n",
      "epoch: 16  batch: 21  loss: 0.42445198\n",
      "epoch: 16  batch: 22  loss: 0.08973726\n",
      "epoch: 16  batch: 23  loss: 0.10152264\n",
      "epoch: 16  batch: 24  loss: 0.08018734\n",
      "epoch: 16  batch: 25  loss: 0.05969323\n",
      "epoch: 16  batch: 26  loss: 0.37724024\n",
      "epoch: 16  batch: 27  loss: 0.84513575\n",
      "epoch: 16  batch: 28  loss: 0.38406307\n",
      "epoch: 16  batch: 29  loss: 0.30284730\n",
      "epoch: 16  batch: 30  loss: 0.18259297\n",
      "epoch: 16  batch: 31  loss: 0.06899438\n",
      "epoch: 16  batch: 32  loss: 0.06331297\n",
      "epoch: 16  batch: 33  loss: 0.11079411\n",
      "epoch: 16  batch: 34  loss: 0.12457789\n",
      "epoch: 16  batch: 35  loss: 0.26983351\n",
      "epoch: 16  batch: 36  loss: 0.09233189\n",
      "epoch: 16  batch: 37  loss: 0.06508400\n",
      "epoch: 16  batch: 38  loss: 0.07076669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16  batch: 39  loss: 0.30427712\n",
      "epoch: 16  batch: 40  loss: 0.11738151\n",
      "epoch: 16  batch: 41  loss: 0.34234557\n",
      "epoch: 16  batch: 42  loss: 0.50379634\n",
      "epoch: 16  batch: 43  loss: 0.25734320\n",
      "epoch: 16  batch: 44  loss: 0.44342738\n",
      "epoch: 16  batch: 45  loss: 0.50308722\n",
      "epoch: 16  batch: 46  loss: 0.20521440\n",
      "epoch: 16  batch: 47  loss: 0.22384559\n",
      "epoch: 16  batch: 48  loss: 0.21525659\n",
      "epoch: 16  batch: 49  loss: 0.15863903\n",
      "epoch: 16  batch: 50  loss: 0.27364841\n",
      "epoch: 16  batch: 51  loss: 0.33623403\n",
      "epoch: 16  batch: 52  loss: 0.15560102\n",
      "epoch: 16  batch: 53  loss: 0.21549967\n",
      "epoch: 16  batch: 54  loss: 0.40870643\n",
      "epoch: 16  batch: 55  loss: 0.33366311\n",
      "epoch: 16  batch: 56  loss: 0.11634155\n",
      "epoch: 16  batch: 57  loss: 0.11965173\n",
      "epoch: 16  batch: 58  loss: 0.06370918\n",
      "epoch: 16  batch: 59  loss: 0.12708396\n",
      "epoch: 16  batch: 60  loss: 0.37290931\n",
      "epoch: 16  batch: 61  loss: 1.44356179\n",
      "epoch: 16  batch: 62  loss: 0.22252053\n",
      "epoch: 16  batch: 63  loss: 0.30967551\n",
      "epoch: 16  batch: 64  loss: 0.20687766\n",
      "epoch: 16  batch: 65  loss: 0.06370218\n",
      "epoch: 16  batch: 66  loss: 0.13549012\n",
      "epoch: 16  batch: 67  loss: 0.21781890\n",
      "epoch: 16  batch: 68  loss: 0.31534576\n",
      "epoch: 17  batch: 1  loss: 0.34325561\n",
      "epoch: 17  batch: 2  loss: 0.42115945\n",
      "epoch: 17  batch: 3  loss: 0.24086656\n",
      "epoch: 17  batch: 4  loss: 0.25970832\n",
      "epoch: 17  batch: 5  loss: 0.47876659\n",
      "epoch: 17  batch: 6  loss: 0.79818946\n",
      "epoch: 17  batch: 7  loss: 0.50667518\n",
      "epoch: 17  batch: 8  loss: 0.27802473\n",
      "epoch: 17  batch: 9  loss: 0.45177680\n",
      "epoch: 17  batch: 10  loss: 0.16599348\n",
      "epoch: 17  batch: 11  loss: 0.35505140\n",
      "epoch: 17  batch: 12  loss: 0.24288845\n",
      "epoch: 17  batch: 13  loss: 0.43622062\n",
      "epoch: 17  batch: 14  loss: 0.25409365\n",
      "epoch: 17  batch: 15  loss: 0.24519074\n",
      "epoch: 17  batch: 16  loss: 0.34003574\n",
      "epoch: 17  batch: 17  loss: 0.65679663\n",
      "epoch: 17  batch: 18  loss: 0.26696455\n",
      "epoch: 17  batch: 19  loss: 0.29059526\n",
      "epoch: 17  batch: 20  loss: 0.33608013\n",
      "epoch: 17  batch: 21  loss: 0.42247298\n",
      "epoch: 17  batch: 22  loss: 0.14805754\n",
      "epoch: 17  batch: 23  loss: 0.16033711\n",
      "epoch: 17  batch: 24  loss: 0.12354902\n",
      "epoch: 17  batch: 25  loss: 0.11974759\n",
      "epoch: 17  batch: 26  loss: 0.51043177\n",
      "epoch: 17  batch: 27  loss: 0.98248005\n",
      "epoch: 17  batch: 28  loss: 0.47054750\n",
      "epoch: 17  batch: 29  loss: 0.34984592\n",
      "epoch: 17  batch: 30  loss: 0.22535229\n",
      "epoch: 17  batch: 31  loss: 0.07672407\n",
      "epoch: 17  batch: 32  loss: 0.08341616\n",
      "epoch: 17  batch: 33  loss: 0.12539297\n",
      "epoch: 17  batch: 34  loss: 0.14993113\n",
      "epoch: 17  batch: 35  loss: 0.30819660\n",
      "epoch: 17  batch: 36  loss: 0.14118415\n",
      "epoch: 17  batch: 37  loss: 0.10995045\n",
      "epoch: 17  batch: 38  loss: 0.16988499\n",
      "epoch: 17  batch: 39  loss: 0.39407849\n",
      "epoch: 17  batch: 40  loss: 0.12334173\n",
      "epoch: 17  batch: 41  loss: 0.46776074\n",
      "epoch: 17  batch: 42  loss: 0.30535737\n",
      "epoch: 17  batch: 43  loss: 0.33736968\n",
      "epoch: 17  batch: 44  loss: 0.29019371\n",
      "epoch: 17  batch: 45  loss: 0.25447023\n",
      "epoch: 17  batch: 46  loss: 0.23639764\n",
      "epoch: 17  batch: 47  loss: 0.35319772\n",
      "epoch: 17  batch: 48  loss: 0.21228494\n",
      "epoch: 17  batch: 49  loss: 0.18245380\n",
      "epoch: 17  batch: 50  loss: 0.28613511\n",
      "epoch: 17  batch: 51  loss: 0.29893038\n",
      "epoch: 17  batch: 52  loss: 0.13375135\n",
      "epoch: 17  batch: 53  loss: 0.26610863\n",
      "epoch: 17  batch: 54  loss: 0.45717344\n",
      "epoch: 17  batch: 55  loss: 0.30426502\n",
      "epoch: 17  batch: 56  loss: 0.12145910\n",
      "epoch: 17  batch: 57  loss: 0.15461835\n",
      "epoch: 17  batch: 58  loss: 0.07209007\n",
      "epoch: 17  batch: 59  loss: 0.12873207\n",
      "epoch: 17  batch: 60  loss: 0.45973486\n",
      "epoch: 17  batch: 61  loss: 0.93172175\n",
      "epoch: 17  batch: 62  loss: 0.24206331\n",
      "epoch: 17  batch: 63  loss: 0.46472105\n",
      "epoch: 17  batch: 64  loss: 0.16902086\n",
      "epoch: 17  batch: 65  loss: 0.05319115\n",
      "epoch: 17  batch: 66  loss: 0.06077569\n",
      "epoch: 17  batch: 67  loss: 0.11264636\n",
      "epoch: 17  batch: 68  loss: 0.23520684\n",
      "epoch: 18  batch: 1  loss: 0.36219212\n",
      "epoch: 18  batch: 2  loss: 0.07902075\n",
      "epoch: 18  batch: 3  loss: 0.12747663\n",
      "epoch: 18  batch: 4  loss: 0.14299227\n",
      "epoch: 18  batch: 5  loss: 0.30301559\n",
      "epoch: 18  batch: 6  loss: 0.20545860\n",
      "epoch: 18  batch: 7  loss: 0.36175254\n",
      "epoch: 18  batch: 8  loss: 0.16139948\n",
      "epoch: 18  batch: 9  loss: 0.26693365\n",
      "epoch: 18  batch: 10  loss: 0.26006830\n",
      "epoch: 18  batch: 11  loss: 0.25177363\n",
      "epoch: 18  batch: 12  loss: 0.17855325\n",
      "epoch: 18  batch: 13  loss: 0.65612298\n",
      "epoch: 18  batch: 14  loss: 0.34807366\n",
      "epoch: 18  batch: 15  loss: 0.15936589\n",
      "epoch: 18  batch: 16  loss: 0.33701304\n",
      "epoch: 18  batch: 17  loss: 0.60831374\n",
      "epoch: 18  batch: 18  loss: 0.23577848\n",
      "epoch: 18  batch: 19  loss: 0.25368381\n",
      "epoch: 18  batch: 20  loss: 0.33988678\n",
      "epoch: 18  batch: 21  loss: 0.40202734\n",
      "epoch: 18  batch: 22  loss: 0.08657404\n",
      "epoch: 18  batch: 23  loss: 0.08471134\n",
      "epoch: 18  batch: 24  loss: 0.05712259\n",
      "epoch: 18  batch: 25  loss: 0.10611098\n",
      "epoch: 18  batch: 26  loss: 0.26612639\n",
      "epoch: 18  batch: 27  loss: 0.58063620\n",
      "epoch: 18  batch: 28  loss: 0.26733026\n",
      "epoch: 18  batch: 29  loss: 0.19635673\n",
      "epoch: 18  batch: 30  loss: 0.12432790\n",
      "epoch: 18  batch: 31  loss: 0.07509380\n",
      "epoch: 18  batch: 32  loss: 0.10234119\n",
      "epoch: 18  batch: 33  loss: 0.17613910\n",
      "epoch: 18  batch: 34  loss: 0.17783241\n",
      "epoch: 18  batch: 35  loss: 0.29951423\n",
      "epoch: 18  batch: 36  loss: 0.08115222\n",
      "epoch: 18  batch: 37  loss: 0.10999612\n",
      "epoch: 18  batch: 38  loss: 0.06704963\n",
      "epoch: 18  batch: 39  loss: 0.28069341\n",
      "epoch: 18  batch: 40  loss: 0.15593946\n",
      "epoch: 18  batch: 41  loss: 0.32631314\n",
      "epoch: 18  batch: 42  loss: 0.29717872\n",
      "epoch: 18  batch: 43  loss: 0.31356418\n",
      "epoch: 18  batch: 44  loss: 0.33095339\n",
      "epoch: 18  batch: 45  loss: 0.32582039\n",
      "epoch: 18  batch: 46  loss: 0.20997472\n",
      "epoch: 18  batch: 47  loss: 0.25173756\n",
      "epoch: 18  batch: 48  loss: 0.17624131\n",
      "epoch: 18  batch: 49  loss: 0.15235418\n",
      "epoch: 18  batch: 50  loss: 0.26696828\n",
      "epoch: 18  batch: 51  loss: 0.18983629\n",
      "epoch: 18  batch: 52  loss: 0.11843643\n",
      "epoch: 18  batch: 53  loss: 0.21708918\n",
      "epoch: 18  batch: 54  loss: 0.38681099\n",
      "epoch: 18  batch: 55  loss: 0.28371176\n",
      "epoch: 18  batch: 56  loss: 0.10035800\n",
      "epoch: 18  batch: 57  loss: 0.08668558\n",
      "epoch: 18  batch: 58  loss: 0.07588872\n",
      "epoch: 18  batch: 59  loss: 0.12942199\n",
      "epoch: 18  batch: 60  loss: 0.36888340\n",
      "epoch: 18  batch: 61  loss: 0.64299756\n",
      "epoch: 18  batch: 62  loss: 0.28261924\n",
      "epoch: 18  batch: 63  loss: 0.38491425\n",
      "epoch: 18  batch: 64  loss: 0.08488882\n",
      "epoch: 18  batch: 65  loss: 0.04989460\n",
      "epoch: 18  batch: 66  loss: 0.09578627\n",
      "epoch: 18  batch: 67  loss: 0.21826702\n",
      "epoch: 18  batch: 68  loss: 0.27446705\n",
      "epoch: 19  batch: 1  loss: 0.41052693\n",
      "epoch: 19  batch: 2  loss: 0.06252931\n",
      "epoch: 19  batch: 3  loss: 0.18215761\n",
      "epoch: 19  batch: 4  loss: 0.10664999\n",
      "epoch: 19  batch: 5  loss: 0.19028641\n",
      "epoch: 19  batch: 6  loss: 0.24163485\n",
      "epoch: 19  batch: 7  loss: 0.36856166\n",
      "epoch: 19  batch: 8  loss: 0.14978945\n",
      "epoch: 19  batch: 9  loss: 0.27842343\n",
      "epoch: 19  batch: 10  loss: 0.24211481\n",
      "epoch: 19  batch: 11  loss: 0.25066388\n",
      "epoch: 19  batch: 12  loss: 0.25199485\n",
      "epoch: 19  batch: 13  loss: 0.45155555\n",
      "epoch: 19  batch: 14  loss: 0.27557138\n",
      "epoch: 19  batch: 15  loss: 0.19034515\n",
      "epoch: 19  batch: 16  loss: 0.30541474\n",
      "epoch: 19  batch: 17  loss: 0.50459003\n",
      "epoch: 19  batch: 18  loss: 0.20720677\n",
      "epoch: 19  batch: 19  loss: 0.24287169\n",
      "epoch: 19  batch: 20  loss: 0.39453143\n",
      "epoch: 19  batch: 21  loss: 0.42250136\n",
      "epoch: 19  batch: 22  loss: 0.10397968\n",
      "epoch: 19  batch: 23  loss: 0.10433269\n",
      "epoch: 19  batch: 24  loss: 0.06233984\n",
      "epoch: 19  batch: 25  loss: 0.06688219\n",
      "epoch: 19  batch: 26  loss: 0.48345575\n",
      "epoch: 19  batch: 27  loss: 0.83646053\n",
      "epoch: 19  batch: 28  loss: 0.44050255\n",
      "epoch: 19  batch: 29  loss: 0.26490107\n",
      "epoch: 19  batch: 30  loss: 0.18767570\n",
      "epoch: 19  batch: 31  loss: 0.08375499\n",
      "epoch: 19  batch: 32  loss: 0.08463819\n",
      "epoch: 19  batch: 33  loss: 0.12242354\n",
      "epoch: 19  batch: 34  loss: 0.11356732\n",
      "epoch: 19  batch: 35  loss: 0.19125400\n",
      "epoch: 19  batch: 36  loss: 0.13869981\n",
      "epoch: 19  batch: 37  loss: 0.10933848\n",
      "epoch: 19  batch: 38  loss: 0.08639685\n",
      "epoch: 19  batch: 39  loss: 0.21059360\n",
      "epoch: 19  batch: 40  loss: 0.11726092\n",
      "epoch: 19  batch: 41  loss: 0.33573541\n",
      "epoch: 19  batch: 42  loss: 0.16366650\n",
      "epoch: 19  batch: 43  loss: 0.35817167\n",
      "epoch: 19  batch: 44  loss: 0.27336350\n",
      "epoch: 19  batch: 45  loss: 0.43937680\n",
      "epoch: 19  batch: 46  loss: 0.25124982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19  batch: 47  loss: 0.30624399\n",
      "epoch: 19  batch: 48  loss: 0.17975052\n",
      "epoch: 19  batch: 49  loss: 0.16520770\n",
      "epoch: 19  batch: 50  loss: 0.31230173\n",
      "epoch: 19  batch: 51  loss: 0.31416726\n",
      "epoch: 19  batch: 52  loss: 0.12005120\n",
      "epoch: 19  batch: 53  loss: 0.19971313\n",
      "epoch: 19  batch: 54  loss: 0.39936668\n",
      "epoch: 19  batch: 55  loss: 0.25926062\n",
      "epoch: 19  batch: 56  loss: 0.10433189\n",
      "epoch: 19  batch: 57  loss: 0.07646573\n",
      "epoch: 19  batch: 58  loss: 0.08471859\n",
      "epoch: 19  batch: 59  loss: 0.13124053\n",
      "epoch: 19  batch: 60  loss: 0.37339276\n",
      "epoch: 19  batch: 61  loss: 0.78800899\n",
      "epoch: 19  batch: 62  loss: 0.23985767\n",
      "epoch: 19  batch: 63  loss: 0.29969686\n",
      "epoch: 19  batch: 64  loss: 0.10079484\n",
      "epoch: 19  batch: 65  loss: 0.07988234\n",
      "epoch: 19  batch: 66  loss: 0.06536432\n",
      "epoch: 19  batch: 67  loss: 0.08260339\n",
      "epoch: 19  batch: 68  loss: 0.22953652\n",
      "epoch: 20  batch: 1  loss: 0.30259666\n",
      "epoch: 20  batch: 2  loss: 0.15617813\n",
      "epoch: 20  batch: 3  loss: 0.12481334\n",
      "epoch: 20  batch: 4  loss: 0.10448059\n",
      "epoch: 20  batch: 5  loss: 0.28106144\n",
      "epoch: 20  batch: 6  loss: 0.17010652\n",
      "epoch: 20  batch: 7  loss: 0.30732557\n",
      "epoch: 20  batch: 8  loss: 0.14756005\n",
      "epoch: 20  batch: 9  loss: 0.30541232\n",
      "epoch: 20  batch: 10  loss: 0.27277675\n",
      "epoch: 20  batch: 11  loss: 0.33494613\n",
      "epoch: 20  batch: 12  loss: 0.20489733\n",
      "epoch: 20  batch: 13  loss: 0.36802351\n",
      "epoch: 20  batch: 14  loss: 0.23798761\n",
      "epoch: 20  batch: 15  loss: 0.18080501\n",
      "epoch: 20  batch: 16  loss: 0.23098192\n",
      "epoch: 20  batch: 17  loss: 0.57070452\n",
      "epoch: 20  batch: 18  loss: 0.23535882\n",
      "epoch: 20  batch: 19  loss: 0.16909045\n",
      "epoch: 20  batch: 20  loss: 0.34830174\n",
      "epoch: 20  batch: 21  loss: 0.41279909\n",
      "epoch: 20  batch: 22  loss: 0.08382866\n",
      "epoch: 20  batch: 23  loss: 0.08169776\n",
      "epoch: 20  batch: 24  loss: 0.05534194\n",
      "epoch: 20  batch: 25  loss: 0.04365871\n",
      "epoch: 20  batch: 26  loss: 0.43576890\n",
      "epoch: 20  batch: 27  loss: 0.70319307\n",
      "epoch: 20  batch: 28  loss: 0.25734487\n",
      "epoch: 20  batch: 29  loss: 0.22362617\n",
      "epoch: 20  batch: 30  loss: 0.15337430\n",
      "epoch: 20  batch: 31  loss: 0.07263105\n",
      "epoch: 20  batch: 32  loss: 0.06707138\n",
      "epoch: 20  batch: 33  loss: 0.18229976\n",
      "epoch: 20  batch: 34  loss: 0.12500973\n",
      "epoch: 20  batch: 35  loss: 0.25805292\n",
      "epoch: 20  batch: 36  loss: 0.18756121\n",
      "epoch: 20  batch: 37  loss: 0.10311337\n",
      "epoch: 20  batch: 38  loss: 0.16577916\n",
      "epoch: 20  batch: 39  loss: 0.28698063\n",
      "epoch: 20  batch: 40  loss: 0.09186962\n",
      "epoch: 20  batch: 41  loss: 0.34907117\n",
      "epoch: 20  batch: 42  loss: 0.22297958\n",
      "epoch: 20  batch: 43  loss: 0.26582116\n",
      "epoch: 20  batch: 44  loss: 0.37588918\n",
      "epoch: 20  batch: 45  loss: 0.25452647\n",
      "epoch: 20  batch: 46  loss: 0.22027969\n",
      "epoch: 20  batch: 47  loss: 0.23247698\n",
      "epoch: 20  batch: 48  loss: 0.19272190\n",
      "epoch: 20  batch: 49  loss: 0.17424850\n",
      "epoch: 20  batch: 50  loss: 0.30345622\n",
      "epoch: 20  batch: 51  loss: 0.39740881\n",
      "epoch: 20  batch: 52  loss: 0.13205168\n",
      "epoch: 20  batch: 53  loss: 0.15718573\n",
      "epoch: 20  batch: 54  loss: 0.42463881\n",
      "epoch: 20  batch: 55  loss: 0.23101260\n",
      "epoch: 20  batch: 56  loss: 0.08727819\n",
      "epoch: 20  batch: 57  loss: 0.06301406\n",
      "epoch: 20  batch: 58  loss: 0.11056627\n",
      "epoch: 20  batch: 59  loss: 0.13123864\n",
      "epoch: 20  batch: 60  loss: 0.34197152\n",
      "epoch: 20  batch: 61  loss: 0.76582760\n",
      "epoch: 20  batch: 62  loss: 0.17583688\n",
      "epoch: 20  batch: 63  loss: 0.26062480\n",
      "epoch: 20  batch: 64  loss: 0.10071488\n",
      "epoch: 20  batch: 65  loss: 0.05130984\n",
      "epoch: 20  batch: 66  loss: 0.10022703\n",
      "epoch: 20  batch: 67  loss: 0.17084470\n",
      "epoch: 20  batch: 68  loss: 0.26541537\n",
      "epoch: 21  batch: 1  loss: 0.33273616\n",
      "epoch: 21  batch: 2  loss: 0.16150284\n",
      "epoch: 21  batch: 3  loss: 0.11776948\n",
      "epoch: 21  batch: 4  loss: 0.07314257\n",
      "epoch: 21  batch: 5  loss: 0.21889590\n",
      "epoch: 21  batch: 6  loss: 0.16472456\n",
      "epoch: 21  batch: 7  loss: 0.35119936\n",
      "epoch: 21  batch: 8  loss: 0.14971338\n",
      "epoch: 21  batch: 9  loss: 0.27863523\n",
      "epoch: 21  batch: 10  loss: 0.28705415\n",
      "epoch: 21  batch: 11  loss: 0.23817660\n",
      "epoch: 21  batch: 12  loss: 0.17577489\n",
      "epoch: 21  batch: 13  loss: 0.39369941\n",
      "epoch: 21  batch: 14  loss: 0.40478042\n",
      "epoch: 21  batch: 15  loss: 0.19968735\n",
      "epoch: 21  batch: 16  loss: 0.34570578\n",
      "epoch: 21  batch: 17  loss: 0.52106613\n",
      "epoch: 21  batch: 18  loss: 0.19333537\n",
      "epoch: 21  batch: 19  loss: 0.24112244\n",
      "epoch: 21  batch: 20  loss: 0.36725727\n",
      "epoch: 21  batch: 21  loss: 0.41431031\n",
      "epoch: 21  batch: 22  loss: 0.09660672\n",
      "epoch: 21  batch: 23  loss: 0.10024512\n",
      "epoch: 21  batch: 24  loss: 0.06360684\n",
      "epoch: 21  batch: 25  loss: 0.06946431\n",
      "epoch: 21  batch: 26  loss: 0.38026801\n",
      "epoch: 21  batch: 27  loss: 0.75865698\n",
      "epoch: 21  batch: 28  loss: 0.33652997\n",
      "epoch: 21  batch: 29  loss: 0.29763660\n",
      "epoch: 21  batch: 30  loss: 0.17137054\n",
      "epoch: 21  batch: 31  loss: 0.06087110\n",
      "epoch: 21  batch: 32  loss: 0.06409181\n",
      "epoch: 21  batch: 33  loss: 0.12659431\n",
      "epoch: 21  batch: 34  loss: 0.17103451\n",
      "epoch: 21  batch: 35  loss: 0.28060326\n",
      "epoch: 21  batch: 36  loss: 0.09465887\n",
      "epoch: 21  batch: 37  loss: 0.14705229\n",
      "epoch: 21  batch: 38  loss: 0.17021574\n",
      "epoch: 21  batch: 39  loss: 0.34190086\n",
      "epoch: 21  batch: 40  loss: 0.17523310\n",
      "epoch: 21  batch: 41  loss: 0.26221734\n",
      "epoch: 21  batch: 42  loss: 0.26908037\n",
      "epoch: 21  batch: 43  loss: 0.20080481\n",
      "epoch: 21  batch: 44  loss: 0.31510222\n",
      "epoch: 21  batch: 45  loss: 0.23587470\n",
      "epoch: 21  batch: 46  loss: 0.25128663\n",
      "epoch: 21  batch: 47  loss: 0.28798935\n",
      "epoch: 21  batch: 48  loss: 0.20803778\n",
      "epoch: 21  batch: 49  loss: 0.15926233\n",
      "epoch: 21  batch: 50  loss: 0.28750199\n",
      "epoch: 21  batch: 51  loss: 0.26870558\n",
      "epoch: 21  batch: 52  loss: 0.14390768\n",
      "epoch: 21  batch: 53  loss: 0.16245051\n",
      "epoch: 21  batch: 54  loss: 0.36894736\n",
      "epoch: 21  batch: 55  loss: 0.22788459\n",
      "epoch: 21  batch: 56  loss: 0.09722445\n",
      "epoch: 21  batch: 57  loss: 0.09341940\n",
      "epoch: 21  batch: 58  loss: 0.08688129\n",
      "epoch: 21  batch: 59  loss: 0.14360659\n",
      "epoch: 21  batch: 60  loss: 0.45735428\n",
      "epoch: 21  batch: 61  loss: 0.92612666\n",
      "epoch: 21  batch: 62  loss: 0.20885326\n",
      "epoch: 21  batch: 63  loss: 0.38003340\n",
      "epoch: 21  batch: 64  loss: 0.18484123\n",
      "epoch: 21  batch: 65  loss: 0.04814579\n",
      "epoch: 21  batch: 66  loss: 0.06671898\n",
      "epoch: 21  batch: 67  loss: 0.08434382\n",
      "epoch: 21  batch: 68  loss: 0.20975655\n",
      "epoch: 22  batch: 1  loss: 0.29087168\n",
      "epoch: 22  batch: 2  loss: 0.06166691\n",
      "epoch: 22  batch: 3  loss: 0.10405865\n",
      "epoch: 22  batch: 4  loss: 0.09105591\n",
      "epoch: 22  batch: 5  loss: 0.15536700\n",
      "epoch: 22  batch: 6  loss: 0.09221563\n",
      "epoch: 22  batch: 7  loss: 0.28526178\n",
      "epoch: 22  batch: 8  loss: 0.05488423\n",
      "epoch: 22  batch: 9  loss: 0.04279799\n",
      "epoch: 22  batch: 10  loss: 0.04260811\n",
      "epoch: 22  batch: 11  loss: 0.00866628\n",
      "epoch: 22  batch: 12  loss: 0.69952881\n",
      "epoch: 22  batch: 13  loss: 1.10062885\n",
      "epoch: 22  batch: 14  loss: 0.25647053\n",
      "epoch: 22  batch: 15  loss: 0.23581383\n",
      "epoch: 22  batch: 16  loss: 0.09442434\n",
      "epoch: 22  batch: 17  loss: 0.16033480\n",
      "epoch: 22  batch: 18  loss: 0.28622565\n",
      "epoch: 22  batch: 19  loss: 0.20155740\n",
      "epoch: 22  batch: 20  loss: 1.00525808\n",
      "epoch: 22  batch: 21  loss: 0.80162221\n",
      "epoch: 22  batch: 22  loss: 0.34290403\n",
      "epoch: 22  batch: 23  loss: 0.11088982\n",
      "epoch: 22  batch: 24  loss: 0.15260519\n",
      "epoch: 22  batch: 25  loss: 0.17679973\n",
      "epoch: 22  batch: 26  loss: 0.28625193\n",
      "epoch: 22  batch: 27  loss: 0.61273611\n",
      "epoch: 22  batch: 28  loss: 0.33540294\n",
      "epoch: 22  batch: 29  loss: 0.30949974\n",
      "epoch: 22  batch: 30  loss: 0.20032120\n",
      "epoch: 22  batch: 31  loss: 0.09316591\n",
      "epoch: 22  batch: 32  loss: 0.05485765\n",
      "epoch: 22  batch: 33  loss: 0.09840149\n",
      "epoch: 22  batch: 34  loss: 0.09396715\n",
      "epoch: 22  batch: 35  loss: 0.16844183\n",
      "epoch: 22  batch: 36  loss: 0.07559248\n",
      "epoch: 22  batch: 37  loss: 0.06928836\n",
      "epoch: 22  batch: 38  loss: 0.04902776\n",
      "epoch: 22  batch: 39  loss: 0.19857487\n",
      "epoch: 22  batch: 40  loss: 0.09109093\n",
      "epoch: 22  batch: 41  loss: 0.20938270\n",
      "epoch: 22  batch: 42  loss: 0.14871766\n",
      "epoch: 22  batch: 43  loss: 0.20214261\n",
      "epoch: 22  batch: 44  loss: 0.22019938\n",
      "epoch: 22  batch: 45  loss: 0.27394482\n",
      "epoch: 22  batch: 46  loss: 0.26325974\n",
      "epoch: 22  batch: 47  loss: 0.31952453\n",
      "epoch: 22  batch: 48  loss: 0.20656158\n",
      "epoch: 22  batch: 49  loss: 0.16569583\n",
      "epoch: 22  batch: 50  loss: 0.33746564\n",
      "epoch: 22  batch: 51  loss: 0.29463005\n",
      "epoch: 22  batch: 52  loss: 0.13479723\n",
      "epoch: 22  batch: 53  loss: 0.17573985\n",
      "epoch: 22  batch: 54  loss: 0.43031627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22  batch: 55  loss: 0.26029351\n",
      "epoch: 22  batch: 56  loss: 0.10048678\n",
      "epoch: 22  batch: 57  loss: 0.14949799\n",
      "epoch: 22  batch: 58  loss: 0.07584812\n",
      "epoch: 22  batch: 59  loss: 0.10866776\n",
      "epoch: 22  batch: 60  loss: 0.37229955\n",
      "epoch: 22  batch: 61  loss: 0.93916529\n",
      "epoch: 22  batch: 62  loss: 0.20875703\n",
      "epoch: 22  batch: 63  loss: 0.39839962\n",
      "epoch: 22  batch: 64  loss: 0.14506966\n",
      "epoch: 22  batch: 65  loss: 0.06056049\n",
      "epoch: 22  batch: 66  loss: 0.06889306\n",
      "epoch: 22  batch: 67  loss: 0.07925083\n",
      "epoch: 22  batch: 68  loss: 0.21727757\n",
      "epoch: 23  batch: 1  loss: 0.27013126\n",
      "epoch: 23  batch: 2  loss: 0.13110144\n",
      "epoch: 23  batch: 3  loss: 0.09926037\n",
      "epoch: 23  batch: 4  loss: 0.10346186\n",
      "epoch: 23  batch: 5  loss: 0.22669157\n",
      "epoch: 23  batch: 6  loss: 0.15462619\n",
      "epoch: 23  batch: 7  loss: 0.30102977\n",
      "epoch: 23  batch: 8  loss: 0.13267314\n",
      "epoch: 23  batch: 9  loss: 0.26597854\n",
      "epoch: 23  batch: 10  loss: 0.28299782\n",
      "epoch: 23  batch: 11  loss: 0.30768457\n",
      "epoch: 23  batch: 12  loss: 0.22169887\n",
      "epoch: 23  batch: 13  loss: 0.35997111\n",
      "epoch: 23  batch: 14  loss: 0.23862481\n",
      "epoch: 23  batch: 15  loss: 0.20759150\n",
      "epoch: 23  batch: 16  loss: 0.21809626\n",
      "epoch: 23  batch: 17  loss: 0.44064608\n",
      "epoch: 23  batch: 18  loss: 0.17196666\n",
      "epoch: 23  batch: 19  loss: 0.18313898\n",
      "epoch: 23  batch: 20  loss: 0.35306790\n",
      "epoch: 23  batch: 21  loss: 0.41821662\n",
      "epoch: 23  batch: 22  loss: 0.08077469\n",
      "epoch: 23  batch: 23  loss: 0.08408774\n",
      "epoch: 23  batch: 24  loss: 0.06118528\n",
      "epoch: 23  batch: 25  loss: 0.07210168\n",
      "epoch: 23  batch: 26  loss: 0.40030348\n",
      "epoch: 23  batch: 27  loss: 0.74484652\n",
      "epoch: 23  batch: 28  loss: 0.34841251\n",
      "epoch: 23  batch: 29  loss: 0.26998761\n",
      "epoch: 23  batch: 30  loss: 0.18277414\n",
      "epoch: 23  batch: 31  loss: 0.10317322\n",
      "epoch: 23  batch: 32  loss: 0.05911497\n",
      "epoch: 23  batch: 33  loss: 0.11511515\n",
      "epoch: 23  batch: 34  loss: 0.14732832\n",
      "epoch: 23  batch: 35  loss: 0.25952208\n",
      "epoch: 23  batch: 36  loss: 0.05298857\n",
      "epoch: 23  batch: 37  loss: 0.06372642\n",
      "epoch: 23  batch: 38  loss: 0.07630827\n",
      "epoch: 23  batch: 39  loss: 0.38695291\n",
      "epoch: 23  batch: 40  loss: 0.21340854\n",
      "epoch: 23  batch: 41  loss: 0.32711262\n",
      "epoch: 23  batch: 42  loss: 0.22832830\n",
      "epoch: 23  batch: 43  loss: 0.43376732\n",
      "epoch: 23  batch: 44  loss: 0.39218116\n",
      "epoch: 23  batch: 45  loss: 0.35971487\n",
      "epoch: 23  batch: 46  loss: 0.21352793\n",
      "epoch: 23  batch: 47  loss: 0.22417203\n",
      "epoch: 23  batch: 48  loss: 0.17026636\n",
      "epoch: 23  batch: 49  loss: 0.15844318\n",
      "epoch: 23  batch: 50  loss: 0.28925905\n",
      "epoch: 23  batch: 51  loss: 0.23377162\n",
      "epoch: 23  batch: 52  loss: 0.12431598\n",
      "epoch: 23  batch: 53  loss: 0.12265218\n",
      "epoch: 23  batch: 54  loss: 0.35961914\n",
      "epoch: 23  batch: 55  loss: 0.23339957\n",
      "epoch: 23  batch: 56  loss: 0.08080997\n",
      "epoch: 23  batch: 57  loss: 0.11438876\n",
      "epoch: 23  batch: 58  loss: 0.09498020\n",
      "epoch: 23  batch: 59  loss: 0.13260557\n",
      "epoch: 23  batch: 60  loss: 0.35847652\n",
      "epoch: 23  batch: 61  loss: 0.83156878\n",
      "epoch: 23  batch: 62  loss: 0.23010077\n",
      "epoch: 23  batch: 63  loss: 0.39031389\n",
      "epoch: 23  batch: 64  loss: 0.25397825\n",
      "epoch: 23  batch: 65  loss: 0.03194048\n",
      "epoch: 23  batch: 66  loss: 0.03368428\n",
      "epoch: 23  batch: 67  loss: 0.06990820\n",
      "epoch: 23  batch: 68  loss: 0.12424106\n",
      "epoch: 24  batch: 1  loss: 0.22508837\n",
      "epoch: 24  batch: 2  loss: 0.07333311\n",
      "epoch: 24  batch: 3  loss: 0.12501225\n",
      "epoch: 24  batch: 4  loss: 0.10081823\n",
      "epoch: 24  batch: 5  loss: 0.26223224\n",
      "epoch: 24  batch: 6  loss: 0.21049415\n",
      "epoch: 24  batch: 7  loss: 0.30470636\n",
      "epoch: 24  batch: 8  loss: 0.19920905\n",
      "epoch: 24  batch: 9  loss: 0.32360825\n",
      "epoch: 24  batch: 10  loss: 0.29639831\n",
      "epoch: 24  batch: 11  loss: 0.37352833\n",
      "epoch: 24  batch: 12  loss: 0.19440295\n",
      "epoch: 24  batch: 13  loss: 0.21705972\n",
      "epoch: 24  batch: 14  loss: 0.20459586\n",
      "epoch: 24  batch: 15  loss: 0.17878558\n",
      "epoch: 24  batch: 16  loss: 0.16354994\n",
      "epoch: 24  batch: 17  loss: 0.31490496\n",
      "epoch: 24  batch: 18  loss: 0.11791341\n",
      "epoch: 24  batch: 19  loss: 0.17214888\n",
      "epoch: 24  batch: 20  loss: 0.31157181\n",
      "epoch: 24  batch: 21  loss: 0.39568961\n",
      "epoch: 24  batch: 22  loss: 0.09319405\n",
      "epoch: 24  batch: 23  loss: 0.11410394\n",
      "epoch: 24  batch: 24  loss: 0.07823921\n",
      "epoch: 24  batch: 25  loss: 0.05443776\n",
      "epoch: 24  batch: 26  loss: 0.38576213\n",
      "epoch: 24  batch: 27  loss: 0.82015127\n",
      "epoch: 24  batch: 28  loss: 0.33934474\n",
      "epoch: 24  batch: 29  loss: 0.28842530\n",
      "epoch: 24  batch: 30  loss: 0.19307826\n",
      "epoch: 24  batch: 31  loss: 0.06854376\n",
      "epoch: 24  batch: 32  loss: 0.02812374\n",
      "epoch: 24  batch: 33  loss: 0.04088452\n",
      "epoch: 24  batch: 34  loss: 0.11294921\n",
      "epoch: 24  batch: 35  loss: 0.22174568\n",
      "epoch: 24  batch: 36  loss: 0.05920627\n",
      "epoch: 24  batch: 37  loss: 0.07376935\n",
      "epoch: 24  batch: 38  loss: 0.10775308\n",
      "epoch: 24  batch: 39  loss: 0.32497111\n",
      "epoch: 24  batch: 40  loss: 0.08971938\n",
      "epoch: 24  batch: 41  loss: 0.31972590\n",
      "epoch: 24  batch: 42  loss: 0.17413978\n",
      "epoch: 24  batch: 43  loss: 0.24501750\n",
      "epoch: 24  batch: 44  loss: 0.30649391\n",
      "epoch: 24  batch: 45  loss: 0.28637412\n",
      "epoch: 24  batch: 46  loss: 0.18616976\n",
      "epoch: 24  batch: 47  loss: 0.22110777\n",
      "epoch: 24  batch: 48  loss: 0.18356730\n",
      "epoch: 24  batch: 49  loss: 0.14044334\n",
      "epoch: 24  batch: 50  loss: 0.24862072\n",
      "epoch: 24  batch: 51  loss: 0.19317098\n",
      "epoch: 24  batch: 52  loss: 0.08541633\n",
      "epoch: 24  batch: 53  loss: 0.12249673\n",
      "epoch: 24  batch: 54  loss: 0.36605412\n",
      "epoch: 24  batch: 55  loss: 0.23047924\n",
      "epoch: 24  batch: 56  loss: 0.08620279\n",
      "epoch: 24  batch: 57  loss: 0.05419598\n",
      "epoch: 24  batch: 58  loss: 0.09516281\n",
      "epoch: 24  batch: 59  loss: 0.11147252\n",
      "epoch: 24  batch: 60  loss: 0.35433522\n",
      "epoch: 24  batch: 61  loss: 0.80635571\n",
      "epoch: 24  batch: 62  loss: 0.17363337\n",
      "epoch: 24  batch: 63  loss: 0.35117254\n",
      "epoch: 24  batch: 64  loss: 0.18201362\n",
      "epoch: 24  batch: 65  loss: 0.03529919\n",
      "epoch: 24  batch: 66  loss: 0.04335989\n",
      "epoch: 24  batch: 67  loss: 0.07796293\n",
      "epoch: 24  batch: 68  loss: 0.15795657\n",
      "epoch: 25  batch: 1  loss: 0.22980975\n",
      "epoch: 25  batch: 2  loss: 0.09175002\n",
      "epoch: 25  batch: 3  loss: 0.09470158\n",
      "epoch: 25  batch: 4  loss: 0.07299791\n",
      "epoch: 25  batch: 5  loss: 0.24272798\n",
      "epoch: 25  batch: 6  loss: 0.15667319\n",
      "epoch: 25  batch: 7  loss: 0.28122702\n",
      "epoch: 25  batch: 8  loss: 0.16218887\n",
      "epoch: 25  batch: 9  loss: 0.21232846\n",
      "epoch: 25  batch: 10  loss: 0.27361959\n",
      "epoch: 25  batch: 11  loss: 0.39137948\n",
      "epoch: 25  batch: 12  loss: 0.19969228\n",
      "epoch: 25  batch: 13  loss: 0.19370143\n",
      "epoch: 25  batch: 14  loss: 0.18540482\n",
      "epoch: 25  batch: 15  loss: 0.18677270\n",
      "epoch: 25  batch: 16  loss: 0.16221066\n",
      "epoch: 25  batch: 17  loss: 0.28205857\n",
      "epoch: 25  batch: 18  loss: 0.09662359\n",
      "epoch: 25  batch: 19  loss: 0.13538319\n",
      "epoch: 25  batch: 20  loss: 0.29709455\n",
      "epoch: 25  batch: 21  loss: 0.38968930\n",
      "epoch: 25  batch: 22  loss: 0.08373651\n",
      "epoch: 25  batch: 23  loss: 0.08142190\n",
      "epoch: 25  batch: 24  loss: 0.07200592\n",
      "epoch: 25  batch: 25  loss: 0.09652812\n",
      "epoch: 25  batch: 26  loss: 0.31228253\n",
      "epoch: 25  batch: 27  loss: 0.75072795\n",
      "epoch: 25  batch: 28  loss: 0.33278328\n",
      "epoch: 25  batch: 29  loss: 0.33659720\n",
      "epoch: 25  batch: 30  loss: 0.21075791\n",
      "epoch: 25  batch: 31  loss: 0.07617656\n",
      "epoch: 25  batch: 32  loss: 0.02708442\n",
      "epoch: 25  batch: 33  loss: 0.06014910\n",
      "epoch: 25  batch: 34  loss: 0.10817700\n",
      "epoch: 25  batch: 35  loss: 0.26990640\n",
      "epoch: 25  batch: 36  loss: 0.05871850\n",
      "epoch: 25  batch: 37  loss: 0.10158101\n",
      "epoch: 25  batch: 38  loss: 0.09645172\n",
      "epoch: 25  batch: 39  loss: 0.27982092\n",
      "epoch: 25  batch: 40  loss: 0.08164553\n",
      "epoch: 25  batch: 41  loss: 0.28040692\n",
      "epoch: 25  batch: 42  loss: 0.19276175\n",
      "epoch: 25  batch: 43  loss: 0.20442551\n",
      "epoch: 25  batch: 44  loss: 0.26456839\n",
      "epoch: 25  batch: 45  loss: 0.24312639\n",
      "epoch: 25  batch: 46  loss: 0.19924648\n",
      "epoch: 25  batch: 47  loss: 0.22423902\n",
      "epoch: 25  batch: 48  loss: 0.16512063\n",
      "epoch: 25  batch: 49  loss: 0.14225657\n",
      "epoch: 25  batch: 50  loss: 0.23321682\n",
      "epoch: 25  batch: 51  loss: 0.14085720\n",
      "epoch: 25  batch: 52  loss: 0.10410409\n",
      "epoch: 25  batch: 53  loss: 0.10853879\n",
      "epoch: 25  batch: 54  loss: 0.36004463\n",
      "epoch: 25  batch: 55  loss: 0.22956175\n",
      "epoch: 25  batch: 56  loss: 0.08912399\n",
      "epoch: 25  batch: 57  loss: 0.06476396\n",
      "epoch: 25  batch: 58  loss: 0.11535194\n",
      "epoch: 25  batch: 59  loss: 0.10863851\n",
      "epoch: 25  batch: 60  loss: 0.38631636\n",
      "epoch: 25  batch: 61  loss: 0.69848686\n",
      "epoch: 25  batch: 62  loss: 0.17359871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25  batch: 63  loss: 0.30099347\n",
      "epoch: 25  batch: 64  loss: 0.21455060\n",
      "epoch: 25  batch: 65  loss: 0.04123782\n",
      "epoch: 25  batch: 66  loss: 0.06813993\n",
      "epoch: 25  batch: 67  loss: 0.11653282\n",
      "epoch: 25  batch: 68  loss: 0.14123440\n",
      "epoch: 26  batch: 1  loss: 0.22953017\n",
      "epoch: 26  batch: 2  loss: 0.11614947\n",
      "epoch: 26  batch: 3  loss: 0.10995580\n",
      "epoch: 26  batch: 4  loss: 0.11289438\n",
      "epoch: 26  batch: 5  loss: 0.20857345\n",
      "epoch: 26  batch: 6  loss: 0.18803868\n",
      "epoch: 26  batch: 7  loss: 0.28543237\n",
      "epoch: 26  batch: 8  loss: 0.19747221\n",
      "epoch: 26  batch: 9  loss: 0.32288146\n",
      "epoch: 26  batch: 10  loss: 0.29291460\n",
      "epoch: 26  batch: 11  loss: 0.32573560\n",
      "epoch: 26  batch: 12  loss: 0.19386275\n",
      "epoch: 26  batch: 13  loss: 0.28030893\n",
      "epoch: 26  batch: 14  loss: 0.17308702\n",
      "epoch: 26  batch: 15  loss: 0.15078640\n",
      "epoch: 26  batch: 16  loss: 0.17808050\n",
      "epoch: 26  batch: 17  loss: 0.31548637\n",
      "epoch: 26  batch: 18  loss: 0.10185727\n",
      "epoch: 26  batch: 19  loss: 0.14499260\n",
      "epoch: 26  batch: 20  loss: 0.29211608\n",
      "epoch: 26  batch: 21  loss: 0.36734757\n",
      "epoch: 26  batch: 22  loss: 0.06739574\n",
      "epoch: 26  batch: 23  loss: 0.07856908\n",
      "epoch: 26  batch: 24  loss: 0.07551876\n",
      "epoch: 26  batch: 25  loss: 0.07661788\n",
      "epoch: 26  batch: 26  loss: 0.38236412\n",
      "epoch: 26  batch: 27  loss: 0.72237647\n",
      "epoch: 26  batch: 28  loss: 0.34637639\n",
      "epoch: 26  batch: 29  loss: 0.27670395\n",
      "epoch: 26  batch: 30  loss: 0.17767374\n",
      "epoch: 26  batch: 31  loss: 0.04876650\n",
      "epoch: 26  batch: 32  loss: 0.02914907\n",
      "epoch: 26  batch: 33  loss: 0.06629143\n",
      "epoch: 26  batch: 34  loss: 0.11249909\n",
      "epoch: 26  batch: 35  loss: 0.21677777\n",
      "epoch: 26  batch: 36  loss: 0.08534050\n",
      "epoch: 26  batch: 37  loss: 0.08389640\n",
      "epoch: 26  batch: 38  loss: 0.07711899\n",
      "epoch: 26  batch: 39  loss: 0.32906598\n",
      "epoch: 26  batch: 40  loss: 0.09719105\n",
      "epoch: 26  batch: 41  loss: 0.39761940\n",
      "epoch: 26  batch: 42  loss: 0.25754669\n",
      "epoch: 26  batch: 43  loss: 0.18601473\n",
      "epoch: 26  batch: 44  loss: 0.26403323\n",
      "epoch: 26  batch: 45  loss: 0.29877844\n",
      "epoch: 26  batch: 46  loss: 0.18750472\n",
      "epoch: 26  batch: 47  loss: 0.20773987\n",
      "epoch: 26  batch: 48  loss: 0.14974403\n",
      "epoch: 26  batch: 49  loss: 0.13276911\n",
      "epoch: 26  batch: 50  loss: 0.20946622\n",
      "epoch: 26  batch: 51  loss: 0.13012789\n",
      "epoch: 26  batch: 52  loss: 0.09735237\n",
      "epoch: 26  batch: 53  loss: 0.12966144\n",
      "epoch: 26  batch: 54  loss: 0.36131373\n",
      "epoch: 26  batch: 55  loss: 0.24122904\n",
      "epoch: 26  batch: 56  loss: 0.08296279\n",
      "epoch: 26  batch: 57  loss: 0.07866523\n",
      "epoch: 26  batch: 58  loss: 0.09683844\n",
      "epoch: 26  batch: 59  loss: 0.11305838\n",
      "epoch: 26  batch: 60  loss: 0.35373271\n",
      "epoch: 26  batch: 61  loss: 0.65149540\n",
      "epoch: 26  batch: 62  loss: 0.15934291\n",
      "epoch: 26  batch: 63  loss: 0.28216413\n",
      "epoch: 26  batch: 64  loss: 0.24294090\n",
      "epoch: 26  batch: 65  loss: 0.05740907\n",
      "epoch: 26  batch: 66  loss: 0.05450365\n",
      "epoch: 26  batch: 67  loss: 0.06339151\n",
      "epoch: 26  batch: 68  loss: 0.13379237\n",
      "epoch: 27  batch: 1  loss: 0.19544305\n",
      "epoch: 27  batch: 2  loss: 0.08758137\n",
      "epoch: 27  batch: 3  loss: 0.13442640\n",
      "epoch: 27  batch: 4  loss: 0.08402204\n",
      "epoch: 27  batch: 5  loss: 0.19894539\n",
      "epoch: 27  batch: 6  loss: 0.22838886\n",
      "epoch: 27  batch: 7  loss: 0.27997780\n",
      "epoch: 27  batch: 8  loss: 0.23884825\n",
      "epoch: 27  batch: 9  loss: 0.26902917\n",
      "epoch: 27  batch: 10  loss: 0.33503759\n",
      "epoch: 27  batch: 11  loss: 0.30691379\n",
      "epoch: 27  batch: 12  loss: 0.20993280\n",
      "epoch: 27  batch: 13  loss: 0.23418683\n",
      "epoch: 27  batch: 14  loss: 0.16791204\n",
      "epoch: 27  batch: 15  loss: 0.15076053\n",
      "epoch: 27  batch: 16  loss: 0.17173885\n",
      "epoch: 27  batch: 17  loss: 0.26439133\n",
      "epoch: 27  batch: 18  loss: 0.13074751\n",
      "epoch: 27  batch: 19  loss: 0.11759423\n",
      "epoch: 27  batch: 20  loss: 0.29302320\n",
      "epoch: 27  batch: 21  loss: 0.36465520\n",
      "epoch: 27  batch: 22  loss: 0.07727586\n",
      "epoch: 27  batch: 23  loss: 0.06981049\n",
      "epoch: 27  batch: 24  loss: 0.07563717\n",
      "epoch: 27  batch: 25  loss: 0.06856409\n",
      "epoch: 27  batch: 26  loss: 0.33713248\n",
      "epoch: 27  batch: 27  loss: 0.77660000\n",
      "epoch: 27  batch: 28  loss: 0.31545061\n",
      "epoch: 27  batch: 29  loss: 0.27148777\n",
      "epoch: 27  batch: 30  loss: 0.17763241\n",
      "epoch: 27  batch: 31  loss: 0.05476902\n",
      "epoch: 27  batch: 32  loss: 0.02760281\n",
      "epoch: 27  batch: 33  loss: 0.05124396\n",
      "epoch: 27  batch: 34  loss: 0.10473625\n",
      "epoch: 27  batch: 35  loss: 0.19944356\n",
      "epoch: 27  batch: 36  loss: 0.06929944\n",
      "epoch: 27  batch: 37  loss: 0.07369166\n",
      "epoch: 27  batch: 38  loss: 0.08296783\n",
      "epoch: 27  batch: 39  loss: 0.33218211\n",
      "epoch: 27  batch: 40  loss: 0.09467059\n",
      "epoch: 27  batch: 41  loss: 0.26910228\n",
      "epoch: 27  batch: 42  loss: 0.23185697\n",
      "epoch: 27  batch: 43  loss: 0.17629401\n",
      "epoch: 27  batch: 44  loss: 0.23766422\n",
      "epoch: 27  batch: 45  loss: 0.30337441\n",
      "epoch: 27  batch: 46  loss: 0.23363166\n",
      "epoch: 27  batch: 47  loss: 0.17371358\n",
      "epoch: 27  batch: 48  loss: 0.16011615\n",
      "epoch: 27  batch: 49  loss: 0.13177735\n",
      "epoch: 27  batch: 50  loss: 0.20482169\n",
      "epoch: 27  batch: 51  loss: 0.18237555\n",
      "epoch: 27  batch: 52  loss: 0.14249615\n",
      "epoch: 27  batch: 53  loss: 0.16161691\n",
      "epoch: 27  batch: 54  loss: 0.37287241\n",
      "epoch: 27  batch: 55  loss: 0.24034886\n",
      "epoch: 27  batch: 56  loss: 0.08688562\n",
      "epoch: 27  batch: 57  loss: 0.10237008\n",
      "epoch: 27  batch: 58  loss: 0.07939190\n",
      "epoch: 27  batch: 59  loss: 0.10812481\n",
      "epoch: 27  batch: 60  loss: 0.30273649\n",
      "epoch: 27  batch: 61  loss: 0.82217205\n",
      "epoch: 27  batch: 62  loss: 0.20835161\n",
      "epoch: 27  batch: 63  loss: 0.30022049\n",
      "epoch: 27  batch: 64  loss: 0.23259002\n",
      "epoch: 27  batch: 65  loss: 0.05804123\n",
      "epoch: 27  batch: 66  loss: 0.05181160\n",
      "epoch: 27  batch: 67  loss: 0.05450907\n",
      "epoch: 27  batch: 68  loss: 0.12718606\n",
      "epoch: 28  batch: 1  loss: 0.23365636\n",
      "epoch: 28  batch: 2  loss: 0.08518362\n",
      "epoch: 28  batch: 3  loss: 0.12157464\n",
      "epoch: 28  batch: 4  loss: 0.10900072\n",
      "epoch: 28  batch: 5  loss: 0.22672370\n",
      "epoch: 28  batch: 6  loss: 0.20930609\n",
      "epoch: 28  batch: 7  loss: 0.32267225\n",
      "epoch: 28  batch: 8  loss: 0.20732889\n",
      "epoch: 28  batch: 9  loss: 0.30937871\n",
      "epoch: 28  batch: 10  loss: 0.30638209\n",
      "epoch: 28  batch: 11  loss: 0.37201479\n",
      "epoch: 28  batch: 12  loss: 0.20106870\n",
      "epoch: 28  batch: 13  loss: 0.17049965\n",
      "epoch: 28  batch: 14  loss: 0.16950615\n",
      "epoch: 28  batch: 15  loss: 0.16180748\n",
      "epoch: 28  batch: 16  loss: 0.17108817\n",
      "epoch: 28  batch: 17  loss: 0.26504245\n",
      "epoch: 28  batch: 18  loss: 0.09417682\n",
      "epoch: 28  batch: 19  loss: 0.10742857\n",
      "epoch: 28  batch: 20  loss: 0.28258312\n",
      "epoch: 28  batch: 21  loss: 0.34668261\n",
      "epoch: 28  batch: 22  loss: 0.07598010\n",
      "epoch: 28  batch: 23  loss: 0.07565892\n",
      "epoch: 28  batch: 24  loss: 0.07520470\n",
      "epoch: 28  batch: 25  loss: 0.11699390\n",
      "epoch: 28  batch: 26  loss: 0.29335177\n",
      "epoch: 28  batch: 27  loss: 0.69595814\n",
      "epoch: 28  batch: 28  loss: 0.34488937\n",
      "epoch: 28  batch: 29  loss: 0.32865465\n",
      "epoch: 28  batch: 30  loss: 0.15471216\n",
      "epoch: 28  batch: 31  loss: 0.06080220\n",
      "epoch: 28  batch: 32  loss: 0.03950270\n",
      "epoch: 28  batch: 33  loss: 0.06748784\n",
      "epoch: 28  batch: 34  loss: 0.10569765\n",
      "epoch: 28  batch: 35  loss: 0.18612589\n",
      "epoch: 28  batch: 36  loss: 0.04398980\n",
      "epoch: 28  batch: 37  loss: 0.06194620\n",
      "epoch: 28  batch: 38  loss: 0.10530423\n",
      "epoch: 28  batch: 39  loss: 0.28181744\n",
      "epoch: 28  batch: 40  loss: 0.11832032\n",
      "epoch: 28  batch: 41  loss: 0.26368102\n",
      "epoch: 28  batch: 42  loss: 0.16134845\n",
      "epoch: 28  batch: 43  loss: 0.17018098\n",
      "epoch: 28  batch: 44  loss: 0.31992358\n",
      "epoch: 28  batch: 45  loss: 0.25662598\n",
      "epoch: 28  batch: 46  loss: 0.19516945\n",
      "epoch: 28  batch: 47  loss: 0.21908544\n",
      "epoch: 28  batch: 48  loss: 0.15911384\n",
      "epoch: 28  batch: 49  loss: 0.16418926\n",
      "epoch: 28  batch: 50  loss: 0.24649327\n",
      "epoch: 28  batch: 51  loss: 0.19293603\n",
      "epoch: 28  batch: 52  loss: 0.10130418\n",
      "epoch: 28  batch: 53  loss: 0.10172518\n",
      "epoch: 28  batch: 54  loss: 0.36423814\n",
      "epoch: 28  batch: 55  loss: 0.23478445\n",
      "epoch: 28  batch: 56  loss: 0.08158753\n",
      "epoch: 28  batch: 57  loss: 0.07661106\n",
      "epoch: 28  batch: 58  loss: 0.09420480\n",
      "epoch: 28  batch: 59  loss: 0.12466721\n",
      "epoch: 28  batch: 60  loss: 0.30871481\n",
      "epoch: 28  batch: 61  loss: 0.83588189\n",
      "epoch: 28  batch: 62  loss: 0.18087541\n",
      "epoch: 28  batch: 63  loss: 0.26199594\n",
      "epoch: 28  batch: 64  loss: 0.14597018\n",
      "epoch: 28  batch: 65  loss: 0.07289901\n",
      "epoch: 28  batch: 66  loss: 0.04455207\n",
      "epoch: 28  batch: 67  loss: 0.07087837\n",
      "epoch: 28  batch: 68  loss: 0.11229540\n",
      "epoch: 29  batch: 1  loss: 0.21805146\n",
      "epoch: 29  batch: 2  loss: 0.09168176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29  batch: 3  loss: 0.09527376\n",
      "epoch: 29  batch: 4  loss: 0.10306327\n",
      "epoch: 29  batch: 5  loss: 0.20939152\n",
      "epoch: 29  batch: 6  loss: 0.20336419\n",
      "epoch: 29  batch: 7  loss: 0.28445300\n",
      "epoch: 29  batch: 8  loss: 0.12219511\n",
      "epoch: 29  batch: 9  loss: 0.34369364\n",
      "epoch: 29  batch: 10  loss: 0.45733637\n",
      "epoch: 29  batch: 11  loss: 0.43496507\n",
      "epoch: 29  batch: 12  loss: 0.19598389\n",
      "epoch: 29  batch: 13  loss: 0.17010224\n",
      "epoch: 29  batch: 14  loss: 0.16246779\n",
      "epoch: 29  batch: 15  loss: 0.14339797\n",
      "epoch: 29  batch: 16  loss: 0.17536922\n",
      "epoch: 29  batch: 17  loss: 0.26435804\n",
      "epoch: 29  batch: 18  loss: 0.08842672\n",
      "epoch: 29  batch: 19  loss: 0.09509337\n",
      "epoch: 29  batch: 20  loss: 0.27835470\n",
      "epoch: 29  batch: 21  loss: 0.39532337\n",
      "epoch: 29  batch: 22  loss: 0.07341673\n",
      "epoch: 29  batch: 23  loss: 0.06591205\n",
      "epoch: 29  batch: 24  loss: 0.07531210\n",
      "epoch: 29  batch: 25  loss: 0.11413448\n",
      "epoch: 29  batch: 26  loss: 0.29012138\n",
      "epoch: 29  batch: 27  loss: 0.78815812\n",
      "epoch: 29  batch: 28  loss: 0.41768965\n",
      "epoch: 29  batch: 29  loss: 0.25503042\n",
      "epoch: 29  batch: 30  loss: 0.17242503\n",
      "epoch: 29  batch: 31  loss: 0.08315589\n",
      "epoch: 29  batch: 32  loss: 0.02737905\n",
      "epoch: 29  batch: 33  loss: 0.03714116\n",
      "epoch: 29  batch: 34  loss: 0.10801440\n",
      "epoch: 29  batch: 35  loss: 0.23112984\n",
      "epoch: 29  batch: 36  loss: 0.04135353\n",
      "epoch: 29  batch: 37  loss: 0.05796238\n",
      "epoch: 29  batch: 38  loss: 0.07351860\n",
      "epoch: 29  batch: 39  loss: 0.27290741\n",
      "epoch: 29  batch: 40  loss: 0.11229989\n",
      "epoch: 29  batch: 41  loss: 0.27750835\n",
      "epoch: 29  batch: 42  loss: 0.26994342\n",
      "epoch: 29  batch: 43  loss: 0.19307870\n",
      "epoch: 29  batch: 44  loss: 0.32131645\n",
      "epoch: 29  batch: 45  loss: 0.26699603\n",
      "epoch: 29  batch: 46  loss: 0.20157857\n",
      "epoch: 29  batch: 47  loss: 0.24181491\n",
      "epoch: 29  batch: 48  loss: 0.16174591\n",
      "epoch: 29  batch: 49  loss: 0.16458789\n",
      "epoch: 29  batch: 50  loss: 0.25765637\n",
      "epoch: 29  batch: 51  loss: 0.20493625\n",
      "epoch: 29  batch: 52  loss: 0.09682819\n",
      "epoch: 29  batch: 53  loss: 0.11392964\n",
      "epoch: 29  batch: 54  loss: 0.36285827\n",
      "epoch: 29  batch: 55  loss: 0.23706721\n",
      "epoch: 29  batch: 56  loss: 0.08208919\n",
      "epoch: 29  batch: 57  loss: 0.11510718\n",
      "epoch: 29  batch: 58  loss: 0.09766144\n",
      "epoch: 29  batch: 59  loss: 0.12013780\n",
      "epoch: 29  batch: 60  loss: 0.27446011\n",
      "epoch: 29  batch: 61  loss: 0.89565378\n",
      "epoch: 29  batch: 62  loss: 0.20467494\n",
      "epoch: 29  batch: 63  loss: 0.35676610\n",
      "epoch: 29  batch: 64  loss: 0.14638464\n",
      "epoch: 29  batch: 65  loss: 0.03686280\n",
      "epoch: 29  batch: 66  loss: 0.04789737\n",
      "epoch: 29  batch: 67  loss: 0.08328176\n",
      "epoch: 29  batch: 68  loss: 0.12075634\n",
      "epoch: 30  batch: 1  loss: 0.23890528\n",
      "epoch: 30  batch: 2  loss: 0.08281435\n",
      "epoch: 30  batch: 3  loss: 0.12653415\n",
      "epoch: 30  batch: 4  loss: 0.08448374\n",
      "epoch: 30  batch: 5  loss: 0.24402784\n",
      "epoch: 30  batch: 6  loss: 0.18688114\n",
      "epoch: 30  batch: 7  loss: 0.29177609\n",
      "epoch: 30  batch: 8  loss: 0.18743469\n",
      "epoch: 30  batch: 9  loss: 0.37446710\n",
      "epoch: 30  batch: 10  loss: 0.30691162\n",
      "epoch: 30  batch: 11  loss: 0.28487542\n",
      "epoch: 30  batch: 12  loss: 0.19619052\n",
      "epoch: 30  batch: 13  loss: 0.19809932\n",
      "epoch: 30  batch: 14  loss: 0.17051019\n",
      "epoch: 30  batch: 15  loss: 0.14310752\n",
      "epoch: 30  batch: 16  loss: 0.17690703\n",
      "epoch: 30  batch: 17  loss: 0.27505982\n",
      "epoch: 30  batch: 18  loss: 0.10388555\n",
      "epoch: 30  batch: 19  loss: 0.10334352\n",
      "epoch: 30  batch: 20  loss: 0.26722583\n",
      "epoch: 30  batch: 21  loss: 0.32668984\n",
      "epoch: 30  batch: 22  loss: 0.07715718\n",
      "epoch: 30  batch: 23  loss: 0.08942787\n",
      "epoch: 30  batch: 24  loss: 0.07607877\n",
      "epoch: 30  batch: 25  loss: 0.11261530\n",
      "epoch: 30  batch: 26  loss: 0.34537554\n",
      "epoch: 30  batch: 27  loss: 0.69025230\n",
      "epoch: 30  batch: 28  loss: 0.33053845\n",
      "epoch: 30  batch: 29  loss: 0.33214545\n",
      "epoch: 30  batch: 30  loss: 0.16021509\n",
      "epoch: 30  batch: 31  loss: 0.07471341\n",
      "epoch: 30  batch: 32  loss: 0.05269502\n",
      "epoch: 30  batch: 33  loss: 0.09797622\n",
      "epoch: 30  batch: 34  loss: 0.13957496\n",
      "epoch: 30  batch: 35  loss: 0.29950413\n",
      "epoch: 30  batch: 36  loss: 0.04045145\n",
      "epoch: 30  batch: 37  loss: 0.04166209\n",
      "epoch: 30  batch: 38  loss: 0.05429287\n",
      "epoch: 30  batch: 39  loss: 0.25684571\n",
      "epoch: 30  batch: 40  loss: 0.10699794\n",
      "epoch: 30  batch: 41  loss: 0.24828051\n",
      "epoch: 30  batch: 42  loss: 0.12371127\n",
      "epoch: 30  batch: 43  loss: 0.15297651\n",
      "epoch: 30  batch: 44  loss: 0.35925674\n",
      "epoch: 30  batch: 45  loss: 0.26601329\n",
      "epoch: 30  batch: 46  loss: 0.19416663\n",
      "epoch: 30  batch: 47  loss: 0.22624563\n",
      "epoch: 30  batch: 48  loss: 0.18397234\n",
      "epoch: 30  batch: 49  loss: 0.14626062\n",
      "epoch: 30  batch: 50  loss: 0.24974464\n",
      "epoch: 30  batch: 51  loss: 0.22435740\n",
      "epoch: 30  batch: 52  loss: 0.09015590\n",
      "epoch: 30  batch: 53  loss: 0.10217813\n",
      "epoch: 30  batch: 54  loss: 0.37988120\n",
      "epoch: 30  batch: 55  loss: 0.22999497\n",
      "epoch: 30  batch: 56  loss: 0.08656808\n",
      "epoch: 30  batch: 57  loss: 0.09210827\n",
      "epoch: 30  batch: 58  loss: 0.10413566\n",
      "epoch: 30  batch: 59  loss: 0.10309385\n",
      "epoch: 30  batch: 60  loss: 0.32950607\n",
      "epoch: 30  batch: 61  loss: 0.71785212\n",
      "epoch: 30  batch: 62  loss: 0.15188049\n",
      "epoch: 30  batch: 63  loss: 0.28895628\n",
      "epoch: 30  batch: 64  loss: 0.22772230\n",
      "epoch: 30  batch: 65  loss: 0.05453182\n",
      "epoch: 30  batch: 66  loss: 0.06280905\n",
      "epoch: 30  batch: 67  loss: 0.10563997\n",
      "epoch: 30  batch: 68  loss: 0.16969870\n",
      "epoch: 31  batch: 1  loss: 0.22397742\n",
      "epoch: 31  batch: 2  loss: 0.13806702\n",
      "epoch: 31  batch: 3  loss: 0.08992184\n",
      "epoch: 31  batch: 4  loss: 0.07522254\n",
      "epoch: 31  batch: 5  loss: 0.25863814\n",
      "epoch: 31  batch: 6  loss: 0.10977908\n",
      "epoch: 31  batch: 7  loss: 0.35211885\n",
      "epoch: 31  batch: 8  loss: 0.15239207\n",
      "epoch: 31  batch: 9  loss: 0.29164028\n",
      "epoch: 31  batch: 10  loss: 0.30315495\n",
      "epoch: 31  batch: 11  loss: 0.24583204\n",
      "epoch: 31  batch: 12  loss: 0.18652865\n",
      "epoch: 31  batch: 13  loss: 0.42096186\n",
      "epoch: 31  batch: 14  loss: 0.18362501\n",
      "epoch: 31  batch: 15  loss: 0.17161885\n",
      "epoch: 31  batch: 16  loss: 0.44879398\n",
      "epoch: 31  batch: 17  loss: 0.41117013\n",
      "epoch: 31  batch: 18  loss: 0.12800483\n",
      "epoch: 31  batch: 19  loss: 0.30474418\n",
      "epoch: 31  batch: 20  loss: 0.37993041\n",
      "epoch: 31  batch: 21  loss: 0.40269998\n",
      "epoch: 31  batch: 22  loss: 0.08996182\n",
      "epoch: 31  batch: 23  loss: 0.07751250\n",
      "epoch: 31  batch: 24  loss: 0.05134365\n",
      "epoch: 31  batch: 25  loss: 0.09846172\n",
      "epoch: 31  batch: 26  loss: 0.24494214\n",
      "epoch: 31  batch: 27  loss: 0.57333511\n",
      "epoch: 31  batch: 28  loss: 0.26322827\n",
      "epoch: 31  batch: 29  loss: 0.20301989\n",
      "epoch: 31  batch: 30  loss: 0.13455504\n",
      "epoch: 31  batch: 31  loss: 0.05236500\n",
      "epoch: 31  batch: 32  loss: 0.08082990\n",
      "epoch: 31  batch: 33  loss: 0.14935596\n",
      "epoch: 31  batch: 34  loss: 0.22945623\n",
      "epoch: 31  batch: 35  loss: 0.29037672\n",
      "epoch: 31  batch: 36  loss: 0.11466113\n",
      "epoch: 31  batch: 37  loss: 0.10058912\n",
      "epoch: 31  batch: 38  loss: 0.07304705\n",
      "epoch: 31  batch: 39  loss: 0.25441769\n",
      "epoch: 31  batch: 40  loss: 0.11029064\n",
      "epoch: 31  batch: 41  loss: 0.27374339\n",
      "epoch: 31  batch: 42  loss: 0.17554867\n",
      "epoch: 31  batch: 43  loss: 0.15957054\n",
      "epoch: 31  batch: 44  loss: 0.30771393\n",
      "epoch: 31  batch: 45  loss: 0.29572034\n",
      "epoch: 31  batch: 46  loss: 0.24206051\n",
      "epoch: 31  batch: 47  loss: 0.25062463\n",
      "epoch: 31  batch: 48  loss: 0.17459762\n",
      "epoch: 31  batch: 49  loss: 0.14646332\n",
      "epoch: 31  batch: 50  loss: 0.28654858\n",
      "epoch: 31  batch: 51  loss: 0.27965397\n",
      "epoch: 31  batch: 52  loss: 0.11211942\n",
      "epoch: 31  batch: 53  loss: 0.14675495\n",
      "epoch: 31  batch: 54  loss: 0.36988559\n",
      "epoch: 31  batch: 55  loss: 0.25483924\n",
      "epoch: 31  batch: 56  loss: 0.08313496\n",
      "epoch: 31  batch: 57  loss: 0.10884292\n",
      "epoch: 31  batch: 58  loss: 0.07815541\n",
      "epoch: 31  batch: 59  loss: 0.11506172\n",
      "epoch: 31  batch: 60  loss: 0.38865316\n",
      "epoch: 31  batch: 61  loss: 0.88099229\n",
      "epoch: 31  batch: 62  loss: 0.17644316\n",
      "epoch: 31  batch: 63  loss: 0.29546759\n",
      "epoch: 31  batch: 64  loss: 0.13710737\n",
      "epoch: 31  batch: 65  loss: 0.04218141\n",
      "epoch: 31  batch: 66  loss: 0.06287406\n",
      "epoch: 31  batch: 67  loss: 0.11356527\n",
      "epoch: 31  batch: 68  loss: 0.20697689\n",
      "epoch: 32  batch: 1  loss: 0.27307868\n",
      "epoch: 32  batch: 2  loss: 0.07911815\n",
      "epoch: 32  batch: 3  loss: 0.09673426\n",
      "epoch: 32  batch: 4  loss: 0.09720857\n",
      "epoch: 32  batch: 5  loss: 0.23822114\n",
      "epoch: 32  batch: 6  loss: 0.17907178\n",
      "epoch: 32  batch: 7  loss: 0.36213940\n",
      "epoch: 32  batch: 8  loss: 0.11496186\n",
      "epoch: 32  batch: 9  loss: 0.28683928\n",
      "epoch: 32  batch: 10  loss: 0.33281803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32  batch: 11  loss: 0.32448804\n",
      "epoch: 32  batch: 12  loss: 0.14502357\n",
      "epoch: 32  batch: 13  loss: 0.31468025\n",
      "epoch: 32  batch: 14  loss: 0.22680613\n",
      "epoch: 32  batch: 15  loss: 0.13868226\n",
      "epoch: 32  batch: 16  loss: 0.19486625\n",
      "epoch: 32  batch: 17  loss: 0.39876643\n",
      "epoch: 32  batch: 18  loss: 0.15011306\n",
      "epoch: 32  batch: 19  loss: 0.30886143\n",
      "epoch: 32  batch: 20  loss: 0.32333201\n",
      "epoch: 32  batch: 21  loss: 0.37123609\n",
      "epoch: 32  batch: 22  loss: 0.08786591\n",
      "epoch: 32  batch: 23  loss: 0.13049176\n",
      "epoch: 32  batch: 24  loss: 0.06870028\n",
      "epoch: 32  batch: 25  loss: 0.07572117\n",
      "epoch: 32  batch: 26  loss: 0.33518696\n",
      "epoch: 32  batch: 27  loss: 0.71467018\n",
      "epoch: 32  batch: 28  loss: 0.34534374\n",
      "epoch: 32  batch: 29  loss: 0.25904566\n",
      "epoch: 32  batch: 30  loss: 0.17893673\n",
      "epoch: 32  batch: 31  loss: 0.07266349\n",
      "epoch: 32  batch: 32  loss: 0.03942631\n",
      "epoch: 32  batch: 33  loss: 0.03075984\n",
      "epoch: 32  batch: 34  loss: 0.11536162\n",
      "epoch: 32  batch: 35  loss: 0.20754687\n",
      "epoch: 32  batch: 36  loss: 0.05293949\n",
      "epoch: 32  batch: 37  loss: 0.10180232\n",
      "epoch: 32  batch: 38  loss: 0.06097153\n",
      "epoch: 32  batch: 39  loss: 0.28267902\n",
      "epoch: 32  batch: 40  loss: 0.16548763\n",
      "epoch: 32  batch: 41  loss: 0.38035330\n",
      "epoch: 32  batch: 42  loss: 0.25759119\n",
      "epoch: 32  batch: 43  loss: 0.33003783\n",
      "epoch: 32  batch: 44  loss: 0.32973024\n",
      "epoch: 32  batch: 45  loss: 0.48472792\n",
      "epoch: 32  batch: 46  loss: 0.22691350\n",
      "epoch: 32  batch: 47  loss: 0.20183025\n",
      "epoch: 32  batch: 48  loss: 0.15266898\n",
      "epoch: 32  batch: 49  loss: 0.14830685\n",
      "epoch: 32  batch: 50  loss: 0.25675875\n",
      "epoch: 32  batch: 51  loss: 0.22635253\n",
      "epoch: 32  batch: 52  loss: 0.09534768\n",
      "epoch: 32  batch: 53  loss: 0.10163882\n",
      "epoch: 32  batch: 54  loss: 0.42097953\n",
      "epoch: 32  batch: 55  loss: 0.24454823\n",
      "epoch: 32  batch: 56  loss: 0.09735117\n",
      "epoch: 32  batch: 57  loss: 0.08164522\n",
      "epoch: 32  batch: 58  loss: 0.10598069\n",
      "epoch: 32  batch: 59  loss: 0.10898507\n",
      "epoch: 32  batch: 60  loss: 0.39746070\n",
      "epoch: 32  batch: 61  loss: 0.80128956\n",
      "epoch: 32  batch: 62  loss: 0.20817912\n",
      "epoch: 32  batch: 63  loss: 0.32642934\n",
      "epoch: 32  batch: 64  loss: 0.19709602\n",
      "epoch: 32  batch: 65  loss: 0.04751040\n",
      "epoch: 32  batch: 66  loss: 0.03651999\n",
      "epoch: 32  batch: 67  loss: 0.08515363\n",
      "epoch: 32  batch: 68  loss: 0.16798912\n",
      "epoch: 33  batch: 1  loss: 0.25306746\n",
      "epoch: 33  batch: 2  loss: 0.07168042\n",
      "epoch: 33  batch: 3  loss: 0.02914820\n",
      "epoch: 33  batch: 4  loss: 0.03672605\n",
      "epoch: 33  batch: 5  loss: 0.17547090\n",
      "epoch: 33  batch: 6  loss: 0.13483855\n",
      "epoch: 33  batch: 7  loss: 0.29690668\n",
      "epoch: 33  batch: 8  loss: 0.19049141\n",
      "epoch: 33  batch: 9  loss: 0.28295389\n",
      "epoch: 33  batch: 10  loss: 0.40879437\n",
      "epoch: 33  batch: 11  loss: 0.38944346\n",
      "epoch: 33  batch: 12  loss: 0.21452561\n",
      "epoch: 33  batch: 13  loss: 0.18197301\n",
      "epoch: 33  batch: 14  loss: 0.24834451\n",
      "epoch: 33  batch: 15  loss: 0.19584619\n",
      "epoch: 33  batch: 16  loss: 0.14205717\n",
      "epoch: 33  batch: 17  loss: 0.25987175\n",
      "epoch: 33  batch: 18  loss: 0.12541099\n",
      "epoch: 33  batch: 19  loss: 0.14152336\n",
      "epoch: 33  batch: 20  loss: 0.31986865\n",
      "epoch: 33  batch: 21  loss: 0.39088780\n",
      "epoch: 33  batch: 22  loss: 0.08341285\n",
      "epoch: 33  batch: 23  loss: 0.06061860\n",
      "epoch: 33  batch: 24  loss: 0.09327438\n",
      "epoch: 33  batch: 25  loss: 0.08706053\n",
      "epoch: 33  batch: 26  loss: 0.32321399\n",
      "epoch: 33  batch: 27  loss: 0.65636063\n",
      "epoch: 33  batch: 28  loss: 0.36321765\n",
      "epoch: 33  batch: 29  loss: 0.31983897\n",
      "epoch: 33  batch: 30  loss: 0.22447324\n",
      "epoch: 33  batch: 31  loss: 0.08071093\n",
      "epoch: 33  batch: 32  loss: 0.03213928\n",
      "epoch: 33  batch: 33  loss: 0.07117328\n",
      "epoch: 33  batch: 34  loss: 0.12112227\n",
      "epoch: 33  batch: 35  loss: 0.20334996\n",
      "epoch: 33  batch: 36  loss: 0.04774540\n",
      "epoch: 33  batch: 37  loss: 0.05203364\n",
      "epoch: 33  batch: 38  loss: 0.11487673\n",
      "epoch: 33  batch: 39  loss: 0.26609680\n",
      "epoch: 33  batch: 40  loss: 0.10243042\n",
      "epoch: 33  batch: 41  loss: 0.28375763\n",
      "epoch: 33  batch: 42  loss: 0.20824772\n",
      "epoch: 33  batch: 43  loss: 0.25608429\n",
      "epoch: 33  batch: 44  loss: 0.47880709\n",
      "epoch: 33  batch: 45  loss: 0.45068589\n",
      "epoch: 33  batch: 46  loss: 0.26118833\n",
      "epoch: 33  batch: 47  loss: 0.18175542\n",
      "epoch: 33  batch: 48  loss: 0.16149245\n",
      "epoch: 33  batch: 49  loss: 0.15218124\n",
      "epoch: 33  batch: 50  loss: 0.29568669\n",
      "epoch: 33  batch: 51  loss: 0.21405429\n",
      "epoch: 33  batch: 52  loss: 0.09571010\n",
      "epoch: 33  batch: 53  loss: 0.13876347\n",
      "epoch: 33  batch: 54  loss: 0.36994764\n",
      "epoch: 33  batch: 55  loss: 0.23762982\n",
      "epoch: 33  batch: 56  loss: 0.08563959\n",
      "epoch: 33  batch: 57  loss: 0.05739342\n",
      "epoch: 33  batch: 58  loss: 0.13573624\n",
      "epoch: 33  batch: 59  loss: 0.11521801\n",
      "epoch: 33  batch: 60  loss: 0.37674141\n",
      "epoch: 33  batch: 61  loss: 0.91665244\n",
      "epoch: 33  batch: 62  loss: 0.22249845\n",
      "epoch: 33  batch: 63  loss: 0.35943288\n",
      "epoch: 33  batch: 64  loss: 0.15773359\n",
      "epoch: 33  batch: 65  loss: 0.08031584\n",
      "epoch: 33  batch: 66  loss: 0.06657746\n",
      "epoch: 33  batch: 67  loss: 0.08064226\n",
      "epoch: 33  batch: 68  loss: 0.17032066\n",
      "epoch: 34  batch: 1  loss: 0.23276553\n",
      "epoch: 34  batch: 2  loss: 0.11303256\n",
      "epoch: 34  batch: 3  loss: 0.10553839\n",
      "epoch: 34  batch: 4  loss: 0.08564875\n",
      "epoch: 34  batch: 5  loss: 0.21977332\n",
      "epoch: 34  batch: 6  loss: 0.17543969\n",
      "epoch: 34  batch: 7  loss: 0.34524983\n",
      "epoch: 34  batch: 8  loss: 0.18407032\n",
      "epoch: 34  batch: 9  loss: 0.17080896\n",
      "epoch: 34  batch: 10  loss: 0.38761783\n",
      "epoch: 34  batch: 11  loss: 0.34686327\n",
      "epoch: 34  batch: 12  loss: 0.20204397\n",
      "epoch: 34  batch: 13  loss: 0.32931587\n",
      "epoch: 34  batch: 14  loss: 0.23688056\n",
      "epoch: 34  batch: 15  loss: 0.17752437\n",
      "epoch: 34  batch: 16  loss: 0.17386062\n",
      "epoch: 34  batch: 17  loss: 0.37498519\n",
      "epoch: 34  batch: 18  loss: 0.16328359\n",
      "epoch: 34  batch: 19  loss: 0.14355160\n",
      "epoch: 34  batch: 20  loss: 0.32633701\n",
      "epoch: 34  batch: 21  loss: 0.39431801\n",
      "epoch: 34  batch: 22  loss: 0.10011603\n",
      "epoch: 34  batch: 23  loss: 0.09969360\n",
      "epoch: 34  batch: 24  loss: 0.08147377\n",
      "epoch: 34  batch: 25  loss: 0.06295831\n",
      "epoch: 34  batch: 26  loss: 0.33711505\n",
      "epoch: 34  batch: 27  loss: 0.75686294\n",
      "epoch: 34  batch: 28  loss: 0.42870456\n",
      "epoch: 34  batch: 29  loss: 0.32719773\n",
      "epoch: 34  batch: 30  loss: 0.23885399\n",
      "epoch: 34  batch: 31  loss: 0.11403773\n",
      "epoch: 34  batch: 32  loss: 0.05082987\n",
      "epoch: 34  batch: 33  loss: 0.03904167\n",
      "epoch: 34  batch: 34  loss: 0.11478528\n",
      "epoch: 34  batch: 35  loss: 0.22520477\n",
      "epoch: 34  batch: 36  loss: 0.05364120\n",
      "epoch: 34  batch: 37  loss: 0.08817618\n",
      "epoch: 34  batch: 38  loss: 0.06402154\n",
      "epoch: 34  batch: 39  loss: 0.25848043\n",
      "epoch: 34  batch: 40  loss: 0.14855556\n",
      "epoch: 34  batch: 41  loss: 0.34455204\n",
      "epoch: 34  batch: 42  loss: 0.22209927\n",
      "epoch: 34  batch: 43  loss: 0.25926772\n",
      "epoch: 34  batch: 44  loss: 0.35727471\n",
      "epoch: 34  batch: 45  loss: 0.30958381\n",
      "epoch: 34  batch: 46  loss: 0.21614504\n",
      "epoch: 34  batch: 47  loss: 0.22839630\n",
      "epoch: 34  batch: 48  loss: 0.15980732\n",
      "epoch: 34  batch: 49  loss: 0.15059926\n",
      "epoch: 34  batch: 50  loss: 0.23702063\n",
      "epoch: 34  batch: 51  loss: 0.22404402\n",
      "epoch: 34  batch: 52  loss: 0.08513098\n",
      "epoch: 34  batch: 53  loss: 0.13694513\n",
      "epoch: 34  batch: 54  loss: 0.35134840\n",
      "epoch: 34  batch: 55  loss: 0.24005422\n",
      "epoch: 34  batch: 56  loss: 0.08403602\n",
      "epoch: 34  batch: 57  loss: 0.06817603\n",
      "epoch: 34  batch: 58  loss: 0.11959023\n",
      "epoch: 34  batch: 59  loss: 0.11675983\n",
      "epoch: 34  batch: 60  loss: 0.34981090\n",
      "epoch: 34  batch: 61  loss: 0.68600219\n",
      "epoch: 34  batch: 62  loss: 0.19339104\n",
      "epoch: 34  batch: 63  loss: 0.37795547\n",
      "epoch: 34  batch: 64  loss: 0.19255315\n",
      "epoch: 34  batch: 65  loss: 0.03374951\n",
      "epoch: 34  batch: 66  loss: 0.03776217\n",
      "epoch: 34  batch: 67  loss: 0.07984462\n",
      "epoch: 34  batch: 68  loss: 0.12026400\n",
      "epoch: 35  batch: 1  loss: 0.21396896\n",
      "epoch: 35  batch: 2  loss: 0.07398455\n",
      "epoch: 35  batch: 3  loss: 0.09488130\n",
      "epoch: 35  batch: 4  loss: 0.11542320\n",
      "epoch: 35  batch: 5  loss: 0.17902121\n",
      "epoch: 35  batch: 6  loss: 0.20430303\n",
      "epoch: 35  batch: 7  loss: 0.34930086\n",
      "epoch: 35  batch: 8  loss: 0.19825333\n",
      "epoch: 35  batch: 9  loss: 0.21310639\n",
      "epoch: 35  batch: 10  loss: 0.34132215\n",
      "epoch: 35  batch: 11  loss: 0.32815772\n",
      "epoch: 35  batch: 12  loss: 0.18330795\n",
      "epoch: 35  batch: 13  loss: 0.18367268\n",
      "epoch: 35  batch: 14  loss: 0.16021816\n",
      "epoch: 35  batch: 15  loss: 0.16299257\n",
      "epoch: 35  batch: 16  loss: 0.15900342\n",
      "epoch: 35  batch: 17  loss: 0.28052330\n",
      "epoch: 35  batch: 18  loss: 0.12121928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35  batch: 19  loss: 0.11559682\n",
      "epoch: 35  batch: 20  loss: 0.29358134\n",
      "epoch: 35  batch: 21  loss: 0.35575962\n",
      "epoch: 35  batch: 22  loss: 0.07397801\n",
      "epoch: 35  batch: 23  loss: 0.07092743\n",
      "epoch: 35  batch: 24  loss: 0.07276905\n",
      "epoch: 35  batch: 25  loss: 0.09581505\n",
      "epoch: 35  batch: 26  loss: 0.31488118\n",
      "epoch: 35  batch: 27  loss: 0.66231871\n",
      "epoch: 35  batch: 28  loss: 0.31866008\n",
      "epoch: 35  batch: 29  loss: 0.27289850\n",
      "epoch: 35  batch: 30  loss: 0.19028041\n",
      "epoch: 35  batch: 31  loss: 0.06616038\n",
      "epoch: 35  batch: 32  loss: 0.02828376\n",
      "epoch: 35  batch: 33  loss: 0.06784026\n",
      "epoch: 35  batch: 34  loss: 0.10676818\n",
      "epoch: 35  batch: 35  loss: 0.23713697\n",
      "epoch: 35  batch: 36  loss: 0.05411850\n",
      "epoch: 35  batch: 37  loss: 0.09337313\n",
      "epoch: 35  batch: 38  loss: 0.06741320\n",
      "epoch: 35  batch: 39  loss: 0.25679365\n",
      "epoch: 35  batch: 40  loss: 0.12058335\n",
      "epoch: 35  batch: 41  loss: 0.31259367\n",
      "epoch: 35  batch: 42  loss: 0.17487349\n",
      "epoch: 35  batch: 43  loss: 0.26052150\n",
      "epoch: 35  batch: 44  loss: 0.28673533\n",
      "epoch: 35  batch: 45  loss: 0.26546395\n",
      "epoch: 35  batch: 46  loss: 0.20963055\n",
      "epoch: 35  batch: 47  loss: 0.21824163\n",
      "epoch: 35  batch: 48  loss: 0.15629007\n",
      "epoch: 35  batch: 49  loss: 0.13372524\n",
      "epoch: 35  batch: 50  loss: 0.21650293\n",
      "epoch: 35  batch: 51  loss: 0.18045616\n",
      "epoch: 35  batch: 52  loss: 0.09855962\n",
      "epoch: 35  batch: 53  loss: 0.10365039\n",
      "epoch: 35  batch: 54  loss: 0.36312199\n",
      "epoch: 35  batch: 55  loss: 0.23435475\n",
      "epoch: 35  batch: 56  loss: 0.08178211\n",
      "epoch: 35  batch: 57  loss: 0.06301678\n",
      "epoch: 35  batch: 58  loss: 0.14789198\n",
      "epoch: 35  batch: 59  loss: 0.10774162\n",
      "epoch: 35  batch: 60  loss: 0.40604788\n",
      "epoch: 35  batch: 61  loss: 0.84214139\n",
      "epoch: 35  batch: 62  loss: 0.16778299\n",
      "epoch: 35  batch: 63  loss: 0.39727250\n",
      "epoch: 35  batch: 64  loss: 0.17028791\n",
      "epoch: 35  batch: 65  loss: 0.09163095\n",
      "epoch: 35  batch: 66  loss: 0.03641087\n",
      "epoch: 35  batch: 67  loss: 0.07906603\n",
      "epoch: 35  batch: 68  loss: 0.16660200\n",
      "epoch: 36  batch: 1  loss: 0.24105398\n",
      "epoch: 36  batch: 2  loss: 0.04836377\n",
      "epoch: 36  batch: 3  loss: 0.05797521\n",
      "epoch: 36  batch: 4  loss: 0.07949523\n",
      "epoch: 36  batch: 5  loss: 0.21975161\n",
      "epoch: 36  batch: 6  loss: 0.16422531\n",
      "epoch: 36  batch: 7  loss: 0.35054198\n",
      "epoch: 36  batch: 8  loss: 0.10597860\n",
      "epoch: 36  batch: 9  loss: 0.30864215\n",
      "epoch: 36  batch: 10  loss: 0.35820600\n",
      "epoch: 36  batch: 11  loss: 0.41658571\n",
      "epoch: 36  batch: 12  loss: 0.19768268\n",
      "epoch: 36  batch: 13  loss: 0.24505961\n",
      "epoch: 36  batch: 14  loss: 0.24419653\n",
      "epoch: 36  batch: 15  loss: 0.14305642\n",
      "epoch: 36  batch: 16  loss: 0.17314023\n",
      "epoch: 36  batch: 17  loss: 0.31008977\n",
      "epoch: 36  batch: 18  loss: 0.16849516\n",
      "epoch: 36  batch: 19  loss: 0.18926528\n",
      "epoch: 36  batch: 20  loss: 0.31830493\n",
      "epoch: 36  batch: 21  loss: 0.37024131\n",
      "epoch: 36  batch: 22  loss: 0.08735778\n",
      "epoch: 36  batch: 23  loss: 0.07977103\n",
      "epoch: 36  batch: 24  loss: 0.20731573\n",
      "epoch: 36  batch: 25  loss: 0.07452850\n",
      "epoch: 36  batch: 26  loss: 0.28223622\n",
      "epoch: 36  batch: 27  loss: 0.70162380\n",
      "epoch: 36  batch: 28  loss: 0.28999776\n",
      "epoch: 36  batch: 29  loss: 0.26911139\n",
      "epoch: 36  batch: 30  loss: 0.18253887\n",
      "epoch: 36  batch: 31  loss: 0.05267417\n",
      "epoch: 36  batch: 32  loss: 0.05141345\n",
      "epoch: 36  batch: 33  loss: 0.12229771\n",
      "epoch: 36  batch: 34  loss: 0.11894974\n",
      "epoch: 36  batch: 35  loss: 0.27982229\n",
      "epoch: 36  batch: 36  loss: 0.09077967\n",
      "epoch: 36  batch: 37  loss: 0.06055893\n",
      "epoch: 36  batch: 38  loss: 0.05904065\n",
      "epoch: 36  batch: 39  loss: 0.26419201\n",
      "epoch: 36  batch: 40  loss: 0.11592884\n",
      "epoch: 36  batch: 41  loss: 0.29108077\n",
      "epoch: 36  batch: 42  loss: 0.25661620\n",
      "epoch: 36  batch: 43  loss: 0.23203844\n",
      "epoch: 36  batch: 44  loss: 0.47310859\n",
      "epoch: 36  batch: 45  loss: 0.38007075\n",
      "epoch: 36  batch: 46  loss: 0.20491214\n",
      "epoch: 36  batch: 47  loss: 0.19594155\n",
      "epoch: 36  batch: 48  loss: 0.15179452\n",
      "epoch: 36  batch: 49  loss: 0.15424646\n",
      "epoch: 36  batch: 50  loss: 0.19576187\n",
      "epoch: 36  batch: 51  loss: 0.12812622\n",
      "epoch: 36  batch: 52  loss: 0.08242442\n",
      "epoch: 36  batch: 53  loss: 0.15001363\n",
      "epoch: 36  batch: 54  loss: 0.37313029\n",
      "epoch: 36  batch: 55  loss: 0.23145977\n",
      "epoch: 36  batch: 56  loss: 0.08359797\n",
      "epoch: 36  batch: 57  loss: 0.05395234\n",
      "epoch: 36  batch: 58  loss: 0.10470207\n",
      "epoch: 36  batch: 59  loss: 0.11685999\n",
      "epoch: 36  batch: 60  loss: 0.43046349\n",
      "epoch: 36  batch: 61  loss: 0.90307695\n",
      "epoch: 36  batch: 62  loss: 0.21640007\n",
      "epoch: 36  batch: 63  loss: 0.39272276\n",
      "epoch: 36  batch: 64  loss: 0.14167583\n",
      "epoch: 36  batch: 65  loss: 0.04494001\n",
      "epoch: 36  batch: 66  loss: 0.03579310\n",
      "epoch: 36  batch: 67  loss: 0.06158020\n",
      "epoch: 36  batch: 68  loss: 0.17953700\n",
      "epoch: 37  batch: 1  loss: 0.26066250\n",
      "epoch: 37  batch: 2  loss: 0.13194905\n",
      "epoch: 37  batch: 3  loss: 0.04887927\n",
      "epoch: 37  batch: 4  loss: 0.06718654\n",
      "epoch: 37  batch: 5  loss: 0.19288874\n",
      "epoch: 37  batch: 6  loss: 0.16552010\n",
      "epoch: 37  batch: 7  loss: 0.29750735\n",
      "epoch: 37  batch: 8  loss: 0.16982077\n",
      "epoch: 37  batch: 9  loss: 0.28228319\n",
      "epoch: 37  batch: 10  loss: 0.29654080\n",
      "epoch: 37  batch: 11  loss: 0.32529962\n",
      "epoch: 37  batch: 12  loss: 0.21552220\n",
      "epoch: 37  batch: 13  loss: 0.22204272\n",
      "epoch: 37  batch: 14  loss: 0.16590351\n",
      "epoch: 37  batch: 15  loss: 0.16880861\n",
      "epoch: 37  batch: 16  loss: 0.16097189\n",
      "epoch: 37  batch: 17  loss: 0.33893803\n",
      "epoch: 37  batch: 18  loss: 0.09802531\n",
      "epoch: 37  batch: 19  loss: 0.12903671\n",
      "epoch: 37  batch: 20  loss: 0.26996887\n",
      "epoch: 37  batch: 21  loss: 0.35435757\n",
      "epoch: 37  batch: 22  loss: 0.06865618\n",
      "epoch: 37  batch: 23  loss: 0.06033824\n",
      "epoch: 37  batch: 24  loss: 0.06076524\n",
      "epoch: 37  batch: 25  loss: 0.12527150\n",
      "epoch: 37  batch: 26  loss: 0.35764974\n",
      "epoch: 37  batch: 27  loss: 0.70153701\n",
      "epoch: 37  batch: 28  loss: 0.36174080\n",
      "epoch: 37  batch: 29  loss: 0.30023751\n",
      "epoch: 37  batch: 30  loss: 0.22679073\n",
      "epoch: 37  batch: 31  loss: 0.04836558\n",
      "epoch: 37  batch: 32  loss: 0.03655670\n",
      "epoch: 37  batch: 33  loss: 0.07779621\n",
      "epoch: 37  batch: 34  loss: 0.12031836\n",
      "epoch: 37  batch: 35  loss: 0.24276510\n",
      "epoch: 37  batch: 36  loss: 0.08748021\n",
      "epoch: 37  batch: 37  loss: 0.07872403\n",
      "epoch: 37  batch: 38  loss: 0.08101650\n",
      "epoch: 37  batch: 39  loss: 0.26585123\n",
      "epoch: 37  batch: 40  loss: 0.09548807\n",
      "epoch: 37  batch: 41  loss: 0.30201721\n",
      "epoch: 37  batch: 42  loss: 0.19040537\n",
      "epoch: 37  batch: 43  loss: 0.21284252\n",
      "epoch: 37  batch: 44  loss: 0.36482355\n",
      "epoch: 37  batch: 45  loss: 0.29091167\n",
      "epoch: 37  batch: 46  loss: 0.22307871\n",
      "epoch: 37  batch: 47  loss: 0.27346402\n",
      "epoch: 37  batch: 48  loss: 0.15786129\n",
      "epoch: 37  batch: 49  loss: 0.15865664\n",
      "epoch: 37  batch: 50  loss: 0.27470055\n",
      "epoch: 37  batch: 51  loss: 0.24776170\n",
      "epoch: 37  batch: 52  loss: 0.08199730\n",
      "epoch: 37  batch: 53  loss: 0.15089175\n",
      "epoch: 37  batch: 54  loss: 0.33974668\n",
      "epoch: 37  batch: 55  loss: 0.24834552\n",
      "epoch: 37  batch: 56  loss: 0.08131059\n",
      "epoch: 37  batch: 57  loss: 0.08725422\n",
      "epoch: 37  batch: 58  loss: 0.13609554\n",
      "epoch: 37  batch: 59  loss: 0.12364919\n",
      "epoch: 37  batch: 60  loss: 0.39446837\n",
      "epoch: 37  batch: 61  loss: 0.90385592\n",
      "epoch: 37  batch: 62  loss: 0.25527292\n",
      "epoch: 37  batch: 63  loss: 0.45878789\n",
      "epoch: 37  batch: 64  loss: 0.19228227\n",
      "epoch: 37  batch: 65  loss: 0.05068000\n",
      "epoch: 37  batch: 66  loss: 0.03871472\n",
      "epoch: 37  batch: 67  loss: 0.07530552\n",
      "epoch: 37  batch: 68  loss: 0.13382648\n",
      "epoch: 38  batch: 1  loss: 0.25076994\n",
      "epoch: 38  batch: 2  loss: 0.07382195\n",
      "epoch: 38  batch: 3  loss: 0.09323034\n",
      "epoch: 38  batch: 4  loss: 0.13426611\n",
      "epoch: 38  batch: 5  loss: 0.28034645\n",
      "epoch: 38  batch: 6  loss: 0.15733247\n",
      "epoch: 38  batch: 7  loss: 0.33880556\n",
      "epoch: 38  batch: 8  loss: 0.18040763\n",
      "epoch: 38  batch: 9  loss: 0.19896080\n",
      "epoch: 38  batch: 10  loss: 0.31114355\n",
      "epoch: 38  batch: 11  loss: 0.36310893\n",
      "epoch: 38  batch: 12  loss: 0.21899407\n",
      "epoch: 38  batch: 13  loss: 0.29431257\n",
      "epoch: 38  batch: 14  loss: 0.55693626\n",
      "epoch: 38  batch: 15  loss: 0.19220056\n",
      "epoch: 38  batch: 16  loss: 0.17259219\n",
      "epoch: 38  batch: 17  loss: 0.34485957\n",
      "epoch: 38  batch: 18  loss: 0.10793065\n",
      "epoch: 38  batch: 19  loss: 0.11670193\n",
      "epoch: 38  batch: 20  loss: 0.31844211\n",
      "epoch: 38  batch: 21  loss: 0.40587863\n",
      "epoch: 38  batch: 22  loss: 0.09247338\n",
      "epoch: 38  batch: 23  loss: 0.06954072\n",
      "epoch: 38  batch: 24  loss: 0.07915055\n",
      "epoch: 38  batch: 25  loss: 0.07360530\n",
      "epoch: 38  batch: 26  loss: 0.28711060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38  batch: 27  loss: 0.66551119\n",
      "epoch: 38  batch: 28  loss: 0.33840802\n",
      "epoch: 38  batch: 29  loss: 0.24358538\n",
      "epoch: 38  batch: 30  loss: 0.15927316\n",
      "epoch: 38  batch: 31  loss: 0.08102530\n",
      "epoch: 38  batch: 32  loss: 0.04729318\n",
      "epoch: 38  batch: 33  loss: 0.07590102\n",
      "epoch: 38  batch: 34  loss: 0.14237644\n",
      "epoch: 38  batch: 35  loss: 0.27232996\n",
      "epoch: 38  batch: 36  loss: 0.08059932\n",
      "epoch: 38  batch: 37  loss: 0.09966983\n",
      "epoch: 38  batch: 38  loss: 0.08386330\n",
      "epoch: 38  batch: 39  loss: 0.32484153\n",
      "epoch: 38  batch: 40  loss: 0.14961763\n",
      "epoch: 38  batch: 41  loss: 0.29597896\n",
      "epoch: 38  batch: 42  loss: 0.23164970\n",
      "epoch: 38  batch: 43  loss: 0.31277949\n",
      "epoch: 38  batch: 44  loss: 0.33053556\n",
      "epoch: 38  batch: 45  loss: 0.38515350\n",
      "epoch: 38  batch: 46  loss: 0.25550663\n",
      "epoch: 38  batch: 47  loss: 0.25308374\n",
      "epoch: 38  batch: 48  loss: 0.21156265\n",
      "epoch: 38  batch: 49  loss: 0.19702755\n",
      "epoch: 38  batch: 50  loss: 0.31147453\n",
      "epoch: 38  batch: 51  loss: 0.25709823\n",
      "epoch: 38  batch: 52  loss: 0.10523077\n",
      "epoch: 38  batch: 53  loss: 0.17013448\n",
      "epoch: 38  batch: 54  loss: 0.39828497\n",
      "epoch: 38  batch: 55  loss: 0.25772151\n",
      "epoch: 38  batch: 56  loss: 0.09795077\n",
      "epoch: 38  batch: 57  loss: 0.07272599\n",
      "epoch: 38  batch: 58  loss: 0.08596402\n",
      "epoch: 38  batch: 59  loss: 0.11553229\n",
      "epoch: 38  batch: 60  loss: 0.38488173\n",
      "epoch: 38  batch: 61  loss: 0.86504036\n",
      "epoch: 38  batch: 62  loss: 0.23347282\n",
      "epoch: 38  batch: 63  loss: 0.33797985\n",
      "epoch: 38  batch: 64  loss: 0.17919478\n",
      "epoch: 38  batch: 65  loss: 0.08700339\n",
      "epoch: 38  batch: 66  loss: 0.06113599\n",
      "epoch: 38  batch: 67  loss: 0.10180784\n",
      "epoch: 38  batch: 68  loss: 0.15956585\n",
      "epoch: 39  batch: 1  loss: 0.23025005\n",
      "epoch: 39  batch: 2  loss: 0.07719550\n",
      "epoch: 39  batch: 3  loss: 0.04196462\n",
      "epoch: 39  batch: 4  loss: 0.06070829\n",
      "epoch: 39  batch: 5  loss: 0.18741706\n",
      "epoch: 39  batch: 6  loss: 0.11799559\n",
      "epoch: 39  batch: 7  loss: 0.30472112\n",
      "epoch: 39  batch: 8  loss: 0.16150162\n",
      "epoch: 39  batch: 9  loss: 0.29993603\n",
      "epoch: 39  batch: 10  loss: 0.30663395\n",
      "epoch: 39  batch: 11  loss: 0.40300679\n",
      "epoch: 39  batch: 12  loss: 0.21752211\n",
      "epoch: 39  batch: 13  loss: 0.29002884\n",
      "epoch: 39  batch: 14  loss: 0.20330901\n",
      "epoch: 39  batch: 15  loss: 0.16420679\n",
      "epoch: 39  batch: 16  loss: 0.16842058\n",
      "epoch: 39  batch: 17  loss: 0.31020200\n",
      "epoch: 39  batch: 18  loss: 0.23004462\n",
      "epoch: 39  batch: 19  loss: 0.23516853\n",
      "epoch: 39  batch: 20  loss: 0.31740871\n",
      "epoch: 39  batch: 21  loss: 0.35982150\n",
      "epoch: 39  batch: 22  loss: 0.07412807\n",
      "epoch: 39  batch: 23  loss: 0.06041662\n",
      "epoch: 39  batch: 24  loss: 0.07275033\n",
      "epoch: 39  batch: 25  loss: 0.10465529\n",
      "epoch: 39  batch: 26  loss: 0.30748305\n",
      "epoch: 39  batch: 27  loss: 0.66355658\n",
      "epoch: 39  batch: 28  loss: 0.29315361\n",
      "epoch: 39  batch: 29  loss: 0.23698273\n",
      "epoch: 39  batch: 30  loss: 0.14685427\n",
      "epoch: 39  batch: 31  loss: 0.06468679\n",
      "epoch: 39  batch: 32  loss: 0.04664391\n",
      "epoch: 39  batch: 33  loss: 0.11469295\n",
      "epoch: 39  batch: 34  loss: 0.11624313\n",
      "epoch: 39  batch: 35  loss: 0.22510245\n",
      "epoch: 39  batch: 36  loss: 0.08218971\n",
      "epoch: 39  batch: 37  loss: 0.10950638\n",
      "epoch: 39  batch: 38  loss: 0.10309141\n",
      "epoch: 39  batch: 39  loss: 0.32393071\n",
      "epoch: 39  batch: 40  loss: 0.12601966\n",
      "epoch: 39  batch: 41  loss: 0.23800516\n",
      "epoch: 39  batch: 42  loss: 0.19364277\n",
      "epoch: 39  batch: 43  loss: 0.23536129\n",
      "epoch: 39  batch: 44  loss: 0.27322102\n",
      "epoch: 39  batch: 45  loss: 0.49028853\n",
      "epoch: 39  batch: 46  loss: 0.22140528\n",
      "epoch: 39  batch: 47  loss: 0.21498579\n",
      "epoch: 39  batch: 48  loss: 0.18026641\n",
      "epoch: 39  batch: 49  loss: 0.15159629\n",
      "epoch: 39  batch: 50  loss: 0.25776559\n",
      "epoch: 39  batch: 51  loss: 0.16608347\n",
      "epoch: 39  batch: 52  loss: 0.08261380\n",
      "epoch: 39  batch: 53  loss: 0.12869665\n",
      "epoch: 39  batch: 54  loss: 0.37506154\n",
      "epoch: 39  batch: 55  loss: 0.24498320\n",
      "epoch: 39  batch: 56  loss: 0.08666771\n",
      "epoch: 39  batch: 57  loss: 0.07218075\n",
      "epoch: 39  batch: 58  loss: 0.11776831\n",
      "epoch: 39  batch: 59  loss: 0.12355462\n",
      "epoch: 39  batch: 60  loss: 0.33982417\n",
      "epoch: 39  batch: 61  loss: 0.80987740\n",
      "epoch: 39  batch: 62  loss: 0.28785762\n",
      "epoch: 39  batch: 63  loss: 0.31483203\n",
      "epoch: 39  batch: 64  loss: 0.21429910\n",
      "epoch: 39  batch: 65  loss: 0.06487077\n",
      "epoch: 39  batch: 66  loss: 0.03645296\n",
      "epoch: 39  batch: 67  loss: 0.05964828\n",
      "epoch: 39  batch: 68  loss: 0.12139258\n",
      "epoch: 40  batch: 1  loss: 0.21833806\n",
      "epoch: 40  batch: 2  loss: 0.06458630\n",
      "epoch: 40  batch: 3  loss: 0.03793391\n",
      "epoch: 40  batch: 4  loss: 0.04364462\n",
      "epoch: 40  batch: 5  loss: 0.15774350\n",
      "epoch: 40  batch: 6  loss: 0.18501964\n",
      "epoch: 40  batch: 7  loss: 0.27507803\n",
      "epoch: 40  batch: 8  loss: 0.19625315\n",
      "epoch: 40  batch: 9  loss: 0.32907501\n",
      "epoch: 40  batch: 10  loss: 0.42215425\n",
      "epoch: 40  batch: 11  loss: 0.40638047\n",
      "epoch: 40  batch: 12  loss: 0.24494766\n",
      "epoch: 40  batch: 13  loss: 0.12839535\n",
      "epoch: 40  batch: 14  loss: 0.15260255\n",
      "epoch: 40  batch: 15  loss: 0.14552146\n",
      "epoch: 40  batch: 16  loss: 0.07691385\n",
      "epoch: 40  batch: 17  loss: 0.21493308\n",
      "epoch: 40  batch: 18  loss: 0.05765510\n",
      "epoch: 40  batch: 19  loss: 0.04294283\n",
      "epoch: 40  batch: 20  loss: 0.30536678\n",
      "epoch: 40  batch: 21  loss: 0.36922118\n",
      "epoch: 40  batch: 22  loss: 0.10341886\n",
      "epoch: 40  batch: 23  loss: 0.05799415\n",
      "epoch: 40  batch: 24  loss: 0.07354582\n",
      "epoch: 40  batch: 25  loss: 0.12085526\n",
      "epoch: 40  batch: 26  loss: 0.20532678\n",
      "epoch: 40  batch: 27  loss: 0.46713111\n",
      "epoch: 40  batch: 28  loss: 0.25525433\n",
      "epoch: 40  batch: 29  loss: 0.16096015\n",
      "epoch: 40  batch: 30  loss: 0.10638072\n",
      "epoch: 40  batch: 31  loss: 0.07027531\n",
      "epoch: 40  batch: 32  loss: 0.02745446\n",
      "epoch: 40  batch: 33  loss: 0.10118479\n",
      "epoch: 40  batch: 34  loss: 0.09195516\n",
      "epoch: 40  batch: 35  loss: 0.18864913\n",
      "epoch: 40  batch: 36  loss: 0.03573773\n",
      "epoch: 40  batch: 37  loss: 0.02681234\n",
      "epoch: 40  batch: 38  loss: 0.07846069\n",
      "epoch: 40  batch: 39  loss: 0.19724093\n",
      "epoch: 40  batch: 40  loss: 0.11837258\n",
      "epoch: 40  batch: 41  loss: 0.23891261\n",
      "epoch: 40  batch: 42  loss: 0.17760214\n",
      "epoch: 40  batch: 43  loss: 0.21772207\n",
      "epoch: 40  batch: 44  loss: 0.36780784\n",
      "epoch: 40  batch: 45  loss: 0.46880326\n",
      "epoch: 40  batch: 46  loss: 0.20627557\n",
      "epoch: 40  batch: 47  loss: 0.17563117\n",
      "epoch: 40  batch: 48  loss: 0.12784484\n",
      "epoch: 40  batch: 49  loss: 0.14665888\n",
      "epoch: 40  batch: 50  loss: 0.13788736\n",
      "epoch: 40  batch: 51  loss: 0.12667033\n",
      "epoch: 40  batch: 52  loss: 0.05769006\n",
      "epoch: 40  batch: 53  loss: 0.06141496\n",
      "epoch: 40  batch: 54  loss: 0.39220878\n",
      "epoch: 40  batch: 55  loss: 0.25143826\n",
      "epoch: 40  batch: 56  loss: 0.08485509\n",
      "epoch: 40  batch: 57  loss: 0.04015516\n",
      "epoch: 40  batch: 58  loss: 0.15528592\n",
      "epoch: 40  batch: 59  loss: 0.10074997\n",
      "epoch: 40  batch: 60  loss: 0.28986397\n",
      "epoch: 40  batch: 61  loss: 0.52655971\n",
      "epoch: 40  batch: 62  loss: 0.18889610\n",
      "epoch: 40  batch: 63  loss: 0.20895886\n",
      "epoch: 40  batch: 64  loss: 0.15310085\n",
      "epoch: 40  batch: 65  loss: 0.05657953\n",
      "epoch: 40  batch: 66  loss: 0.03189956\n",
      "epoch: 40  batch: 67  loss: 0.04434805\n",
      "epoch: 40  batch: 68  loss: 0.09540664\n",
      "epoch: 41  batch: 1  loss: 0.18661924\n",
      "epoch: 41  batch: 2  loss: 0.04560666\n",
      "epoch: 41  batch: 3  loss: 0.03110596\n",
      "epoch: 41  batch: 4  loss: 0.03109649\n",
      "epoch: 41  batch: 5  loss: 0.13006608\n",
      "epoch: 41  batch: 6  loss: 0.12574792\n",
      "epoch: 41  batch: 7  loss: 0.24801649\n",
      "epoch: 41  batch: 8  loss: 0.14709370\n",
      "epoch: 41  batch: 9  loss: 0.26533258\n",
      "epoch: 41  batch: 10  loss: 0.36248928\n",
      "epoch: 41  batch: 11  loss: 0.34506115\n",
      "epoch: 41  batch: 12  loss: 0.22190268\n",
      "epoch: 41  batch: 13  loss: 0.15225342\n",
      "epoch: 41  batch: 14  loss: 0.15582851\n",
      "epoch: 41  batch: 15  loss: 0.13966653\n",
      "epoch: 41  batch: 16  loss: 0.08877914\n",
      "epoch: 41  batch: 17  loss: 0.22253446\n",
      "epoch: 41  batch: 18  loss: 0.06017293\n",
      "epoch: 41  batch: 19  loss: 0.04376264\n",
      "epoch: 41  batch: 20  loss: 0.28879464\n",
      "epoch: 41  batch: 21  loss: 0.35673261\n",
      "epoch: 41  batch: 22  loss: 0.08736233\n",
      "epoch: 41  batch: 23  loss: 0.06151797\n",
      "epoch: 41  batch: 24  loss: 0.06355341\n",
      "epoch: 41  batch: 25  loss: 0.10324860\n",
      "epoch: 41  batch: 26  loss: 0.19711979\n",
      "epoch: 41  batch: 27  loss: 0.52131987\n",
      "epoch: 41  batch: 28  loss: 0.25282082\n",
      "epoch: 41  batch: 29  loss: 0.18497251\n",
      "epoch: 41  batch: 30  loss: 0.12751308\n",
      "epoch: 41  batch: 31  loss: 0.07597105\n",
      "epoch: 41  batch: 32  loss: 0.02418616\n",
      "epoch: 41  batch: 33  loss: 0.07627682\n",
      "epoch: 41  batch: 34  loss: 0.08725672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41  batch: 35  loss: 0.17322123\n",
      "epoch: 41  batch: 36  loss: 0.03213803\n",
      "epoch: 41  batch: 37  loss: 0.02668798\n",
      "epoch: 41  batch: 38  loss: 0.06161433\n",
      "epoch: 41  batch: 39  loss: 0.18069153\n",
      "epoch: 41  batch: 40  loss: 0.10292138\n",
      "epoch: 41  batch: 41  loss: 0.22202289\n",
      "epoch: 41  batch: 42  loss: 0.15355748\n",
      "epoch: 41  batch: 43  loss: 0.19476654\n",
      "epoch: 41  batch: 44  loss: 0.31946036\n",
      "epoch: 41  batch: 45  loss: 0.41516411\n",
      "epoch: 41  batch: 46  loss: 0.21340324\n",
      "epoch: 41  batch: 47  loss: 0.18493034\n",
      "epoch: 41  batch: 48  loss: 0.13145781\n",
      "epoch: 41  batch: 49  loss: 0.13051149\n",
      "epoch: 41  batch: 50  loss: 0.15152986\n",
      "epoch: 41  batch: 51  loss: 0.13485828\n",
      "epoch: 41  batch: 52  loss: 0.05897051\n",
      "epoch: 41  batch: 53  loss: 0.06080020\n",
      "epoch: 41  batch: 54  loss: 0.38082519\n",
      "epoch: 41  batch: 55  loss: 0.24565913\n",
      "epoch: 41  batch: 56  loss: 0.08255657\n",
      "epoch: 41  batch: 57  loss: 0.04377205\n",
      "epoch: 41  batch: 58  loss: 0.14357087\n",
      "epoch: 41  batch: 59  loss: 0.09658942\n",
      "epoch: 41  batch: 60  loss: 0.29940200\n",
      "epoch: 41  batch: 61  loss: 0.55318445\n",
      "epoch: 41  batch: 62  loss: 0.19513220\n",
      "epoch: 41  batch: 63  loss: 0.23669367\n",
      "epoch: 41  batch: 64  loss: 0.15566041\n",
      "epoch: 41  batch: 65  loss: 0.06057322\n",
      "epoch: 41  batch: 66  loss: 0.02870491\n",
      "epoch: 41  batch: 67  loss: 0.04105280\n",
      "epoch: 41  batch: 68  loss: 0.08779842\n",
      "epoch: 42  batch: 1  loss: 0.17872700\n",
      "epoch: 42  batch: 2  loss: 0.04499874\n",
      "epoch: 42  batch: 3  loss: 0.03083159\n",
      "epoch: 42  batch: 4  loss: 0.02891616\n",
      "epoch: 42  batch: 5  loss: 0.12297577\n",
      "epoch: 42  batch: 6  loss: 0.10429018\n",
      "epoch: 42  batch: 7  loss: 0.23624247\n",
      "epoch: 42  batch: 8  loss: 0.13567483\n",
      "epoch: 42  batch: 9  loss: 0.24992153\n",
      "epoch: 42  batch: 10  loss: 0.32830548\n",
      "epoch: 42  batch: 11  loss: 0.30759305\n",
      "epoch: 42  batch: 12  loss: 0.21523227\n",
      "epoch: 42  batch: 13  loss: 0.15808003\n",
      "epoch: 42  batch: 14  loss: 0.15841417\n",
      "epoch: 42  batch: 15  loss: 0.13819422\n",
      "epoch: 42  batch: 16  loss: 0.09118549\n",
      "epoch: 42  batch: 17  loss: 0.22536452\n",
      "epoch: 42  batch: 18  loss: 0.06194055\n",
      "epoch: 42  batch: 19  loss: 0.04639611\n",
      "epoch: 42  batch: 20  loss: 0.28685227\n",
      "epoch: 42  batch: 21  loss: 0.35411745\n",
      "epoch: 42  batch: 22  loss: 0.09113391\n",
      "epoch: 42  batch: 23  loss: 0.05651771\n",
      "epoch: 42  batch: 24  loss: 0.06091804\n",
      "epoch: 42  batch: 25  loss: 0.08441190\n",
      "epoch: 42  batch: 26  loss: 0.22450662\n",
      "epoch: 42  batch: 27  loss: 0.53229815\n",
      "epoch: 42  batch: 28  loss: 0.23881751\n",
      "epoch: 42  batch: 29  loss: 0.18256599\n",
      "epoch: 42  batch: 30  loss: 0.12660185\n",
      "epoch: 42  batch: 31  loss: 0.07927524\n",
      "epoch: 42  batch: 32  loss: 0.02096197\n",
      "epoch: 42  batch: 33  loss: 0.07124242\n",
      "epoch: 42  batch: 34  loss: 0.08601843\n",
      "epoch: 42  batch: 35  loss: 0.17144579\n",
      "epoch: 42  batch: 36  loss: 0.03280318\n",
      "epoch: 42  batch: 37  loss: 0.02704270\n",
      "epoch: 42  batch: 38  loss: 0.05315336\n",
      "epoch: 42  batch: 39  loss: 0.17871240\n",
      "epoch: 42  batch: 40  loss: 0.09112996\n",
      "epoch: 42  batch: 41  loss: 0.21726806\n",
      "epoch: 42  batch: 42  loss: 0.14720368\n",
      "epoch: 42  batch: 43  loss: 0.18687211\n",
      "epoch: 42  batch: 44  loss: 0.29262763\n",
      "epoch: 42  batch: 45  loss: 0.40823972\n",
      "epoch: 42  batch: 46  loss: 0.21225533\n",
      "epoch: 42  batch: 47  loss: 0.20449184\n",
      "epoch: 42  batch: 48  loss: 0.13237758\n",
      "epoch: 42  batch: 49  loss: 0.13035969\n",
      "epoch: 42  batch: 50  loss: 0.16508615\n",
      "epoch: 42  batch: 51  loss: 0.13754484\n",
      "epoch: 42  batch: 52  loss: 0.05949321\n",
      "epoch: 42  batch: 53  loss: 0.06480831\n",
      "epoch: 42  batch: 54  loss: 0.37994596\n",
      "epoch: 42  batch: 55  loss: 0.24562213\n",
      "epoch: 42  batch: 56  loss: 0.08256587\n",
      "epoch: 42  batch: 57  loss: 0.04706182\n",
      "epoch: 42  batch: 58  loss: 0.13627397\n",
      "epoch: 42  batch: 59  loss: 0.09402841\n",
      "epoch: 42  batch: 60  loss: 0.29198396\n",
      "epoch: 42  batch: 61  loss: 0.56268823\n",
      "epoch: 42  batch: 62  loss: 0.18923272\n",
      "epoch: 42  batch: 63  loss: 0.22515789\n",
      "epoch: 42  batch: 64  loss: 0.16768624\n",
      "epoch: 42  batch: 65  loss: 0.06341412\n",
      "epoch: 42  batch: 66  loss: 0.02876114\n",
      "epoch: 42  batch: 67  loss: 0.03828640\n",
      "epoch: 42  batch: 68  loss: 0.08636939\n",
      "epoch: 43  batch: 1  loss: 0.17855307\n",
      "epoch: 43  batch: 2  loss: 0.04502216\n",
      "epoch: 43  batch: 3  loss: 0.03049788\n",
      "epoch: 43  batch: 4  loss: 0.02825405\n",
      "epoch: 43  batch: 5  loss: 0.12124183\n",
      "epoch: 43  batch: 6  loss: 0.12609756\n",
      "epoch: 43  batch: 7  loss: 0.22673918\n",
      "epoch: 43  batch: 8  loss: 0.13716516\n",
      "epoch: 43  batch: 9  loss: 0.25655842\n",
      "epoch: 43  batch: 10  loss: 0.32538557\n",
      "epoch: 43  batch: 11  loss: 0.30380061\n",
      "epoch: 43  batch: 12  loss: 0.20444001\n",
      "epoch: 43  batch: 13  loss: 0.15533556\n",
      "epoch: 43  batch: 14  loss: 0.15867659\n",
      "epoch: 43  batch: 15  loss: 0.13477956\n",
      "epoch: 43  batch: 16  loss: 0.09304578\n",
      "epoch: 43  batch: 17  loss: 0.22389472\n",
      "epoch: 43  batch: 18  loss: 0.06146964\n",
      "epoch: 43  batch: 19  loss: 0.04432975\n",
      "epoch: 43  batch: 20  loss: 0.28444031\n",
      "epoch: 43  batch: 21  loss: 0.35258850\n",
      "epoch: 43  batch: 22  loss: 0.08631763\n",
      "epoch: 43  batch: 23  loss: 0.05356682\n",
      "epoch: 43  batch: 24  loss: 0.06017238\n",
      "epoch: 43  batch: 25  loss: 0.08113743\n",
      "epoch: 43  batch: 26  loss: 0.22201101\n",
      "epoch: 43  batch: 27  loss: 0.53640324\n",
      "epoch: 43  batch: 28  loss: 0.23585998\n",
      "epoch: 43  batch: 29  loss: 0.17829281\n",
      "epoch: 43  batch: 30  loss: 0.12760291\n",
      "epoch: 43  batch: 31  loss: 0.08014414\n",
      "epoch: 43  batch: 32  loss: 0.01860871\n",
      "epoch: 43  batch: 33  loss: 0.06755659\n",
      "epoch: 43  batch: 34  loss: 0.08564645\n",
      "epoch: 43  batch: 35  loss: 0.17045289\n",
      "epoch: 43  batch: 36  loss: 0.03315537\n",
      "epoch: 43  batch: 37  loss: 0.02788592\n",
      "epoch: 43  batch: 38  loss: 0.05127775\n",
      "epoch: 43  batch: 39  loss: 0.17776798\n",
      "epoch: 43  batch: 40  loss: 0.09103845\n",
      "epoch: 43  batch: 41  loss: 0.21423455\n",
      "epoch: 43  batch: 42  loss: 0.14175740\n",
      "epoch: 43  batch: 43  loss: 0.18401960\n",
      "epoch: 43  batch: 44  loss: 0.28510427\n",
      "epoch: 43  batch: 45  loss: 0.40213659\n",
      "epoch: 43  batch: 46  loss: 0.21163717\n",
      "epoch: 43  batch: 47  loss: 0.20137061\n",
      "epoch: 43  batch: 48  loss: 0.13249236\n",
      "epoch: 43  batch: 49  loss: 0.12801006\n",
      "epoch: 43  batch: 50  loss: 0.16484620\n",
      "epoch: 43  batch: 51  loss: 0.14149144\n",
      "epoch: 43  batch: 52  loss: 0.06030804\n",
      "epoch: 43  batch: 53  loss: 0.06327152\n",
      "epoch: 43  batch: 54  loss: 0.37777093\n",
      "epoch: 43  batch: 55  loss: 0.24410240\n",
      "epoch: 43  batch: 56  loss: 0.08277433\n",
      "epoch: 43  batch: 57  loss: 0.04718644\n",
      "epoch: 43  batch: 58  loss: 0.13480844\n",
      "epoch: 43  batch: 59  loss: 0.09173743\n",
      "epoch: 43  batch: 60  loss: 0.30541304\n",
      "epoch: 43  batch: 61  loss: 0.56369585\n",
      "epoch: 43  batch: 62  loss: 0.18889053\n",
      "epoch: 43  batch: 63  loss: 0.22999892\n",
      "epoch: 43  batch: 64  loss: 0.15868908\n",
      "epoch: 43  batch: 65  loss: 0.06155949\n",
      "epoch: 43  batch: 66  loss: 0.02913127\n",
      "epoch: 43  batch: 67  loss: 0.03765852\n",
      "epoch: 43  batch: 68  loss: 0.08534028\n",
      "epoch: 44  batch: 1  loss: 0.17598842\n",
      "epoch: 44  batch: 2  loss: 0.04537824\n",
      "epoch: 44  batch: 3  loss: 0.03021380\n",
      "epoch: 44  batch: 4  loss: 0.02799656\n",
      "epoch: 44  batch: 5  loss: 0.12034082\n",
      "epoch: 44  batch: 6  loss: 0.13000998\n",
      "epoch: 44  batch: 7  loss: 0.22900952\n",
      "epoch: 44  batch: 8  loss: 0.13752154\n",
      "epoch: 44  batch: 9  loss: 0.24313377\n",
      "epoch: 44  batch: 10  loss: 0.32076547\n",
      "epoch: 44  batch: 11  loss: 0.28507712\n",
      "epoch: 44  batch: 12  loss: 0.20182478\n",
      "epoch: 44  batch: 13  loss: 0.15392703\n",
      "epoch: 44  batch: 14  loss: 0.15586655\n",
      "epoch: 44  batch: 15  loss: 0.13453951\n",
      "epoch: 44  batch: 16  loss: 0.09374405\n",
      "epoch: 44  batch: 17  loss: 0.22115912\n",
      "epoch: 44  batch: 18  loss: 0.06488921\n",
      "epoch: 44  batch: 19  loss: 0.04543937\n",
      "epoch: 44  batch: 20  loss: 0.28450248\n",
      "epoch: 44  batch: 21  loss: 0.35079220\n",
      "epoch: 44  batch: 22  loss: 0.08821576\n",
      "epoch: 44  batch: 23  loss: 0.05277927\n",
      "epoch: 44  batch: 24  loss: 0.05885056\n",
      "epoch: 44  batch: 25  loss: 0.08312376\n",
      "epoch: 44  batch: 26  loss: 0.23379526\n",
      "epoch: 44  batch: 27  loss: 0.52786690\n",
      "epoch: 44  batch: 28  loss: 0.23583163\n",
      "epoch: 44  batch: 29  loss: 0.20322005\n",
      "epoch: 44  batch: 30  loss: 0.14895849\n",
      "epoch: 44  batch: 31  loss: 0.07880071\n",
      "epoch: 44  batch: 32  loss: 0.01929478\n",
      "epoch: 44  batch: 33  loss: 0.06357880\n",
      "epoch: 44  batch: 34  loss: 0.08448555\n",
      "epoch: 44  batch: 35  loss: 0.16937444\n",
      "epoch: 44  batch: 36  loss: 0.03366721\n",
      "epoch: 44  batch: 37  loss: 0.02857923\n",
      "epoch: 44  batch: 38  loss: 0.04740576\n",
      "epoch: 44  batch: 39  loss: 0.17474939\n",
      "epoch: 44  batch: 40  loss: 0.10164320\n",
      "epoch: 44  batch: 41  loss: 0.20594455\n",
      "epoch: 44  batch: 42  loss: 0.15426037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44  batch: 43  loss: 0.17742023\n",
      "epoch: 44  batch: 44  loss: 0.25888801\n",
      "epoch: 44  batch: 45  loss: 0.40159565\n",
      "epoch: 44  batch: 46  loss: 0.21236482\n",
      "epoch: 44  batch: 47  loss: 0.17921533\n",
      "epoch: 44  batch: 48  loss: 0.13255896\n",
      "epoch: 44  batch: 49  loss: 0.13665296\n",
      "epoch: 44  batch: 50  loss: 0.16383551\n",
      "epoch: 44  batch: 51  loss: 0.13139966\n",
      "epoch: 44  batch: 52  loss: 0.06305641\n",
      "epoch: 44  batch: 53  loss: 0.06476449\n",
      "epoch: 44  batch: 54  loss: 0.37709472\n",
      "epoch: 44  batch: 55  loss: 0.24410619\n",
      "epoch: 44  batch: 56  loss: 0.08477236\n",
      "epoch: 44  batch: 57  loss: 0.04827214\n",
      "epoch: 44  batch: 58  loss: 0.12783754\n",
      "epoch: 44  batch: 59  loss: 0.10241791\n",
      "epoch: 44  batch: 60  loss: 0.30277309\n",
      "epoch: 44  batch: 61  loss: 0.56673729\n",
      "epoch: 44  batch: 62  loss: 0.19322722\n",
      "epoch: 44  batch: 63  loss: 0.24511355\n",
      "epoch: 44  batch: 64  loss: 0.17404544\n",
      "epoch: 44  batch: 65  loss: 0.05979588\n",
      "epoch: 44  batch: 66  loss: 0.02996559\n",
      "epoch: 44  batch: 67  loss: 0.04035788\n",
      "epoch: 44  batch: 68  loss: 0.08572609\n",
      "epoch: 45  batch: 1  loss: 0.17884083\n",
      "epoch: 45  batch: 2  loss: 0.04387559\n",
      "epoch: 45  batch: 3  loss: 0.03001759\n",
      "epoch: 45  batch: 4  loss: 0.02807035\n",
      "epoch: 45  batch: 5  loss: 0.11962549\n",
      "epoch: 45  batch: 6  loss: 0.12301002\n",
      "epoch: 45  batch: 7  loss: 0.22083576\n",
      "epoch: 45  batch: 8  loss: 0.13226156\n",
      "epoch: 45  batch: 9  loss: 0.26127595\n",
      "epoch: 45  batch: 10  loss: 0.31270796\n",
      "epoch: 45  batch: 11  loss: 0.28448194\n",
      "epoch: 45  batch: 12  loss: 0.19938010\n",
      "epoch: 45  batch: 13  loss: 0.15581094\n",
      "epoch: 45  batch: 14  loss: 0.15447612\n",
      "epoch: 45  batch: 15  loss: 0.12943071\n",
      "epoch: 45  batch: 16  loss: 0.09350213\n",
      "epoch: 45  batch: 17  loss: 0.20979445\n",
      "epoch: 45  batch: 18  loss: 0.06402140\n",
      "epoch: 45  batch: 19  loss: 0.04680452\n",
      "epoch: 45  batch: 20  loss: 0.28282288\n",
      "epoch: 45  batch: 21  loss: 0.35039082\n",
      "epoch: 45  batch: 22  loss: 0.08792864\n",
      "epoch: 45  batch: 23  loss: 0.05412823\n",
      "epoch: 45  batch: 24  loss: 0.05696834\n",
      "epoch: 45  batch: 25  loss: 0.08899857\n",
      "epoch: 45  batch: 26  loss: 0.21119331\n",
      "epoch: 45  batch: 27  loss: 0.51755053\n",
      "epoch: 45  batch: 28  loss: 0.20304324\n",
      "epoch: 45  batch: 29  loss: 0.19342476\n",
      "epoch: 45  batch: 30  loss: 0.11836603\n",
      "epoch: 45  batch: 31  loss: 0.07450164\n",
      "epoch: 45  batch: 32  loss: 0.01779910\n",
      "epoch: 45  batch: 33  loss: 0.06092315\n",
      "epoch: 45  batch: 34  loss: 0.08559254\n",
      "epoch: 45  batch: 35  loss: 0.16906536\n",
      "epoch: 45  batch: 36  loss: 0.03389372\n",
      "epoch: 45  batch: 37  loss: 0.02998095\n",
      "epoch: 45  batch: 38  loss: 0.05233300\n",
      "epoch: 45  batch: 39  loss: 0.17651445\n",
      "epoch: 45  batch: 40  loss: 0.10809128\n",
      "epoch: 45  batch: 41  loss: 0.21067272\n",
      "epoch: 45  batch: 42  loss: 0.13960314\n",
      "epoch: 45  batch: 43  loss: 0.17507641\n",
      "epoch: 45  batch: 44  loss: 0.25760648\n",
      "epoch: 45  batch: 45  loss: 0.39142898\n",
      "epoch: 45  batch: 46  loss: 0.21112317\n",
      "epoch: 45  batch: 47  loss: 0.19014347\n",
      "epoch: 45  batch: 48  loss: 0.13194238\n",
      "epoch: 45  batch: 49  loss: 0.12610714\n",
      "epoch: 45  batch: 50  loss: 0.15791871\n",
      "epoch: 45  batch: 51  loss: 0.13986492\n",
      "epoch: 45  batch: 52  loss: 0.06140617\n",
      "epoch: 45  batch: 53  loss: 0.06414453\n",
      "epoch: 45  batch: 54  loss: 0.38014531\n",
      "epoch: 45  batch: 55  loss: 0.24441813\n",
      "epoch: 45  batch: 56  loss: 0.08486822\n",
      "epoch: 45  batch: 57  loss: 0.04921650\n",
      "epoch: 45  batch: 58  loss: 0.12959631\n",
      "epoch: 45  batch: 59  loss: 0.08749537\n",
      "epoch: 45  batch: 60  loss: 0.30344427\n",
      "epoch: 45  batch: 61  loss: 0.55934948\n",
      "epoch: 45  batch: 62  loss: 0.19184354\n",
      "epoch: 45  batch: 63  loss: 0.24454272\n",
      "epoch: 45  batch: 64  loss: 0.16585214\n",
      "epoch: 45  batch: 65  loss: 0.05633562\n",
      "epoch: 45  batch: 66  loss: 0.03079164\n",
      "epoch: 45  batch: 67  loss: 0.04093515\n",
      "epoch: 45  batch: 68  loss: 0.08564939\n",
      "epoch: 46  batch: 1  loss: 0.17951722\n",
      "epoch: 46  batch: 2  loss: 0.04528695\n",
      "epoch: 46  batch: 3  loss: 0.03037576\n",
      "epoch: 46  batch: 4  loss: 0.02843646\n",
      "epoch: 46  batch: 5  loss: 0.11727034\n",
      "epoch: 46  batch: 6  loss: 0.09535798\n",
      "epoch: 46  batch: 7  loss: 0.31331125\n",
      "epoch: 46  batch: 8  loss: 0.12514549\n",
      "epoch: 46  batch: 9  loss: 0.22440843\n",
      "epoch: 46  batch: 10  loss: 0.31757504\n",
      "epoch: 46  batch: 11  loss: 0.28149322\n",
      "epoch: 46  batch: 12  loss: 0.19880921\n",
      "epoch: 46  batch: 13  loss: 0.14982687\n",
      "epoch: 46  batch: 14  loss: 0.15313166\n",
      "epoch: 46  batch: 15  loss: 0.13673005\n",
      "epoch: 46  batch: 16  loss: 0.09324574\n",
      "epoch: 46  batch: 17  loss: 0.20947762\n",
      "epoch: 46  batch: 18  loss: 0.06356665\n",
      "epoch: 46  batch: 19  loss: 0.04978598\n",
      "epoch: 46  batch: 20  loss: 0.28260222\n",
      "epoch: 46  batch: 21  loss: 0.34959400\n",
      "epoch: 46  batch: 22  loss: 0.09082451\n",
      "epoch: 46  batch: 23  loss: 0.05510729\n",
      "epoch: 46  batch: 24  loss: 0.05549089\n",
      "epoch: 46  batch: 25  loss: 0.08015909\n",
      "epoch: 46  batch: 26  loss: 0.20224185\n",
      "epoch: 46  batch: 27  loss: 0.52826810\n",
      "epoch: 46  batch: 28  loss: 0.22139458\n",
      "epoch: 46  batch: 29  loss: 0.19493052\n",
      "epoch: 46  batch: 30  loss: 0.11386866\n",
      "epoch: 46  batch: 31  loss: 0.07835685\n",
      "epoch: 46  batch: 32  loss: 0.01706458\n",
      "epoch: 46  batch: 33  loss: 0.06160077\n",
      "epoch: 46  batch: 34  loss: 0.08651561\n",
      "epoch: 46  batch: 35  loss: 0.16855444\n",
      "epoch: 46  batch: 36  loss: 0.03459245\n",
      "epoch: 46  batch: 37  loss: 0.03018527\n",
      "epoch: 46  batch: 38  loss: 0.04965806\n",
      "epoch: 46  batch: 39  loss: 0.17468239\n",
      "epoch: 46  batch: 40  loss: 0.09805049\n",
      "epoch: 46  batch: 41  loss: 0.21722287\n",
      "epoch: 46  batch: 42  loss: 0.13960868\n",
      "epoch: 46  batch: 43  loss: 0.16889367\n",
      "epoch: 46  batch: 44  loss: 0.24946402\n",
      "epoch: 46  batch: 45  loss: 0.37218353\n",
      "epoch: 46  batch: 46  loss: 0.20552382\n",
      "epoch: 46  batch: 47  loss: 0.19765604\n",
      "epoch: 46  batch: 48  loss: 0.13095281\n",
      "epoch: 46  batch: 49  loss: 0.12640359\n",
      "epoch: 46  batch: 50  loss: 0.16491492\n",
      "epoch: 46  batch: 51  loss: 0.13574985\n",
      "epoch: 46  batch: 52  loss: 0.06230751\n",
      "epoch: 46  batch: 53  loss: 0.06409254\n",
      "epoch: 46  batch: 54  loss: 0.38060176\n",
      "epoch: 46  batch: 55  loss: 0.24336442\n",
      "epoch: 46  batch: 56  loss: 0.08481155\n",
      "epoch: 46  batch: 57  loss: 0.05050363\n",
      "epoch: 46  batch: 58  loss: 0.12557602\n",
      "epoch: 46  batch: 59  loss: 0.08760975\n",
      "epoch: 46  batch: 60  loss: 0.29201820\n",
      "epoch: 46  batch: 61  loss: 0.56492156\n",
      "epoch: 46  batch: 62  loss: 0.19120854\n",
      "epoch: 46  batch: 63  loss: 0.22298822\n",
      "epoch: 46  batch: 64  loss: 0.16325855\n",
      "epoch: 46  batch: 65  loss: 0.06304729\n",
      "epoch: 46  batch: 66  loss: 0.03126818\n",
      "epoch: 46  batch: 67  loss: 0.04100383\n",
      "epoch: 46  batch: 68  loss: 0.08516969\n",
      "epoch: 47  batch: 1  loss: 0.17301886\n",
      "epoch: 47  batch: 2  loss: 0.04348351\n",
      "epoch: 47  batch: 3  loss: 0.03081625\n",
      "epoch: 47  batch: 4  loss: 0.02772188\n",
      "epoch: 47  batch: 5  loss: 0.11724681\n",
      "epoch: 47  batch: 6  loss: 0.09550735\n",
      "epoch: 47  batch: 7  loss: 0.27389583\n",
      "epoch: 47  batch: 8  loss: 0.12457106\n",
      "epoch: 47  batch: 9  loss: 0.24853575\n",
      "epoch: 47  batch: 10  loss: 0.29261741\n",
      "epoch: 47  batch: 11  loss: 0.27797985\n",
      "epoch: 47  batch: 12  loss: 0.19535811\n",
      "epoch: 47  batch: 13  loss: 0.13595067\n",
      "epoch: 47  batch: 14  loss: 0.15565388\n",
      "epoch: 47  batch: 15  loss: 0.12838183\n",
      "epoch: 47  batch: 16  loss: 0.09400668\n",
      "epoch: 47  batch: 17  loss: 0.19793469\n",
      "epoch: 47  batch: 18  loss: 0.06142438\n",
      "epoch: 47  batch: 19  loss: 0.04785253\n",
      "epoch: 47  batch: 20  loss: 0.28177527\n",
      "epoch: 47  batch: 21  loss: 0.34727734\n",
      "epoch: 47  batch: 22  loss: 0.09176560\n",
      "epoch: 47  batch: 23  loss: 0.05183246\n",
      "epoch: 47  batch: 24  loss: 0.05612743\n",
      "epoch: 47  batch: 25  loss: 0.07959431\n",
      "epoch: 47  batch: 26  loss: 0.21923311\n",
      "epoch: 47  batch: 27  loss: 0.51670837\n",
      "epoch: 47  batch: 28  loss: 0.20768209\n",
      "epoch: 47  batch: 29  loss: 0.20068957\n",
      "epoch: 47  batch: 30  loss: 0.15286499\n",
      "epoch: 47  batch: 31  loss: 0.07269309\n",
      "epoch: 47  batch: 32  loss: 0.01649430\n",
      "epoch: 47  batch: 33  loss: 0.05680478\n",
      "epoch: 47  batch: 34  loss: 0.08651135\n",
      "epoch: 47  batch: 35  loss: 0.16973990\n",
      "epoch: 47  batch: 36  loss: 0.03570515\n",
      "epoch: 47  batch: 37  loss: 0.03067013\n",
      "epoch: 47  batch: 38  loss: 0.04771354\n",
      "epoch: 47  batch: 39  loss: 0.17387238\n",
      "epoch: 47  batch: 40  loss: 0.10970921\n",
      "epoch: 47  batch: 41  loss: 0.20290644\n",
      "epoch: 47  batch: 42  loss: 0.14550863\n",
      "epoch: 47  batch: 43  loss: 0.17004466\n",
      "epoch: 47  batch: 44  loss: 0.23546222\n",
      "epoch: 47  batch: 45  loss: 0.36303076\n",
      "epoch: 47  batch: 46  loss: 0.20832185\n",
      "epoch: 47  batch: 47  loss: 0.18921104\n",
      "epoch: 47  batch: 48  loss: 0.13208959\n",
      "epoch: 47  batch: 49  loss: 0.12803674\n",
      "epoch: 47  batch: 50  loss: 0.16323552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47  batch: 51  loss: 0.13206874\n",
      "epoch: 47  batch: 52  loss: 0.06266937\n",
      "epoch: 47  batch: 53  loss: 0.06523903\n",
      "epoch: 47  batch: 54  loss: 0.38175845\n",
      "epoch: 47  batch: 55  loss: 0.24250881\n",
      "epoch: 47  batch: 56  loss: 0.08554003\n",
      "epoch: 47  batch: 57  loss: 0.05017555\n",
      "epoch: 47  batch: 58  loss: 0.12778349\n",
      "epoch: 47  batch: 59  loss: 0.08756828\n",
      "epoch: 47  batch: 60  loss: 0.30110389\n",
      "epoch: 47  batch: 61  loss: 0.55337805\n",
      "epoch: 47  batch: 62  loss: 0.17841005\n",
      "epoch: 47  batch: 63  loss: 0.22550528\n",
      "epoch: 47  batch: 64  loss: 0.17632715\n",
      "epoch: 47  batch: 65  loss: 0.05362870\n",
      "epoch: 47  batch: 66  loss: 0.03215944\n",
      "epoch: 47  batch: 67  loss: 0.04004962\n",
      "epoch: 47  batch: 68  loss: 0.08645894\n",
      "epoch: 48  batch: 1  loss: 0.17702228\n",
      "epoch: 48  batch: 2  loss: 0.04413509\n",
      "epoch: 48  batch: 3  loss: 0.03090690\n",
      "epoch: 48  batch: 4  loss: 0.02899460\n",
      "epoch: 48  batch: 5  loss: 0.11952091\n",
      "epoch: 48  batch: 6  loss: 0.09547281\n",
      "epoch: 48  batch: 7  loss: 0.26252586\n",
      "epoch: 48  batch: 8  loss: 0.13102967\n",
      "epoch: 48  batch: 9  loss: 0.22373353\n",
      "epoch: 48  batch: 10  loss: 0.32931644\n",
      "epoch: 48  batch: 11  loss: 0.27998990\n",
      "epoch: 48  batch: 12  loss: 0.18853985\n",
      "epoch: 48  batch: 13  loss: 0.13465585\n",
      "epoch: 48  batch: 14  loss: 0.15096530\n",
      "epoch: 48  batch: 15  loss: 0.13220669\n",
      "epoch: 48  batch: 16  loss: 0.09399868\n",
      "epoch: 48  batch: 17  loss: 0.20373052\n",
      "epoch: 48  batch: 18  loss: 0.05990768\n",
      "epoch: 48  batch: 19  loss: 0.04989015\n",
      "epoch: 48  batch: 20  loss: 0.28103298\n",
      "epoch: 48  batch: 21  loss: 0.34671593\n",
      "epoch: 48  batch: 22  loss: 0.08935015\n",
      "epoch: 48  batch: 23  loss: 0.05226703\n",
      "epoch: 48  batch: 24  loss: 0.05696530\n",
      "epoch: 48  batch: 25  loss: 0.07888637\n",
      "epoch: 48  batch: 26  loss: 0.20080656\n",
      "epoch: 48  batch: 27  loss: 0.52653760\n",
      "epoch: 48  batch: 28  loss: 0.17328818\n",
      "epoch: 48  batch: 29  loss: 0.18903188\n",
      "epoch: 48  batch: 30  loss: 0.11007823\n",
      "epoch: 48  batch: 31  loss: 0.07389916\n",
      "epoch: 48  batch: 32  loss: 0.01631899\n",
      "epoch: 48  batch: 33  loss: 0.05663695\n",
      "epoch: 48  batch: 34  loss: 0.08717344\n",
      "epoch: 48  batch: 35  loss: 0.16995998\n",
      "epoch: 48  batch: 36  loss: 0.03596439\n",
      "epoch: 48  batch: 37  loss: 0.03076200\n",
      "epoch: 48  batch: 38  loss: 0.04561117\n",
      "epoch: 48  batch: 39  loss: 0.17395785\n",
      "epoch: 48  batch: 40  loss: 0.11529626\n",
      "epoch: 48  batch: 41  loss: 0.20184284\n",
      "epoch: 48  batch: 42  loss: 0.14714321\n",
      "epoch: 48  batch: 43  loss: 0.16964404\n",
      "epoch: 48  batch: 44  loss: 0.23832330\n",
      "epoch: 48  batch: 45  loss: 0.36319461\n",
      "epoch: 48  batch: 46  loss: 0.20482965\n",
      "epoch: 48  batch: 47  loss: 0.18675683\n",
      "epoch: 48  batch: 48  loss: 0.12945731\n",
      "epoch: 48  batch: 49  loss: 0.13053493\n",
      "epoch: 48  batch: 50  loss: 0.15698247\n",
      "epoch: 48  batch: 51  loss: 0.13174739\n",
      "epoch: 48  batch: 52  loss: 0.06515609\n",
      "epoch: 48  batch: 53  loss: 0.06996657\n",
      "epoch: 48  batch: 54  loss: 0.38243163\n",
      "epoch: 48  batch: 55  loss: 0.24263500\n",
      "epoch: 48  batch: 56  loss: 0.08608885\n",
      "epoch: 48  batch: 57  loss: 0.04963608\n",
      "epoch: 48  batch: 58  loss: 0.12328541\n",
      "epoch: 48  batch: 59  loss: 0.09176090\n",
      "epoch: 48  batch: 60  loss: 0.29642397\n",
      "epoch: 48  batch: 61  loss: 0.55980694\n",
      "epoch: 48  batch: 62  loss: 0.17023945\n",
      "epoch: 48  batch: 63  loss: 0.20708381\n",
      "epoch: 48  batch: 64  loss: 0.17729829\n",
      "epoch: 48  batch: 65  loss: 0.05260242\n",
      "epoch: 48  batch: 66  loss: 0.03234521\n",
      "epoch: 48  batch: 67  loss: 0.04183535\n",
      "epoch: 48  batch: 68  loss: 0.08528664\n",
      "epoch: 49  batch: 1  loss: 0.16870935\n",
      "epoch: 49  batch: 2  loss: 0.04361644\n",
      "epoch: 49  batch: 3  loss: 0.03027368\n",
      "epoch: 49  batch: 4  loss: 0.02805907\n",
      "epoch: 49  batch: 5  loss: 0.11551448\n",
      "epoch: 49  batch: 6  loss: 0.09454316\n",
      "epoch: 49  batch: 7  loss: 0.23767751\n",
      "epoch: 49  batch: 8  loss: 0.12100624\n",
      "epoch: 49  batch: 9  loss: 0.23145591\n",
      "epoch: 49  batch: 10  loss: 0.28622472\n",
      "epoch: 49  batch: 11  loss: 0.27332804\n",
      "epoch: 49  batch: 12  loss: 0.17899410\n",
      "epoch: 49  batch: 13  loss: 0.11954703\n",
      "epoch: 49  batch: 14  loss: 0.15248348\n",
      "epoch: 49  batch: 15  loss: 0.12482153\n",
      "epoch: 49  batch: 16  loss: 0.09384662\n",
      "epoch: 49  batch: 17  loss: 0.18104659\n",
      "epoch: 49  batch: 18  loss: 0.05651939\n",
      "epoch: 49  batch: 19  loss: 0.04215785\n",
      "epoch: 49  batch: 20  loss: 0.28241372\n",
      "epoch: 49  batch: 21  loss: 0.34714830\n",
      "epoch: 49  batch: 22  loss: 0.08728158\n",
      "epoch: 49  batch: 23  loss: 0.05449486\n",
      "epoch: 49  batch: 24  loss: 0.05508807\n",
      "epoch: 49  batch: 25  loss: 0.08302670\n",
      "epoch: 49  batch: 26  loss: 0.17360245\n",
      "epoch: 49  batch: 27  loss: 0.51966274\n",
      "epoch: 49  batch: 28  loss: 0.16052929\n",
      "epoch: 49  batch: 29  loss: 0.18156879\n",
      "epoch: 49  batch: 30  loss: 0.12621066\n",
      "epoch: 49  batch: 31  loss: 0.07200161\n",
      "epoch: 49  batch: 32  loss: 0.01387654\n",
      "epoch: 49  batch: 33  loss: 0.07032820\n",
      "epoch: 49  batch: 34  loss: 0.08717524\n",
      "epoch: 49  batch: 35  loss: 0.16974895\n",
      "epoch: 49  batch: 36  loss: 0.03618073\n",
      "epoch: 49  batch: 37  loss: 0.03108507\n",
      "epoch: 49  batch: 38  loss: 0.04649347\n",
      "epoch: 49  batch: 39  loss: 0.17305329\n",
      "epoch: 49  batch: 40  loss: 0.11303472\n",
      "epoch: 49  batch: 41  loss: 0.20385078\n",
      "epoch: 49  batch: 42  loss: 0.13857657\n",
      "epoch: 49  batch: 43  loss: 0.16520394\n",
      "epoch: 49  batch: 44  loss: 0.23420809\n",
      "epoch: 49  batch: 45  loss: 0.35925993\n",
      "epoch: 49  batch: 46  loss: 0.20271195\n",
      "epoch: 49  batch: 47  loss: 0.19023499\n",
      "epoch: 49  batch: 48  loss: 0.12884974\n",
      "epoch: 49  batch: 49  loss: 0.12851284\n",
      "epoch: 49  batch: 50  loss: 0.15772383\n",
      "epoch: 49  batch: 51  loss: 0.13456395\n",
      "epoch: 49  batch: 52  loss: 0.06447115\n",
      "epoch: 49  batch: 53  loss: 0.06469646\n",
      "epoch: 49  batch: 54  loss: 0.38277984\n",
      "epoch: 49  batch: 55  loss: 0.24235177\n",
      "epoch: 49  batch: 56  loss: 0.08607365\n",
      "epoch: 49  batch: 57  loss: 0.05103680\n",
      "epoch: 49  batch: 58  loss: 0.12361028\n",
      "epoch: 49  batch: 59  loss: 0.08871407\n",
      "epoch: 49  batch: 60  loss: 0.27010241\n",
      "epoch: 49  batch: 61  loss: 0.55083787\n",
      "epoch: 49  batch: 62  loss: 0.16535714\n",
      "epoch: 49  batch: 63  loss: 0.19380327\n",
      "epoch: 49  batch: 64  loss: 0.16670418\n",
      "epoch: 49  batch: 65  loss: 0.05523532\n",
      "epoch: 49  batch: 66  loss: 0.03326818\n",
      "epoch: 49  batch: 67  loss: 0.04014071\n",
      "epoch: 49  batch: 68  loss: 0.08567056\n",
      "epoch: 50  batch: 1  loss: 0.16966878\n",
      "epoch: 50  batch: 2  loss: 0.04346054\n",
      "epoch: 50  batch: 3  loss: 0.03014167\n",
      "epoch: 50  batch: 4  loss: 0.02811426\n",
      "epoch: 50  batch: 5  loss: 0.11596557\n",
      "epoch: 50  batch: 6  loss: 0.10841361\n",
      "epoch: 50  batch: 7  loss: 0.24092752\n",
      "epoch: 50  batch: 8  loss: 0.12184353\n",
      "epoch: 50  batch: 9  loss: 0.21887276\n",
      "epoch: 50  batch: 10  loss: 0.27844501\n",
      "epoch: 50  batch: 11  loss: 0.27164090\n",
      "epoch: 50  batch: 12  loss: 0.17813878\n",
      "epoch: 50  batch: 13  loss: 0.11494035\n",
      "epoch: 50  batch: 14  loss: 0.14864886\n",
      "epoch: 50  batch: 15  loss: 0.12342385\n",
      "epoch: 50  batch: 16  loss: 0.09368747\n",
      "epoch: 50  batch: 17  loss: 0.16412020\n",
      "epoch: 50  batch: 18  loss: 0.05717534\n",
      "epoch: 50  batch: 19  loss: 0.04202418\n",
      "epoch: 50  batch: 20  loss: 0.28327477\n",
      "epoch: 50  batch: 21  loss: 0.34713811\n",
      "epoch: 50  batch: 22  loss: 0.08714225\n",
      "epoch: 50  batch: 23  loss: 0.05510473\n",
      "epoch: 50  batch: 24  loss: 0.05521793\n",
      "epoch: 50  batch: 25  loss: 0.08216006\n",
      "epoch: 50  batch: 26  loss: 0.16794646\n",
      "epoch: 50  batch: 27  loss: 0.51743859\n",
      "epoch: 50  batch: 28  loss: 0.15658139\n",
      "epoch: 50  batch: 29  loss: 0.17620322\n",
      "epoch: 50  batch: 30  loss: 0.11016780\n",
      "epoch: 50  batch: 31  loss: 0.07066544\n",
      "epoch: 50  batch: 32  loss: 0.01397930\n",
      "epoch: 50  batch: 33  loss: 0.06605455\n",
      "epoch: 50  batch: 34  loss: 0.08678100\n",
      "epoch: 50  batch: 35  loss: 0.16919887\n",
      "epoch: 50  batch: 36  loss: 0.03629450\n",
      "epoch: 50  batch: 37  loss: 0.03167170\n",
      "epoch: 50  batch: 38  loss: 0.04782735\n",
      "epoch: 50  batch: 39  loss: 0.17277266\n",
      "epoch: 50  batch: 40  loss: 0.11836220\n",
      "epoch: 50  batch: 41  loss: 0.20718057\n",
      "epoch: 50  batch: 42  loss: 0.13224080\n",
      "epoch: 50  batch: 43  loss: 0.16157049\n",
      "epoch: 50  batch: 44  loss: 0.23232126\n",
      "epoch: 50  batch: 45  loss: 0.35766909\n",
      "epoch: 50  batch: 46  loss: 0.20448469\n",
      "epoch: 50  batch: 47  loss: 0.18702760\n",
      "epoch: 50  batch: 48  loss: 0.12872149\n",
      "epoch: 50  batch: 49  loss: 0.12588888\n",
      "epoch: 50  batch: 50  loss: 0.15461551\n",
      "epoch: 50  batch: 51  loss: 0.13841663\n",
      "epoch: 50  batch: 52  loss: 0.06518999\n",
      "epoch: 50  batch: 53  loss: 0.06467432\n",
      "epoch: 50  batch: 54  loss: 0.38452759\n",
      "epoch: 50  batch: 55  loss: 0.24188507\n",
      "epoch: 50  batch: 56  loss: 0.08640473\n",
      "epoch: 50  batch: 57  loss: 0.05156748\n",
      "epoch: 50  batch: 58  loss: 0.12700099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50  batch: 59  loss: 0.08820120\n",
      "epoch: 50  batch: 60  loss: 0.28496704\n",
      "epoch: 50  batch: 61  loss: 0.54962683\n",
      "epoch: 50  batch: 62  loss: 0.15784942\n",
      "epoch: 50  batch: 63  loss: 0.19886085\n",
      "epoch: 50  batch: 64  loss: 0.18929747\n",
      "epoch: 50  batch: 65  loss: 0.04667930\n",
      "epoch: 50  batch: 66  loss: 0.03416573\n",
      "epoch: 50  batch: 67  loss: 0.04229149\n",
      "epoch: 50  batch: 68  loss: 0.08577015\n",
      "epoch: 51  batch: 1  loss: 0.17035249\n",
      "epoch: 51  batch: 2  loss: 0.04391793\n",
      "epoch: 51  batch: 3  loss: 0.03064666\n",
      "epoch: 51  batch: 4  loss: 0.02933981\n",
      "epoch: 51  batch: 5  loss: 0.11509368\n",
      "epoch: 51  batch: 6  loss: 0.09255350\n",
      "epoch: 51  batch: 7  loss: 0.24102670\n",
      "epoch: 51  batch: 8  loss: 0.12326655\n",
      "epoch: 51  batch: 9  loss: 0.21563098\n",
      "epoch: 51  batch: 10  loss: 0.32926437\n",
      "epoch: 51  batch: 11  loss: 0.27938107\n",
      "epoch: 51  batch: 12  loss: 0.18345660\n",
      "epoch: 51  batch: 13  loss: 0.11358527\n",
      "epoch: 51  batch: 14  loss: 0.14627966\n",
      "epoch: 51  batch: 15  loss: 0.12698796\n",
      "epoch: 51  batch: 16  loss: 0.09309181\n",
      "epoch: 51  batch: 17  loss: 0.17289110\n",
      "epoch: 51  batch: 18  loss: 0.06203688\n",
      "epoch: 51  batch: 19  loss: 0.04533525\n",
      "epoch: 51  batch: 20  loss: 0.28376630\n",
      "epoch: 51  batch: 21  loss: 0.34678537\n",
      "epoch: 51  batch: 22  loss: 0.09126263\n",
      "epoch: 51  batch: 23  loss: 0.05185865\n",
      "epoch: 51  batch: 24  loss: 0.05595079\n",
      "epoch: 51  batch: 25  loss: 0.07967815\n",
      "epoch: 51  batch: 26  loss: 0.22511029\n",
      "epoch: 51  batch: 27  loss: 0.50402594\n",
      "epoch: 51  batch: 28  loss: 0.17718227\n",
      "epoch: 51  batch: 29  loss: 0.18183477\n",
      "epoch: 51  batch: 30  loss: 0.14829601\n",
      "epoch: 51  batch: 31  loss: 0.06758339\n",
      "epoch: 51  batch: 32  loss: 0.01518294\n",
      "epoch: 51  batch: 33  loss: 0.05319706\n",
      "epoch: 51  batch: 34  loss: 0.08691002\n",
      "epoch: 51  batch: 35  loss: 0.17007868\n",
      "epoch: 51  batch: 36  loss: 0.03642099\n",
      "epoch: 51  batch: 37  loss: 0.03113278\n",
      "epoch: 51  batch: 38  loss: 0.04474933\n",
      "epoch: 51  batch: 39  loss: 0.17201589\n",
      "epoch: 51  batch: 40  loss: 0.11687610\n",
      "epoch: 51  batch: 41  loss: 0.19808546\n",
      "epoch: 51  batch: 42  loss: 0.16281749\n",
      "epoch: 51  batch: 43  loss: 0.16914478\n",
      "epoch: 51  batch: 44  loss: 0.22990204\n",
      "epoch: 51  batch: 45  loss: 0.36832553\n",
      "epoch: 51  batch: 46  loss: 0.19453579\n",
      "epoch: 51  batch: 47  loss: 0.18040000\n",
      "epoch: 51  batch: 48  loss: 0.12905392\n",
      "epoch: 51  batch: 49  loss: 0.13095172\n",
      "epoch: 51  batch: 50  loss: 0.15550743\n",
      "epoch: 51  batch: 51  loss: 0.12966740\n",
      "epoch: 51  batch: 52  loss: 0.06753545\n",
      "epoch: 51  batch: 53  loss: 0.06612234\n",
      "epoch: 51  batch: 54  loss: 0.38467503\n",
      "epoch: 51  batch: 55  loss: 0.24108081\n",
      "epoch: 51  batch: 56  loss: 0.08644684\n",
      "epoch: 51  batch: 57  loss: 0.05037654\n",
      "epoch: 51  batch: 58  loss: 0.12582034\n",
      "epoch: 51  batch: 59  loss: 0.08966987\n",
      "epoch: 51  batch: 60  loss: 0.28760189\n",
      "epoch: 51  batch: 61  loss: 0.54753065\n",
      "epoch: 51  batch: 62  loss: 0.15950789\n",
      "epoch: 51  batch: 63  loss: 0.20362046\n",
      "epoch: 51  batch: 64  loss: 0.17144468\n",
      "epoch: 51  batch: 65  loss: 0.05551367\n",
      "epoch: 51  batch: 66  loss: 0.03388187\n",
      "epoch: 51  batch: 67  loss: 0.04364983\n",
      "epoch: 51  batch: 68  loss: 0.08524888\n",
      "epoch: 52  batch: 1  loss: 0.16658807\n",
      "epoch: 52  batch: 2  loss: 0.04426119\n",
      "epoch: 52  batch: 3  loss: 0.03088720\n",
      "epoch: 52  batch: 4  loss: 0.02840548\n",
      "epoch: 52  batch: 5  loss: 0.11387403\n",
      "epoch: 52  batch: 6  loss: 0.09222396\n",
      "epoch: 52  batch: 7  loss: 0.22344483\n",
      "epoch: 52  batch: 8  loss: 0.11924678\n",
      "epoch: 52  batch: 9  loss: 0.22110115\n",
      "epoch: 52  batch: 10  loss: 0.29877377\n",
      "epoch: 52  batch: 11  loss: 0.28031605\n",
      "epoch: 52  batch: 12  loss: 0.18254273\n",
      "epoch: 52  batch: 13  loss: 0.11087893\n",
      "epoch: 52  batch: 14  loss: 0.14875147\n",
      "epoch: 52  batch: 15  loss: 0.12191696\n",
      "epoch: 52  batch: 16  loss: 0.09354752\n",
      "epoch: 52  batch: 17  loss: 0.15410158\n",
      "epoch: 52  batch: 18  loss: 0.05565507\n",
      "epoch: 52  batch: 19  loss: 0.04104558\n",
      "epoch: 52  batch: 20  loss: 0.28556648\n",
      "epoch: 52  batch: 21  loss: 0.34619883\n",
      "epoch: 52  batch: 22  loss: 0.08886582\n",
      "epoch: 52  batch: 23  loss: 0.05404867\n",
      "epoch: 52  batch: 24  loss: 0.05379997\n",
      "epoch: 52  batch: 25  loss: 0.08804666\n",
      "epoch: 52  batch: 26  loss: 0.15773953\n",
      "epoch: 52  batch: 27  loss: 0.49532604\n",
      "epoch: 52  batch: 28  loss: 0.14657626\n",
      "epoch: 52  batch: 29  loss: 0.18449195\n",
      "epoch: 52  batch: 30  loss: 0.10774277\n",
      "epoch: 52  batch: 31  loss: 0.06954774\n",
      "epoch: 52  batch: 32  loss: 0.01378849\n",
      "epoch: 52  batch: 33  loss: 0.06616082\n",
      "epoch: 52  batch: 34  loss: 0.08652197\n",
      "epoch: 52  batch: 35  loss: 0.16801277\n",
      "epoch: 52  batch: 36  loss: 0.03686183\n",
      "epoch: 52  batch: 37  loss: 0.03220102\n",
      "epoch: 52  batch: 38  loss: 0.04679526\n",
      "epoch: 52  batch: 39  loss: 0.16910471\n",
      "epoch: 52  batch: 40  loss: 0.11728878\n",
      "epoch: 52  batch: 41  loss: 0.20812009\n",
      "epoch: 52  batch: 42  loss: 0.13698779\n",
      "epoch: 52  batch: 43  loss: 0.15918067\n",
      "epoch: 52  batch: 44  loss: 0.24149628\n",
      "epoch: 52  batch: 45  loss: 0.35456347\n",
      "epoch: 52  batch: 46  loss: 0.19741388\n",
      "epoch: 52  batch: 47  loss: 0.18806708\n",
      "epoch: 52  batch: 48  loss: 0.12796390\n",
      "epoch: 52  batch: 49  loss: 0.12416457\n",
      "epoch: 52  batch: 50  loss: 0.14455065\n",
      "epoch: 52  batch: 51  loss: 0.13926636\n",
      "epoch: 52  batch: 52  loss: 0.06505179\n",
      "epoch: 52  batch: 53  loss: 0.06550673\n",
      "epoch: 52  batch: 54  loss: 0.38653651\n",
      "epoch: 52  batch: 55  loss: 0.24173479\n",
      "epoch: 52  batch: 56  loss: 0.08563703\n",
      "epoch: 52  batch: 57  loss: 0.04900671\n",
      "epoch: 52  batch: 58  loss: 0.12963313\n",
      "epoch: 52  batch: 59  loss: 0.08974732\n",
      "epoch: 52  batch: 60  loss: 0.31387758\n",
      "epoch: 52  batch: 61  loss: 0.57222706\n",
      "epoch: 52  batch: 62  loss: 0.16319215\n",
      "epoch: 52  batch: 63  loss: 0.21113153\n",
      "epoch: 52  batch: 64  loss: 0.15835530\n",
      "epoch: 52  batch: 65  loss: 0.06170927\n",
      "epoch: 52  batch: 66  loss: 0.03544530\n",
      "epoch: 52  batch: 67  loss: 0.04126218\n",
      "epoch: 52  batch: 68  loss: 0.08561569\n",
      "epoch: 53  batch: 1  loss: 0.16366763\n",
      "epoch: 53  batch: 2  loss: 0.04763355\n",
      "epoch: 53  batch: 3  loss: 0.03073038\n",
      "epoch: 53  batch: 4  loss: 0.02842828\n",
      "epoch: 53  batch: 5  loss: 0.11379956\n",
      "epoch: 53  batch: 6  loss: 0.09861047\n",
      "epoch: 53  batch: 7  loss: 0.25558531\n",
      "epoch: 53  batch: 8  loss: 0.11393581\n",
      "epoch: 53  batch: 9  loss: 0.20479228\n",
      "epoch: 53  batch: 10  loss: 0.27406773\n",
      "epoch: 53  batch: 11  loss: 0.29219016\n",
      "epoch: 53  batch: 12  loss: 0.17591938\n",
      "epoch: 53  batch: 13  loss: 0.12136163\n",
      "epoch: 53  batch: 14  loss: 0.13384300\n",
      "epoch: 53  batch: 15  loss: 0.12785348\n",
      "epoch: 53  batch: 16  loss: 0.09249194\n",
      "epoch: 53  batch: 17  loss: 0.15417169\n",
      "epoch: 53  batch: 18  loss: 0.06924523\n",
      "epoch: 53  batch: 19  loss: 0.05982370\n",
      "epoch: 53  batch: 20  loss: 0.28544030\n",
      "epoch: 53  batch: 21  loss: 0.34468889\n",
      "epoch: 53  batch: 22  loss: 0.09963731\n",
      "epoch: 53  batch: 23  loss: 0.05364667\n",
      "epoch: 53  batch: 24  loss: 0.06111667\n",
      "epoch: 53  batch: 25  loss: 0.07649346\n",
      "epoch: 53  batch: 26  loss: 0.19455302\n",
      "epoch: 53  batch: 27  loss: 0.48110861\n",
      "epoch: 53  batch: 28  loss: 0.24179561\n",
      "epoch: 53  batch: 29  loss: 0.21036141\n",
      "epoch: 53  batch: 30  loss: 0.11080876\n",
      "epoch: 53  batch: 31  loss: 0.05890035\n",
      "epoch: 53  batch: 32  loss: 0.01836227\n",
      "epoch: 53  batch: 33  loss: 0.03086196\n",
      "epoch: 53  batch: 34  loss: 0.08296479\n",
      "epoch: 53  batch: 35  loss: 0.16756698\n",
      "epoch: 53  batch: 36  loss: 0.03829346\n",
      "epoch: 53  batch: 37  loss: 0.03264089\n",
      "epoch: 53  batch: 38  loss: 0.05261288\n",
      "epoch: 53  batch: 39  loss: 0.18149085\n",
      "epoch: 53  batch: 40  loss: 0.10647728\n",
      "epoch: 53  batch: 41  loss: 0.19813105\n",
      "epoch: 53  batch: 42  loss: 0.15409945\n",
      "epoch: 53  batch: 43  loss: 0.17489518\n",
      "epoch: 53  batch: 44  loss: 0.24398118\n",
      "epoch: 53  batch: 45  loss: 0.36982003\n",
      "epoch: 53  batch: 46  loss: 0.19100952\n",
      "epoch: 53  batch: 47  loss: 0.19853354\n",
      "epoch: 53  batch: 48  loss: 0.12926073\n",
      "epoch: 53  batch: 49  loss: 0.16725539\n",
      "epoch: 53  batch: 50  loss: 0.15709157\n",
      "epoch: 53  batch: 51  loss: 0.12032916\n",
      "epoch: 53  batch: 52  loss: 0.06546041\n",
      "epoch: 53  batch: 53  loss: 0.06384270\n",
      "epoch: 53  batch: 54  loss: 0.38134810\n",
      "epoch: 53  batch: 55  loss: 0.24029109\n",
      "epoch: 53  batch: 56  loss: 0.10856174\n",
      "epoch: 53  batch: 57  loss: 0.04946241\n",
      "epoch: 53  batch: 58  loss: 0.14408940\n",
      "epoch: 53  batch: 59  loss: 0.09395893\n",
      "epoch: 53  batch: 60  loss: 0.27042979\n",
      "epoch: 53  batch: 61  loss: 0.54568034\n",
      "epoch: 53  batch: 62  loss: 0.16750634\n",
      "epoch: 53  batch: 63  loss: 0.30666542\n",
      "epoch: 53  batch: 64  loss: 0.16589843\n",
      "epoch: 53  batch: 65  loss: 0.06329449\n",
      "epoch: 53  batch: 66  loss: 0.03565761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53  batch: 67  loss: 0.04383086\n",
      "epoch: 53  batch: 68  loss: 0.08605681\n",
      "epoch: 54  batch: 1  loss: 0.16612683\n",
      "epoch: 54  batch: 2  loss: 0.04949744\n",
      "epoch: 54  batch: 3  loss: 0.03661246\n",
      "epoch: 54  batch: 4  loss: 0.02825259\n",
      "epoch: 54  batch: 5  loss: 0.13310248\n",
      "epoch: 54  batch: 6  loss: 0.14500532\n",
      "epoch: 54  batch: 7  loss: 0.23844019\n",
      "epoch: 54  batch: 8  loss: 0.11365090\n",
      "epoch: 54  batch: 9  loss: 0.23330215\n",
      "epoch: 54  batch: 10  loss: 0.31189638\n",
      "epoch: 54  batch: 11  loss: 0.34041059\n",
      "epoch: 54  batch: 12  loss: 0.17197980\n",
      "epoch: 54  batch: 13  loss: 0.13749844\n",
      "epoch: 54  batch: 14  loss: 0.13092323\n",
      "epoch: 54  batch: 15  loss: 0.12717672\n",
      "epoch: 54  batch: 16  loss: 0.09297145\n",
      "epoch: 54  batch: 17  loss: 0.14443843\n",
      "epoch: 54  batch: 18  loss: 0.06770362\n",
      "epoch: 54  batch: 19  loss: 0.06835410\n",
      "epoch: 54  batch: 20  loss: 0.28362390\n",
      "epoch: 54  batch: 21  loss: 0.34547222\n",
      "epoch: 54  batch: 22  loss: 0.09872657\n",
      "epoch: 54  batch: 23  loss: 0.05306572\n",
      "epoch: 54  batch: 24  loss: 0.05885649\n",
      "epoch: 54  batch: 25  loss: 0.07251252\n",
      "epoch: 54  batch: 26  loss: 0.18018465\n",
      "epoch: 54  batch: 27  loss: 0.49015045\n",
      "epoch: 54  batch: 28  loss: 0.18355061\n",
      "epoch: 54  batch: 29  loss: 0.20849353\n",
      "epoch: 54  batch: 30  loss: 0.11122695\n",
      "epoch: 54  batch: 31  loss: 0.05697019\n",
      "epoch: 54  batch: 32  loss: 0.01745812\n",
      "epoch: 54  batch: 33  loss: 0.02311861\n",
      "epoch: 54  batch: 34  loss: 0.08456017\n",
      "epoch: 54  batch: 35  loss: 0.16908188\n",
      "epoch: 54  batch: 36  loss: 0.03653570\n",
      "epoch: 54  batch: 37  loss: 0.03165380\n",
      "epoch: 54  batch: 38  loss: 0.04510085\n",
      "epoch: 54  batch: 39  loss: 0.17649549\n",
      "epoch: 54  batch: 40  loss: 0.09894622\n",
      "epoch: 54  batch: 41  loss: 0.19805837\n",
      "epoch: 54  batch: 42  loss: 0.14163952\n",
      "epoch: 54  batch: 43  loss: 0.17953515\n",
      "epoch: 54  batch: 44  loss: 0.23088072\n",
      "epoch: 54  batch: 45  loss: 0.36175141\n",
      "epoch: 54  batch: 46  loss: 0.18637685\n",
      "epoch: 54  batch: 47  loss: 0.20301060\n",
      "epoch: 54  batch: 48  loss: 0.13049346\n",
      "epoch: 54  batch: 49  loss: 0.16211836\n",
      "epoch: 54  batch: 50  loss: 0.16055407\n",
      "epoch: 54  batch: 51  loss: 0.12452222\n",
      "epoch: 54  batch: 52  loss: 0.06240464\n",
      "epoch: 54  batch: 53  loss: 0.06681655\n",
      "epoch: 54  batch: 54  loss: 0.38076240\n",
      "epoch: 54  batch: 55  loss: 0.24152723\n",
      "epoch: 54  batch: 56  loss: 0.09995894\n",
      "epoch: 54  batch: 57  loss: 0.05322421\n",
      "epoch: 54  batch: 58  loss: 0.12664160\n",
      "epoch: 54  batch: 59  loss: 0.09153908\n",
      "epoch: 54  batch: 60  loss: 0.23914219\n",
      "epoch: 54  batch: 61  loss: 0.56471014\n",
      "epoch: 54  batch: 62  loss: 0.14427464\n",
      "epoch: 54  batch: 63  loss: 0.29985324\n",
      "epoch: 54  batch: 64  loss: 0.15577123\n",
      "epoch: 54  batch: 65  loss: 0.06642620\n",
      "epoch: 54  batch: 66  loss: 0.03527071\n",
      "epoch: 54  batch: 67  loss: 0.04459681\n",
      "epoch: 54  batch: 68  loss: 0.08430474\n",
      "epoch: 55  batch: 1  loss: 0.16356556\n",
      "epoch: 55  batch: 2  loss: 0.05040239\n",
      "epoch: 55  batch: 3  loss: 0.04086163\n",
      "epoch: 55  batch: 4  loss: 0.02778341\n",
      "epoch: 55  batch: 5  loss: 0.12189742\n",
      "epoch: 55  batch: 6  loss: 0.12225853\n",
      "epoch: 55  batch: 7  loss: 0.23075157\n",
      "epoch: 55  batch: 8  loss: 0.11004485\n",
      "epoch: 55  batch: 9  loss: 0.19720030\n",
      "epoch: 55  batch: 10  loss: 0.20454475\n",
      "epoch: 55  batch: 11  loss: 0.33025455\n",
      "epoch: 55  batch: 12  loss: 0.16884975\n",
      "epoch: 55  batch: 13  loss: 0.13437235\n",
      "epoch: 55  batch: 14  loss: 0.13133904\n",
      "epoch: 55  batch: 15  loss: 0.11444425\n",
      "epoch: 55  batch: 16  loss: 0.09262890\n",
      "epoch: 55  batch: 17  loss: 0.14613973\n",
      "epoch: 55  batch: 18  loss: 0.05928014\n",
      "epoch: 55  batch: 19  loss: 0.06060008\n",
      "epoch: 55  batch: 20  loss: 0.28589475\n",
      "epoch: 55  batch: 21  loss: 0.34727865\n",
      "epoch: 55  batch: 22  loss: 0.10409314\n",
      "epoch: 55  batch: 23  loss: 0.05589928\n",
      "epoch: 55  batch: 24  loss: 0.05600883\n",
      "epoch: 55  batch: 25  loss: 0.06894461\n",
      "epoch: 55  batch: 26  loss: 0.14523405\n",
      "epoch: 55  batch: 27  loss: 0.49082831\n",
      "epoch: 55  batch: 28  loss: 0.21821146\n",
      "epoch: 55  batch: 29  loss: 0.18505290\n",
      "epoch: 55  batch: 30  loss: 0.10289807\n",
      "epoch: 55  batch: 31  loss: 0.05526019\n",
      "epoch: 55  batch: 32  loss: 0.01786197\n",
      "epoch: 55  batch: 33  loss: 0.02923180\n",
      "epoch: 55  batch: 34  loss: 0.08314195\n",
      "epoch: 55  batch: 35  loss: 0.16543789\n",
      "epoch: 55  batch: 36  loss: 0.03719548\n",
      "epoch: 55  batch: 37  loss: 0.03308575\n",
      "epoch: 55  batch: 38  loss: 0.04383298\n",
      "epoch: 55  batch: 39  loss: 0.17522617\n",
      "epoch: 55  batch: 40  loss: 0.08736484\n",
      "epoch: 55  batch: 41  loss: 0.20047837\n",
      "epoch: 55  batch: 42  loss: 0.17546381\n",
      "epoch: 55  batch: 43  loss: 0.15445390\n",
      "epoch: 55  batch: 44  loss: 0.24255463\n",
      "epoch: 55  batch: 45  loss: 0.34854180\n",
      "epoch: 55  batch: 46  loss: 0.17804842\n",
      "epoch: 55  batch: 47  loss: 0.18952730\n",
      "epoch: 55  batch: 48  loss: 0.12763485\n",
      "epoch: 55  batch: 49  loss: 0.15680663\n",
      "epoch: 55  batch: 50  loss: 0.15942238\n",
      "epoch: 55  batch: 51  loss: 0.12646826\n",
      "epoch: 55  batch: 52  loss: 0.06262229\n",
      "epoch: 55  batch: 53  loss: 0.06444702\n",
      "epoch: 55  batch: 54  loss: 0.38382065\n",
      "epoch: 55  batch: 55  loss: 0.24044466\n",
      "epoch: 55  batch: 56  loss: 0.10076862\n",
      "epoch: 55  batch: 57  loss: 0.05158362\n",
      "epoch: 55  batch: 58  loss: 0.12314580\n",
      "epoch: 55  batch: 59  loss: 0.09069803\n",
      "epoch: 55  batch: 60  loss: 0.21491420\n",
      "epoch: 55  batch: 61  loss: 0.55330569\n",
      "epoch: 55  batch: 62  loss: 0.15958576\n",
      "epoch: 55  batch: 63  loss: 0.29439279\n",
      "epoch: 55  batch: 64  loss: 0.15148708\n",
      "epoch: 55  batch: 65  loss: 0.06873845\n",
      "epoch: 55  batch: 66  loss: 0.03699339\n",
      "epoch: 55  batch: 67  loss: 0.04708548\n",
      "epoch: 55  batch: 68  loss: 0.08654733\n",
      "epoch: 56  batch: 1  loss: 0.16418651\n",
      "epoch: 56  batch: 2  loss: 0.05001596\n",
      "epoch: 56  batch: 3  loss: 0.04122253\n",
      "epoch: 56  batch: 4  loss: 0.02788498\n",
      "epoch: 56  batch: 5  loss: 0.12399811\n",
      "epoch: 56  batch: 6  loss: 0.11197348\n",
      "epoch: 56  batch: 7  loss: 0.23125698\n",
      "epoch: 56  batch: 8  loss: 0.11633744\n",
      "epoch: 56  batch: 9  loss: 0.19019733\n",
      "epoch: 56  batch: 10  loss: 0.21091025\n",
      "epoch: 56  batch: 11  loss: 0.33654359\n",
      "epoch: 56  batch: 12  loss: 0.17306347\n",
      "epoch: 56  batch: 13  loss: 0.11070879\n",
      "epoch: 56  batch: 14  loss: 0.13024449\n",
      "epoch: 56  batch: 15  loss: 0.11730281\n",
      "epoch: 56  batch: 16  loss: 0.09120253\n",
      "epoch: 56  batch: 17  loss: 0.12928960\n",
      "epoch: 56  batch: 18  loss: 0.06038627\n",
      "epoch: 56  batch: 19  loss: 0.06024817\n",
      "epoch: 56  batch: 20  loss: 0.28609017\n",
      "epoch: 56  batch: 21  loss: 0.34536010\n",
      "epoch: 56  batch: 22  loss: 0.10034945\n",
      "epoch: 56  batch: 23  loss: 0.05175322\n",
      "epoch: 56  batch: 24  loss: 0.05536573\n",
      "epoch: 56  batch: 25  loss: 0.06876677\n",
      "epoch: 56  batch: 26  loss: 0.15267953\n",
      "epoch: 56  batch: 27  loss: 0.46918666\n",
      "epoch: 56  batch: 28  loss: 0.13941585\n",
      "epoch: 56  batch: 29  loss: 0.18793161\n",
      "epoch: 56  batch: 30  loss: 0.12792435\n",
      "epoch: 56  batch: 31  loss: 0.05202690\n",
      "epoch: 56  batch: 32  loss: 0.01753162\n",
      "epoch: 56  batch: 33  loss: 0.03296718\n",
      "epoch: 56  batch: 34  loss: 0.08310985\n",
      "epoch: 56  batch: 35  loss: 0.16492751\n",
      "epoch: 56  batch: 36  loss: 0.03729516\n",
      "epoch: 56  batch: 37  loss: 0.03302053\n",
      "epoch: 56  batch: 38  loss: 0.04404687\n",
      "epoch: 56  batch: 39  loss: 0.17229933\n",
      "epoch: 56  batch: 40  loss: 0.08993635\n",
      "epoch: 56  batch: 41  loss: 0.19906971\n",
      "epoch: 56  batch: 42  loss: 0.16739927\n",
      "epoch: 56  batch: 43  loss: 0.14666530\n",
      "epoch: 56  batch: 44  loss: 0.22870588\n",
      "epoch: 56  batch: 45  loss: 0.34032816\n",
      "epoch: 56  batch: 46  loss: 0.17822927\n",
      "epoch: 56  batch: 47  loss: 0.17103475\n",
      "epoch: 56  batch: 48  loss: 0.12686391\n",
      "epoch: 56  batch: 49  loss: 0.13542256\n",
      "epoch: 56  batch: 50  loss: 0.16230711\n",
      "epoch: 56  batch: 51  loss: 0.13283840\n",
      "epoch: 56  batch: 52  loss: 0.06814412\n",
      "epoch: 56  batch: 53  loss: 0.07493597\n",
      "epoch: 56  batch: 54  loss: 0.38726199\n",
      "epoch: 56  batch: 55  loss: 0.23973487\n",
      "epoch: 56  batch: 56  loss: 0.09869344\n",
      "epoch: 56  batch: 57  loss: 0.05005132\n",
      "epoch: 56  batch: 58  loss: 0.13603806\n",
      "epoch: 56  batch: 59  loss: 0.08952090\n",
      "epoch: 56  batch: 60  loss: 0.24783827\n",
      "epoch: 56  batch: 61  loss: 0.58853471\n",
      "epoch: 56  batch: 62  loss: 0.15577477\n",
      "epoch: 56  batch: 63  loss: 0.25882965\n",
      "epoch: 56  batch: 64  loss: 0.20130958\n",
      "epoch: 56  batch: 65  loss: 0.06434532\n",
      "epoch: 56  batch: 66  loss: 0.03742914\n",
      "epoch: 56  batch: 67  loss: 0.05453726\n",
      "epoch: 56  batch: 68  loss: 0.08570043\n",
      "epoch: 57  batch: 1  loss: 0.16255099\n",
      "epoch: 57  batch: 2  loss: 0.04737401\n",
      "epoch: 57  batch: 3  loss: 0.03476370\n",
      "epoch: 57  batch: 4  loss: 0.02811254\n",
      "epoch: 57  batch: 5  loss: 0.12767757\n",
      "epoch: 57  batch: 6  loss: 0.11056962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57  batch: 7  loss: 0.22738534\n",
      "epoch: 57  batch: 8  loss: 0.11551113\n",
      "epoch: 57  batch: 9  loss: 0.19678207\n",
      "epoch: 57  batch: 10  loss: 0.22867402\n",
      "epoch: 57  batch: 11  loss: 0.32473236\n",
      "epoch: 57  batch: 12  loss: 0.17002687\n",
      "epoch: 57  batch: 13  loss: 0.11353704\n",
      "epoch: 57  batch: 14  loss: 0.13206932\n",
      "epoch: 57  batch: 15  loss: 0.11600323\n",
      "epoch: 57  batch: 16  loss: 0.08907874\n",
      "epoch: 57  batch: 17  loss: 0.13324906\n",
      "epoch: 57  batch: 18  loss: 0.05541839\n",
      "epoch: 57  batch: 19  loss: 0.07048003\n",
      "epoch: 57  batch: 20  loss: 0.28520715\n",
      "epoch: 57  batch: 21  loss: 0.34435424\n",
      "epoch: 57  batch: 22  loss: 0.11736147\n",
      "epoch: 57  batch: 23  loss: 0.05416487\n",
      "epoch: 57  batch: 24  loss: 0.06115513\n",
      "epoch: 57  batch: 25  loss: 0.06629146\n",
      "epoch: 57  batch: 26  loss: 0.15417489\n",
      "epoch: 57  batch: 27  loss: 0.44922626\n",
      "epoch: 57  batch: 28  loss: 0.14807965\n",
      "epoch: 57  batch: 29  loss: 0.15911084\n",
      "epoch: 57  batch: 30  loss: 0.10536675\n",
      "epoch: 57  batch: 31  loss: 0.05233342\n",
      "epoch: 57  batch: 32  loss: 0.01915387\n",
      "epoch: 57  batch: 33  loss: 0.03842378\n",
      "epoch: 57  batch: 34  loss: 0.08350562\n",
      "epoch: 57  batch: 35  loss: 0.17288344\n",
      "epoch: 57  batch: 36  loss: 0.03820239\n",
      "epoch: 57  batch: 37  loss: 0.03845531\n",
      "epoch: 57  batch: 38  loss: 0.04091299\n",
      "epoch: 57  batch: 39  loss: 0.17872708\n",
      "epoch: 57  batch: 40  loss: 0.07399201\n",
      "epoch: 57  batch: 41  loss: 0.20212984\n",
      "epoch: 57  batch: 42  loss: 0.15444474\n",
      "epoch: 57  batch: 43  loss: 0.15373190\n",
      "epoch: 57  batch: 44  loss: 0.25661916\n",
      "epoch: 57  batch: 45  loss: 0.33655876\n",
      "epoch: 57  batch: 46  loss: 0.17642134\n",
      "epoch: 57  batch: 47  loss: 0.19801609\n",
      "epoch: 57  batch: 48  loss: 0.12628768\n",
      "epoch: 57  batch: 49  loss: 0.12951453\n",
      "epoch: 57  batch: 50  loss: 0.16750976\n",
      "epoch: 57  batch: 51  loss: 0.11554195\n",
      "epoch: 57  batch: 52  loss: 0.06347957\n",
      "epoch: 57  batch: 53  loss: 0.08496241\n",
      "epoch: 57  batch: 54  loss: 0.38486820\n",
      "epoch: 57  batch: 55  loss: 0.24020742\n",
      "epoch: 57  batch: 56  loss: 0.08845450\n",
      "epoch: 57  batch: 57  loss: 0.04507947\n",
      "epoch: 57  batch: 58  loss: 0.13105270\n",
      "epoch: 57  batch: 59  loss: 0.08884113\n",
      "epoch: 57  batch: 60  loss: 0.22038552\n",
      "epoch: 57  batch: 61  loss: 0.61615688\n",
      "epoch: 57  batch: 62  loss: 0.15279850\n",
      "epoch: 57  batch: 63  loss: 0.20403519\n",
      "epoch: 57  batch: 64  loss: 0.11505920\n",
      "epoch: 57  batch: 65  loss: 0.04051337\n",
      "epoch: 57  batch: 66  loss: 0.03879127\n",
      "epoch: 57  batch: 67  loss: 0.05735254\n",
      "epoch: 57  batch: 68  loss: 0.08761750\n",
      "epoch: 58  batch: 1  loss: 0.16232757\n",
      "epoch: 58  batch: 2  loss: 0.04259796\n",
      "epoch: 58  batch: 3  loss: 0.03803753\n",
      "epoch: 58  batch: 4  loss: 0.02947753\n",
      "epoch: 58  batch: 5  loss: 0.13197884\n",
      "epoch: 58  batch: 6  loss: 0.12266742\n",
      "epoch: 58  batch: 7  loss: 0.22251940\n",
      "epoch: 58  batch: 8  loss: 0.13187148\n",
      "epoch: 58  batch: 9  loss: 0.26452819\n",
      "epoch: 58  batch: 10  loss: 0.22234841\n",
      "epoch: 58  batch: 11  loss: 0.41334373\n",
      "epoch: 58  batch: 12  loss: 0.17859730\n",
      "epoch: 58  batch: 13  loss: 0.09767426\n",
      "epoch: 58  batch: 14  loss: 0.13506599\n",
      "epoch: 58  batch: 15  loss: 0.11600433\n",
      "epoch: 58  batch: 16  loss: 0.08869103\n",
      "epoch: 58  batch: 17  loss: 0.13104713\n",
      "epoch: 58  batch: 18  loss: 0.05034732\n",
      "epoch: 58  batch: 19  loss: 0.05014926\n",
      "epoch: 58  batch: 20  loss: 0.29095760\n",
      "epoch: 58  batch: 21  loss: 0.34306479\n",
      "epoch: 58  batch: 22  loss: 0.11962819\n",
      "epoch: 58  batch: 23  loss: 0.04997212\n",
      "epoch: 58  batch: 24  loss: 0.05643775\n",
      "epoch: 58  batch: 25  loss: 0.06544328\n",
      "epoch: 58  batch: 26  loss: 0.13773671\n",
      "epoch: 58  batch: 27  loss: 0.46459004\n",
      "epoch: 58  batch: 28  loss: 0.14069043\n",
      "epoch: 58  batch: 29  loss: 0.17802091\n",
      "epoch: 58  batch: 30  loss: 0.12855680\n",
      "epoch: 58  batch: 31  loss: 0.05563789\n",
      "epoch: 58  batch: 32  loss: 0.01653538\n",
      "epoch: 58  batch: 33  loss: 0.04225759\n",
      "epoch: 58  batch: 34  loss: 0.08374920\n",
      "epoch: 58  batch: 35  loss: 0.16195089\n",
      "epoch: 58  batch: 36  loss: 0.03810944\n",
      "epoch: 58  batch: 37  loss: 0.03440069\n",
      "epoch: 58  batch: 38  loss: 0.03982628\n",
      "epoch: 58  batch: 39  loss: 0.17466110\n",
      "epoch: 58  batch: 40  loss: 0.07416262\n",
      "epoch: 58  batch: 41  loss: 0.19562769\n",
      "epoch: 58  batch: 42  loss: 0.14163706\n",
      "epoch: 58  batch: 43  loss: 0.14616111\n",
      "epoch: 58  batch: 44  loss: 0.20863125\n",
      "epoch: 58  batch: 45  loss: 0.32986024\n",
      "epoch: 58  batch: 46  loss: 0.18154368\n",
      "epoch: 58  batch: 47  loss: 0.16852745\n",
      "epoch: 58  batch: 48  loss: 0.12444706\n",
      "epoch: 58  batch: 49  loss: 0.13654839\n",
      "epoch: 58  batch: 50  loss: 0.17229494\n",
      "epoch: 58  batch: 51  loss: 0.11856677\n",
      "epoch: 58  batch: 52  loss: 0.06290820\n",
      "epoch: 58  batch: 53  loss: 0.06883327\n",
      "epoch: 58  batch: 54  loss: 0.38214251\n",
      "epoch: 58  batch: 55  loss: 0.23771191\n",
      "epoch: 58  batch: 56  loss: 0.10675164\n",
      "epoch: 58  batch: 57  loss: 0.04337690\n",
      "epoch: 58  batch: 58  loss: 0.11866120\n",
      "epoch: 58  batch: 59  loss: 0.09104325\n",
      "epoch: 58  batch: 60  loss: 0.21406820\n",
      "epoch: 58  batch: 61  loss: 0.54272425\n",
      "epoch: 58  batch: 62  loss: 0.14511901\n",
      "epoch: 58  batch: 63  loss: 0.18459210\n",
      "epoch: 58  batch: 64  loss: 0.13840620\n",
      "epoch: 58  batch: 65  loss: 0.05197078\n",
      "epoch: 58  batch: 66  loss: 0.03908930\n",
      "epoch: 58  batch: 67  loss: 0.04870861\n",
      "epoch: 58  batch: 68  loss: 0.09017512\n",
      "epoch: 59  batch: 1  loss: 0.16172244\n",
      "epoch: 59  batch: 2  loss: 0.04347714\n",
      "epoch: 59  batch: 3  loss: 0.04041627\n",
      "epoch: 59  batch: 4  loss: 0.02960188\n",
      "epoch: 59  batch: 5  loss: 0.13920081\n",
      "epoch: 59  batch: 6  loss: 0.11477663\n",
      "epoch: 59  batch: 7  loss: 0.22319984\n",
      "epoch: 59  batch: 8  loss: 0.13607135\n",
      "epoch: 59  batch: 9  loss: 0.25123799\n",
      "epoch: 59  batch: 10  loss: 0.21758239\n",
      "epoch: 59  batch: 11  loss: 0.39520690\n",
      "epoch: 59  batch: 12  loss: 0.16893668\n",
      "epoch: 59  batch: 13  loss: 0.09728012\n",
      "epoch: 59  batch: 14  loss: 0.13076745\n",
      "epoch: 59  batch: 15  loss: 0.11509708\n",
      "epoch: 59  batch: 16  loss: 0.08818860\n",
      "epoch: 59  batch: 17  loss: 0.13583130\n",
      "epoch: 59  batch: 18  loss: 0.05222249\n",
      "epoch: 59  batch: 19  loss: 0.05808325\n",
      "epoch: 59  batch: 20  loss: 0.28946722\n",
      "epoch: 59  batch: 21  loss: 0.34816793\n",
      "epoch: 59  batch: 22  loss: 0.09979586\n",
      "epoch: 59  batch: 23  loss: 0.05352706\n",
      "epoch: 59  batch: 24  loss: 0.05511932\n",
      "epoch: 59  batch: 25  loss: 0.06153006\n",
      "epoch: 59  batch: 26  loss: 0.12476890\n",
      "epoch: 59  batch: 27  loss: 0.47805342\n",
      "epoch: 59  batch: 28  loss: 0.18846372\n",
      "epoch: 59  batch: 29  loss: 0.17218605\n",
      "epoch: 59  batch: 30  loss: 0.11996271\n",
      "epoch: 59  batch: 31  loss: 0.05322217\n",
      "epoch: 59  batch: 32  loss: 0.01737473\n",
      "epoch: 59  batch: 33  loss: 0.03568078\n",
      "epoch: 59  batch: 34  loss: 0.08394022\n",
      "epoch: 59  batch: 35  loss: 0.16019869\n",
      "epoch: 59  batch: 36  loss: 0.03988484\n",
      "epoch: 59  batch: 37  loss: 0.03731022\n",
      "epoch: 59  batch: 38  loss: 0.04177230\n",
      "epoch: 59  batch: 39  loss: 0.16915627\n",
      "epoch: 59  batch: 40  loss: 0.07298902\n",
      "epoch: 59  batch: 41  loss: 0.19839033\n",
      "epoch: 59  batch: 42  loss: 0.14962888\n",
      "epoch: 59  batch: 43  loss: 0.15353037\n",
      "epoch: 59  batch: 44  loss: 0.20743202\n",
      "epoch: 59  batch: 45  loss: 0.32909197\n",
      "epoch: 59  batch: 46  loss: 0.16940454\n",
      "epoch: 59  batch: 47  loss: 0.18127191\n",
      "epoch: 59  batch: 48  loss: 0.12647854\n",
      "epoch: 59  batch: 49  loss: 0.12762298\n",
      "epoch: 59  batch: 50  loss: 0.16730396\n",
      "epoch: 59  batch: 51  loss: 0.11765575\n",
      "epoch: 59  batch: 52  loss: 0.06272520\n",
      "epoch: 59  batch: 53  loss: 0.06970309\n",
      "epoch: 59  batch: 54  loss: 0.38260528\n",
      "epoch: 59  batch: 55  loss: 0.23723887\n",
      "epoch: 59  batch: 56  loss: 0.10760829\n",
      "epoch: 59  batch: 57  loss: 0.04341764\n",
      "epoch: 59  batch: 58  loss: 0.11715544\n",
      "epoch: 59  batch: 59  loss: 0.09166607\n",
      "epoch: 59  batch: 60  loss: 0.20825379\n",
      "epoch: 59  batch: 61  loss: 0.53346074\n",
      "epoch: 59  batch: 62  loss: 0.13318288\n",
      "epoch: 59  batch: 63  loss: 0.21248712\n",
      "epoch: 59  batch: 64  loss: 0.12524110\n",
      "epoch: 59  batch: 65  loss: 0.04870725\n",
      "epoch: 59  batch: 66  loss: 0.04037260\n",
      "epoch: 59  batch: 67  loss: 0.04813811\n",
      "epoch: 59  batch: 68  loss: 0.08707163\n",
      "epoch: 60  batch: 1  loss: 0.16083315\n",
      "epoch: 60  batch: 2  loss: 0.04565241\n",
      "epoch: 60  batch: 3  loss: 0.03958860\n",
      "epoch: 60  batch: 4  loss: 0.02806426\n",
      "epoch: 60  batch: 5  loss: 0.13848753\n",
      "epoch: 60  batch: 6  loss: 0.10841583\n",
      "epoch: 60  batch: 7  loss: 0.22132577\n",
      "epoch: 60  batch: 8  loss: 0.13421366\n",
      "epoch: 60  batch: 9  loss: 0.24322690\n",
      "epoch: 60  batch: 10  loss: 0.21839939\n",
      "epoch: 60  batch: 11  loss: 0.41169283\n",
      "epoch: 60  batch: 12  loss: 0.16289246\n",
      "epoch: 60  batch: 13  loss: 0.09117355\n",
      "epoch: 60  batch: 14  loss: 0.13351086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60  batch: 15  loss: 0.11293702\n",
      "epoch: 60  batch: 16  loss: 0.08379826\n",
      "epoch: 60  batch: 17  loss: 0.13142604\n",
      "epoch: 60  batch: 18  loss: 0.05211737\n",
      "epoch: 60  batch: 19  loss: 0.07325823\n",
      "epoch: 60  batch: 20  loss: 0.28873363\n",
      "epoch: 60  batch: 21  loss: 0.34479839\n",
      "epoch: 60  batch: 22  loss: 0.12454271\n",
      "epoch: 60  batch: 23  loss: 0.05057454\n",
      "epoch: 60  batch: 24  loss: 0.05905658\n",
      "epoch: 60  batch: 25  loss: 0.06100250\n",
      "epoch: 60  batch: 26  loss: 0.15792765\n",
      "epoch: 60  batch: 27  loss: 0.43082666\n",
      "epoch: 60  batch: 28  loss: 0.16654225\n",
      "epoch: 60  batch: 29  loss: 0.16490415\n",
      "epoch: 60  batch: 30  loss: 0.12312919\n",
      "epoch: 60  batch: 31  loss: 0.05153004\n",
      "epoch: 60  batch: 32  loss: 0.01619896\n",
      "epoch: 60  batch: 33  loss: 0.03710027\n",
      "epoch: 60  batch: 34  loss: 0.08174568\n",
      "epoch: 60  batch: 35  loss: 0.15973575\n",
      "epoch: 60  batch: 36  loss: 0.04018617\n",
      "epoch: 60  batch: 37  loss: 0.03675773\n",
      "epoch: 60  batch: 38  loss: 0.04450500\n",
      "epoch: 60  batch: 39  loss: 0.17957340\n",
      "epoch: 60  batch: 40  loss: 0.08014370\n",
      "epoch: 60  batch: 41  loss: 0.19370376\n",
      "epoch: 60  batch: 42  loss: 0.13304268\n",
      "epoch: 60  batch: 43  loss: 0.13759851\n",
      "epoch: 60  batch: 44  loss: 0.20897707\n",
      "epoch: 60  batch: 45  loss: 0.32095727\n",
      "epoch: 60  batch: 46  loss: 0.17714731\n",
      "epoch: 60  batch: 47  loss: 0.16799664\n",
      "epoch: 60  batch: 48  loss: 0.13008203\n",
      "epoch: 60  batch: 49  loss: 0.12209606\n",
      "epoch: 60  batch: 50  loss: 0.15800993\n",
      "epoch: 60  batch: 51  loss: 0.11911394\n",
      "epoch: 60  batch: 52  loss: 0.06097500\n",
      "epoch: 60  batch: 53  loss: 0.07246841\n",
      "epoch: 60  batch: 54  loss: 0.38786787\n",
      "epoch: 60  batch: 55  loss: 0.23694442\n",
      "epoch: 60  batch: 56  loss: 0.10479952\n",
      "epoch: 60  batch: 57  loss: 0.04123187\n",
      "epoch: 60  batch: 58  loss: 0.11926161\n",
      "epoch: 60  batch: 59  loss: 0.09215245\n",
      "epoch: 60  batch: 60  loss: 0.21277320\n",
      "epoch: 60  batch: 61  loss: 0.57531369\n",
      "epoch: 60  batch: 62  loss: 0.12746467\n",
      "epoch: 60  batch: 63  loss: 0.21350765\n",
      "epoch: 60  batch: 64  loss: 0.14168100\n",
      "epoch: 60  batch: 65  loss: 0.03869468\n",
      "epoch: 60  batch: 66  loss: 0.04030537\n",
      "epoch: 60  batch: 67  loss: 0.04881038\n",
      "epoch: 60  batch: 68  loss: 0.09486889\n",
      "epoch: 61  batch: 1  loss: 0.16123505\n",
      "epoch: 61  batch: 2  loss: 0.04711020\n",
      "epoch: 61  batch: 3  loss: 0.04813240\n",
      "epoch: 61  batch: 4  loss: 0.02770008\n",
      "epoch: 61  batch: 5  loss: 0.13428439\n",
      "epoch: 61  batch: 6  loss: 0.11268492\n",
      "epoch: 61  batch: 7  loss: 0.22582814\n",
      "epoch: 61  batch: 8  loss: 0.15692270\n",
      "epoch: 61  batch: 9  loss: 0.18646739\n",
      "epoch: 61  batch: 10  loss: 0.24610613\n",
      "epoch: 61  batch: 11  loss: 0.42416421\n",
      "epoch: 61  batch: 12  loss: 0.18327174\n",
      "epoch: 61  batch: 13  loss: 0.10197341\n",
      "epoch: 61  batch: 14  loss: 0.13286608\n",
      "epoch: 61  batch: 15  loss: 0.12171379\n",
      "epoch: 61  batch: 16  loss: 0.07989188\n",
      "epoch: 61  batch: 17  loss: 0.14304006\n",
      "epoch: 61  batch: 18  loss: 0.05914498\n",
      "epoch: 61  batch: 19  loss: 0.07678303\n",
      "epoch: 61  batch: 20  loss: 0.28896424\n",
      "epoch: 61  batch: 21  loss: 0.34243041\n",
      "epoch: 61  batch: 22  loss: 0.11176807\n",
      "epoch: 61  batch: 23  loss: 0.05117632\n",
      "epoch: 61  batch: 24  loss: 0.06952552\n",
      "epoch: 61  batch: 25  loss: 0.05982759\n",
      "epoch: 61  batch: 26  loss: 0.14532785\n",
      "epoch: 61  batch: 27  loss: 0.40540078\n",
      "epoch: 61  batch: 28  loss: 0.13184373\n",
      "epoch: 61  batch: 29  loss: 0.15739235\n",
      "epoch: 61  batch: 30  loss: 0.12456973\n",
      "epoch: 61  batch: 31  loss: 0.04807898\n",
      "epoch: 61  batch: 32  loss: 0.01698963\n",
      "epoch: 61  batch: 33  loss: 0.02654666\n",
      "epoch: 61  batch: 34  loss: 0.09455700\n",
      "epoch: 61  batch: 35  loss: 0.15859830\n",
      "epoch: 61  batch: 36  loss: 0.03974357\n",
      "epoch: 61  batch: 37  loss: 0.03597452\n",
      "epoch: 61  batch: 38  loss: 0.04265351\n",
      "epoch: 61  batch: 39  loss: 0.17403659\n",
      "epoch: 61  batch: 40  loss: 0.07607520\n",
      "epoch: 61  batch: 41  loss: 0.19233187\n",
      "epoch: 61  batch: 42  loss: 0.14120413\n",
      "epoch: 61  batch: 43  loss: 0.13763438\n",
      "epoch: 61  batch: 44  loss: 0.20106612\n",
      "epoch: 61  batch: 45  loss: 0.31664625\n",
      "epoch: 61  batch: 46  loss: 0.16928893\n",
      "epoch: 61  batch: 47  loss: 0.17823623\n",
      "epoch: 61  batch: 48  loss: 0.12599938\n",
      "epoch: 61  batch: 49  loss: 0.11783471\n",
      "epoch: 61  batch: 50  loss: 0.16290469\n",
      "epoch: 61  batch: 51  loss: 0.11791994\n",
      "epoch: 61  batch: 52  loss: 0.06210041\n",
      "epoch: 61  batch: 53  loss: 0.06812196\n",
      "epoch: 61  batch: 54  loss: 0.38607281\n",
      "epoch: 61  batch: 55  loss: 0.23612086\n",
      "epoch: 61  batch: 56  loss: 0.11232343\n",
      "epoch: 61  batch: 57  loss: 0.04164007\n",
      "epoch: 61  batch: 58  loss: 0.11715675\n",
      "epoch: 61  batch: 59  loss: 0.09312080\n",
      "epoch: 61  batch: 60  loss: 0.18899645\n",
      "epoch: 61  batch: 61  loss: 0.50739926\n",
      "epoch: 61  batch: 62  loss: 0.12619174\n",
      "epoch: 61  batch: 63  loss: 0.19837329\n",
      "epoch: 61  batch: 64  loss: 0.10249561\n",
      "epoch: 61  batch: 65  loss: 0.04668402\n",
      "epoch: 61  batch: 66  loss: 0.04131817\n",
      "epoch: 61  batch: 67  loss: 0.05300505\n",
      "epoch: 61  batch: 68  loss: 0.08557548\n",
      "epoch: 62  batch: 1  loss: 0.16048467\n",
      "epoch: 62  batch: 2  loss: 0.04706316\n",
      "epoch: 62  batch: 3  loss: 0.03740476\n",
      "epoch: 62  batch: 4  loss: 0.02747212\n",
      "epoch: 62  batch: 5  loss: 0.12395316\n",
      "epoch: 62  batch: 6  loss: 0.10800143\n",
      "epoch: 62  batch: 7  loss: 0.22523478\n",
      "epoch: 62  batch: 8  loss: 0.11292221\n",
      "epoch: 62  batch: 9  loss: 0.27835912\n",
      "epoch: 62  batch: 10  loss: 0.21315138\n",
      "epoch: 62  batch: 11  loss: 0.38985533\n",
      "epoch: 62  batch: 12  loss: 0.16704880\n",
      "epoch: 62  batch: 13  loss: 0.09749699\n",
      "epoch: 62  batch: 14  loss: 0.13840334\n",
      "epoch: 62  batch: 15  loss: 0.12600943\n",
      "epoch: 62  batch: 16  loss: 0.07842898\n",
      "epoch: 62  batch: 17  loss: 0.11983193\n",
      "epoch: 62  batch: 18  loss: 0.05447546\n",
      "epoch: 62  batch: 19  loss: 0.06501579\n",
      "epoch: 62  batch: 20  loss: 0.30599269\n",
      "epoch: 62  batch: 21  loss: 0.34512833\n",
      "epoch: 62  batch: 22  loss: 0.11635712\n",
      "epoch: 62  batch: 23  loss: 0.05101967\n",
      "epoch: 62  batch: 24  loss: 0.06729913\n",
      "epoch: 62  batch: 25  loss: 0.05980521\n",
      "epoch: 62  batch: 26  loss: 0.16789159\n",
      "epoch: 62  batch: 27  loss: 0.43584850\n",
      "epoch: 62  batch: 28  loss: 0.15660222\n",
      "epoch: 62  batch: 29  loss: 0.15579094\n",
      "epoch: 62  batch: 30  loss: 0.09025967\n",
      "epoch: 62  batch: 31  loss: 0.04535641\n",
      "epoch: 62  batch: 32  loss: 0.01853969\n",
      "epoch: 62  batch: 33  loss: 0.03311836\n",
      "epoch: 62  batch: 34  loss: 0.07937527\n",
      "epoch: 62  batch: 35  loss: 0.15857926\n",
      "epoch: 62  batch: 36  loss: 0.04034223\n",
      "epoch: 62  batch: 37  loss: 0.03646253\n",
      "epoch: 62  batch: 38  loss: 0.04625008\n",
      "epoch: 62  batch: 39  loss: 0.16027781\n",
      "epoch: 62  batch: 40  loss: 0.10088493\n",
      "epoch: 62  batch: 41  loss: 0.18962830\n",
      "epoch: 62  batch: 42  loss: 0.12877148\n",
      "epoch: 62  batch: 43  loss: 0.12627657\n",
      "epoch: 62  batch: 44  loss: 0.22269920\n",
      "epoch: 62  batch: 45  loss: 0.31768459\n",
      "epoch: 62  batch: 46  loss: 0.17064701\n",
      "epoch: 62  batch: 47  loss: 0.13680895\n",
      "epoch: 62  batch: 48  loss: 0.12190562\n",
      "epoch: 62  batch: 49  loss: 0.11878780\n",
      "epoch: 62  batch: 50  loss: 0.15701056\n",
      "epoch: 62  batch: 51  loss: 0.11656306\n",
      "epoch: 62  batch: 52  loss: 0.06364328\n",
      "epoch: 62  batch: 53  loss: 0.06995240\n",
      "epoch: 62  batch: 54  loss: 0.39563912\n",
      "epoch: 62  batch: 55  loss: 0.23559450\n",
      "epoch: 62  batch: 56  loss: 0.09085700\n",
      "epoch: 62  batch: 57  loss: 0.04369999\n",
      "epoch: 62  batch: 58  loss: 0.11196657\n",
      "epoch: 62  batch: 59  loss: 0.09391456\n",
      "epoch: 62  batch: 60  loss: 0.19053397\n",
      "epoch: 62  batch: 61  loss: 0.51261735\n",
      "epoch: 62  batch: 62  loss: 0.12686838\n",
      "epoch: 62  batch: 63  loss: 0.19703463\n",
      "epoch: 62  batch: 64  loss: 0.10553496\n",
      "epoch: 62  batch: 65  loss: 0.05221393\n",
      "epoch: 62  batch: 66  loss: 0.04241526\n",
      "epoch: 62  batch: 67  loss: 0.05277279\n",
      "epoch: 62  batch: 68  loss: 0.08678770\n",
      "epoch: 63  batch: 1  loss: 0.16751771\n",
      "epoch: 63  batch: 2  loss: 0.04688997\n",
      "epoch: 63  batch: 3  loss: 0.03846515\n",
      "epoch: 63  batch: 4  loss: 0.02742002\n",
      "epoch: 63  batch: 5  loss: 0.12452804\n",
      "epoch: 63  batch: 6  loss: 0.09901924\n",
      "epoch: 63  batch: 7  loss: 0.22147493\n",
      "epoch: 63  batch: 8  loss: 0.12064622\n",
      "epoch: 63  batch: 9  loss: 0.20729388\n",
      "epoch: 63  batch: 10  loss: 0.21524344\n",
      "epoch: 63  batch: 11  loss: 0.40546358\n",
      "epoch: 63  batch: 12  loss: 0.18095182\n",
      "epoch: 63  batch: 13  loss: 0.07704619\n",
      "epoch: 63  batch: 14  loss: 0.13229097\n",
      "epoch: 63  batch: 15  loss: 0.11100756\n",
      "epoch: 63  batch: 16  loss: 0.07354932\n",
      "epoch: 63  batch: 17  loss: 0.11454406\n",
      "epoch: 63  batch: 18  loss: 0.05203053\n",
      "epoch: 63  batch: 19  loss: 0.06224930\n",
      "epoch: 63  batch: 20  loss: 0.29498440\n",
      "epoch: 63  batch: 21  loss: 0.34631068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63  batch: 22  loss: 0.11582721\n",
      "epoch: 63  batch: 23  loss: 0.05090778\n",
      "epoch: 63  batch: 24  loss: 0.06546129\n",
      "epoch: 63  batch: 25  loss: 0.05992648\n",
      "epoch: 63  batch: 26  loss: 0.09517952\n",
      "epoch: 63  batch: 27  loss: 0.40888113\n",
      "epoch: 63  batch: 28  loss: 0.16364568\n",
      "epoch: 63  batch: 29  loss: 0.10928595\n",
      "epoch: 63  batch: 30  loss: 0.08998436\n",
      "epoch: 63  batch: 31  loss: 0.04592913\n",
      "epoch: 63  batch: 32  loss: 0.01846929\n",
      "epoch: 63  batch: 33  loss: 0.03285476\n",
      "epoch: 63  batch: 34  loss: 0.09405931\n",
      "epoch: 63  batch: 35  loss: 0.15621169\n",
      "epoch: 63  batch: 36  loss: 0.03897976\n",
      "epoch: 63  batch: 37  loss: 0.03496760\n",
      "epoch: 63  batch: 38  loss: 0.04402227\n",
      "epoch: 63  batch: 39  loss: 0.17646740\n",
      "epoch: 63  batch: 40  loss: 0.07188139\n",
      "epoch: 63  batch: 41  loss: 0.18640541\n",
      "epoch: 63  batch: 42  loss: 0.13174434\n",
      "epoch: 63  batch: 43  loss: 0.12949868\n",
      "epoch: 63  batch: 44  loss: 0.20069654\n",
      "epoch: 63  batch: 45  loss: 0.31163242\n",
      "epoch: 63  batch: 46  loss: 0.15120126\n",
      "epoch: 63  batch: 47  loss: 0.15237775\n",
      "epoch: 63  batch: 48  loss: 0.12417579\n",
      "epoch: 63  batch: 49  loss: 0.11706582\n",
      "epoch: 63  batch: 50  loss: 0.17599387\n",
      "epoch: 63  batch: 51  loss: 0.12135157\n",
      "epoch: 63  batch: 52  loss: 0.06606334\n",
      "epoch: 63  batch: 53  loss: 0.07086451\n",
      "epoch: 63  batch: 54  loss: 0.38410011\n",
      "epoch: 63  batch: 55  loss: 0.23593526\n",
      "epoch: 63  batch: 56  loss: 0.11450047\n",
      "epoch: 63  batch: 57  loss: 0.04152115\n",
      "epoch: 63  batch: 58  loss: 0.11382599\n",
      "epoch: 63  batch: 59  loss: 0.09681509\n",
      "epoch: 63  batch: 60  loss: 0.18054716\n",
      "epoch: 63  batch: 61  loss: 0.50036091\n",
      "epoch: 63  batch: 62  loss: 0.12234882\n",
      "epoch: 63  batch: 63  loss: 0.25937423\n",
      "epoch: 63  batch: 64  loss: 0.11562312\n",
      "epoch: 63  batch: 65  loss: 0.04365485\n",
      "epoch: 63  batch: 66  loss: 0.04293014\n",
      "epoch: 63  batch: 67  loss: 0.05252381\n",
      "epoch: 63  batch: 68  loss: 0.08372821\n",
      "epoch: 64  batch: 1  loss: 0.16087210\n",
      "epoch: 64  batch: 2  loss: 0.05731796\n",
      "epoch: 64  batch: 3  loss: 0.04021573\n",
      "epoch: 64  batch: 4  loss: 0.03000236\n",
      "epoch: 64  batch: 5  loss: 0.15443657\n",
      "epoch: 64  batch: 6  loss: 0.12525538\n",
      "epoch: 64  batch: 7  loss: 0.21035822\n",
      "epoch: 64  batch: 8  loss: 0.11614455\n",
      "epoch: 64  batch: 9  loss: 0.24918243\n",
      "epoch: 64  batch: 10  loss: 0.20635970\n",
      "epoch: 64  batch: 11  loss: 0.40315950\n",
      "epoch: 64  batch: 12  loss: 0.17085823\n",
      "epoch: 64  batch: 13  loss: 0.07147238\n",
      "epoch: 64  batch: 14  loss: 0.13421848\n",
      "epoch: 64  batch: 15  loss: 0.11287180\n",
      "epoch: 64  batch: 16  loss: 0.06277561\n",
      "epoch: 64  batch: 17  loss: 0.10944214\n",
      "epoch: 64  batch: 18  loss: 0.05902122\n",
      "epoch: 64  batch: 19  loss: 0.06684041\n",
      "epoch: 64  batch: 20  loss: 0.29139563\n",
      "epoch: 64  batch: 21  loss: 0.33664718\n",
      "epoch: 64  batch: 22  loss: 0.10853142\n",
      "epoch: 64  batch: 23  loss: 0.05095264\n",
      "epoch: 64  batch: 24  loss: 0.06789035\n",
      "epoch: 64  batch: 25  loss: 0.05896635\n",
      "epoch: 64  batch: 26  loss: 0.08546020\n",
      "epoch: 64  batch: 27  loss: 0.34979740\n",
      "epoch: 64  batch: 28  loss: 0.14940022\n",
      "epoch: 64  batch: 29  loss: 0.12765050\n",
      "epoch: 64  batch: 30  loss: 0.06886014\n",
      "epoch: 64  batch: 31  loss: 0.04368285\n",
      "epoch: 64  batch: 32  loss: 0.02046224\n",
      "epoch: 64  batch: 33  loss: 0.02496682\n",
      "epoch: 64  batch: 34  loss: 0.09571479\n",
      "epoch: 64  batch: 35  loss: 0.15427691\n",
      "epoch: 64  batch: 36  loss: 0.04094665\n",
      "epoch: 64  batch: 37  loss: 0.03688916\n",
      "epoch: 64  batch: 38  loss: 0.04477550\n",
      "epoch: 64  batch: 39  loss: 0.15699510\n",
      "epoch: 64  batch: 40  loss: 0.07169956\n",
      "epoch: 64  batch: 41  loss: 0.18498260\n",
      "epoch: 64  batch: 42  loss: 0.12233245\n",
      "epoch: 64  batch: 43  loss: 0.11982500\n",
      "epoch: 64  batch: 44  loss: 0.21621472\n",
      "epoch: 64  batch: 45  loss: 0.30436873\n",
      "epoch: 64  batch: 46  loss: 0.15681252\n",
      "epoch: 64  batch: 47  loss: 0.15542926\n",
      "epoch: 64  batch: 48  loss: 0.11885603\n",
      "epoch: 64  batch: 49  loss: 0.11787979\n",
      "epoch: 64  batch: 50  loss: 0.17876811\n",
      "epoch: 64  batch: 51  loss: 0.11596166\n",
      "epoch: 64  batch: 52  loss: 0.06431324\n",
      "epoch: 64  batch: 53  loss: 0.07664166\n",
      "epoch: 64  batch: 54  loss: 0.38668031\n",
      "epoch: 64  batch: 55  loss: 0.23497650\n",
      "epoch: 64  batch: 56  loss: 0.11773852\n",
      "epoch: 64  batch: 57  loss: 0.04162280\n",
      "epoch: 64  batch: 58  loss: 0.10674267\n",
      "epoch: 64  batch: 59  loss: 0.09956377\n",
      "epoch: 64  batch: 60  loss: 0.15472052\n",
      "epoch: 64  batch: 61  loss: 0.44553110\n",
      "epoch: 64  batch: 62  loss: 0.10346235\n",
      "epoch: 64  batch: 63  loss: 0.18123321\n",
      "epoch: 64  batch: 64  loss: 0.07616394\n",
      "epoch: 64  batch: 65  loss: 0.05937480\n",
      "epoch: 64  batch: 66  loss: 0.04562315\n",
      "epoch: 64  batch: 67  loss: 0.04863353\n",
      "epoch: 64  batch: 68  loss: 0.08302190\n",
      "epoch: 65  batch: 1  loss: 0.16016622\n",
      "epoch: 65  batch: 2  loss: 0.05965208\n",
      "epoch: 65  batch: 3  loss: 0.03168660\n",
      "epoch: 65  batch: 4  loss: 0.02819157\n",
      "epoch: 65  batch: 5  loss: 0.15372176\n",
      "epoch: 65  batch: 6  loss: 0.09052370\n",
      "epoch: 65  batch: 7  loss: 0.21134748\n",
      "epoch: 65  batch: 8  loss: 0.13680165\n",
      "epoch: 65  batch: 9  loss: 0.24687958\n",
      "epoch: 65  batch: 10  loss: 0.26952603\n",
      "epoch: 65  batch: 11  loss: 0.34286335\n",
      "epoch: 65  batch: 12  loss: 0.17097466\n",
      "epoch: 65  batch: 13  loss: 0.06216056\n",
      "epoch: 65  batch: 14  loss: 0.14800303\n",
      "epoch: 65  batch: 15  loss: 0.17850538\n",
      "epoch: 65  batch: 16  loss: 0.07081994\n",
      "epoch: 65  batch: 17  loss: 0.12496307\n",
      "epoch: 65  batch: 18  loss: 0.05306669\n",
      "epoch: 65  batch: 19  loss: 0.08115341\n",
      "epoch: 65  batch: 20  loss: 0.32650858\n",
      "epoch: 65  batch: 21  loss: 0.34395638\n",
      "epoch: 65  batch: 22  loss: 0.08973004\n",
      "epoch: 65  batch: 23  loss: 0.04940708\n",
      "epoch: 65  batch: 24  loss: 0.06931809\n",
      "epoch: 65  batch: 25  loss: 0.05732708\n",
      "epoch: 65  batch: 26  loss: 0.12136918\n",
      "epoch: 65  batch: 27  loss: 0.36985695\n",
      "epoch: 65  batch: 28  loss: 0.11729892\n",
      "epoch: 65  batch: 29  loss: 0.14334764\n",
      "epoch: 65  batch: 30  loss: 0.11226478\n",
      "epoch: 65  batch: 31  loss: 0.04101209\n",
      "epoch: 65  batch: 32  loss: 0.01654718\n",
      "epoch: 65  batch: 33  loss: 0.02437259\n",
      "epoch: 65  batch: 34  loss: 0.07798229\n",
      "epoch: 65  batch: 35  loss: 0.15319827\n",
      "epoch: 65  batch: 36  loss: 0.04176613\n",
      "epoch: 65  batch: 37  loss: 0.03568249\n",
      "epoch: 65  batch: 38  loss: 0.04536134\n",
      "epoch: 65  batch: 39  loss: 0.14920649\n",
      "epoch: 65  batch: 40  loss: 0.11924801\n",
      "epoch: 65  batch: 41  loss: 0.18110979\n",
      "epoch: 65  batch: 42  loss: 0.11809441\n",
      "epoch: 65  batch: 43  loss: 0.11212640\n",
      "epoch: 65  batch: 44  loss: 0.19614455\n",
      "epoch: 65  batch: 45  loss: 0.28749421\n",
      "epoch: 65  batch: 46  loss: 0.15206221\n",
      "epoch: 65  batch: 47  loss: 0.17299215\n",
      "epoch: 65  batch: 48  loss: 0.13603026\n",
      "epoch: 65  batch: 49  loss: 0.13827085\n",
      "epoch: 65  batch: 50  loss: 0.15341143\n",
      "epoch: 65  batch: 51  loss: 0.12540409\n",
      "epoch: 65  batch: 52  loss: 0.06622266\n",
      "epoch: 65  batch: 53  loss: 0.07604779\n",
      "epoch: 65  batch: 54  loss: 0.40594441\n",
      "epoch: 65  batch: 55  loss: 0.23153704\n",
      "epoch: 65  batch: 56  loss: 0.08239563\n",
      "epoch: 65  batch: 57  loss: 0.05517421\n",
      "epoch: 65  batch: 58  loss: 0.10365716\n",
      "epoch: 65  batch: 59  loss: 0.09498294\n",
      "epoch: 65  batch: 60  loss: 0.15892944\n",
      "epoch: 65  batch: 61  loss: 0.46811923\n",
      "epoch: 65  batch: 62  loss: 0.15083082\n",
      "epoch: 65  batch: 63  loss: 0.24361463\n",
      "epoch: 65  batch: 64  loss: 0.09636530\n",
      "epoch: 65  batch: 65  loss: 0.04487183\n",
      "epoch: 65  batch: 66  loss: 0.04222349\n",
      "epoch: 65  batch: 67  loss: 0.05361071\n",
      "epoch: 65  batch: 68  loss: 0.08796774\n",
      "epoch: 66  batch: 1  loss: 0.15634340\n",
      "epoch: 66  batch: 2  loss: 0.05077673\n",
      "epoch: 66  batch: 3  loss: 0.03423709\n",
      "epoch: 66  batch: 4  loss: 0.02830093\n",
      "epoch: 66  batch: 5  loss: 0.12493565\n",
      "epoch: 66  batch: 6  loss: 0.14470005\n",
      "epoch: 66  batch: 7  loss: 0.23153344\n",
      "epoch: 66  batch: 8  loss: 0.17104118\n",
      "epoch: 66  batch: 9  loss: 0.15984832\n",
      "epoch: 66  batch: 10  loss: 0.48069841\n",
      "epoch: 66  batch: 11  loss: 0.40782195\n",
      "epoch: 66  batch: 12  loss: 0.19807613\n",
      "epoch: 66  batch: 13  loss: 0.08296288\n",
      "epoch: 66  batch: 14  loss: 0.13970514\n",
      "epoch: 66  batch: 15  loss: 0.11813857\n",
      "epoch: 66  batch: 16  loss: 0.05651375\n",
      "epoch: 66  batch: 17  loss: 0.11634233\n",
      "epoch: 66  batch: 18  loss: 0.06559144\n",
      "epoch: 66  batch: 19  loss: 0.08494278\n",
      "epoch: 66  batch: 20  loss: 0.28044039\n",
      "epoch: 66  batch: 21  loss: 0.32991698\n",
      "epoch: 66  batch: 22  loss: 0.08986922\n",
      "epoch: 66  batch: 23  loss: 0.05927019\n",
      "epoch: 66  batch: 24  loss: 0.07400911\n",
      "epoch: 66  batch: 25  loss: 0.06211603\n",
      "epoch: 66  batch: 26  loss: 0.12909687\n",
      "epoch: 66  batch: 27  loss: 0.40440425\n",
      "epoch: 66  batch: 28  loss: 0.19094270\n",
      "epoch: 66  batch: 29  loss: 0.17805997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66  batch: 30  loss: 0.04580212\n",
      "epoch: 66  batch: 31  loss: 0.04082143\n",
      "epoch: 66  batch: 32  loss: 0.02251836\n",
      "epoch: 66  batch: 33  loss: 0.03084210\n",
      "epoch: 66  batch: 34  loss: 0.07520740\n",
      "epoch: 66  batch: 35  loss: 0.16298091\n",
      "epoch: 66  batch: 36  loss: 0.03860517\n",
      "epoch: 66  batch: 37  loss: 0.04349544\n",
      "epoch: 66  batch: 38  loss: 0.03976844\n",
      "epoch: 66  batch: 39  loss: 0.15904675\n",
      "epoch: 66  batch: 40  loss: 0.06816587\n",
      "epoch: 66  batch: 41  loss: 0.17813575\n",
      "epoch: 66  batch: 42  loss: 0.09893590\n",
      "epoch: 66  batch: 43  loss: 0.12617302\n",
      "epoch: 66  batch: 44  loss: 0.21964788\n",
      "epoch: 66  batch: 45  loss: 0.28783247\n",
      "epoch: 66  batch: 46  loss: 0.15970446\n",
      "epoch: 66  batch: 47  loss: 0.11342371\n",
      "epoch: 66  batch: 48  loss: 0.13399492\n",
      "epoch: 66  batch: 49  loss: 0.13601685\n",
      "epoch: 66  batch: 50  loss: 0.14188576\n",
      "epoch: 66  batch: 51  loss: 0.17850846\n",
      "epoch: 66  batch: 52  loss: 0.08620381\n",
      "epoch: 66  batch: 53  loss: 0.08678737\n",
      "epoch: 66  batch: 54  loss: 0.39833570\n",
      "epoch: 66  batch: 55  loss: 0.23140599\n",
      "epoch: 66  batch: 56  loss: 0.10313174\n",
      "epoch: 66  batch: 57  loss: 0.04202642\n",
      "epoch: 66  batch: 58  loss: 0.10940985\n",
      "epoch: 66  batch: 59  loss: 0.09609014\n",
      "epoch: 66  batch: 60  loss: 0.15611726\n",
      "epoch: 66  batch: 61  loss: 0.58273953\n",
      "epoch: 66  batch: 62  loss: 0.12391716\n",
      "epoch: 66  batch: 63  loss: 0.17957029\n",
      "epoch: 66  batch: 64  loss: 0.08313555\n",
      "epoch: 66  batch: 65  loss: 0.05668953\n",
      "epoch: 66  batch: 66  loss: 0.03750584\n",
      "epoch: 66  batch: 67  loss: 0.06149741\n",
      "epoch: 66  batch: 68  loss: 0.08960544\n",
      "epoch: 67  batch: 1  loss: 0.15204515\n",
      "epoch: 67  batch: 2  loss: 0.04836904\n",
      "epoch: 67  batch: 3  loss: 0.03945573\n",
      "epoch: 67  batch: 4  loss: 0.02809138\n",
      "epoch: 67  batch: 5  loss: 0.11232411\n",
      "epoch: 67  batch: 6  loss: 0.08816455\n",
      "epoch: 67  batch: 7  loss: 0.21919391\n",
      "epoch: 67  batch: 8  loss: 0.14294699\n",
      "epoch: 67  batch: 9  loss: 0.21457179\n",
      "epoch: 67  batch: 10  loss: 0.38191825\n",
      "epoch: 67  batch: 11  loss: 0.26279637\n",
      "epoch: 67  batch: 12  loss: 0.16037180\n",
      "epoch: 67  batch: 13  loss: 0.06360295\n",
      "epoch: 67  batch: 14  loss: 0.14370294\n",
      "epoch: 67  batch: 15  loss: 0.12609179\n",
      "epoch: 67  batch: 16  loss: 0.05382847\n",
      "epoch: 67  batch: 17  loss: 0.13938227\n",
      "epoch: 67  batch: 18  loss: 0.05894144\n",
      "epoch: 67  batch: 19  loss: 0.05564709\n",
      "epoch: 67  batch: 20  loss: 0.38184717\n",
      "epoch: 67  batch: 21  loss: 0.32881567\n",
      "epoch: 67  batch: 22  loss: 0.14249495\n",
      "epoch: 67  batch: 23  loss: 0.05217637\n",
      "epoch: 67  batch: 24  loss: 0.06260100\n",
      "epoch: 67  batch: 25  loss: 0.06166447\n",
      "epoch: 67  batch: 26  loss: 0.16742113\n",
      "epoch: 67  batch: 27  loss: 0.42416763\n",
      "epoch: 67  batch: 28  loss: 0.29119021\n",
      "epoch: 67  batch: 29  loss: 0.16749635\n",
      "epoch: 67  batch: 30  loss: 0.18959627\n",
      "epoch: 67  batch: 31  loss: 0.05633640\n",
      "epoch: 67  batch: 32  loss: 0.04295374\n",
      "epoch: 67  batch: 33  loss: 0.04118455\n",
      "epoch: 67  batch: 34  loss: 0.07764282\n",
      "epoch: 67  batch: 35  loss: 0.15391375\n",
      "epoch: 67  batch: 36  loss: 0.03976398\n",
      "epoch: 67  batch: 37  loss: 0.04334919\n",
      "epoch: 67  batch: 38  loss: 0.04912908\n",
      "epoch: 67  batch: 39  loss: 0.15320359\n",
      "epoch: 67  batch: 40  loss: 0.07688555\n",
      "epoch: 67  batch: 41  loss: 0.17550346\n",
      "epoch: 67  batch: 42  loss: 0.10514558\n",
      "epoch: 67  batch: 43  loss: 0.11860070\n",
      "epoch: 67  batch: 44  loss: 0.19263986\n",
      "epoch: 67  batch: 45  loss: 0.28453436\n",
      "epoch: 67  batch: 46  loss: 0.15133327\n",
      "epoch: 67  batch: 47  loss: 0.20833576\n",
      "epoch: 67  batch: 48  loss: 0.14148664\n",
      "epoch: 67  batch: 49  loss: 0.12663755\n",
      "epoch: 67  batch: 50  loss: 0.11728866\n",
      "epoch: 67  batch: 51  loss: 0.13604333\n",
      "epoch: 67  batch: 52  loss: 0.08495804\n",
      "epoch: 67  batch: 53  loss: 0.07463834\n",
      "epoch: 67  batch: 54  loss: 0.39617917\n",
      "epoch: 67  batch: 55  loss: 0.22752886\n",
      "epoch: 67  batch: 56  loss: 0.07570591\n",
      "epoch: 67  batch: 57  loss: 0.03940997\n",
      "epoch: 67  batch: 58  loss: 0.14165811\n",
      "epoch: 67  batch: 59  loss: 0.09613888\n",
      "epoch: 67  batch: 60  loss: 0.13722903\n",
      "epoch: 67  batch: 61  loss: 0.53515923\n",
      "epoch: 67  batch: 62  loss: 0.16219902\n",
      "epoch: 67  batch: 63  loss: 0.28162196\n",
      "epoch: 67  batch: 64  loss: 0.07537543\n",
      "epoch: 67  batch: 65  loss: 0.04554187\n",
      "epoch: 67  batch: 66  loss: 0.03949520\n",
      "epoch: 67  batch: 67  loss: 0.03691883\n",
      "epoch: 67  batch: 68  loss: 0.06584145\n",
      "epoch: 68  batch: 1  loss: 0.15403329\n",
      "epoch: 68  batch: 2  loss: 0.04625878\n",
      "epoch: 68  batch: 3  loss: 0.03681437\n",
      "epoch: 68  batch: 4  loss: 0.02936715\n",
      "epoch: 68  batch: 5  loss: 0.10861512\n",
      "epoch: 68  batch: 6  loss: 0.09086864\n",
      "epoch: 68  batch: 7  loss: 0.25811061\n",
      "epoch: 68  batch: 8  loss: 0.18084823\n",
      "epoch: 68  batch: 9  loss: 0.21301669\n",
      "epoch: 68  batch: 10  loss: 0.37268466\n",
      "epoch: 68  batch: 11  loss: 0.24090649\n",
      "epoch: 68  batch: 12  loss: 0.16090627\n",
      "epoch: 68  batch: 13  loss: 0.07994577\n",
      "epoch: 68  batch: 14  loss: 0.14005272\n",
      "epoch: 68  batch: 15  loss: 0.12954000\n",
      "epoch: 68  batch: 16  loss: 0.05712251\n",
      "epoch: 68  batch: 17  loss: 0.10127526\n",
      "epoch: 68  batch: 18  loss: 0.06813867\n",
      "epoch: 68  batch: 19  loss: 0.05325893\n",
      "epoch: 68  batch: 20  loss: 0.36959282\n",
      "epoch: 68  batch: 21  loss: 0.32242590\n",
      "epoch: 68  batch: 22  loss: 0.13215090\n",
      "epoch: 68  batch: 23  loss: 0.05115317\n",
      "epoch: 68  batch: 24  loss: 0.06341889\n",
      "epoch: 68  batch: 25  loss: 0.06301210\n",
      "epoch: 68  batch: 26  loss: 0.11412038\n",
      "epoch: 68  batch: 27  loss: 0.39275709\n",
      "epoch: 68  batch: 28  loss: 0.16391692\n",
      "epoch: 68  batch: 29  loss: 0.14979225\n",
      "epoch: 68  batch: 30  loss: 0.06877153\n",
      "epoch: 68  batch: 31  loss: 0.03500868\n",
      "epoch: 68  batch: 32  loss: 0.05881446\n",
      "epoch: 68  batch: 33  loss: 0.04194316\n",
      "epoch: 68  batch: 34  loss: 0.07343027\n",
      "epoch: 68  batch: 35  loss: 0.15010884\n",
      "epoch: 68  batch: 36  loss: 0.04182991\n",
      "epoch: 68  batch: 37  loss: 0.03653384\n",
      "epoch: 68  batch: 38  loss: 0.05844554\n",
      "epoch: 68  batch: 39  loss: 0.14703982\n",
      "epoch: 68  batch: 40  loss: 0.06939210\n",
      "epoch: 68  batch: 41  loss: 0.17725001\n",
      "epoch: 68  batch: 42  loss: 0.13516404\n",
      "epoch: 68  batch: 43  loss: 0.11714997\n",
      "epoch: 68  batch: 44  loss: 0.18665247\n",
      "epoch: 68  batch: 45  loss: 0.27758929\n",
      "epoch: 68  batch: 46  loss: 0.14532371\n",
      "epoch: 68  batch: 47  loss: 0.14697573\n",
      "epoch: 68  batch: 48  loss: 0.13584937\n",
      "epoch: 68  batch: 49  loss: 0.12658827\n",
      "epoch: 68  batch: 50  loss: 0.12292483\n",
      "epoch: 68  batch: 51  loss: 0.09455957\n",
      "epoch: 68  batch: 52  loss: 0.07829730\n",
      "epoch: 68  batch: 53  loss: 0.07456647\n",
      "epoch: 68  batch: 54  loss: 0.45888710\n",
      "epoch: 68  batch: 55  loss: 0.22561936\n",
      "epoch: 68  batch: 56  loss: 0.07531635\n",
      "epoch: 68  batch: 57  loss: 0.04056774\n",
      "epoch: 68  batch: 58  loss: 0.14066257\n",
      "epoch: 68  batch: 59  loss: 0.09902196\n",
      "epoch: 68  batch: 60  loss: 0.12233285\n",
      "epoch: 68  batch: 61  loss: 0.49401271\n",
      "epoch: 68  batch: 62  loss: 0.11247642\n",
      "epoch: 68  batch: 63  loss: 0.16332074\n",
      "epoch: 68  batch: 64  loss: 0.08204831\n",
      "epoch: 68  batch: 65  loss: 0.03597988\n",
      "epoch: 68  batch: 66  loss: 0.03968698\n",
      "epoch: 68  batch: 67  loss: 0.07460497\n",
      "epoch: 68  batch: 68  loss: 0.08259487\n",
      "epoch: 69  batch: 1  loss: 0.15385601\n",
      "epoch: 69  batch: 2  loss: 0.06067405\n",
      "epoch: 69  batch: 3  loss: 0.03750467\n",
      "epoch: 69  batch: 4  loss: 0.02912509\n",
      "epoch: 69  batch: 5  loss: 0.10960132\n",
      "epoch: 69  batch: 6  loss: 0.10359030\n",
      "epoch: 69  batch: 7  loss: 0.21163478\n",
      "epoch: 69  batch: 8  loss: 0.09844580\n",
      "epoch: 69  batch: 9  loss: 0.22624436\n",
      "epoch: 69  batch: 10  loss: 0.33539689\n",
      "epoch: 69  batch: 11  loss: 0.27522093\n",
      "epoch: 69  batch: 12  loss: 0.18891098\n",
      "epoch: 69  batch: 13  loss: 0.04901814\n",
      "epoch: 69  batch: 14  loss: 0.14728068\n",
      "epoch: 69  batch: 15  loss: 0.13137773\n",
      "epoch: 69  batch: 16  loss: 0.05687419\n",
      "epoch: 69  batch: 17  loss: 0.10279251\n",
      "epoch: 69  batch: 18  loss: 0.07538479\n",
      "epoch: 69  batch: 19  loss: 0.07355368\n",
      "epoch: 69  batch: 20  loss: 0.32027471\n",
      "epoch: 69  batch: 21  loss: 0.32061332\n",
      "epoch: 69  batch: 22  loss: 0.10948014\n",
      "epoch: 69  batch: 23  loss: 0.04952203\n",
      "epoch: 69  batch: 24  loss: 0.07270037\n",
      "epoch: 69  batch: 25  loss: 0.06095292\n",
      "epoch: 69  batch: 26  loss: 0.06760900\n",
      "epoch: 69  batch: 27  loss: 0.28218657\n",
      "epoch: 69  batch: 28  loss: 0.10763367\n",
      "epoch: 69  batch: 29  loss: 0.13044226\n",
      "epoch: 69  batch: 30  loss: 0.05095734\n",
      "epoch: 69  batch: 31  loss: 0.02984085\n",
      "epoch: 69  batch: 32  loss: 0.02470414\n",
      "epoch: 69  batch: 33  loss: 0.02103302\n",
      "epoch: 69  batch: 34  loss: 0.09802788\n",
      "epoch: 69  batch: 35  loss: 0.14717436\n",
      "epoch: 69  batch: 36  loss: 0.04195790\n",
      "epoch: 69  batch: 37  loss: 0.03964424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69  batch: 38  loss: 0.03982551\n",
      "epoch: 69  batch: 39  loss: 0.14218093\n",
      "epoch: 69  batch: 40  loss: 0.15977243\n",
      "epoch: 69  batch: 41  loss: 0.17310619\n",
      "epoch: 69  batch: 42  loss: 0.10819174\n",
      "epoch: 69  batch: 43  loss: 0.14285366\n",
      "epoch: 69  batch: 44  loss: 0.18777187\n",
      "epoch: 69  batch: 45  loss: 0.56718194\n",
      "epoch: 69  batch: 46  loss: 0.21143113\n",
      "epoch: 69  batch: 47  loss: 0.20102629\n",
      "epoch: 69  batch: 48  loss: 0.13408858\n",
      "epoch: 69  batch: 49  loss: 0.13653193\n",
      "epoch: 69  batch: 50  loss: 0.09835241\n",
      "epoch: 69  batch: 51  loss: 0.10003433\n",
      "epoch: 69  batch: 52  loss: 0.06533120\n",
      "epoch: 69  batch: 53  loss: 0.07013458\n",
      "epoch: 69  batch: 54  loss: 0.34792086\n",
      "epoch: 69  batch: 55  loss: 0.22533093\n",
      "epoch: 69  batch: 56  loss: 0.12464350\n",
      "epoch: 69  batch: 57  loss: 0.05445012\n",
      "epoch: 69  batch: 58  loss: 0.11036495\n",
      "epoch: 69  batch: 59  loss: 0.10633201\n",
      "epoch: 69  batch: 60  loss: 0.16541605\n",
      "epoch: 69  batch: 61  loss: 0.72489369\n",
      "epoch: 69  batch: 62  loss: 0.23477401\n",
      "epoch: 69  batch: 63  loss: 0.22804290\n",
      "epoch: 69  batch: 64  loss: 0.24571534\n",
      "epoch: 69  batch: 65  loss: 0.11048396\n",
      "epoch: 69  batch: 66  loss: 0.03629911\n",
      "epoch: 69  batch: 67  loss: 0.05877280\n",
      "epoch: 69  batch: 68  loss: 0.08783782\n",
      "epoch: 70  batch: 1  loss: 0.15633687\n",
      "epoch: 70  batch: 2  loss: 0.04658949\n",
      "epoch: 70  batch: 3  loss: 0.04784213\n",
      "epoch: 70  batch: 4  loss: 0.02973864\n",
      "epoch: 70  batch: 5  loss: 0.10601133\n",
      "epoch: 70  batch: 6  loss: 0.18915488\n",
      "epoch: 70  batch: 7  loss: 0.20019616\n",
      "epoch: 70  batch: 8  loss: 0.13615702\n",
      "epoch: 70  batch: 9  loss: 0.21337813\n",
      "epoch: 70  batch: 10  loss: 0.17922316\n",
      "epoch: 70  batch: 11  loss: 0.31067446\n",
      "epoch: 70  batch: 12  loss: 0.16019981\n",
      "epoch: 70  batch: 13  loss: 0.07106472\n",
      "epoch: 70  batch: 14  loss: 0.16518304\n",
      "epoch: 70  batch: 15  loss: 0.14067806\n",
      "epoch: 70  batch: 16  loss: 0.07692638\n",
      "epoch: 70  batch: 17  loss: 0.20489281\n",
      "epoch: 70  batch: 18  loss: 0.07689676\n",
      "epoch: 70  batch: 19  loss: 0.06625790\n",
      "epoch: 70  batch: 20  loss: 0.28417307\n",
      "epoch: 70  batch: 21  loss: 0.48692602\n",
      "epoch: 70  batch: 22  loss: 0.12043586\n",
      "epoch: 70  batch: 23  loss: 0.04572863\n",
      "epoch: 70  batch: 24  loss: 0.06708142\n",
      "epoch: 70  batch: 25  loss: 0.05874028\n",
      "epoch: 70  batch: 26  loss: 0.09237999\n",
      "epoch: 70  batch: 27  loss: 0.36848027\n",
      "epoch: 70  batch: 28  loss: 0.10991440\n",
      "epoch: 70  batch: 29  loss: 0.30750811\n",
      "epoch: 70  batch: 30  loss: 0.12050845\n",
      "epoch: 70  batch: 31  loss: 0.03764239\n",
      "epoch: 70  batch: 32  loss: 0.01538589\n",
      "epoch: 70  batch: 33  loss: 0.02239518\n",
      "epoch: 70  batch: 34  loss: 0.07607273\n",
      "epoch: 70  batch: 35  loss: 0.15163282\n",
      "epoch: 70  batch: 36  loss: 0.04248195\n",
      "epoch: 70  batch: 37  loss: 0.03738934\n",
      "epoch: 70  batch: 38  loss: 0.04033019\n",
      "epoch: 70  batch: 39  loss: 0.20867823\n",
      "epoch: 70  batch: 40  loss: 0.06819072\n",
      "epoch: 70  batch: 41  loss: 0.17515457\n",
      "epoch: 70  batch: 42  loss: 0.12485062\n",
      "epoch: 70  batch: 43  loss: 0.12473281\n",
      "epoch: 70  batch: 44  loss: 0.18787573\n",
      "epoch: 70  batch: 45  loss: 0.28824592\n",
      "epoch: 70  batch: 46  loss: 0.16057403\n",
      "epoch: 70  batch: 47  loss: 0.21089593\n",
      "epoch: 70  batch: 48  loss: 0.13958347\n",
      "epoch: 70  batch: 49  loss: 0.14717509\n",
      "epoch: 70  batch: 50  loss: 0.20307508\n",
      "epoch: 70  batch: 51  loss: 0.13353707\n",
      "epoch: 70  batch: 52  loss: 0.05795258\n",
      "epoch: 70  batch: 53  loss: 0.07488327\n",
      "epoch: 70  batch: 54  loss: 0.35260472\n",
      "epoch: 70  batch: 55  loss: 0.22452435\n",
      "epoch: 70  batch: 56  loss: 0.07991488\n",
      "epoch: 70  batch: 57  loss: 0.04682235\n",
      "epoch: 70  batch: 58  loss: 0.11588425\n",
      "epoch: 70  batch: 59  loss: 0.09517134\n",
      "epoch: 70  batch: 60  loss: 0.17504846\n",
      "epoch: 70  batch: 61  loss: 0.29814315\n",
      "epoch: 70  batch: 62  loss: 0.21444410\n",
      "epoch: 70  batch: 63  loss: 0.31496489\n",
      "epoch: 70  batch: 64  loss: 0.18375389\n",
      "epoch: 70  batch: 65  loss: 0.04367914\n",
      "epoch: 70  batch: 66  loss: 0.04050303\n",
      "epoch: 70  batch: 67  loss: 0.03756743\n",
      "epoch: 70  batch: 68  loss: 0.08941214\n",
      "epoch: 71  batch: 1  loss: 0.14757596\n",
      "epoch: 71  batch: 2  loss: 0.04954464\n",
      "epoch: 71  batch: 3  loss: 0.03403621\n",
      "epoch: 71  batch: 4  loss: 0.03332295\n",
      "epoch: 71  batch: 5  loss: 0.09858864\n",
      "epoch: 71  batch: 6  loss: 0.31403938\n",
      "epoch: 71  batch: 7  loss: 0.37720045\n",
      "epoch: 71  batch: 8  loss: 0.14773466\n",
      "epoch: 71  batch: 9  loss: 0.20926332\n",
      "epoch: 71  batch: 10  loss: 0.16027349\n",
      "epoch: 71  batch: 11  loss: 0.23992722\n",
      "epoch: 71  batch: 12  loss: 0.15154131\n",
      "epoch: 71  batch: 13  loss: 0.04321662\n",
      "epoch: 71  batch: 14  loss: 0.16014142\n",
      "epoch: 71  batch: 15  loss: 0.14001366\n",
      "epoch: 71  batch: 16  loss: 0.09174693\n",
      "epoch: 71  batch: 17  loss: 0.09616309\n",
      "epoch: 71  batch: 18  loss: 0.05599459\n",
      "epoch: 71  batch: 19  loss: 0.06079174\n",
      "epoch: 71  batch: 20  loss: 0.29293132\n",
      "epoch: 71  batch: 21  loss: 0.33162349\n",
      "epoch: 71  batch: 22  loss: 0.10153563\n",
      "epoch: 71  batch: 23  loss: 0.04579052\n",
      "epoch: 71  batch: 24  loss: 0.07491753\n",
      "epoch: 71  batch: 25  loss: 0.06825253\n",
      "epoch: 71  batch: 26  loss: 0.09028916\n",
      "epoch: 71  batch: 27  loss: 0.52106833\n",
      "epoch: 71  batch: 28  loss: 0.10251772\n",
      "epoch: 71  batch: 29  loss: 0.25461394\n",
      "epoch: 71  batch: 30  loss: 0.21540968\n",
      "epoch: 71  batch: 31  loss: 0.04532668\n",
      "epoch: 71  batch: 32  loss: 0.01854855\n",
      "epoch: 71  batch: 33  loss: 0.01295352\n",
      "epoch: 71  batch: 34  loss: 0.09285367\n",
      "epoch: 71  batch: 35  loss: 0.15176074\n",
      "epoch: 71  batch: 36  loss: 0.04217082\n",
      "epoch: 71  batch: 37  loss: 0.03605719\n",
      "epoch: 71  batch: 38  loss: 0.03723627\n",
      "epoch: 71  batch: 39  loss: 0.15281296\n",
      "epoch: 71  batch: 40  loss: 0.08325696\n",
      "epoch: 71  batch: 41  loss: 0.17557468\n",
      "epoch: 71  batch: 42  loss: 0.11569496\n",
      "epoch: 71  batch: 43  loss: 0.13009706\n",
      "epoch: 71  batch: 44  loss: 0.16565292\n",
      "epoch: 71  batch: 45  loss: 0.25843665\n",
      "epoch: 71  batch: 46  loss: 0.15702541\n",
      "epoch: 71  batch: 47  loss: 0.16109280\n",
      "epoch: 71  batch: 48  loss: 0.13307044\n",
      "epoch: 71  batch: 49  loss: 0.12098967\n",
      "epoch: 71  batch: 50  loss: 0.17831381\n",
      "epoch: 71  batch: 51  loss: 0.12996402\n",
      "epoch: 71  batch: 52  loss: 0.06049965\n",
      "epoch: 71  batch: 53  loss: 0.08449948\n",
      "epoch: 71  batch: 54  loss: 0.35112923\n",
      "epoch: 71  batch: 55  loss: 0.22754818\n",
      "epoch: 71  batch: 56  loss: 0.08063134\n",
      "epoch: 71  batch: 57  loss: 0.05102532\n",
      "epoch: 71  batch: 58  loss: 0.11532371\n",
      "epoch: 71  batch: 59  loss: 0.09070083\n",
      "epoch: 71  batch: 60  loss: 0.15130304\n",
      "epoch: 71  batch: 61  loss: 0.42713907\n",
      "epoch: 71  batch: 62  loss: 0.21729158\n",
      "epoch: 71  batch: 63  loss: 0.31115991\n",
      "epoch: 71  batch: 64  loss: 0.21152005\n",
      "epoch: 71  batch: 65  loss: 0.08329733\n",
      "epoch: 71  batch: 66  loss: 0.03976211\n",
      "epoch: 71  batch: 67  loss: 0.08737157\n",
      "epoch: 71  batch: 68  loss: 0.07900008\n",
      "epoch: 72  batch: 1  loss: 0.14733046\n",
      "epoch: 72  batch: 2  loss: 0.04855109\n",
      "epoch: 72  batch: 3  loss: 0.04859320\n",
      "epoch: 72  batch: 4  loss: 0.06084228\n",
      "epoch: 72  batch: 5  loss: 0.10434772\n",
      "epoch: 72  batch: 6  loss: 0.40847024\n",
      "epoch: 72  batch: 7  loss: 0.28564110\n",
      "epoch: 72  batch: 8  loss: 0.10378985\n",
      "epoch: 72  batch: 9  loss: 0.18257616\n",
      "epoch: 72  batch: 10  loss: 0.24543564\n",
      "epoch: 72  batch: 11  loss: 0.29908231\n",
      "epoch: 72  batch: 12  loss: 0.14871027\n",
      "epoch: 72  batch: 13  loss: 0.04278928\n",
      "epoch: 72  batch: 14  loss: 0.15614966\n",
      "epoch: 72  batch: 15  loss: 0.12853000\n",
      "epoch: 72  batch: 16  loss: 0.06615105\n",
      "epoch: 72  batch: 17  loss: 0.08541166\n",
      "epoch: 72  batch: 18  loss: 0.10314939\n",
      "epoch: 72  batch: 19  loss: 0.04966648\n",
      "epoch: 72  batch: 20  loss: 0.28014290\n",
      "epoch: 72  batch: 21  loss: 0.32550499\n",
      "epoch: 72  batch: 22  loss: 0.15229024\n",
      "epoch: 72  batch: 23  loss: 0.04532450\n",
      "epoch: 72  batch: 24  loss: 0.06446541\n",
      "epoch: 72  batch: 25  loss: 0.07676263\n",
      "epoch: 72  batch: 26  loss: 0.05920445\n",
      "epoch: 72  batch: 27  loss: 0.35760269\n",
      "epoch: 72  batch: 28  loss: 0.14520876\n",
      "epoch: 72  batch: 29  loss: 0.33971617\n",
      "epoch: 72  batch: 30  loss: 0.12869012\n",
      "epoch: 72  batch: 31  loss: 0.05714794\n",
      "epoch: 72  batch: 32  loss: 0.04911056\n",
      "epoch: 72  batch: 33  loss: 0.13429289\n",
      "epoch: 72  batch: 34  loss: 0.08238126\n",
      "epoch: 72  batch: 35  loss: 0.15462981\n",
      "epoch: 72  batch: 36  loss: 0.04530642\n",
      "epoch: 72  batch: 37  loss: 0.03354070\n",
      "epoch: 72  batch: 38  loss: 0.03975722\n",
      "epoch: 72  batch: 39  loss: 0.14620078\n",
      "epoch: 72  batch: 40  loss: 0.12426636\n",
      "epoch: 72  batch: 41  loss: 0.18142127\n",
      "epoch: 72  batch: 42  loss: 0.09656068\n",
      "epoch: 72  batch: 43  loss: 0.15365888\n",
      "epoch: 72  batch: 44  loss: 0.19389978\n",
      "epoch: 72  batch: 45  loss: 0.28285480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72  batch: 46  loss: 0.16949649\n",
      "epoch: 72  batch: 47  loss: 0.17476963\n",
      "epoch: 72  batch: 48  loss: 0.13582408\n",
      "epoch: 72  batch: 49  loss: 0.12325945\n",
      "epoch: 72  batch: 50  loss: 0.12668774\n",
      "epoch: 72  batch: 51  loss: 0.10804630\n",
      "epoch: 72  batch: 52  loss: 0.05732927\n",
      "epoch: 72  batch: 53  loss: 0.07077196\n",
      "epoch: 72  batch: 54  loss: 0.41229239\n",
      "epoch: 72  batch: 55  loss: 0.22303104\n",
      "epoch: 72  batch: 56  loss: 0.10728344\n",
      "epoch: 72  batch: 57  loss: 0.04909407\n",
      "epoch: 72  batch: 58  loss: 0.12808177\n",
      "epoch: 72  batch: 59  loss: 0.10146260\n",
      "epoch: 72  batch: 60  loss: 0.12559931\n",
      "epoch: 72  batch: 61  loss: 0.43937463\n",
      "epoch: 72  batch: 62  loss: 0.21211353\n",
      "epoch: 72  batch: 63  loss: 0.26651511\n",
      "epoch: 72  batch: 64  loss: 0.13139664\n",
      "epoch: 72  batch: 65  loss: 0.04119802\n",
      "epoch: 72  batch: 66  loss: 0.03819292\n",
      "epoch: 72  batch: 67  loss: 0.03291210\n",
      "epoch: 72  batch: 68  loss: 0.06710463\n",
      "epoch: 73  batch: 1  loss: 0.21102682\n",
      "epoch: 73  batch: 2  loss: 0.04743122\n",
      "epoch: 73  batch: 3  loss: 0.05096971\n",
      "epoch: 73  batch: 4  loss: 0.03114475\n",
      "epoch: 73  batch: 5  loss: 0.09678717\n",
      "epoch: 73  batch: 6  loss: 0.10893756\n",
      "epoch: 73  batch: 7  loss: 0.31314504\n",
      "epoch: 73  batch: 8  loss: 0.09510911\n",
      "epoch: 73  batch: 9  loss: 0.17554966\n",
      "epoch: 73  batch: 10  loss: 0.19440433\n",
      "epoch: 73  batch: 11  loss: 0.27429077\n",
      "epoch: 73  batch: 12  loss: 0.17481934\n",
      "epoch: 73  batch: 13  loss: 0.05429496\n",
      "epoch: 73  batch: 14  loss: 0.15064086\n",
      "epoch: 73  batch: 15  loss: 0.12160087\n",
      "epoch: 73  batch: 16  loss: 0.06108389\n",
      "epoch: 73  batch: 17  loss: 0.08948843\n",
      "epoch: 73  batch: 18  loss: 0.05850621\n",
      "epoch: 73  batch: 19  loss: 0.09813663\n",
      "epoch: 73  batch: 20  loss: 0.27565283\n",
      "epoch: 73  batch: 21  loss: 0.32014546\n",
      "epoch: 73  batch: 22  loss: 0.10339718\n",
      "epoch: 73  batch: 23  loss: 0.04595119\n",
      "epoch: 73  batch: 24  loss: 0.11612480\n",
      "epoch: 73  batch: 25  loss: 0.06505833\n",
      "epoch: 73  batch: 26  loss: 0.06042874\n",
      "epoch: 73  batch: 27  loss: 0.30301565\n",
      "epoch: 73  batch: 28  loss: 0.12360118\n",
      "epoch: 73  batch: 29  loss: 0.12057839\n",
      "epoch: 73  batch: 30  loss: 0.15498005\n",
      "epoch: 73  batch: 31  loss: 0.04012553\n",
      "epoch: 73  batch: 32  loss: 0.01389465\n",
      "epoch: 73  batch: 33  loss: 0.01856346\n",
      "epoch: 73  batch: 34  loss: 0.08652698\n",
      "epoch: 73  batch: 35  loss: 0.15316395\n",
      "epoch: 73  batch: 36  loss: 0.04803440\n",
      "epoch: 73  batch: 37  loss: 0.04457849\n",
      "epoch: 73  batch: 38  loss: 0.04265057\n",
      "epoch: 73  batch: 39  loss: 0.14659265\n",
      "epoch: 73  batch: 40  loss: 0.12635842\n",
      "epoch: 73  batch: 41  loss: 0.17473041\n",
      "epoch: 73  batch: 42  loss: 0.10785438\n",
      "epoch: 73  batch: 43  loss: 0.11870918\n",
      "epoch: 73  batch: 44  loss: 0.19526376\n",
      "epoch: 73  batch: 45  loss: 0.40840033\n",
      "epoch: 73  batch: 46  loss: 0.17661703\n",
      "epoch: 73  batch: 47  loss: 0.11891104\n",
      "epoch: 73  batch: 48  loss: 0.13998011\n",
      "epoch: 73  batch: 49  loss: 0.14287774\n",
      "epoch: 73  batch: 50  loss: 0.10345586\n",
      "epoch: 73  batch: 51  loss: 0.11269240\n",
      "epoch: 73  batch: 52  loss: 0.08783052\n",
      "epoch: 73  batch: 53  loss: 0.12334240\n",
      "epoch: 73  batch: 54  loss: 0.34909895\n",
      "epoch: 73  batch: 55  loss: 0.22239693\n",
      "epoch: 73  batch: 56  loss: 0.08416162\n",
      "epoch: 73  batch: 57  loss: 0.05182057\n",
      "epoch: 73  batch: 58  loss: 0.09882247\n",
      "epoch: 73  batch: 59  loss: 0.11134282\n",
      "epoch: 73  batch: 60  loss: 0.12449598\n",
      "epoch: 73  batch: 61  loss: 0.74310261\n",
      "epoch: 73  batch: 62  loss: 0.19811575\n",
      "epoch: 73  batch: 63  loss: 0.21275052\n",
      "epoch: 73  batch: 64  loss: 0.29484624\n",
      "epoch: 73  batch: 65  loss: 0.06298321\n",
      "epoch: 73  batch: 66  loss: 0.03531654\n",
      "epoch: 73  batch: 67  loss: 0.03887596\n",
      "epoch: 73  batch: 68  loss: 0.06353298\n",
      "epoch: 74  batch: 1  loss: 0.15037777\n",
      "epoch: 74  batch: 2  loss: 0.04781630\n",
      "epoch: 74  batch: 3  loss: 0.03882650\n",
      "epoch: 74  batch: 4  loss: 0.03091265\n",
      "epoch: 74  batch: 5  loss: 0.09492937\n",
      "epoch: 74  batch: 6  loss: 0.32701433\n",
      "epoch: 74  batch: 7  loss: 0.21860303\n",
      "epoch: 74  batch: 8  loss: 0.14246614\n",
      "epoch: 74  batch: 9  loss: 0.17182197\n",
      "epoch: 74  batch: 10  loss: 0.22180375\n",
      "epoch: 74  batch: 11  loss: 0.25969666\n",
      "epoch: 74  batch: 12  loss: 0.14916468\n",
      "epoch: 74  batch: 13  loss: 0.04855693\n",
      "epoch: 74  batch: 14  loss: 0.15396103\n",
      "epoch: 74  batch: 15  loss: 0.13130260\n",
      "epoch: 74  batch: 16  loss: 0.06530850\n",
      "epoch: 74  batch: 17  loss: 0.07651947\n",
      "epoch: 74  batch: 18  loss: 0.06921934\n",
      "epoch: 74  batch: 19  loss: 0.05829308\n",
      "epoch: 74  batch: 20  loss: 0.31200600\n",
      "epoch: 74  batch: 21  loss: 0.31674516\n",
      "epoch: 74  batch: 22  loss: 0.14733194\n",
      "epoch: 74  batch: 23  loss: 0.04757056\n",
      "epoch: 74  batch: 24  loss: 0.06466496\n",
      "epoch: 74  batch: 25  loss: 0.07295655\n",
      "epoch: 74  batch: 26  loss: 0.05932639\n",
      "epoch: 74  batch: 27  loss: 0.35516727\n",
      "epoch: 74  batch: 28  loss: 0.11407706\n",
      "epoch: 74  batch: 29  loss: 0.24956968\n",
      "epoch: 74  batch: 30  loss: 0.09488074\n",
      "epoch: 74  batch: 31  loss: 0.03544999\n",
      "epoch: 74  batch: 32  loss: 0.02736394\n",
      "epoch: 74  batch: 33  loss: 0.01676461\n",
      "epoch: 74  batch: 34  loss: 0.07639470\n",
      "epoch: 74  batch: 35  loss: 0.15399456\n",
      "epoch: 74  batch: 36  loss: 0.04673645\n",
      "epoch: 74  batch: 37  loss: 0.04036336\n",
      "epoch: 74  batch: 38  loss: 0.03810955\n",
      "epoch: 74  batch: 39  loss: 0.14973746\n",
      "epoch: 74  batch: 40  loss: 0.07982041\n",
      "epoch: 74  batch: 41  loss: 0.17257051\n",
      "epoch: 74  batch: 42  loss: 0.10492033\n",
      "epoch: 74  batch: 43  loss: 0.16168217\n",
      "epoch: 74  batch: 44  loss: 0.16939393\n",
      "epoch: 74  batch: 45  loss: 0.27441815\n",
      "epoch: 74  batch: 46  loss: 0.15422294\n",
      "epoch: 74  batch: 47  loss: 0.13543385\n",
      "epoch: 74  batch: 48  loss: 0.14335717\n",
      "epoch: 74  batch: 49  loss: 0.12992473\n",
      "epoch: 74  batch: 50  loss: 0.10490545\n",
      "epoch: 74  batch: 51  loss: 0.09759884\n",
      "epoch: 74  batch: 52  loss: 0.10843457\n",
      "epoch: 74  batch: 53  loss: 0.07330935\n",
      "epoch: 74  batch: 54  loss: 0.34268168\n",
      "epoch: 74  batch: 55  loss: 0.22042495\n",
      "epoch: 74  batch: 56  loss: 0.11041610\n",
      "epoch: 74  batch: 57  loss: 0.04334811\n",
      "epoch: 74  batch: 58  loss: 0.12827457\n",
      "epoch: 74  batch: 59  loss: 0.10050318\n",
      "epoch: 74  batch: 60  loss: 0.06967080\n",
      "epoch: 74  batch: 61  loss: 0.29470804\n",
      "epoch: 74  batch: 62  loss: 0.21496998\n",
      "epoch: 74  batch: 63  loss: 0.25571582\n",
      "epoch: 74  batch: 64  loss: 0.09227762\n",
      "epoch: 74  batch: 65  loss: 0.03708911\n",
      "epoch: 74  batch: 66  loss: 0.03577062\n",
      "epoch: 74  batch: 67  loss: 0.02999025\n",
      "epoch: 74  batch: 68  loss: 0.07133722\n",
      "epoch: 75  batch: 1  loss: 0.19054757\n",
      "epoch: 75  batch: 2  loss: 0.04710944\n",
      "epoch: 75  batch: 3  loss: 0.04381089\n",
      "epoch: 75  batch: 4  loss: 0.03034790\n",
      "epoch: 75  batch: 5  loss: 0.09641980\n",
      "epoch: 75  batch: 6  loss: 0.18671677\n",
      "epoch: 75  batch: 7  loss: 0.28315020\n",
      "epoch: 75  batch: 8  loss: 0.13481440\n",
      "epoch: 75  batch: 9  loss: 0.23549087\n",
      "epoch: 75  batch: 10  loss: 0.15360314\n",
      "epoch: 75  batch: 11  loss: 0.22900032\n",
      "epoch: 75  batch: 12  loss: 0.16167456\n",
      "epoch: 75  batch: 13  loss: 0.03881321\n",
      "epoch: 75  batch: 14  loss: 0.15899061\n",
      "epoch: 75  batch: 15  loss: 0.12417231\n",
      "epoch: 75  batch: 16  loss: 0.07933167\n",
      "epoch: 75  batch: 17  loss: 0.09708883\n",
      "epoch: 75  batch: 18  loss: 0.05582050\n",
      "epoch: 75  batch: 19  loss: 0.04659961\n",
      "epoch: 75  batch: 20  loss: 0.27706239\n",
      "epoch: 75  batch: 21  loss: 0.31769055\n",
      "epoch: 75  batch: 22  loss: 0.10068033\n",
      "epoch: 75  batch: 23  loss: 0.04966791\n",
      "epoch: 75  batch: 24  loss: 0.06511424\n",
      "epoch: 75  batch: 25  loss: 0.06424025\n",
      "epoch: 75  batch: 26  loss: 0.03452435\n",
      "epoch: 75  batch: 27  loss: 0.30601326\n",
      "epoch: 75  batch: 28  loss: 0.19393171\n",
      "epoch: 75  batch: 29  loss: 0.13779669\n",
      "epoch: 75  batch: 30  loss: 0.10406971\n",
      "epoch: 75  batch: 31  loss: 0.05642568\n",
      "epoch: 75  batch: 32  loss: 0.01449820\n",
      "epoch: 75  batch: 33  loss: 0.06021313\n",
      "epoch: 75  batch: 34  loss: 0.09246720\n",
      "epoch: 75  batch: 35  loss: 0.15083364\n",
      "epoch: 75  batch: 36  loss: 0.05259713\n",
      "epoch: 75  batch: 37  loss: 0.04126170\n",
      "epoch: 75  batch: 38  loss: 0.04698835\n",
      "epoch: 75  batch: 39  loss: 0.14842342\n",
      "epoch: 75  batch: 40  loss: 0.06974229\n",
      "epoch: 75  batch: 41  loss: 0.16899510\n",
      "epoch: 75  batch: 42  loss: 0.11383565\n",
      "epoch: 75  batch: 43  loss: 0.11484010\n",
      "epoch: 75  batch: 44  loss: 0.15292683\n",
      "epoch: 75  batch: 45  loss: 0.23215392\n",
      "epoch: 75  batch: 46  loss: 0.11215433\n",
      "epoch: 75  batch: 47  loss: 0.10809140\n",
      "epoch: 75  batch: 48  loss: 0.14412674\n",
      "epoch: 75  batch: 49  loss: 0.12876584\n",
      "epoch: 75  batch: 50  loss: 0.07999741\n",
      "epoch: 75  batch: 51  loss: 0.11495098\n",
      "epoch: 75  batch: 52  loss: 0.09484764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75  batch: 53  loss: 0.08950429\n",
      "epoch: 75  batch: 54  loss: 0.35710442\n",
      "epoch: 75  batch: 55  loss: 0.21897936\n",
      "epoch: 75  batch: 56  loss: 0.07787557\n",
      "epoch: 75  batch: 57  loss: 0.04289823\n",
      "epoch: 75  batch: 58  loss: 0.10445017\n",
      "epoch: 75  batch: 59  loss: 0.09928131\n",
      "epoch: 75  batch: 60  loss: 0.05007618\n",
      "epoch: 75  batch: 61  loss: 0.24417850\n",
      "epoch: 75  batch: 62  loss: 0.21359652\n",
      "epoch: 75  batch: 63  loss: 0.20949359\n",
      "epoch: 75  batch: 64  loss: 0.25034109\n",
      "epoch: 75  batch: 65  loss: 0.04864652\n",
      "epoch: 75  batch: 66  loss: 0.03984641\n",
      "epoch: 75  batch: 67  loss: 0.04137602\n",
      "epoch: 75  batch: 68  loss: 0.06810505\n",
      "epoch: 76  batch: 1  loss: 0.15769282\n",
      "epoch: 76  batch: 2  loss: 0.04842997\n",
      "epoch: 76  batch: 3  loss: 0.03818843\n",
      "epoch: 76  batch: 4  loss: 0.03045953\n",
      "epoch: 76  batch: 5  loss: 0.10375477\n",
      "epoch: 76  batch: 6  loss: 0.07910710\n",
      "epoch: 76  batch: 7  loss: 0.23539159\n",
      "epoch: 76  batch: 8  loss: 0.09286576\n",
      "epoch: 76  batch: 9  loss: 0.13867466\n",
      "epoch: 76  batch: 10  loss: 0.19236374\n",
      "epoch: 76  batch: 11  loss: 0.25540864\n",
      "epoch: 76  batch: 12  loss: 0.20283242\n",
      "epoch: 76  batch: 13  loss: 0.04271621\n",
      "epoch: 76  batch: 14  loss: 0.14864047\n",
      "epoch: 76  batch: 15  loss: 0.13508943\n",
      "epoch: 76  batch: 16  loss: 0.06821451\n",
      "epoch: 76  batch: 17  loss: 0.13635132\n",
      "epoch: 76  batch: 18  loss: 0.09071126\n",
      "epoch: 76  batch: 19  loss: 0.05674475\n",
      "epoch: 76  batch: 20  loss: 0.28642160\n",
      "epoch: 76  batch: 21  loss: 0.38575712\n",
      "epoch: 76  batch: 22  loss: 0.12474552\n",
      "epoch: 76  batch: 23  loss: 0.04756201\n",
      "epoch: 76  batch: 24  loss: 0.07028984\n",
      "epoch: 76  batch: 25  loss: 0.05872283\n",
      "epoch: 76  batch: 26  loss: 0.05193948\n",
      "epoch: 76  batch: 27  loss: 0.24089973\n",
      "epoch: 76  batch: 28  loss: 0.04508047\n",
      "epoch: 76  batch: 29  loss: 0.13922557\n",
      "epoch: 76  batch: 30  loss: 0.03328083\n",
      "epoch: 76  batch: 31  loss: 0.03004940\n",
      "epoch: 76  batch: 32  loss: 0.01292533\n",
      "epoch: 76  batch: 33  loss: 0.01203887\n",
      "epoch: 76  batch: 34  loss: 0.09058955\n",
      "epoch: 76  batch: 35  loss: 0.14953484\n",
      "epoch: 76  batch: 36  loss: 0.05180470\n",
      "epoch: 76  batch: 37  loss: 0.03576997\n",
      "epoch: 76  batch: 38  loss: 0.04197681\n",
      "epoch: 76  batch: 39  loss: 0.14912257\n",
      "epoch: 76  batch: 40  loss: 0.06804911\n",
      "epoch: 76  batch: 41  loss: 0.16625489\n",
      "epoch: 76  batch: 42  loss: 0.12665240\n",
      "epoch: 76  batch: 43  loss: 0.11665847\n",
      "epoch: 76  batch: 44  loss: 0.16346219\n",
      "epoch: 76  batch: 45  loss: 0.19799316\n",
      "epoch: 76  batch: 46  loss: 0.14296375\n",
      "epoch: 76  batch: 47  loss: 0.21723381\n",
      "epoch: 76  batch: 48  loss: 0.15863454\n",
      "epoch: 76  batch: 49  loss: 0.12508242\n",
      "epoch: 76  batch: 50  loss: 0.11343750\n",
      "epoch: 76  batch: 51  loss: 0.09263488\n",
      "epoch: 76  batch: 52  loss: 0.12529653\n",
      "epoch: 76  batch: 53  loss: 0.07232159\n",
      "epoch: 76  batch: 54  loss: 0.33860686\n",
      "epoch: 76  batch: 55  loss: 0.21451648\n",
      "epoch: 76  batch: 56  loss: 0.07869895\n",
      "epoch: 76  batch: 57  loss: 0.04803550\n",
      "epoch: 76  batch: 58  loss: 0.09229980\n",
      "epoch: 76  batch: 59  loss: 0.10197900\n",
      "epoch: 76  batch: 60  loss: 0.04500860\n",
      "epoch: 76  batch: 61  loss: 0.15996423\n",
      "epoch: 76  batch: 62  loss: 0.19959122\n",
      "epoch: 76  batch: 63  loss: 0.09458705\n",
      "epoch: 76  batch: 64  loss: 0.24524403\n",
      "epoch: 76  batch: 65  loss: 0.04243011\n",
      "epoch: 76  batch: 66  loss: 0.03685480\n",
      "epoch: 76  batch: 67  loss: 0.02959098\n",
      "epoch: 76  batch: 68  loss: 0.06181946\n",
      "epoch: 77  batch: 1  loss: 0.14124410\n",
      "epoch: 77  batch: 2  loss: 0.05005525\n",
      "epoch: 77  batch: 3  loss: 0.04088522\n",
      "epoch: 77  batch: 4  loss: 0.03267782\n",
      "epoch: 77  batch: 5  loss: 0.09306832\n",
      "epoch: 77  batch: 6  loss: 0.07932768\n",
      "epoch: 77  batch: 7  loss: 0.19789319\n",
      "epoch: 77  batch: 8  loss: 0.08750411\n",
      "epoch: 77  batch: 9  loss: 0.13261934\n",
      "epoch: 77  batch: 10  loss: 0.13191958\n",
      "epoch: 77  batch: 11  loss: 0.21515563\n",
      "epoch: 77  batch: 12  loss: 0.15703918\n",
      "epoch: 77  batch: 13  loss: 0.07771308\n",
      "epoch: 77  batch: 14  loss: 0.14909111\n",
      "epoch: 77  batch: 15  loss: 0.14148565\n",
      "epoch: 77  batch: 16  loss: 0.08045039\n",
      "epoch: 77  batch: 17  loss: 0.08188523\n",
      "epoch: 77  batch: 18  loss: 0.08198600\n",
      "epoch: 77  batch: 19  loss: 0.07673705\n",
      "epoch: 77  batch: 20  loss: 0.26443389\n",
      "epoch: 77  batch: 21  loss: 0.30287710\n",
      "epoch: 77  batch: 22  loss: 0.08334237\n",
      "epoch: 77  batch: 23  loss: 0.04462979\n",
      "epoch: 77  batch: 24  loss: 0.06657552\n",
      "epoch: 77  batch: 25  loss: 0.06140432\n",
      "epoch: 77  batch: 26  loss: 0.04475965\n",
      "epoch: 77  batch: 27  loss: 0.17261666\n",
      "epoch: 77  batch: 28  loss: 0.02581894\n",
      "epoch: 77  batch: 29  loss: 0.12277818\n",
      "epoch: 77  batch: 30  loss: 0.13661996\n",
      "epoch: 77  batch: 31  loss: 0.02841383\n",
      "epoch: 77  batch: 32  loss: 0.01132704\n",
      "epoch: 77  batch: 33  loss: 0.00893143\n",
      "epoch: 77  batch: 34  loss: 0.08861890\n",
      "epoch: 77  batch: 35  loss: 0.15179197\n",
      "epoch: 77  batch: 36  loss: 0.05573270\n",
      "epoch: 77  batch: 37  loss: 0.04215429\n",
      "epoch: 77  batch: 38  loss: 0.03975358\n",
      "epoch: 77  batch: 39  loss: 0.13262147\n",
      "epoch: 77  batch: 40  loss: 0.06847128\n",
      "epoch: 77  batch: 41  loss: 0.16292796\n",
      "epoch: 77  batch: 42  loss: 0.11078059\n",
      "epoch: 77  batch: 43  loss: 0.08586694\n",
      "epoch: 77  batch: 44  loss: 0.17129929\n",
      "epoch: 77  batch: 45  loss: 0.19067426\n",
      "epoch: 77  batch: 46  loss: 0.13385794\n",
      "epoch: 77  batch: 47  loss: 0.30078170\n",
      "epoch: 77  batch: 48  loss: 0.16806899\n",
      "epoch: 77  batch: 49  loss: 0.12731391\n",
      "epoch: 77  batch: 50  loss: 0.21595702\n",
      "epoch: 77  batch: 51  loss: 0.12770467\n",
      "epoch: 77  batch: 52  loss: 0.05918867\n",
      "epoch: 77  batch: 53  loss: 0.11510514\n",
      "epoch: 77  batch: 54  loss: 0.33556664\n",
      "epoch: 77  batch: 55  loss: 0.21552260\n",
      "epoch: 77  batch: 56  loss: 0.08262458\n",
      "epoch: 77  batch: 57  loss: 0.06086692\n",
      "epoch: 77  batch: 58  loss: 0.10669959\n",
      "epoch: 77  batch: 59  loss: 0.10186377\n",
      "epoch: 77  batch: 60  loss: 0.22096387\n",
      "epoch: 77  batch: 61  loss: 0.34019178\n",
      "epoch: 77  batch: 62  loss: 0.26177126\n",
      "epoch: 77  batch: 63  loss: 0.07671049\n",
      "epoch: 77  batch: 64  loss: 0.13448228\n",
      "epoch: 77  batch: 65  loss: 0.08726250\n",
      "epoch: 77  batch: 66  loss: 0.04603301\n",
      "epoch: 77  batch: 67  loss: 0.03309136\n",
      "epoch: 77  batch: 68  loss: 0.06052285\n",
      "epoch: 78  batch: 1  loss: 0.13822997\n",
      "epoch: 78  batch: 2  loss: 0.04905062\n",
      "epoch: 78  batch: 3  loss: 0.03606532\n",
      "epoch: 78  batch: 4  loss: 0.03105560\n",
      "epoch: 78  batch: 5  loss: 0.09258521\n",
      "epoch: 78  batch: 6  loss: 0.07864370\n",
      "epoch: 78  batch: 7  loss: 0.26372421\n",
      "epoch: 78  batch: 8  loss: 0.21014866\n",
      "epoch: 78  batch: 9  loss: 0.16221045\n",
      "epoch: 78  batch: 10  loss: 0.17550723\n",
      "epoch: 78  batch: 11  loss: 0.19121560\n",
      "epoch: 78  batch: 12  loss: 0.13606919\n",
      "epoch: 78  batch: 13  loss: 0.07200748\n",
      "epoch: 78  batch: 14  loss: 0.15384626\n",
      "epoch: 78  batch: 15  loss: 0.14654270\n",
      "epoch: 78  batch: 16  loss: 0.06371793\n",
      "epoch: 78  batch: 17  loss: 0.06156154\n",
      "epoch: 78  batch: 18  loss: 0.07986634\n",
      "epoch: 78  batch: 19  loss: 0.04927004\n",
      "epoch: 78  batch: 20  loss: 0.26666877\n",
      "epoch: 78  batch: 21  loss: 0.30781898\n",
      "epoch: 78  batch: 22  loss: 0.07306994\n",
      "epoch: 78  batch: 23  loss: 0.04359729\n",
      "epoch: 78  batch: 24  loss: 0.06814077\n",
      "epoch: 78  batch: 25  loss: 0.07075490\n",
      "epoch: 78  batch: 26  loss: 0.03396610\n",
      "epoch: 78  batch: 27  loss: 0.15982527\n",
      "epoch: 78  batch: 28  loss: 0.02114982\n",
      "epoch: 78  batch: 29  loss: 0.07115217\n",
      "epoch: 78  batch: 30  loss: 0.14051297\n",
      "epoch: 78  batch: 31  loss: 0.05981469\n",
      "epoch: 78  batch: 32  loss: 0.01364432\n",
      "epoch: 78  batch: 33  loss: 0.00859722\n",
      "epoch: 78  batch: 34  loss: 0.09604918\n",
      "epoch: 78  batch: 35  loss: 0.17079544\n",
      "epoch: 78  batch: 36  loss: 0.05601104\n",
      "epoch: 78  batch: 37  loss: 0.03748693\n",
      "epoch: 78  batch: 38  loss: 0.24060357\n",
      "epoch: 78  batch: 39  loss: 0.13737968\n",
      "epoch: 78  batch: 40  loss: 0.08167293\n",
      "epoch: 78  batch: 41  loss: 0.16488472\n",
      "epoch: 78  batch: 42  loss: 0.08919515\n",
      "epoch: 78  batch: 43  loss: 0.08706769\n",
      "epoch: 78  batch: 44  loss: 0.14452247\n",
      "epoch: 78  batch: 45  loss: 0.21161817\n",
      "epoch: 78  batch: 46  loss: 0.18213975\n",
      "epoch: 78  batch: 47  loss: 0.25929838\n",
      "epoch: 78  batch: 48  loss: 0.16096327\n",
      "epoch: 78  batch: 49  loss: 0.12702058\n",
      "epoch: 78  batch: 50  loss: 0.10828437\n",
      "epoch: 78  batch: 51  loss: 0.10026415\n",
      "epoch: 78  batch: 52  loss: 0.09908421\n",
      "epoch: 78  batch: 53  loss: 0.11668601\n",
      "epoch: 78  batch: 54  loss: 0.32694861\n",
      "epoch: 78  batch: 55  loss: 0.21421196\n",
      "epoch: 78  batch: 56  loss: 0.08400614\n",
      "epoch: 78  batch: 57  loss: 0.06220955\n",
      "epoch: 78  batch: 58  loss: 0.10075918\n",
      "epoch: 78  batch: 59  loss: 0.11636072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78  batch: 60  loss: 0.05535252\n",
      "epoch: 78  batch: 61  loss: 0.27219772\n",
      "epoch: 78  batch: 62  loss: 0.21064208\n",
      "epoch: 78  batch: 63  loss: 0.20789160\n",
      "epoch: 78  batch: 64  loss: 0.11172543\n",
      "epoch: 78  batch: 65  loss: 0.08413241\n",
      "epoch: 78  batch: 66  loss: 0.03856070\n",
      "epoch: 78  batch: 67  loss: 0.02774915\n",
      "epoch: 78  batch: 68  loss: 0.06714522\n",
      "epoch: 79  batch: 1  loss: 0.16871062\n",
      "epoch: 79  batch: 2  loss: 0.05183396\n",
      "epoch: 79  batch: 3  loss: 0.04994156\n",
      "epoch: 79  batch: 4  loss: 0.03431249\n",
      "epoch: 79  batch: 5  loss: 0.09177549\n",
      "epoch: 79  batch: 6  loss: 0.07863769\n",
      "epoch: 79  batch: 7  loss: 0.18232746\n",
      "epoch: 79  batch: 8  loss: 0.10379753\n",
      "epoch: 79  batch: 9  loss: 0.14269884\n",
      "epoch: 79  batch: 10  loss: 0.19129565\n",
      "epoch: 79  batch: 11  loss: 0.19891898\n",
      "epoch: 79  batch: 12  loss: 0.14536986\n",
      "epoch: 79  batch: 13  loss: 0.03915523\n",
      "epoch: 79  batch: 14  loss: 0.15293264\n",
      "epoch: 79  batch: 15  loss: 0.12519984\n",
      "epoch: 79  batch: 16  loss: 0.06180554\n",
      "epoch: 79  batch: 17  loss: 0.06644266\n",
      "epoch: 79  batch: 18  loss: 0.05155233\n",
      "epoch: 79  batch: 19  loss: 0.05565581\n",
      "epoch: 79  batch: 20  loss: 0.34616426\n",
      "epoch: 79  batch: 21  loss: 0.30592960\n",
      "epoch: 79  batch: 22  loss: 0.15786257\n",
      "epoch: 79  batch: 23  loss: 0.05675833\n",
      "epoch: 79  batch: 24  loss: 0.07383792\n",
      "epoch: 79  batch: 25  loss: 0.05768618\n",
      "epoch: 79  batch: 26  loss: 0.03468401\n",
      "epoch: 79  batch: 27  loss: 0.12317105\n",
      "epoch: 79  batch: 28  loss: 0.02927474\n",
      "epoch: 79  batch: 29  loss: 0.16048920\n",
      "epoch: 79  batch: 30  loss: 0.02957374\n",
      "epoch: 79  batch: 31  loss: 0.02589088\n",
      "epoch: 79  batch: 32  loss: 0.01489821\n",
      "epoch: 79  batch: 33  loss: 0.01067938\n",
      "epoch: 79  batch: 34  loss: 0.08205672\n",
      "epoch: 79  batch: 35  loss: 0.15098585\n",
      "epoch: 79  batch: 36  loss: 0.05032861\n",
      "epoch: 79  batch: 37  loss: 0.05133193\n",
      "epoch: 79  batch: 38  loss: 0.03884398\n",
      "epoch: 79  batch: 39  loss: 0.13411963\n",
      "epoch: 79  batch: 40  loss: 0.06821962\n",
      "epoch: 79  batch: 41  loss: 0.16255574\n",
      "epoch: 79  batch: 42  loss: 0.09573012\n",
      "epoch: 79  batch: 43  loss: 0.11962988\n",
      "epoch: 79  batch: 44  loss: 0.14960177\n",
      "epoch: 79  batch: 45  loss: 0.26558009\n",
      "epoch: 79  batch: 46  loss: 0.13840976\n",
      "epoch: 79  batch: 47  loss: 0.16850385\n",
      "epoch: 79  batch: 48  loss: 0.16368400\n",
      "epoch: 79  batch: 49  loss: 0.12532090\n",
      "epoch: 79  batch: 50  loss: 0.15548834\n",
      "epoch: 79  batch: 51  loss: 0.10950025\n",
      "epoch: 79  batch: 52  loss: 0.06398650\n",
      "epoch: 79  batch: 53  loss: 0.10701048\n",
      "epoch: 79  batch: 54  loss: 0.34017533\n",
      "epoch: 79  batch: 55  loss: 0.21563028\n",
      "epoch: 79  batch: 56  loss: 0.07653760\n",
      "epoch: 79  batch: 57  loss: 0.06278870\n",
      "epoch: 79  batch: 58  loss: 0.09213851\n",
      "epoch: 79  batch: 59  loss: 0.11578745\n",
      "epoch: 79  batch: 60  loss: 0.04596266\n",
      "epoch: 79  batch: 61  loss: 0.54164267\n",
      "epoch: 79  batch: 62  loss: 0.28610051\n",
      "epoch: 79  batch: 63  loss: 0.12447396\n",
      "epoch: 79  batch: 64  loss: 0.26575428\n",
      "epoch: 79  batch: 65  loss: 0.05965046\n",
      "epoch: 79  batch: 66  loss: 0.07510296\n",
      "epoch: 79  batch: 67  loss: 0.31338638\n",
      "epoch: 79  batch: 68  loss: 0.13796872\n",
      "epoch: 80  batch: 1  loss: 0.29480332\n",
      "epoch: 80  batch: 2  loss: 0.06196491\n",
      "epoch: 80  batch: 3  loss: 0.05412035\n",
      "epoch: 80  batch: 4  loss: 0.03451501\n",
      "epoch: 80  batch: 5  loss: 0.09006538\n",
      "epoch: 80  batch: 6  loss: 0.07585567\n",
      "epoch: 80  batch: 7  loss: 0.47325230\n",
      "epoch: 80  batch: 8  loss: 0.07073548\n",
      "epoch: 80  batch: 9  loss: 0.10553409\n",
      "epoch: 80  batch: 10  loss: 0.84408891\n",
      "epoch: 80  batch: 11  loss: 0.28578433\n",
      "epoch: 80  batch: 12  loss: 0.15706719\n",
      "epoch: 80  batch: 13  loss: 0.20954536\n",
      "epoch: 80  batch: 14  loss: 0.16333674\n",
      "epoch: 80  batch: 15  loss: 0.12889358\n",
      "epoch: 80  batch: 16  loss: 0.09523348\n",
      "epoch: 80  batch: 17  loss: 0.30494109\n",
      "epoch: 80  batch: 18  loss: 0.13056237\n",
      "epoch: 80  batch: 19  loss: 0.04875429\n",
      "epoch: 80  batch: 20  loss: 0.24837884\n",
      "epoch: 80  batch: 21  loss: 0.31058124\n",
      "epoch: 80  batch: 22  loss: 0.07092503\n",
      "epoch: 80  batch: 23  loss: 0.05263309\n",
      "epoch: 80  batch: 24  loss: 0.07266369\n",
      "epoch: 80  batch: 25  loss: 0.06575245\n",
      "epoch: 80  batch: 26  loss: 0.31740335\n",
      "epoch: 80  batch: 27  loss: 0.65548074\n",
      "epoch: 80  batch: 28  loss: 0.20561841\n",
      "epoch: 80  batch: 29  loss: 0.16126771\n",
      "epoch: 80  batch: 30  loss: 0.25467750\n",
      "epoch: 80  batch: 31  loss: 0.06393615\n",
      "epoch: 80  batch: 32  loss: 0.01721243\n",
      "epoch: 80  batch: 33  loss: 0.02205803\n",
      "epoch: 80  batch: 34  loss: 0.11234504\n",
      "epoch: 80  batch: 35  loss: 0.14824469\n",
      "epoch: 80  batch: 36  loss: 0.05169990\n",
      "epoch: 80  batch: 37  loss: 0.04486191\n",
      "epoch: 80  batch: 38  loss: 0.04477377\n",
      "epoch: 80  batch: 39  loss: 0.18080536\n",
      "epoch: 80  batch: 40  loss: 0.07250836\n",
      "epoch: 80  batch: 41  loss: 0.17421727\n",
      "epoch: 80  batch: 42  loss: 0.09956387\n",
      "epoch: 80  batch: 43  loss: 0.14245403\n",
      "epoch: 80  batch: 44  loss: 0.27512592\n",
      "epoch: 80  batch: 45  loss: 0.23527299\n",
      "epoch: 80  batch: 46  loss: 0.16053268\n",
      "epoch: 80  batch: 47  loss: 0.13142912\n",
      "epoch: 80  batch: 48  loss: 0.16968605\n",
      "epoch: 80  batch: 49  loss: 0.13293813\n",
      "epoch: 80  batch: 50  loss: 0.16818373\n",
      "epoch: 80  batch: 51  loss: 0.08565885\n",
      "epoch: 80  batch: 52  loss: 0.06145143\n",
      "epoch: 80  batch: 53  loss: 0.09281857\n",
      "epoch: 80  batch: 54  loss: 0.33586001\n",
      "epoch: 80  batch: 55  loss: 0.21418652\n",
      "epoch: 80  batch: 56  loss: 0.07800432\n",
      "epoch: 80  batch: 57  loss: 0.05873888\n",
      "epoch: 80  batch: 58  loss: 0.10329008\n",
      "epoch: 80  batch: 59  loss: 0.09838697\n",
      "epoch: 80  batch: 60  loss: 0.18650903\n",
      "epoch: 80  batch: 61  loss: 0.39797491\n",
      "epoch: 80  batch: 62  loss: 0.23898940\n",
      "epoch: 80  batch: 63  loss: 0.21454866\n",
      "epoch: 80  batch: 64  loss: 0.19344866\n",
      "epoch: 80  batch: 65  loss: 0.04084735\n",
      "epoch: 80  batch: 66  loss: 0.04199576\n",
      "epoch: 80  batch: 67  loss: 0.02962664\n",
      "epoch: 80  batch: 68  loss: 0.06610012\n",
      "epoch: 81  batch: 1  loss: 0.14183180\n",
      "epoch: 81  batch: 2  loss: 0.05022467\n",
      "epoch: 81  batch: 3  loss: 0.04913079\n",
      "epoch: 81  batch: 4  loss: 0.03570048\n",
      "epoch: 81  batch: 5  loss: 0.09711995\n",
      "epoch: 81  batch: 6  loss: 0.08757204\n",
      "epoch: 81  batch: 7  loss: 0.18921424\n",
      "epoch: 81  batch: 8  loss: 0.08985851\n",
      "epoch: 81  batch: 9  loss: 0.12556466\n",
      "epoch: 81  batch: 10  loss: 0.70774943\n",
      "epoch: 81  batch: 11  loss: 0.55140215\n",
      "epoch: 81  batch: 12  loss: 0.13736524\n",
      "epoch: 81  batch: 13  loss: 0.05238754\n",
      "epoch: 81  batch: 14  loss: 0.14710286\n",
      "epoch: 81  batch: 15  loss: 0.11929916\n",
      "epoch: 81  batch: 16  loss: 0.06717090\n",
      "epoch: 81  batch: 17  loss: 0.19892301\n",
      "epoch: 81  batch: 18  loss: 0.10567127\n",
      "epoch: 81  batch: 19  loss: 0.04283946\n",
      "epoch: 81  batch: 20  loss: 0.26435733\n",
      "epoch: 81  batch: 21  loss: 0.38705650\n",
      "epoch: 81  batch: 22  loss: 0.06866451\n",
      "epoch: 81  batch: 23  loss: 0.05642983\n",
      "epoch: 81  batch: 24  loss: 0.06804737\n",
      "epoch: 81  batch: 25  loss: 0.05253137\n",
      "epoch: 81  batch: 26  loss: 0.20372052\n",
      "epoch: 81  batch: 27  loss: 0.27472246\n",
      "epoch: 81  batch: 28  loss: 0.07244437\n",
      "epoch: 81  batch: 29  loss: 0.05048250\n",
      "epoch: 81  batch: 30  loss: 0.10781382\n",
      "epoch: 81  batch: 31  loss: 0.02988536\n",
      "epoch: 81  batch: 32  loss: 0.02589870\n",
      "epoch: 81  batch: 33  loss: 0.01184350\n",
      "epoch: 81  batch: 34  loss: 0.07360373\n",
      "epoch: 81  batch: 35  loss: 0.15071277\n",
      "epoch: 81  batch: 36  loss: 0.04414028\n",
      "epoch: 81  batch: 37  loss: 0.04803386\n",
      "epoch: 81  batch: 38  loss: 0.04409771\n",
      "epoch: 81  batch: 39  loss: 0.16865997\n",
      "epoch: 81  batch: 40  loss: 0.08274885\n",
      "epoch: 81  batch: 41  loss: 0.17004545\n",
      "epoch: 81  batch: 42  loss: 0.11970696\n",
      "epoch: 81  batch: 43  loss: 0.11313967\n",
      "epoch: 81  batch: 44  loss: 0.15748318\n",
      "epoch: 81  batch: 45  loss: 0.22104433\n",
      "epoch: 81  batch: 46  loss: 0.18887854\n",
      "epoch: 81  batch: 47  loss: 0.11656693\n",
      "epoch: 81  batch: 48  loss: 0.15757920\n",
      "epoch: 81  batch: 49  loss: 0.12974727\n",
      "epoch: 81  batch: 50  loss: 0.22541057\n",
      "epoch: 81  batch: 51  loss: 0.07982802\n",
      "epoch: 81  batch: 52  loss: 0.06714594\n",
      "epoch: 81  batch: 53  loss: 0.09188067\n",
      "epoch: 81  batch: 54  loss: 0.39072579\n",
      "epoch: 81  batch: 55  loss: 0.25229657\n",
      "epoch: 81  batch: 56  loss: 0.07889486\n",
      "epoch: 81  batch: 57  loss: 0.05063609\n",
      "epoch: 81  batch: 58  loss: 0.08977337\n",
      "epoch: 81  batch: 59  loss: 0.10171367\n",
      "epoch: 81  batch: 60  loss: 0.13833925\n",
      "epoch: 81  batch: 61  loss: 0.30959138\n",
      "epoch: 81  batch: 62  loss: 0.19493695\n",
      "epoch: 81  batch: 63  loss: 0.25908414\n",
      "epoch: 81  batch: 64  loss: 0.25752208\n",
      "epoch: 81  batch: 65  loss: 0.04932870\n",
      "epoch: 81  batch: 66  loss: 0.04048198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81  batch: 67  loss: 0.02874660\n",
      "epoch: 81  batch: 68  loss: 0.06145630\n",
      "epoch: 82  batch: 1  loss: 0.15012902\n",
      "epoch: 82  batch: 2  loss: 0.04835812\n",
      "epoch: 82  batch: 3  loss: 0.03882504\n",
      "epoch: 82  batch: 4  loss: 0.03212027\n",
      "epoch: 82  batch: 5  loss: 0.09579392\n",
      "epoch: 82  batch: 6  loss: 0.07758556\n",
      "epoch: 82  batch: 7  loss: 0.19049670\n",
      "epoch: 82  batch: 8  loss: 0.07886288\n",
      "epoch: 82  batch: 9  loss: 0.15162693\n",
      "epoch: 82  batch: 10  loss: 0.40745911\n",
      "epoch: 82  batch: 11  loss: 0.26682037\n",
      "epoch: 82  batch: 12  loss: 0.13836026\n",
      "epoch: 82  batch: 13  loss: 0.03868630\n",
      "epoch: 82  batch: 14  loss: 0.14656870\n",
      "epoch: 82  batch: 15  loss: 0.11723915\n",
      "epoch: 82  batch: 16  loss: 0.07104494\n",
      "epoch: 82  batch: 17  loss: 0.13744043\n",
      "epoch: 82  batch: 18  loss: 0.09057812\n",
      "epoch: 82  batch: 19  loss: 0.04874758\n",
      "epoch: 82  batch: 20  loss: 0.27596691\n",
      "epoch: 82  batch: 21  loss: 0.41832021\n",
      "epoch: 82  batch: 22  loss: 0.07710996\n",
      "epoch: 82  batch: 23  loss: 0.05278356\n",
      "epoch: 82  batch: 24  loss: 0.06265204\n",
      "epoch: 82  batch: 25  loss: 0.05860116\n",
      "epoch: 82  batch: 26  loss: 0.04921015\n",
      "epoch: 82  batch: 27  loss: 0.18502168\n",
      "epoch: 82  batch: 28  loss: 0.04963247\n",
      "epoch: 82  batch: 29  loss: 0.02456308\n",
      "epoch: 82  batch: 30  loss: 0.03439052\n",
      "epoch: 82  batch: 31  loss: 0.05579919\n",
      "epoch: 82  batch: 32  loss: 0.03356704\n",
      "epoch: 82  batch: 33  loss: 0.01581591\n",
      "epoch: 82  batch: 34  loss: 0.07793193\n",
      "epoch: 82  batch: 35  loss: 0.15029083\n",
      "epoch: 82  batch: 36  loss: 0.04740506\n",
      "epoch: 82  batch: 37  loss: 0.03796109\n",
      "epoch: 82  batch: 38  loss: 0.04317707\n",
      "epoch: 82  batch: 39  loss: 0.16308486\n",
      "epoch: 82  batch: 40  loss: 0.07830510\n",
      "epoch: 82  batch: 41  loss: 0.17671317\n",
      "epoch: 82  batch: 42  loss: 0.09735313\n",
      "epoch: 82  batch: 43  loss: 0.10824828\n",
      "epoch: 82  batch: 44  loss: 0.15380834\n",
      "epoch: 82  batch: 45  loss: 0.23419495\n",
      "epoch: 82  batch: 46  loss: 0.11637767\n",
      "epoch: 82  batch: 47  loss: 0.10102773\n",
      "epoch: 82  batch: 48  loss: 0.15840359\n",
      "epoch: 82  batch: 49  loss: 0.12559485\n",
      "epoch: 82  batch: 50  loss: 0.10653640\n",
      "epoch: 82  batch: 51  loss: 0.07942130\n",
      "epoch: 82  batch: 52  loss: 0.06481590\n",
      "epoch: 82  batch: 53  loss: 0.07824226\n",
      "epoch: 82  batch: 54  loss: 0.33779326\n",
      "epoch: 82  batch: 55  loss: 0.21763614\n",
      "epoch: 82  batch: 56  loss: 0.07846847\n",
      "epoch: 82  batch: 57  loss: 0.05415202\n",
      "epoch: 82  batch: 58  loss: 0.10866804\n",
      "epoch: 82  batch: 59  loss: 0.10050176\n",
      "epoch: 82  batch: 60  loss: 0.05411059\n",
      "epoch: 82  batch: 61  loss: 0.17157650\n",
      "epoch: 82  batch: 62  loss: 0.20358692\n",
      "epoch: 82  batch: 63  loss: 0.06833826\n",
      "epoch: 82  batch: 64  loss: 0.20892535\n",
      "epoch: 82  batch: 65  loss: 0.03755747\n",
      "epoch: 82  batch: 66  loss: 0.03643097\n",
      "epoch: 82  batch: 67  loss: 0.02969366\n",
      "epoch: 82  batch: 68  loss: 0.06073271\n",
      "epoch: 83  batch: 1  loss: 0.13437076\n",
      "epoch: 83  batch: 2  loss: 0.05002676\n",
      "epoch: 83  batch: 3  loss: 0.04036367\n",
      "epoch: 83  batch: 4  loss: 0.03427375\n",
      "epoch: 83  batch: 5  loss: 0.09216744\n",
      "epoch: 83  batch: 6  loss: 0.07507032\n",
      "epoch: 83  batch: 7  loss: 0.19178461\n",
      "epoch: 83  batch: 8  loss: 0.07635014\n",
      "epoch: 83  batch: 9  loss: 0.13121703\n",
      "epoch: 83  batch: 10  loss: 0.27264372\n",
      "epoch: 83  batch: 11  loss: 0.21035396\n",
      "epoch: 83  batch: 12  loss: 0.12688039\n",
      "epoch: 83  batch: 13  loss: 0.04513421\n",
      "epoch: 83  batch: 14  loss: 0.14519069\n",
      "epoch: 83  batch: 15  loss: 0.12530315\n",
      "epoch: 83  batch: 16  loss: 0.06956978\n",
      "epoch: 83  batch: 17  loss: 0.08302822\n",
      "epoch: 83  batch: 18  loss: 0.08181756\n",
      "epoch: 83  batch: 19  loss: 0.05467964\n",
      "epoch: 83  batch: 20  loss: 0.25515467\n",
      "epoch: 83  batch: 21  loss: 0.34841597\n",
      "epoch: 83  batch: 22  loss: 0.06782100\n",
      "epoch: 83  batch: 23  loss: 0.04321966\n",
      "epoch: 83  batch: 24  loss: 0.06129003\n",
      "epoch: 83  batch: 25  loss: 0.06080030\n",
      "epoch: 83  batch: 26  loss: 0.02540810\n",
      "epoch: 83  batch: 27  loss: 0.13311465\n",
      "epoch: 83  batch: 28  loss: 0.03768237\n",
      "epoch: 83  batch: 29  loss: 0.02594601\n",
      "epoch: 83  batch: 30  loss: 0.03160504\n",
      "epoch: 83  batch: 31  loss: 0.08642057\n",
      "epoch: 83  batch: 32  loss: 0.01906224\n",
      "epoch: 83  batch: 33  loss: 0.01265512\n",
      "epoch: 83  batch: 34  loss: 0.08052419\n",
      "epoch: 83  batch: 35  loss: 0.14824452\n",
      "epoch: 83  batch: 36  loss: 0.05048665\n",
      "epoch: 83  batch: 37  loss: 0.04501532\n",
      "epoch: 83  batch: 38  loss: 0.03789850\n",
      "epoch: 83  batch: 39  loss: 0.14336486\n",
      "epoch: 83  batch: 40  loss: 0.06885567\n",
      "epoch: 83  batch: 41  loss: 0.16374004\n",
      "epoch: 83  batch: 42  loss: 0.09527560\n",
      "epoch: 83  batch: 43  loss: 0.09062625\n",
      "epoch: 83  batch: 44  loss: 0.13201782\n",
      "epoch: 83  batch: 45  loss: 0.20384204\n",
      "epoch: 83  batch: 46  loss: 0.11490570\n",
      "epoch: 83  batch: 47  loss: 0.10394223\n",
      "epoch: 83  batch: 48  loss: 0.16975313\n",
      "epoch: 83  batch: 49  loss: 0.13014561\n",
      "epoch: 83  batch: 50  loss: 0.09206543\n",
      "epoch: 83  batch: 51  loss: 0.11762207\n",
      "epoch: 83  batch: 52  loss: 0.06308229\n",
      "epoch: 83  batch: 53  loss: 0.07614753\n",
      "epoch: 83  batch: 54  loss: 0.32915455\n",
      "epoch: 83  batch: 55  loss: 0.21231413\n",
      "epoch: 83  batch: 56  loss: 0.07481865\n",
      "epoch: 83  batch: 57  loss: 0.06011993\n",
      "epoch: 83  batch: 58  loss: 0.10297955\n",
      "epoch: 83  batch: 59  loss: 0.10324843\n",
      "epoch: 83  batch: 60  loss: 0.05618326\n",
      "epoch: 83  batch: 61  loss: 0.14959221\n",
      "epoch: 83  batch: 62  loss: 0.20258974\n",
      "epoch: 83  batch: 63  loss: 0.04879197\n",
      "epoch: 83  batch: 64  loss: 0.21886753\n",
      "epoch: 83  batch: 65  loss: 0.03889692\n",
      "epoch: 83  batch: 66  loss: 0.04016713\n",
      "epoch: 83  batch: 67  loss: 0.03117444\n",
      "epoch: 83  batch: 68  loss: 0.05712327\n",
      "epoch: 84  batch: 1  loss: 0.13190061\n",
      "epoch: 84  batch: 2  loss: 0.05121456\n",
      "epoch: 84  batch: 3  loss: 0.04274390\n",
      "epoch: 84  batch: 4  loss: 0.03474587\n",
      "epoch: 84  batch: 5  loss: 0.08875117\n",
      "epoch: 84  batch: 6  loss: 0.07117187\n",
      "epoch: 84  batch: 7  loss: 0.20345256\n",
      "epoch: 84  batch: 8  loss: 0.07092959\n",
      "epoch: 84  batch: 9  loss: 0.12587933\n",
      "epoch: 84  batch: 10  loss: 0.19278647\n",
      "epoch: 84  batch: 11  loss: 0.18341494\n",
      "epoch: 84  batch: 12  loss: 0.11961884\n",
      "epoch: 84  batch: 13  loss: 0.05690969\n",
      "epoch: 84  batch: 14  loss: 0.14723778\n",
      "epoch: 84  batch: 15  loss: 0.11376338\n",
      "epoch: 84  batch: 16  loss: 0.06396669\n",
      "epoch: 84  batch: 17  loss: 0.06232914\n",
      "epoch: 84  batch: 18  loss: 0.08749432\n",
      "epoch: 84  batch: 19  loss: 0.06707667\n",
      "epoch: 84  batch: 20  loss: 0.25191823\n",
      "epoch: 84  batch: 21  loss: 0.36095387\n",
      "epoch: 84  batch: 22  loss: 0.06511629\n",
      "epoch: 84  batch: 23  loss: 0.05430963\n",
      "epoch: 84  batch: 24  loss: 0.06269420\n",
      "epoch: 84  batch: 25  loss: 0.06580466\n",
      "epoch: 84  batch: 26  loss: 0.02993018\n",
      "epoch: 84  batch: 27  loss: 0.12610334\n",
      "epoch: 84  batch: 28  loss: 0.02155079\n",
      "epoch: 84  batch: 29  loss: 0.03142773\n",
      "epoch: 84  batch: 30  loss: 0.02526145\n",
      "epoch: 84  batch: 31  loss: 0.02883465\n",
      "epoch: 84  batch: 32  loss: 0.01118397\n",
      "epoch: 84  batch: 33  loss: 0.01025015\n",
      "epoch: 84  batch: 34  loss: 0.08712638\n",
      "epoch: 84  batch: 35  loss: 0.14993443\n",
      "epoch: 84  batch: 36  loss: 0.05318927\n",
      "epoch: 84  batch: 37  loss: 0.04600428\n",
      "epoch: 84  batch: 38  loss: 0.04159159\n",
      "epoch: 84  batch: 39  loss: 0.13836102\n",
      "epoch: 84  batch: 40  loss: 0.06682102\n",
      "epoch: 84  batch: 41  loss: 0.16022725\n",
      "epoch: 84  batch: 42  loss: 0.08891962\n",
      "epoch: 84  batch: 43  loss: 0.08300768\n",
      "epoch: 84  batch: 44  loss: 0.13660592\n",
      "epoch: 84  batch: 45  loss: 0.20743765\n",
      "epoch: 84  batch: 46  loss: 0.10889819\n",
      "epoch: 84  batch: 47  loss: 0.17347889\n",
      "epoch: 84  batch: 48  loss: 0.17090714\n",
      "epoch: 84  batch: 49  loss: 0.12889403\n",
      "epoch: 84  batch: 50  loss: 0.08608466\n",
      "epoch: 84  batch: 51  loss: 0.08656579\n",
      "epoch: 84  batch: 52  loss: 0.05821374\n",
      "epoch: 84  batch: 53  loss: 0.06528984\n",
      "epoch: 84  batch: 54  loss: 0.32483602\n",
      "epoch: 84  batch: 55  loss: 0.21165891\n",
      "epoch: 84  batch: 56  loss: 0.07901188\n",
      "epoch: 84  batch: 57  loss: 0.06288130\n",
      "epoch: 84  batch: 58  loss: 0.10863387\n",
      "epoch: 84  batch: 59  loss: 0.10175730\n",
      "epoch: 84  batch: 60  loss: 0.04647481\n",
      "epoch: 84  batch: 61  loss: 0.11686777\n",
      "epoch: 84  batch: 62  loss: 0.22971971\n",
      "epoch: 84  batch: 63  loss: 0.04396339\n",
      "epoch: 84  batch: 64  loss: 0.19433238\n",
      "epoch: 84  batch: 65  loss: 0.03895377\n",
      "epoch: 84  batch: 66  loss: 0.04360121\n",
      "epoch: 84  batch: 67  loss: 0.03260519\n",
      "epoch: 84  batch: 68  loss: 0.05601712\n",
      "epoch: 85  batch: 1  loss: 0.13061224\n",
      "epoch: 85  batch: 2  loss: 0.05248320\n",
      "epoch: 85  batch: 3  loss: 0.04739064\n",
      "epoch: 85  batch: 4  loss: 0.03700390\n",
      "epoch: 85  batch: 5  loss: 0.08763428\n",
      "epoch: 85  batch: 6  loss: 0.07050799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85  batch: 7  loss: 0.18192163\n",
      "epoch: 85  batch: 8  loss: 0.06617297\n",
      "epoch: 85  batch: 9  loss: 0.10796922\n",
      "epoch: 85  batch: 10  loss: 0.17637937\n",
      "epoch: 85  batch: 11  loss: 0.16371255\n",
      "epoch: 85  batch: 12  loss: 0.11461599\n",
      "epoch: 85  batch: 13  loss: 0.04380787\n",
      "epoch: 85  batch: 14  loss: 0.15100975\n",
      "epoch: 85  batch: 15  loss: 0.11675180\n",
      "epoch: 85  batch: 16  loss: 0.07311164\n",
      "epoch: 85  batch: 17  loss: 0.05691805\n",
      "epoch: 85  batch: 18  loss: 0.08468134\n",
      "epoch: 85  batch: 19  loss: 0.04491648\n",
      "epoch: 85  batch: 20  loss: 0.24623613\n",
      "epoch: 85  batch: 21  loss: 0.32331032\n",
      "epoch: 85  batch: 22  loss: 0.07027336\n",
      "epoch: 85  batch: 23  loss: 0.04727508\n",
      "epoch: 85  batch: 24  loss: 0.06526554\n",
      "epoch: 85  batch: 25  loss: 0.06918125\n",
      "epoch: 85  batch: 26  loss: 0.02978152\n",
      "epoch: 85  batch: 27  loss: 0.06872306\n",
      "epoch: 85  batch: 28  loss: 0.05928544\n",
      "epoch: 85  batch: 29  loss: 0.02882847\n",
      "epoch: 85  batch: 30  loss: 0.01771137\n",
      "epoch: 85  batch: 31  loss: 0.02818127\n",
      "epoch: 85  batch: 32  loss: 0.02337644\n",
      "epoch: 85  batch: 33  loss: 0.00995484\n",
      "epoch: 85  batch: 34  loss: 0.08024850\n",
      "epoch: 85  batch: 35  loss: 0.14916670\n",
      "epoch: 85  batch: 36  loss: 0.05444352\n",
      "epoch: 85  batch: 37  loss: 0.04957795\n",
      "epoch: 85  batch: 38  loss: 0.04178966\n",
      "epoch: 85  batch: 39  loss: 0.12783426\n",
      "epoch: 85  batch: 40  loss: 0.07375120\n",
      "epoch: 85  batch: 41  loss: 0.16044664\n",
      "epoch: 85  batch: 42  loss: 0.07588077\n",
      "epoch: 85  batch: 43  loss: 0.08773930\n",
      "epoch: 85  batch: 44  loss: 0.12373066\n",
      "epoch: 85  batch: 45  loss: 0.19386548\n",
      "epoch: 85  batch: 46  loss: 0.13413751\n",
      "epoch: 85  batch: 47  loss: 0.11425221\n",
      "epoch: 85  batch: 48  loss: 0.17129426\n",
      "epoch: 85  batch: 49  loss: 0.13386090\n",
      "epoch: 85  batch: 50  loss: 0.07956789\n",
      "epoch: 85  batch: 51  loss: 0.07377420\n",
      "epoch: 85  batch: 52  loss: 0.05775026\n",
      "epoch: 85  batch: 53  loss: 0.06341986\n",
      "epoch: 85  batch: 54  loss: 0.31998977\n",
      "epoch: 85  batch: 55  loss: 0.21013023\n",
      "epoch: 85  batch: 56  loss: 0.08110595\n",
      "epoch: 85  batch: 57  loss: 0.06220463\n",
      "epoch: 85  batch: 58  loss: 0.10141972\n",
      "epoch: 85  batch: 59  loss: 0.10610034\n",
      "epoch: 85  batch: 60  loss: 0.04146769\n",
      "epoch: 85  batch: 61  loss: 0.12594886\n",
      "epoch: 85  batch: 62  loss: 0.17033231\n",
      "epoch: 85  batch: 63  loss: 0.03505547\n",
      "epoch: 85  batch: 64  loss: 0.19225876\n",
      "epoch: 85  batch: 65  loss: 0.03898715\n",
      "epoch: 85  batch: 66  loss: 0.03809581\n",
      "epoch: 85  batch: 67  loss: 0.03325129\n",
      "epoch: 85  batch: 68  loss: 0.05477009\n",
      "epoch: 86  batch: 1  loss: 0.12724940\n",
      "epoch: 86  batch: 2  loss: 0.05543205\n",
      "epoch: 86  batch: 3  loss: 0.04916724\n",
      "epoch: 86  batch: 4  loss: 0.03710059\n",
      "epoch: 86  batch: 5  loss: 0.08660428\n",
      "epoch: 86  batch: 6  loss: 0.06907736\n",
      "epoch: 86  batch: 7  loss: 0.19977808\n",
      "epoch: 86  batch: 8  loss: 0.06199411\n",
      "epoch: 86  batch: 9  loss: 0.10369173\n",
      "epoch: 86  batch: 10  loss: 0.17014237\n",
      "epoch: 86  batch: 11  loss: 0.14993688\n",
      "epoch: 86  batch: 12  loss: 0.11709596\n",
      "epoch: 86  batch: 13  loss: 0.04422472\n",
      "epoch: 86  batch: 14  loss: 0.15200616\n",
      "epoch: 86  batch: 15  loss: 0.11692618\n",
      "epoch: 86  batch: 16  loss: 0.06397580\n",
      "epoch: 86  batch: 17  loss: 0.07268813\n",
      "epoch: 86  batch: 18  loss: 0.08443446\n",
      "epoch: 86  batch: 19  loss: 0.04235010\n",
      "epoch: 86  batch: 20  loss: 0.24534607\n",
      "epoch: 86  batch: 21  loss: 0.30534548\n",
      "epoch: 86  batch: 22  loss: 0.07088214\n",
      "epoch: 86  batch: 23  loss: 0.04308187\n",
      "epoch: 86  batch: 24  loss: 0.06507481\n",
      "epoch: 86  batch: 25  loss: 0.05484219\n",
      "epoch: 86  batch: 26  loss: 0.02913681\n",
      "epoch: 86  batch: 27  loss: 0.06627310\n",
      "epoch: 86  batch: 28  loss: 0.02793363\n",
      "epoch: 86  batch: 29  loss: 0.03693895\n",
      "epoch: 86  batch: 30  loss: 0.01928991\n",
      "epoch: 86  batch: 31  loss: 0.03688258\n",
      "epoch: 86  batch: 32  loss: 0.01868916\n",
      "epoch: 86  batch: 33  loss: 0.00945760\n",
      "epoch: 86  batch: 34  loss: 0.08445784\n",
      "epoch: 86  batch: 35  loss: 0.14230451\n",
      "epoch: 86  batch: 36  loss: 0.05732064\n",
      "epoch: 86  batch: 37  loss: 0.04799086\n",
      "epoch: 86  batch: 38  loss: 0.04490589\n",
      "epoch: 86  batch: 39  loss: 0.12956613\n",
      "epoch: 86  batch: 40  loss: 0.06795075\n",
      "epoch: 86  batch: 41  loss: 0.15713067\n",
      "epoch: 86  batch: 42  loss: 0.07695517\n",
      "epoch: 86  batch: 43  loss: 0.08187659\n",
      "epoch: 86  batch: 44  loss: 0.12501901\n",
      "epoch: 86  batch: 45  loss: 0.19195732\n",
      "epoch: 86  batch: 46  loss: 0.09928027\n",
      "epoch: 86  batch: 47  loss: 0.11680047\n",
      "epoch: 86  batch: 48  loss: 0.17673801\n",
      "epoch: 86  batch: 49  loss: 0.13137974\n",
      "epoch: 86  batch: 50  loss: 0.07763504\n",
      "epoch: 86  batch: 51  loss: 0.07883497\n",
      "epoch: 86  batch: 52  loss: 0.06825035\n",
      "epoch: 86  batch: 53  loss: 0.06229038\n",
      "epoch: 86  batch: 54  loss: 0.31750441\n",
      "epoch: 86  batch: 55  loss: 0.20534866\n",
      "epoch: 86  batch: 56  loss: 0.07571926\n",
      "epoch: 86  batch: 57  loss: 0.06336737\n",
      "epoch: 86  batch: 58  loss: 0.10496382\n",
      "epoch: 86  batch: 59  loss: 0.11168654\n",
      "epoch: 86  batch: 60  loss: 0.03503994\n",
      "epoch: 86  batch: 61  loss: 0.11356842\n",
      "epoch: 86  batch: 62  loss: 0.22156911\n",
      "epoch: 86  batch: 63  loss: 0.05558788\n",
      "epoch: 86  batch: 64  loss: 0.16212872\n",
      "epoch: 86  batch: 65  loss: 0.03679515\n",
      "epoch: 86  batch: 66  loss: 0.03958725\n",
      "epoch: 86  batch: 67  loss: 0.03378511\n",
      "epoch: 86  batch: 68  loss: 0.05485974\n",
      "epoch: 87  batch: 1  loss: 0.12360516\n",
      "epoch: 87  batch: 2  loss: 0.05771393\n",
      "epoch: 87  batch: 3  loss: 0.05065406\n",
      "epoch: 87  batch: 4  loss: 0.03700285\n",
      "epoch: 87  batch: 5  loss: 0.08642165\n",
      "epoch: 87  batch: 6  loss: 0.06830415\n",
      "epoch: 87  batch: 7  loss: 0.17716250\n",
      "epoch: 87  batch: 8  loss: 0.06225979\n",
      "epoch: 87  batch: 9  loss: 0.10262000\n",
      "epoch: 87  batch: 10  loss: 0.16458018\n",
      "epoch: 87  batch: 11  loss: 0.16097963\n",
      "epoch: 87  batch: 12  loss: 0.10998201\n",
      "epoch: 87  batch: 13  loss: 0.05269273\n",
      "epoch: 87  batch: 14  loss: 0.15292536\n",
      "epoch: 87  batch: 15  loss: 0.11593512\n",
      "epoch: 87  batch: 16  loss: 0.07093200\n",
      "epoch: 87  batch: 17  loss: 0.05825367\n",
      "epoch: 87  batch: 18  loss: 0.09859066\n",
      "epoch: 87  batch: 19  loss: 0.08992150\n",
      "epoch: 87  batch: 20  loss: 0.24496515\n",
      "epoch: 87  batch: 21  loss: 0.30263489\n",
      "epoch: 87  batch: 22  loss: 0.06057839\n",
      "epoch: 87  batch: 23  loss: 0.05112819\n",
      "epoch: 87  batch: 24  loss: 0.06779089\n",
      "epoch: 87  batch: 25  loss: 0.06617136\n",
      "epoch: 87  batch: 26  loss: 0.04243645\n",
      "epoch: 87  batch: 27  loss: 0.08196753\n",
      "epoch: 87  batch: 28  loss: 0.05965279\n",
      "epoch: 87  batch: 29  loss: 0.03680210\n",
      "epoch: 87  batch: 30  loss: 0.02076527\n",
      "epoch: 87  batch: 31  loss: 0.06429380\n",
      "epoch: 87  batch: 32  loss: 0.01480024\n",
      "epoch: 87  batch: 33  loss: 0.00888409\n",
      "epoch: 87  batch: 34  loss: 0.08178950\n",
      "epoch: 87  batch: 35  loss: 0.14001288\n",
      "epoch: 87  batch: 36  loss: 0.05898283\n",
      "epoch: 87  batch: 37  loss: 0.04573822\n",
      "epoch: 87  batch: 38  loss: 0.04338368\n",
      "epoch: 87  batch: 39  loss: 0.13032824\n",
      "epoch: 87  batch: 40  loss: 0.08092286\n",
      "epoch: 87  batch: 41  loss: 0.16083775\n",
      "epoch: 87  batch: 42  loss: 0.07382668\n",
      "epoch: 87  batch: 43  loss: 0.08494101\n",
      "epoch: 87  batch: 44  loss: 0.12732098\n",
      "epoch: 87  batch: 45  loss: 0.18996739\n",
      "epoch: 87  batch: 46  loss: 0.11581896\n",
      "epoch: 87  batch: 47  loss: 0.12763184\n",
      "epoch: 87  batch: 48  loss: 0.17194487\n",
      "epoch: 87  batch: 49  loss: 0.13850424\n",
      "epoch: 87  batch: 50  loss: 0.08326419\n",
      "epoch: 87  batch: 51  loss: 0.07797943\n",
      "epoch: 87  batch: 52  loss: 0.05956858\n",
      "epoch: 87  batch: 53  loss: 0.07107189\n",
      "epoch: 87  batch: 54  loss: 0.32130122\n",
      "epoch: 87  batch: 55  loss: 0.20812957\n",
      "epoch: 87  batch: 56  loss: 0.08101095\n",
      "epoch: 87  batch: 57  loss: 0.06207403\n",
      "epoch: 87  batch: 58  loss: 0.10542443\n",
      "epoch: 87  batch: 59  loss: 0.10872142\n",
      "epoch: 87  batch: 60  loss: 0.03155351\n",
      "epoch: 87  batch: 61  loss: 0.12752160\n",
      "epoch: 87  batch: 62  loss: 0.24859357\n",
      "epoch: 87  batch: 63  loss: 0.04718005\n",
      "epoch: 87  batch: 64  loss: 0.12891299\n",
      "epoch: 87  batch: 65  loss: 0.03863382\n",
      "epoch: 87  batch: 66  loss: 0.05136556\n",
      "epoch: 87  batch: 67  loss: 0.03606450\n",
      "epoch: 87  batch: 68  loss: 0.07197533\n",
      "epoch: 88  batch: 1  loss: 0.12279917\n",
      "epoch: 88  batch: 2  loss: 0.05513544\n",
      "epoch: 88  batch: 3  loss: 0.05356462\n",
      "epoch: 88  batch: 4  loss: 0.03468283\n",
      "epoch: 88  batch: 5  loss: 0.08884947\n",
      "epoch: 88  batch: 6  loss: 0.07072910\n",
      "epoch: 88  batch: 7  loss: 0.29380697\n",
      "epoch: 88  batch: 8  loss: 0.06265330\n",
      "epoch: 88  batch: 9  loss: 0.10907239\n",
      "epoch: 88  batch: 10  loss: 0.15027839\n",
      "epoch: 88  batch: 11  loss: 0.13015442\n",
      "epoch: 88  batch: 12  loss: 0.13156345\n",
      "epoch: 88  batch: 13  loss: 0.07027532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88  batch: 14  loss: 0.15714249\n",
      "epoch: 88  batch: 15  loss: 0.17061414\n",
      "epoch: 88  batch: 16  loss: 0.06653446\n",
      "epoch: 88  batch: 17  loss: 0.13066608\n",
      "epoch: 88  batch: 18  loss: 0.05267137\n",
      "epoch: 88  batch: 19  loss: 0.05386209\n",
      "epoch: 88  batch: 20  loss: 0.29953355\n",
      "epoch: 88  batch: 21  loss: 0.44955912\n",
      "epoch: 88  batch: 22  loss: 0.06209067\n",
      "epoch: 88  batch: 23  loss: 0.08433113\n",
      "epoch: 88  batch: 24  loss: 0.06893042\n",
      "epoch: 88  batch: 25  loss: 0.07770650\n",
      "epoch: 88  batch: 26  loss: 0.05086076\n",
      "epoch: 88  batch: 27  loss: 0.08442138\n",
      "epoch: 88  batch: 28  loss: 0.02111785\n",
      "epoch: 88  batch: 29  loss: 0.21756959\n",
      "epoch: 88  batch: 30  loss: 0.23597637\n",
      "epoch: 88  batch: 31  loss: 0.14091605\n",
      "epoch: 88  batch: 32  loss: 0.01529259\n",
      "epoch: 88  batch: 33  loss: 0.05275897\n",
      "epoch: 88  batch: 34  loss: 0.11302508\n",
      "epoch: 88  batch: 35  loss: 0.14611423\n",
      "epoch: 88  batch: 36  loss: 0.05315137\n",
      "epoch: 88  batch: 37  loss: 0.05956217\n",
      "epoch: 88  batch: 38  loss: 0.04181461\n",
      "epoch: 88  batch: 39  loss: 0.14353582\n",
      "epoch: 88  batch: 40  loss: 0.07046442\n",
      "epoch: 88  batch: 41  loss: 0.18312509\n",
      "epoch: 88  batch: 42  loss: 0.07573088\n",
      "epoch: 88  batch: 43  loss: 0.13613404\n",
      "epoch: 88  batch: 44  loss: 0.12982449\n",
      "epoch: 88  batch: 45  loss: 0.19715068\n",
      "epoch: 88  batch: 46  loss: 0.20252173\n",
      "epoch: 88  batch: 47  loss: 0.27879104\n",
      "epoch: 88  batch: 48  loss: 0.17048374\n",
      "epoch: 88  batch: 49  loss: 0.13163018\n",
      "epoch: 88  batch: 50  loss: 0.15914433\n",
      "epoch: 88  batch: 51  loss: 0.07916216\n",
      "epoch: 88  batch: 52  loss: 0.06063476\n",
      "epoch: 88  batch: 53  loss: 0.12677522\n",
      "epoch: 88  batch: 54  loss: 0.38821691\n",
      "epoch: 88  batch: 55  loss: 0.21187440\n",
      "epoch: 88  batch: 56  loss: 0.07727730\n",
      "epoch: 88  batch: 57  loss: 0.07610255\n",
      "epoch: 88  batch: 58  loss: 0.12421322\n",
      "epoch: 88  batch: 59  loss: 0.11365641\n",
      "epoch: 88  batch: 60  loss: 0.09260976\n",
      "epoch: 88  batch: 61  loss: 0.53360307\n",
      "epoch: 88  batch: 62  loss: 0.08212086\n",
      "epoch: 88  batch: 63  loss: 0.54128259\n",
      "epoch: 88  batch: 64  loss: 0.15488201\n",
      "epoch: 88  batch: 65  loss: 0.06389610\n",
      "epoch: 88  batch: 66  loss: 0.04829092\n",
      "epoch: 88  batch: 67  loss: 0.03161442\n",
      "epoch: 88  batch: 68  loss: 0.06034035\n",
      "epoch: 89  batch: 1  loss: 0.45564952\n",
      "epoch: 89  batch: 2  loss: 0.05381635\n",
      "epoch: 89  batch: 3  loss: 0.04541043\n",
      "epoch: 89  batch: 4  loss: 0.04507419\n",
      "epoch: 89  batch: 5  loss: 0.10082725\n",
      "epoch: 89  batch: 6  loss: 0.07279609\n",
      "epoch: 89  batch: 7  loss: 0.35624292\n",
      "epoch: 89  batch: 8  loss: 0.10577238\n",
      "epoch: 89  batch: 9  loss: 0.17941584\n",
      "epoch: 89  batch: 10  loss: 0.19864422\n",
      "epoch: 89  batch: 11  loss: 0.15182312\n",
      "epoch: 89  batch: 12  loss: 0.13523568\n",
      "epoch: 89  batch: 13  loss: 0.04688092\n",
      "epoch: 89  batch: 14  loss: 0.15372469\n",
      "epoch: 89  batch: 15  loss: 0.15887050\n",
      "epoch: 89  batch: 16  loss: 0.08833928\n",
      "epoch: 89  batch: 17  loss: 0.10792904\n",
      "epoch: 89  batch: 18  loss: 0.04683353\n",
      "epoch: 89  batch: 19  loss: 0.07043330\n",
      "epoch: 89  batch: 20  loss: 0.24536332\n",
      "epoch: 89  batch: 21  loss: 0.30136564\n",
      "epoch: 89  batch: 22  loss: 0.09780364\n",
      "epoch: 89  batch: 23  loss: 0.07354230\n",
      "epoch: 89  batch: 24  loss: 0.07708121\n",
      "epoch: 89  batch: 25  loss: 0.07688460\n",
      "epoch: 89  batch: 26  loss: 0.04260680\n",
      "epoch: 89  batch: 27  loss: 0.12899427\n",
      "epoch: 89  batch: 28  loss: 0.05882328\n",
      "epoch: 89  batch: 29  loss: 0.02719215\n",
      "epoch: 89  batch: 30  loss: 0.05820327\n",
      "epoch: 89  batch: 31  loss: 0.11836701\n",
      "epoch: 89  batch: 32  loss: 0.01360409\n",
      "epoch: 89  batch: 33  loss: 0.03877511\n",
      "epoch: 89  batch: 34  loss: 0.11102106\n",
      "epoch: 89  batch: 35  loss: 0.14824554\n",
      "epoch: 89  batch: 36  loss: 0.04693199\n",
      "epoch: 89  batch: 37  loss: 0.05676996\n",
      "epoch: 89  batch: 38  loss: 0.03834718\n",
      "epoch: 89  batch: 39  loss: 0.13920948\n",
      "epoch: 89  batch: 40  loss: 0.07084201\n",
      "epoch: 89  batch: 41  loss: 0.17845455\n",
      "epoch: 89  batch: 42  loss: 0.07319018\n",
      "epoch: 89  batch: 43  loss: 0.14407387\n",
      "epoch: 89  batch: 44  loss: 0.19334698\n",
      "epoch: 89  batch: 45  loss: 0.20941187\n",
      "epoch: 89  batch: 46  loss: 0.16749239\n",
      "epoch: 89  batch: 47  loss: 0.26673043\n",
      "epoch: 89  batch: 48  loss: 0.15568368\n",
      "epoch: 89  batch: 49  loss: 0.12788209\n",
      "epoch: 89  batch: 50  loss: 0.22012669\n",
      "epoch: 89  batch: 51  loss: 0.09881905\n",
      "epoch: 89  batch: 52  loss: 0.06414730\n",
      "epoch: 89  batch: 53  loss: 0.10707599\n",
      "epoch: 89  batch: 54  loss: 0.41023988\n",
      "epoch: 89  batch: 55  loss: 0.21857402\n",
      "epoch: 89  batch: 56  loss: 0.07975768\n",
      "epoch: 89  batch: 57  loss: 0.06060494\n",
      "epoch: 89  batch: 58  loss: 0.11558414\n",
      "epoch: 89  batch: 59  loss: 0.10322446\n",
      "epoch: 89  batch: 60  loss: 0.06251999\n",
      "epoch: 89  batch: 61  loss: 0.32413289\n",
      "epoch: 89  batch: 62  loss: 0.10219250\n",
      "epoch: 89  batch: 63  loss: 0.45461199\n",
      "epoch: 89  batch: 64  loss: 0.12649386\n",
      "epoch: 89  batch: 65  loss: 0.05108662\n",
      "epoch: 89  batch: 66  loss: 0.05031799\n",
      "epoch: 89  batch: 67  loss: 0.03636204\n",
      "epoch: 89  batch: 68  loss: 0.18429890\n",
      "epoch: 90  batch: 1  loss: 0.14719599\n",
      "epoch: 90  batch: 2  loss: 0.05220503\n",
      "epoch: 90  batch: 3  loss: 0.05086590\n",
      "epoch: 90  batch: 4  loss: 0.03714023\n",
      "epoch: 90  batch: 5  loss: 0.08933043\n",
      "epoch: 90  batch: 6  loss: 0.07455745\n",
      "epoch: 90  batch: 7  loss: 0.20794128\n",
      "epoch: 90  batch: 8  loss: 0.13400497\n",
      "epoch: 90  batch: 9  loss: 0.15838480\n",
      "epoch: 90  batch: 10  loss: 0.17317207\n",
      "epoch: 90  batch: 11  loss: 0.15912807\n",
      "epoch: 90  batch: 12  loss: 0.11902604\n",
      "epoch: 90  batch: 13  loss: 0.03699017\n",
      "epoch: 90  batch: 14  loss: 0.15370607\n",
      "epoch: 90  batch: 15  loss: 0.14703508\n",
      "epoch: 90  batch: 16  loss: 0.07848307\n",
      "epoch: 90  batch: 17  loss: 0.07647171\n",
      "epoch: 90  batch: 18  loss: 0.04557286\n",
      "epoch: 90  batch: 19  loss: 0.07278314\n",
      "epoch: 90  batch: 20  loss: 0.24647336\n",
      "epoch: 90  batch: 21  loss: 0.30006078\n",
      "epoch: 90  batch: 22  loss: 0.07016768\n",
      "epoch: 90  batch: 23  loss: 0.06745274\n",
      "epoch: 90  batch: 24  loss: 0.07514611\n",
      "epoch: 90  batch: 25  loss: 0.08037063\n",
      "epoch: 90  batch: 26  loss: 0.03827620\n",
      "epoch: 90  batch: 27  loss: 0.06923110\n",
      "epoch: 90  batch: 28  loss: 0.08898692\n",
      "epoch: 90  batch: 29  loss: 0.06359982\n",
      "epoch: 90  batch: 30  loss: 0.08030666\n",
      "epoch: 90  batch: 31  loss: 0.12903473\n",
      "epoch: 90  batch: 32  loss: 0.03304852\n",
      "epoch: 90  batch: 33  loss: 0.02774649\n",
      "epoch: 90  batch: 34  loss: 0.10819452\n",
      "epoch: 90  batch: 35  loss: 0.14978191\n",
      "epoch: 90  batch: 36  loss: 0.07486343\n",
      "epoch: 90  batch: 37  loss: 0.05085331\n",
      "epoch: 90  batch: 38  loss: 0.16609147\n",
      "epoch: 90  batch: 39  loss: 0.14236732\n",
      "epoch: 90  batch: 40  loss: 0.06806566\n",
      "epoch: 90  batch: 41  loss: 0.17593841\n",
      "epoch: 90  batch: 42  loss: 0.07564297\n",
      "epoch: 90  batch: 43  loss: 0.12312328\n",
      "epoch: 90  batch: 44  loss: 0.15631711\n",
      "epoch: 90  batch: 45  loss: 0.18197078\n",
      "epoch: 90  batch: 46  loss: 0.18569168\n",
      "epoch: 90  batch: 47  loss: 0.27210402\n",
      "epoch: 90  batch: 48  loss: 0.15723670\n",
      "epoch: 90  batch: 49  loss: 0.12647170\n",
      "epoch: 90  batch: 50  loss: 0.19103254\n",
      "epoch: 90  batch: 51  loss: 0.08069914\n",
      "epoch: 90  batch: 52  loss: 0.06871384\n",
      "epoch: 90  batch: 53  loss: 0.11006472\n",
      "epoch: 90  batch: 54  loss: 0.33202940\n",
      "epoch: 90  batch: 55  loss: 0.23485535\n",
      "epoch: 90  batch: 56  loss: 0.07354809\n",
      "epoch: 90  batch: 57  loss: 0.05819287\n",
      "epoch: 90  batch: 58  loss: 0.10784175\n",
      "epoch: 90  batch: 59  loss: 0.10490008\n",
      "epoch: 90  batch: 60  loss: 0.10672036\n",
      "epoch: 90  batch: 61  loss: 0.40275720\n",
      "epoch: 90  batch: 62  loss: 0.09076959\n",
      "epoch: 90  batch: 63  loss: 0.44613010\n",
      "epoch: 90  batch: 64  loss: 0.08192118\n",
      "epoch: 90  batch: 65  loss: 0.03887467\n",
      "epoch: 90  batch: 66  loss: 0.04732476\n",
      "epoch: 90  batch: 67  loss: 0.03552489\n",
      "epoch: 90  batch: 68  loss: 0.06115430\n",
      "epoch: 91  batch: 1  loss: 0.22055541\n",
      "epoch: 91  batch: 2  loss: 0.05406008\n",
      "epoch: 91  batch: 3  loss: 0.05537448\n",
      "epoch: 91  batch: 4  loss: 0.05493352\n",
      "epoch: 91  batch: 5  loss: 1.06907892\n",
      "epoch: 91  batch: 6  loss: 0.07285444\n",
      "epoch: 91  batch: 7  loss: 0.19219622\n",
      "epoch: 91  batch: 8  loss: 0.09725241\n",
      "epoch: 91  batch: 9  loss: 0.11291480\n",
      "epoch: 91  batch: 10  loss: 0.16605531\n",
      "epoch: 91  batch: 11  loss: 0.18988046\n",
      "epoch: 91  batch: 12  loss: 0.39855289\n",
      "epoch: 91  batch: 13  loss: 0.08378368\n",
      "epoch: 91  batch: 14  loss: 0.18332486\n",
      "epoch: 91  batch: 15  loss: 0.16436811\n",
      "epoch: 91  batch: 16  loss: 0.06887063\n",
      "epoch: 91  batch: 17  loss: 0.09496529\n",
      "epoch: 91  batch: 18  loss: 0.06469686\n",
      "epoch: 91  batch: 19  loss: 0.07640958\n",
      "epoch: 91  batch: 20  loss: 0.33372781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91  batch: 21  loss: 0.29201683\n",
      "epoch: 91  batch: 22  loss: 0.10002948\n",
      "epoch: 91  batch: 23  loss: 0.05090638\n",
      "epoch: 91  batch: 24  loss: 0.13820559\n",
      "epoch: 91  batch: 25  loss: 0.09258972\n",
      "epoch: 91  batch: 26  loss: 0.26174903\n",
      "epoch: 91  batch: 27  loss: 0.39732608\n",
      "epoch: 91  batch: 28  loss: 0.31311616\n",
      "epoch: 91  batch: 29  loss: 0.23782896\n",
      "epoch: 91  batch: 30  loss: 0.12803529\n",
      "epoch: 91  batch: 31  loss: 0.04571598\n",
      "epoch: 91  batch: 32  loss: 0.01590512\n",
      "epoch: 91  batch: 33  loss: 0.04533750\n",
      "epoch: 91  batch: 34  loss: 0.10081524\n",
      "epoch: 91  batch: 35  loss: 0.13995054\n",
      "epoch: 91  batch: 36  loss: 0.07703622\n",
      "epoch: 91  batch: 37  loss: 0.04902412\n",
      "epoch: 91  batch: 38  loss: 0.04820677\n",
      "epoch: 91  batch: 39  loss: 0.15359591\n",
      "epoch: 91  batch: 40  loss: 0.07409877\n",
      "epoch: 91  batch: 41  loss: 0.16934995\n",
      "epoch: 91  batch: 42  loss: 0.09601994\n",
      "epoch: 91  batch: 43  loss: 0.30794403\n",
      "epoch: 91  batch: 44  loss: 0.19851933\n",
      "epoch: 91  batch: 45  loss: 0.31557560\n",
      "epoch: 91  batch: 46  loss: 0.20677596\n",
      "epoch: 91  batch: 47  loss: 0.17250478\n",
      "epoch: 91  batch: 48  loss: 0.12783006\n",
      "epoch: 91  batch: 49  loss: 0.15089838\n",
      "epoch: 91  batch: 50  loss: 0.28085744\n",
      "epoch: 91  batch: 51  loss: 0.14592090\n",
      "epoch: 91  batch: 52  loss: 0.08925574\n",
      "epoch: 91  batch: 53  loss: 0.10443062\n",
      "epoch: 91  batch: 54  loss: 0.34872577\n",
      "epoch: 91  batch: 55  loss: 0.22212008\n",
      "epoch: 91  batch: 56  loss: 0.07585762\n",
      "epoch: 91  batch: 57  loss: 0.06744823\n",
      "epoch: 91  batch: 58  loss: 0.10708609\n",
      "epoch: 91  batch: 59  loss: 0.10271293\n",
      "epoch: 91  batch: 60  loss: 0.45089450\n",
      "epoch: 91  batch: 61  loss: 0.99039257\n",
      "epoch: 91  batch: 62  loss: 0.29447404\n",
      "epoch: 91  batch: 63  loss: 0.11957397\n",
      "epoch: 91  batch: 64  loss: 0.15959278\n",
      "epoch: 91  batch: 65  loss: 0.04161135\n",
      "epoch: 91  batch: 66  loss: 0.04467337\n",
      "epoch: 91  batch: 67  loss: 0.02754899\n",
      "epoch: 91  batch: 68  loss: 0.06008483\n",
      "epoch: 92  batch: 1  loss: 0.23317169\n",
      "epoch: 92  batch: 2  loss: 0.09385423\n",
      "epoch: 92  batch: 3  loss: 0.04776630\n",
      "epoch: 92  batch: 4  loss: 0.03283204\n",
      "epoch: 92  batch: 5  loss: 0.13275973\n",
      "epoch: 92  batch: 6  loss: 0.22929756\n",
      "epoch: 92  batch: 7  loss: 0.20615628\n",
      "epoch: 92  batch: 8  loss: 0.10655073\n",
      "epoch: 92  batch: 9  loss: 0.19502454\n",
      "epoch: 92  batch: 10  loss: 0.57870698\n",
      "epoch: 92  batch: 11  loss: 0.51684099\n",
      "epoch: 92  batch: 12  loss: 0.15628769\n",
      "epoch: 92  batch: 13  loss: 0.27754641\n",
      "epoch: 92  batch: 14  loss: 0.18978603\n",
      "epoch: 92  batch: 15  loss: 0.12269797\n",
      "epoch: 92  batch: 16  loss: 0.07611242\n",
      "epoch: 92  batch: 17  loss: 0.16127466\n",
      "epoch: 92  batch: 18  loss: 0.05025001\n",
      "epoch: 92  batch: 19  loss: 0.05431730\n",
      "epoch: 92  batch: 20  loss: 0.26081944\n",
      "epoch: 92  batch: 21  loss: 0.30223480\n",
      "epoch: 92  batch: 22  loss: 0.06183636\n",
      "epoch: 92  batch: 23  loss: 0.04768629\n",
      "epoch: 92  batch: 24  loss: 0.08961608\n",
      "epoch: 92  batch: 25  loss: 0.08429182\n",
      "epoch: 92  batch: 26  loss: 0.18814747\n",
      "epoch: 92  batch: 27  loss: 0.47093761\n",
      "epoch: 92  batch: 28  loss: 0.29554725\n",
      "epoch: 92  batch: 29  loss: 0.18017676\n",
      "epoch: 92  batch: 30  loss: 0.11397114\n",
      "epoch: 92  batch: 31  loss: 0.05696652\n",
      "epoch: 92  batch: 32  loss: 0.01951179\n",
      "epoch: 92  batch: 33  loss: 0.03532736\n",
      "epoch: 92  batch: 34  loss: 0.09725641\n",
      "epoch: 92  batch: 35  loss: 0.14307393\n",
      "epoch: 92  batch: 36  loss: 0.06237907\n",
      "epoch: 92  batch: 37  loss: 0.04820733\n",
      "epoch: 92  batch: 38  loss: 0.04955453\n",
      "epoch: 92  batch: 39  loss: 0.15220426\n",
      "epoch: 92  batch: 40  loss: 0.07927562\n",
      "epoch: 92  batch: 41  loss: 0.18195297\n",
      "epoch: 92  batch: 42  loss: 0.09332207\n",
      "epoch: 92  batch: 43  loss: 0.21052614\n",
      "epoch: 92  batch: 44  loss: 0.22045837\n",
      "epoch: 92  batch: 45  loss: 0.29672465\n",
      "epoch: 92  batch: 46  loss: 0.16376840\n",
      "epoch: 92  batch: 47  loss: 0.14376566\n",
      "epoch: 92  batch: 48  loss: 0.14617527\n",
      "epoch: 92  batch: 49  loss: 0.14183982\n",
      "epoch: 92  batch: 50  loss: 0.24650247\n",
      "epoch: 92  batch: 51  loss: 0.10388739\n",
      "epoch: 92  batch: 52  loss: 0.06865607\n",
      "epoch: 92  batch: 53  loss: 0.06733157\n",
      "epoch: 92  batch: 54  loss: 0.34833488\n",
      "epoch: 92  batch: 55  loss: 0.22681987\n",
      "epoch: 92  batch: 56  loss: 0.07724515\n",
      "epoch: 92  batch: 57  loss: 0.05715404\n",
      "epoch: 92  batch: 58  loss: 0.11606978\n",
      "epoch: 92  batch: 59  loss: 0.09594668\n",
      "epoch: 92  batch: 60  loss: 0.36789528\n",
      "epoch: 92  batch: 61  loss: 0.92349941\n",
      "epoch: 92  batch: 62  loss: 0.25968742\n",
      "epoch: 92  batch: 63  loss: 0.14446850\n",
      "epoch: 92  batch: 64  loss: 0.12290627\n",
      "epoch: 92  batch: 65  loss: 0.04624069\n",
      "epoch: 92  batch: 66  loss: 0.04375694\n",
      "epoch: 92  batch: 67  loss: 0.03855759\n",
      "epoch: 92  batch: 68  loss: 0.06055943\n",
      "epoch: 93  batch: 1  loss: 0.17796314\n",
      "epoch: 93  batch: 2  loss: 0.07217459\n",
      "epoch: 93  batch: 3  loss: 0.04606050\n",
      "epoch: 93  batch: 4  loss: 0.03267535\n",
      "epoch: 93  batch: 5  loss: 0.13106367\n",
      "epoch: 93  batch: 6  loss: 0.21003936\n",
      "epoch: 93  batch: 7  loss: 0.22634897\n",
      "epoch: 93  batch: 8  loss: 0.10809767\n",
      "epoch: 93  batch: 9  loss: 0.12665986\n",
      "epoch: 93  batch: 10  loss: 0.58385772\n",
      "epoch: 93  batch: 11  loss: 0.42547557\n",
      "epoch: 93  batch: 12  loss: 0.14166656\n",
      "epoch: 93  batch: 13  loss: 0.23478365\n",
      "epoch: 93  batch: 14  loss: 0.17760500\n",
      "epoch: 93  batch: 15  loss: 0.11650705\n",
      "epoch: 93  batch: 16  loss: 0.06303069\n",
      "epoch: 93  batch: 17  loss: 0.11035859\n",
      "epoch: 93  batch: 18  loss: 0.05626737\n",
      "epoch: 93  batch: 19  loss: 0.04806582\n",
      "epoch: 93  batch: 20  loss: 0.29574123\n",
      "epoch: 93  batch: 21  loss: 0.30239868\n",
      "epoch: 93  batch: 22  loss: 0.07132326\n",
      "epoch: 93  batch: 23  loss: 0.04703865\n",
      "epoch: 93  batch: 24  loss: 0.08013168\n",
      "epoch: 93  batch: 25  loss: 0.07826659\n",
      "epoch: 93  batch: 26  loss: 0.13560601\n",
      "epoch: 93  batch: 27  loss: 0.40509784\n",
      "epoch: 93  batch: 28  loss: 0.21915339\n",
      "epoch: 93  batch: 29  loss: 0.14486769\n",
      "epoch: 93  batch: 30  loss: 0.11180288\n",
      "epoch: 93  batch: 31  loss: 0.04348296\n",
      "epoch: 93  batch: 32  loss: 0.02705421\n",
      "epoch: 93  batch: 33  loss: 0.03910148\n",
      "epoch: 93  batch: 34  loss: 0.10126485\n",
      "epoch: 93  batch: 35  loss: 0.14324695\n",
      "epoch: 93  batch: 36  loss: 0.05906300\n",
      "epoch: 93  batch: 37  loss: 0.04528907\n",
      "epoch: 93  batch: 38  loss: 0.05152272\n",
      "epoch: 93  batch: 39  loss: 0.15047714\n",
      "epoch: 93  batch: 40  loss: 0.07546359\n",
      "epoch: 93  batch: 41  loss: 0.18215129\n",
      "epoch: 93  batch: 42  loss: 0.08967026\n",
      "epoch: 93  batch: 43  loss: 0.18874927\n",
      "epoch: 93  batch: 44  loss: 0.22189294\n",
      "epoch: 93  batch: 45  loss: 0.26642627\n",
      "epoch: 93  batch: 46  loss: 0.15153183\n",
      "epoch: 93  batch: 47  loss: 0.12317845\n",
      "epoch: 93  batch: 48  loss: 0.13715795\n",
      "epoch: 93  batch: 49  loss: 0.13702899\n",
      "epoch: 93  batch: 50  loss: 0.23554540\n",
      "epoch: 93  batch: 51  loss: 0.09336759\n",
      "epoch: 93  batch: 52  loss: 0.07879546\n",
      "epoch: 93  batch: 53  loss: 0.07528166\n",
      "epoch: 93  batch: 54  loss: 0.34461182\n",
      "epoch: 93  batch: 55  loss: 0.22466321\n",
      "epoch: 93  batch: 56  loss: 0.07969207\n",
      "epoch: 93  batch: 57  loss: 0.05731000\n",
      "epoch: 93  batch: 58  loss: 0.11730246\n",
      "epoch: 93  batch: 59  loss: 0.09817736\n",
      "epoch: 93  batch: 60  loss: 0.34715793\n",
      "epoch: 93  batch: 61  loss: 0.89110017\n",
      "epoch: 93  batch: 62  loss: 0.24376738\n",
      "epoch: 93  batch: 63  loss: 0.15548086\n",
      "epoch: 93  batch: 64  loss: 0.12525086\n",
      "epoch: 93  batch: 65  loss: 0.04532520\n",
      "epoch: 93  batch: 66  loss: 0.04579243\n",
      "epoch: 93  batch: 67  loss: 0.04099854\n",
      "epoch: 93  batch: 68  loss: 0.06144373\n",
      "epoch: 94  batch: 1  loss: 0.17736717\n",
      "epoch: 94  batch: 2  loss: 0.07060680\n",
      "epoch: 94  batch: 3  loss: 0.04348686\n",
      "epoch: 94  batch: 4  loss: 0.03308839\n",
      "epoch: 94  batch: 5  loss: 0.12592702\n",
      "epoch: 94  batch: 6  loss: 0.22479452\n",
      "epoch: 94  batch: 7  loss: 0.20986596\n",
      "epoch: 94  batch: 8  loss: 0.12460665\n",
      "epoch: 94  batch: 9  loss: 0.11894660\n",
      "epoch: 94  batch: 10  loss: 0.58334422\n",
      "epoch: 94  batch: 11  loss: 0.37427345\n",
      "epoch: 94  batch: 12  loss: 0.11710271\n",
      "epoch: 94  batch: 13  loss: 0.22249189\n",
      "epoch: 94  batch: 14  loss: 0.17530040\n",
      "epoch: 94  batch: 15  loss: 0.11257171\n",
      "epoch: 94  batch: 16  loss: 0.05213880\n",
      "epoch: 94  batch: 17  loss: 0.10306277\n",
      "epoch: 94  batch: 18  loss: 0.05365294\n",
      "epoch: 94  batch: 19  loss: 0.04853711\n",
      "epoch: 94  batch: 20  loss: 0.29721427\n",
      "epoch: 94  batch: 21  loss: 0.30274823\n",
      "epoch: 94  batch: 22  loss: 0.06666761\n",
      "epoch: 94  batch: 23  loss: 0.04528153\n",
      "epoch: 94  batch: 24  loss: 0.07674712\n",
      "epoch: 94  batch: 25  loss: 0.08234067\n",
      "epoch: 94  batch: 26  loss: 0.11624991\n",
      "epoch: 94  batch: 27  loss: 0.39940348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94  batch: 28  loss: 0.12894931\n",
      "epoch: 94  batch: 29  loss: 0.12473334\n",
      "epoch: 94  batch: 30  loss: 0.10670904\n",
      "epoch: 94  batch: 31  loss: 0.04334054\n",
      "epoch: 94  batch: 32  loss: 0.01541668\n",
      "epoch: 94  batch: 33  loss: 0.03424915\n",
      "epoch: 94  batch: 34  loss: 0.10418780\n",
      "epoch: 94  batch: 35  loss: 0.14448856\n",
      "epoch: 94  batch: 36  loss: 0.05776402\n",
      "epoch: 94  batch: 37  loss: 0.04215105\n",
      "epoch: 94  batch: 38  loss: 0.04286781\n",
      "epoch: 94  batch: 39  loss: 0.16144562\n",
      "epoch: 94  batch: 40  loss: 0.07421748\n",
      "epoch: 94  batch: 41  loss: 0.18086968\n",
      "epoch: 94  batch: 42  loss: 0.09067889\n",
      "epoch: 94  batch: 43  loss: 0.18282010\n",
      "epoch: 94  batch: 44  loss: 0.23362811\n",
      "epoch: 94  batch: 45  loss: 0.27080637\n",
      "epoch: 94  batch: 46  loss: 0.13345498\n",
      "epoch: 94  batch: 47  loss: 0.11403018\n",
      "epoch: 94  batch: 48  loss: 0.13058959\n",
      "epoch: 94  batch: 49  loss: 0.13453503\n",
      "epoch: 94  batch: 50  loss: 0.23442031\n",
      "epoch: 94  batch: 51  loss: 0.10003953\n",
      "epoch: 94  batch: 52  loss: 0.07994918\n",
      "epoch: 94  batch: 53  loss: 0.07044891\n",
      "epoch: 94  batch: 54  loss: 0.35371155\n",
      "epoch: 94  batch: 55  loss: 0.22512782\n",
      "epoch: 94  batch: 56  loss: 0.07707409\n",
      "epoch: 94  batch: 57  loss: 0.05919313\n",
      "epoch: 94  batch: 58  loss: 0.10817201\n",
      "epoch: 94  batch: 59  loss: 0.09800328\n",
      "epoch: 94  batch: 60  loss: 0.35617024\n",
      "epoch: 94  batch: 61  loss: 0.88903117\n",
      "epoch: 94  batch: 62  loss: 0.24334607\n",
      "epoch: 94  batch: 63  loss: 0.08637762\n",
      "epoch: 94  batch: 64  loss: 0.07227708\n",
      "epoch: 94  batch: 65  loss: 0.04636731\n",
      "epoch: 94  batch: 66  loss: 0.04648920\n",
      "epoch: 94  batch: 67  loss: 0.04419054\n",
      "epoch: 94  batch: 68  loss: 0.06072520\n",
      "epoch: 95  batch: 1  loss: 0.16279793\n",
      "epoch: 95  batch: 2  loss: 0.04887158\n",
      "epoch: 95  batch: 3  loss: 0.04196443\n",
      "epoch: 95  batch: 4  loss: 0.03112466\n",
      "epoch: 95  batch: 5  loss: 0.11640555\n",
      "epoch: 95  batch: 6  loss: 0.20499656\n",
      "epoch: 95  batch: 7  loss: 0.21469994\n",
      "epoch: 95  batch: 8  loss: 0.11181993\n",
      "epoch: 95  batch: 9  loss: 0.11536223\n",
      "epoch: 95  batch: 10  loss: 0.52377641\n",
      "epoch: 95  batch: 11  loss: 0.33029643\n",
      "epoch: 95  batch: 12  loss: 0.10583869\n",
      "epoch: 95  batch: 13  loss: 0.20815116\n",
      "epoch: 95  batch: 14  loss: 0.16731416\n",
      "epoch: 95  batch: 15  loss: 0.11251853\n",
      "epoch: 95  batch: 16  loss: 0.04517908\n",
      "epoch: 95  batch: 17  loss: 0.09821217\n",
      "epoch: 95  batch: 18  loss: 0.05024366\n",
      "epoch: 95  batch: 19  loss: 0.04937759\n",
      "epoch: 95  batch: 20  loss: 0.31500906\n",
      "epoch: 95  batch: 21  loss: 0.30355510\n",
      "epoch: 95  batch: 22  loss: 0.06158065\n",
      "epoch: 95  batch: 23  loss: 0.04886066\n",
      "epoch: 95  batch: 24  loss: 0.07213065\n",
      "epoch: 95  batch: 25  loss: 0.07779299\n",
      "epoch: 95  batch: 26  loss: 0.07719870\n",
      "epoch: 95  batch: 27  loss: 0.32864821\n",
      "epoch: 95  batch: 28  loss: 0.09273757\n",
      "epoch: 95  batch: 29  loss: 0.11455806\n",
      "epoch: 95  batch: 30  loss: 0.07810497\n",
      "epoch: 95  batch: 31  loss: 0.03444259\n",
      "epoch: 95  batch: 32  loss: 0.01675866\n",
      "epoch: 95  batch: 33  loss: 0.04452383\n",
      "epoch: 95  batch: 34  loss: 0.10314933\n",
      "epoch: 95  batch: 35  loss: 0.14422034\n",
      "epoch: 95  batch: 36  loss: 0.05729953\n",
      "epoch: 95  batch: 37  loss: 0.04085556\n",
      "epoch: 95  batch: 38  loss: 0.04718595\n",
      "epoch: 95  batch: 39  loss: 0.15168329\n",
      "epoch: 95  batch: 40  loss: 0.07115143\n",
      "epoch: 95  batch: 41  loss: 0.17863405\n",
      "epoch: 95  batch: 42  loss: 0.08694723\n",
      "epoch: 95  batch: 43  loss: 0.16537948\n",
      "epoch: 95  batch: 44  loss: 0.22719797\n",
      "epoch: 95  batch: 45  loss: 0.27147359\n",
      "epoch: 95  batch: 46  loss: 0.12400396\n",
      "epoch: 95  batch: 47  loss: 0.12102520\n",
      "epoch: 95  batch: 48  loss: 0.13684025\n",
      "epoch: 95  batch: 49  loss: 0.12879412\n",
      "epoch: 95  batch: 50  loss: 0.23282836\n",
      "epoch: 95  batch: 51  loss: 0.08411536\n",
      "epoch: 95  batch: 52  loss: 0.08095589\n",
      "epoch: 95  batch: 53  loss: 0.06385836\n",
      "epoch: 95  batch: 54  loss: 0.34852475\n",
      "epoch: 95  batch: 55  loss: 0.22231880\n",
      "epoch: 95  batch: 56  loss: 0.07832793\n",
      "epoch: 95  batch: 57  loss: 0.05332530\n",
      "epoch: 95  batch: 58  loss: 0.10981037\n",
      "epoch: 95  batch: 59  loss: 0.09329095\n",
      "epoch: 95  batch: 60  loss: 0.31911764\n",
      "epoch: 95  batch: 61  loss: 0.87195200\n",
      "epoch: 95  batch: 62  loss: 0.23399727\n",
      "epoch: 95  batch: 63  loss: 0.06865378\n",
      "epoch: 95  batch: 64  loss: 0.04702806\n",
      "epoch: 95  batch: 65  loss: 0.04453317\n",
      "epoch: 95  batch: 66  loss: 0.04717164\n",
      "epoch: 95  batch: 67  loss: 0.06112606\n",
      "epoch: 95  batch: 68  loss: 0.05946925\n",
      "epoch: 96  batch: 1  loss: 0.16529462\n",
      "epoch: 96  batch: 2  loss: 0.05153408\n",
      "epoch: 96  batch: 3  loss: 0.04265181\n",
      "epoch: 96  batch: 4  loss: 0.03310851\n",
      "epoch: 96  batch: 5  loss: 0.10986943\n",
      "epoch: 96  batch: 6  loss: 0.20067978\n",
      "epoch: 96  batch: 7  loss: 0.21627070\n",
      "epoch: 96  batch: 8  loss: 0.10148946\n",
      "epoch: 96  batch: 9  loss: 0.11300839\n",
      "epoch: 96  batch: 10  loss: 0.35021439\n",
      "epoch: 96  batch: 11  loss: 0.31369832\n",
      "epoch: 96  batch: 12  loss: 0.10011243\n",
      "epoch: 96  batch: 13  loss: 0.18790203\n",
      "epoch: 96  batch: 14  loss: 0.17468709\n",
      "epoch: 96  batch: 15  loss: 0.12138331\n",
      "epoch: 96  batch: 16  loss: 0.05040743\n",
      "epoch: 96  batch: 17  loss: 0.07115098\n",
      "epoch: 96  batch: 18  loss: 0.04856142\n",
      "epoch: 96  batch: 19  loss: 0.05070210\n",
      "epoch: 96  batch: 20  loss: 0.31766415\n",
      "epoch: 96  batch: 21  loss: 0.30143797\n",
      "epoch: 96  batch: 22  loss: 0.05944412\n",
      "epoch: 96  batch: 23  loss: 0.04478869\n",
      "epoch: 96  batch: 24  loss: 0.06812651\n",
      "epoch: 96  batch: 25  loss: 0.07679007\n",
      "epoch: 96  batch: 26  loss: 0.05278186\n",
      "epoch: 96  batch: 27  loss: 0.25096005\n",
      "epoch: 96  batch: 28  loss: 0.04509433\n",
      "epoch: 96  batch: 29  loss: 0.07950526\n",
      "epoch: 96  batch: 30  loss: 0.12223684\n",
      "epoch: 96  batch: 31  loss: 0.03266364\n",
      "epoch: 96  batch: 32  loss: 0.01942601\n",
      "epoch: 96  batch: 33  loss: 0.05070242\n",
      "epoch: 96  batch: 34  loss: 0.10386835\n",
      "epoch: 96  batch: 35  loss: 0.14481011\n",
      "epoch: 96  batch: 36  loss: 0.06025869\n",
      "epoch: 96  batch: 37  loss: 0.04207147\n",
      "epoch: 96  batch: 38  loss: 0.06059629\n",
      "epoch: 96  batch: 39  loss: 0.14300731\n",
      "epoch: 96  batch: 40  loss: 0.06796246\n",
      "epoch: 96  batch: 41  loss: 0.17520556\n",
      "epoch: 96  batch: 42  loss: 0.08068059\n",
      "epoch: 96  batch: 43  loss: 0.13820714\n",
      "epoch: 96  batch: 44  loss: 0.22900014\n",
      "epoch: 96  batch: 45  loss: 0.25652936\n",
      "epoch: 96  batch: 46  loss: 0.13259502\n",
      "epoch: 96  batch: 47  loss: 0.10783988\n",
      "epoch: 96  batch: 48  loss: 0.13912199\n",
      "epoch: 96  batch: 49  loss: 0.12871028\n",
      "epoch: 96  batch: 50  loss: 0.24827759\n",
      "epoch: 96  batch: 51  loss: 0.08483399\n",
      "epoch: 96  batch: 52  loss: 0.09254049\n",
      "epoch: 96  batch: 53  loss: 0.07658828\n",
      "epoch: 96  batch: 54  loss: 0.33971924\n",
      "epoch: 96  batch: 55  loss: 0.21921737\n",
      "epoch: 96  batch: 56  loss: 0.08132513\n",
      "epoch: 96  batch: 57  loss: 0.04656065\n",
      "epoch: 96  batch: 58  loss: 0.10724591\n",
      "epoch: 96  batch: 59  loss: 0.09766068\n",
      "epoch: 96  batch: 60  loss: 0.26891577\n",
      "epoch: 96  batch: 61  loss: 0.86775362\n",
      "epoch: 96  batch: 62  loss: 0.22698697\n",
      "epoch: 96  batch: 63  loss: 0.06273523\n",
      "epoch: 96  batch: 64  loss: 0.04167166\n",
      "epoch: 96  batch: 65  loss: 0.04037865\n",
      "epoch: 96  batch: 66  loss: 0.04561247\n",
      "epoch: 96  batch: 67  loss: 0.05429519\n",
      "epoch: 96  batch: 68  loss: 0.05706826\n",
      "epoch: 97  batch: 1  loss: 0.14267702\n",
      "epoch: 97  batch: 2  loss: 0.04472081\n",
      "epoch: 97  batch: 3  loss: 0.04132297\n",
      "epoch: 97  batch: 4  loss: 0.03391404\n",
      "epoch: 97  batch: 5  loss: 0.10464447\n",
      "epoch: 97  batch: 6  loss: 0.14514214\n",
      "epoch: 97  batch: 7  loss: 0.20819516\n",
      "epoch: 97  batch: 8  loss: 0.10406650\n",
      "epoch: 97  batch: 9  loss: 0.10870088\n",
      "epoch: 97  batch: 10  loss: 0.27575806\n",
      "epoch: 97  batch: 11  loss: 0.30229950\n",
      "epoch: 97  batch: 12  loss: 0.10983688\n",
      "epoch: 97  batch: 13  loss: 0.15064168\n",
      "epoch: 97  batch: 14  loss: 0.17748664\n",
      "epoch: 97  batch: 15  loss: 0.10581163\n",
      "epoch: 97  batch: 16  loss: 0.09024258\n",
      "epoch: 97  batch: 17  loss: 0.05088667\n",
      "epoch: 97  batch: 18  loss: 0.10096887\n",
      "epoch: 97  batch: 19  loss: 0.06599279\n",
      "epoch: 97  batch: 20  loss: 0.34764481\n",
      "epoch: 97  batch: 21  loss: 0.31244975\n",
      "epoch: 97  batch: 22  loss: 0.08687020\n",
      "epoch: 97  batch: 23  loss: 0.05776187\n",
      "epoch: 97  batch: 24  loss: 0.10870025\n",
      "epoch: 97  batch: 25  loss: 0.09859459\n",
      "epoch: 97  batch: 26  loss: 0.02410218\n",
      "epoch: 97  batch: 27  loss: 0.08182260\n",
      "epoch: 97  batch: 28  loss: 0.01668886\n",
      "epoch: 97  batch: 29  loss: 0.03795927\n",
      "epoch: 97  batch: 30  loss: 0.08988756\n",
      "epoch: 97  batch: 31  loss: 0.02725373\n",
      "epoch: 97  batch: 32  loss: 0.01238983\n",
      "epoch: 97  batch: 33  loss: 0.07295100\n",
      "epoch: 97  batch: 34  loss: 0.09338386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97  batch: 35  loss: 0.14284937\n",
      "epoch: 97  batch: 36  loss: 0.05814733\n",
      "epoch: 97  batch: 37  loss: 0.04149022\n",
      "epoch: 97  batch: 38  loss: 0.05561291\n",
      "epoch: 97  batch: 39  loss: 0.14139362\n",
      "epoch: 97  batch: 40  loss: 0.06669624\n",
      "epoch: 97  batch: 41  loss: 0.17189962\n",
      "epoch: 97  batch: 42  loss: 0.08411119\n",
      "epoch: 97  batch: 43  loss: 0.14264072\n",
      "epoch: 97  batch: 44  loss: 0.22030434\n",
      "epoch: 97  batch: 45  loss: 0.24018075\n",
      "epoch: 97  batch: 46  loss: 0.11178445\n",
      "epoch: 97  batch: 47  loss: 0.09124061\n",
      "epoch: 97  batch: 48  loss: 0.13019007\n",
      "epoch: 97  batch: 49  loss: 0.12640822\n",
      "epoch: 97  batch: 50  loss: 0.21712787\n",
      "epoch: 97  batch: 51  loss: 0.07647598\n",
      "epoch: 97  batch: 52  loss: 0.08875839\n",
      "epoch: 97  batch: 53  loss: 0.05546645\n",
      "epoch: 97  batch: 54  loss: 0.33476579\n",
      "epoch: 97  batch: 55  loss: 0.21620277\n",
      "epoch: 97  batch: 56  loss: 0.07564012\n",
      "epoch: 97  batch: 57  loss: 0.04143448\n",
      "epoch: 97  batch: 58  loss: 0.11895084\n",
      "epoch: 97  batch: 59  loss: 0.08618413\n",
      "epoch: 97  batch: 60  loss: 0.16316263\n",
      "epoch: 97  batch: 61  loss: 0.78083515\n",
      "epoch: 97  batch: 62  loss: 0.18388553\n",
      "epoch: 97  batch: 63  loss: 0.04053570\n",
      "epoch: 97  batch: 64  loss: 0.03118253\n",
      "epoch: 97  batch: 65  loss: 0.03928129\n",
      "epoch: 97  batch: 66  loss: 0.04325512\n",
      "epoch: 97  batch: 67  loss: 0.03798833\n",
      "epoch: 97  batch: 68  loss: 0.05496849\n",
      "epoch: 98  batch: 1  loss: 0.13442478\n",
      "epoch: 98  batch: 2  loss: 0.04351822\n",
      "epoch: 98  batch: 3  loss: 0.04118995\n",
      "epoch: 98  batch: 4  loss: 0.03405929\n",
      "epoch: 98  batch: 5  loss: 0.09820272\n",
      "epoch: 98  batch: 6  loss: 0.10008562\n",
      "epoch: 98  batch: 7  loss: 0.20051545\n",
      "epoch: 98  batch: 8  loss: 0.09216916\n",
      "epoch: 98  batch: 9  loss: 0.10144946\n",
      "epoch: 98  batch: 10  loss: 0.24713755\n",
      "epoch: 98  batch: 11  loss: 0.28039047\n",
      "epoch: 98  batch: 12  loss: 0.09052382\n",
      "epoch: 98  batch: 13  loss: 0.16895205\n",
      "epoch: 98  batch: 14  loss: 0.16490434\n",
      "epoch: 98  batch: 15  loss: 0.10631955\n",
      "epoch: 98  batch: 16  loss: 0.07093773\n",
      "epoch: 98  batch: 17  loss: 0.05248259\n",
      "epoch: 98  batch: 18  loss: 0.07231937\n",
      "epoch: 98  batch: 19  loss: 0.05096469\n",
      "epoch: 98  batch: 20  loss: 0.31300235\n",
      "epoch: 98  batch: 21  loss: 0.30003896\n",
      "epoch: 98  batch: 22  loss: 0.07110972\n",
      "epoch: 98  batch: 23  loss: 0.04834135\n",
      "epoch: 98  batch: 24  loss: 0.09206929\n",
      "epoch: 98  batch: 25  loss: 0.09027634\n",
      "epoch: 98  batch: 26  loss: 0.02091407\n",
      "epoch: 98  batch: 27  loss: 0.09455858\n",
      "epoch: 98  batch: 28  loss: 0.01589800\n",
      "epoch: 98  batch: 29  loss: 0.03905401\n",
      "epoch: 98  batch: 30  loss: 0.05998521\n",
      "epoch: 98  batch: 31  loss: 0.02783011\n",
      "epoch: 98  batch: 32  loss: 0.01228332\n",
      "epoch: 98  batch: 33  loss: 0.05546336\n",
      "epoch: 98  batch: 34  loss: 0.09423271\n",
      "epoch: 98  batch: 35  loss: 0.14230555\n",
      "epoch: 98  batch: 36  loss: 0.05901749\n",
      "epoch: 98  batch: 37  loss: 0.04020517\n",
      "epoch: 98  batch: 38  loss: 0.04677712\n",
      "epoch: 98  batch: 39  loss: 0.13913989\n",
      "epoch: 98  batch: 40  loss: 0.06491446\n",
      "epoch: 98  batch: 41  loss: 0.17034751\n",
      "epoch: 98  batch: 42  loss: 0.08118182\n",
      "epoch: 98  batch: 43  loss: 0.13656750\n",
      "epoch: 98  batch: 44  loss: 0.20869204\n",
      "epoch: 98  batch: 45  loss: 0.22918628\n",
      "epoch: 98  batch: 46  loss: 0.11171958\n",
      "epoch: 98  batch: 47  loss: 0.09020983\n",
      "epoch: 98  batch: 48  loss: 0.13287303\n",
      "epoch: 98  batch: 49  loss: 0.12625839\n",
      "epoch: 98  batch: 50  loss: 0.22144707\n",
      "epoch: 98  batch: 51  loss: 0.07542136\n",
      "epoch: 98  batch: 52  loss: 0.08310042\n",
      "epoch: 98  batch: 53  loss: 0.05585427\n",
      "epoch: 98  batch: 54  loss: 0.33524814\n",
      "epoch: 98  batch: 55  loss: 0.21622711\n",
      "epoch: 98  batch: 56  loss: 0.07691390\n",
      "epoch: 98  batch: 57  loss: 0.04172160\n",
      "epoch: 98  batch: 58  loss: 0.11573987\n",
      "epoch: 98  batch: 59  loss: 0.08578275\n",
      "epoch: 98  batch: 60  loss: 0.16180250\n",
      "epoch: 98  batch: 61  loss: 0.79005605\n",
      "epoch: 98  batch: 62  loss: 0.19089256\n",
      "epoch: 98  batch: 63  loss: 0.04427896\n",
      "epoch: 98  batch: 64  loss: 0.03248779\n",
      "epoch: 98  batch: 65  loss: 0.03956284\n",
      "epoch: 98  batch: 66  loss: 0.04238166\n",
      "epoch: 98  batch: 67  loss: 0.03508029\n",
      "epoch: 98  batch: 68  loss: 0.05396475\n",
      "epoch: 99  batch: 1  loss: 0.13285844\n",
      "epoch: 99  batch: 2  loss: 0.04338914\n",
      "epoch: 99  batch: 3  loss: 0.04042269\n",
      "epoch: 99  batch: 4  loss: 0.03373025\n",
      "epoch: 99  batch: 5  loss: 0.09601853\n",
      "epoch: 99  batch: 6  loss: 0.09068903\n",
      "epoch: 99  batch: 7  loss: 0.19801521\n",
      "epoch: 99  batch: 8  loss: 0.08677904\n",
      "epoch: 99  batch: 9  loss: 0.09869234\n",
      "epoch: 99  batch: 10  loss: 0.23411369\n",
      "epoch: 99  batch: 11  loss: 0.27157754\n",
      "epoch: 99  batch: 12  loss: 0.08674762\n",
      "epoch: 99  batch: 13  loss: 0.17088172\n",
      "epoch: 99  batch: 14  loss: 0.16243842\n",
      "epoch: 99  batch: 15  loss: 0.10653041\n",
      "epoch: 99  batch: 16  loss: 0.06595536\n",
      "epoch: 99  batch: 17  loss: 0.05234432\n",
      "epoch: 99  batch: 18  loss: 0.06176670\n",
      "epoch: 99  batch: 19  loss: 0.04797760\n",
      "epoch: 99  batch: 20  loss: 0.30398640\n",
      "epoch: 99  batch: 21  loss: 0.29764241\n",
      "epoch: 99  batch: 22  loss: 0.06678284\n",
      "epoch: 99  batch: 23  loss: 0.04626067\n",
      "epoch: 99  batch: 24  loss: 0.08757257\n",
      "epoch: 99  batch: 25  loss: 0.08622153\n",
      "epoch: 99  batch: 26  loss: 0.02005955\n",
      "epoch: 99  batch: 27  loss: 0.09533335\n",
      "epoch: 99  batch: 28  loss: 0.01615380\n",
      "epoch: 99  batch: 29  loss: 0.03496979\n",
      "epoch: 99  batch: 30  loss: 0.04053118\n",
      "epoch: 99  batch: 31  loss: 0.02770786\n",
      "epoch: 99  batch: 32  loss: 0.01230177\n",
      "epoch: 99  batch: 33  loss: 0.05031038\n",
      "epoch: 99  batch: 34  loss: 0.09433483\n",
      "epoch: 99  batch: 35  loss: 0.14219390\n",
      "epoch: 99  batch: 36  loss: 0.05926407\n",
      "epoch: 99  batch: 37  loss: 0.03991832\n",
      "epoch: 99  batch: 38  loss: 0.04361759\n",
      "epoch: 99  batch: 39  loss: 0.13883623\n",
      "epoch: 99  batch: 40  loss: 0.06434350\n",
      "epoch: 99  batch: 41  loss: 0.17015904\n",
      "epoch: 99  batch: 42  loss: 0.08008893\n",
      "epoch: 99  batch: 43  loss: 0.13473091\n",
      "epoch: 99  batch: 44  loss: 0.20538023\n",
      "epoch: 99  batch: 45  loss: 0.22438346\n",
      "epoch: 99  batch: 46  loss: 0.10997345\n",
      "epoch: 99  batch: 47  loss: 0.08897234\n",
      "epoch: 99  batch: 48  loss: 0.13409486\n",
      "epoch: 99  batch: 49  loss: 0.12660609\n",
      "epoch: 99  batch: 50  loss: 0.22196101\n",
      "epoch: 99  batch: 51  loss: 0.07566356\n",
      "epoch: 99  batch: 52  loss: 0.08203354\n",
      "epoch: 99  batch: 53  loss: 0.05602306\n",
      "epoch: 99  batch: 54  loss: 0.33557430\n",
      "epoch: 99  batch: 55  loss: 0.21615121\n",
      "epoch: 99  batch: 56  loss: 0.07743856\n",
      "epoch: 99  batch: 57  loss: 0.04194085\n",
      "epoch: 99  batch: 58  loss: 0.11488794\n",
      "epoch: 99  batch: 59  loss: 0.08564451\n",
      "epoch: 99  batch: 60  loss: 0.15521869\n",
      "epoch: 99  batch: 61  loss: 0.78969175\n",
      "epoch: 99  batch: 62  loss: 0.19265871\n",
      "epoch: 99  batch: 63  loss: 0.04414798\n",
      "epoch: 99  batch: 64  loss: 0.03215574\n",
      "epoch: 99  batch: 65  loss: 0.03992845\n",
      "epoch: 99  batch: 66  loss: 0.04207481\n",
      "epoch: 99  batch: 67  loss: 0.03425610\n",
      "epoch: 99  batch: 68  loss: 0.05348788\n",
      "epoch: 100  batch: 1  loss: 0.13222942\n",
      "epoch: 100  batch: 2  loss: 0.04343583\n",
      "epoch: 100  batch: 3  loss: 0.03982864\n",
      "epoch: 100  batch: 4  loss: 0.03362959\n",
      "epoch: 100  batch: 5  loss: 0.09496619\n",
      "epoch: 100  batch: 6  loss: 0.08904605\n",
      "epoch: 100  batch: 7  loss: 0.19714187\n",
      "epoch: 100  batch: 8  loss: 0.08375243\n",
      "epoch: 100  batch: 9  loss: 0.09697863\n",
      "epoch: 100  batch: 10  loss: 0.22793874\n",
      "epoch: 100  batch: 11  loss: 0.26764733\n",
      "epoch: 100  batch: 12  loss: 0.08478189\n",
      "epoch: 100  batch: 13  loss: 0.16826263\n",
      "epoch: 100  batch: 14  loss: 0.16126557\n",
      "epoch: 100  batch: 15  loss: 0.10664538\n",
      "epoch: 100  batch: 16  loss: 0.06417961\n",
      "epoch: 100  batch: 17  loss: 0.05212328\n",
      "epoch: 100  batch: 18  loss: 0.05612933\n",
      "epoch: 100  batch: 19  loss: 0.04722644\n",
      "epoch: 100  batch: 20  loss: 0.30150372\n",
      "epoch: 100  batch: 21  loss: 0.29668665\n",
      "epoch: 100  batch: 22  loss: 0.06480286\n",
      "epoch: 100  batch: 23  loss: 0.04534676\n",
      "epoch: 100  batch: 24  loss: 0.08519346\n",
      "epoch: 100  batch: 25  loss: 0.08381731\n",
      "epoch: 100  batch: 26  loss: 0.01944195\n",
      "epoch: 100  batch: 27  loss: 0.09367962\n",
      "epoch: 100  batch: 28  loss: 0.01641358\n",
      "epoch: 100  batch: 29  loss: 0.03069035\n",
      "epoch: 100  batch: 30  loss: 0.03166560\n",
      "epoch: 100  batch: 31  loss: 0.02748370\n",
      "epoch: 100  batch: 32  loss: 0.01226281\n",
      "epoch: 100  batch: 33  loss: 0.04856354\n",
      "epoch: 100  batch: 34  loss: 0.09436680\n",
      "epoch: 100  batch: 35  loss: 0.14214112\n",
      "epoch: 100  batch: 36  loss: 0.05941632\n",
      "epoch: 100  batch: 37  loss: 0.03974930\n",
      "epoch: 100  batch: 38  loss: 0.04201173\n",
      "epoch: 100  batch: 39  loss: 0.13852453\n",
      "epoch: 100  batch: 40  loss: 0.06406189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100  batch: 41  loss: 0.17005658\n",
      "epoch: 100  batch: 42  loss: 0.07939699\n",
      "epoch: 100  batch: 43  loss: 0.13372637\n",
      "epoch: 100  batch: 44  loss: 0.20412980\n",
      "epoch: 100  batch: 45  loss: 0.22109894\n",
      "epoch: 100  batch: 46  loss: 0.10821671\n",
      "epoch: 100  batch: 47  loss: 0.08783097\n",
      "epoch: 100  batch: 48  loss: 0.13494737\n",
      "epoch: 100  batch: 49  loss: 0.12695356\n",
      "epoch: 100  batch: 50  loss: 0.22140965\n",
      "epoch: 100  batch: 51  loss: 0.07602966\n",
      "epoch: 100  batch: 52  loss: 0.08208172\n",
      "epoch: 100  batch: 53  loss: 0.05615015\n",
      "epoch: 100  batch: 54  loss: 0.33559445\n",
      "epoch: 100  batch: 55  loss: 0.21592306\n",
      "epoch: 100  batch: 56  loss: 0.07776849\n",
      "epoch: 100  batch: 57  loss: 0.04199324\n",
      "epoch: 100  batch: 58  loss: 0.11466309\n",
      "epoch: 100  batch: 59  loss: 0.08568795\n",
      "epoch: 100  batch: 60  loss: 0.14781746\n",
      "epoch: 100  batch: 61  loss: 0.78612554\n",
      "epoch: 100  batch: 62  loss: 0.19237180\n",
      "epoch: 100  batch: 63  loss: 0.04330532\n",
      "epoch: 100  batch: 64  loss: 0.03140552\n",
      "epoch: 100  batch: 65  loss: 0.04020394\n",
      "epoch: 100  batch: 66  loss: 0.04191232\n",
      "epoch: 100  batch: 67  loss: 0.03393060\n",
      "epoch: 100  batch: 68  loss: 0.05312161\n",
      "epoch: 101  batch: 1  loss: 0.13182086\n",
      "epoch: 101  batch: 2  loss: 0.04349433\n",
      "epoch: 101  batch: 3  loss: 0.03931346\n",
      "epoch: 101  batch: 4  loss: 0.03357670\n",
      "epoch: 101  batch: 5  loss: 0.09419893\n",
      "epoch: 101  batch: 6  loss: 0.08785579\n",
      "epoch: 101  batch: 7  loss: 0.19655180\n",
      "epoch: 101  batch: 8  loss: 0.08164428\n",
      "epoch: 101  batch: 9  loss: 0.09558228\n",
      "epoch: 101  batch: 10  loss: 0.22342293\n",
      "epoch: 101  batch: 11  loss: 0.26492250\n",
      "epoch: 101  batch: 12  loss: 0.08344263\n",
      "epoch: 101  batch: 13  loss: 0.16401085\n",
      "epoch: 101  batch: 14  loss: 0.16051470\n",
      "epoch: 101  batch: 15  loss: 0.10681102\n",
      "epoch: 101  batch: 16  loss: 0.06340283\n",
      "epoch: 101  batch: 17  loss: 0.05173538\n",
      "epoch: 101  batch: 18  loss: 0.05232490\n",
      "epoch: 101  batch: 19  loss: 0.04698021\n",
      "epoch: 101  batch: 20  loss: 0.30063349\n",
      "epoch: 101  batch: 21  loss: 0.29592299\n",
      "epoch: 101  batch: 22  loss: 0.06347146\n",
      "epoch: 101  batch: 23  loss: 0.04477143\n",
      "epoch: 101  batch: 24  loss: 0.08343632\n",
      "epoch: 101  batch: 25  loss: 0.08221789\n",
      "epoch: 101  batch: 26  loss: 0.01900213\n",
      "epoch: 101  batch: 27  loss: 0.09153290\n",
      "epoch: 101  batch: 28  loss: 0.01655566\n",
      "epoch: 101  batch: 29  loss: 0.02681135\n",
      "epoch: 101  batch: 30  loss: 0.02671589\n",
      "epoch: 101  batch: 31  loss: 0.02729752\n",
      "epoch: 101  batch: 32  loss: 0.01221749\n",
      "epoch: 101  batch: 33  loss: 0.04737485\n",
      "epoch: 101  batch: 34  loss: 0.09440730\n",
      "epoch: 101  batch: 35  loss: 0.14205401\n",
      "epoch: 101  batch: 36  loss: 0.05960094\n",
      "epoch: 101  batch: 37  loss: 0.03961802\n",
      "epoch: 101  batch: 38  loss: 0.04107396\n",
      "epoch: 101  batch: 39  loss: 0.13806133\n",
      "epoch: 101  batch: 40  loss: 0.06388913\n",
      "epoch: 101  batch: 41  loss: 0.16989622\n",
      "epoch: 101  batch: 42  loss: 0.07882850\n",
      "epoch: 101  batch: 43  loss: 0.13291728\n",
      "epoch: 101  batch: 44  loss: 0.20342661\n",
      "epoch: 101  batch: 45  loss: 0.21812715\n",
      "epoch: 101  batch: 46  loss: 0.10666218\n",
      "epoch: 101  batch: 47  loss: 0.08678012\n",
      "epoch: 101  batch: 48  loss: 0.13573056\n",
      "epoch: 101  batch: 49  loss: 0.12721860\n",
      "epoch: 101  batch: 50  loss: 0.22012092\n",
      "epoch: 101  batch: 51  loss: 0.07626702\n",
      "epoch: 101  batch: 52  loss: 0.08247732\n",
      "epoch: 101  batch: 53  loss: 0.05628720\n",
      "epoch: 101  batch: 54  loss: 0.33542973\n",
      "epoch: 101  batch: 55  loss: 0.21551618\n",
      "epoch: 101  batch: 56  loss: 0.07799229\n",
      "epoch: 101  batch: 57  loss: 0.04192032\n",
      "epoch: 101  batch: 58  loss: 0.11458357\n",
      "epoch: 101  batch: 59  loss: 0.08583028\n",
      "epoch: 101  batch: 60  loss: 0.14036644\n",
      "epoch: 101  batch: 61  loss: 0.78092730\n",
      "epoch: 101  batch: 62  loss: 0.19088131\n",
      "epoch: 101  batch: 63  loss: 0.04211070\n",
      "epoch: 101  batch: 64  loss: 0.03053144\n",
      "epoch: 101  batch: 65  loss: 0.04036096\n",
      "epoch: 101  batch: 66  loss: 0.04178324\n",
      "epoch: 101  batch: 67  loss: 0.03378025\n",
      "epoch: 101  batch: 68  loss: 0.05282253\n",
      "epoch: 102  batch: 1  loss: 0.13151808\n",
      "epoch: 102  batch: 2  loss: 0.04351655\n",
      "epoch: 102  batch: 3  loss: 0.03887281\n",
      "epoch: 102  batch: 4  loss: 0.03355423\n",
      "epoch: 102  batch: 5  loss: 0.09356641\n",
      "epoch: 102  batch: 6  loss: 0.08680325\n",
      "epoch: 102  batch: 7  loss: 0.19603187\n",
      "epoch: 102  batch: 8  loss: 0.07999048\n",
      "epoch: 102  batch: 9  loss: 0.09434478\n",
      "epoch: 102  batch: 10  loss: 0.21959820\n",
      "epoch: 102  batch: 11  loss: 0.26265767\n",
      "epoch: 102  batch: 12  loss: 0.08243100\n",
      "epoch: 102  batch: 13  loss: 0.15897457\n",
      "epoch: 102  batch: 14  loss: 0.15984701\n",
      "epoch: 102  batch: 15  loss: 0.10704842\n",
      "epoch: 102  batch: 16  loss: 0.06294382\n",
      "epoch: 102  batch: 17  loss: 0.05137433\n",
      "epoch: 102  batch: 18  loss: 0.04962632\n",
      "epoch: 102  batch: 19  loss: 0.04688669\n",
      "epoch: 102  batch: 20  loss: 0.29983488\n",
      "epoch: 102  batch: 21  loss: 0.29520613\n",
      "epoch: 102  batch: 22  loss: 0.06240911\n",
      "epoch: 102  batch: 23  loss: 0.04436890\n",
      "epoch: 102  batch: 24  loss: 0.08212540\n",
      "epoch: 102  batch: 25  loss: 0.08104184\n",
      "epoch: 102  batch: 26  loss: 0.01868576\n",
      "epoch: 102  batch: 27  loss: 0.08928365\n",
      "epoch: 102  batch: 28  loss: 0.01658392\n",
      "epoch: 102  batch: 29  loss: 0.02355526\n",
      "epoch: 102  batch: 30  loss: 0.02372237\n",
      "epoch: 102  batch: 31  loss: 0.02714363\n",
      "epoch: 102  batch: 32  loss: 0.01215174\n",
      "epoch: 102  batch: 33  loss: 0.04633675\n",
      "epoch: 102  batch: 34  loss: 0.09439384\n",
      "epoch: 102  batch: 35  loss: 0.14195730\n",
      "epoch: 102  batch: 36  loss: 0.05981459\n",
      "epoch: 102  batch: 37  loss: 0.03950170\n",
      "epoch: 102  batch: 38  loss: 0.04044458\n",
      "epoch: 102  batch: 39  loss: 0.13754445\n",
      "epoch: 102  batch: 40  loss: 0.06374720\n",
      "epoch: 102  batch: 41  loss: 0.16967270\n",
      "epoch: 102  batch: 42  loss: 0.07827596\n",
      "epoch: 102  batch: 43  loss: 0.13217197\n",
      "epoch: 102  batch: 44  loss: 0.20277062\n",
      "epoch: 102  batch: 45  loss: 0.21545535\n",
      "epoch: 102  batch: 46  loss: 0.10528273\n",
      "epoch: 102  batch: 47  loss: 0.08590645\n",
      "epoch: 102  batch: 48  loss: 0.13625325\n",
      "epoch: 102  batch: 49  loss: 0.12740606\n",
      "epoch: 102  batch: 50  loss: 0.21808705\n",
      "epoch: 102  batch: 51  loss: 0.07640297\n",
      "epoch: 102  batch: 52  loss: 0.08298338\n",
      "epoch: 102  batch: 53  loss: 0.05641664\n",
      "epoch: 102  batch: 54  loss: 0.33511624\n",
      "epoch: 102  batch: 55  loss: 0.21494196\n",
      "epoch: 102  batch: 56  loss: 0.07819270\n",
      "epoch: 102  batch: 57  loss: 0.04177774\n",
      "epoch: 102  batch: 58  loss: 0.11458901\n",
      "epoch: 102  batch: 59  loss: 0.08605625\n",
      "epoch: 102  batch: 60  loss: 0.13273326\n",
      "epoch: 102  batch: 61  loss: 0.77392697\n",
      "epoch: 102  batch: 62  loss: 0.18854108\n",
      "epoch: 102  batch: 63  loss: 0.04059957\n",
      "epoch: 102  batch: 64  loss: 0.02960934\n",
      "epoch: 102  batch: 65  loss: 0.04049101\n",
      "epoch: 102  batch: 66  loss: 0.04164889\n",
      "epoch: 102  batch: 67  loss: 0.03369261\n",
      "epoch: 102  batch: 68  loss: 0.05258260\n",
      "epoch: 103  batch: 1  loss: 0.13129921\n",
      "epoch: 103  batch: 2  loss: 0.04353878\n",
      "epoch: 103  batch: 3  loss: 0.03846181\n",
      "epoch: 103  batch: 4  loss: 0.03356751\n",
      "epoch: 103  batch: 5  loss: 0.09302811\n",
      "epoch: 103  batch: 6  loss: 0.08585273\n",
      "epoch: 103  batch: 7  loss: 0.19558950\n",
      "epoch: 103  batch: 8  loss: 0.07862525\n",
      "epoch: 103  batch: 9  loss: 0.09321065\n",
      "epoch: 103  batch: 10  loss: 0.21633504\n",
      "epoch: 103  batch: 11  loss: 0.26046070\n",
      "epoch: 103  batch: 12  loss: 0.08159022\n",
      "epoch: 103  batch: 13  loss: 0.15343674\n",
      "epoch: 103  batch: 14  loss: 0.15933344\n",
      "epoch: 103  batch: 15  loss: 0.10729570\n",
      "epoch: 103  batch: 16  loss: 0.06272069\n",
      "epoch: 103  batch: 17  loss: 0.05109320\n",
      "epoch: 103  batch: 18  loss: 0.04776946\n",
      "epoch: 103  batch: 19  loss: 0.04692267\n",
      "epoch: 103  batch: 20  loss: 0.29901519\n",
      "epoch: 103  batch: 21  loss: 0.29443279\n",
      "epoch: 103  batch: 22  loss: 0.06151524\n",
      "epoch: 103  batch: 23  loss: 0.04401100\n",
      "epoch: 103  batch: 24  loss: 0.08103503\n",
      "epoch: 103  batch: 25  loss: 0.08021394\n",
      "epoch: 103  batch: 26  loss: 0.01844268\n",
      "epoch: 103  batch: 27  loss: 0.08701345\n",
      "epoch: 103  batch: 28  loss: 0.01653117\n",
      "epoch: 103  batch: 29  loss: 0.02081014\n",
      "epoch: 103  batch: 30  loss: 0.02185206\n",
      "epoch: 103  batch: 31  loss: 0.02704697\n",
      "epoch: 103  batch: 32  loss: 0.01210609\n",
      "epoch: 103  batch: 33  loss: 0.04543065\n",
      "epoch: 103  batch: 34  loss: 0.09433179\n",
      "epoch: 103  batch: 35  loss: 0.14181048\n",
      "epoch: 103  batch: 36  loss: 0.06005769\n",
      "epoch: 103  batch: 37  loss: 0.03939526\n",
      "epoch: 103  batch: 38  loss: 0.03999430\n",
      "epoch: 103  batch: 39  loss: 0.13693292\n",
      "epoch: 103  batch: 40  loss: 0.06364770\n",
      "epoch: 103  batch: 41  loss: 0.16940236\n",
      "epoch: 103  batch: 42  loss: 0.07774613\n",
      "epoch: 103  batch: 43  loss: 0.13135771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103  batch: 44  loss: 0.20215617\n",
      "epoch: 103  batch: 45  loss: 0.21283644\n",
      "epoch: 103  batch: 46  loss: 0.10394673\n",
      "epoch: 103  batch: 47  loss: 0.08517512\n",
      "epoch: 103  batch: 48  loss: 0.13662182\n",
      "epoch: 103  batch: 49  loss: 0.12760715\n",
      "epoch: 103  batch: 50  loss: 0.21544309\n",
      "epoch: 103  batch: 51  loss: 0.07648292\n",
      "epoch: 103  batch: 52  loss: 0.08351441\n",
      "epoch: 103  batch: 53  loss: 0.05651116\n",
      "epoch: 103  batch: 54  loss: 0.33474392\n",
      "epoch: 103  batch: 55  loss: 0.21424091\n",
      "epoch: 103  batch: 56  loss: 0.07837763\n",
      "epoch: 103  batch: 57  loss: 0.04159398\n",
      "epoch: 103  batch: 58  loss: 0.11451334\n",
      "epoch: 103  batch: 59  loss: 0.08631906\n",
      "epoch: 103  batch: 60  loss: 0.12553057\n",
      "epoch: 103  batch: 61  loss: 0.76509064\n",
      "epoch: 103  batch: 62  loss: 0.18537560\n",
      "epoch: 103  batch: 63  loss: 0.03914941\n",
      "epoch: 103  batch: 64  loss: 0.02864865\n",
      "epoch: 103  batch: 65  loss: 0.04057686\n",
      "epoch: 103  batch: 66  loss: 0.04151873\n",
      "epoch: 103  batch: 67  loss: 0.03368253\n",
      "epoch: 103  batch: 68  loss: 0.05237056\n",
      "epoch: 104  batch: 1  loss: 0.13114345\n",
      "epoch: 104  batch: 2  loss: 0.04355885\n",
      "epoch: 104  batch: 3  loss: 0.03806849\n",
      "epoch: 104  batch: 4  loss: 0.03356903\n",
      "epoch: 104  batch: 5  loss: 0.09253298\n",
      "epoch: 104  batch: 6  loss: 0.08500344\n",
      "epoch: 104  batch: 7  loss: 0.19521421\n",
      "epoch: 104  batch: 8  loss: 0.07749969\n",
      "epoch: 104  batch: 9  loss: 0.09216250\n",
      "epoch: 104  batch: 10  loss: 0.21344084\n",
      "epoch: 104  batch: 11  loss: 0.25839639\n",
      "epoch: 104  batch: 12  loss: 0.08086621\n",
      "epoch: 104  batch: 13  loss: 0.14737836\n",
      "epoch: 104  batch: 14  loss: 0.15873888\n",
      "epoch: 104  batch: 15  loss: 0.10756258\n",
      "epoch: 104  batch: 16  loss: 0.06265666\n",
      "epoch: 104  batch: 17  loss: 0.05091198\n",
      "epoch: 104  batch: 18  loss: 0.04658851\n",
      "epoch: 104  batch: 19  loss: 0.04711834\n",
      "epoch: 104  batch: 20  loss: 0.29830384\n",
      "epoch: 104  batch: 21  loss: 0.29370719\n",
      "epoch: 104  batch: 22  loss: 0.06072418\n",
      "epoch: 104  batch: 23  loss: 0.04373763\n",
      "epoch: 104  batch: 24  loss: 0.08016144\n",
      "epoch: 104  batch: 25  loss: 0.07958087\n",
      "epoch: 104  batch: 26  loss: 0.01825496\n",
      "epoch: 104  batch: 27  loss: 0.08470603\n",
      "epoch: 104  batch: 28  loss: 0.01639416\n",
      "epoch: 104  batch: 29  loss: 0.01870324\n",
      "epoch: 104  batch: 30  loss: 0.02080211\n",
      "epoch: 104  batch: 31  loss: 0.02696904\n",
      "epoch: 104  batch: 32  loss: 0.01208836\n",
      "epoch: 104  batch: 33  loss: 0.04467328\n",
      "epoch: 104  batch: 34  loss: 0.09421895\n",
      "epoch: 104  batch: 35  loss: 0.14169134\n",
      "epoch: 104  batch: 36  loss: 0.06034485\n",
      "epoch: 104  batch: 37  loss: 0.03928058\n",
      "epoch: 104  batch: 38  loss: 0.03968116\n",
      "epoch: 104  batch: 39  loss: 0.13630681\n",
      "epoch: 104  batch: 40  loss: 0.06354547\n",
      "epoch: 104  batch: 41  loss: 0.16908465\n",
      "epoch: 104  batch: 42  loss: 0.07718927\n",
      "epoch: 104  batch: 43  loss: 0.13062115\n",
      "epoch: 104  batch: 44  loss: 0.20113310\n",
      "epoch: 104  batch: 45  loss: 0.21032710\n",
      "epoch: 104  batch: 46  loss: 0.10273249\n",
      "epoch: 104  batch: 47  loss: 0.08463475\n",
      "epoch: 104  batch: 48  loss: 0.13679096\n",
      "epoch: 104  batch: 49  loss: 0.12783617\n",
      "epoch: 104  batch: 50  loss: 0.21223454\n",
      "epoch: 104  batch: 51  loss: 0.07654250\n",
      "epoch: 104  batch: 52  loss: 0.08410314\n",
      "epoch: 104  batch: 53  loss: 0.05659597\n",
      "epoch: 104  batch: 54  loss: 0.33428913\n",
      "epoch: 104  batch: 55  loss: 0.21338651\n",
      "epoch: 104  batch: 56  loss: 0.07852887\n",
      "epoch: 104  batch: 57  loss: 0.04136995\n",
      "epoch: 104  batch: 58  loss: 0.11458073\n",
      "epoch: 104  batch: 59  loss: 0.08658346\n",
      "epoch: 104  batch: 60  loss: 0.11831542\n",
      "epoch: 104  batch: 61  loss: 0.75292683\n",
      "epoch: 104  batch: 62  loss: 0.18123047\n",
      "epoch: 104  batch: 63  loss: 0.03772674\n",
      "epoch: 104  batch: 64  loss: 0.02774139\n",
      "epoch: 104  batch: 65  loss: 0.04066207\n",
      "epoch: 104  batch: 66  loss: 0.04137623\n",
      "epoch: 104  batch: 67  loss: 0.03373030\n",
      "epoch: 104  batch: 68  loss: 0.05216338\n",
      "epoch: 105  batch: 1  loss: 0.13109235\n",
      "epoch: 105  batch: 2  loss: 0.04358509\n",
      "epoch: 105  batch: 3  loss: 0.03771533\n",
      "epoch: 105  batch: 4  loss: 0.03352726\n",
      "epoch: 105  batch: 5  loss: 0.09211584\n",
      "epoch: 105  batch: 6  loss: 0.08425499\n",
      "epoch: 105  batch: 7  loss: 0.19495049\n",
      "epoch: 105  batch: 8  loss: 0.07655486\n",
      "epoch: 105  batch: 9  loss: 0.09112354\n",
      "epoch: 105  batch: 10  loss: 0.21090652\n",
      "epoch: 105  batch: 11  loss: 0.25665569\n",
      "epoch: 105  batch: 12  loss: 0.08021414\n",
      "epoch: 105  batch: 13  loss: 0.14069194\n",
      "epoch: 105  batch: 14  loss: 0.15800054\n",
      "epoch: 105  batch: 15  loss: 0.10786436\n",
      "epoch: 105  batch: 16  loss: 0.06273538\n",
      "epoch: 105  batch: 17  loss: 0.05079481\n",
      "epoch: 105  batch: 18  loss: 0.04592077\n",
      "epoch: 105  batch: 19  loss: 0.04750870\n",
      "epoch: 105  batch: 20  loss: 0.29734999\n",
      "epoch: 105  batch: 21  loss: 0.29302728\n",
      "epoch: 105  batch: 22  loss: 0.06000505\n",
      "epoch: 105  batch: 23  loss: 0.04351656\n",
      "epoch: 105  batch: 24  loss: 0.07933845\n",
      "epoch: 105  batch: 25  loss: 0.07915177\n",
      "epoch: 105  batch: 26  loss: 0.01810410\n",
      "epoch: 105  batch: 27  loss: 0.08263186\n",
      "epoch: 105  batch: 28  loss: 0.01620187\n",
      "epoch: 105  batch: 29  loss: 0.01714673\n",
      "epoch: 105  batch: 30  loss: 0.02023309\n",
      "epoch: 105  batch: 31  loss: 0.02693632\n",
      "epoch: 105  batch: 32  loss: 0.01210269\n",
      "epoch: 105  batch: 33  loss: 0.04411882\n",
      "epoch: 105  batch: 34  loss: 0.09404384\n",
      "epoch: 105  batch: 35  loss: 0.14153765\n",
      "epoch: 105  batch: 36  loss: 0.06069604\n",
      "epoch: 105  batch: 37  loss: 0.03918521\n",
      "epoch: 105  batch: 38  loss: 0.03959592\n",
      "epoch: 105  batch: 39  loss: 0.13555904\n",
      "epoch: 105  batch: 40  loss: 0.06347273\n",
      "epoch: 105  batch: 41  loss: 0.16873696\n",
      "epoch: 105  batch: 42  loss: 0.07663856\n",
      "epoch: 105  batch: 43  loss: 0.13000961\n",
      "epoch: 105  batch: 44  loss: 0.20010816\n",
      "epoch: 105  batch: 45  loss: 0.20780423\n",
      "epoch: 105  batch: 46  loss: 0.10153389\n",
      "epoch: 105  batch: 47  loss: 0.08415534\n",
      "epoch: 105  batch: 48  loss: 0.13695344\n",
      "epoch: 105  batch: 49  loss: 0.12813982\n",
      "epoch: 105  batch: 50  loss: 0.20814170\n",
      "epoch: 105  batch: 51  loss: 0.07663851\n",
      "epoch: 105  batch: 52  loss: 0.08472697\n",
      "epoch: 105  batch: 53  loss: 0.05667594\n",
      "epoch: 105  batch: 54  loss: 0.33380529\n",
      "epoch: 105  batch: 55  loss: 0.21234174\n",
      "epoch: 105  batch: 56  loss: 0.07867400\n",
      "epoch: 105  batch: 57  loss: 0.04116349\n",
      "epoch: 105  batch: 58  loss: 0.11464944\n",
      "epoch: 105  batch: 59  loss: 0.08683004\n",
      "epoch: 105  batch: 60  loss: 0.11118019\n",
      "epoch: 105  batch: 61  loss: 0.73417944\n",
      "epoch: 105  batch: 62  loss: 0.17598423\n",
      "epoch: 105  batch: 63  loss: 0.03663834\n",
      "epoch: 105  batch: 64  loss: 0.02684148\n",
      "epoch: 105  batch: 65  loss: 0.04073052\n",
      "epoch: 105  batch: 66  loss: 0.04126041\n",
      "epoch: 105  batch: 67  loss: 0.03382128\n",
      "epoch: 105  batch: 68  loss: 0.05198255\n",
      "epoch: 106  batch: 1  loss: 0.13121240\n",
      "epoch: 106  batch: 2  loss: 0.04361304\n",
      "epoch: 106  batch: 3  loss: 0.03751440\n",
      "epoch: 106  batch: 4  loss: 0.03328842\n",
      "epoch: 106  batch: 5  loss: 0.09179467\n",
      "epoch: 106  batch: 6  loss: 0.08348899\n",
      "epoch: 106  batch: 7  loss: 0.19473301\n",
      "epoch: 106  batch: 8  loss: 0.07590927\n",
      "epoch: 106  batch: 9  loss: 0.09007789\n",
      "epoch: 106  batch: 10  loss: 0.20924732\n",
      "epoch: 106  batch: 11  loss: 0.25580865\n",
      "epoch: 106  batch: 12  loss: 0.07980499\n",
      "epoch: 106  batch: 13  loss: 0.13312431\n",
      "epoch: 106  batch: 14  loss: 0.15685353\n",
      "epoch: 106  batch: 15  loss: 0.10817159\n",
      "epoch: 106  batch: 16  loss: 0.06308446\n",
      "epoch: 106  batch: 17  loss: 0.05072322\n",
      "epoch: 106  batch: 18  loss: 0.04564672\n",
      "epoch: 106  batch: 19  loss: 0.04861564\n",
      "epoch: 106  batch: 20  loss: 0.29648447\n",
      "epoch: 106  batch: 21  loss: 0.29237041\n",
      "epoch: 106  batch: 22  loss: 0.05919415\n",
      "epoch: 106  batch: 23  loss: 0.04332299\n",
      "epoch: 106  batch: 24  loss: 0.07853246\n",
      "epoch: 106  batch: 25  loss: 0.07901617\n",
      "epoch: 106  batch: 26  loss: 0.01795534\n",
      "epoch: 106  batch: 27  loss: 0.08131330\n",
      "epoch: 106  batch: 28  loss: 0.01608775\n",
      "epoch: 106  batch: 29  loss: 0.01596507\n",
      "epoch: 106  batch: 30  loss: 0.02026962\n",
      "epoch: 106  batch: 31  loss: 0.02692988\n",
      "epoch: 106  batch: 32  loss: 0.01213821\n",
      "epoch: 106  batch: 33  loss: 0.04416934\n",
      "epoch: 106  batch: 34  loss: 0.09377953\n",
      "epoch: 106  batch: 35  loss: 0.14140251\n",
      "epoch: 106  batch: 36  loss: 0.06107809\n",
      "epoch: 106  batch: 37  loss: 0.03908289\n",
      "epoch: 106  batch: 38  loss: 0.03983560\n",
      "epoch: 106  batch: 39  loss: 0.13476938\n",
      "epoch: 106  batch: 40  loss: 0.06341045\n",
      "epoch: 106  batch: 41  loss: 0.16838029\n",
      "epoch: 106  batch: 42  loss: 0.07607120\n",
      "epoch: 106  batch: 43  loss: 0.12972240\n",
      "epoch: 106  batch: 44  loss: 0.19887204\n",
      "epoch: 106  batch: 45  loss: 0.20512915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106  batch: 46  loss: 0.10032615\n",
      "epoch: 106  batch: 47  loss: 0.08367211\n",
      "epoch: 106  batch: 48  loss: 0.13759665\n",
      "epoch: 106  batch: 49  loss: 0.12851869\n",
      "epoch: 106  batch: 50  loss: 0.20282444\n",
      "epoch: 106  batch: 51  loss: 0.07686535\n",
      "epoch: 106  batch: 52  loss: 0.08548107\n",
      "epoch: 106  batch: 53  loss: 0.05704508\n",
      "epoch: 106  batch: 54  loss: 0.33322453\n",
      "epoch: 106  batch: 55  loss: 0.21078154\n",
      "epoch: 106  batch: 56  loss: 0.07889898\n",
      "epoch: 106  batch: 57  loss: 0.04101130\n",
      "epoch: 106  batch: 58  loss: 0.11530845\n",
      "epoch: 106  batch: 59  loss: 0.08704455\n",
      "epoch: 106  batch: 60  loss: 0.10351656\n",
      "epoch: 106  batch: 61  loss: 0.69680959\n",
      "epoch: 106  batch: 62  loss: 0.16945791\n",
      "epoch: 106  batch: 63  loss: 0.03601244\n",
      "epoch: 106  batch: 64  loss: 0.02594399\n",
      "epoch: 106  batch: 65  loss: 0.04076420\n",
      "epoch: 106  batch: 66  loss: 0.04107495\n",
      "epoch: 106  batch: 67  loss: 0.03394675\n",
      "epoch: 106  batch: 68  loss: 0.05181530\n",
      "epoch: 107  batch: 1  loss: 0.13164765\n",
      "epoch: 107  batch: 2  loss: 0.04364013\n",
      "epoch: 107  batch: 3  loss: 0.03721890\n",
      "epoch: 107  batch: 4  loss: 0.03283234\n",
      "epoch: 107  batch: 5  loss: 0.09160271\n",
      "epoch: 107  batch: 6  loss: 0.08279742\n",
      "epoch: 107  batch: 7  loss: 0.19453886\n",
      "epoch: 107  batch: 8  loss: 0.07539475\n",
      "epoch: 107  batch: 9  loss: 0.08896975\n",
      "epoch: 107  batch: 10  loss: 0.20814352\n",
      "epoch: 107  batch: 11  loss: 0.25636765\n",
      "epoch: 107  batch: 12  loss: 0.07960271\n",
      "epoch: 107  batch: 13  loss: 0.12505993\n",
      "epoch: 107  batch: 14  loss: 0.15533766\n",
      "epoch: 107  batch: 15  loss: 0.10851574\n",
      "epoch: 107  batch: 16  loss: 0.06333452\n",
      "epoch: 107  batch: 17  loss: 0.05078580\n",
      "epoch: 107  batch: 18  loss: 0.04590241\n",
      "epoch: 107  batch: 19  loss: 0.05023917\n",
      "epoch: 107  batch: 20  loss: 0.29490757\n",
      "epoch: 107  batch: 21  loss: 0.29174379\n",
      "epoch: 107  batch: 22  loss: 0.05837684\n",
      "epoch: 107  batch: 23  loss: 0.04312827\n",
      "epoch: 107  batch: 24  loss: 0.07748955\n",
      "epoch: 107  batch: 25  loss: 0.07887049\n",
      "epoch: 107  batch: 26  loss: 0.01780372\n",
      "epoch: 107  batch: 27  loss: 0.08058976\n",
      "epoch: 107  batch: 28  loss: 0.01599538\n",
      "epoch: 107  batch: 29  loss: 0.01544003\n",
      "epoch: 107  batch: 30  loss: 0.02084404\n",
      "epoch: 107  batch: 31  loss: 0.02692711\n",
      "epoch: 107  batch: 32  loss: 0.01219709\n",
      "epoch: 107  batch: 33  loss: 0.04446636\n",
      "epoch: 107  batch: 34  loss: 0.09353080\n",
      "epoch: 107  batch: 35  loss: 0.14124455\n",
      "epoch: 107  batch: 36  loss: 0.06156623\n",
      "epoch: 107  batch: 37  loss: 0.03900879\n",
      "epoch: 107  batch: 38  loss: 0.04014628\n",
      "epoch: 107  batch: 39  loss: 0.13396433\n",
      "epoch: 107  batch: 40  loss: 0.06338525\n",
      "epoch: 107  batch: 41  loss: 0.16798072\n",
      "epoch: 107  batch: 42  loss: 0.07547892\n",
      "epoch: 107  batch: 43  loss: 0.12962006\n",
      "epoch: 107  batch: 44  loss: 0.19777328\n",
      "epoch: 107  batch: 45  loss: 0.20246553\n",
      "epoch: 107  batch: 46  loss: 0.09918866\n",
      "epoch: 107  batch: 47  loss: 0.08315501\n",
      "epoch: 107  batch: 48  loss: 0.13836226\n",
      "epoch: 107  batch: 49  loss: 0.12901244\n",
      "epoch: 107  batch: 50  loss: 0.19698524\n",
      "epoch: 107  batch: 51  loss: 0.07719690\n",
      "epoch: 107  batch: 52  loss: 0.08630474\n",
      "epoch: 107  batch: 53  loss: 0.05842974\n",
      "epoch: 107  batch: 54  loss: 0.33263332\n",
      "epoch: 107  batch: 55  loss: 0.20912074\n",
      "epoch: 107  batch: 56  loss: 0.07913488\n",
      "epoch: 107  batch: 57  loss: 0.04107101\n",
      "epoch: 107  batch: 58  loss: 0.11576556\n",
      "epoch: 107  batch: 59  loss: 0.08731874\n",
      "epoch: 107  batch: 60  loss: 0.09544978\n",
      "epoch: 107  batch: 61  loss: 0.64316553\n",
      "epoch: 107  batch: 62  loss: 0.16247553\n",
      "epoch: 107  batch: 63  loss: 0.03563882\n",
      "epoch: 107  batch: 64  loss: 0.02513580\n",
      "epoch: 107  batch: 65  loss: 0.04075975\n",
      "epoch: 107  batch: 66  loss: 0.04083278\n",
      "epoch: 107  batch: 67  loss: 0.03399439\n",
      "epoch: 107  batch: 68  loss: 0.05163796\n",
      "epoch: 108  batch: 1  loss: 0.13195516\n",
      "epoch: 108  batch: 2  loss: 0.04363327\n",
      "epoch: 108  batch: 3  loss: 0.03676492\n",
      "epoch: 108  batch: 4  loss: 0.03248146\n",
      "epoch: 108  batch: 5  loss: 0.09129154\n",
      "epoch: 108  batch: 6  loss: 0.08236841\n",
      "epoch: 108  batch: 7  loss: 0.19418323\n",
      "epoch: 108  batch: 8  loss: 0.07447853\n",
      "epoch: 108  batch: 9  loss: 0.08782671\n",
      "epoch: 108  batch: 10  loss: 0.20568866\n",
      "epoch: 108  batch: 11  loss: 0.25447968\n",
      "epoch: 108  batch: 12  loss: 0.07935577\n",
      "epoch: 108  batch: 13  loss: 0.11836012\n",
      "epoch: 108  batch: 14  loss: 0.15414028\n",
      "epoch: 108  batch: 15  loss: 0.10898658\n",
      "epoch: 108  batch: 16  loss: 0.06278238\n",
      "epoch: 108  batch: 17  loss: 0.05100471\n",
      "epoch: 108  batch: 18  loss: 0.04631054\n",
      "epoch: 108  batch: 19  loss: 0.05110070\n",
      "epoch: 108  batch: 20  loss: 0.29308346\n",
      "epoch: 108  batch: 21  loss: 0.29120934\n",
      "epoch: 108  batch: 22  loss: 0.05774588\n",
      "epoch: 108  batch: 23  loss: 0.04303956\n",
      "epoch: 108  batch: 24  loss: 0.07617514\n",
      "epoch: 108  batch: 25  loss: 0.07830792\n",
      "epoch: 108  batch: 26  loss: 0.01764761\n",
      "epoch: 108  batch: 27  loss: 0.07944060\n",
      "epoch: 108  batch: 28  loss: 0.01581828\n",
      "epoch: 108  batch: 29  loss: 0.01538869\n",
      "epoch: 108  batch: 30  loss: 0.02126411\n",
      "epoch: 108  batch: 31  loss: 0.02692569\n",
      "epoch: 108  batch: 32  loss: 0.01225967\n",
      "epoch: 108  batch: 33  loss: 0.04417952\n",
      "epoch: 108  batch: 34  loss: 0.09345086\n",
      "epoch: 108  batch: 35  loss: 0.14098801\n",
      "epoch: 108  batch: 36  loss: 0.06225865\n",
      "epoch: 108  batch: 37  loss: 0.03898840\n",
      "epoch: 108  batch: 38  loss: 0.04013230\n",
      "epoch: 108  batch: 39  loss: 0.13307537\n",
      "epoch: 108  batch: 40  loss: 0.06344674\n",
      "epoch: 108  batch: 41  loss: 0.16745628\n",
      "epoch: 108  batch: 42  loss: 0.07485260\n",
      "epoch: 108  batch: 43  loss: 0.12879033\n",
      "epoch: 108  batch: 44  loss: 0.19615224\n",
      "epoch: 108  batch: 45  loss: 0.19966692\n",
      "epoch: 108  batch: 46  loss: 0.09815977\n",
      "epoch: 108  batch: 47  loss: 0.08279253\n",
      "epoch: 108  batch: 48  loss: 0.13851811\n",
      "epoch: 108  batch: 49  loss: 0.12958051\n",
      "epoch: 108  batch: 50  loss: 0.19149077\n",
      "epoch: 108  batch: 51  loss: 0.07746904\n",
      "epoch: 108  batch: 52  loss: 0.08707210\n",
      "epoch: 108  batch: 53  loss: 0.05954236\n",
      "epoch: 108  batch: 54  loss: 0.33211273\n",
      "epoch: 108  batch: 55  loss: 0.20818463\n",
      "epoch: 108  batch: 56  loss: 0.07935036\n",
      "epoch: 108  batch: 57  loss: 0.04128618\n",
      "epoch: 108  batch: 58  loss: 0.11549989\n",
      "epoch: 108  batch: 59  loss: 0.08765177\n",
      "epoch: 108  batch: 60  loss: 0.08788697\n",
      "epoch: 108  batch: 61  loss: 0.59303945\n",
      "epoch: 108  batch: 62  loss: 0.15563869\n",
      "epoch: 108  batch: 63  loss: 0.03511100\n",
      "epoch: 108  batch: 64  loss: 0.02437835\n",
      "epoch: 108  batch: 65  loss: 0.04072151\n",
      "epoch: 108  batch: 66  loss: 0.04065818\n",
      "epoch: 108  batch: 67  loss: 0.03402400\n",
      "epoch: 108  batch: 68  loss: 0.05141725\n",
      "epoch: 109  batch: 1  loss: 0.13224176\n",
      "epoch: 109  batch: 2  loss: 0.04362115\n",
      "epoch: 109  batch: 3  loss: 0.03626392\n",
      "epoch: 109  batch: 4  loss: 0.03218647\n",
      "epoch: 109  batch: 5  loss: 0.09088296\n",
      "epoch: 109  batch: 6  loss: 0.08196669\n",
      "epoch: 109  batch: 7  loss: 0.19370456\n",
      "epoch: 109  batch: 8  loss: 0.07326975\n",
      "epoch: 109  batch: 9  loss: 0.08666550\n",
      "epoch: 109  batch: 10  loss: 0.20249571\n",
      "epoch: 109  batch: 11  loss: 0.25076661\n",
      "epoch: 109  batch: 12  loss: 0.07917071\n",
      "epoch: 109  batch: 13  loss: 0.11269923\n",
      "epoch: 109  batch: 14  loss: 0.15298605\n",
      "epoch: 109  batch: 15  loss: 0.10954843\n",
      "epoch: 109  batch: 16  loss: 0.06183783\n",
      "epoch: 109  batch: 17  loss: 0.05127132\n",
      "epoch: 109  batch: 18  loss: 0.04667733\n",
      "epoch: 109  batch: 19  loss: 0.05156945\n",
      "epoch: 109  batch: 20  loss: 0.29052681\n",
      "epoch: 109  batch: 21  loss: 0.29065824\n",
      "epoch: 109  batch: 22  loss: 0.05721529\n",
      "epoch: 109  batch: 23  loss: 0.04303214\n",
      "epoch: 109  batch: 24  loss: 0.07477000\n",
      "epoch: 109  batch: 25  loss: 0.07771888\n",
      "epoch: 109  batch: 26  loss: 0.01751431\n",
      "epoch: 109  batch: 27  loss: 0.07788778\n",
      "epoch: 109  batch: 28  loss: 0.01562949\n",
      "epoch: 109  batch: 29  loss: 0.01549532\n",
      "epoch: 109  batch: 30  loss: 0.02155737\n",
      "epoch: 109  batch: 31  loss: 0.02692343\n",
      "epoch: 109  batch: 32  loss: 0.01232121\n",
      "epoch: 109  batch: 33  loss: 0.04364781\n",
      "epoch: 109  batch: 34  loss: 0.09342635\n",
      "epoch: 109  batch: 35  loss: 0.14065312\n",
      "epoch: 109  batch: 36  loss: 0.06304250\n",
      "epoch: 109  batch: 37  loss: 0.03900092\n",
      "epoch: 109  batch: 38  loss: 0.03988244\n",
      "epoch: 109  batch: 39  loss: 0.13213782\n",
      "epoch: 109  batch: 40  loss: 0.06357675\n",
      "epoch: 109  batch: 41  loss: 0.16683084\n",
      "epoch: 109  batch: 42  loss: 0.07419372\n",
      "epoch: 109  batch: 43  loss: 0.12759270\n",
      "epoch: 109  batch: 44  loss: 0.19406858\n",
      "epoch: 109  batch: 45  loss: 0.19673662\n",
      "epoch: 109  batch: 46  loss: 0.09704655\n",
      "epoch: 109  batch: 47  loss: 0.08235551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109  batch: 48  loss: 0.13842833\n",
      "epoch: 109  batch: 49  loss: 0.13017327\n",
      "epoch: 109  batch: 50  loss: 0.18580903\n",
      "epoch: 109  batch: 51  loss: 0.07771125\n",
      "epoch: 109  batch: 52  loss: 0.08779737\n",
      "epoch: 109  batch: 53  loss: 0.05993729\n",
      "epoch: 109  batch: 54  loss: 0.33158630\n",
      "epoch: 109  batch: 55  loss: 0.20771968\n",
      "epoch: 109  batch: 56  loss: 0.07951459\n",
      "epoch: 109  batch: 57  loss: 0.04156177\n",
      "epoch: 109  batch: 58  loss: 0.11493376\n",
      "epoch: 109  batch: 59  loss: 0.08798406\n",
      "epoch: 109  batch: 60  loss: 0.08044536\n",
      "epoch: 109  batch: 61  loss: 0.54743975\n",
      "epoch: 109  batch: 62  loss: 0.14866613\n",
      "epoch: 109  batch: 63  loss: 0.03463047\n",
      "epoch: 109  batch: 64  loss: 0.02366411\n",
      "epoch: 109  batch: 65  loss: 0.04064374\n",
      "epoch: 109  batch: 66  loss: 0.04048917\n",
      "epoch: 109  batch: 67  loss: 0.03404225\n",
      "epoch: 109  batch: 68  loss: 0.05118121\n",
      "epoch: 110  batch: 1  loss: 0.13247691\n",
      "epoch: 110  batch: 2  loss: 0.04360734\n",
      "epoch: 110  batch: 3  loss: 0.03576597\n",
      "epoch: 110  batch: 4  loss: 0.03191231\n",
      "epoch: 110  batch: 5  loss: 0.09045671\n",
      "epoch: 110  batch: 6  loss: 0.08150951\n",
      "epoch: 110  batch: 7  loss: 0.19313826\n",
      "epoch: 110  batch: 8  loss: 0.07189221\n",
      "epoch: 110  batch: 9  loss: 0.08544960\n",
      "epoch: 110  batch: 10  loss: 0.19893430\n",
      "epoch: 110  batch: 11  loss: 0.24695240\n",
      "epoch: 110  batch: 12  loss: 0.07890180\n",
      "epoch: 110  batch: 13  loss: 0.10749029\n",
      "epoch: 110  batch: 14  loss: 0.15179858\n",
      "epoch: 110  batch: 15  loss: 0.11016539\n",
      "epoch: 110  batch: 16  loss: 0.06080469\n",
      "epoch: 110  batch: 17  loss: 0.05147514\n",
      "epoch: 110  batch: 18  loss: 0.04708266\n",
      "epoch: 110  batch: 19  loss: 0.05178766\n",
      "epoch: 110  batch: 20  loss: 0.28738469\n",
      "epoch: 110  batch: 21  loss: 0.29019180\n",
      "epoch: 110  batch: 22  loss: 0.05670759\n",
      "epoch: 110  batch: 23  loss: 0.04303367\n",
      "epoch: 110  batch: 24  loss: 0.07335465\n",
      "epoch: 110  batch: 25  loss: 0.07712514\n",
      "epoch: 110  batch: 26  loss: 0.01742865\n",
      "epoch: 110  batch: 27  loss: 0.07594529\n",
      "epoch: 110  batch: 28  loss: 0.01545488\n",
      "epoch: 110  batch: 29  loss: 0.01562010\n",
      "epoch: 110  batch: 30  loss: 0.02175074\n",
      "epoch: 110  batch: 31  loss: 0.02691332\n",
      "epoch: 110  batch: 32  loss: 0.01236671\n",
      "epoch: 110  batch: 33  loss: 0.04294572\n",
      "epoch: 110  batch: 34  loss: 0.09338839\n",
      "epoch: 110  batch: 35  loss: 0.14028780\n",
      "epoch: 110  batch: 36  loss: 0.06387638\n",
      "epoch: 110  batch: 37  loss: 0.03902607\n",
      "epoch: 110  batch: 38  loss: 0.03935555\n",
      "epoch: 110  batch: 39  loss: 0.13126116\n",
      "epoch: 110  batch: 40  loss: 0.06375065\n",
      "epoch: 110  batch: 41  loss: 0.16614428\n",
      "epoch: 110  batch: 42  loss: 0.07351102\n",
      "epoch: 110  batch: 43  loss: 0.12610818\n",
      "epoch: 110  batch: 44  loss: 0.19151099\n",
      "epoch: 110  batch: 45  loss: 0.19376698\n",
      "epoch: 110  batch: 46  loss: 0.09574362\n",
      "epoch: 110  batch: 47  loss: 0.08201652\n",
      "epoch: 110  batch: 48  loss: 0.13801979\n",
      "epoch: 110  batch: 49  loss: 0.13084708\n",
      "epoch: 110  batch: 50  loss: 0.17963377\n",
      "epoch: 110  batch: 51  loss: 0.07790693\n",
      "epoch: 110  batch: 52  loss: 0.08843785\n",
      "epoch: 110  batch: 53  loss: 0.05982850\n",
      "epoch: 110  batch: 54  loss: 0.33105826\n",
      "epoch: 110  batch: 55  loss: 0.20784679\n",
      "epoch: 110  batch: 56  loss: 0.07962296\n",
      "epoch: 110  batch: 57  loss: 0.04180103\n",
      "epoch: 110  batch: 58  loss: 0.11399710\n",
      "epoch: 110  batch: 59  loss: 0.08825917\n",
      "epoch: 110  batch: 60  loss: 0.07300199\n",
      "epoch: 110  batch: 61  loss: 0.50756425\n",
      "epoch: 110  batch: 62  loss: 0.14189227\n",
      "epoch: 110  batch: 63  loss: 0.03413935\n",
      "epoch: 110  batch: 64  loss: 0.02297652\n",
      "epoch: 110  batch: 65  loss: 0.04058336\n",
      "epoch: 110  batch: 66  loss: 0.04039029\n",
      "epoch: 110  batch: 67  loss: 0.03408997\n",
      "epoch: 110  batch: 68  loss: 0.05092521\n",
      "epoch: 111  batch: 1  loss: 0.13253996\n",
      "epoch: 111  batch: 2  loss: 0.04356858\n",
      "epoch: 111  batch: 3  loss: 0.03526119\n",
      "epoch: 111  batch: 4  loss: 0.03168361\n",
      "epoch: 111  batch: 5  loss: 0.08995157\n",
      "epoch: 111  batch: 6  loss: 0.08105545\n",
      "epoch: 111  batch: 7  loss: 0.19248579\n",
      "epoch: 111  batch: 8  loss: 0.07039334\n",
      "epoch: 111  batch: 9  loss: 0.08423163\n",
      "epoch: 111  batch: 10  loss: 0.19513892\n",
      "epoch: 111  batch: 11  loss: 0.24282518\n",
      "epoch: 111  batch: 12  loss: 0.07856433\n",
      "epoch: 111  batch: 13  loss: 0.10291194\n",
      "epoch: 111  batch: 14  loss: 0.15091418\n",
      "epoch: 111  batch: 15  loss: 0.11081214\n",
      "epoch: 111  batch: 16  loss: 0.05966463\n",
      "epoch: 111  batch: 17  loss: 0.05163672\n",
      "epoch: 111  batch: 18  loss: 0.04737862\n",
      "epoch: 111  batch: 19  loss: 0.05175469\n",
      "epoch: 111  batch: 20  loss: 0.28394002\n",
      "epoch: 111  batch: 21  loss: 0.28958195\n",
      "epoch: 111  batch: 22  loss: 0.05627392\n",
      "epoch: 111  batch: 23  loss: 0.04304812\n",
      "epoch: 111  batch: 24  loss: 0.07215620\n",
      "epoch: 111  batch: 25  loss: 0.07646716\n",
      "epoch: 111  batch: 26  loss: 0.01741520\n",
      "epoch: 111  batch: 27  loss: 0.07366562\n",
      "epoch: 111  batch: 28  loss: 0.01531645\n",
      "epoch: 111  batch: 29  loss: 0.01568852\n",
      "epoch: 111  batch: 30  loss: 0.02126587\n",
      "epoch: 111  batch: 31  loss: 0.02688402\n",
      "epoch: 111  batch: 32  loss: 0.01239025\n",
      "epoch: 111  batch: 33  loss: 0.04217093\n",
      "epoch: 111  batch: 34  loss: 0.09336793\n",
      "epoch: 111  batch: 35  loss: 0.13991827\n",
      "epoch: 111  batch: 36  loss: 0.06476220\n",
      "epoch: 111  batch: 37  loss: 0.03906266\n",
      "epoch: 111  batch: 38  loss: 0.03868743\n",
      "epoch: 111  batch: 39  loss: 0.13052133\n",
      "epoch: 111  batch: 40  loss: 0.06399016\n",
      "epoch: 111  batch: 41  loss: 0.16541918\n",
      "epoch: 111  batch: 42  loss: 0.07283466\n",
      "epoch: 111  batch: 43  loss: 0.12443165\n",
      "epoch: 111  batch: 44  loss: 0.18836704\n",
      "epoch: 111  batch: 45  loss: 0.19077376\n",
      "epoch: 111  batch: 46  loss: 0.09440494\n",
      "epoch: 111  batch: 47  loss: 0.08156202\n",
      "epoch: 111  batch: 48  loss: 0.13723479\n",
      "epoch: 111  batch: 49  loss: 0.13158326\n",
      "epoch: 111  batch: 50  loss: 0.17383474\n",
      "epoch: 111  batch: 51  loss: 0.07807089\n",
      "epoch: 111  batch: 52  loss: 0.08898234\n",
      "epoch: 111  batch: 53  loss: 0.05947127\n",
      "epoch: 111  batch: 54  loss: 0.33053848\n",
      "epoch: 111  batch: 55  loss: 0.20800875\n",
      "epoch: 111  batch: 56  loss: 0.07974385\n",
      "epoch: 111  batch: 57  loss: 0.04195773\n",
      "epoch: 111  batch: 58  loss: 0.11272001\n",
      "epoch: 111  batch: 59  loss: 0.08848862\n",
      "epoch: 111  batch: 60  loss: 0.06575749\n",
      "epoch: 111  batch: 61  loss: 0.47284794\n",
      "epoch: 111  batch: 62  loss: 0.13505670\n",
      "epoch: 111  batch: 63  loss: 0.03372352\n",
      "epoch: 111  batch: 64  loss: 0.02241079\n",
      "epoch: 111  batch: 65  loss: 0.04049204\n",
      "epoch: 111  batch: 66  loss: 0.04032767\n",
      "epoch: 111  batch: 67  loss: 0.03411244\n",
      "epoch: 111  batch: 68  loss: 0.05068099\n",
      "epoch: 112  batch: 1  loss: 0.13222151\n",
      "epoch: 112  batch: 2  loss: 0.04361631\n",
      "epoch: 112  batch: 3  loss: 0.03484435\n",
      "epoch: 112  batch: 4  loss: 0.03155772\n",
      "epoch: 112  batch: 5  loss: 0.08942907\n",
      "epoch: 112  batch: 6  loss: 0.08049247\n",
      "epoch: 112  batch: 7  loss: 0.19182524\n",
      "epoch: 112  batch: 8  loss: 0.06901935\n",
      "epoch: 112  batch: 9  loss: 0.08299191\n",
      "epoch: 112  batch: 10  loss: 0.19157423\n",
      "epoch: 112  batch: 11  loss: 0.23926108\n",
      "epoch: 112  batch: 12  loss: 0.07811570\n",
      "epoch: 112  batch: 13  loss: 0.09853902\n",
      "epoch: 112  batch: 14  loss: 0.15002961\n",
      "epoch: 112  batch: 15  loss: 0.11150214\n",
      "epoch: 112  batch: 16  loss: 0.05871518\n",
      "epoch: 112  batch: 17  loss: 0.05168829\n",
      "epoch: 112  batch: 18  loss: 0.04770609\n",
      "epoch: 112  batch: 19  loss: 0.05168718\n",
      "epoch: 112  batch: 20  loss: 0.28027672\n",
      "epoch: 112  batch: 21  loss: 0.28882080\n",
      "epoch: 112  batch: 22  loss: 0.05584895\n",
      "epoch: 112  batch: 23  loss: 0.04304384\n",
      "epoch: 112  batch: 24  loss: 0.07119221\n",
      "epoch: 112  batch: 25  loss: 0.07592082\n",
      "epoch: 112  batch: 26  loss: 0.01746506\n",
      "epoch: 112  batch: 27  loss: 0.07131682\n",
      "epoch: 112  batch: 28  loss: 0.01526628\n",
      "epoch: 112  batch: 29  loss: 0.01579912\n",
      "epoch: 112  batch: 30  loss: 0.02073643\n",
      "epoch: 112  batch: 31  loss: 0.02682018\n",
      "epoch: 112  batch: 32  loss: 0.01237247\n",
      "epoch: 112  batch: 33  loss: 0.04126133\n",
      "epoch: 112  batch: 34  loss: 0.09338938\n",
      "epoch: 112  batch: 35  loss: 0.13953982\n",
      "epoch: 112  batch: 36  loss: 0.06570643\n",
      "epoch: 112  batch: 37  loss: 0.03908459\n",
      "epoch: 112  batch: 38  loss: 0.03791604\n",
      "epoch: 112  batch: 39  loss: 0.12970968\n",
      "epoch: 112  batch: 40  loss: 0.06428934\n",
      "epoch: 112  batch: 41  loss: 0.16466570\n",
      "epoch: 112  batch: 42  loss: 0.07218842\n",
      "epoch: 112  batch: 43  loss: 0.12267355\n",
      "epoch: 112  batch: 44  loss: 0.18502806\n",
      "epoch: 112  batch: 45  loss: 0.18754567\n",
      "epoch: 112  batch: 46  loss: 0.09322660\n",
      "epoch: 112  batch: 47  loss: 0.08105824\n",
      "epoch: 112  batch: 48  loss: 0.13639867\n",
      "epoch: 112  batch: 49  loss: 0.13227347\n",
      "epoch: 112  batch: 50  loss: 0.16809824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112  batch: 51  loss: 0.07812683\n",
      "epoch: 112  batch: 52  loss: 0.08943482\n",
      "epoch: 112  batch: 53  loss: 0.05886140\n",
      "epoch: 112  batch: 54  loss: 0.33003142\n",
      "epoch: 112  batch: 55  loss: 0.20812027\n",
      "epoch: 112  batch: 56  loss: 0.07983533\n",
      "epoch: 112  batch: 57  loss: 0.04215518\n",
      "epoch: 112  batch: 58  loss: 0.11140310\n",
      "epoch: 112  batch: 59  loss: 0.08851849\n",
      "epoch: 112  batch: 60  loss: 0.05900661\n",
      "epoch: 112  batch: 61  loss: 0.44121602\n",
      "epoch: 112  batch: 62  loss: 0.12794322\n",
      "epoch: 112  batch: 63  loss: 0.03331224\n",
      "epoch: 112  batch: 64  loss: 0.02193506\n",
      "epoch: 112  batch: 65  loss: 0.04041338\n",
      "epoch: 112  batch: 66  loss: 0.04033937\n",
      "epoch: 112  batch: 67  loss: 0.03421323\n",
      "epoch: 112  batch: 68  loss: 0.05042664\n",
      "epoch: 113  batch: 1  loss: 0.13183659\n",
      "epoch: 113  batch: 2  loss: 0.04372888\n",
      "epoch: 113  batch: 3  loss: 0.03452039\n",
      "epoch: 113  batch: 4  loss: 0.03140817\n",
      "epoch: 113  batch: 5  loss: 0.08886854\n",
      "epoch: 113  batch: 6  loss: 0.07974692\n",
      "epoch: 113  batch: 7  loss: 0.19107968\n",
      "epoch: 113  batch: 8  loss: 0.06770512\n",
      "epoch: 113  batch: 9  loss: 0.08179677\n",
      "epoch: 113  batch: 10  loss: 0.18785280\n",
      "epoch: 113  batch: 11  loss: 0.23594497\n",
      "epoch: 113  batch: 12  loss: 0.07773523\n",
      "epoch: 113  batch: 13  loss: 0.09434143\n",
      "epoch: 113  batch: 14  loss: 0.14874370\n",
      "epoch: 113  batch: 15  loss: 0.11220394\n",
      "epoch: 113  batch: 16  loss: 0.05764814\n",
      "epoch: 113  batch: 17  loss: 0.05165482\n",
      "epoch: 113  batch: 18  loss: 0.04804679\n",
      "epoch: 113  batch: 19  loss: 0.05181830\n",
      "epoch: 113  batch: 20  loss: 0.27629870\n",
      "epoch: 113  batch: 21  loss: 0.28800941\n",
      "epoch: 113  batch: 22  loss: 0.05545368\n",
      "epoch: 113  batch: 23  loss: 0.04306016\n",
      "epoch: 113  batch: 24  loss: 0.07055922\n",
      "epoch: 113  batch: 25  loss: 0.07535172\n",
      "epoch: 113  batch: 26  loss: 0.01757823\n",
      "epoch: 113  batch: 27  loss: 0.06895892\n",
      "epoch: 113  batch: 28  loss: 0.01528053\n",
      "epoch: 113  batch: 29  loss: 0.01594640\n",
      "epoch: 113  batch: 30  loss: 0.02014356\n",
      "epoch: 113  batch: 31  loss: 0.02675682\n",
      "epoch: 113  batch: 32  loss: 0.01233753\n",
      "epoch: 113  batch: 33  loss: 0.04018550\n",
      "epoch: 113  batch: 34  loss: 0.09354869\n",
      "epoch: 113  batch: 35  loss: 0.13913561\n",
      "epoch: 113  batch: 36  loss: 0.06667763\n",
      "epoch: 113  batch: 37  loss: 0.03910537\n",
      "epoch: 113  batch: 38  loss: 0.03718689\n",
      "epoch: 113  batch: 39  loss: 0.12885262\n",
      "epoch: 113  batch: 40  loss: 0.06466363\n",
      "epoch: 113  batch: 41  loss: 0.16389139\n",
      "epoch: 113  batch: 42  loss: 0.07159726\n",
      "epoch: 113  batch: 43  loss: 0.12081464\n",
      "epoch: 113  batch: 44  loss: 0.18196924\n",
      "epoch: 113  batch: 45  loss: 0.18434982\n",
      "epoch: 113  batch: 46  loss: 0.09217733\n",
      "epoch: 113  batch: 47  loss: 0.08044079\n",
      "epoch: 113  batch: 48  loss: 0.13519239\n",
      "epoch: 113  batch: 49  loss: 0.13289496\n",
      "epoch: 113  batch: 50  loss: 0.16281748\n",
      "epoch: 113  batch: 51  loss: 0.07811705\n",
      "epoch: 113  batch: 52  loss: 0.08979957\n",
      "epoch: 113  batch: 53  loss: 0.05841938\n",
      "epoch: 113  batch: 54  loss: 0.32950851\n",
      "epoch: 113  batch: 55  loss: 0.20826243\n",
      "epoch: 113  batch: 56  loss: 0.07994418\n",
      "epoch: 113  batch: 57  loss: 0.04233615\n",
      "epoch: 113  batch: 58  loss: 0.10987721\n",
      "epoch: 113  batch: 59  loss: 0.08839380\n",
      "epoch: 113  batch: 60  loss: 0.05342775\n",
      "epoch: 113  batch: 61  loss: 0.41297796\n",
      "epoch: 113  batch: 62  loss: 0.12069549\n",
      "epoch: 113  batch: 63  loss: 0.03264898\n",
      "epoch: 113  batch: 64  loss: 0.02154197\n",
      "epoch: 113  batch: 65  loss: 0.04037777\n",
      "epoch: 113  batch: 66  loss: 0.04031237\n",
      "epoch: 113  batch: 67  loss: 0.03423566\n",
      "epoch: 113  batch: 68  loss: 0.05020250\n",
      "epoch: 114  batch: 1  loss: 0.13116162\n",
      "epoch: 114  batch: 2  loss: 0.04385974\n",
      "epoch: 114  batch: 3  loss: 0.03424684\n",
      "epoch: 114  batch: 4  loss: 0.03127184\n",
      "epoch: 114  batch: 5  loss: 0.08828643\n",
      "epoch: 114  batch: 6  loss: 0.07906693\n",
      "epoch: 114  batch: 7  loss: 0.19026510\n",
      "epoch: 114  batch: 8  loss: 0.06644996\n",
      "epoch: 114  batch: 9  loss: 0.08067734\n",
      "epoch: 114  batch: 10  loss: 0.18404688\n",
      "epoch: 114  batch: 11  loss: 0.23244897\n",
      "epoch: 114  batch: 12  loss: 0.07733361\n",
      "epoch: 114  batch: 13  loss: 0.09030607\n",
      "epoch: 114  batch: 14  loss: 0.14764316\n",
      "epoch: 114  batch: 15  loss: 0.11288457\n",
      "epoch: 114  batch: 16  loss: 0.05652530\n",
      "epoch: 114  batch: 17  loss: 0.05155691\n",
      "epoch: 114  batch: 18  loss: 0.04832584\n",
      "epoch: 114  batch: 19  loss: 0.05194842\n",
      "epoch: 114  batch: 20  loss: 0.27221525\n",
      "epoch: 114  batch: 21  loss: 0.28698933\n",
      "epoch: 114  batch: 22  loss: 0.05509467\n",
      "epoch: 114  batch: 23  loss: 0.04304841\n",
      "epoch: 114  batch: 24  loss: 0.07012490\n",
      "epoch: 114  batch: 25  loss: 0.07481690\n",
      "epoch: 114  batch: 26  loss: 0.01774186\n",
      "epoch: 114  batch: 27  loss: 0.06645689\n",
      "epoch: 114  batch: 28  loss: 0.01531161\n",
      "epoch: 114  batch: 29  loss: 0.01605837\n",
      "epoch: 114  batch: 30  loss: 0.01947710\n",
      "epoch: 114  batch: 31  loss: 0.02670819\n",
      "epoch: 114  batch: 32  loss: 0.01228644\n",
      "epoch: 114  batch: 33  loss: 0.03913740\n",
      "epoch: 114  batch: 34  loss: 0.09376594\n",
      "epoch: 114  batch: 35  loss: 0.13874298\n",
      "epoch: 114  batch: 36  loss: 0.06764598\n",
      "epoch: 114  batch: 37  loss: 0.03907511\n",
      "epoch: 114  batch: 38  loss: 0.03647478\n",
      "epoch: 114  batch: 39  loss: 0.12803683\n",
      "epoch: 114  batch: 40  loss: 0.06509423\n",
      "epoch: 114  batch: 41  loss: 0.16312391\n",
      "epoch: 114  batch: 42  loss: 0.07103962\n",
      "epoch: 114  batch: 43  loss: 0.11889456\n",
      "epoch: 114  batch: 44  loss: 0.17914955\n",
      "epoch: 114  batch: 45  loss: 0.18118766\n",
      "epoch: 114  batch: 46  loss: 0.09102238\n",
      "epoch: 114  batch: 47  loss: 0.07983187\n",
      "epoch: 114  batch: 48  loss: 0.13380693\n",
      "epoch: 114  batch: 49  loss: 0.13353613\n",
      "epoch: 114  batch: 50  loss: 0.15744378\n",
      "epoch: 114  batch: 51  loss: 0.07810846\n",
      "epoch: 114  batch: 52  loss: 0.08987274\n",
      "epoch: 114  batch: 53  loss: 0.05826708\n",
      "epoch: 114  batch: 54  loss: 0.32898051\n",
      "epoch: 114  batch: 55  loss: 0.20833185\n",
      "epoch: 114  batch: 56  loss: 0.08005090\n",
      "epoch: 114  batch: 57  loss: 0.04251473\n",
      "epoch: 114  batch: 58  loss: 0.10835599\n",
      "epoch: 114  batch: 59  loss: 0.08784544\n",
      "epoch: 114  batch: 60  loss: 0.04871612\n",
      "epoch: 114  batch: 61  loss: 0.38756597\n",
      "epoch: 114  batch: 62  loss: 0.11347195\n",
      "epoch: 114  batch: 63  loss: 0.03167204\n",
      "epoch: 114  batch: 64  loss: 0.02123276\n",
      "epoch: 114  batch: 65  loss: 0.04044216\n",
      "epoch: 114  batch: 66  loss: 0.04028281\n",
      "epoch: 114  batch: 67  loss: 0.03417122\n",
      "epoch: 114  batch: 68  loss: 0.05001011\n",
      "epoch: 115  batch: 1  loss: 0.13036478\n",
      "epoch: 115  batch: 2  loss: 0.04402637\n",
      "epoch: 115  batch: 3  loss: 0.03401742\n",
      "epoch: 115  batch: 4  loss: 0.03119245\n",
      "epoch: 115  batch: 5  loss: 0.08773667\n",
      "epoch: 115  batch: 6  loss: 0.07838411\n",
      "epoch: 115  batch: 7  loss: 0.18946823\n",
      "epoch: 115  batch: 8  loss: 0.06518413\n",
      "epoch: 115  batch: 9  loss: 0.07954103\n",
      "epoch: 115  batch: 10  loss: 0.18031114\n",
      "epoch: 115  batch: 11  loss: 0.22904581\n",
      "epoch: 115  batch: 12  loss: 0.07681923\n",
      "epoch: 115  batch: 13  loss: 0.08642665\n",
      "epoch: 115  batch: 14  loss: 0.14649880\n",
      "epoch: 115  batch: 15  loss: 0.11360130\n",
      "epoch: 115  batch: 16  loss: 0.05535630\n",
      "epoch: 115  batch: 17  loss: 0.05139406\n",
      "epoch: 115  batch: 18  loss: 0.04868279\n",
      "epoch: 115  batch: 19  loss: 0.05205400\n",
      "epoch: 115  batch: 20  loss: 0.26795754\n",
      "epoch: 115  batch: 21  loss: 0.28596291\n",
      "epoch: 115  batch: 22  loss: 0.05473889\n",
      "epoch: 115  batch: 23  loss: 0.04303721\n",
      "epoch: 115  batch: 24  loss: 0.06986094\n",
      "epoch: 115  batch: 25  loss: 0.07431432\n",
      "epoch: 115  batch: 26  loss: 0.01793460\n",
      "epoch: 115  batch: 27  loss: 0.06401073\n",
      "epoch: 115  batch: 28  loss: 0.01538774\n",
      "epoch: 115  batch: 29  loss: 0.01616449\n",
      "epoch: 115  batch: 30  loss: 0.01882849\n",
      "epoch: 115  batch: 31  loss: 0.02662855\n",
      "epoch: 115  batch: 32  loss: 0.01224682\n",
      "epoch: 115  batch: 33  loss: 0.03780888\n",
      "epoch: 115  batch: 34  loss: 0.09401165\n",
      "epoch: 115  batch: 35  loss: 0.13829507\n",
      "epoch: 115  batch: 36  loss: 0.06862964\n",
      "epoch: 115  batch: 37  loss: 0.03901369\n",
      "epoch: 115  batch: 38  loss: 0.03578598\n",
      "epoch: 115  batch: 39  loss: 0.12721156\n",
      "epoch: 115  batch: 40  loss: 0.06557487\n",
      "epoch: 115  batch: 41  loss: 0.16234843\n",
      "epoch: 115  batch: 42  loss: 0.07053197\n",
      "epoch: 115  batch: 43  loss: 0.11694171\n",
      "epoch: 115  batch: 44  loss: 0.17649813\n",
      "epoch: 115  batch: 45  loss: 0.17793232\n",
      "epoch: 115  batch: 46  loss: 0.08989088\n",
      "epoch: 115  batch: 47  loss: 0.07917660\n",
      "epoch: 115  batch: 48  loss: 0.13245580\n",
      "epoch: 115  batch: 49  loss: 0.13420340\n",
      "epoch: 115  batch: 50  loss: 0.15238273\n",
      "epoch: 115  batch: 51  loss: 0.07807538\n",
      "epoch: 115  batch: 52  loss: 0.08975245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115  batch: 53  loss: 0.05806317\n",
      "epoch: 115  batch: 54  loss: 0.32853064\n",
      "epoch: 115  batch: 55  loss: 0.20846063\n",
      "epoch: 115  batch: 56  loss: 0.08011009\n",
      "epoch: 115  batch: 57  loss: 0.04266443\n",
      "epoch: 115  batch: 58  loss: 0.10680591\n",
      "epoch: 115  batch: 59  loss: 0.08573350\n",
      "epoch: 115  batch: 60  loss: 0.04478041\n",
      "epoch: 115  batch: 61  loss: 0.36374953\n",
      "epoch: 115  batch: 62  loss: 0.10597354\n",
      "epoch: 115  batch: 63  loss: 0.03052790\n",
      "epoch: 115  batch: 64  loss: 0.02099548\n",
      "epoch: 115  batch: 65  loss: 0.04054766\n",
      "epoch: 115  batch: 66  loss: 0.04035118\n",
      "epoch: 115  batch: 67  loss: 0.03415383\n",
      "epoch: 115  batch: 68  loss: 0.04983664\n",
      "epoch: 116  batch: 1  loss: 0.12969944\n",
      "epoch: 116  batch: 2  loss: 0.04418296\n",
      "epoch: 116  batch: 3  loss: 0.03381820\n",
      "epoch: 116  batch: 4  loss: 0.03116591\n",
      "epoch: 116  batch: 5  loss: 0.08723924\n",
      "epoch: 116  batch: 6  loss: 0.07753861\n",
      "epoch: 116  batch: 7  loss: 0.18891686\n",
      "epoch: 116  batch: 8  loss: 0.06410947\n",
      "epoch: 116  batch: 9  loss: 0.07833046\n",
      "epoch: 116  batch: 10  loss: 0.17667304\n",
      "epoch: 116  batch: 11  loss: 0.22568537\n",
      "epoch: 116  batch: 12  loss: 0.07620735\n",
      "epoch: 116  batch: 13  loss: 0.08285841\n",
      "epoch: 116  batch: 14  loss: 0.14505954\n",
      "epoch: 116  batch: 15  loss: 0.11435327\n",
      "epoch: 116  batch: 16  loss: 0.05416856\n",
      "epoch: 116  batch: 17  loss: 0.05122332\n",
      "epoch: 116  batch: 18  loss: 0.04921486\n",
      "epoch: 116  batch: 19  loss: 0.05226166\n",
      "epoch: 116  batch: 20  loss: 0.26343331\n",
      "epoch: 116  batch: 21  loss: 0.28481323\n",
      "epoch: 116  batch: 22  loss: 0.05440915\n",
      "epoch: 116  batch: 23  loss: 0.04291365\n",
      "epoch: 116  batch: 24  loss: 0.06981550\n",
      "epoch: 116  batch: 25  loss: 0.07400230\n",
      "epoch: 116  batch: 26  loss: 0.01808158\n",
      "epoch: 116  batch: 27  loss: 0.06179399\n",
      "epoch: 116  batch: 28  loss: 0.01539985\n",
      "epoch: 116  batch: 29  loss: 0.01617398\n",
      "epoch: 116  batch: 30  loss: 0.01874290\n",
      "epoch: 116  batch: 31  loss: 0.02650455\n",
      "epoch: 116  batch: 32  loss: 0.01221412\n",
      "epoch: 116  batch: 33  loss: 0.03649442\n",
      "epoch: 116  batch: 34  loss: 0.09415156\n",
      "epoch: 116  batch: 35  loss: 0.13788417\n",
      "epoch: 116  batch: 36  loss: 0.06969810\n",
      "epoch: 116  batch: 37  loss: 0.03890587\n",
      "epoch: 116  batch: 38  loss: 0.03509826\n",
      "epoch: 116  batch: 39  loss: 0.12641707\n",
      "epoch: 116  batch: 40  loss: 0.06606658\n",
      "epoch: 116  batch: 41  loss: 0.16158602\n",
      "epoch: 116  batch: 42  loss: 0.07003336\n",
      "epoch: 116  batch: 43  loss: 0.11509584\n",
      "epoch: 116  batch: 44  loss: 0.17350259\n",
      "epoch: 116  batch: 45  loss: 0.17478882\n",
      "epoch: 116  batch: 46  loss: 0.08870856\n",
      "epoch: 116  batch: 47  loss: 0.07849437\n",
      "epoch: 116  batch: 48  loss: 0.13089469\n",
      "epoch: 116  batch: 49  loss: 0.13487765\n",
      "epoch: 116  batch: 50  loss: 0.14720494\n",
      "epoch: 116  batch: 51  loss: 0.07824064\n",
      "epoch: 116  batch: 52  loss: 0.08974419\n",
      "epoch: 116  batch: 53  loss: 0.05791156\n",
      "epoch: 116  batch: 54  loss: 0.32824475\n",
      "epoch: 116  batch: 55  loss: 0.20823814\n",
      "epoch: 116  batch: 56  loss: 0.08012857\n",
      "epoch: 116  batch: 57  loss: 0.04269065\n",
      "epoch: 116  batch: 58  loss: 0.10508429\n",
      "epoch: 116  batch: 59  loss: 0.08124089\n",
      "epoch: 116  batch: 60  loss: 0.04138903\n",
      "epoch: 116  batch: 61  loss: 0.34166878\n",
      "epoch: 116  batch: 62  loss: 0.09815192\n",
      "epoch: 116  batch: 63  loss: 0.02950546\n",
      "epoch: 116  batch: 64  loss: 0.02075770\n",
      "epoch: 116  batch: 65  loss: 0.04070481\n",
      "epoch: 116  batch: 66  loss: 0.04034269\n",
      "epoch: 116  batch: 67  loss: 0.03372602\n",
      "epoch: 116  batch: 68  loss: 0.04970013\n",
      "epoch: 117  batch: 1  loss: 0.12897807\n",
      "epoch: 117  batch: 2  loss: 0.04457323\n",
      "epoch: 117  batch: 3  loss: 0.03357752\n",
      "epoch: 117  batch: 4  loss: 0.03114742\n",
      "epoch: 117  batch: 5  loss: 0.08674666\n",
      "epoch: 117  batch: 6  loss: 0.07688564\n",
      "epoch: 117  batch: 7  loss: 0.18792748\n",
      "epoch: 117  batch: 8  loss: 0.06308354\n",
      "epoch: 117  batch: 9  loss: 0.07718926\n",
      "epoch: 117  batch: 10  loss: 0.17311712\n",
      "epoch: 117  batch: 11  loss: 0.22219713\n",
      "epoch: 117  batch: 12  loss: 0.07568438\n",
      "epoch: 117  batch: 13  loss: 0.07932554\n",
      "epoch: 117  batch: 14  loss: 0.14379175\n",
      "epoch: 117  batch: 15  loss: 0.11511034\n",
      "epoch: 117  batch: 16  loss: 0.05272947\n",
      "epoch: 117  batch: 17  loss: 0.05114264\n",
      "epoch: 117  batch: 18  loss: 0.04946074\n",
      "epoch: 117  batch: 19  loss: 0.05225362\n",
      "epoch: 117  batch: 20  loss: 0.25895578\n",
      "epoch: 117  batch: 21  loss: 0.28352582\n",
      "epoch: 117  batch: 22  loss: 0.05408809\n",
      "epoch: 117  batch: 23  loss: 0.04313703\n",
      "epoch: 117  batch: 24  loss: 0.06973975\n",
      "epoch: 117  batch: 25  loss: 0.07318331\n",
      "epoch: 117  batch: 26  loss: 0.01826260\n",
      "epoch: 117  batch: 27  loss: 0.05954983\n",
      "epoch: 117  batch: 28  loss: 0.01547100\n",
      "epoch: 117  batch: 29  loss: 0.01650400\n",
      "epoch: 117  batch: 30  loss: 0.01796931\n",
      "epoch: 117  batch: 31  loss: 0.02637823\n",
      "epoch: 117  batch: 32  loss: 0.01223486\n",
      "epoch: 117  batch: 33  loss: 0.03442535\n",
      "epoch: 117  batch: 34  loss: 0.09471618\n",
      "epoch: 117  batch: 35  loss: 0.13736872\n",
      "epoch: 117  batch: 36  loss: 0.07082990\n",
      "epoch: 117  batch: 37  loss: 0.03880488\n",
      "epoch: 117  batch: 38  loss: 0.03450887\n",
      "epoch: 117  batch: 39  loss: 0.12548809\n",
      "epoch: 117  batch: 40  loss: 0.06672522\n",
      "epoch: 117  batch: 41  loss: 0.16078982\n",
      "epoch: 117  batch: 42  loss: 0.06957361\n",
      "epoch: 117  batch: 43  loss: 0.11314671\n",
      "epoch: 117  batch: 44  loss: 0.17087655\n",
      "epoch: 117  batch: 45  loss: 0.17142776\n",
      "epoch: 117  batch: 46  loss: 0.08797526\n",
      "epoch: 117  batch: 47  loss: 0.07755561\n",
      "epoch: 117  batch: 48  loss: 0.12939051\n",
      "epoch: 117  batch: 49  loss: 0.13541789\n",
      "epoch: 117  batch: 50  loss: 0.14307658\n",
      "epoch: 117  batch: 51  loss: 0.07834438\n",
      "epoch: 117  batch: 52  loss: 0.08937559\n",
      "epoch: 117  batch: 53  loss: 0.05784703\n",
      "epoch: 117  batch: 54  loss: 0.32765168\n",
      "epoch: 117  batch: 55  loss: 0.20850743\n",
      "epoch: 117  batch: 56  loss: 0.08032691\n",
      "epoch: 117  batch: 57  loss: 0.04285421\n",
      "epoch: 117  batch: 58  loss: 0.10319835\n",
      "epoch: 117  batch: 59  loss: 0.08052812\n",
      "epoch: 117  batch: 60  loss: 0.03846120\n",
      "epoch: 117  batch: 61  loss: 0.32194826\n",
      "epoch: 117  batch: 62  loss: 0.09050615\n",
      "epoch: 117  batch: 63  loss: 0.02864755\n",
      "epoch: 117  batch: 64  loss: 0.02066758\n",
      "epoch: 117  batch: 65  loss: 0.04065214\n",
      "epoch: 117  batch: 66  loss: 0.04017177\n",
      "epoch: 117  batch: 67  loss: 0.03306343\n",
      "epoch: 117  batch: 68  loss: 0.04952591\n",
      "epoch: 118  batch: 1  loss: 0.12822855\n",
      "epoch: 118  batch: 2  loss: 0.04515789\n",
      "epoch: 118  batch: 3  loss: 0.03328818\n",
      "epoch: 118  batch: 4  loss: 0.03106822\n",
      "epoch: 118  batch: 5  loss: 0.08621769\n",
      "epoch: 118  batch: 6  loss: 0.07624426\n",
      "epoch: 118  batch: 7  loss: 0.18666558\n",
      "epoch: 118  batch: 8  loss: 0.06205834\n",
      "epoch: 118  batch: 9  loss: 0.07616129\n",
      "epoch: 118  batch: 10  loss: 0.16968545\n",
      "epoch: 118  batch: 11  loss: 0.21900928\n",
      "epoch: 118  batch: 12  loss: 0.07523529\n",
      "epoch: 118  batch: 13  loss: 0.07580531\n",
      "epoch: 118  batch: 14  loss: 0.14295557\n",
      "epoch: 118  batch: 15  loss: 0.11586093\n",
      "epoch: 118  batch: 16  loss: 0.05145929\n",
      "epoch: 118  batch: 17  loss: 0.05153622\n",
      "epoch: 118  batch: 18  loss: 0.04943978\n",
      "epoch: 118  batch: 19  loss: 0.05217961\n",
      "epoch: 118  batch: 20  loss: 0.25501952\n",
      "epoch: 118  batch: 21  loss: 0.28230980\n",
      "epoch: 118  batch: 22  loss: 0.05375452\n",
      "epoch: 118  batch: 23  loss: 0.04299097\n",
      "epoch: 118  batch: 24  loss: 0.06985375\n",
      "epoch: 118  batch: 25  loss: 0.07222722\n",
      "epoch: 118  batch: 26  loss: 0.01854221\n",
      "epoch: 118  batch: 27  loss: 0.05749180\n",
      "epoch: 118  batch: 28  loss: 0.01543439\n",
      "epoch: 118  batch: 29  loss: 0.01592711\n",
      "epoch: 118  batch: 30  loss: 0.01732833\n",
      "epoch: 118  batch: 31  loss: 0.02632000\n",
      "epoch: 118  batch: 32  loss: 0.01214161\n",
      "epoch: 118  batch: 33  loss: 0.03432669\n",
      "epoch: 118  batch: 34  loss: 0.09518744\n",
      "epoch: 118  batch: 35  loss: 0.13729873\n",
      "epoch: 118  batch: 36  loss: 0.07191601\n",
      "epoch: 118  batch: 37  loss: 0.03844535\n",
      "epoch: 118  batch: 38  loss: 0.03387815\n",
      "epoch: 118  batch: 39  loss: 0.12509389\n",
      "epoch: 118  batch: 40  loss: 0.06742363\n",
      "epoch: 118  batch: 41  loss: 0.15996742\n",
      "epoch: 118  batch: 42  loss: 0.06903496\n",
      "epoch: 118  batch: 43  loss: 0.11111195\n",
      "epoch: 118  batch: 44  loss: 0.16705498\n",
      "epoch: 118  batch: 45  loss: 0.16930504\n",
      "epoch: 118  batch: 46  loss: 0.08730920\n",
      "epoch: 118  batch: 47  loss: 0.07743744\n",
      "epoch: 118  batch: 48  loss: 0.12618175\n",
      "epoch: 118  batch: 49  loss: 0.13623449\n",
      "epoch: 118  batch: 50  loss: 0.13728222\n",
      "epoch: 118  batch: 51  loss: 0.07846238\n",
      "epoch: 118  batch: 52  loss: 0.08874545\n",
      "epoch: 118  batch: 53  loss: 0.05758762\n",
      "epoch: 118  batch: 54  loss: 0.32668102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118  batch: 55  loss: 0.20768510\n",
      "epoch: 118  batch: 56  loss: 0.08049925\n",
      "epoch: 118  batch: 57  loss: 0.04292401\n",
      "epoch: 118  batch: 58  loss: 0.10186175\n",
      "epoch: 118  batch: 59  loss: 0.08089497\n",
      "epoch: 118  batch: 60  loss: 0.03651116\n",
      "epoch: 118  batch: 61  loss: 0.30228752\n",
      "epoch: 118  batch: 62  loss: 0.08165490\n",
      "epoch: 118  batch: 63  loss: 0.02761540\n",
      "epoch: 118  batch: 64  loss: 0.02066438\n",
      "epoch: 118  batch: 65  loss: 0.04083997\n",
      "epoch: 118  batch: 66  loss: 0.04038896\n",
      "epoch: 118  batch: 67  loss: 0.03349531\n",
      "epoch: 118  batch: 68  loss: 0.04932909\n",
      "epoch: 119  batch: 1  loss: 0.12787069\n",
      "epoch: 119  batch: 2  loss: 0.04544005\n",
      "epoch: 119  batch: 3  loss: 0.03315436\n",
      "epoch: 119  batch: 4  loss: 0.03081630\n",
      "epoch: 119  batch: 5  loss: 0.08576554\n",
      "epoch: 119  batch: 6  loss: 0.07507990\n",
      "epoch: 119  batch: 7  loss: 0.18610294\n",
      "epoch: 119  batch: 8  loss: 0.06118700\n",
      "epoch: 119  batch: 9  loss: 0.07496638\n",
      "epoch: 119  batch: 10  loss: 0.16621891\n",
      "epoch: 119  batch: 11  loss: 0.21598952\n",
      "epoch: 119  batch: 12  loss: 0.07462958\n",
      "epoch: 119  batch: 13  loss: 0.07246573\n",
      "epoch: 119  batch: 14  loss: 0.14137433\n",
      "epoch: 119  batch: 15  loss: 0.11672343\n",
      "epoch: 119  batch: 16  loss: 0.05084661\n",
      "epoch: 119  batch: 17  loss: 0.05070963\n",
      "epoch: 119  batch: 18  loss: 0.05001078\n",
      "epoch: 119  batch: 19  loss: 0.05197132\n",
      "epoch: 119  batch: 20  loss: 0.25103796\n",
      "epoch: 119  batch: 21  loss: 0.28088456\n",
      "epoch: 119  batch: 22  loss: 0.05356497\n",
      "epoch: 119  batch: 23  loss: 0.04279274\n",
      "epoch: 119  batch: 24  loss: 0.07001308\n",
      "epoch: 119  batch: 25  loss: 0.07235438\n",
      "epoch: 119  batch: 26  loss: 0.01877846\n",
      "epoch: 119  batch: 27  loss: 0.05516968\n",
      "epoch: 119  batch: 28  loss: 0.01525548\n",
      "epoch: 119  batch: 29  loss: 0.01670389\n",
      "epoch: 119  batch: 30  loss: 0.01723737\n",
      "epoch: 119  batch: 31  loss: 0.02591283\n",
      "epoch: 119  batch: 32  loss: 0.01218474\n",
      "epoch: 119  batch: 33  loss: 0.03128267\n",
      "epoch: 119  batch: 34  loss: 0.09519182\n",
      "epoch: 119  batch: 35  loss: 0.13644834\n",
      "epoch: 119  batch: 36  loss: 0.07301084\n",
      "epoch: 119  batch: 37  loss: 0.03861655\n",
      "epoch: 119  batch: 38  loss: 0.03359082\n",
      "epoch: 119  batch: 39  loss: 0.12377548\n",
      "epoch: 119  batch: 40  loss: 0.06794053\n",
      "epoch: 119  batch: 41  loss: 0.15925018\n",
      "epoch: 119  batch: 42  loss: 0.06871665\n",
      "epoch: 119  batch: 43  loss: 0.10955177\n",
      "epoch: 119  batch: 44  loss: 0.16472760\n",
      "epoch: 119  batch: 45  loss: 0.16514921\n",
      "epoch: 119  batch: 46  loss: 0.08599117\n",
      "epoch: 119  batch: 47  loss: 0.07621453\n",
      "epoch: 119  batch: 48  loss: 0.12573861\n",
      "epoch: 119  batch: 49  loss: 0.13679986\n",
      "epoch: 119  batch: 50  loss: 0.13395512\n",
      "epoch: 119  batch: 51  loss: 0.07857062\n",
      "epoch: 119  batch: 52  loss: 0.08872715\n",
      "epoch: 119  batch: 53  loss: 0.05687850\n",
      "epoch: 119  batch: 54  loss: 0.32648554\n",
      "epoch: 119  batch: 55  loss: 0.20762579\n",
      "epoch: 119  batch: 56  loss: 0.08040398\n",
      "epoch: 119  batch: 57  loss: 0.04282596\n",
      "epoch: 119  batch: 58  loss: 0.10001481\n",
      "epoch: 119  batch: 59  loss: 0.08504277\n",
      "epoch: 119  batch: 60  loss: 0.03397224\n",
      "epoch: 119  batch: 61  loss: 0.28508660\n",
      "epoch: 119  batch: 62  loss: 0.07564007\n",
      "epoch: 119  batch: 63  loss: 0.02712806\n",
      "epoch: 119  batch: 64  loss: 0.02034793\n",
      "epoch: 119  batch: 65  loss: 0.04059711\n",
      "epoch: 119  batch: 66  loss: 0.03953268\n",
      "epoch: 119  batch: 67  loss: 0.03164559\n",
      "epoch: 119  batch: 68  loss: 0.04927798\n",
      "epoch: 120  batch: 1  loss: 0.12692763\n",
      "epoch: 120  batch: 2  loss: 0.04730581\n",
      "epoch: 120  batch: 3  loss: 0.03290224\n",
      "epoch: 120  batch: 4  loss: 0.03216643\n",
      "epoch: 120  batch: 5  loss: 0.08529396\n",
      "epoch: 120  batch: 6  loss: 0.07551929\n",
      "epoch: 120  batch: 7  loss: 0.18377173\n",
      "epoch: 120  batch: 8  loss: 0.06045740\n",
      "epoch: 120  batch: 9  loss: 0.07449104\n",
      "epoch: 120  batch: 10  loss: 0.16413189\n",
      "epoch: 120  batch: 11  loss: 0.21273020\n",
      "epoch: 120  batch: 12  loss: 0.07463564\n",
      "epoch: 120  batch: 13  loss: 0.06867465\n",
      "epoch: 120  batch: 14  loss: 0.14177713\n",
      "epoch: 120  batch: 15  loss: 0.11727150\n",
      "epoch: 120  batch: 16  loss: 0.04884989\n",
      "epoch: 120  batch: 17  loss: 0.05132733\n",
      "epoch: 120  batch: 18  loss: 0.04858409\n",
      "epoch: 120  batch: 19  loss: 0.05137547\n",
      "epoch: 120  batch: 20  loss: 0.24829026\n",
      "epoch: 120  batch: 21  loss: 0.27930182\n",
      "epoch: 120  batch: 22  loss: 0.05324925\n",
      "epoch: 120  batch: 23  loss: 0.04383181\n",
      "epoch: 120  batch: 24  loss: 0.07010598\n",
      "epoch: 120  batch: 25  loss: 0.07015463\n",
      "epoch: 120  batch: 26  loss: 0.01947233\n",
      "epoch: 120  batch: 27  loss: 0.05322894\n",
      "epoch: 120  batch: 28  loss: 0.01483816\n",
      "epoch: 120  batch: 29  loss: 0.01714864\n",
      "epoch: 120  batch: 30  loss: 0.01654806\n",
      "epoch: 120  batch: 31  loss: 0.02609489\n",
      "epoch: 120  batch: 32  loss: 0.01218175\n",
      "epoch: 120  batch: 33  loss: 0.03087675\n",
      "epoch: 120  batch: 34  loss: 0.09729739\n",
      "epoch: 120  batch: 35  loss: 0.13616008\n",
      "epoch: 120  batch: 36  loss: 0.07399309\n",
      "epoch: 120  batch: 37  loss: 0.03819461\n",
      "epoch: 120  batch: 38  loss: 0.03311418\n",
      "epoch: 120  batch: 39  loss: 0.12366863\n",
      "epoch: 120  batch: 40  loss: 0.06913829\n",
      "epoch: 120  batch: 41  loss: 0.15839441\n",
      "epoch: 120  batch: 42  loss: 0.06827100\n",
      "epoch: 120  batch: 43  loss: 0.10722648\n",
      "epoch: 120  batch: 44  loss: 0.16323514\n",
      "epoch: 120  batch: 45  loss: 0.16365814\n",
      "epoch: 120  batch: 46  loss: 0.08705924\n",
      "epoch: 120  batch: 47  loss: 0.07597503\n",
      "epoch: 120  batch: 48  loss: 0.12149365\n",
      "epoch: 120  batch: 49  loss: 0.13744879\n",
      "epoch: 120  batch: 50  loss: 0.13087970\n",
      "epoch: 120  batch: 51  loss: 0.07864092\n",
      "epoch: 120  batch: 52  loss: 0.08612740\n",
      "epoch: 120  batch: 53  loss: 0.05758812\n",
      "epoch: 120  batch: 54  loss: 0.32365188\n",
      "epoch: 120  batch: 55  loss: 0.20811866\n",
      "epoch: 120  batch: 56  loss: 0.08121366\n",
      "epoch: 120  batch: 57  loss: 0.04341053\n",
      "epoch: 120  batch: 58  loss: 0.09888625\n",
      "epoch: 120  batch: 59  loss: 0.09514445\n",
      "epoch: 120  batch: 60  loss: 0.03369350\n",
      "epoch: 120  batch: 61  loss: 0.27043980\n",
      "epoch: 120  batch: 62  loss: 0.06815948\n",
      "epoch: 120  batch: 63  loss: 0.02651670\n",
      "epoch: 120  batch: 64  loss: 0.02049769\n",
      "epoch: 120  batch: 65  loss: 0.04040885\n",
      "epoch: 120  batch: 66  loss: 0.03956472\n",
      "epoch: 120  batch: 67  loss: 0.03215655\n",
      "epoch: 120  batch: 68  loss: 0.04912191\n",
      "epoch: 121  batch: 1  loss: 0.12664874\n",
      "epoch: 121  batch: 2  loss: 0.04738629\n",
      "epoch: 121  batch: 3  loss: 0.03267352\n",
      "epoch: 121  batch: 4  loss: 0.03132418\n",
      "epoch: 121  batch: 5  loss: 0.08479238\n",
      "epoch: 121  batch: 6  loss: 0.07416958\n",
      "epoch: 121  batch: 7  loss: 0.18316354\n",
      "epoch: 121  batch: 8  loss: 0.05969503\n",
      "epoch: 121  batch: 9  loss: 0.07336376\n",
      "epoch: 121  batch: 10  loss: 0.16066082\n",
      "epoch: 121  batch: 11  loss: 0.21070762\n",
      "epoch: 121  batch: 12  loss: 0.07412963\n",
      "epoch: 121  batch: 13  loss: 0.06581160\n",
      "epoch: 121  batch: 14  loss: 0.14120005\n",
      "epoch: 121  batch: 15  loss: 0.11814877\n",
      "epoch: 121  batch: 16  loss: 0.04951366\n",
      "epoch: 121  batch: 17  loss: 0.04997809\n",
      "epoch: 121  batch: 18  loss: 0.04886758\n",
      "epoch: 121  batch: 19  loss: 0.05059187\n",
      "epoch: 121  batch: 20  loss: 0.24650255\n",
      "epoch: 121  batch: 21  loss: 0.27755404\n",
      "epoch: 121  batch: 22  loss: 0.05317405\n",
      "epoch: 121  batch: 23  loss: 0.04210133\n",
      "epoch: 121  batch: 24  loss: 0.07052004\n",
      "epoch: 121  batch: 25  loss: 0.07076877\n",
      "epoch: 121  batch: 26  loss: 0.01995881\n",
      "epoch: 121  batch: 27  loss: 0.05026008\n",
      "epoch: 121  batch: 28  loss: 0.01473799\n",
      "epoch: 121  batch: 29  loss: 0.01763485\n",
      "epoch: 121  batch: 30  loss: 0.01617901\n",
      "epoch: 121  batch: 31  loss: 0.02564573\n",
      "epoch: 121  batch: 32  loss: 0.01207485\n",
      "epoch: 121  batch: 33  loss: 0.02814131\n",
      "epoch: 121  batch: 34  loss: 0.09647470\n",
      "epoch: 121  batch: 35  loss: 0.13531308\n",
      "epoch: 121  batch: 36  loss: 0.07473917\n",
      "epoch: 121  batch: 37  loss: 0.03846316\n",
      "epoch: 121  batch: 38  loss: 0.03310632\n",
      "epoch: 121  batch: 39  loss: 0.12219881\n",
      "epoch: 121  batch: 40  loss: 0.06937898\n",
      "epoch: 121  batch: 41  loss: 0.15762845\n",
      "epoch: 121  batch: 42  loss: 0.06800430\n",
      "epoch: 121  batch: 43  loss: 0.10584208\n",
      "epoch: 121  batch: 44  loss: 0.15979275\n",
      "epoch: 121  batch: 45  loss: 0.15961908\n",
      "epoch: 121  batch: 46  loss: 0.08437646\n",
      "epoch: 121  batch: 47  loss: 0.07533025\n",
      "epoch: 121  batch: 48  loss: 0.12186373\n",
      "epoch: 121  batch: 49  loss: 0.13823128\n",
      "epoch: 121  batch: 50  loss: 0.12666407\n",
      "epoch: 121  batch: 51  loss: 0.07839607\n",
      "epoch: 121  batch: 52  loss: 0.08599930\n",
      "epoch: 121  batch: 53  loss: 0.05614146\n",
      "epoch: 121  batch: 54  loss: 0.32365870\n",
      "epoch: 121  batch: 55  loss: 0.20604935\n",
      "epoch: 121  batch: 56  loss: 0.08074114\n",
      "epoch: 121  batch: 57  loss: 0.04240083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121  batch: 58  loss: 0.09753058\n",
      "epoch: 121  batch: 59  loss: 0.09145959\n",
      "epoch: 121  batch: 60  loss: 0.03177845\n",
      "epoch: 121  batch: 61  loss: 0.25655928\n",
      "epoch: 121  batch: 62  loss: 0.06004220\n",
      "epoch: 121  batch: 63  loss: 0.02561545\n",
      "epoch: 121  batch: 64  loss: 0.02019162\n",
      "epoch: 121  batch: 65  loss: 0.03969243\n",
      "epoch: 121  batch: 66  loss: 0.04015757\n",
      "epoch: 121  batch: 67  loss: 0.03258846\n",
      "epoch: 121  batch: 68  loss: 0.04888561\n",
      "epoch: 122  batch: 1  loss: 0.12638466\n",
      "epoch: 122  batch: 2  loss: 0.04703120\n",
      "epoch: 122  batch: 3  loss: 0.03276037\n",
      "epoch: 122  batch: 4  loss: 0.03080643\n",
      "epoch: 122  batch: 5  loss: 0.08471830\n",
      "epoch: 122  batch: 6  loss: 0.07302156\n",
      "epoch: 122  batch: 7  loss: 0.18289287\n",
      "epoch: 122  batch: 8  loss: 0.05920415\n",
      "epoch: 122  batch: 9  loss: 0.07226298\n",
      "epoch: 122  batch: 10  loss: 0.15810236\n",
      "epoch: 122  batch: 11  loss: 0.20768276\n",
      "epoch: 122  batch: 12  loss: 0.07336094\n",
      "epoch: 122  batch: 13  loss: 0.06296389\n",
      "epoch: 122  batch: 14  loss: 0.13977094\n",
      "epoch: 122  batch: 15  loss: 0.11877631\n",
      "epoch: 122  batch: 16  loss: 0.04917801\n",
      "epoch: 122  batch: 17  loss: 0.05111154\n",
      "epoch: 122  batch: 18  loss: 0.04948561\n",
      "epoch: 122  batch: 19  loss: 0.05092524\n",
      "epoch: 122  batch: 20  loss: 0.24335964\n",
      "epoch: 122  batch: 21  loss: 0.27632460\n",
      "epoch: 122  batch: 22  loss: 0.05297524\n",
      "epoch: 122  batch: 23  loss: 0.04104552\n",
      "epoch: 122  batch: 24  loss: 0.07089831\n",
      "epoch: 122  batch: 25  loss: 0.07107452\n",
      "epoch: 122  batch: 26  loss: 0.02002656\n",
      "epoch: 122  batch: 27  loss: 0.04895116\n",
      "epoch: 122  batch: 28  loss: 0.01448063\n",
      "epoch: 122  batch: 29  loss: 0.01601208\n",
      "epoch: 122  batch: 30  loss: 0.01635946\n",
      "epoch: 122  batch: 31  loss: 0.02542772\n",
      "epoch: 122  batch: 32  loss: 0.01190598\n",
      "epoch: 122  batch: 33  loss: 0.02925850\n",
      "epoch: 122  batch: 34  loss: 0.09572639\n",
      "epoch: 122  batch: 35  loss: 0.13565257\n",
      "epoch: 122  batch: 36  loss: 0.07572216\n",
      "epoch: 122  batch: 37  loss: 0.03790081\n",
      "epoch: 122  batch: 38  loss: 0.03286205\n",
      "epoch: 122  batch: 39  loss: 0.12222513\n",
      "epoch: 122  batch: 40  loss: 0.06974243\n",
      "epoch: 122  batch: 41  loss: 0.15715796\n",
      "epoch: 122  batch: 42  loss: 0.06754160\n",
      "epoch: 122  batch: 43  loss: 0.10462326\n",
      "epoch: 122  batch: 44  loss: 0.15557989\n",
      "epoch: 122  batch: 45  loss: 0.15849885\n",
      "epoch: 122  batch: 46  loss: 0.08346871\n",
      "epoch: 122  batch: 47  loss: 0.07622633\n",
      "epoch: 122  batch: 48  loss: 0.11772713\n",
      "epoch: 122  batch: 49  loss: 0.13894854\n",
      "epoch: 122  batch: 50  loss: 0.11861878\n",
      "epoch: 122  batch: 51  loss: 0.07926058\n",
      "epoch: 122  batch: 52  loss: 0.08587261\n",
      "epoch: 122  batch: 53  loss: 0.05567155\n",
      "epoch: 122  batch: 54  loss: 0.32338649\n",
      "epoch: 122  batch: 55  loss: 0.20588376\n",
      "epoch: 122  batch: 56  loss: 0.08030068\n",
      "epoch: 122  batch: 57  loss: 0.04219929\n",
      "epoch: 122  batch: 58  loss: 0.09680038\n",
      "epoch: 122  batch: 59  loss: 0.08486845\n",
      "epoch: 122  batch: 60  loss: 0.03130430\n",
      "epoch: 122  batch: 61  loss: 0.24128199\n",
      "epoch: 122  batch: 62  loss: 0.05089149\n",
      "epoch: 122  batch: 63  loss: 0.02412064\n",
      "epoch: 122  batch: 64  loss: 0.02043524\n",
      "epoch: 122  batch: 65  loss: 0.04000738\n",
      "epoch: 122  batch: 66  loss: 0.04069380\n",
      "epoch: 122  batch: 67  loss: 0.03330754\n",
      "epoch: 122  batch: 68  loss: 0.04880450\n",
      "epoch: 123  batch: 1  loss: 0.12609655\n",
      "epoch: 123  batch: 2  loss: 0.04677640\n",
      "epoch: 123  batch: 3  loss: 0.03263849\n",
      "epoch: 123  batch: 4  loss: 0.03067785\n",
      "epoch: 123  batch: 5  loss: 0.08440486\n",
      "epoch: 123  batch: 6  loss: 0.07249349\n",
      "epoch: 123  batch: 7  loss: 0.18259139\n",
      "epoch: 123  batch: 8  loss: 0.05868925\n",
      "epoch: 123  batch: 9  loss: 0.07106494\n",
      "epoch: 123  batch: 10  loss: 0.15457031\n",
      "epoch: 123  batch: 11  loss: 0.20439498\n",
      "epoch: 123  batch: 12  loss: 0.07221109\n",
      "epoch: 123  batch: 13  loss: 0.06148777\n",
      "epoch: 123  batch: 14  loss: 0.13878274\n",
      "epoch: 123  batch: 15  loss: 0.11960755\n",
      "epoch: 123  batch: 16  loss: 0.04776626\n",
      "epoch: 123  batch: 17  loss: 0.04897652\n",
      "epoch: 123  batch: 18  loss: 0.04953993\n",
      "epoch: 123  batch: 19  loss: 0.05057961\n",
      "epoch: 123  batch: 20  loss: 0.24212515\n",
      "epoch: 123  batch: 21  loss: 0.27485415\n",
      "epoch: 123  batch: 22  loss: 0.05295156\n",
      "epoch: 123  batch: 23  loss: 0.04118189\n",
      "epoch: 123  batch: 24  loss: 0.07090644\n",
      "epoch: 123  batch: 25  loss: 0.07089704\n",
      "epoch: 123  batch: 26  loss: 0.01967366\n",
      "epoch: 123  batch: 27  loss: 0.04756333\n",
      "epoch: 123  batch: 28  loss: 0.01428317\n",
      "epoch: 123  batch: 29  loss: 0.01698357\n",
      "epoch: 123  batch: 30  loss: 0.01627810\n",
      "epoch: 123  batch: 31  loss: 0.02479310\n",
      "epoch: 123  batch: 32  loss: 0.01202409\n",
      "epoch: 123  batch: 33  loss: 0.02473751\n",
      "epoch: 123  batch: 34  loss: 0.09597655\n",
      "epoch: 123  batch: 35  loss: 0.13466698\n",
      "epoch: 123  batch: 36  loss: 0.07711376\n",
      "epoch: 123  batch: 37  loss: 0.03804088\n",
      "epoch: 123  batch: 38  loss: 0.03266493\n",
      "epoch: 123  batch: 39  loss: 0.12044063\n",
      "epoch: 123  batch: 40  loss: 0.07034186\n",
      "epoch: 123  batch: 41  loss: 0.15643644\n",
      "epoch: 123  batch: 42  loss: 0.06730888\n",
      "epoch: 123  batch: 43  loss: 0.10275467\n",
      "epoch: 123  batch: 44  loss: 0.15210623\n",
      "epoch: 123  batch: 45  loss: 0.15438175\n",
      "epoch: 123  batch: 46  loss: 0.08289085\n",
      "epoch: 123  batch: 47  loss: 0.07466435\n",
      "epoch: 123  batch: 48  loss: 0.11732966\n",
      "epoch: 123  batch: 49  loss: 0.13927427\n",
      "epoch: 123  batch: 50  loss: 0.11760698\n",
      "epoch: 123  batch: 51  loss: 0.07936902\n",
      "epoch: 123  batch: 52  loss: 0.08514747\n",
      "epoch: 123  batch: 53  loss: 0.05548532\n",
      "epoch: 123  batch: 54  loss: 0.32360688\n",
      "epoch: 123  batch: 55  loss: 0.20481373\n",
      "epoch: 123  batch: 56  loss: 0.08010264\n",
      "epoch: 123  batch: 57  loss: 0.04181568\n",
      "epoch: 123  batch: 58  loss: 0.09514332\n",
      "epoch: 123  batch: 59  loss: 0.08280213\n",
      "epoch: 123  batch: 60  loss: 0.02940838\n",
      "epoch: 123  batch: 61  loss: 0.22852449\n",
      "epoch: 123  batch: 62  loss: 0.04436349\n",
      "epoch: 123  batch: 63  loss: 0.02373587\n",
      "epoch: 123  batch: 64  loss: 0.01988724\n",
      "epoch: 123  batch: 65  loss: 0.03996178\n",
      "epoch: 123  batch: 66  loss: 0.03967766\n",
      "epoch: 123  batch: 67  loss: 0.03089964\n",
      "epoch: 123  batch: 68  loss: 0.04880489\n",
      "epoch: 124  batch: 1  loss: 0.12531967\n",
      "epoch: 124  batch: 2  loss: 0.04883713\n",
      "epoch: 124  batch: 3  loss: 0.03252786\n",
      "epoch: 124  batch: 4  loss: 0.03261019\n",
      "epoch: 124  batch: 5  loss: 0.08408717\n",
      "epoch: 124  batch: 6  loss: 0.07283602\n",
      "epoch: 124  batch: 7  loss: 0.18024278\n",
      "epoch: 124  batch: 8  loss: 0.05834265\n",
      "epoch: 124  batch: 9  loss: 0.07065888\n",
      "epoch: 124  batch: 10  loss: 0.15322736\n",
      "epoch: 124  batch: 11  loss: 0.20094715\n",
      "epoch: 124  batch: 12  loss: 0.07163086\n",
      "epoch: 124  batch: 13  loss: 0.05844085\n",
      "epoch: 124  batch: 14  loss: 0.13843220\n",
      "epoch: 124  batch: 15  loss: 0.12005069\n",
      "epoch: 124  batch: 16  loss: 0.04582991\n",
      "epoch: 124  batch: 17  loss: 0.04950582\n",
      "epoch: 124  batch: 18  loss: 0.04805787\n",
      "epoch: 124  batch: 19  loss: 0.05023916\n",
      "epoch: 124  batch: 20  loss: 0.24081063\n",
      "epoch: 124  batch: 21  loss: 0.27347225\n",
      "epoch: 124  batch: 22  loss: 0.05275016\n",
      "epoch: 124  batch: 23  loss: 0.04220296\n",
      "epoch: 124  batch: 24  loss: 0.07091991\n",
      "epoch: 124  batch: 25  loss: 0.06913957\n",
      "epoch: 124  batch: 26  loss: 0.02045163\n",
      "epoch: 124  batch: 27  loss: 0.04617995\n",
      "epoch: 124  batch: 28  loss: 0.01383312\n",
      "epoch: 124  batch: 29  loss: 0.01681376\n",
      "epoch: 124  batch: 30  loss: 0.01619287\n",
      "epoch: 124  batch: 31  loss: 0.02493373\n",
      "epoch: 124  batch: 32  loss: 0.01200857\n",
      "epoch: 124  batch: 33  loss: 0.02401809\n",
      "epoch: 124  batch: 34  loss: 0.09816312\n",
      "epoch: 124  batch: 35  loss: 0.13536581\n",
      "epoch: 124  batch: 36  loss: 0.07818767\n",
      "epoch: 124  batch: 37  loss: 0.03738502\n",
      "epoch: 124  batch: 38  loss: 0.03268375\n",
      "epoch: 124  batch: 39  loss: 0.12033627\n",
      "epoch: 124  batch: 40  loss: 0.07167131\n",
      "epoch: 124  batch: 41  loss: 0.15566321\n",
      "epoch: 124  batch: 42  loss: 0.06691529\n",
      "epoch: 124  batch: 43  loss: 0.10006680\n",
      "epoch: 124  batch: 44  loss: 0.15006213\n",
      "epoch: 124  batch: 45  loss: 0.15319879\n",
      "epoch: 124  batch: 46  loss: 0.08356643\n",
      "epoch: 124  batch: 47  loss: 0.07436913\n",
      "epoch: 124  batch: 48  loss: 0.11398678\n",
      "epoch: 124  batch: 49  loss: 0.13970555\n",
      "epoch: 124  batch: 50  loss: 0.11389747\n",
      "epoch: 124  batch: 51  loss: 0.07894426\n",
      "epoch: 124  batch: 52  loss: 0.08212308\n",
      "epoch: 124  batch: 53  loss: 0.05619717\n",
      "epoch: 124  batch: 54  loss: 0.32091674\n",
      "epoch: 124  batch: 55  loss: 0.20644811\n",
      "epoch: 124  batch: 56  loss: 0.08111565\n",
      "epoch: 124  batch: 57  loss: 0.04243418\n",
      "epoch: 124  batch: 58  loss: 0.09391566\n",
      "epoch: 124  batch: 59  loss: 0.09417909\n",
      "epoch: 124  batch: 60  loss: 0.02957831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124  batch: 61  loss: 0.21887042\n",
      "epoch: 124  batch: 62  loss: 0.03990813\n",
      "epoch: 124  batch: 63  loss: 0.02339012\n",
      "epoch: 124  batch: 64  loss: 0.02026834\n",
      "epoch: 124  batch: 65  loss: 0.03937712\n",
      "epoch: 124  batch: 66  loss: 0.03982591\n",
      "epoch: 124  batch: 67  loss: 0.03131703\n",
      "epoch: 124  batch: 68  loss: 0.04870238\n",
      "epoch: 125  batch: 1  loss: 0.12502448\n",
      "epoch: 125  batch: 2  loss: 0.04832089\n",
      "epoch: 125  batch: 3  loss: 0.03228236\n",
      "epoch: 125  batch: 4  loss: 0.03113125\n",
      "epoch: 125  batch: 5  loss: 0.08355881\n",
      "epoch: 125  batch: 6  loss: 0.07162406\n",
      "epoch: 125  batch: 7  loss: 0.17967464\n",
      "epoch: 125  batch: 8  loss: 0.05775662\n",
      "epoch: 125  batch: 9  loss: 0.06947049\n",
      "epoch: 125  batch: 10  loss: 0.14888375\n",
      "epoch: 125  batch: 11  loss: 0.19903594\n",
      "epoch: 125  batch: 12  loss: 0.07049269\n",
      "epoch: 125  batch: 13  loss: 0.05677329\n",
      "epoch: 125  batch: 14  loss: 0.13829155\n",
      "epoch: 125  batch: 15  loss: 0.12097751\n",
      "epoch: 125  batch: 16  loss: 0.04645356\n",
      "epoch: 125  batch: 17  loss: 0.04793724\n",
      "epoch: 125  batch: 18  loss: 0.04826292\n",
      "epoch: 125  batch: 19  loss: 0.04945776\n",
      "epoch: 125  batch: 20  loss: 0.23949917\n",
      "epoch: 125  batch: 21  loss: 0.27183083\n",
      "epoch: 125  batch: 22  loss: 0.05261315\n",
      "epoch: 125  batch: 23  loss: 0.04014315\n",
      "epoch: 125  batch: 24  loss: 0.07124889\n",
      "epoch: 125  batch: 25  loss: 0.06996800\n",
      "epoch: 125  batch: 26  loss: 0.02054674\n",
      "epoch: 125  batch: 27  loss: 0.04410349\n",
      "epoch: 125  batch: 28  loss: 0.01452792\n",
      "epoch: 125  batch: 29  loss: 0.01643163\n",
      "epoch: 125  batch: 30  loss: 0.01589496\n",
      "epoch: 125  batch: 31  loss: 0.02460331\n",
      "epoch: 125  batch: 32  loss: 0.01185850\n",
      "epoch: 125  batch: 33  loss: 0.02288239\n",
      "epoch: 125  batch: 34  loss: 0.09711992\n",
      "epoch: 125  batch: 35  loss: 0.13444428\n",
      "epoch: 125  batch: 36  loss: 0.07904830\n",
      "epoch: 125  batch: 37  loss: 0.03739563\n",
      "epoch: 125  batch: 38  loss: 0.03265790\n",
      "epoch: 125  batch: 39  loss: 0.11946328\n",
      "epoch: 125  batch: 40  loss: 0.07176808\n",
      "epoch: 125  batch: 41  loss: 0.15487695\n",
      "epoch: 125  batch: 42  loss: 0.06660892\n",
      "epoch: 125  batch: 43  loss: 0.09857316\n",
      "epoch: 125  batch: 44  loss: 0.14531878\n",
      "epoch: 125  batch: 45  loss: 0.15082183\n",
      "epoch: 125  batch: 46  loss: 0.08156249\n",
      "epoch: 125  batch: 47  loss: 0.07452506\n",
      "epoch: 125  batch: 48  loss: 0.11324418\n",
      "epoch: 125  batch: 49  loss: 0.14038169\n",
      "epoch: 125  batch: 50  loss: 0.11085501\n",
      "epoch: 125  batch: 51  loss: 0.07929228\n",
      "epoch: 125  batch: 52  loss: 0.08104447\n",
      "epoch: 125  batch: 53  loss: 0.05509979\n",
      "epoch: 125  batch: 54  loss: 0.32100263\n",
      "epoch: 125  batch: 55  loss: 0.20317031\n",
      "epoch: 125  batch: 56  loss: 0.08067932\n",
      "epoch: 125  batch: 57  loss: 0.04109032\n",
      "epoch: 125  batch: 58  loss: 0.09325510\n",
      "epoch: 125  batch: 59  loss: 0.08542468\n",
      "epoch: 125  batch: 60  loss: 0.02890472\n",
      "epoch: 125  batch: 61  loss: 0.20825128\n",
      "epoch: 125  batch: 62  loss: 0.03686377\n",
      "epoch: 125  batch: 63  loss: 0.02230979\n",
      "epoch: 125  batch: 64  loss: 0.02016463\n",
      "epoch: 125  batch: 65  loss: 0.03908069\n",
      "epoch: 125  batch: 66  loss: 0.04049378\n",
      "epoch: 125  batch: 67  loss: 0.03191863\n",
      "epoch: 125  batch: 68  loss: 0.04847063\n",
      "epoch: 126  batch: 1  loss: 0.12492320\n",
      "epoch: 126  batch: 2  loss: 0.04777633\n",
      "epoch: 126  batch: 3  loss: 0.03224422\n",
      "epoch: 126  batch: 4  loss: 0.03059083\n",
      "epoch: 126  batch: 5  loss: 0.08343317\n",
      "epoch: 126  batch: 6  loss: 0.07098489\n",
      "epoch: 126  batch: 7  loss: 0.17939304\n",
      "epoch: 126  batch: 8  loss: 0.05735265\n",
      "epoch: 126  batch: 9  loss: 0.06838517\n",
      "epoch: 126  batch: 10  loss: 0.14655922\n",
      "epoch: 126  batch: 11  loss: 0.19588047\n",
      "epoch: 126  batch: 12  loss: 0.06935192\n",
      "epoch: 126  batch: 13  loss: 0.05461396\n",
      "epoch: 126  batch: 14  loss: 0.13688424\n",
      "epoch: 126  batch: 15  loss: 0.12165432\n",
      "epoch: 126  batch: 16  loss: 0.04564958\n",
      "epoch: 126  batch: 17  loss: 0.04752388\n",
      "epoch: 126  batch: 18  loss: 0.04867747\n",
      "epoch: 126  batch: 19  loss: 0.04937685\n",
      "epoch: 126  batch: 20  loss: 0.23795377\n",
      "epoch: 126  batch: 21  loss: 0.27064341\n",
      "epoch: 126  batch: 22  loss: 0.05253292\n",
      "epoch: 126  batch: 23  loss: 0.03979357\n",
      "epoch: 126  batch: 24  loss: 0.07125553\n",
      "epoch: 126  batch: 25  loss: 0.07020563\n",
      "epoch: 126  batch: 26  loss: 0.02019617\n",
      "epoch: 126  batch: 27  loss: 0.04316724\n",
      "epoch: 126  batch: 28  loss: 0.01386765\n",
      "epoch: 126  batch: 29  loss: 0.01616313\n",
      "epoch: 126  batch: 30  loss: 0.01586253\n",
      "epoch: 126  batch: 31  loss: 0.02423040\n",
      "epoch: 126  batch: 32  loss: 0.01186179\n",
      "epoch: 126  batch: 33  loss: 0.02149946\n",
      "epoch: 126  batch: 34  loss: 0.09657145\n",
      "epoch: 126  batch: 35  loss: 0.13424283\n",
      "epoch: 126  batch: 36  loss: 0.08021105\n",
      "epoch: 126  batch: 37  loss: 0.03727932\n",
      "epoch: 126  batch: 38  loss: 0.03268299\n",
      "epoch: 126  batch: 39  loss: 0.11872190\n",
      "epoch: 126  batch: 40  loss: 0.07209400\n",
      "epoch: 126  batch: 41  loss: 0.15444490\n",
      "epoch: 126  batch: 42  loss: 0.06626049\n",
      "epoch: 126  batch: 43  loss: 0.09740934\n",
      "epoch: 126  batch: 44  loss: 0.14208405\n",
      "epoch: 126  batch: 45  loss: 0.14841951\n",
      "epoch: 126  batch: 46  loss: 0.08083500\n",
      "epoch: 126  batch: 47  loss: 0.07407738\n",
      "epoch: 126  batch: 48  loss: 0.11139590\n",
      "epoch: 126  batch: 49  loss: 0.14086778\n",
      "epoch: 126  batch: 50  loss: 0.10645017\n",
      "epoch: 126  batch: 51  loss: 0.07984587\n",
      "epoch: 126  batch: 52  loss: 0.08042832\n",
      "epoch: 126  batch: 53  loss: 0.05501646\n",
      "epoch: 126  batch: 54  loss: 0.32094723\n",
      "epoch: 126  batch: 55  loss: 0.20273122\n",
      "epoch: 126  batch: 56  loss: 0.08043073\n",
      "epoch: 126  batch: 57  loss: 0.04106870\n",
      "epoch: 126  batch: 58  loss: 0.09266424\n",
      "epoch: 126  batch: 59  loss: 0.07809525\n",
      "epoch: 126  batch: 60  loss: 0.02811673\n",
      "epoch: 126  batch: 61  loss: 0.19671716\n",
      "epoch: 126  batch: 62  loss: 0.03550243\n",
      "epoch: 126  batch: 63  loss: 0.02160070\n",
      "epoch: 126  batch: 64  loss: 0.01993911\n",
      "epoch: 126  batch: 65  loss: 0.03914488\n",
      "epoch: 126  batch: 66  loss: 0.03989855\n",
      "epoch: 126  batch: 67  loss: 0.03076809\n",
      "epoch: 126  batch: 68  loss: 0.04841235\n",
      "epoch: 127  batch: 1  loss: 0.12446114\n",
      "epoch: 127  batch: 2  loss: 0.04846256\n",
      "epoch: 127  batch: 3  loss: 0.03207967\n",
      "epoch: 127  batch: 4  loss: 0.03122629\n",
      "epoch: 127  batch: 5  loss: 0.08317143\n",
      "epoch: 127  batch: 6  loss: 0.07087506\n",
      "epoch: 127  batch: 7  loss: 0.17779522\n",
      "epoch: 127  batch: 8  loss: 0.05696749\n",
      "epoch: 127  batch: 9  loss: 0.06769644\n",
      "epoch: 127  batch: 10  loss: 0.14424445\n",
      "epoch: 127  batch: 11  loss: 0.19231509\n",
      "epoch: 127  batch: 12  loss: 0.06823844\n",
      "epoch: 127  batch: 13  loss: 0.05298154\n",
      "epoch: 127  batch: 14  loss: 0.13612691\n",
      "epoch: 127  batch: 15  loss: 0.12227332\n",
      "epoch: 127  batch: 16  loss: 0.04381386\n",
      "epoch: 127  batch: 17  loss: 0.04746573\n",
      "epoch: 127  batch: 18  loss: 0.04796172\n",
      "epoch: 127  batch: 19  loss: 0.04880085\n",
      "epoch: 127  batch: 20  loss: 0.23700036\n",
      "epoch: 127  batch: 21  loss: 0.26938707\n",
      "epoch: 127  batch: 22  loss: 0.05252257\n",
      "epoch: 127  batch: 23  loss: 0.04048679\n",
      "epoch: 127  batch: 24  loss: 0.07103109\n",
      "epoch: 127  batch: 25  loss: 0.06935666\n",
      "epoch: 127  batch: 26  loss: 0.02042891\n",
      "epoch: 127  batch: 27  loss: 0.04205215\n",
      "epoch: 127  batch: 28  loss: 0.01321485\n",
      "epoch: 127  batch: 29  loss: 0.01693767\n",
      "epoch: 127  batch: 30  loss: 0.01610649\n",
      "epoch: 127  batch: 31  loss: 0.02406488\n",
      "epoch: 127  batch: 32  loss: 0.01195454\n",
      "epoch: 127  batch: 33  loss: 0.01791326\n",
      "epoch: 127  batch: 34  loss: 0.09782645\n",
      "epoch: 127  batch: 35  loss: 0.13345142\n",
      "epoch: 127  batch: 36  loss: 0.08139774\n",
      "epoch: 127  batch: 37  loss: 0.03722629\n",
      "epoch: 127  batch: 38  loss: 0.03258919\n",
      "epoch: 127  batch: 39  loss: 0.11750741\n",
      "epoch: 127  batch: 40  loss: 0.07305839\n",
      "epoch: 127  batch: 41  loss: 0.15375346\n",
      "epoch: 127  batch: 42  loss: 0.06605242\n",
      "epoch: 127  batch: 43  loss: 0.09548076\n",
      "epoch: 127  batch: 44  loss: 0.14044192\n",
      "epoch: 127  batch: 45  loss: 0.14528348\n",
      "epoch: 127  batch: 46  loss: 0.08053147\n",
      "epoch: 127  batch: 47  loss: 0.07227372\n",
      "epoch: 127  batch: 48  loss: 0.11073887\n",
      "epoch: 127  batch: 49  loss: 0.14124788\n",
      "epoch: 127  batch: 50  loss: 0.10486904\n",
      "epoch: 127  batch: 51  loss: 0.07935446\n",
      "epoch: 127  batch: 52  loss: 0.07859466\n",
      "epoch: 127  batch: 53  loss: 0.05491193\n",
      "epoch: 127  batch: 54  loss: 0.31959072\n",
      "epoch: 127  batch: 55  loss: 0.20253882\n",
      "epoch: 127  batch: 56  loss: 0.08077225\n",
      "epoch: 127  batch: 57  loss: 0.04128285\n",
      "epoch: 127  batch: 58  loss: 0.09158247\n",
      "epoch: 127  batch: 59  loss: 0.08043331\n",
      "epoch: 127  batch: 60  loss: 0.02732097\n",
      "epoch: 127  batch: 61  loss: 0.18809283\n",
      "epoch: 127  batch: 62  loss: 0.03486573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127  batch: 63  loss: 0.02111409\n",
      "epoch: 127  batch: 64  loss: 0.02024124\n",
      "epoch: 127  batch: 65  loss: 0.03878601\n",
      "epoch: 127  batch: 66  loss: 0.03977873\n",
      "epoch: 127  batch: 67  loss: 0.03109488\n",
      "epoch: 127  batch: 68  loss: 0.04830945\n",
      "epoch: 128  batch: 1  loss: 0.12428359\n",
      "epoch: 128  batch: 2  loss: 0.04733136\n",
      "epoch: 128  batch: 3  loss: 0.03179231\n",
      "epoch: 128  batch: 4  loss: 0.03047528\n",
      "epoch: 128  batch: 5  loss: 0.08288064\n",
      "epoch: 128  batch: 6  loss: 0.07033142\n",
      "epoch: 128  batch: 7  loss: 0.17727363\n",
      "epoch: 128  batch: 8  loss: 0.05660463\n",
      "epoch: 128  batch: 9  loss: 0.06686623\n",
      "epoch: 128  batch: 10  loss: 0.14096142\n",
      "epoch: 128  batch: 11  loss: 0.19058523\n",
      "epoch: 128  batch: 12  loss: 0.06778154\n",
      "epoch: 128  batch: 13  loss: 0.05147646\n",
      "epoch: 128  batch: 14  loss: 0.13619667\n",
      "epoch: 128  batch: 15  loss: 0.12291493\n",
      "epoch: 128  batch: 16  loss: 0.04372749\n",
      "epoch: 128  batch: 17  loss: 0.04899520\n",
      "epoch: 128  batch: 18  loss: 0.04779191\n",
      "epoch: 128  batch: 19  loss: 0.04888945\n",
      "epoch: 128  batch: 20  loss: 0.23591074\n",
      "epoch: 128  batch: 21  loss: 0.26805192\n",
      "epoch: 128  batch: 22  loss: 0.05242598\n",
      "epoch: 128  batch: 23  loss: 0.03893212\n",
      "epoch: 128  batch: 24  loss: 0.07124374\n",
      "epoch: 128  batch: 25  loss: 0.06980684\n",
      "epoch: 128  batch: 26  loss: 0.02030450\n",
      "epoch: 128  batch: 27  loss: 0.04093345\n",
      "epoch: 128  batch: 28  loss: 0.01318359\n",
      "epoch: 128  batch: 29  loss: 0.01532928\n",
      "epoch: 128  batch: 30  loss: 0.01567888\n",
      "epoch: 128  batch: 31  loss: 0.02400632\n",
      "epoch: 128  batch: 32  loss: 0.01164162\n",
      "epoch: 128  batch: 33  loss: 0.02021259\n",
      "epoch: 128  batch: 34  loss: 0.09650872\n",
      "epoch: 128  batch: 35  loss: 0.13474318\n",
      "epoch: 128  batch: 36  loss: 0.08244619\n",
      "epoch: 128  batch: 37  loss: 0.03678028\n",
      "epoch: 128  batch: 38  loss: 0.03301445\n",
      "epoch: 128  batch: 39  loss: 0.11802883\n",
      "epoch: 128  batch: 40  loss: 0.07308064\n",
      "epoch: 128  batch: 41  loss: 0.15324588\n",
      "epoch: 128  batch: 42  loss: 0.06567809\n",
      "epoch: 128  batch: 43  loss: 0.09474473\n",
      "epoch: 128  batch: 44  loss: 0.13560060\n",
      "epoch: 128  batch: 45  loss: 0.14525028\n",
      "epoch: 128  batch: 46  loss: 0.07930925\n",
      "epoch: 128  batch: 47  loss: 0.07394900\n",
      "epoch: 128  batch: 48  loss: 0.10802291\n",
      "epoch: 128  batch: 49  loss: 0.14205858\n",
      "epoch: 128  batch: 50  loss: 0.09980295\n",
      "epoch: 128  batch: 51  loss: 0.08084439\n",
      "epoch: 128  batch: 52  loss: 0.07673085\n",
      "epoch: 128  batch: 53  loss: 0.05501350\n",
      "epoch: 128  batch: 54  loss: 0.31933343\n",
      "epoch: 128  batch: 55  loss: 0.20074672\n",
      "epoch: 128  batch: 56  loss: 0.08051023\n",
      "epoch: 128  batch: 57  loss: 0.04063058\n",
      "epoch: 128  batch: 58  loss: 0.09131502\n",
      "epoch: 128  batch: 59  loss: 0.08766192\n",
      "epoch: 128  batch: 60  loss: 0.02757178\n",
      "epoch: 128  batch: 61  loss: 0.18060032\n",
      "epoch: 128  batch: 62  loss: 0.03446740\n",
      "epoch: 128  batch: 63  loss: 0.02063999\n",
      "epoch: 128  batch: 64  loss: 0.01911288\n",
      "epoch: 128  batch: 65  loss: 0.03911027\n",
      "epoch: 128  batch: 66  loss: 0.03846965\n",
      "epoch: 128  batch: 67  loss: 0.02973216\n",
      "epoch: 128  batch: 68  loss: 0.04843821\n",
      "epoch: 129  batch: 1  loss: 0.12343378\n",
      "epoch: 129  batch: 2  loss: 0.05171708\n",
      "epoch: 129  batch: 3  loss: 0.03170723\n",
      "epoch: 129  batch: 4  loss: 0.03472389\n",
      "epoch: 129  batch: 5  loss: 0.08258277\n",
      "epoch: 129  batch: 6  loss: 0.07090112\n",
      "epoch: 129  batch: 7  loss: 0.17536713\n",
      "epoch: 129  batch: 8  loss: 0.05662007\n",
      "epoch: 129  batch: 9  loss: 0.06653291\n",
      "epoch: 129  batch: 10  loss: 0.14061485\n",
      "epoch: 129  batch: 11  loss: 0.18651444\n",
      "epoch: 129  batch: 12  loss: 0.06745747\n",
      "epoch: 129  batch: 13  loss: 0.04959752\n",
      "epoch: 129  batch: 14  loss: 0.13603038\n",
      "epoch: 129  batch: 15  loss: 0.12390885\n",
      "epoch: 129  batch: 16  loss: 0.04175598\n",
      "epoch: 129  batch: 17  loss: 0.05075916\n",
      "epoch: 129  batch: 18  loss: 0.04682925\n",
      "epoch: 129  batch: 19  loss: 0.04755905\n",
      "epoch: 129  batch: 20  loss: 0.23488647\n",
      "epoch: 129  batch: 21  loss: 0.26678693\n",
      "epoch: 129  batch: 22  loss: 0.05242028\n",
      "epoch: 129  batch: 23  loss: 0.04159231\n",
      "epoch: 129  batch: 24  loss: 0.07098512\n",
      "epoch: 129  batch: 25  loss: 0.06838354\n",
      "epoch: 129  batch: 26  loss: 0.02116462\n",
      "epoch: 129  batch: 27  loss: 0.04027399\n",
      "epoch: 129  batch: 28  loss: 0.01274176\n",
      "epoch: 129  batch: 29  loss: 0.01648020\n",
      "epoch: 129  batch: 30  loss: 0.01957481\n",
      "epoch: 129  batch: 31  loss: 0.02384163\n",
      "epoch: 129  batch: 32  loss: 0.01195231\n",
      "epoch: 129  batch: 33  loss: 0.01448186\n",
      "epoch: 129  batch: 34  loss: 0.10067980\n",
      "epoch: 129  batch: 35  loss: 0.13710803\n",
      "epoch: 129  batch: 36  loss: 0.08325192\n",
      "epoch: 129  batch: 37  loss: 0.03729461\n",
      "epoch: 129  batch: 38  loss: 0.03309332\n",
      "epoch: 129  batch: 39  loss: 0.11559602\n",
      "epoch: 129  batch: 40  loss: 0.07464643\n",
      "epoch: 129  batch: 41  loss: 0.15226653\n",
      "epoch: 129  batch: 42  loss: 0.06560739\n",
      "epoch: 129  batch: 43  loss: 0.09191311\n",
      "epoch: 129  batch: 44  loss: 0.13650006\n",
      "epoch: 129  batch: 45  loss: 0.13990918\n",
      "epoch: 129  batch: 46  loss: 0.08073684\n",
      "epoch: 129  batch: 47  loss: 0.07108516\n",
      "epoch: 129  batch: 48  loss: 0.11089904\n",
      "epoch: 129  batch: 49  loss: 0.14239989\n",
      "epoch: 129  batch: 50  loss: 0.10424122\n",
      "epoch: 129  batch: 51  loss: 0.07918195\n",
      "epoch: 129  batch: 52  loss: 0.07606796\n",
      "epoch: 129  batch: 53  loss: 0.05582773\n",
      "epoch: 129  batch: 54  loss: 0.31637540\n",
      "epoch: 129  batch: 55  loss: 0.20361288\n",
      "epoch: 129  batch: 56  loss: 0.08273281\n",
      "epoch: 129  batch: 57  loss: 0.04163543\n",
      "epoch: 129  batch: 58  loss: 0.08952086\n",
      "epoch: 129  batch: 59  loss: 0.10051297\n",
      "epoch: 129  batch: 60  loss: 0.02686682\n",
      "epoch: 129  batch: 61  loss: 0.17554300\n",
      "epoch: 129  batch: 62  loss: 0.03448505\n",
      "epoch: 129  batch: 63  loss: 0.02192656\n",
      "epoch: 129  batch: 64  loss: 0.01939756\n",
      "epoch: 129  batch: 65  loss: 0.03712059\n",
      "epoch: 129  batch: 66  loss: 0.03836686\n",
      "epoch: 129  batch: 67  loss: 0.03013950\n",
      "epoch: 129  batch: 68  loss: 0.04833471\n",
      "epoch: 130  batch: 1  loss: 0.12337650\n",
      "epoch: 130  batch: 2  loss: 0.04889397\n",
      "epoch: 130  batch: 3  loss: 0.03160426\n",
      "epoch: 130  batch: 4  loss: 0.03065563\n",
      "epoch: 130  batch: 5  loss: 0.08212922\n",
      "epoch: 130  batch: 6  loss: 0.06950707\n",
      "epoch: 130  batch: 7  loss: 0.17479584\n",
      "epoch: 130  batch: 8  loss: 0.05629317\n",
      "epoch: 130  batch: 9  loss: 0.06572623\n",
      "epoch: 130  batch: 10  loss: 0.13597612\n",
      "epoch: 130  batch: 11  loss: 0.18630211\n",
      "epoch: 130  batch: 12  loss: 0.06685051\n",
      "epoch: 130  batch: 13  loss: 0.04805709\n",
      "epoch: 130  batch: 14  loss: 0.13644888\n",
      "epoch: 130  batch: 15  loss: 0.12399657\n",
      "epoch: 130  batch: 16  loss: 0.04420697\n",
      "epoch: 130  batch: 17  loss: 0.04884472\n",
      "epoch: 130  batch: 18  loss: 0.04633275\n",
      "epoch: 130  batch: 19  loss: 0.04702903\n",
      "epoch: 130  batch: 20  loss: 0.23339647\n",
      "epoch: 130  batch: 21  loss: 0.26469430\n",
      "epoch: 130  batch: 22  loss: 0.05220062\n",
      "epoch: 130  batch: 23  loss: 0.03827306\n",
      "epoch: 130  batch: 24  loss: 0.07143884\n",
      "epoch: 130  batch: 25  loss: 0.06965514\n",
      "epoch: 130  batch: 26  loss: 0.02212796\n",
      "epoch: 130  batch: 27  loss: 0.03760785\n",
      "epoch: 130  batch: 28  loss: 0.01584250\n",
      "epoch: 130  batch: 29  loss: 0.01591477\n",
      "epoch: 130  batch: 30  loss: 0.01575551\n",
      "epoch: 130  batch: 31  loss: 0.02381334\n",
      "epoch: 130  batch: 32  loss: 0.01151783\n",
      "epoch: 130  batch: 33  loss: 0.01822276\n",
      "epoch: 130  batch: 34  loss: 0.09779338\n",
      "epoch: 130  batch: 35  loss: 0.13290139\n",
      "epoch: 130  batch: 36  loss: 0.08382849\n",
      "epoch: 130  batch: 37  loss: 0.03652116\n",
      "epoch: 130  batch: 38  loss: 0.03318156\n",
      "epoch: 130  batch: 39  loss: 0.11689143\n",
      "epoch: 130  batch: 40  loss: 0.07393325\n",
      "epoch: 130  batch: 41  loss: 0.15187331\n",
      "epoch: 130  batch: 42  loss: 0.06518473\n",
      "epoch: 130  batch: 43  loss: 0.09163391\n",
      "epoch: 130  batch: 44  loss: 0.13156568\n",
      "epoch: 130  batch: 45  loss: 0.14226113\n",
      "epoch: 130  batch: 46  loss: 0.07756934\n",
      "epoch: 130  batch: 47  loss: 0.07306697\n",
      "epoch: 130  batch: 48  loss: 0.10658963\n",
      "epoch: 130  batch: 49  loss: 0.14308108\n",
      "epoch: 130  batch: 50  loss: 0.09582467\n",
      "epoch: 130  batch: 51  loss: 0.08066392\n",
      "epoch: 130  batch: 52  loss: 0.07305025\n",
      "epoch: 130  batch: 53  loss: 0.05469735\n",
      "epoch: 130  batch: 54  loss: 0.31607249\n",
      "epoch: 130  batch: 55  loss: 0.19881681\n",
      "epoch: 130  batch: 56  loss: 0.08135434\n",
      "epoch: 130  batch: 57  loss: 0.03992315\n",
      "epoch: 130  batch: 58  loss: 0.08955891\n",
      "epoch: 130  batch: 59  loss: 0.09243925\n",
      "epoch: 130  batch: 60  loss: 0.02757953\n",
      "epoch: 130  batch: 61  loss: 0.17027590\n",
      "epoch: 130  batch: 62  loss: 0.03393399\n",
      "epoch: 130  batch: 63  loss: 0.02005336\n",
      "epoch: 130  batch: 64  loss: 0.01944214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130  batch: 65  loss: 0.03765304\n",
      "epoch: 130  batch: 66  loss: 0.03968696\n",
      "epoch: 130  batch: 67  loss: 0.03100343\n",
      "epoch: 130  batch: 68  loss: 0.04810396\n",
      "epoch: 131  batch: 1  loss: 0.12357721\n",
      "epoch: 131  batch: 2  loss: 0.04773357\n",
      "epoch: 131  batch: 3  loss: 0.03153795\n",
      "epoch: 131  batch: 4  loss: 0.03006226\n",
      "epoch: 131  batch: 5  loss: 0.08198546\n",
      "epoch: 131  batch: 6  loss: 0.06896067\n",
      "epoch: 131  batch: 7  loss: 0.17447428\n",
      "epoch: 131  batch: 8  loss: 0.05597231\n",
      "epoch: 131  batch: 9  loss: 0.06464912\n",
      "epoch: 131  batch: 10  loss: 0.13428135\n",
      "epoch: 131  batch: 11  loss: 0.18295097\n",
      "epoch: 131  batch: 12  loss: 0.06605373\n",
      "epoch: 131  batch: 13  loss: 0.04746618\n",
      "epoch: 131  batch: 14  loss: 0.13426977\n",
      "epoch: 131  batch: 15  loss: 0.12458258\n",
      "epoch: 131  batch: 16  loss: 0.04259781\n",
      "epoch: 131  batch: 17  loss: 0.04456546\n",
      "epoch: 131  batch: 18  loss: 0.04695519\n",
      "epoch: 131  batch: 19  loss: 0.04712707\n",
      "epoch: 131  batch: 20  loss: 0.23242059\n",
      "epoch: 131  batch: 21  loss: 0.26388884\n",
      "epoch: 131  batch: 22  loss: 0.05231921\n",
      "epoch: 131  batch: 23  loss: 0.03848679\n",
      "epoch: 131  batch: 24  loss: 0.07099807\n",
      "epoch: 131  batch: 25  loss: 0.06953162\n",
      "epoch: 131  batch: 26  loss: 0.02106750\n",
      "epoch: 131  batch: 27  loss: 0.03669539\n",
      "epoch: 131  batch: 28  loss: 0.01300236\n",
      "epoch: 131  batch: 29  loss: 0.01653061\n",
      "epoch: 131  batch: 30  loss: 0.01550542\n",
      "epoch: 131  batch: 31  loss: 0.02350728\n",
      "epoch: 131  batch: 32  loss: 0.01176844\n",
      "epoch: 131  batch: 33  loss: 0.01439263\n",
      "epoch: 131  batch: 34  loss: 0.09750414\n",
      "epoch: 131  batch: 35  loss: 0.13142948\n",
      "epoch: 131  batch: 36  loss: 0.08490298\n",
      "epoch: 131  batch: 37  loss: 0.03712741\n",
      "epoch: 131  batch: 38  loss: 0.03242353\n",
      "epoch: 131  batch: 39  loss: 0.11460341\n",
      "epoch: 131  batch: 40  loss: 0.07426021\n",
      "epoch: 131  batch: 41  loss: 0.15147913\n",
      "epoch: 131  batch: 42  loss: 0.06496617\n",
      "epoch: 131  batch: 43  loss: 0.09045771\n",
      "epoch: 131  batch: 44  loss: 0.12993242\n",
      "epoch: 131  batch: 45  loss: 0.13704315\n",
      "epoch: 131  batch: 46  loss: 0.07716918\n",
      "epoch: 131  batch: 47  loss: 0.07106572\n",
      "epoch: 131  batch: 48  loss: 0.10647073\n",
      "epoch: 131  batch: 49  loss: 0.14327905\n",
      "epoch: 131  batch: 50  loss: 0.09293264\n",
      "epoch: 131  batch: 51  loss: 0.08061590\n",
      "epoch: 131  batch: 52  loss: 0.07433835\n",
      "epoch: 131  batch: 53  loss: 0.05438722\n",
      "epoch: 131  batch: 54  loss: 0.31611973\n",
      "epoch: 131  batch: 55  loss: 0.19760768\n",
      "epoch: 131  batch: 56  loss: 0.08093375\n",
      "epoch: 131  batch: 57  loss: 0.04046387\n",
      "epoch: 131  batch: 58  loss: 0.08880462\n",
      "epoch: 131  batch: 59  loss: 0.07803680\n",
      "epoch: 131  batch: 60  loss: 0.02618907\n",
      "epoch: 131  batch: 61  loss: 0.15801965\n",
      "epoch: 131  batch: 62  loss: 0.03396356\n",
      "epoch: 131  batch: 63  loss: 0.01952562\n",
      "epoch: 131  batch: 64  loss: 0.01932947\n",
      "epoch: 131  batch: 65  loss: 0.03722955\n",
      "epoch: 131  batch: 66  loss: 0.03896564\n",
      "epoch: 131  batch: 67  loss: 0.03044303\n",
      "epoch: 131  batch: 68  loss: 0.04797284\n",
      "epoch: 132  batch: 1  loss: 0.12322629\n",
      "epoch: 132  batch: 2  loss: 0.04678698\n",
      "epoch: 132  batch: 3  loss: 0.03135073\n",
      "epoch: 132  batch: 4  loss: 0.03032032\n",
      "epoch: 132  batch: 5  loss: 0.08187107\n",
      "epoch: 132  batch: 6  loss: 0.06896211\n",
      "epoch: 132  batch: 7  loss: 0.17375439\n",
      "epoch: 132  batch: 8  loss: 0.05557391\n",
      "epoch: 132  batch: 9  loss: 0.06394087\n",
      "epoch: 132  batch: 10  loss: 0.13198680\n",
      "epoch: 132  batch: 11  loss: 0.18005539\n",
      "epoch: 132  batch: 12  loss: 0.06431022\n",
      "epoch: 132  batch: 13  loss: 0.04613408\n",
      "epoch: 132  batch: 14  loss: 0.13329872\n",
      "epoch: 132  batch: 15  loss: 0.12525433\n",
      "epoch: 132  batch: 16  loss: 0.04175001\n",
      "epoch: 132  batch: 17  loss: 0.04589518\n",
      "epoch: 132  batch: 18  loss: 0.04687920\n",
      "epoch: 132  batch: 19  loss: 0.04719739\n",
      "epoch: 132  batch: 20  loss: 0.23143992\n",
      "epoch: 132  batch: 21  loss: 0.26277670\n",
      "epoch: 132  batch: 22  loss: 0.05226749\n",
      "epoch: 132  batch: 23  loss: 0.03791303\n",
      "epoch: 132  batch: 24  loss: 0.07055575\n",
      "epoch: 132  batch: 25  loss: 0.06960485\n",
      "epoch: 132  batch: 26  loss: 0.02046170\n",
      "epoch: 132  batch: 27  loss: 0.03628517\n",
      "epoch: 132  batch: 28  loss: 0.01274451\n",
      "epoch: 132  batch: 29  loss: 0.01543937\n",
      "epoch: 132  batch: 30  loss: 0.01547483\n",
      "epoch: 132  batch: 31  loss: 0.02346170\n",
      "epoch: 132  batch: 32  loss: 0.01158899\n",
      "epoch: 132  batch: 33  loss: 0.01586556\n",
      "epoch: 132  batch: 34  loss: 0.09662912\n",
      "epoch: 132  batch: 35  loss: 0.13225228\n",
      "epoch: 132  batch: 36  loss: 0.08582238\n",
      "epoch: 132  batch: 37  loss: 0.03654867\n",
      "epoch: 132  batch: 38  loss: 0.03285190\n",
      "epoch: 132  batch: 39  loss: 0.11496396\n",
      "epoch: 132  batch: 40  loss: 0.07428422\n",
      "epoch: 132  batch: 41  loss: 0.15132633\n",
      "epoch: 132  batch: 42  loss: 0.06457726\n",
      "epoch: 132  batch: 43  loss: 0.08996832\n",
      "epoch: 132  batch: 44  loss: 0.12701070\n",
      "epoch: 132  batch: 45  loss: 0.13658230\n",
      "epoch: 132  batch: 46  loss: 0.07599021\n",
      "epoch: 132  batch: 47  loss: 0.07118271\n",
      "epoch: 132  batch: 48  loss: 0.10413387\n",
      "epoch: 132  batch: 49  loss: 0.14391501\n",
      "epoch: 132  batch: 50  loss: 0.08810341\n",
      "epoch: 132  batch: 51  loss: 0.08119906\n",
      "epoch: 132  batch: 52  loss: 0.07316740\n",
      "epoch: 132  batch: 53  loss: 0.05456119\n",
      "epoch: 132  batch: 54  loss: 0.31549713\n",
      "epoch: 132  batch: 55  loss: 0.19626902\n",
      "epoch: 132  batch: 56  loss: 0.08071628\n",
      "epoch: 132  batch: 57  loss: 0.04027671\n",
      "epoch: 132  batch: 58  loss: 0.08842909\n",
      "epoch: 132  batch: 59  loss: 0.07685941\n",
      "epoch: 132  batch: 60  loss: 0.02623694\n",
      "epoch: 132  batch: 61  loss: 0.15291353\n",
      "epoch: 132  batch: 62  loss: 0.03311309\n",
      "epoch: 132  batch: 63  loss: 0.01869738\n",
      "epoch: 132  batch: 64  loss: 0.01858463\n",
      "epoch: 132  batch: 65  loss: 0.03778050\n",
      "epoch: 132  batch: 66  loss: 0.03831998\n",
      "epoch: 132  batch: 67  loss: 0.02964383\n",
      "epoch: 132  batch: 68  loss: 0.04809513\n",
      "epoch: 133  batch: 1  loss: 0.12263485\n",
      "epoch: 133  batch: 2  loss: 0.04786062\n",
      "epoch: 133  batch: 3  loss: 0.03112413\n",
      "epoch: 133  batch: 4  loss: 0.03157508\n",
      "epoch: 133  batch: 5  loss: 0.08166154\n",
      "epoch: 133  batch: 6  loss: 0.06886130\n",
      "epoch: 133  batch: 7  loss: 0.17238185\n",
      "epoch: 133  batch: 8  loss: 0.05545332\n",
      "epoch: 133  batch: 9  loss: 0.06336113\n",
      "epoch: 133  batch: 10  loss: 0.12989148\n",
      "epoch: 133  batch: 11  loss: 0.17632437\n",
      "epoch: 133  batch: 12  loss: 0.06401484\n",
      "epoch: 133  batch: 13  loss: 0.04595640\n",
      "epoch: 133  batch: 14  loss: 0.13203424\n",
      "epoch: 133  batch: 15  loss: 0.12583210\n",
      "epoch: 133  batch: 16  loss: 0.03990722\n",
      "epoch: 133  batch: 17  loss: 0.04583379\n",
      "epoch: 133  batch: 18  loss: 0.04653048\n",
      "epoch: 133  batch: 19  loss: 0.04674280\n",
      "epoch: 133  batch: 20  loss: 0.23055972\n",
      "epoch: 133  batch: 21  loss: 0.26166141\n",
      "epoch: 133  batch: 22  loss: 0.05234119\n",
      "epoch: 133  batch: 23  loss: 0.03892796\n",
      "epoch: 133  batch: 24  loss: 0.06997881\n",
      "epoch: 133  batch: 25  loss: 0.06899737\n",
      "epoch: 133  batch: 26  loss: 0.02106243\n",
      "epoch: 133  batch: 27  loss: 0.03539286\n",
      "epoch: 133  batch: 28  loss: 0.01223857\n",
      "epoch: 133  batch: 29  loss: 0.01685855\n",
      "epoch: 133  batch: 30  loss: 0.01713093\n",
      "epoch: 133  batch: 31  loss: 0.02335481\n",
      "epoch: 133  batch: 32  loss: 0.01171666\n",
      "epoch: 133  batch: 33  loss: 0.01217116\n",
      "epoch: 133  batch: 34  loss: 0.09867395\n",
      "epoch: 133  batch: 35  loss: 0.13029940\n",
      "epoch: 133  batch: 36  loss: 0.08685498\n",
      "epoch: 133  batch: 37  loss: 0.03676606\n",
      "epoch: 133  batch: 38  loss: 0.03236136\n",
      "epoch: 133  batch: 39  loss: 0.11299057\n",
      "epoch: 133  batch: 40  loss: 0.07517365\n",
      "epoch: 133  batch: 41  loss: 0.15051706\n",
      "epoch: 133  batch: 42  loss: 0.06452448\n",
      "epoch: 133  batch: 43  loss: 0.08760443\n",
      "epoch: 133  batch: 44  loss: 0.12633322\n",
      "epoch: 133  batch: 45  loss: 0.13227330\n",
      "epoch: 133  batch: 46  loss: 0.07595365\n",
      "epoch: 133  batch: 47  loss: 0.06902217\n",
      "epoch: 133  batch: 48  loss: 0.10493930\n",
      "epoch: 133  batch: 49  loss: 0.14431435\n",
      "epoch: 133  batch: 50  loss: 0.08824627\n",
      "epoch: 133  batch: 51  loss: 0.08025427\n",
      "epoch: 133  batch: 52  loss: 0.07313583\n",
      "epoch: 133  batch: 53  loss: 0.05387774\n",
      "epoch: 133  batch: 54  loss: 0.31404150\n",
      "epoch: 133  batch: 55  loss: 0.19494237\n",
      "epoch: 133  batch: 56  loss: 0.08097036\n",
      "epoch: 133  batch: 57  loss: 0.04098285\n",
      "epoch: 133  batch: 58  loss: 0.08741485\n",
      "epoch: 133  batch: 59  loss: 0.08324194\n",
      "epoch: 133  batch: 60  loss: 0.02550035\n",
      "epoch: 133  batch: 61  loss: 0.14574206\n",
      "epoch: 133  batch: 62  loss: 0.03339737\n",
      "epoch: 133  batch: 63  loss: 0.01883697\n",
      "epoch: 133  batch: 64  loss: 0.01920837\n",
      "epoch: 133  batch: 65  loss: 0.03687466\n",
      "epoch: 133  batch: 66  loss: 0.03774502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133  batch: 67  loss: 0.03025844\n",
      "epoch: 133  batch: 68  loss: 0.04792300\n",
      "epoch: 134  batch: 1  loss: 0.12277495\n",
      "epoch: 134  batch: 2  loss: 0.04567878\n",
      "epoch: 134  batch: 3  loss: 0.03107320\n",
      "epoch: 134  batch: 4  loss: 0.02990613\n",
      "epoch: 134  batch: 5  loss: 0.08130255\n",
      "epoch: 134  batch: 6  loss: 0.06827292\n",
      "epoch: 134  batch: 7  loss: 0.17194206\n",
      "epoch: 134  batch: 8  loss: 0.05511532\n",
      "epoch: 134  batch: 9  loss: 0.06256910\n",
      "epoch: 134  batch: 10  loss: 0.12720917\n",
      "epoch: 134  batch: 11  loss: 0.17547765\n",
      "epoch: 134  batch: 12  loss: 0.06319783\n",
      "epoch: 134  batch: 13  loss: 0.04435477\n",
      "epoch: 134  batch: 14  loss: 0.13234489\n",
      "epoch: 134  batch: 15  loss: 0.12651023\n",
      "epoch: 134  batch: 16  loss: 0.04099200\n",
      "epoch: 134  batch: 17  loss: 0.04593458\n",
      "epoch: 134  batch: 18  loss: 0.04650705\n",
      "epoch: 134  batch: 19  loss: 0.04661342\n",
      "epoch: 134  batch: 20  loss: 0.22945710\n",
      "epoch: 134  batch: 21  loss: 0.25996524\n",
      "epoch: 134  batch: 22  loss: 0.05213962\n",
      "epoch: 134  batch: 23  loss: 0.03723381\n",
      "epoch: 134  batch: 24  loss: 0.06990892\n",
      "epoch: 134  batch: 25  loss: 0.06959101\n",
      "epoch: 134  batch: 26  loss: 0.02025371\n",
      "epoch: 134  batch: 27  loss: 0.03433812\n",
      "epoch: 134  batch: 28  loss: 0.01263951\n",
      "epoch: 134  batch: 29  loss: 0.01516531\n",
      "epoch: 134  batch: 30  loss: 0.01537009\n",
      "epoch: 134  batch: 31  loss: 0.02315725\n",
      "epoch: 134  batch: 32  loss: 0.01148160\n",
      "epoch: 134  batch: 33  loss: 0.01458070\n",
      "epoch: 134  batch: 34  loss: 0.09652928\n",
      "epoch: 134  batch: 35  loss: 0.13189758\n",
      "epoch: 134  batch: 36  loss: 0.08771853\n",
      "epoch: 134  batch: 37  loss: 0.03634853\n",
      "epoch: 134  batch: 38  loss: 0.03291743\n",
      "epoch: 134  batch: 39  loss: 0.11373092\n",
      "epoch: 134  batch: 40  loss: 0.07482086\n",
      "epoch: 134  batch: 41  loss: 0.15034224\n",
      "epoch: 134  batch: 42  loss: 0.06408242\n",
      "epoch: 134  batch: 43  loss: 0.08752390\n",
      "epoch: 134  batch: 44  loss: 0.12216435\n",
      "epoch: 134  batch: 45  loss: 0.13292368\n",
      "epoch: 134  batch: 46  loss: 0.07406811\n",
      "epoch: 134  batch: 47  loss: 0.07005513\n",
      "epoch: 134  batch: 48  loss: 0.10277420\n",
      "epoch: 134  batch: 49  loss: 0.14494576\n",
      "epoch: 134  batch: 50  loss: 0.08435575\n",
      "epoch: 134  batch: 51  loss: 0.08116598\n",
      "epoch: 134  batch: 52  loss: 0.07042922\n",
      "epoch: 134  batch: 53  loss: 0.05463572\n",
      "epoch: 134  batch: 54  loss: 0.31374803\n",
      "epoch: 134  batch: 55  loss: 0.19321595\n",
      "epoch: 134  batch: 56  loss: 0.08055466\n",
      "epoch: 134  batch: 57  loss: 0.04003807\n",
      "epoch: 134  batch: 58  loss: 0.08733377\n",
      "epoch: 134  batch: 59  loss: 0.07931318\n",
      "epoch: 134  batch: 60  loss: 0.02575914\n",
      "epoch: 134  batch: 61  loss: 0.14239779\n",
      "epoch: 134  batch: 62  loss: 0.03265824\n",
      "epoch: 134  batch: 63  loss: 0.01826239\n",
      "epoch: 134  batch: 64  loss: 0.01813017\n",
      "epoch: 134  batch: 65  loss: 0.03698356\n",
      "epoch: 134  batch: 66  loss: 0.03743371\n",
      "epoch: 134  batch: 67  loss: 0.02948556\n",
      "epoch: 134  batch: 68  loss: 0.04802320\n",
      "epoch: 135  batch: 1  loss: 0.12178315\n",
      "epoch: 135  batch: 2  loss: 0.04792696\n",
      "epoch: 135  batch: 3  loss: 0.03089602\n",
      "epoch: 135  batch: 4  loss: 0.03222289\n",
      "epoch: 135  batch: 5  loss: 0.08112249\n",
      "epoch: 135  batch: 6  loss: 0.06836294\n",
      "epoch: 135  batch: 7  loss: 0.17064303\n",
      "epoch: 135  batch: 8  loss: 0.05506106\n",
      "epoch: 135  batch: 9  loss: 0.06192930\n",
      "epoch: 135  batch: 10  loss: 0.12554830\n",
      "epoch: 135  batch: 11  loss: 0.17102180\n",
      "epoch: 135  batch: 12  loss: 0.06253222\n",
      "epoch: 135  batch: 13  loss: 0.04420094\n",
      "epoch: 135  batch: 14  loss: 0.13062982\n",
      "epoch: 135  batch: 15  loss: 0.12703562\n",
      "epoch: 135  batch: 16  loss: 0.03877484\n",
      "epoch: 135  batch: 17  loss: 0.04487503\n",
      "epoch: 135  batch: 18  loss: 0.04606172\n",
      "epoch: 135  batch: 19  loss: 0.04610812\n",
      "epoch: 135  batch: 20  loss: 0.22838652\n",
      "epoch: 135  batch: 21  loss: 0.25901252\n",
      "epoch: 135  batch: 22  loss: 0.05224911\n",
      "epoch: 135  batch: 23  loss: 0.03859814\n",
      "epoch: 135  batch: 24  loss: 0.06932950\n",
      "epoch: 135  batch: 25  loss: 0.06923977\n",
      "epoch: 135  batch: 26  loss: 0.02160658\n",
      "epoch: 135  batch: 27  loss: 0.03355746\n",
      "epoch: 135  batch: 28  loss: 0.01212816\n",
      "epoch: 135  batch: 29  loss: 0.01658971\n",
      "epoch: 135  batch: 30  loss: 0.01780316\n",
      "epoch: 135  batch: 31  loss: 0.02296600\n",
      "epoch: 135  batch: 32  loss: 0.01161817\n",
      "epoch: 135  batch: 33  loss: 0.01126894\n",
      "epoch: 135  batch: 34  loss: 0.09930297\n",
      "epoch: 135  batch: 35  loss: 0.12903841\n",
      "epoch: 135  batch: 36  loss: 0.08858579\n",
      "epoch: 135  batch: 37  loss: 0.03641966\n",
      "epoch: 135  batch: 38  loss: 0.03249713\n",
      "epoch: 135  batch: 39  loss: 0.11160318\n",
      "epoch: 135  batch: 40  loss: 0.07578949\n",
      "epoch: 135  batch: 41  loss: 0.14944132\n",
      "epoch: 135  batch: 42  loss: 0.06405278\n",
      "epoch: 135  batch: 43  loss: 0.08515650\n",
      "epoch: 135  batch: 44  loss: 0.12301062\n",
      "epoch: 135  batch: 45  loss: 0.12836230\n",
      "epoch: 135  batch: 46  loss: 0.07473676\n",
      "epoch: 135  batch: 47  loss: 0.06760201\n",
      "epoch: 135  batch: 48  loss: 0.10342206\n",
      "epoch: 135  batch: 49  loss: 0.14549816\n",
      "epoch: 135  batch: 50  loss: 0.08401053\n",
      "epoch: 135  batch: 51  loss: 0.08049244\n",
      "epoch: 135  batch: 52  loss: 0.07171114\n",
      "epoch: 135  batch: 53  loss: 0.05372069\n",
      "epoch: 135  batch: 54  loss: 0.31210023\n",
      "epoch: 135  batch: 55  loss: 0.19193527\n",
      "epoch: 135  batch: 56  loss: 0.08068488\n",
      "epoch: 135  batch: 57  loss: 0.04101473\n",
      "epoch: 135  batch: 58  loss: 0.08638745\n",
      "epoch: 135  batch: 59  loss: 0.09433988\n",
      "epoch: 135  batch: 60  loss: 0.02511191\n",
      "epoch: 135  batch: 61  loss: 0.13586976\n",
      "epoch: 135  batch: 62  loss: 0.03292006\n",
      "epoch: 135  batch: 63  loss: 0.01829266\n",
      "epoch: 135  batch: 64  loss: 0.01894150\n",
      "epoch: 135  batch: 65  loss: 0.03599074\n",
      "epoch: 135  batch: 66  loss: 0.03656051\n",
      "epoch: 135  batch: 67  loss: 0.03020489\n",
      "epoch: 135  batch: 68  loss: 0.04782807\n",
      "epoch: 136  batch: 1  loss: 0.12198134\n",
      "epoch: 136  batch: 2  loss: 0.04496194\n",
      "epoch: 136  batch: 3  loss: 0.03094756\n",
      "epoch: 136  batch: 4  loss: 0.02971328\n",
      "epoch: 136  batch: 5  loss: 0.08073550\n",
      "epoch: 136  batch: 6  loss: 0.06786181\n",
      "epoch: 136  batch: 7  loss: 0.17006959\n",
      "epoch: 136  batch: 8  loss: 0.05470501\n",
      "epoch: 136  batch: 9  loss: 0.06141348\n",
      "epoch: 136  batch: 10  loss: 0.12269194\n",
      "epoch: 136  batch: 11  loss: 0.17098133\n",
      "epoch: 136  batch: 12  loss: 0.06219787\n",
      "epoch: 136  batch: 13  loss: 0.04289328\n",
      "epoch: 136  batch: 14  loss: 0.13168681\n",
      "epoch: 136  batch: 15  loss: 0.12763071\n",
      "epoch: 136  batch: 16  loss: 0.03997709\n",
      "epoch: 136  batch: 17  loss: 0.04452325\n",
      "epoch: 136  batch: 18  loss: 0.04565809\n",
      "epoch: 136  batch: 19  loss: 0.04559853\n",
      "epoch: 136  batch: 20  loss: 0.22708912\n",
      "epoch: 136  batch: 21  loss: 0.25676543\n",
      "epoch: 136  batch: 22  loss: 0.05200703\n",
      "epoch: 136  batch: 23  loss: 0.03676407\n",
      "epoch: 136  batch: 24  loss: 0.06925245\n",
      "epoch: 136  batch: 25  loss: 0.06966618\n",
      "epoch: 136  batch: 26  loss: 0.02073843\n",
      "epoch: 136  batch: 27  loss: 0.03221692\n",
      "epoch: 136  batch: 28  loss: 0.01235776\n",
      "epoch: 136  batch: 29  loss: 0.01509803\n",
      "epoch: 136  batch: 30  loss: 0.01542562\n",
      "epoch: 136  batch: 31  loss: 0.02271739\n",
      "epoch: 136  batch: 32  loss: 0.01140303\n",
      "epoch: 136  batch: 33  loss: 0.01345223\n",
      "epoch: 136  batch: 34  loss: 0.09659226\n",
      "epoch: 136  batch: 35  loss: 0.13072328\n",
      "epoch: 136  batch: 36  loss: 0.08931263\n",
      "epoch: 136  batch: 37  loss: 0.03597148\n",
      "epoch: 136  batch: 38  loss: 0.03290400\n",
      "epoch: 136  batch: 39  loss: 0.11241576\n",
      "epoch: 136  batch: 40  loss: 0.07543181\n",
      "epoch: 136  batch: 41  loss: 0.14918965\n",
      "epoch: 136  batch: 42  loss: 0.06363469\n",
      "epoch: 136  batch: 43  loss: 0.08530362\n",
      "epoch: 136  batch: 44  loss: 0.11820469\n",
      "epoch: 136  batch: 45  loss: 0.12918819\n",
      "epoch: 136  batch: 46  loss: 0.07233299\n",
      "epoch: 136  batch: 47  loss: 0.06880805\n",
      "epoch: 136  batch: 48  loss: 0.10158382\n",
      "epoch: 136  batch: 49  loss: 0.14599310\n",
      "epoch: 136  batch: 50  loss: 0.08100832\n",
      "epoch: 136  batch: 51  loss: 0.08108744\n",
      "epoch: 136  batch: 52  loss: 0.06810325\n",
      "epoch: 136  batch: 53  loss: 0.05451089\n",
      "epoch: 136  batch: 54  loss: 0.31148651\n",
      "epoch: 136  batch: 55  loss: 0.19101363\n",
      "epoch: 136  batch: 56  loss: 0.08025671\n",
      "epoch: 136  batch: 57  loss: 0.03983463\n",
      "epoch: 136  batch: 58  loss: 0.08627319\n",
      "epoch: 136  batch: 59  loss: 0.07185486\n",
      "epoch: 136  batch: 60  loss: 0.02521681\n",
      "epoch: 136  batch: 61  loss: 0.13208044\n",
      "epoch: 136  batch: 62  loss: 0.03266666\n",
      "epoch: 136  batch: 63  loss: 0.01799425\n",
      "epoch: 136  batch: 64  loss: 0.01826928\n",
      "epoch: 136  batch: 65  loss: 0.03598206\n",
      "epoch: 136  batch: 66  loss: 0.03783431\n",
      "epoch: 136  batch: 67  loss: 0.03001661\n",
      "epoch: 136  batch: 68  loss: 0.04764880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137  batch: 1  loss: 0.12164875\n",
      "epoch: 137  batch: 2  loss: 0.04583190\n",
      "epoch: 137  batch: 3  loss: 0.03086751\n",
      "epoch: 137  batch: 4  loss: 0.03010011\n",
      "epoch: 137  batch: 5  loss: 0.08040907\n",
      "epoch: 137  batch: 6  loss: 0.06730210\n",
      "epoch: 137  batch: 7  loss: 0.16932802\n",
      "epoch: 137  batch: 8  loss: 0.05454880\n",
      "epoch: 137  batch: 9  loss: 0.06014627\n",
      "epoch: 137  batch: 10  loss: 0.12070760\n",
      "epoch: 137  batch: 11  loss: 0.16631778\n",
      "epoch: 137  batch: 12  loss: 0.06084723\n",
      "epoch: 137  batch: 13  loss: 0.04307285\n",
      "epoch: 137  batch: 14  loss: 0.12889726\n",
      "epoch: 137  batch: 15  loss: 0.12839910\n",
      "epoch: 137  batch: 16  loss: 0.03874778\n",
      "epoch: 137  batch: 17  loss: 0.04135580\n",
      "epoch: 137  batch: 18  loss: 0.04610553\n",
      "epoch: 137  batch: 19  loss: 0.04585661\n",
      "epoch: 137  batch: 20  loss: 0.22632305\n",
      "epoch: 137  batch: 21  loss: 0.25587404\n",
      "epoch: 137  batch: 22  loss: 0.05217495\n",
      "epoch: 137  batch: 23  loss: 0.03690727\n",
      "epoch: 137  batch: 24  loss: 0.06865338\n",
      "epoch: 137  batch: 25  loss: 0.06949762\n",
      "epoch: 137  batch: 26  loss: 0.02062172\n",
      "epoch: 137  batch: 27  loss: 0.03146232\n",
      "epoch: 137  batch: 28  loss: 0.01232510\n",
      "epoch: 137  batch: 29  loss: 0.01602701\n",
      "epoch: 137  batch: 30  loss: 0.01564836\n",
      "epoch: 137  batch: 31  loss: 0.02267526\n",
      "epoch: 137  batch: 32  loss: 0.01154979\n",
      "epoch: 137  batch: 33  loss: 0.01092268\n",
      "epoch: 137  batch: 34  loss: 0.09713043\n",
      "epoch: 137  batch: 35  loss: 0.12846941\n",
      "epoch: 137  batch: 36  loss: 0.09041575\n",
      "epoch: 137  batch: 37  loss: 0.03627530\n",
      "epoch: 137  batch: 38  loss: 0.03221776\n",
      "epoch: 137  batch: 39  loss: 0.11038581\n",
      "epoch: 137  batch: 40  loss: 0.07570402\n",
      "epoch: 137  batch: 41  loss: 0.14869520\n",
      "epoch: 137  batch: 42  loss: 0.06347729\n",
      "epoch: 137  batch: 43  loss: 0.08365312\n",
      "epoch: 137  batch: 44  loss: 0.11668581\n",
      "epoch: 137  batch: 45  loss: 0.12477663\n",
      "epoch: 137  batch: 46  loss: 0.07189672\n",
      "epoch: 137  batch: 47  loss: 0.06649958\n",
      "epoch: 137  batch: 48  loss: 0.10121942\n",
      "epoch: 137  batch: 49  loss: 0.14642771\n",
      "epoch: 137  batch: 50  loss: 0.07808615\n",
      "epoch: 137  batch: 51  loss: 0.08106770\n",
      "epoch: 137  batch: 52  loss: 0.06901328\n",
      "epoch: 137  batch: 53  loss: 0.05354152\n",
      "epoch: 137  batch: 54  loss: 0.31088218\n",
      "epoch: 137  batch: 55  loss: 0.18865372\n",
      "epoch: 137  batch: 56  loss: 0.07956933\n",
      "epoch: 137  batch: 57  loss: 0.04040266\n",
      "epoch: 137  batch: 58  loss: 0.08555779\n",
      "epoch: 137  batch: 59  loss: 0.07066897\n",
      "epoch: 137  batch: 60  loss: 0.02447083\n",
      "epoch: 137  batch: 61  loss: 0.12536912\n",
      "epoch: 137  batch: 62  loss: 0.03205873\n",
      "epoch: 137  batch: 63  loss: 0.01763247\n",
      "epoch: 137  batch: 64  loss: 0.01796376\n",
      "epoch: 137  batch: 65  loss: 0.03565559\n",
      "epoch: 137  batch: 66  loss: 0.03629513\n",
      "epoch: 137  batch: 67  loss: 0.02936960\n",
      "epoch: 137  batch: 68  loss: 0.04767840\n",
      "epoch: 138  batch: 1  loss: 0.12084541\n",
      "epoch: 138  batch: 2  loss: 0.04491760\n",
      "epoch: 138  batch: 3  loss: 0.03050680\n",
      "epoch: 138  batch: 4  loss: 0.03068788\n",
      "epoch: 138  batch: 5  loss: 0.08028998\n",
      "epoch: 138  batch: 6  loss: 0.06736038\n",
      "epoch: 138  batch: 7  loss: 0.16830468\n",
      "epoch: 138  batch: 8  loss: 0.05434070\n",
      "epoch: 138  batch: 9  loss: 0.05997188\n",
      "epoch: 138  batch: 10  loss: 0.11862539\n",
      "epoch: 138  batch: 11  loss: 0.16418196\n",
      "epoch: 138  batch: 12  loss: 0.06037947\n",
      "epoch: 138  batch: 13  loss: 0.04219571\n",
      "epoch: 138  batch: 14  loss: 0.12890464\n",
      "epoch: 138  batch: 15  loss: 0.12885574\n",
      "epoch: 138  batch: 16  loss: 0.03790086\n",
      "epoch: 138  batch: 17  loss: 0.04109974\n",
      "epoch: 138  batch: 18  loss: 0.04537268\n",
      "epoch: 138  batch: 19  loss: 0.04552743\n",
      "epoch: 138  batch: 20  loss: 0.22513203\n",
      "epoch: 138  batch: 21  loss: 0.25435734\n",
      "epoch: 138  batch: 22  loss: 0.05211265\n",
      "epoch: 138  batch: 23  loss: 0.03666978\n",
      "epoch: 138  batch: 24  loss: 0.06778481\n",
      "epoch: 138  batch: 25  loss: 0.06974390\n",
      "epoch: 138  batch: 26  loss: 0.02066266\n",
      "epoch: 138  batch: 27  loss: 0.03081265\n",
      "epoch: 138  batch: 28  loss: 0.01189456\n",
      "epoch: 138  batch: 29  loss: 0.01511087\n",
      "epoch: 138  batch: 30  loss: 0.01589161\n",
      "epoch: 138  batch: 31  loss: 0.02226256\n",
      "epoch: 138  batch: 32  loss: 0.01142921\n",
      "epoch: 138  batch: 33  loss: 0.01189180\n",
      "epoch: 138  batch: 34  loss: 0.09715574\n",
      "epoch: 138  batch: 35  loss: 0.12857644\n",
      "epoch: 138  batch: 36  loss: 0.09131215\n",
      "epoch: 138  batch: 37  loss: 0.03533504\n",
      "epoch: 138  batch: 38  loss: 0.03263586\n",
      "epoch: 138  batch: 39  loss: 0.11051829\n",
      "epoch: 138  batch: 40  loss: 0.07603709\n",
      "epoch: 138  batch: 41  loss: 0.14827169\n",
      "epoch: 138  batch: 42  loss: 0.06317303\n",
      "epoch: 138  batch: 43  loss: 0.08271509\n",
      "epoch: 138  batch: 44  loss: 0.11472724\n",
      "epoch: 138  batch: 45  loss: 0.12432525\n",
      "epoch: 138  batch: 46  loss: 0.07072115\n",
      "epoch: 138  batch: 47  loss: 0.06682496\n",
      "epoch: 138  batch: 48  loss: 0.09975363\n",
      "epoch: 138  batch: 49  loss: 0.14693300\n",
      "epoch: 138  batch: 50  loss: 0.07551205\n",
      "epoch: 138  batch: 51  loss: 0.08091196\n",
      "epoch: 138  batch: 52  loss: 0.06759511\n",
      "epoch: 138  batch: 53  loss: 0.05338691\n",
      "epoch: 138  batch: 54  loss: 0.30966598\n",
      "epoch: 138  batch: 55  loss: 0.18773375\n",
      "epoch: 138  batch: 56  loss: 0.07967756\n",
      "epoch: 138  batch: 57  loss: 0.04029159\n",
      "epoch: 138  batch: 58  loss: 0.08494110\n",
      "epoch: 138  batch: 59  loss: 0.07094555\n",
      "epoch: 138  batch: 60  loss: 0.02418607\n",
      "epoch: 138  batch: 61  loss: 0.12180117\n",
      "epoch: 138  batch: 62  loss: 0.03222468\n",
      "epoch: 138  batch: 63  loss: 0.01755043\n",
      "epoch: 138  batch: 64  loss: 0.01828915\n",
      "epoch: 138  batch: 65  loss: 0.03539486\n",
      "epoch: 138  batch: 66  loss: 0.03667184\n",
      "epoch: 138  batch: 67  loss: 0.02987249\n",
      "epoch: 138  batch: 68  loss: 0.04753850\n",
      "epoch: 139  batch: 1  loss: 0.12089361\n",
      "epoch: 139  batch: 2  loss: 0.04404635\n",
      "epoch: 139  batch: 3  loss: 0.03053615\n",
      "epoch: 139  batch: 4  loss: 0.02990295\n",
      "epoch: 139  batch: 5  loss: 0.07974970\n",
      "epoch: 139  batch: 6  loss: 0.06675448\n",
      "epoch: 139  batch: 7  loss: 0.16765755\n",
      "epoch: 139  batch: 8  loss: 0.05401275\n",
      "epoch: 139  batch: 9  loss: 0.05880757\n",
      "epoch: 139  batch: 10  loss: 0.11614021\n",
      "epoch: 139  batch: 11  loss: 0.16154577\n",
      "epoch: 139  batch: 12  loss: 0.05905511\n",
      "epoch: 139  batch: 13  loss: 0.04210468\n",
      "epoch: 139  batch: 14  loss: 0.12683699\n",
      "epoch: 139  batch: 15  loss: 0.12984590\n",
      "epoch: 139  batch: 16  loss: 0.03788574\n",
      "epoch: 139  batch: 17  loss: 0.03975638\n",
      "epoch: 139  batch: 18  loss: 0.04599763\n",
      "epoch: 139  batch: 19  loss: 0.04532254\n",
      "epoch: 139  batch: 20  loss: 0.22413348\n",
      "epoch: 139  batch: 21  loss: 0.25257161\n",
      "epoch: 139  batch: 22  loss: 0.05208652\n",
      "epoch: 139  batch: 23  loss: 0.03626111\n",
      "epoch: 139  batch: 24  loss: 0.06739099\n",
      "epoch: 139  batch: 25  loss: 0.06975780\n",
      "epoch: 139  batch: 26  loss: 0.01991849\n",
      "epoch: 139  batch: 27  loss: 0.02983743\n",
      "epoch: 139  batch: 28  loss: 0.01226631\n",
      "epoch: 139  batch: 29  loss: 0.01558667\n",
      "epoch: 139  batch: 30  loss: 0.01564970\n",
      "epoch: 139  batch: 31  loss: 0.02214771\n",
      "epoch: 139  batch: 32  loss: 0.01143394\n",
      "epoch: 139  batch: 33  loss: 0.01077677\n",
      "epoch: 139  batch: 34  loss: 0.09622767\n",
      "epoch: 139  batch: 35  loss: 0.12782238\n",
      "epoch: 139  batch: 36  loss: 0.09232307\n",
      "epoch: 139  batch: 37  loss: 0.03576848\n",
      "epoch: 139  batch: 38  loss: 0.03227007\n",
      "epoch: 139  batch: 39  loss: 0.10938329\n",
      "epoch: 139  batch: 40  loss: 0.07589237\n",
      "epoch: 139  batch: 41  loss: 0.14773272\n",
      "epoch: 139  batch: 42  loss: 0.06291232\n",
      "epoch: 139  batch: 43  loss: 0.08154812\n",
      "epoch: 139  batch: 44  loss: 0.11155678\n",
      "epoch: 139  batch: 45  loss: 0.12186956\n",
      "epoch: 139  batch: 46  loss: 0.06964137\n",
      "epoch: 139  batch: 47  loss: 0.06557327\n",
      "epoch: 139  batch: 48  loss: 0.09928185\n",
      "epoch: 139  batch: 49  loss: 0.14735696\n",
      "epoch: 139  batch: 50  loss: 0.07380653\n",
      "epoch: 139  batch: 51  loss: 0.08172508\n",
      "epoch: 139  batch: 52  loss: 0.06657410\n",
      "epoch: 139  batch: 53  loss: 0.05357290\n",
      "epoch: 139  batch: 54  loss: 0.30911842\n",
      "epoch: 139  batch: 55  loss: 0.18635920\n",
      "epoch: 139  batch: 56  loss: 0.07878576\n",
      "epoch: 139  batch: 57  loss: 0.04005937\n",
      "epoch: 139  batch: 58  loss: 0.08457240\n",
      "epoch: 139  batch: 59  loss: 0.08066096\n",
      "epoch: 139  batch: 60  loss: 0.02393040\n",
      "epoch: 139  batch: 61  loss: 0.11769301\n",
      "epoch: 139  batch: 62  loss: 0.03143690\n",
      "epoch: 139  batch: 63  loss: 0.01747452\n",
      "epoch: 139  batch: 64  loss: 0.01755274\n",
      "epoch: 139  batch: 65  loss: 0.03516511\n",
      "epoch: 139  batch: 66  loss: 0.03531039\n",
      "epoch: 139  batch: 67  loss: 0.02938371\n",
      "epoch: 139  batch: 68  loss: 0.04770927\n",
      "epoch: 140  batch: 1  loss: 0.11898677\n",
      "epoch: 140  batch: 2  loss: 0.04577128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140  batch: 3  loss: 0.03006151\n",
      "epoch: 140  batch: 4  loss: 0.03467375\n",
      "epoch: 140  batch: 5  loss: 0.07966741\n",
      "epoch: 140  batch: 6  loss: 0.06735639\n",
      "epoch: 140  batch: 7  loss: 0.16646259\n",
      "epoch: 140  batch: 8  loss: 0.05400471\n",
      "epoch: 140  batch: 9  loss: 0.05892470\n",
      "epoch: 140  batch: 10  loss: 0.11535084\n",
      "epoch: 140  batch: 11  loss: 0.15896940\n",
      "epoch: 140  batch: 12  loss: 0.05921898\n",
      "epoch: 140  batch: 13  loss: 0.04118311\n",
      "epoch: 140  batch: 14  loss: 0.12721592\n",
      "epoch: 140  batch: 15  loss: 0.12984288\n",
      "epoch: 140  batch: 16  loss: 0.03617978\n",
      "epoch: 140  batch: 17  loss: 0.04033140\n",
      "epoch: 140  batch: 18  loss: 0.04480657\n",
      "epoch: 140  batch: 19  loss: 0.04468735\n",
      "epoch: 140  batch: 20  loss: 0.22259414\n",
      "epoch: 140  batch: 21  loss: 0.25122920\n",
      "epoch: 140  batch: 22  loss: 0.05201375\n",
      "epoch: 140  batch: 23  loss: 0.03761623\n",
      "epoch: 140  batch: 24  loss: 0.06693446\n",
      "epoch: 140  batch: 25  loss: 0.07026231\n",
      "epoch: 140  batch: 26  loss: 0.02177480\n",
      "epoch: 140  batch: 27  loss: 0.02932899\n",
      "epoch: 140  batch: 28  loss: 0.01228171\n",
      "epoch: 140  batch: 29  loss: 0.01544785\n",
      "epoch: 140  batch: 30  loss: 0.01883877\n",
      "epoch: 140  batch: 31  loss: 0.02167734\n",
      "epoch: 140  batch: 32  loss: 0.01137971\n",
      "epoch: 140  batch: 33  loss: 0.01027672\n",
      "epoch: 140  batch: 34  loss: 0.09920800\n",
      "epoch: 140  batch: 35  loss: 0.12614667\n",
      "epoch: 140  batch: 36  loss: 0.09306167\n",
      "epoch: 140  batch: 37  loss: 0.03533640\n",
      "epoch: 140  batch: 38  loss: 0.03307832\n",
      "epoch: 140  batch: 39  loss: 0.10839948\n",
      "epoch: 140  batch: 40  loss: 0.07691596\n",
      "epoch: 140  batch: 41  loss: 0.14688425\n",
      "epoch: 140  batch: 42  loss: 0.06285577\n",
      "epoch: 140  batch: 43  loss: 0.08004957\n",
      "epoch: 140  batch: 44  loss: 0.11266537\n",
      "epoch: 140  batch: 45  loss: 0.11952126\n",
      "epoch: 140  batch: 46  loss: 0.07010005\n",
      "epoch: 140  batch: 47  loss: 0.06539018\n",
      "epoch: 140  batch: 48  loss: 0.09939790\n",
      "epoch: 140  batch: 49  loss: 0.14791854\n",
      "epoch: 140  batch: 50  loss: 0.07322760\n",
      "epoch: 140  batch: 51  loss: 0.08193489\n",
      "epoch: 140  batch: 52  loss: 0.06705383\n",
      "epoch: 140  batch: 53  loss: 0.05333681\n",
      "epoch: 140  batch: 54  loss: 0.30804548\n",
      "epoch: 140  batch: 55  loss: 0.18636230\n",
      "epoch: 140  batch: 56  loss: 0.07910822\n",
      "epoch: 140  batch: 57  loss: 0.04070251\n",
      "epoch: 140  batch: 58  loss: 0.08360120\n",
      "epoch: 140  batch: 59  loss: 0.10344645\n",
      "epoch: 140  batch: 60  loss: 0.02361777\n",
      "epoch: 140  batch: 61  loss: 0.11367468\n",
      "epoch: 140  batch: 62  loss: 0.03162602\n",
      "epoch: 140  batch: 63  loss: 0.01733432\n",
      "epoch: 140  batch: 64  loss: 0.01839353\n",
      "epoch: 140  batch: 65  loss: 0.03433803\n",
      "epoch: 140  batch: 66  loss: 0.03504106\n",
      "epoch: 140  batch: 67  loss: 0.03050172\n",
      "epoch: 140  batch: 68  loss: 0.04733081\n",
      "epoch: 141  batch: 1  loss: 0.11941359\n",
      "epoch: 141  batch: 2  loss: 0.04309869\n",
      "epoch: 141  batch: 3  loss: 0.03059606\n",
      "epoch: 141  batch: 4  loss: 0.02967269\n",
      "epoch: 141  batch: 5  loss: 0.07886708\n",
      "epoch: 141  batch: 6  loss: 0.06638406\n",
      "epoch: 141  batch: 7  loss: 0.16539705\n",
      "epoch: 141  batch: 8  loss: 0.05360495\n",
      "epoch: 141  batch: 9  loss: 0.05797949\n",
      "epoch: 141  batch: 10  loss: 0.11247224\n",
      "epoch: 141  batch: 11  loss: 0.15820059\n",
      "epoch: 141  batch: 12  loss: 0.05832169\n",
      "epoch: 141  batch: 13  loss: 0.04060244\n",
      "epoch: 141  batch: 14  loss: 0.12733822\n",
      "epoch: 141  batch: 15  loss: 0.13089231\n",
      "epoch: 141  batch: 16  loss: 0.03746780\n",
      "epoch: 141  batch: 17  loss: 0.04085952\n",
      "epoch: 141  batch: 18  loss: 0.04485497\n",
      "epoch: 141  batch: 19  loss: 0.04417836\n",
      "epoch: 141  batch: 20  loss: 0.22043809\n",
      "epoch: 141  batch: 21  loss: 0.24827521\n",
      "epoch: 141  batch: 22  loss: 0.05180520\n",
      "epoch: 141  batch: 23  loss: 0.03551129\n",
      "epoch: 141  batch: 24  loss: 0.06677243\n",
      "epoch: 141  batch: 25  loss: 0.07049366\n",
      "epoch: 141  batch: 26  loss: 0.02119004\n",
      "epoch: 141  batch: 27  loss: 0.02767649\n",
      "epoch: 141  batch: 28  loss: 0.01234219\n",
      "epoch: 141  batch: 29  loss: 0.01493422\n",
      "epoch: 141  batch: 30  loss: 0.01532227\n",
      "epoch: 141  batch: 31  loss: 0.02150459\n",
      "epoch: 141  batch: 32  loss: 0.01110267\n",
      "epoch: 141  batch: 33  loss: 0.01146149\n",
      "epoch: 141  batch: 34  loss: 0.09542034\n",
      "epoch: 141  batch: 35  loss: 0.12703381\n",
      "epoch: 141  batch: 36  loss: 0.09361543\n",
      "epoch: 141  batch: 37  loss: 0.03483959\n",
      "epoch: 141  batch: 38  loss: 0.03274683\n",
      "epoch: 141  batch: 39  loss: 0.10877620\n",
      "epoch: 141  batch: 40  loss: 0.07626594\n",
      "epoch: 141  batch: 41  loss: 0.14666934\n",
      "epoch: 141  batch: 42  loss: 0.06234416\n",
      "epoch: 141  batch: 43  loss: 0.08013038\n",
      "epoch: 141  batch: 44  loss: 0.10857902\n",
      "epoch: 141  batch: 45  loss: 0.12007078\n",
      "epoch: 141  batch: 46  loss: 0.06800550\n",
      "epoch: 141  batch: 47  loss: 0.06529932\n",
      "epoch: 141  batch: 48  loss: 0.09758060\n",
      "epoch: 141  batch: 49  loss: 0.14802907\n",
      "epoch: 141  batch: 50  loss: 0.07157388\n",
      "epoch: 141  batch: 51  loss: 0.08169937\n",
      "epoch: 141  batch: 52  loss: 0.06378826\n",
      "epoch: 141  batch: 53  loss: 0.05369721\n",
      "epoch: 141  batch: 54  loss: 0.30635303\n",
      "epoch: 141  batch: 55  loss: 0.18588847\n",
      "epoch: 141  batch: 56  loss: 0.07829342\n",
      "epoch: 141  batch: 57  loss: 0.03961092\n",
      "epoch: 141  batch: 58  loss: 0.08338702\n",
      "epoch: 141  batch: 59  loss: 0.07532752\n",
      "epoch: 141  batch: 60  loss: 0.02360658\n",
      "epoch: 141  batch: 61  loss: 0.10988687\n",
      "epoch: 141  batch: 62  loss: 0.03209637\n",
      "epoch: 141  batch: 63  loss: 0.01742451\n",
      "epoch: 141  batch: 64  loss: 0.01805971\n",
      "epoch: 141  batch: 65  loss: 0.03430322\n",
      "epoch: 141  batch: 66  loss: 0.03639698\n",
      "epoch: 141  batch: 67  loss: 0.03027633\n",
      "epoch: 141  batch: 68  loss: 0.04687040\n",
      "epoch: 142  batch: 1  loss: 0.11962122\n",
      "epoch: 142  batch: 2  loss: 0.04281859\n",
      "epoch: 142  batch: 3  loss: 0.03041100\n",
      "epoch: 142  batch: 4  loss: 0.03138603\n",
      "epoch: 142  batch: 5  loss: 0.07845087\n",
      "epoch: 142  batch: 6  loss: 0.06580000\n",
      "epoch: 142  batch: 7  loss: 0.16484176\n",
      "epoch: 142  batch: 8  loss: 0.05339090\n",
      "epoch: 142  batch: 9  loss: 0.05669838\n",
      "epoch: 142  batch: 10  loss: 0.11078402\n",
      "epoch: 142  batch: 11  loss: 0.15417345\n",
      "epoch: 142  batch: 12  loss: 0.05669662\n",
      "epoch: 142  batch: 13  loss: 0.04064191\n",
      "epoch: 142  batch: 14  loss: 0.12489183\n",
      "epoch: 142  batch: 15  loss: 0.13169533\n",
      "epoch: 142  batch: 16  loss: 0.03655500\n",
      "epoch: 142  batch: 17  loss: 0.03788489\n",
      "epoch: 142  batch: 18  loss: 0.04566250\n",
      "epoch: 142  batch: 19  loss: 0.04484339\n",
      "epoch: 142  batch: 20  loss: 0.21989425\n",
      "epoch: 142  batch: 21  loss: 0.24734169\n",
      "epoch: 142  batch: 22  loss: 0.05205641\n",
      "epoch: 142  batch: 23  loss: 0.03536431\n",
      "epoch: 142  batch: 24  loss: 0.06629208\n",
      "epoch: 142  batch: 25  loss: 0.07012019\n",
      "epoch: 142  batch: 26  loss: 0.01946928\n",
      "epoch: 142  batch: 27  loss: 0.02760768\n",
      "epoch: 142  batch: 28  loss: 0.01223088\n",
      "epoch: 142  batch: 29  loss: 0.01541383\n",
      "epoch: 142  batch: 30  loss: 0.01550756\n",
      "epoch: 142  batch: 31  loss: 0.02175277\n",
      "epoch: 142  batch: 32  loss: 0.01142410\n",
      "epoch: 142  batch: 33  loss: 0.01001086\n",
      "epoch: 142  batch: 34  loss: 0.09502106\n",
      "epoch: 142  batch: 35  loss: 0.12502684\n",
      "epoch: 142  batch: 36  loss: 0.09480343\n",
      "epoch: 142  batch: 37  loss: 0.03531131\n",
      "epoch: 142  batch: 38  loss: 0.03219653\n",
      "epoch: 142  batch: 39  loss: 0.10719884\n",
      "epoch: 142  batch: 40  loss: 0.07619330\n",
      "epoch: 142  batch: 41  loss: 0.14630903\n",
      "epoch: 142  batch: 42  loss: 0.06212746\n",
      "epoch: 142  batch: 43  loss: 0.07926340\n",
      "epoch: 142  batch: 44  loss: 0.10674300\n",
      "epoch: 142  batch: 45  loss: 0.11636806\n",
      "epoch: 142  batch: 46  loss: 0.06724576\n",
      "epoch: 142  batch: 47  loss: 0.06339191\n",
      "epoch: 142  batch: 48  loss: 0.09657126\n",
      "epoch: 142  batch: 49  loss: 0.14822327\n",
      "epoch: 142  batch: 50  loss: 0.06807560\n",
      "epoch: 142  batch: 51  loss: 0.08249648\n",
      "epoch: 142  batch: 52  loss: 0.06477945\n",
      "epoch: 142  batch: 53  loss: 0.05297480\n",
      "epoch: 142  batch: 54  loss: 0.30582279\n",
      "epoch: 142  batch: 55  loss: 0.18388389\n",
      "epoch: 142  batch: 56  loss: 0.07678104\n",
      "epoch: 142  batch: 57  loss: 0.03979461\n",
      "epoch: 142  batch: 58  loss: 0.08279039\n",
      "epoch: 142  batch: 59  loss: 0.07163665\n",
      "epoch: 142  batch: 60  loss: 0.02302857\n",
      "epoch: 142  batch: 61  loss: 0.10528775\n",
      "epoch: 142  batch: 62  loss: 0.03030615\n",
      "epoch: 142  batch: 63  loss: 0.01730723\n",
      "epoch: 142  batch: 64  loss: 0.01730055\n",
      "epoch: 142  batch: 65  loss: 0.03416310\n",
      "epoch: 142  batch: 66  loss: 0.03490797\n",
      "epoch: 142  batch: 67  loss: 0.02945323\n",
      "epoch: 142  batch: 68  loss: 0.04714483\n",
      "epoch: 143  batch: 1  loss: 0.11695988\n",
      "epoch: 143  batch: 2  loss: 0.04380378\n",
      "epoch: 143  batch: 3  loss: 0.02980919\n",
      "epoch: 143  batch: 4  loss: 0.03418922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143  batch: 5  loss: 0.07826038\n",
      "epoch: 143  batch: 6  loss: 0.06611206\n",
      "epoch: 143  batch: 7  loss: 0.16350289\n",
      "epoch: 143  batch: 8  loss: 0.05326234\n",
      "epoch: 143  batch: 9  loss: 0.05699572\n",
      "epoch: 143  batch: 10  loss: 0.10875361\n",
      "epoch: 143  batch: 11  loss: 0.15188105\n",
      "epoch: 143  batch: 12  loss: 0.05747120\n",
      "epoch: 143  batch: 13  loss: 0.04007703\n",
      "epoch: 143  batch: 14  loss: 0.12522791\n",
      "epoch: 143  batch: 15  loss: 0.13184382\n",
      "epoch: 143  batch: 16  loss: 0.03465484\n",
      "epoch: 143  batch: 17  loss: 0.03824276\n",
      "epoch: 143  batch: 18  loss: 0.04384103\n",
      "epoch: 143  batch: 19  loss: 0.04433511\n",
      "epoch: 143  batch: 20  loss: 0.21858725\n",
      "epoch: 143  batch: 21  loss: 0.24626882\n",
      "epoch: 143  batch: 22  loss: 0.05179524\n",
      "epoch: 143  batch: 23  loss: 0.03580042\n",
      "epoch: 143  batch: 24  loss: 0.06531717\n",
      "epoch: 143  batch: 25  loss: 0.07093077\n",
      "epoch: 143  batch: 26  loss: 0.02056002\n",
      "epoch: 143  batch: 27  loss: 0.02700337\n",
      "epoch: 143  batch: 28  loss: 0.01194757\n",
      "epoch: 143  batch: 29  loss: 0.01512719\n",
      "epoch: 143  batch: 30  loss: 0.01770300\n",
      "epoch: 143  batch: 31  loss: 0.02083652\n",
      "epoch: 143  batch: 32  loss: 0.01113980\n",
      "epoch: 143  batch: 33  loss: 0.01020587\n",
      "epoch: 143  batch: 34  loss: 0.09707890\n",
      "epoch: 143  batch: 35  loss: 0.12421405\n",
      "epoch: 143  batch: 36  loss: 0.09590138\n",
      "epoch: 143  batch: 37  loss: 0.03439709\n",
      "epoch: 143  batch: 38  loss: 0.03291106\n",
      "epoch: 143  batch: 39  loss: 0.10667833\n",
      "epoch: 143  batch: 40  loss: 0.07730807\n",
      "epoch: 143  batch: 41  loss: 0.14558318\n",
      "epoch: 143  batch: 42  loss: 0.06206848\n",
      "epoch: 143  batch: 43  loss: 0.07764889\n",
      "epoch: 143  batch: 44  loss: 0.10492217\n",
      "epoch: 143  batch: 45  loss: 0.11501151\n",
      "epoch: 143  batch: 46  loss: 0.06667826\n",
      "epoch: 143  batch: 47  loss: 0.06324348\n",
      "epoch: 143  batch: 48  loss: 0.09605081\n",
      "epoch: 143  batch: 49  loss: 0.14849645\n",
      "epoch: 143  batch: 50  loss: 0.06768572\n",
      "epoch: 143  batch: 51  loss: 0.08173741\n",
      "epoch: 143  batch: 52  loss: 0.06316848\n",
      "epoch: 143  batch: 53  loss: 0.05240075\n",
      "epoch: 143  batch: 54  loss: 0.30459264\n",
      "epoch: 143  batch: 55  loss: 0.18301231\n",
      "epoch: 143  batch: 56  loss: 0.07688145\n",
      "epoch: 143  batch: 57  loss: 0.04007129\n",
      "epoch: 143  batch: 58  loss: 0.08190258\n",
      "epoch: 143  batch: 59  loss: 0.08463526\n",
      "epoch: 143  batch: 60  loss: 0.02263435\n",
      "epoch: 143  batch: 61  loss: 0.10183926\n",
      "epoch: 143  batch: 62  loss: 0.03135732\n",
      "epoch: 143  batch: 63  loss: 0.01722586\n",
      "epoch: 143  batch: 64  loss: 0.01818115\n",
      "epoch: 143  batch: 65  loss: 0.03384304\n",
      "epoch: 143  batch: 66  loss: 0.03528167\n",
      "epoch: 143  batch: 67  loss: 0.03052270\n",
      "epoch: 143  batch: 68  loss: 0.04666570\n",
      "epoch: 144  batch: 1  loss: 0.11797393\n",
      "epoch: 144  batch: 2  loss: 0.04338560\n",
      "epoch: 144  batch: 3  loss: 0.03008118\n",
      "epoch: 144  batch: 4  loss: 0.03065168\n",
      "epoch: 144  batch: 5  loss: 0.07742874\n",
      "epoch: 144  batch: 6  loss: 0.06498747\n",
      "epoch: 144  batch: 7  loss: 0.16258752\n",
      "epoch: 144  batch: 8  loss: 0.05293445\n",
      "epoch: 144  batch: 9  loss: 0.05557434\n",
      "epoch: 144  batch: 10  loss: 0.10696796\n",
      "epoch: 144  batch: 11  loss: 0.14959376\n",
      "epoch: 144  batch: 12  loss: 0.05508904\n",
      "epoch: 144  batch: 13  loss: 0.03977414\n",
      "epoch: 144  batch: 14  loss: 0.12391277\n",
      "epoch: 144  batch: 15  loss: 0.13283926\n",
      "epoch: 144  batch: 16  loss: 0.03559064\n",
      "epoch: 144  batch: 17  loss: 0.03830829\n",
      "epoch: 144  batch: 18  loss: 0.04558896\n",
      "epoch: 144  batch: 19  loss: 0.04419925\n",
      "epoch: 144  batch: 20  loss: 0.21654701\n",
      "epoch: 144  batch: 21  loss: 0.24307591\n",
      "epoch: 144  batch: 22  loss: 0.05173359\n",
      "epoch: 144  batch: 23  loss: 0.03467889\n",
      "epoch: 144  batch: 24  loss: 0.06530265\n",
      "epoch: 144  batch: 25  loss: 0.07074740\n",
      "epoch: 144  batch: 26  loss: 0.01933115\n",
      "epoch: 144  batch: 27  loss: 0.02587809\n",
      "epoch: 144  batch: 28  loss: 0.01198410\n",
      "epoch: 144  batch: 29  loss: 0.01487746\n",
      "epoch: 144  batch: 30  loss: 0.01540765\n",
      "epoch: 144  batch: 31  loss: 0.02123166\n",
      "epoch: 144  batch: 32  loss: 0.01109009\n",
      "epoch: 144  batch: 33  loss: 0.01017164\n",
      "epoch: 144  batch: 34  loss: 0.09393985\n",
      "epoch: 144  batch: 35  loss: 0.12391324\n",
      "epoch: 144  batch: 36  loss: 0.09638575\n",
      "epoch: 144  batch: 37  loss: 0.03427511\n",
      "epoch: 144  batch: 38  loss: 0.03228577\n",
      "epoch: 144  batch: 39  loss: 0.10630667\n",
      "epoch: 144  batch: 40  loss: 0.07654892\n",
      "epoch: 144  batch: 41  loss: 0.14529559\n",
      "epoch: 144  batch: 42  loss: 0.06149371\n",
      "epoch: 144  batch: 43  loss: 0.07733448\n",
      "epoch: 144  batch: 44  loss: 0.10325757\n",
      "epoch: 144  batch: 45  loss: 0.11409561\n",
      "epoch: 144  batch: 46  loss: 0.06532145\n",
      "epoch: 144  batch: 47  loss: 0.06253851\n",
      "epoch: 144  batch: 48  loss: 0.09440115\n",
      "epoch: 144  batch: 49  loss: 0.14851324\n",
      "epoch: 144  batch: 50  loss: 0.06568290\n",
      "epoch: 144  batch: 51  loss: 0.08262391\n",
      "epoch: 144  batch: 52  loss: 0.06247217\n",
      "epoch: 144  batch: 53  loss: 0.05294105\n",
      "epoch: 144  batch: 54  loss: 0.30312690\n",
      "epoch: 144  batch: 55  loss: 0.18209733\n",
      "epoch: 144  batch: 56  loss: 0.07546858\n",
      "epoch: 144  batch: 57  loss: 0.03949980\n",
      "epoch: 144  batch: 58  loss: 0.08150399\n",
      "epoch: 144  batch: 59  loss: 0.06913892\n",
      "epoch: 144  batch: 60  loss: 0.02222732\n",
      "epoch: 144  batch: 61  loss: 0.09862605\n",
      "epoch: 144  batch: 62  loss: 0.02970463\n",
      "epoch: 144  batch: 63  loss: 0.01721920\n",
      "epoch: 144  batch: 64  loss: 0.01719751\n",
      "epoch: 144  batch: 65  loss: 0.03339215\n",
      "epoch: 144  batch: 66  loss: 0.03468440\n",
      "epoch: 144  batch: 67  loss: 0.02964798\n",
      "epoch: 144  batch: 68  loss: 0.04674787\n",
      "epoch: 145  batch: 1  loss: 0.11540089\n",
      "epoch: 145  batch: 2  loss: 0.04546411\n",
      "epoch: 145  batch: 3  loss: 0.02976795\n",
      "epoch: 145  batch: 4  loss: 0.03298736\n",
      "epoch: 145  batch: 5  loss: 0.07707978\n",
      "epoch: 145  batch: 6  loss: 0.06508524\n",
      "epoch: 145  batch: 7  loss: 0.16132493\n",
      "epoch: 145  batch: 8  loss: 0.05282195\n",
      "epoch: 145  batch: 9  loss: 0.05553591\n",
      "epoch: 145  batch: 10  loss: 0.10560525\n",
      "epoch: 145  batch: 11  loss: 0.14676890\n",
      "epoch: 145  batch: 12  loss: 0.05629056\n",
      "epoch: 145  batch: 13  loss: 0.03930509\n",
      "epoch: 145  batch: 14  loss: 0.12251033\n",
      "epoch: 145  batch: 15  loss: 0.13321157\n",
      "epoch: 145  batch: 16  loss: 0.03330373\n",
      "epoch: 145  batch: 17  loss: 0.03737622\n",
      "epoch: 145  batch: 18  loss: 0.04307785\n",
      "epoch: 145  batch: 19  loss: 0.04388431\n",
      "epoch: 145  batch: 20  loss: 0.21560779\n",
      "epoch: 145  batch: 21  loss: 0.24275498\n",
      "epoch: 145  batch: 22  loss: 0.05150659\n",
      "epoch: 145  batch: 23  loss: 0.03495718\n",
      "epoch: 145  batch: 24  loss: 0.06442738\n",
      "epoch: 145  batch: 25  loss: 0.07137723\n",
      "epoch: 145  batch: 26  loss: 0.02021082\n",
      "epoch: 145  batch: 27  loss: 0.02558902\n",
      "epoch: 145  batch: 28  loss: 0.01188555\n",
      "epoch: 145  batch: 29  loss: 0.01523025\n",
      "epoch: 145  batch: 30  loss: 0.01717030\n",
      "epoch: 145  batch: 31  loss: 0.02033517\n",
      "epoch: 145  batch: 32  loss: 0.01104035\n",
      "epoch: 145  batch: 33  loss: 0.00975456\n",
      "epoch: 145  batch: 34  loss: 0.09608466\n",
      "epoch: 145  batch: 35  loss: 0.12242550\n",
      "epoch: 145  batch: 36  loss: 0.09762480\n",
      "epoch: 145  batch: 37  loss: 0.03395832\n",
      "epoch: 145  batch: 38  loss: 0.03269543\n",
      "epoch: 145  batch: 39  loss: 0.10490961\n",
      "epoch: 145  batch: 40  loss: 0.07759351\n",
      "epoch: 145  batch: 41  loss: 0.14463581\n",
      "epoch: 145  batch: 42  loss: 0.06154271\n",
      "epoch: 145  batch: 43  loss: 0.07584380\n",
      "epoch: 145  batch: 44  loss: 0.10153928\n",
      "epoch: 145  batch: 45  loss: 0.11126012\n",
      "epoch: 145  batch: 46  loss: 0.06463379\n",
      "epoch: 145  batch: 47  loss: 0.06145847\n",
      "epoch: 145  batch: 48  loss: 0.09417613\n",
      "epoch: 145  batch: 49  loss: 0.14876837\n",
      "epoch: 145  batch: 50  loss: 0.06474321\n",
      "epoch: 145  batch: 51  loss: 0.08223280\n",
      "epoch: 145  batch: 52  loss: 0.06139527\n",
      "epoch: 145  batch: 53  loss: 0.05210178\n",
      "epoch: 145  batch: 54  loss: 0.30201626\n",
      "epoch: 145  batch: 55  loss: 0.18129911\n",
      "epoch: 145  batch: 56  loss: 0.07491059\n",
      "epoch: 145  batch: 57  loss: 0.03994645\n",
      "epoch: 145  batch: 58  loss: 0.08064996\n",
      "epoch: 145  batch: 59  loss: 0.07974581\n",
      "epoch: 145  batch: 60  loss: 0.02193455\n",
      "epoch: 145  batch: 61  loss: 0.09492951\n",
      "epoch: 145  batch: 62  loss: 0.02998285\n",
      "epoch: 145  batch: 63  loss: 0.01719759\n",
      "epoch: 145  batch: 64  loss: 0.01817124\n",
      "epoch: 145  batch: 65  loss: 0.03318271\n",
      "epoch: 145  batch: 66  loss: 0.03483368\n",
      "epoch: 145  batch: 67  loss: 0.03054476\n",
      "epoch: 145  batch: 68  loss: 0.04632622\n",
      "epoch: 146  batch: 1  loss: 0.11585177\n",
      "epoch: 146  batch: 2  loss: 0.04300702\n",
      "epoch: 146  batch: 3  loss: 0.02977122\n",
      "epoch: 146  batch: 4  loss: 0.03070323\n",
      "epoch: 146  batch: 5  loss: 0.07611742\n",
      "epoch: 146  batch: 6  loss: 0.06424082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146  batch: 7  loss: 0.16044235\n",
      "epoch: 146  batch: 8  loss: 0.05246551\n",
      "epoch: 146  batch: 9  loss: 0.05453310\n",
      "epoch: 146  batch: 10  loss: 0.10302982\n",
      "epoch: 146  batch: 11  loss: 0.14497155\n",
      "epoch: 146  batch: 12  loss: 0.05374439\n",
      "epoch: 146  batch: 13  loss: 0.03924600\n",
      "epoch: 146  batch: 14  loss: 0.12195687\n",
      "epoch: 146  batch: 15  loss: 0.13408184\n",
      "epoch: 146  batch: 16  loss: 0.03392220\n",
      "epoch: 146  batch: 17  loss: 0.03761266\n",
      "epoch: 146  batch: 18  loss: 0.04447570\n",
      "epoch: 146  batch: 19  loss: 0.04365760\n",
      "epoch: 146  batch: 20  loss: 0.21315779\n",
      "epoch: 146  batch: 21  loss: 0.23920569\n",
      "epoch: 146  batch: 22  loss: 0.05141273\n",
      "epoch: 146  batch: 23  loss: 0.03393367\n",
      "epoch: 146  batch: 24  loss: 0.06404047\n",
      "epoch: 146  batch: 25  loss: 0.07140861\n",
      "epoch: 146  batch: 26  loss: 0.01839125\n",
      "epoch: 146  batch: 27  loss: 0.02458297\n",
      "epoch: 146  batch: 28  loss: 0.01175275\n",
      "epoch: 146  batch: 29  loss: 0.01453990\n",
      "epoch: 146  batch: 30  loss: 0.01547038\n",
      "epoch: 146  batch: 31  loss: 0.02064952\n",
      "epoch: 146  batch: 32  loss: 0.01096981\n",
      "epoch: 146  batch: 33  loss: 0.01004446\n",
      "epoch: 146  batch: 34  loss: 0.09253111\n",
      "epoch: 146  batch: 35  loss: 0.12242356\n",
      "epoch: 146  batch: 36  loss: 0.09815682\n",
      "epoch: 146  batch: 37  loss: 0.03373424\n",
      "epoch: 146  batch: 38  loss: 0.03237352\n",
      "epoch: 146  batch: 39  loss: 0.10490651\n",
      "epoch: 146  batch: 40  loss: 0.07670546\n",
      "epoch: 146  batch: 41  loss: 0.14439246\n",
      "epoch: 146  batch: 42  loss: 0.06096229\n",
      "epoch: 146  batch: 43  loss: 0.07603446\n",
      "epoch: 146  batch: 44  loss: 0.09910503\n",
      "epoch: 146  batch: 45  loss: 0.11138643\n",
      "epoch: 146  batch: 46  loss: 0.06349194\n",
      "epoch: 146  batch: 47  loss: 0.06140014\n",
      "epoch: 146  batch: 48  loss: 0.09215239\n",
      "epoch: 146  batch: 49  loss: 0.14896247\n",
      "epoch: 146  batch: 50  loss: 0.06344248\n",
      "epoch: 146  batch: 51  loss: 0.08328779\n",
      "epoch: 146  batch: 52  loss: 0.06041008\n",
      "epoch: 146  batch: 53  loss: 0.05318873\n",
      "epoch: 146  batch: 54  loss: 0.30040941\n",
      "epoch: 146  batch: 55  loss: 0.18132469\n",
      "epoch: 146  batch: 56  loss: 0.07373990\n",
      "epoch: 146  batch: 57  loss: 0.03944862\n",
      "epoch: 146  batch: 58  loss: 0.08026750\n",
      "epoch: 146  batch: 59  loss: 0.08023617\n",
      "epoch: 146  batch: 60  loss: 0.02139500\n",
      "epoch: 146  batch: 61  loss: 0.09285073\n",
      "epoch: 146  batch: 62  loss: 0.02928988\n",
      "epoch: 146  batch: 63  loss: 0.01721474\n",
      "epoch: 146  batch: 64  loss: 0.01760822\n",
      "epoch: 146  batch: 65  loss: 0.03294025\n",
      "epoch: 146  batch: 66  loss: 0.03403321\n",
      "epoch: 146  batch: 67  loss: 0.03005386\n",
      "epoch: 146  batch: 68  loss: 0.04663298\n",
      "epoch: 147  batch: 1  loss: 0.11293533\n",
      "epoch: 147  batch: 2  loss: 0.04870120\n",
      "epoch: 147  batch: 3  loss: 0.02999793\n",
      "epoch: 147  batch: 4  loss: 0.03656025\n",
      "epoch: 147  batch: 5  loss: 0.07603665\n",
      "epoch: 147  batch: 6  loss: 0.06441947\n",
      "epoch: 147  batch: 7  loss: 0.15894389\n",
      "epoch: 147  batch: 8  loss: 0.05251981\n",
      "epoch: 147  batch: 9  loss: 0.05463857\n",
      "epoch: 147  batch: 10  loss: 0.10350761\n",
      "epoch: 147  batch: 11  loss: 0.14214480\n",
      "epoch: 147  batch: 12  loss: 0.05555264\n",
      "epoch: 147  batch: 13  loss: 0.03897766\n",
      "epoch: 147  batch: 14  loss: 0.12014197\n",
      "epoch: 147  batch: 15  loss: 0.13417096\n",
      "epoch: 147  batch: 16  loss: 0.03142803\n",
      "epoch: 147  batch: 17  loss: 0.03766793\n",
      "epoch: 147  batch: 18  loss: 0.04227438\n",
      "epoch: 147  batch: 19  loss: 0.04324691\n",
      "epoch: 147  batch: 20  loss: 0.21206312\n",
      "epoch: 147  batch: 21  loss: 0.23943901\n",
      "epoch: 147  batch: 22  loss: 0.05099655\n",
      "epoch: 147  batch: 23  loss: 0.03470661\n",
      "epoch: 147  batch: 24  loss: 0.06336126\n",
      "epoch: 147  batch: 25  loss: 0.07202987\n",
      "epoch: 147  batch: 26  loss: 0.02086924\n",
      "epoch: 147  batch: 27  loss: 0.02420268\n",
      "epoch: 147  batch: 28  loss: 0.01201131\n",
      "epoch: 147  batch: 29  loss: 0.01499130\n",
      "epoch: 147  batch: 30  loss: 0.01885751\n",
      "epoch: 147  batch: 31  loss: 0.01974945\n",
      "epoch: 147  batch: 32  loss: 0.01107975\n",
      "epoch: 147  batch: 33  loss: 0.00959124\n",
      "epoch: 147  batch: 34  loss: 0.09643521\n",
      "epoch: 147  batch: 35  loss: 0.12124299\n",
      "epoch: 147  batch: 36  loss: 0.09918290\n",
      "epoch: 147  batch: 37  loss: 0.03378064\n",
      "epoch: 147  batch: 38  loss: 0.03347950\n",
      "epoch: 147  batch: 39  loss: 0.10316218\n",
      "epoch: 147  batch: 40  loss: 0.07805335\n",
      "epoch: 147  batch: 41  loss: 0.14359979\n",
      "epoch: 147  batch: 42  loss: 0.06112579\n",
      "epoch: 147  batch: 43  loss: 0.07440191\n",
      "epoch: 147  batch: 44  loss: 0.09919298\n",
      "epoch: 147  batch: 45  loss: 0.10733153\n",
      "epoch: 147  batch: 46  loss: 0.06335189\n",
      "epoch: 147  batch: 47  loss: 0.06136608\n",
      "epoch: 147  batch: 48  loss: 0.09303551\n",
      "epoch: 147  batch: 49  loss: 0.14935561\n",
      "epoch: 147  batch: 50  loss: 0.06228392\n",
      "epoch: 147  batch: 51  loss: 0.08335572\n",
      "epoch: 147  batch: 52  loss: 0.06051639\n",
      "epoch: 147  batch: 53  loss: 0.05196495\n",
      "epoch: 147  batch: 54  loss: 0.30025584\n",
      "epoch: 147  batch: 55  loss: 0.18376002\n",
      "epoch: 147  batch: 56  loss: 0.07359339\n",
      "epoch: 147  batch: 57  loss: 0.03995929\n",
      "epoch: 147  batch: 58  loss: 0.07933756\n",
      "epoch: 147  batch: 59  loss: 0.10012630\n",
      "epoch: 147  batch: 60  loss: 0.02162344\n",
      "epoch: 147  batch: 61  loss: 0.09040484\n",
      "epoch: 147  batch: 62  loss: 0.02855688\n",
      "epoch: 147  batch: 63  loss: 0.01717428\n",
      "epoch: 147  batch: 64  loss: 0.01868639\n",
      "epoch: 147  batch: 65  loss: 0.03232791\n",
      "epoch: 147  batch: 66  loss: 0.03418078\n",
      "epoch: 147  batch: 67  loss: 0.03141066\n",
      "epoch: 147  batch: 68  loss: 0.04613983\n",
      "epoch: 148  batch: 1  loss: 0.11299966\n",
      "epoch: 148  batch: 2  loss: 0.04263797\n",
      "epoch: 148  batch: 3  loss: 0.02959936\n",
      "epoch: 148  batch: 4  loss: 0.02981309\n",
      "epoch: 148  batch: 5  loss: 0.07457791\n",
      "epoch: 148  batch: 6  loss: 0.06351481\n",
      "epoch: 148  batch: 7  loss: 0.15757149\n",
      "epoch: 148  batch: 8  loss: 0.05201094\n",
      "epoch: 148  batch: 9  loss: 0.05392717\n",
      "epoch: 148  batch: 10  loss: 0.09880757\n",
      "epoch: 148  batch: 11  loss: 0.14139771\n",
      "epoch: 148  batch: 12  loss: 0.05287018\n",
      "epoch: 148  batch: 13  loss: 0.03866643\n",
      "epoch: 148  batch: 14  loss: 0.12177555\n",
      "epoch: 148  batch: 15  loss: 0.13513169\n",
      "epoch: 148  batch: 16  loss: 0.03280096\n",
      "epoch: 148  batch: 17  loss: 0.03732619\n",
      "epoch: 148  batch: 18  loss: 0.04244266\n",
      "epoch: 148  batch: 19  loss: 0.04270345\n",
      "epoch: 148  batch: 20  loss: 0.20892839\n",
      "epoch: 148  batch: 21  loss: 0.23504508\n",
      "epoch: 148  batch: 22  loss: 0.05083586\n",
      "epoch: 148  batch: 23  loss: 0.03335199\n",
      "epoch: 148  batch: 24  loss: 0.06306116\n",
      "epoch: 148  batch: 25  loss: 0.07269890\n",
      "epoch: 148  batch: 26  loss: 0.01873737\n",
      "epoch: 148  batch: 27  loss: 0.02338257\n",
      "epoch: 148  batch: 28  loss: 0.01158841\n",
      "epoch: 148  batch: 29  loss: 0.01462218\n",
      "epoch: 148  batch: 30  loss: 0.01571962\n",
      "epoch: 148  batch: 31  loss: 0.01985022\n",
      "epoch: 148  batch: 32  loss: 0.01083990\n",
      "epoch: 148  batch: 33  loss: 0.01008328\n",
      "epoch: 148  batch: 34  loss: 0.09208508\n",
      "epoch: 148  batch: 35  loss: 0.12058759\n",
      "epoch: 148  batch: 36  loss: 0.09968832\n",
      "epoch: 148  batch: 37  loss: 0.03316462\n",
      "epoch: 148  batch: 38  loss: 0.03286750\n",
      "epoch: 148  batch: 39  loss: 0.10375328\n",
      "epoch: 148  batch: 40  loss: 0.07681447\n",
      "epoch: 148  batch: 41  loss: 0.14328372\n",
      "epoch: 148  batch: 42  loss: 0.06043377\n",
      "epoch: 148  batch: 43  loss: 0.07442626\n",
      "epoch: 148  batch: 44  loss: 0.09591705\n",
      "epoch: 148  batch: 45  loss: 0.10929541\n",
      "epoch: 148  batch: 46  loss: 0.06200659\n",
      "epoch: 148  batch: 47  loss: 0.06077012\n",
      "epoch: 148  batch: 48  loss: 0.09077227\n",
      "epoch: 148  batch: 49  loss: 0.14930619\n",
      "epoch: 148  batch: 50  loss: 0.06241173\n",
      "epoch: 148  batch: 51  loss: 0.08330178\n",
      "epoch: 148  batch: 52  loss: 0.05821248\n",
      "epoch: 148  batch: 53  loss: 0.05332855\n",
      "epoch: 148  batch: 54  loss: 0.29685089\n",
      "epoch: 148  batch: 55  loss: 0.18453920\n",
      "epoch: 148  batch: 56  loss: 0.07256174\n",
      "epoch: 148  batch: 57  loss: 0.03930906\n",
      "epoch: 148  batch: 58  loss: 0.07866608\n",
      "epoch: 148  batch: 59  loss: 0.06327482\n",
      "epoch: 148  batch: 60  loss: 0.02110086\n",
      "epoch: 148  batch: 61  loss: 0.08680503\n",
      "epoch: 148  batch: 62  loss: 0.02988197\n",
      "epoch: 148  batch: 63  loss: 0.01728727\n",
      "epoch: 148  batch: 64  loss: 0.01701250\n",
      "epoch: 148  batch: 65  loss: 0.03211904\n",
      "epoch: 148  batch: 66  loss: 0.03495449\n",
      "epoch: 148  batch: 67  loss: 0.03004728\n",
      "epoch: 148  batch: 68  loss: 0.04584546\n",
      "epoch: 149  batch: 1  loss: 0.11252748\n",
      "epoch: 149  batch: 2  loss: 0.04494892\n",
      "epoch: 149  batch: 3  loss: 0.02974403\n",
      "epoch: 149  batch: 4  loss: 0.03229713\n",
      "epoch: 149  batch: 5  loss: 0.07393873\n",
      "epoch: 149  batch: 6  loss: 0.06232254\n",
      "epoch: 149  batch: 7  loss: 0.15629166\n",
      "epoch: 149  batch: 8  loss: 0.05180709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149  batch: 9  loss: 0.05251449\n",
      "epoch: 149  batch: 10  loss: 0.09853993\n",
      "epoch: 149  batch: 11  loss: 0.13703151\n",
      "epoch: 149  batch: 12  loss: 0.05260563\n",
      "epoch: 149  batch: 13  loss: 0.03850156\n",
      "epoch: 149  batch: 14  loss: 0.11756836\n",
      "epoch: 149  batch: 15  loss: 0.13610199\n",
      "epoch: 149  batch: 16  loss: 0.03137420\n",
      "epoch: 149  batch: 17  loss: 0.03455815\n",
      "epoch: 149  batch: 18  loss: 0.04246689\n",
      "epoch: 149  batch: 19  loss: 0.04371069\n",
      "epoch: 149  batch: 20  loss: 0.20843197\n",
      "epoch: 149  batch: 21  loss: 0.23466535\n",
      "epoch: 149  batch: 22  loss: 0.05066844\n",
      "epoch: 149  batch: 23  loss: 0.03344502\n",
      "epoch: 149  batch: 24  loss: 0.06259605\n",
      "epoch: 149  batch: 25  loss: 0.07185557\n",
      "epoch: 149  batch: 26  loss: 0.01798258\n",
      "epoch: 149  batch: 27  loss: 0.02297193\n",
      "epoch: 149  batch: 28  loss: 0.01196864\n",
      "epoch: 149  batch: 29  loss: 0.01444709\n",
      "epoch: 149  batch: 30  loss: 0.01596751\n",
      "epoch: 149  batch: 31  loss: 0.01966892\n",
      "epoch: 149  batch: 32  loss: 0.01118476\n",
      "epoch: 149  batch: 33  loss: 0.00946373\n",
      "epoch: 149  batch: 34  loss: 0.09115267\n",
      "epoch: 149  batch: 35  loss: 0.11937000\n",
      "epoch: 149  batch: 36  loss: 0.10051887\n",
      "epoch: 149  batch: 37  loss: 0.03410237\n",
      "epoch: 149  batch: 38  loss: 0.03210805\n",
      "epoch: 149  batch: 39  loss: 0.10183042\n",
      "epoch: 149  batch: 40  loss: 0.07626042\n",
      "epoch: 149  batch: 41  loss: 0.14291662\n",
      "epoch: 149  batch: 42  loss: 0.06023082\n",
      "epoch: 149  batch: 43  loss: 0.07347471\n",
      "epoch: 149  batch: 44  loss: 0.09524799\n",
      "epoch: 149  batch: 45  loss: 0.10542794\n",
      "epoch: 149  batch: 46  loss: 0.06061428\n",
      "epoch: 149  batch: 47  loss: 0.05891071\n",
      "epoch: 149  batch: 48  loss: 0.09003133\n",
      "epoch: 149  batch: 49  loss: 0.14878196\n",
      "epoch: 149  batch: 50  loss: 0.05853125\n",
      "epoch: 149  batch: 51  loss: 0.08330977\n",
      "epoch: 149  batch: 52  loss: 0.05900649\n",
      "epoch: 149  batch: 53  loss: 0.05221858\n",
      "epoch: 149  batch: 54  loss: 0.29545152\n",
      "epoch: 149  batch: 55  loss: 0.17763437\n",
      "epoch: 149  batch: 56  loss: 0.07013924\n",
      "epoch: 149  batch: 57  loss: 0.03969936\n",
      "epoch: 149  batch: 58  loss: 0.07811499\n",
      "epoch: 149  batch: 59  loss: 0.06016988\n",
      "epoch: 149  batch: 60  loss: 0.02089614\n",
      "epoch: 149  batch: 61  loss: 0.08292783\n",
      "epoch: 149  batch: 62  loss: 0.02766628\n",
      "epoch: 149  batch: 63  loss: 0.01687173\n",
      "epoch: 149  batch: 64  loss: 0.01686923\n",
      "epoch: 149  batch: 65  loss: 0.03184847\n",
      "epoch: 149  batch: 66  loss: 0.03378603\n",
      "epoch: 149  batch: 67  loss: 0.02973284\n",
      "epoch: 149  batch: 68  loss: 0.04583615\n",
      "epoch: 150  batch: 1  loss: 0.11005248\n",
      "epoch: 150  batch: 2  loss: 0.04143951\n",
      "epoch: 150  batch: 3  loss: 0.02830939\n",
      "epoch: 150  batch: 4  loss: 0.03156676\n",
      "epoch: 150  batch: 5  loss: 0.07311878\n",
      "epoch: 150  batch: 6  loss: 0.06217840\n",
      "epoch: 150  batch: 7  loss: 0.15485592\n",
      "epoch: 150  batch: 8  loss: 0.05136816\n",
      "epoch: 150  batch: 9  loss: 0.05240019\n",
      "epoch: 150  batch: 10  loss: 0.09698694\n",
      "epoch: 150  batch: 11  loss: 0.13485357\n",
      "epoch: 150  batch: 12  loss: 0.05258293\n",
      "epoch: 150  batch: 13  loss: 0.03800476\n",
      "epoch: 150  batch: 14  loss: 0.11618534\n",
      "epoch: 150  batch: 15  loss: 0.13700308\n",
      "epoch: 150  batch: 16  loss: 0.03047456\n",
      "epoch: 150  batch: 17  loss: 0.03515739\n",
      "epoch: 150  batch: 18  loss: 0.04185868\n",
      "epoch: 150  batch: 19  loss: 0.04306636\n",
      "epoch: 150  batch: 20  loss: 0.20622969\n",
      "epoch: 150  batch: 21  loss: 0.23223193\n",
      "epoch: 150  batch: 22  loss: 0.05046402\n",
      "epoch: 150  batch: 23  loss: 0.03319444\n",
      "epoch: 150  batch: 24  loss: 0.06126948\n",
      "epoch: 150  batch: 25  loss: 0.07216829\n",
      "epoch: 150  batch: 26  loss: 0.01766390\n",
      "epoch: 150  batch: 27  loss: 0.02215626\n",
      "epoch: 150  batch: 28  loss: 0.01173952\n",
      "epoch: 150  batch: 29  loss: 0.01458598\n",
      "epoch: 150  batch: 30  loss: 0.01591561\n",
      "epoch: 150  batch: 31  loss: 0.01885035\n",
      "epoch: 150  batch: 32  loss: 0.01100290\n",
      "epoch: 150  batch: 33  loss: 0.00996333\n",
      "epoch: 150  batch: 34  loss: 0.09099940\n",
      "epoch: 150  batch: 35  loss: 0.11839212\n",
      "epoch: 150  batch: 36  loss: 0.10219494\n",
      "epoch: 150  batch: 37  loss: 0.03223336\n",
      "epoch: 150  batch: 38  loss: 0.03295723\n",
      "epoch: 150  batch: 39  loss: 0.10132377\n",
      "epoch: 150  batch: 40  loss: 0.07691777\n",
      "epoch: 150  batch: 41  loss: 0.14254442\n",
      "epoch: 150  batch: 42  loss: 0.06000767\n",
      "epoch: 150  batch: 43  loss: 0.07245573\n",
      "epoch: 150  batch: 44  loss: 0.09203739\n",
      "epoch: 150  batch: 45  loss: 0.10371649\n",
      "epoch: 150  batch: 46  loss: 0.05923179\n",
      "epoch: 150  batch: 47  loss: 0.05878817\n",
      "epoch: 150  batch: 48  loss: 0.08842759\n",
      "epoch: 150  batch: 49  loss: 0.14889853\n",
      "epoch: 150  batch: 50  loss: 0.05769314\n",
      "epoch: 150  batch: 51  loss: 0.08265936\n",
      "epoch: 150  batch: 52  loss: 0.05776572\n",
      "epoch: 150  batch: 53  loss: 0.05206336\n",
      "epoch: 150  batch: 54  loss: 0.29302266\n",
      "epoch: 150  batch: 55  loss: 0.17789805\n",
      "epoch: 150  batch: 56  loss: 0.06943024\n",
      "epoch: 150  batch: 57  loss: 0.03968037\n",
      "epoch: 150  batch: 58  loss: 0.07792831\n",
      "epoch: 150  batch: 59  loss: 0.05859768\n",
      "epoch: 150  batch: 60  loss: 0.02095145\n",
      "epoch: 150  batch: 61  loss: 0.08221819\n",
      "epoch: 150  batch: 62  loss: 0.02709562\n",
      "epoch: 150  batch: 63  loss: 0.01709599\n",
      "epoch: 150  batch: 64  loss: 0.01707556\n",
      "epoch: 150  batch: 65  loss: 0.03151885\n",
      "epoch: 150  batch: 66  loss: 0.03402966\n",
      "epoch: 150  batch: 67  loss: 0.03018491\n",
      "epoch: 150  batch: 68  loss: 0.04556703\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "                \n",
    "        # Apply the model\n",
    "        y_pred = Model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "#         torch.cuda.empty_cache()\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%1 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Run the validationing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "            # Apply the model\n",
    "            \n",
    "            X_validation = X_validation.to(device)\n",
    "            y_validation = y_validation.to(device)\n",
    "            \n",
    "            y_val = Model(X_validation)\n",
    "    loss = criterion(y_val, y_validation)\n",
    "    validation_losses.append(loss.cpu().detach().numpy())\n",
    "#     validation_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7796f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:16:08.885595Z",
     "start_time": "2023-01-17T23:16:08.598603Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(validation_losses, label='validation loss')\n",
    "plt.legend();\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fce3df",
   "metadata": {},
   "source": [
    "# Cheking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb8d7322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:08.727419Z",
     "start_time": "2023-02-03T22:26:08.721335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(color_im)\n",
    "    depth_raw = o3d.geometry.Image(depth_im)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "#     PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,0,1]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d61af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e456c1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:10.035127Z",
     "start_time": "2023-02-03T22:26:10.031379Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_resize = transforms.Resize(480, interpolation=transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a78878d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:10.867799Z",
     "start_time": "2023-02-03T22:26:10.732575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AoRNet(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('Modele/Small2_RN_150Epoch'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c474164f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:44.576874Z",
     "start_time": "2023-02-03T22:26:35.417369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.06647,     -0.52906,      1.70012], [     0.07016,      0.51426,      1.80695]]\n",
      "REAL:\n",
      "[[     0.45473,     -0.58426,      1.51100], [     0.45519,      0.72499,      1.73800]]\n",
      "DIFFERENCE:\n",
      "[[     0.38826,      0.05520,      0.18912], [     0.38503,      0.21073,      0.06895]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.09591,     -0.51812,      1.74780], [     0.08962,      0.51914,      1.86796]]\n",
      "REAL:\n",
      "[[     0.45473,     -0.58426,      1.51100], [     0.45519,      0.72499,      1.73800]]\n",
      "DIFFERENCE:\n",
      "[[     0.35882,      0.06614,      0.23680], [     0.36557,      0.20585,      0.12996]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.08353,     -0.52084,      1.74195], [     0.07839,      0.52309,      1.86012]]\n",
      "REAL:\n",
      "[[     0.45473,     -0.58426,      1.51100], [     0.45519,      0.72499,      1.73800]]\n",
      "DIFFERENCE:\n",
      "[[     0.37120,      0.06342,      0.23095], [     0.37680,      0.20191,      0.12212]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.04966,     -0.50645,      1.56594], [     0.05553,      0.49469,      1.65743]]\n",
      "REAL:\n",
      "[[     0.35956,     -0.54271,      1.41400], [     0.43229,      0.54343,      1.44100]]\n",
      "DIFFERENCE:\n",
      "[[     0.30990,      0.03625,      0.15194], [     0.37675,      0.04873,      0.21643]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.08322,     -0.52415,      1.67486], [     0.08852,      0.53193,      1.81559]]\n",
      "REAL:\n",
      "[[     0.35956,     -0.54271,      1.41400], [     0.43229,      0.54343,      1.44100]]\n",
      "DIFFERENCE:\n",
      "[[     0.27634,      0.01856,      0.26086], [     0.34377,      0.01150,      0.37459]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.08149,     -0.49465,      1.61329], [     0.08623,      0.51882,      1.70246]]\n",
      "REAL:\n",
      "[[     0.35956,     -0.54271,      1.41400], [     0.43229,      0.54343,      1.44100]]\n",
      "DIFFERENCE:\n",
      "[[     0.27807,      0.04806,      0.19929], [     0.34605,      0.02461,      0.26146]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.01721,     -0.58785,      1.80193], [     0.00041,      0.64817,      1.88512]]\n",
      "REAL:\n",
      "[[    -0.01913,     -0.70258,      1.82600], [    -0.06973,      0.86918,      2.61500]]\n",
      "DIFFERENCE:\n",
      "[[     0.03634,      0.11473,      0.02407], [     0.07014,      0.22100,      0.72988]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.05162,     -0.60200,      1.85837], [     0.03625,      0.65818,      1.97113]]\n",
      "REAL:\n",
      "[[    -0.01913,     -0.70258,      1.82600], [    -0.06973,      0.86918,      2.61500]]\n",
      "DIFFERENCE:\n",
      "[[     0.07075,      0.10058,      0.03237], [     0.10599,      0.21099,      0.64387]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.07526,     -0.58308,      1.89800], [     0.06695,      0.65563,      1.99552]]\n",
      "REAL:\n",
      "[[    -0.01913,     -0.70258,      1.82600], [    -0.06973,      0.86918,      2.61500]]\n",
      "DIFFERENCE:\n",
      "[[     0.09439,      0.11950,      0.07200], [     0.13668,      0.21355,      0.61948]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.13665,     -0.45117,      1.89671], [     0.15051,      0.62672,      1.92423]]\n",
      "REAL:\n",
      "[[    -0.16107,     -0.26375,      1.13500], [    -0.17242,      0.38238,      1.36100]]\n",
      "DIFFERENCE:\n",
      "[[     0.29772,      0.18742,      0.76171], [     0.32293,      0.24434,      0.56323]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.09507,     -0.52082,      1.82148], [     0.09516,      0.59734,      1.93302]]\n",
      "REAL:\n",
      "[[    -0.16107,     -0.26375,      1.13500], [    -0.17242,      0.38238,      1.36100]]\n",
      "DIFFERENCE:\n",
      "[[     0.25614,      0.25707,      0.68648], [     0.26758,      0.21496,      0.57202]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.08783,     -0.52320,      1.83157], [     0.09160,      0.55105,      1.96911]]\n",
      "REAL:\n",
      "[[    -0.16107,     -0.26375,      1.13500], [    -0.17242,      0.38238,      1.36100]]\n",
      "DIFFERENCE:\n",
      "[[     0.24890,      0.25945,      0.69657], [     0.26403,      0.16867,      0.60811]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m PREDICTED \u001b[38;5;241m=\u001b[39m [[y_val[j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()],\n\u001b[1;32m     43\u001b[0m              [y_val[j][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]]\n\u001b[1;32m     44\u001b[0m REAL \u001b[38;5;241m=\u001b[39m [[y_validation[j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()],\n\u001b[1;32m     45\u001b[0m         [y_validation[j][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]]\n\u001b[0;32m---> 46\u001b[0m \u001b[43mdraw_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mREAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPREDICTED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> BATCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <-- | --> ROW: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [26], line 32\u001b[0m, in \u001b[0;36mdraw_arrow\u001b[0;34m(pcd, points_real, points_extimated)\u001b[0m\n\u001b[1;32m     26\u001b[0m line_set \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mLineSet(\n\u001b[1;32m     27\u001b[0m     points\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector3dVector(points),\n\u001b[1;32m     28\u001b[0m     lines\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector2iVector(lines),\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m line_set\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector3dVector(colors)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mline_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "diff_X1 = []\n",
    "diff_Y1 = []\n",
    "diff_Z1 = []\n",
    "diff_X2 = []\n",
    "diff_Y2 = []\n",
    "diff_Z2 = []\n",
    "\n",
    "X1 = [] \n",
    "Y1 = [] \n",
    "Z1 = []\n",
    "X2 = []\n",
    "Y2 = []\n",
    "Z2 = [] \n",
    "\n",
    "hX1 = [] \n",
    "hY1 = [] \n",
    "hZ1 = []\n",
    "hX2 = []\n",
    "hY2 = []\n",
    "hZ2 = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "#         Apply the model\n",
    "        \n",
    "        X_validation = X_validation.to(device)\n",
    "        y_validation = y_validation.to(device)\n",
    "        \n",
    "\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = X_invNorm[0].cpu().numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "#             RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "            DEPTH_buff = X_invNorm[1].cpu().numpy()*5500\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_validation[j][0].cpu().numpy(), y_validation[j][1].cpu().numpy(), y_validation[j][2].cpu().numpy()],\n",
    "                    [y_validation[j][3].cpu().numpy(), y_validation[j][4].cpu().numpy(), y_validation[j][5].cpu().numpy()]]\n",
    "            draw_arrow(PC, REAL, PREDICTED)\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            diff_X1.append(diff[j][0])\n",
    "            diff_Y1.append(diff[j][1])\n",
    "            diff_Z1.append(diff[j][2])\n",
    "            diff_X2.append(diff[j][3])\n",
    "            diff_Y2.append(diff[j][4])\n",
    "            diff_Z2.append(diff[j][5])\n",
    "            \n",
    "            X1.append(y_validation[j][0].cpu().numpy())\n",
    "            Y1.append(y_validation[j][1].cpu().numpy())\n",
    "            Z1.append(y_validation[j][2].cpu().numpy())\n",
    "            X2.append(y_validation[j][3].cpu().numpy())\n",
    "            Y2.append(y_validation[j][4].cpu().numpy())\n",
    "            Z2.append(y_validation[j][5].cpu().numpy())\n",
    "\n",
    "            hX1.append(y_val[j][0].cpu().numpy()) \n",
    "            hY1.append(y_val[j][1].cpu().numpy()) \n",
    "            hZ1.append(y_val[j][2].cpu().numpy())\n",
    "            hX2.append(y_val[j][3].cpu().numpy())\n",
    "            hY2.append(y_val[j][4].cpu().numpy())\n",
    "            hZ2.append(y_val[j][5].cpu().numpy()) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80527311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:17.739575Z",
     "start_time": "2023-02-03T22:26:17.737801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(Model.state_dict(), 'Modele/Big2_RN_150Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d673a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:19.025976Z",
     "start_time": "2023-02-03T22:26:18.632887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "fig, axs = plt.subplots(2, 3,figsize=(20,7))\n",
    "axs[0, 0].plot(X1[0:20],'o')\n",
    "axs[0, 0].plot(hX1[0:20],'+r')\n",
    "axs[0, 0].set_title('X_1')\n",
    "axs[0, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[0, 1].plot(Y1[0:20],'o')\n",
    "axs[0, 1].plot(hY1[0:20],'+r')\n",
    "axs[0, 1].set_title('Y_1')\n",
    "\n",
    "axs[0, 2].plot(Z1[0:20],'o')\n",
    "axs[0, 2].plot(hZ1[0:20],'+r')\n",
    "axs[0, 2].set_title('Z_1')\n",
    "\n",
    "axs[1, 0].plot(X2[0:20],'o')\n",
    "axs[1, 0].plot(hX2[0:20],'+r')\n",
    "axs[1, 0].set_title('X_2')\n",
    "axs[1, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[1, 1].plot(Y2[0:20],'o')\n",
    "axs[1, 1].plot(hY2[0:20],'+r')\n",
    "axs[1, 1].set_title('Y_2')\n",
    "axs[1, 1].set(xlabel='Numer zdjęcia')\n",
    "\n",
    "axs[1, 2].plot(Z2[0:20],'o')\n",
    "axs[1, 2].plot(hZ2[0:20],'+r')\n",
    "axs[1, 2].set_title('Z_2')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.legend(['Współrzędne rzeczywiste','Współrzędne esymowne'])\n",
    "\n",
    "plt.show()\n",
    "SAVE_DIR = '/home/el_zlociako/Documents/Praca_inzynierska/CNN/Ploty_do_inz/'\n",
    "# fig.savefig(SAVE_DIR+'Small_REG_test.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db49c8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:26:22.556105Z",
     "start_time": "2023-02-03T22:26:22.552523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27090982, 0.12706468, 0.45283493, 0.27090982, 0.2109709, 0.5147743]\n"
     ]
    }
   ],
   "source": [
    "X1_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y1_MEAN_DIFF = np.mean(diff_Y1)\n",
    "Z1_MEAN_DIFF = np.mean(diff_Z1)\n",
    "X2_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y2_MEAN_DIFF = np.mean(diff_Y2)\n",
    "Z2_MEAN_DIFF = np.mean(diff_Z2)\n",
    "\n",
    "MEAN_ERR = [X1_MEAN_DIFF, Y1_MEAN_DIFF, Z1_MEAN_DIFF, X2_MEAN_DIFF, Y2_MEAN_DIFF, Z2_MEAN_DIFF]\n",
    "print(MEAN_ERR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351666d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28057c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b361d4100cabf439e872d27edcfc9e968620b5cc1a2991a8793a2beed62efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
