{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1329c18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:32.464439Z",
     "start_time": "2023-01-17T17:18:29.413800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import open3d as o3d\n",
    "\n",
    "from Libraries.dataloader import DataLoader as DL\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6dfab",
   "metadata": {},
   "source": [
    "#  Inicjalizowane danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e02fc2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:32.468718Z",
     "start_time": "2023-01-17T17:18:32.466631Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68719e44",
   "metadata": {},
   "source": [
    "# Załadowanie danych\n",
    "Ładujemy dane do zmiennych a następnie odpowiednio przekształcamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376f4b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:32.481545Z",
     "start_time": "2023-01-17T17:18:32.469704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, p=0.5, mean=[0.0, 0.5], std=[1.0, 1.0]):\n",
    "        self.p    = p\n",
    "        self.std  = np.random.uniform(std[0],std[1])\n",
    "        self.mean = np.random.uniform(mean[0],mean[1])\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        if random.random() < self.p:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            return tensor \n",
    "\n",
    "\n",
    "DataAug = transforms.Compose([\n",
    "    transforms.ColorJitter(\n",
    "        brightness=[0.5,1.5],\n",
    "        contrast=[0.5, 1.5],\n",
    "        saturation=[0.5, 1.5],\n",
    "        hue=[-0.1,0.1],\n",
    "    ),\n",
    "    transforms.GaussianBlur(\n",
    "        kernel_size=3,\n",
    "        sigma=(0.1, 9.0)\n",
    "    ),\n",
    "#     transforms.RandomErasing(\n",
    "#         p=0.1,\n",
    "#         scale=(0.01, 0.1),\n",
    "#         ratio=(0.01, 3.3),\n",
    "#         value=0,\n",
    "#     ),\n",
    "    GaussianNoise(\n",
    "        p=0.2,\n",
    "        mean=[0.0, 0.1],\n",
    "        std=[0.01, 0.3]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b2e63e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:32.493987Z",
     "start_time": "2023-01-17T17:18:32.482872Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResizeData = transforms.Resize([256, 320], interpolation=transforms.InterpolationMode.NEAREST)\n",
    "# RGBtoGRAY = transforms.Grayscale(num_output_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e31d631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:32.506468Z",
     "start_time": "2023-01-17T17:18:32.496137Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Set root path\n",
    "# DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "\n",
    "# df = pd.read_csv(f'{DATASET_ROOTDIR}files/data.csv') \n",
    "# df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "# df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "# df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]\n",
    "\n",
    "# RGBimg_begin = load_from_csv(DATASET_ROOTDIR, df_INPUT_RGB, 'rgb' ,0)\n",
    "# DEPTHimg_begin = load_from_csv(DATASET_ROOTDIR, df_INPUT_DEPTH, 'depth',0)\n",
    "# DEPTHimg_end = load_from_csv(DATASET_ROOTDIR, df_INPUT_DEPTH, 'depth', 1)\n",
    "\n",
    "# # Taking first rgb image\n",
    "# rgb_in = torch.IntTensor(RGBimg_begin.transpose(0,3,1,2))\n",
    "# gray_in = RGBtoGRAY(rgb_in).div(255)\n",
    "# # plt.imshow(gray_in[0].numpy().transpose(1,2,0),cmap='gray')\n",
    "\n",
    "# # Taking depth beginning state of the movement\n",
    "# depthBeg_in = NormImage(DEPTHimg_begin,5500,reshape=True)\n",
    "\n",
    "# # Taking depth end state of the movement\n",
    "# depthEnd_in = NormImage(DEPTHimg_end,5500,reshape=True)\n",
    "\n",
    "# # Taking depth difference between movements\n",
    "# depthDiff_in = NormImage(abs(DEPTHimg_begin - DEPTHimg_end),5500,reshape=True)\n",
    "\n",
    "# # Taking outputs\n",
    "# axis_out = df_OUTPUT.values\n",
    "# axis_out = torch.Tensor(axis_out)\n",
    "\n",
    "# RGBD_input = ResizeData(torch.cat((gray_in, depthBeg_in, depthDiff_in),axis=1))\n",
    "\n",
    "\n",
    "# print(RGBD_input.shape)\n",
    "# # RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823deffa",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025b1d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:42.613606Z",
     "start_time": "2023-01-17T17:18:33.051987Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "A_RGBD_input,A_axis_out = dl.load(DATASET_ROOTDIR, 'files_ArUco/data_ArUco.csv', 'R')\n",
    "\n",
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "B_RGBD_input,B_axis_out = dl.load(DATASET_ROOTDIR, 'files/data.csv', 'R')\n",
    "\n",
    "RGBD_input = torch.cat((A_RGBD_input, B_RGBD_input),axis=0)\n",
    "axis_out = torch.cat((A_axis_out, B_axis_out),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d92a",
   "metadata": {},
   "source": [
    "# RGB + D \n",
    "Na wejście do modelu zostanie podany tensor zawieający kombinację RGB + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2280a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:42.687191Z",
     "start_time": "2023-01-17T17:18:42.615274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([435, 3, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(RGBD_input, axis_out, test_size=0.2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23db3ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:45.032137Z",
     "start_time": "2023-01-17T17:18:42.688333Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_aug = X_train.clone()\n",
    "\n",
    "for i in range(X_train_aug.shape[0]):\n",
    "     X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "y_train = torch.cat((y_train, y_train),axis=0)\n",
    "X_train = torch.cat((X_train, X_train_aug),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb1b812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:45.035829Z",
     "start_time": "2023-01-17T17:18:45.033794Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_trainDataset = TensorDataset(X_train, y_train)\n",
    "AoRD_validationDataset = TensorDataset(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:45.053314Z",
     "start_time": "2023-01-17T17:18:45.037003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AoRD_trainDataset, batch_size=10, shuffle=False)\n",
    "validation_loader = DataLoader(AoRD_validationDataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159076ba",
   "metadata": {},
   "source": [
    "# Wyciąganie pojedyńczego elementu z batcha\n",
    "Można zrobić to na kilka sposobów, ale ten jest najszybszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab99ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:45.068471Z",
     "start_time": "2023-01-17T17:18:45.054945Z"
    }
   },
   "outputs": [],
   "source": [
    "# for b, (X_train, y_train) in enumerate(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "# Stworzenie modelu\n",
    "Nazwałem model AoRNet od angielsiego **A**xis **o**f **R**rotation oraz od nazwy modelu matki Res**Net**`u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0db1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:45.084558Z",
     "start_time": "2023-01-17T17:18:45.069577Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=3, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a67d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:46.946081Z",
     "start_time": "2023-01-17T17:18:45.085831Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = AoRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b0f079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T16:26:18.007917Z",
     "start_time": "2023-01-17T16:26:18.004483Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=5, factor=0.1, min_lr=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad777bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T11:01:20.150764Z",
     "start_time": "2023-01-16T10:29:58.399199Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch: 1  loss: 0.89206183\n",
      "epoch:  1  batch: 2  loss: 2.50206041\n",
      "epoch:  1  batch: 3  loss: 1.35267854\n",
      "epoch:  1  batch: 4  loss: 0.73345989\n",
      "epoch:  1  batch: 5  loss: 0.76032108\n",
      "epoch:  1  batch: 6  loss: 1.16733372\n",
      "epoch:  1  batch: 7  loss: 1.11666346\n",
      "epoch:  1  batch: 8  loss: 0.64967144\n",
      "epoch:  1  batch: 9  loss: 0.51359057\n",
      "epoch:  1  batch: 10  loss: 0.35968602\n",
      "epoch:  1  batch: 11  loss: 0.47364917\n",
      "epoch:  1  batch: 12  loss: 0.52930999\n",
      "epoch:  1  batch: 13  loss: 0.47500324\n",
      "epoch:  1  batch: 14  loss: 0.45735121\n",
      "epoch:  1  batch: 15  loss: 0.50384599\n",
      "epoch:  1  batch: 16  loss: 0.41072866\n",
      "epoch:  1  batch: 17  loss: 0.32447702\n",
      "epoch:  1  batch: 18  loss: 0.41056895\n",
      "epoch:  1  batch: 19  loss: 0.41391164\n",
      "epoch:  1  batch: 20  loss: 0.41957346\n",
      "epoch:  1  batch: 21  loss: 0.31908914\n",
      "epoch:  1  batch: 22  loss: 0.32444525\n",
      "epoch:  1  batch: 23  loss: 0.29454079\n",
      "epoch:  1  batch: 24  loss: 0.39096555\n",
      "epoch:  1  batch: 25  loss: 0.29617530\n",
      "epoch:  1  batch: 26  loss: 0.34416670\n",
      "epoch:  1  batch: 27  loss: 0.33215678\n",
      "epoch:  1  batch: 28  loss: 0.32821706\n",
      "epoch:  1  batch: 29  loss: 0.33295023\n",
      "epoch:  1  batch: 30  loss: 0.36852297\n",
      "epoch:  1  batch: 31  loss: 0.23681185\n",
      "epoch:  1  batch: 32  loss: 0.31009981\n",
      "epoch:  1  batch: 33  loss: 0.31804922\n",
      "epoch:  1  batch: 34  loss: 0.33416158\n",
      "epoch:  1  batch: 35  loss: 0.39422497\n",
      "epoch:  1  batch: 36  loss: 0.28251198\n",
      "epoch:  1  batch: 37  loss: 0.38539770\n",
      "epoch:  1  batch: 38  loss: 0.72345215\n",
      "epoch:  1  batch: 39  loss: 0.65655041\n",
      "epoch:  1  batch: 40  loss: 0.50273532\n",
      "epoch:  1  batch: 41  loss: 0.42773235\n",
      "epoch:  1  batch: 42  loss: 0.36938760\n",
      "epoch:  1  batch: 43  loss: 0.51120126\n",
      "epoch:  1  batch: 44  loss: 0.51162833\n",
      "epoch:  1  batch: 45  loss: 0.40020436\n",
      "epoch:  1  batch: 46  loss: 0.40642855\n",
      "epoch:  1  batch: 47  loss: 0.49371192\n",
      "epoch:  1  batch: 48  loss: 0.37024361\n",
      "epoch:  1  batch: 49  loss: 0.38078299\n",
      "epoch:  1  batch: 50  loss: 0.28986132\n",
      "epoch:  1  batch: 51  loss: 0.38496149\n",
      "epoch:  1  batch: 52  loss: 0.35743716\n",
      "epoch:  1  batch: 53  loss: 0.30024368\n",
      "epoch:  1  batch: 54  loss: 0.24898148\n",
      "epoch:  1  batch: 55  loss: 0.42380470\n",
      "epoch:  1  batch: 56  loss: 0.38885927\n",
      "epoch:  1  batch: 57  loss: 0.36800122\n",
      "epoch:  1  batch: 58  loss: 0.33766323\n",
      "epoch:  1  batch: 59  loss: 0.28626519\n",
      "epoch:  1  batch: 60  loss: 0.35360020\n",
      "epoch:  1  batch: 61  loss: 0.40100569\n",
      "epoch:  1  batch: 62  loss: 0.38553521\n",
      "epoch:  1  batch: 63  loss: 0.35084566\n",
      "epoch:  1  batch: 64  loss: 0.44616348\n",
      "epoch:  1  batch: 65  loss: 0.28200212\n",
      "epoch:  1  batch: 66  loss: 0.35427120\n",
      "epoch:  1  batch: 67  loss: 0.34660015\n",
      "epoch:  1  batch: 68  loss: 0.34762993\n",
      "epoch:  1  batch: 69  loss: 0.24710310\n",
      "epoch:  1  batch: 70  loss: 0.25060245\n",
      "epoch:  1  batch: 71  loss: 0.40429085\n",
      "epoch:  1  batch: 72  loss: 0.33357325\n",
      "epoch:  1  batch: 73  loss: 0.35561183\n",
      "epoch:  1  batch: 74  loss: 0.38872471\n",
      "epoch:  1  batch: 75  loss: 0.43684539\n",
      "epoch:  1  batch: 76  loss: 0.32190749\n",
      "epoch:  1  batch: 77  loss: 0.33939624\n",
      "epoch:  1  batch: 78  loss: 0.38901731\n",
      "epoch:  1  batch: 79  loss: 0.41929895\n",
      "epoch:  1  batch: 80  loss: 0.34655178\n",
      "epoch:  1  batch: 81  loss: 0.37622169\n",
      "epoch:  1  batch: 82  loss: 0.25293386\n",
      "epoch:  1  batch: 83  loss: 0.40640283\n",
      "epoch:  1  batch: 84  loss: 0.26858884\n",
      "epoch:  1  batch: 85  loss: 0.30926377\n",
      "epoch:  1  batch: 86  loss: 0.36779627\n",
      "epoch:  1  batch: 87  loss: 0.36968017\n",
      "epoch:  2  batch: 1  loss: 0.47256401\n",
      "epoch:  2  batch: 2  loss: 0.39641485\n",
      "epoch:  2  batch: 3  loss: 0.36344686\n",
      "epoch:  2  batch: 4  loss: 0.32509673\n",
      "epoch:  2  batch: 5  loss: 0.33336225\n",
      "epoch:  2  batch: 6  loss: 0.38083443\n",
      "epoch:  2  batch: 7  loss: 0.37858704\n",
      "epoch:  2  batch: 8  loss: 0.30010512\n",
      "epoch:  2  batch: 9  loss: 0.46371844\n",
      "epoch:  2  batch: 10  loss: 0.34698653\n",
      "epoch:  2  batch: 11  loss: 0.24666825\n",
      "epoch:  2  batch: 12  loss: 0.44954371\n",
      "epoch:  2  batch: 13  loss: 0.35173401\n",
      "epoch:  2  batch: 14  loss: 0.39922437\n",
      "epoch:  2  batch: 15  loss: 0.36174649\n",
      "epoch:  2  batch: 16  loss: 0.38462433\n",
      "epoch:  2  batch: 17  loss: 0.29484266\n",
      "epoch:  2  batch: 18  loss: 0.29429153\n",
      "epoch:  2  batch: 19  loss: 0.29616654\n",
      "epoch:  2  batch: 20  loss: 0.33227763\n",
      "epoch:  2  batch: 21  loss: 0.19357118\n",
      "epoch:  2  batch: 22  loss: 0.30245116\n",
      "epoch:  2  batch: 23  loss: 0.40361425\n",
      "epoch:  2  batch: 24  loss: 0.35795099\n",
      "epoch:  2  batch: 25  loss: 0.46989158\n",
      "epoch:  2  batch: 26  loss: 0.29565132\n",
      "epoch:  2  batch: 27  loss: 0.23963012\n",
      "epoch:  2  batch: 28  loss: 0.45013881\n",
      "epoch:  2  batch: 29  loss: 0.42608970\n",
      "epoch:  2  batch: 30  loss: 0.37807548\n",
      "epoch:  2  batch: 31  loss: 0.42114276\n",
      "epoch:  2  batch: 32  loss: 0.28390709\n",
      "epoch:  2  batch: 33  loss: 0.40387619\n",
      "epoch:  2  batch: 34  loss: 0.35439435\n",
      "epoch:  2  batch: 35  loss: 0.34819090\n",
      "epoch:  2  batch: 36  loss: 0.44672516\n",
      "epoch:  2  batch: 37  loss: 0.35901043\n",
      "epoch:  2  batch: 38  loss: 0.32452789\n",
      "epoch:  2  batch: 39  loss: 0.29043403\n",
      "epoch:  2  batch: 40  loss: 0.33524057\n",
      "epoch:  2  batch: 41  loss: 0.27881986\n",
      "epoch:  2  batch: 42  loss: 0.57966757\n",
      "epoch:  2  batch: 43  loss: 0.35717258\n",
      "epoch:  2  batch: 44  loss: 0.42105454\n",
      "epoch:  2  batch: 45  loss: 0.34641218\n",
      "epoch:  2  batch: 46  loss: 0.33037475\n",
      "epoch:  2  batch: 47  loss: 0.24828273\n",
      "epoch:  2  batch: 48  loss: 0.54622972\n",
      "epoch:  2  batch: 49  loss: 0.37773898\n",
      "epoch:  2  batch: 50  loss: 0.43120998\n",
      "epoch:  2  batch: 51  loss: 0.28165513\n",
      "epoch:  2  batch: 52  loss: 0.44381908\n",
      "epoch:  2  batch: 53  loss: 0.46757859\n",
      "epoch:  2  batch: 54  loss: 0.32236260\n",
      "epoch:  2  batch: 55  loss: 0.30774942\n",
      "epoch:  2  batch: 56  loss: 0.34669903\n",
      "epoch:  2  batch: 57  loss: 0.35345256\n",
      "epoch:  2  batch: 58  loss: 0.41140971\n",
      "epoch:  2  batch: 59  loss: 0.43779075\n",
      "epoch:  2  batch: 60  loss: 0.31257457\n",
      "epoch:  2  batch: 61  loss: 0.42068523\n",
      "epoch:  2  batch: 62  loss: 0.37814319\n",
      "epoch:  2  batch: 63  loss: 0.32179141\n",
      "epoch:  2  batch: 64  loss: 0.40400273\n",
      "epoch:  2  batch: 65  loss: 0.33120358\n",
      "epoch:  2  batch: 66  loss: 0.35218391\n",
      "epoch:  2  batch: 67  loss: 0.33235016\n",
      "epoch:  2  batch: 68  loss: 0.38150403\n",
      "epoch:  2  batch: 69  loss: 0.26955354\n",
      "epoch:  2  batch: 70  loss: 0.26817742\n",
      "epoch:  2  batch: 71  loss: 0.26644325\n",
      "epoch:  2  batch: 72  loss: 0.44143161\n",
      "epoch:  2  batch: 73  loss: 0.33606160\n",
      "epoch:  2  batch: 74  loss: 0.32810771\n",
      "epoch:  2  batch: 75  loss: 0.32706344\n",
      "epoch:  2  batch: 76  loss: 0.38403249\n",
      "epoch:  2  batch: 77  loss: 0.46728030\n",
      "epoch:  2  batch: 78  loss: 0.34533334\n",
      "epoch:  2  batch: 79  loss: 0.33993754\n",
      "epoch:  2  batch: 80  loss: 0.44943434\n",
      "epoch:  2  batch: 81  loss: 0.42800963\n",
      "epoch:  2  batch: 82  loss: 0.36351982\n",
      "epoch:  2  batch: 83  loss: 0.30604729\n",
      "epoch:  2  batch: 84  loss: 0.35191077\n",
      "epoch:  2  batch: 85  loss: 0.44150439\n",
      "epoch:  2  batch: 86  loss: 0.33173513\n",
      "epoch:  2  batch: 87  loss: 0.30219278\n",
      "epoch:  3  batch: 1  loss: 0.51626629\n",
      "epoch:  3  batch: 2  loss: 0.37074184\n",
      "epoch:  3  batch: 3  loss: 0.43632942\n",
      "epoch:  3  batch: 4  loss: 0.32797635\n",
      "epoch:  3  batch: 5  loss: 0.35172099\n",
      "epoch:  3  batch: 6  loss: 0.51546609\n",
      "epoch:  3  batch: 7  loss: 0.39551622\n",
      "epoch:  3  batch: 8  loss: 0.22070040\n",
      "epoch:  3  batch: 9  loss: 0.32384428\n",
      "epoch:  3  batch: 10  loss: 0.23880582\n",
      "epoch:  3  batch: 11  loss: 0.43392017\n",
      "epoch:  3  batch: 12  loss: 0.30930197\n",
      "epoch:  3  batch: 13  loss: 0.36400956\n",
      "epoch:  3  batch: 14  loss: 0.32402575\n",
      "epoch:  3  batch: 15  loss: 0.32959947\n",
      "epoch:  3  batch: 16  loss: 0.32388917\n",
      "epoch:  3  batch: 17  loss: 0.30493826\n",
      "epoch:  3  batch: 18  loss: 0.39290532\n",
      "epoch:  3  batch: 19  loss: 0.33113003\n",
      "epoch:  3  batch: 20  loss: 0.33370566\n",
      "epoch:  3  batch: 21  loss: 0.36030346\n",
      "epoch:  3  batch: 22  loss: 0.45316857\n",
      "epoch:  3  batch: 23  loss: 0.38658085\n",
      "epoch:  3  batch: 24  loss: 0.46775275\n",
      "epoch:  3  batch: 25  loss: 0.35369620\n",
      "epoch:  3  batch: 26  loss: 0.33006370\n",
      "epoch:  3  batch: 27  loss: 0.38460702\n",
      "epoch:  3  batch: 28  loss: 0.33883852\n",
      "epoch:  3  batch: 29  loss: 0.40864611\n",
      "epoch:  3  batch: 30  loss: 0.34463951\n",
      "epoch:  3  batch: 31  loss: 0.39086279\n",
      "epoch:  3  batch: 32  loss: 0.29720283\n",
      "epoch:  3  batch: 33  loss: 0.39054772\n",
      "epoch:  3  batch: 34  loss: 0.36208892\n",
      "epoch:  3  batch: 35  loss: 0.29414788\n",
      "epoch:  3  batch: 36  loss: 0.35785264\n",
      "epoch:  3  batch: 37  loss: 0.35191613\n",
      "epoch:  3  batch: 38  loss: 0.33687237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3  batch: 39  loss: 0.33074635\n",
      "epoch:  3  batch: 40  loss: 0.33896577\n",
      "epoch:  3  batch: 41  loss: 0.44936419\n",
      "epoch:  3  batch: 42  loss: 0.28828171\n",
      "epoch:  3  batch: 43  loss: 0.32554412\n",
      "epoch:  3  batch: 44  loss: 0.21762387\n",
      "epoch:  3  batch: 45  loss: 0.30175987\n",
      "epoch:  3  batch: 46  loss: 0.32624838\n",
      "epoch:  3  batch: 47  loss: 0.27495971\n",
      "epoch:  3  batch: 48  loss: 0.28202429\n",
      "epoch:  3  batch: 49  loss: 0.31068963\n",
      "epoch:  3  batch: 50  loss: 0.41218209\n",
      "epoch:  3  batch: 51  loss: 0.25415230\n",
      "epoch:  3  batch: 52  loss: 0.27550572\n",
      "epoch:  3  batch: 53  loss: 0.41443071\n",
      "epoch:  3  batch: 54  loss: 0.29077676\n",
      "epoch:  3  batch: 55  loss: 0.27382335\n",
      "epoch:  3  batch: 56  loss: 0.27990571\n",
      "epoch:  3  batch: 57  loss: 0.20665793\n",
      "epoch:  3  batch: 58  loss: 0.32655948\n",
      "epoch:  3  batch: 59  loss: 0.31947094\n",
      "epoch:  3  batch: 60  loss: 0.36319804\n",
      "epoch:  3  batch: 61  loss: 0.26930153\n",
      "epoch:  3  batch: 62  loss: 0.29394698\n",
      "epoch:  3  batch: 63  loss: 0.33192325\n",
      "epoch:  3  batch: 64  loss: 0.27724576\n",
      "epoch:  3  batch: 65  loss: 0.29423854\n",
      "epoch:  3  batch: 66  loss: 0.30351970\n",
      "epoch:  3  batch: 67  loss: 0.31876713\n",
      "epoch:  3  batch: 68  loss: 0.30017954\n",
      "epoch:  3  batch: 69  loss: 0.31728026\n",
      "epoch:  3  batch: 70  loss: 0.31606364\n",
      "epoch:  3  batch: 71  loss: 0.42026630\n",
      "epoch:  3  batch: 72  loss: 0.31511787\n",
      "epoch:  3  batch: 73  loss: 0.30317590\n",
      "epoch:  3  batch: 74  loss: 0.24072047\n",
      "epoch:  3  batch: 75  loss: 0.33617854\n",
      "epoch:  3  batch: 76  loss: 0.44392782\n",
      "epoch:  3  batch: 77  loss: 0.40180871\n",
      "epoch:  3  batch: 78  loss: 0.40722114\n",
      "epoch:  3  batch: 79  loss: 0.35254869\n",
      "epoch:  3  batch: 80  loss: 0.27114311\n",
      "epoch:  3  batch: 81  loss: 0.25928247\n",
      "epoch:  3  batch: 82  loss: 0.33022946\n",
      "epoch:  3  batch: 83  loss: 0.32411510\n",
      "epoch:  3  batch: 84  loss: 0.31281322\n",
      "epoch:  3  batch: 85  loss: 0.40007403\n",
      "epoch:  3  batch: 86  loss: 0.30222180\n",
      "epoch:  3  batch: 87  loss: 0.29806668\n",
      "epoch:  4  batch: 1  loss: 0.33581665\n",
      "epoch:  4  batch: 2  loss: 0.28576747\n",
      "epoch:  4  batch: 3  loss: 0.35066202\n",
      "epoch:  4  batch: 4  loss: 0.37363532\n",
      "epoch:  4  batch: 5  loss: 0.28644547\n",
      "epoch:  4  batch: 6  loss: 0.28888729\n",
      "epoch:  4  batch: 7  loss: 0.50314659\n",
      "epoch:  4  batch: 8  loss: 0.37777394\n",
      "epoch:  4  batch: 9  loss: 0.37351739\n",
      "epoch:  4  batch: 10  loss: 0.41622394\n",
      "epoch:  4  batch: 11  loss: 0.38625208\n",
      "epoch:  4  batch: 12  loss: 0.22805361\n",
      "epoch:  4  batch: 13  loss: 0.31927609\n",
      "epoch:  4  batch: 14  loss: 0.32017818\n",
      "epoch:  4  batch: 15  loss: 0.29714739\n",
      "epoch:  4  batch: 16  loss: 0.27457234\n",
      "epoch:  4  batch: 17  loss: 0.36199665\n",
      "epoch:  4  batch: 18  loss: 0.31010312\n",
      "epoch:  4  batch: 19  loss: 0.28406429\n",
      "epoch:  4  batch: 20  loss: 0.27956232\n",
      "epoch:  4  batch: 21  loss: 0.38846576\n",
      "epoch:  4  batch: 22  loss: 0.28820676\n",
      "epoch:  4  batch: 23  loss: 0.28019977\n",
      "epoch:  4  batch: 24  loss: 0.28921574\n",
      "epoch:  4  batch: 25  loss: 0.34919828\n",
      "epoch:  4  batch: 26  loss: 0.25282645\n",
      "epoch:  4  batch: 27  loss: 0.31999567\n",
      "epoch:  4  batch: 28  loss: 0.30551040\n",
      "epoch:  4  batch: 29  loss: 0.26395249\n",
      "epoch:  4  batch: 30  loss: 0.37655324\n",
      "epoch:  4  batch: 31  loss: 0.27880168\n",
      "epoch:  4  batch: 32  loss: 0.29919523\n",
      "epoch:  4  batch: 33  loss: 0.26648790\n",
      "epoch:  4  batch: 34  loss: 0.43595603\n",
      "epoch:  4  batch: 35  loss: 0.36943850\n",
      "epoch:  4  batch: 36  loss: 0.36249316\n",
      "epoch:  4  batch: 37  loss: 0.37341896\n",
      "epoch:  4  batch: 38  loss: 0.25756437\n",
      "epoch:  4  batch: 39  loss: 0.26035044\n",
      "epoch:  4  batch: 40  loss: 0.36257750\n",
      "epoch:  4  batch: 41  loss: 0.34256473\n",
      "epoch:  4  batch: 42  loss: 0.46744356\n",
      "epoch:  4  batch: 43  loss: 0.29432830\n",
      "epoch:  4  batch: 44  loss: 0.30352700\n",
      "epoch:  4  batch: 45  loss: 0.32901558\n",
      "epoch:  4  batch: 46  loss: 0.25560924\n",
      "epoch:  4  batch: 47  loss: 0.29617605\n",
      "epoch:  4  batch: 48  loss: 0.39001241\n",
      "epoch:  4  batch: 49  loss: 0.29250121\n",
      "epoch:  4  batch: 50  loss: 0.30960283\n",
      "epoch:  4  batch: 51  loss: 0.32479593\n",
      "epoch:  4  batch: 52  loss: 0.39788094\n",
      "epoch:  4  batch: 53  loss: 0.23926912\n",
      "epoch:  4  batch: 54  loss: 0.24177247\n",
      "epoch:  4  batch: 55  loss: 0.29101899\n",
      "epoch:  4  batch: 56  loss: 0.22253242\n",
      "epoch:  4  batch: 57  loss: 0.25898215\n",
      "epoch:  4  batch: 58  loss: 0.27667186\n",
      "epoch:  4  batch: 59  loss: 0.23801914\n",
      "epoch:  4  batch: 60  loss: 0.32464603\n",
      "epoch:  4  batch: 61  loss: 0.30311957\n",
      "epoch:  4  batch: 62  loss: 0.35428017\n",
      "epoch:  4  batch: 63  loss: 0.25199488\n",
      "epoch:  4  batch: 64  loss: 0.36165470\n",
      "epoch:  4  batch: 65  loss: 0.40384695\n",
      "epoch:  4  batch: 66  loss: 0.27740797\n",
      "epoch:  4  batch: 67  loss: 0.37354282\n",
      "epoch:  4  batch: 68  loss: 0.36831617\n",
      "epoch:  4  batch: 69  loss: 0.30442697\n",
      "epoch:  4  batch: 70  loss: 0.29882643\n",
      "epoch:  4  batch: 71  loss: 0.28018740\n",
      "epoch:  4  batch: 72  loss: 0.25630009\n",
      "epoch:  4  batch: 73  loss: 0.27775058\n",
      "epoch:  4  batch: 74  loss: 0.29929718\n",
      "epoch:  4  batch: 75  loss: 0.33438265\n",
      "epoch:  4  batch: 76  loss: 0.28992769\n",
      "epoch:  4  batch: 77  loss: 0.27256671\n",
      "epoch:  4  batch: 78  loss: 0.24957111\n",
      "epoch:  4  batch: 79  loss: 0.30962932\n",
      "epoch:  4  batch: 80  loss: 0.28332329\n",
      "epoch:  4  batch: 81  loss: 0.28087795\n",
      "epoch:  4  batch: 82  loss: 0.29443032\n",
      "epoch:  4  batch: 83  loss: 0.32902583\n",
      "epoch:  4  batch: 84  loss: 0.33720684\n",
      "epoch:  4  batch: 85  loss: 0.38690034\n",
      "epoch:  4  batch: 86  loss: 0.37531400\n",
      "epoch:  4  batch: 87  loss: 0.45860386\n",
      "epoch:  5  batch: 1  loss: 0.25953150\n",
      "epoch:  5  batch: 2  loss: 0.32881695\n",
      "epoch:  5  batch: 3  loss: 0.32753971\n",
      "epoch:  5  batch: 4  loss: 0.24341369\n",
      "epoch:  5  batch: 5  loss: 0.33381230\n",
      "epoch:  5  batch: 6  loss: 0.32644343\n",
      "epoch:  5  batch: 7  loss: 0.31522533\n",
      "epoch:  5  batch: 8  loss: 0.27688235\n",
      "epoch:  5  batch: 9  loss: 0.20722829\n",
      "epoch:  5  batch: 10  loss: 0.40414330\n",
      "epoch:  5  batch: 11  loss: 0.36021724\n",
      "epoch:  5  batch: 12  loss: 0.31411248\n",
      "epoch:  5  batch: 13  loss: 0.36841246\n",
      "epoch:  5  batch: 14  loss: 0.24949774\n",
      "epoch:  5  batch: 15  loss: 0.35475048\n",
      "epoch:  5  batch: 16  loss: 0.24728373\n",
      "epoch:  5  batch: 17  loss: 0.23302194\n",
      "epoch:  5  batch: 18  loss: 0.35509369\n",
      "epoch:  5  batch: 19  loss: 0.34518465\n",
      "epoch:  5  batch: 20  loss: 0.29205778\n",
      "epoch:  5  batch: 21  loss: 0.29362819\n",
      "epoch:  5  batch: 22  loss: 0.28758651\n",
      "epoch:  5  batch: 23  loss: 0.28318292\n",
      "epoch:  5  batch: 24  loss: 0.30566925\n",
      "epoch:  5  batch: 25  loss: 0.35389176\n",
      "epoch:  5  batch: 26  loss: 0.40555099\n",
      "epoch:  5  batch: 27  loss: 0.30149424\n",
      "epoch:  5  batch: 28  loss: 0.44443890\n",
      "epoch:  5  batch: 29  loss: 0.26166868\n",
      "epoch:  5  batch: 30  loss: 0.43348688\n",
      "epoch:  5  batch: 31  loss: 0.32866782\n",
      "epoch:  5  batch: 32  loss: 0.34661570\n",
      "epoch:  5  batch: 33  loss: 0.32993636\n",
      "epoch:  5  batch: 34  loss: 0.37534526\n",
      "epoch:  5  batch: 35  loss: 0.25697851\n",
      "epoch:  5  batch: 36  loss: 0.26534063\n",
      "epoch:  5  batch: 37  loss: 0.29908881\n",
      "epoch:  5  batch: 38  loss: 0.30600423\n",
      "epoch:  5  batch: 39  loss: 0.28951457\n",
      "epoch:  5  batch: 40  loss: 0.38541237\n",
      "epoch:  5  batch: 41  loss: 0.29590243\n",
      "epoch:  5  batch: 42  loss: 0.33972728\n",
      "epoch:  5  batch: 43  loss: 0.29795581\n",
      "epoch:  5  batch: 44  loss: 0.30808839\n",
      "epoch:  5  batch: 45  loss: 0.20703535\n",
      "epoch:  5  batch: 46  loss: 0.27897161\n",
      "epoch:  5  batch: 47  loss: 0.28969029\n",
      "epoch:  5  batch: 48  loss: 0.31997842\n",
      "epoch:  5  batch: 49  loss: 0.26127619\n",
      "epoch:  5  batch: 50  loss: 0.34060344\n",
      "epoch:  5  batch: 51  loss: 0.30039069\n",
      "epoch:  5  batch: 52  loss: 0.29722208\n",
      "epoch:  5  batch: 53  loss: 0.31167737\n",
      "epoch:  5  batch: 54  loss: 0.31313884\n",
      "epoch:  5  batch: 55  loss: 0.26328468\n",
      "epoch:  5  batch: 56  loss: 0.28250721\n",
      "epoch:  5  batch: 57  loss: 0.39773256\n",
      "epoch:  5  batch: 58  loss: 0.17666748\n",
      "epoch:  5  batch: 59  loss: 0.36532676\n",
      "epoch:  5  batch: 60  loss: 0.26107538\n",
      "epoch:  5  batch: 61  loss: 0.23442578\n",
      "epoch:  5  batch: 62  loss: 0.31181177\n",
      "epoch:  5  batch: 63  loss: 0.24946237\n",
      "epoch:  5  batch: 64  loss: 0.31320331\n",
      "epoch:  5  batch: 65  loss: 0.33127740\n",
      "epoch:  5  batch: 66  loss: 0.47276872\n",
      "epoch:  5  batch: 67  loss: 0.33463663\n",
      "epoch:  5  batch: 68  loss: 0.26244336\n",
      "epoch:  5  batch: 69  loss: 0.31663707\n",
      "epoch:  5  batch: 70  loss: 0.26162678\n",
      "epoch:  5  batch: 71  loss: 0.35818210\n",
      "epoch:  5  batch: 72  loss: 0.27206761\n",
      "epoch:  5  batch: 73  loss: 0.41881016\n",
      "epoch:  5  batch: 74  loss: 0.25094068\n",
      "epoch:  5  batch: 75  loss: 0.32865170\n",
      "epoch:  5  batch: 76  loss: 0.33079869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5  batch: 77  loss: 0.24370658\n",
      "epoch:  5  batch: 78  loss: 0.34529385\n",
      "epoch:  5  batch: 79  loss: 0.27484572\n",
      "epoch:  5  batch: 80  loss: 0.25012630\n",
      "epoch:  5  batch: 81  loss: 0.31064156\n",
      "epoch:  5  batch: 82  loss: 0.26181707\n",
      "epoch:  5  batch: 83  loss: 0.26266763\n",
      "epoch:  5  batch: 84  loss: 0.19139567\n",
      "epoch:  5  batch: 85  loss: 0.25864446\n",
      "epoch:  5  batch: 86  loss: 0.24014461\n",
      "epoch:  5  batch: 87  loss: 0.26377386\n",
      "epoch:  6  batch: 1  loss: 0.29476696\n",
      "epoch:  6  batch: 2  loss: 0.32009208\n",
      "epoch:  6  batch: 3  loss: 0.19256806\n",
      "epoch:  6  batch: 4  loss: 0.34291634\n",
      "epoch:  6  batch: 5  loss: 0.19115449\n",
      "epoch:  6  batch: 6  loss: 0.32879946\n",
      "epoch:  6  batch: 7  loss: 0.29697743\n",
      "epoch:  6  batch: 8  loss: 0.26394817\n",
      "epoch:  6  batch: 9  loss: 0.27066714\n",
      "epoch:  6  batch: 10  loss: 0.30159891\n",
      "epoch:  6  batch: 11  loss: 0.22605909\n",
      "epoch:  6  batch: 12  loss: 0.26064867\n",
      "epoch:  6  batch: 13  loss: 0.27793822\n",
      "epoch:  6  batch: 14  loss: 0.17851831\n",
      "epoch:  6  batch: 15  loss: 0.24488893\n",
      "epoch:  6  batch: 16  loss: 0.27307755\n",
      "epoch:  6  batch: 17  loss: 0.26333264\n",
      "epoch:  6  batch: 18  loss: 0.30209154\n",
      "epoch:  6  batch: 19  loss: 0.27199709\n",
      "epoch:  6  batch: 20  loss: 0.24919559\n",
      "epoch:  6  batch: 21  loss: 0.29771313\n",
      "epoch:  6  batch: 22  loss: 0.45063174\n",
      "epoch:  6  batch: 23  loss: 0.23845921\n",
      "epoch:  6  batch: 24  loss: 0.26907724\n",
      "epoch:  6  batch: 25  loss: 0.25355518\n",
      "epoch:  6  batch: 26  loss: 0.28408667\n",
      "epoch:  6  batch: 27  loss: 0.28782269\n",
      "epoch:  6  batch: 28  loss: 0.32133764\n",
      "epoch:  6  batch: 29  loss: 0.22847590\n",
      "epoch:  6  batch: 30  loss: 0.32874388\n",
      "epoch:  6  batch: 31  loss: 0.31469044\n",
      "epoch:  6  batch: 32  loss: 0.27395660\n",
      "epoch:  6  batch: 33  loss: 0.24165800\n",
      "epoch:  6  batch: 34  loss: 0.31681532\n",
      "epoch:  6  batch: 35  loss: 0.29489681\n",
      "epoch:  6  batch: 36  loss: 0.31495148\n",
      "epoch:  6  batch: 37  loss: 0.21374466\n",
      "epoch:  6  batch: 38  loss: 0.22519684\n",
      "epoch:  6  batch: 39  loss: 0.30239359\n",
      "epoch:  6  batch: 40  loss: 0.27924010\n",
      "epoch:  6  batch: 41  loss: 0.31658295\n",
      "epoch:  6  batch: 42  loss: 0.26350209\n",
      "epoch:  6  batch: 43  loss: 0.26773900\n",
      "epoch:  6  batch: 44  loss: 0.21951771\n",
      "epoch:  6  batch: 45  loss: 0.30179337\n",
      "epoch:  6  batch: 46  loss: 0.25771445\n",
      "epoch:  6  batch: 47  loss: 0.28762835\n",
      "epoch:  6  batch: 48  loss: 0.27037793\n",
      "epoch:  6  batch: 49  loss: 0.36832631\n",
      "epoch:  6  batch: 50  loss: 0.31886125\n",
      "epoch:  6  batch: 51  loss: 0.27017510\n",
      "epoch:  6  batch: 52  loss: 0.31688914\n",
      "epoch:  6  batch: 53  loss: 0.40281203\n",
      "epoch:  6  batch: 54  loss: 0.29615819\n",
      "epoch:  6  batch: 55  loss: 0.25106037\n",
      "epoch:  6  batch: 56  loss: 0.33278778\n",
      "epoch:  6  batch: 57  loss: 0.29618579\n",
      "epoch:  6  batch: 58  loss: 0.31373149\n",
      "epoch:  6  batch: 59  loss: 0.33065638\n",
      "epoch:  6  batch: 60  loss: 0.31436926\n",
      "epoch:  6  batch: 61  loss: 0.34397355\n",
      "epoch:  6  batch: 62  loss: 0.29845986\n",
      "epoch:  6  batch: 63  loss: 0.35718513\n",
      "epoch:  6  batch: 64  loss: 0.38643140\n",
      "epoch:  6  batch: 65  loss: 0.30086842\n",
      "epoch:  6  batch: 66  loss: 0.36038473\n",
      "epoch:  6  batch: 67  loss: 0.30467933\n",
      "epoch:  6  batch: 68  loss: 0.40817899\n",
      "epoch:  6  batch: 69  loss: 0.35178590\n",
      "epoch:  6  batch: 70  loss: 0.30462253\n",
      "epoch:  6  batch: 71  loss: 0.43163693\n",
      "epoch:  6  batch: 72  loss: 0.28425017\n",
      "epoch:  6  batch: 73  loss: 0.34905857\n",
      "epoch:  6  batch: 74  loss: 0.26709223\n",
      "epoch:  6  batch: 75  loss: 0.24910940\n",
      "epoch:  6  batch: 76  loss: 0.36931244\n",
      "epoch:  6  batch: 77  loss: 0.19627018\n",
      "epoch:  6  batch: 78  loss: 0.28575343\n",
      "epoch:  6  batch: 79  loss: 0.23491165\n",
      "epoch:  6  batch: 80  loss: 0.38422745\n",
      "epoch:  6  batch: 81  loss: 0.29622149\n",
      "epoch:  6  batch: 82  loss: 0.30232540\n",
      "epoch:  6  batch: 83  loss: 0.29550636\n",
      "epoch:  6  batch: 84  loss: 0.35671729\n",
      "epoch:  6  batch: 85  loss: 0.44960928\n",
      "epoch:  6  batch: 86  loss: 0.30813810\n",
      "epoch:  6  batch: 87  loss: 0.41055441\n",
      "epoch:  7  batch: 1  loss: 0.30813658\n",
      "epoch:  7  batch: 2  loss: 0.30971387\n",
      "epoch:  7  batch: 3  loss: 0.31366846\n",
      "epoch:  7  batch: 4  loss: 0.32750392\n",
      "epoch:  7  batch: 5  loss: 0.29263404\n",
      "epoch:  7  batch: 6  loss: 0.37416697\n",
      "epoch:  7  batch: 7  loss: 0.28393784\n",
      "epoch:  7  batch: 8  loss: 0.38758045\n",
      "epoch:  7  batch: 9  loss: 0.27185962\n",
      "epoch:  7  batch: 10  loss: 0.31387368\n",
      "epoch:  7  batch: 11  loss: 0.22085665\n",
      "epoch:  7  batch: 12  loss: 0.24007908\n",
      "epoch:  7  batch: 13  loss: 0.36728060\n",
      "epoch:  7  batch: 14  loss: 0.33588800\n",
      "epoch:  7  batch: 15  loss: 0.24753426\n",
      "epoch:  7  batch: 16  loss: 0.30389392\n",
      "epoch:  7  batch: 17  loss: 0.33256620\n",
      "epoch:  7  batch: 18  loss: 0.27153102\n",
      "epoch:  7  batch: 19  loss: 0.24938279\n",
      "epoch:  7  batch: 20  loss: 0.30195943\n",
      "epoch:  7  batch: 21  loss: 0.23997803\n",
      "epoch:  7  batch: 22  loss: 0.33828133\n",
      "epoch:  7  batch: 23  loss: 0.23263799\n",
      "epoch:  7  batch: 24  loss: 0.41684377\n",
      "epoch:  7  batch: 25  loss: 0.34398246\n",
      "epoch:  7  batch: 26  loss: 0.31993619\n",
      "epoch:  7  batch: 27  loss: 0.41011769\n",
      "epoch:  7  batch: 28  loss: 0.27738261\n",
      "epoch:  7  batch: 29  loss: 0.33056879\n",
      "epoch:  7  batch: 30  loss: 0.22675841\n",
      "epoch:  7  batch: 31  loss: 0.30107734\n",
      "epoch:  7  batch: 32  loss: 0.29513443\n",
      "epoch:  7  batch: 33  loss: 0.30683032\n",
      "epoch:  7  batch: 34  loss: 0.31256816\n",
      "epoch:  7  batch: 35  loss: 0.17508647\n",
      "epoch:  7  batch: 36  loss: 0.28845212\n",
      "epoch:  7  batch: 37  loss: 0.25700307\n",
      "epoch:  7  batch: 38  loss: 0.31327480\n",
      "epoch:  7  batch: 39  loss: 0.28128064\n",
      "epoch:  7  batch: 40  loss: 0.23428145\n",
      "epoch:  7  batch: 41  loss: 0.17465013\n",
      "epoch:  7  batch: 42  loss: 0.20596963\n",
      "epoch:  7  batch: 43  loss: 0.32447958\n",
      "epoch:  7  batch: 44  loss: 0.29072896\n",
      "epoch:  7  batch: 45  loss: 0.22374009\n",
      "epoch:  7  batch: 46  loss: 0.31759334\n",
      "epoch:  7  batch: 47  loss: 0.33814746\n",
      "epoch:  7  batch: 48  loss: 0.34120172\n",
      "epoch:  7  batch: 49  loss: 0.24602067\n",
      "epoch:  7  batch: 50  loss: 0.23237920\n",
      "epoch:  7  batch: 51  loss: 0.32461181\n",
      "epoch:  7  batch: 52  loss: 0.28676811\n",
      "epoch:  7  batch: 53  loss: 0.28223553\n",
      "epoch:  7  batch: 54  loss: 0.34356552\n",
      "epoch:  7  batch: 55  loss: 0.30786568\n",
      "epoch:  7  batch: 56  loss: 0.30009344\n",
      "epoch:  7  batch: 57  loss: 0.29192850\n",
      "epoch:  7  batch: 58  loss: 0.32636371\n",
      "epoch:  7  batch: 59  loss: 0.25179529\n",
      "epoch:  7  batch: 60  loss: 0.22670551\n",
      "epoch:  7  batch: 61  loss: 0.36532184\n",
      "epoch:  7  batch: 62  loss: 0.24214432\n",
      "epoch:  7  batch: 63  loss: 0.22791421\n",
      "epoch:  7  batch: 64  loss: 0.21815366\n",
      "epoch:  7  batch: 65  loss: 0.30135292\n",
      "epoch:  7  batch: 66  loss: 0.22955155\n",
      "epoch:  7  batch: 67  loss: 0.30077866\n",
      "epoch:  7  batch: 68  loss: 0.33121803\n",
      "epoch:  7  batch: 69  loss: 0.18887354\n",
      "epoch:  7  batch: 70  loss: 0.26876608\n",
      "epoch:  7  batch: 71  loss: 0.29617557\n",
      "epoch:  7  batch: 72  loss: 0.26922089\n",
      "epoch:  7  batch: 73  loss: 0.24223430\n",
      "epoch:  7  batch: 74  loss: 0.35141858\n",
      "epoch:  7  batch: 75  loss: 0.35201168\n",
      "epoch:  7  batch: 76  loss: 0.24073000\n",
      "epoch:  7  batch: 77  loss: 0.29429039\n",
      "epoch:  7  batch: 78  loss: 0.30053216\n",
      "epoch:  7  batch: 79  loss: 0.29083043\n",
      "epoch:  7  batch: 80  loss: 0.28164774\n",
      "epoch:  7  batch: 81  loss: 0.29700655\n",
      "epoch:  7  batch: 82  loss: 0.16635042\n",
      "epoch:  7  batch: 83  loss: 0.23951483\n",
      "epoch:  7  batch: 84  loss: 0.31836960\n",
      "epoch:  7  batch: 85  loss: 0.26765421\n",
      "epoch:  7  batch: 86  loss: 0.32722217\n",
      "epoch:  7  batch: 87  loss: 0.27181074\n",
      "epoch:  8  batch: 1  loss: 0.30421147\n",
      "epoch:  8  batch: 2  loss: 0.24936080\n",
      "epoch:  8  batch: 3  loss: 0.19189979\n",
      "epoch:  8  batch: 4  loss: 0.30783877\n",
      "epoch:  8  batch: 5  loss: 0.38722485\n",
      "epoch:  8  batch: 6  loss: 0.30146793\n",
      "epoch:  8  batch: 7  loss: 0.20342340\n",
      "epoch:  8  batch: 8  loss: 0.22574687\n",
      "epoch:  8  batch: 9  loss: 0.26094848\n",
      "epoch:  8  batch: 10  loss: 0.22767904\n",
      "epoch:  8  batch: 11  loss: 0.23904380\n",
      "epoch:  8  batch: 12  loss: 0.24685241\n",
      "epoch:  8  batch: 13  loss: 0.21977000\n",
      "epoch:  8  batch: 14  loss: 0.24430358\n",
      "epoch:  8  batch: 15  loss: 0.27298811\n",
      "epoch:  8  batch: 16  loss: 0.27835971\n",
      "epoch:  8  batch: 17  loss: 0.26620311\n",
      "epoch:  8  batch: 18  loss: 0.27585724\n",
      "epoch:  8  batch: 19  loss: 0.20692001\n",
      "epoch:  8  batch: 20  loss: 0.25603217\n",
      "epoch:  8  batch: 21  loss: 0.30104986\n",
      "epoch:  8  batch: 22  loss: 0.23800024\n",
      "epoch:  8  batch: 23  loss: 0.22048938\n",
      "epoch:  8  batch: 24  loss: 0.38702407\n",
      "epoch:  8  batch: 25  loss: 0.29516646\n",
      "epoch:  8  batch: 26  loss: 0.32833704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8  batch: 27  loss: 0.32779980\n",
      "epoch:  8  batch: 28  loss: 0.27291116\n",
      "epoch:  8  batch: 29  loss: 0.20132518\n",
      "epoch:  8  batch: 30  loss: 0.30443600\n",
      "epoch:  8  batch: 31  loss: 0.27046248\n",
      "epoch:  8  batch: 32  loss: 0.21409494\n",
      "epoch:  8  batch: 33  loss: 0.30071530\n",
      "epoch:  8  batch: 34  loss: 0.26215565\n",
      "epoch:  8  batch: 35  loss: 0.22424649\n",
      "epoch:  8  batch: 36  loss: 0.26645175\n",
      "epoch:  8  batch: 37  loss: 0.28853530\n",
      "epoch:  8  batch: 38  loss: 0.17838491\n",
      "epoch:  8  batch: 39  loss: 0.21269864\n",
      "epoch:  8  batch: 40  loss: 0.37474543\n",
      "epoch:  8  batch: 41  loss: 0.33304352\n",
      "epoch:  8  batch: 42  loss: 0.27472746\n",
      "epoch:  8  batch: 43  loss: 0.31395659\n",
      "epoch:  8  batch: 44  loss: 0.31325981\n",
      "epoch:  8  batch: 45  loss: 0.30248266\n",
      "epoch:  8  batch: 46  loss: 0.24417198\n",
      "epoch:  8  batch: 47  loss: 0.25642711\n",
      "epoch:  8  batch: 48  loss: 0.25026640\n",
      "epoch:  8  batch: 49  loss: 0.31362543\n",
      "epoch:  8  batch: 50  loss: 0.32050955\n",
      "epoch:  8  batch: 51  loss: 0.22431244\n",
      "epoch:  8  batch: 52  loss: 0.33118492\n",
      "epoch:  8  batch: 53  loss: 0.30487356\n",
      "epoch:  8  batch: 54  loss: 0.28007829\n",
      "epoch:  8  batch: 55  loss: 0.22423525\n",
      "epoch:  8  batch: 56  loss: 0.25584349\n",
      "epoch:  8  batch: 57  loss: 0.28757018\n",
      "epoch:  8  batch: 58  loss: 0.31036866\n",
      "epoch:  8  batch: 59  loss: 0.31040737\n",
      "epoch:  8  batch: 60  loss: 0.26788127\n",
      "epoch:  8  batch: 61  loss: 0.25546065\n",
      "epoch:  8  batch: 62  loss: 0.32559219\n",
      "epoch:  8  batch: 63  loss: 0.27509874\n",
      "epoch:  8  batch: 64  loss: 0.27957314\n",
      "epoch:  8  batch: 65  loss: 0.23522677\n",
      "epoch:  8  batch: 66  loss: 0.20441590\n",
      "epoch:  8  batch: 67  loss: 0.30554464\n",
      "epoch:  8  batch: 68  loss: 0.29567721\n",
      "epoch:  8  batch: 69  loss: 0.25199252\n",
      "epoch:  8  batch: 70  loss: 0.29489964\n",
      "epoch:  8  batch: 71  loss: 0.23714194\n",
      "epoch:  8  batch: 72  loss: 0.35302648\n",
      "epoch:  8  batch: 73  loss: 0.39460120\n",
      "epoch:  8  batch: 74  loss: 0.27597162\n",
      "epoch:  8  batch: 75  loss: 0.26637933\n",
      "epoch:  8  batch: 76  loss: 0.27375293\n",
      "epoch:  8  batch: 77  loss: 0.22912927\n",
      "epoch:  8  batch: 78  loss: 0.33745545\n",
      "epoch:  8  batch: 79  loss: 0.30116358\n",
      "epoch:  8  batch: 80  loss: 0.31980199\n",
      "epoch:  8  batch: 81  loss: 0.41011363\n",
      "epoch:  8  batch: 82  loss: 0.23280746\n",
      "epoch:  8  batch: 83  loss: 0.28208321\n",
      "epoch:  8  batch: 84  loss: 0.29025057\n",
      "epoch:  8  batch: 85  loss: 0.26773661\n",
      "epoch:  8  batch: 86  loss: 0.29517218\n",
      "epoch:  8  batch: 87  loss: 0.32158396\n",
      "epoch:  9  batch: 1  loss: 0.29310411\n",
      "epoch:  9  batch: 2  loss: 0.25542158\n",
      "epoch:  9  batch: 3  loss: 0.23911129\n",
      "epoch:  9  batch: 4  loss: 0.34515414\n",
      "epoch:  9  batch: 5  loss: 0.21490861\n",
      "epoch:  9  batch: 6  loss: 0.21616986\n",
      "epoch:  9  batch: 7  loss: 0.26048750\n",
      "epoch:  9  batch: 8  loss: 0.21722236\n",
      "epoch:  9  batch: 9  loss: 0.34813190\n",
      "epoch:  9  batch: 10  loss: 0.29528677\n",
      "epoch:  9  batch: 11  loss: 0.25114548\n",
      "epoch:  9  batch: 12  loss: 0.26258665\n",
      "epoch:  9  batch: 13  loss: 0.23923653\n",
      "epoch:  9  batch: 14  loss: 0.29943734\n",
      "epoch:  9  batch: 15  loss: 0.23536059\n",
      "epoch:  9  batch: 16  loss: 0.27381453\n",
      "epoch:  9  batch: 17  loss: 0.34261099\n",
      "epoch:  9  batch: 18  loss: 0.35852626\n",
      "epoch:  9  batch: 19  loss: 0.35113400\n",
      "epoch:  9  batch: 20  loss: 0.21005742\n",
      "epoch:  9  batch: 21  loss: 0.27091968\n",
      "epoch:  9  batch: 22  loss: 0.25659367\n",
      "epoch:  9  batch: 23  loss: 0.25952917\n",
      "epoch:  9  batch: 24  loss: 0.23131429\n",
      "epoch:  9  batch: 25  loss: 0.30954283\n",
      "epoch:  9  batch: 26  loss: 0.23672543\n",
      "epoch:  9  batch: 27  loss: 0.32650775\n",
      "epoch:  9  batch: 28  loss: 0.27611575\n",
      "epoch:  9  batch: 29  loss: 0.23820266\n",
      "epoch:  9  batch: 30  loss: 0.29149166\n",
      "epoch:  9  batch: 31  loss: 0.21867587\n",
      "epoch:  9  batch: 32  loss: 0.25588629\n",
      "epoch:  9  batch: 33  loss: 0.27754709\n",
      "epoch:  9  batch: 34  loss: 0.31853122\n",
      "epoch:  9  batch: 35  loss: 0.20840465\n",
      "epoch:  9  batch: 36  loss: 0.27071229\n",
      "epoch:  9  batch: 37  loss: 0.21643862\n",
      "epoch:  9  batch: 38  loss: 0.21812099\n",
      "epoch:  9  batch: 39  loss: 0.23844339\n",
      "epoch:  9  batch: 40  loss: 0.30365017\n",
      "epoch:  9  batch: 41  loss: 0.25418222\n",
      "epoch:  9  batch: 42  loss: 0.24449395\n",
      "epoch:  9  batch: 43  loss: 0.28909388\n",
      "epoch:  9  batch: 44  loss: 0.24944618\n",
      "epoch:  9  batch: 45  loss: 0.35458627\n",
      "epoch:  9  batch: 46  loss: 0.28201860\n",
      "epoch:  9  batch: 47  loss: 0.23295166\n",
      "epoch:  9  batch: 48  loss: 0.25844559\n",
      "epoch:  9  batch: 49  loss: 0.22442147\n",
      "epoch:  9  batch: 50  loss: 0.20201883\n",
      "epoch:  9  batch: 51  loss: 0.23795973\n",
      "epoch:  9  batch: 52  loss: 0.22056629\n",
      "epoch:  9  batch: 53  loss: 0.25146815\n",
      "epoch:  9  batch: 54  loss: 0.19560796\n",
      "epoch:  9  batch: 55  loss: 0.19581421\n",
      "epoch:  9  batch: 56  loss: 0.21088828\n",
      "epoch:  9  batch: 57  loss: 0.20646466\n",
      "epoch:  9  batch: 58  loss: 0.21711789\n",
      "epoch:  9  batch: 59  loss: 0.28395885\n",
      "epoch:  9  batch: 60  loss: 0.32269919\n",
      "epoch:  9  batch: 61  loss: 0.27502188\n",
      "epoch:  9  batch: 62  loss: 0.24859518\n",
      "epoch:  9  batch: 63  loss: 0.26029980\n",
      "epoch:  9  batch: 64  loss: 0.27202392\n",
      "epoch:  9  batch: 65  loss: 0.24210797\n",
      "epoch:  9  batch: 66  loss: 0.25544897\n",
      "epoch:  9  batch: 67  loss: 0.26938301\n",
      "epoch:  9  batch: 68  loss: 0.18481521\n",
      "epoch:  9  batch: 69  loss: 0.17248161\n",
      "epoch:  9  batch: 70  loss: 0.32870701\n",
      "epoch:  9  batch: 71  loss: 0.35004261\n",
      "epoch:  9  batch: 72  loss: 0.21156347\n",
      "epoch:  9  batch: 73  loss: 0.22988789\n",
      "epoch:  9  batch: 74  loss: 0.25671571\n",
      "epoch:  9  batch: 75  loss: 0.24569835\n",
      "epoch:  9  batch: 76  loss: 0.21836895\n",
      "epoch:  9  batch: 77  loss: 0.24685496\n",
      "epoch:  9  batch: 78  loss: 0.23751731\n",
      "epoch:  9  batch: 79  loss: 0.26093480\n",
      "epoch:  9  batch: 80  loss: 0.23733884\n",
      "epoch:  9  batch: 81  loss: 0.30176112\n",
      "epoch:  9  batch: 82  loss: 0.24808380\n",
      "epoch:  9  batch: 83  loss: 0.30474955\n",
      "epoch:  9  batch: 84  loss: 0.30743900\n",
      "epoch:  9  batch: 85  loss: 0.34213755\n",
      "epoch:  9  batch: 86  loss: 0.35391313\n",
      "epoch:  9  batch: 87  loss: 0.37506402\n",
      "epoch: 10  batch: 1  loss: 0.25665322\n",
      "epoch: 10  batch: 2  loss: 0.26746222\n",
      "epoch: 10  batch: 3  loss: 0.24448764\n",
      "epoch: 10  batch: 4  loss: 0.34089571\n",
      "epoch: 10  batch: 5  loss: 0.23815534\n",
      "epoch: 10  batch: 6  loss: 0.32077602\n",
      "epoch: 10  batch: 7  loss: 0.24553934\n",
      "epoch: 10  batch: 8  loss: 0.25159821\n",
      "epoch: 10  batch: 9  loss: 0.35028923\n",
      "epoch: 10  batch: 10  loss: 0.29041418\n",
      "epoch: 10  batch: 11  loss: 0.21455136\n",
      "epoch: 10  batch: 12  loss: 0.35103950\n",
      "epoch: 10  batch: 13  loss: 0.23860966\n",
      "epoch: 10  batch: 14  loss: 0.25721073\n",
      "epoch: 10  batch: 15  loss: 0.18527983\n",
      "epoch: 10  batch: 16  loss: 0.25788423\n",
      "epoch: 10  batch: 17  loss: 0.22787690\n",
      "epoch: 10  batch: 18  loss: 0.21712627\n",
      "epoch: 10  batch: 19  loss: 0.24475452\n",
      "epoch: 10  batch: 20  loss: 0.22161271\n",
      "epoch: 10  batch: 21  loss: 0.28863630\n",
      "epoch: 10  batch: 22  loss: 0.21796986\n",
      "epoch: 10  batch: 23  loss: 0.27604944\n",
      "epoch: 10  batch: 24  loss: 0.22748461\n",
      "epoch: 10  batch: 25  loss: 0.21505618\n",
      "epoch: 10  batch: 26  loss: 0.28379843\n",
      "epoch: 10  batch: 27  loss: 0.35910928\n",
      "epoch: 10  batch: 28  loss: 0.31617421\n",
      "epoch: 10  batch: 29  loss: 0.29745573\n",
      "epoch: 10  batch: 30  loss: 0.29454976\n",
      "epoch: 10  batch: 31  loss: 0.30195770\n",
      "epoch: 10  batch: 32  loss: 0.28078693\n",
      "epoch: 10  batch: 33  loss: 0.24928921\n",
      "epoch: 10  batch: 34  loss: 0.26158127\n",
      "epoch: 10  batch: 35  loss: 0.30890566\n",
      "epoch: 10  batch: 36  loss: 0.27067247\n",
      "epoch: 10  batch: 37  loss: 0.35414755\n",
      "epoch: 10  batch: 38  loss: 0.31133869\n",
      "epoch: 10  batch: 39  loss: 0.34578574\n",
      "epoch: 10  batch: 40  loss: 0.22060809\n",
      "epoch: 10  batch: 41  loss: 0.18644691\n",
      "epoch: 10  batch: 42  loss: 0.21091209\n",
      "epoch: 10  batch: 43  loss: 0.20895931\n",
      "epoch: 10  batch: 44  loss: 0.31854954\n",
      "epoch: 10  batch: 45  loss: 0.29963964\n",
      "epoch: 10  batch: 46  loss: 0.26617432\n",
      "epoch: 10  batch: 47  loss: 0.28949142\n",
      "epoch: 10  batch: 48  loss: 0.37292814\n",
      "epoch: 10  batch: 49  loss: 0.31998879\n",
      "epoch: 10  batch: 50  loss: 0.18540852\n",
      "epoch: 10  batch: 51  loss: 0.22749631\n",
      "epoch: 10  batch: 52  loss: 0.33268225\n",
      "epoch: 10  batch: 53  loss: 0.29728132\n",
      "epoch: 10  batch: 54  loss: 0.29588065\n",
      "epoch: 10  batch: 55  loss: 0.22042876\n",
      "epoch: 10  batch: 56  loss: 0.19233823\n",
      "epoch: 10  batch: 57  loss: 0.25272685\n",
      "epoch: 10  batch: 58  loss: 0.24006844\n",
      "epoch: 10  batch: 59  loss: 0.25132251\n",
      "epoch: 10  batch: 60  loss: 0.25019753\n",
      "epoch: 10  batch: 61  loss: 0.28820461\n",
      "epoch: 10  batch: 62  loss: 0.28461280\n",
      "epoch: 10  batch: 63  loss: 0.35719433\n",
      "epoch: 10  batch: 64  loss: 0.32382697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10  batch: 65  loss: 0.33196038\n",
      "epoch: 10  batch: 66  loss: 0.21805106\n",
      "epoch: 10  batch: 67  loss: 0.24614236\n",
      "epoch: 10  batch: 68  loss: 0.28228113\n",
      "epoch: 10  batch: 69  loss: 0.27548510\n",
      "epoch: 10  batch: 70  loss: 0.31505865\n",
      "epoch: 10  batch: 71  loss: 0.21746758\n",
      "epoch: 10  batch: 72  loss: 0.25761482\n",
      "epoch: 10  batch: 73  loss: 0.25981399\n",
      "epoch: 10  batch: 74  loss: 0.26246333\n",
      "epoch: 10  batch: 75  loss: 0.28855526\n",
      "epoch: 10  batch: 76  loss: 0.22030176\n",
      "epoch: 10  batch: 77  loss: 0.26540881\n",
      "epoch: 10  batch: 78  loss: 0.22048523\n",
      "epoch: 10  batch: 79  loss: 0.21377052\n",
      "epoch: 10  batch: 80  loss: 0.18088832\n",
      "epoch: 10  batch: 81  loss: 0.28656617\n",
      "epoch: 10  batch: 82  loss: 0.25995594\n",
      "epoch: 10  batch: 83  loss: 0.33302215\n",
      "epoch: 10  batch: 84  loss: 0.25435662\n",
      "epoch: 10  batch: 85  loss: 0.29861432\n",
      "epoch: 10  batch: 86  loss: 0.20728104\n",
      "epoch: 10  batch: 87  loss: 0.32884148\n",
      "epoch: 11  batch: 1  loss: 0.28991914\n",
      "epoch: 11  batch: 2  loss: 0.16928363\n",
      "epoch: 11  batch: 3  loss: 0.28094691\n",
      "epoch: 11  batch: 4  loss: 0.25843009\n",
      "epoch: 11  batch: 5  loss: 0.33750534\n",
      "epoch: 11  batch: 6  loss: 0.28890646\n",
      "epoch: 11  batch: 7  loss: 0.38965610\n",
      "epoch: 11  batch: 8  loss: 0.29324710\n",
      "epoch: 11  batch: 9  loss: 0.25955427\n",
      "epoch: 11  batch: 10  loss: 0.27632236\n",
      "epoch: 11  batch: 11  loss: 0.28099722\n",
      "epoch: 11  batch: 12  loss: 0.31185693\n",
      "epoch: 11  batch: 13  loss: 0.29860058\n",
      "epoch: 11  batch: 14  loss: 0.23327520\n",
      "epoch: 11  batch: 15  loss: 0.29451114\n",
      "epoch: 11  batch: 16  loss: 0.24696666\n",
      "epoch: 11  batch: 17  loss: 0.18729036\n",
      "epoch: 11  batch: 18  loss: 0.23974738\n",
      "epoch: 11  batch: 19  loss: 0.21480015\n",
      "epoch: 11  batch: 20  loss: 0.29406244\n",
      "epoch: 11  batch: 21  loss: 0.28042001\n",
      "epoch: 11  batch: 22  loss: 0.30405238\n",
      "epoch: 11  batch: 23  loss: 0.22858344\n",
      "epoch: 11  batch: 24  loss: 0.23505594\n",
      "epoch: 11  batch: 25  loss: 0.20092261\n",
      "epoch: 11  batch: 26  loss: 0.23271705\n",
      "epoch: 11  batch: 27  loss: 0.34932470\n",
      "epoch: 11  batch: 28  loss: 0.25962767\n",
      "epoch: 11  batch: 29  loss: 0.23054066\n",
      "epoch: 11  batch: 30  loss: 0.22688225\n",
      "epoch: 11  batch: 31  loss: 0.21668285\n",
      "epoch: 11  batch: 32  loss: 0.32700998\n",
      "epoch: 11  batch: 33  loss: 0.35249132\n",
      "epoch: 11  batch: 34  loss: 0.23169385\n",
      "epoch: 11  batch: 35  loss: 0.22754730\n",
      "epoch: 11  batch: 36  loss: 0.26722306\n",
      "epoch: 11  batch: 37  loss: 0.23873998\n",
      "epoch: 11  batch: 38  loss: 0.30557761\n",
      "epoch: 11  batch: 39  loss: 0.19106871\n",
      "epoch: 11  batch: 40  loss: 0.26931855\n",
      "epoch: 11  batch: 41  loss: 0.36022702\n",
      "epoch: 11  batch: 42  loss: 0.33155686\n",
      "epoch: 11  batch: 43  loss: 0.31608760\n",
      "epoch: 11  batch: 44  loss: 0.33598584\n",
      "epoch: 11  batch: 45  loss: 0.32259378\n",
      "epoch: 11  batch: 46  loss: 0.24583961\n",
      "epoch: 11  batch: 47  loss: 0.24907410\n",
      "epoch: 11  batch: 48  loss: 0.24385773\n",
      "epoch: 11  batch: 49  loss: 0.30302322\n",
      "epoch: 11  batch: 50  loss: 0.31531513\n",
      "epoch: 11  batch: 51  loss: 0.27520567\n",
      "epoch: 11  batch: 52  loss: 0.17014284\n",
      "epoch: 11  batch: 53  loss: 0.24430493\n",
      "epoch: 11  batch: 54  loss: 0.27780023\n",
      "epoch: 11  batch: 55  loss: 0.27512959\n",
      "epoch: 11  batch: 56  loss: 0.32734904\n",
      "epoch: 11  batch: 57  loss: 0.25139323\n",
      "epoch: 11  batch: 58  loss: 0.21959211\n",
      "epoch: 11  batch: 59  loss: 0.26374623\n",
      "epoch: 11  batch: 60  loss: 0.24937627\n",
      "epoch: 11  batch: 61  loss: 0.19513224\n",
      "epoch: 11  batch: 62  loss: 0.20638016\n",
      "epoch: 11  batch: 63  loss: 0.22215675\n",
      "epoch: 11  batch: 64  loss: 0.24785927\n",
      "epoch: 11  batch: 65  loss: 0.23273838\n",
      "epoch: 11  batch: 66  loss: 0.24976419\n",
      "epoch: 11  batch: 67  loss: 0.31787249\n",
      "epoch: 11  batch: 68  loss: 0.23085921\n",
      "epoch: 11  batch: 69  loss: 0.21862511\n",
      "epoch: 11  batch: 70  loss: 0.27050185\n",
      "epoch: 11  batch: 71  loss: 0.36772832\n",
      "epoch: 11  batch: 72  loss: 0.39714333\n",
      "epoch: 11  batch: 73  loss: 0.28649136\n",
      "epoch: 11  batch: 74  loss: 0.29985920\n",
      "epoch: 11  batch: 75  loss: 0.27624837\n",
      "epoch: 11  batch: 76  loss: 0.26560721\n",
      "epoch: 11  batch: 77  loss: 0.23766579\n",
      "epoch: 11  batch: 78  loss: 0.21683025\n",
      "epoch: 11  batch: 79  loss: 0.32924184\n",
      "epoch: 11  batch: 80  loss: 0.23030673\n",
      "epoch: 11  batch: 81  loss: 0.30345181\n",
      "epoch: 11  batch: 82  loss: 0.26425090\n",
      "epoch: 11  batch: 83  loss: 0.31344888\n",
      "epoch: 11  batch: 84  loss: 0.35377565\n",
      "epoch: 11  batch: 85  loss: 0.26975042\n",
      "epoch: 11  batch: 86  loss: 0.25628680\n",
      "epoch: 11  batch: 87  loss: 0.26062378\n",
      "epoch: 12  batch: 1  loss: 0.33029622\n",
      "epoch: 12  batch: 2  loss: 0.33525348\n",
      "epoch: 12  batch: 3  loss: 0.33872956\n",
      "epoch: 12  batch: 4  loss: 0.27523375\n",
      "epoch: 12  batch: 5  loss: 0.29541877\n",
      "epoch: 12  batch: 6  loss: 0.29336143\n",
      "epoch: 12  batch: 7  loss: 0.28681445\n",
      "epoch: 12  batch: 8  loss: 0.27257204\n",
      "epoch: 12  batch: 9  loss: 0.36200753\n",
      "epoch: 12  batch: 10  loss: 0.24156196\n",
      "epoch: 12  batch: 11  loss: 0.31129053\n",
      "epoch: 12  batch: 12  loss: 0.50695825\n",
      "epoch: 12  batch: 13  loss: 0.19952624\n",
      "epoch: 12  batch: 14  loss: 0.40307030\n",
      "epoch: 12  batch: 15  loss: 0.31296983\n",
      "epoch: 12  batch: 16  loss: 0.29653588\n",
      "epoch: 12  batch: 17  loss: 0.29352525\n",
      "epoch: 12  batch: 18  loss: 0.29223189\n",
      "epoch: 12  batch: 19  loss: 0.28861430\n",
      "epoch: 12  batch: 20  loss: 0.33197740\n",
      "epoch: 12  batch: 21  loss: 0.27303028\n",
      "epoch: 12  batch: 22  loss: 0.25135288\n",
      "epoch: 12  batch: 23  loss: 0.26701871\n",
      "epoch: 12  batch: 24  loss: 0.30195421\n",
      "epoch: 12  batch: 25  loss: 0.34533229\n",
      "epoch: 12  batch: 26  loss: 0.33488673\n",
      "epoch: 12  batch: 27  loss: 0.27647790\n",
      "epoch: 12  batch: 28  loss: 0.27587116\n",
      "epoch: 12  batch: 29  loss: 0.27774933\n",
      "epoch: 12  batch: 30  loss: 0.26010403\n",
      "epoch: 12  batch: 31  loss: 0.28349489\n",
      "epoch: 12  batch: 32  loss: 0.27170190\n",
      "epoch: 12  batch: 33  loss: 0.23187903\n",
      "epoch: 12  batch: 34  loss: 0.30183402\n",
      "epoch: 12  batch: 35  loss: 0.32915810\n",
      "epoch: 12  batch: 36  loss: 0.33744934\n",
      "epoch: 12  batch: 37  loss: 0.31087908\n",
      "epoch: 12  batch: 38  loss: 0.20477320\n",
      "epoch: 12  batch: 39  loss: 0.31657085\n",
      "epoch: 12  batch: 40  loss: 0.25088909\n",
      "epoch: 12  batch: 41  loss: 0.25881016\n",
      "epoch: 12  batch: 42  loss: 0.30046460\n",
      "epoch: 12  batch: 43  loss: 0.23504475\n",
      "epoch: 12  batch: 44  loss: 0.33611169\n",
      "epoch: 12  batch: 45  loss: 0.18560204\n",
      "epoch: 12  batch: 46  loss: 0.19214348\n",
      "epoch: 12  batch: 47  loss: 0.33083084\n",
      "epoch: 12  batch: 48  loss: 0.33997244\n",
      "epoch: 12  batch: 49  loss: 0.30165526\n",
      "epoch: 12  batch: 50  loss: 0.28918394\n",
      "epoch: 12  batch: 51  loss: 0.16103904\n",
      "epoch: 12  batch: 52  loss: 0.21656528\n",
      "epoch: 12  batch: 53  loss: 0.26644599\n",
      "epoch: 12  batch: 54  loss: 0.28742474\n",
      "epoch: 12  batch: 55  loss: 0.21337736\n",
      "epoch: 12  batch: 56  loss: 0.23465766\n",
      "epoch: 12  batch: 57  loss: 0.30636746\n",
      "epoch: 12  batch: 58  loss: 0.24954797\n",
      "epoch: 12  batch: 59  loss: 0.25901353\n",
      "epoch: 12  batch: 60  loss: 0.25434208\n",
      "epoch: 12  batch: 61  loss: 0.27188089\n",
      "epoch: 12  batch: 62  loss: 0.20258161\n",
      "epoch: 12  batch: 63  loss: 0.23138645\n",
      "epoch: 12  batch: 64  loss: 0.30445650\n",
      "epoch: 12  batch: 65  loss: 0.31053278\n",
      "epoch: 12  batch: 66  loss: 0.30362746\n",
      "epoch: 12  batch: 67  loss: 0.21219163\n",
      "epoch: 12  batch: 68  loss: 0.25071201\n",
      "epoch: 12  batch: 69  loss: 0.15545171\n",
      "epoch: 12  batch: 70  loss: 0.24655840\n",
      "epoch: 12  batch: 71  loss: 0.30989653\n",
      "epoch: 12  batch: 72  loss: 0.24363570\n",
      "epoch: 12  batch: 73  loss: 0.23632191\n",
      "epoch: 12  batch: 74  loss: 0.24932456\n",
      "epoch: 12  batch: 75  loss: 0.20938350\n",
      "epoch: 12  batch: 76  loss: 0.24596690\n",
      "epoch: 12  batch: 77  loss: 0.30465308\n",
      "epoch: 12  batch: 78  loss: 0.35778782\n",
      "epoch: 12  batch: 79  loss: 0.30153859\n",
      "epoch: 12  batch: 80  loss: 0.28532025\n",
      "epoch: 12  batch: 81  loss: 0.44595122\n",
      "epoch: 12  batch: 82  loss: 0.24770127\n",
      "epoch: 12  batch: 83  loss: 0.20022905\n",
      "epoch: 12  batch: 84  loss: 0.31732300\n",
      "epoch: 12  batch: 85  loss: 0.21565136\n",
      "epoch: 12  batch: 86  loss: 0.19799624\n",
      "epoch: 12  batch: 87  loss: 0.26578879\n",
      "epoch: 13  batch: 1  loss: 0.22881840\n",
      "epoch: 13  batch: 2  loss: 0.26024103\n",
      "epoch: 13  batch: 3  loss: 0.26424333\n",
      "epoch: 13  batch: 4  loss: 0.27316496\n",
      "epoch: 13  batch: 5  loss: 0.29935580\n",
      "epoch: 13  batch: 6  loss: 0.22568589\n",
      "epoch: 13  batch: 7  loss: 0.25266248\n",
      "epoch: 13  batch: 8  loss: 0.24408957\n",
      "epoch: 13  batch: 9  loss: 0.29540843\n",
      "epoch: 13  batch: 10  loss: 0.25368050\n",
      "epoch: 13  batch: 11  loss: 0.25827980\n",
      "epoch: 13  batch: 12  loss: 0.24398634\n",
      "epoch: 13  batch: 13  loss: 0.26454324\n",
      "epoch: 13  batch: 14  loss: 0.26610038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13  batch: 15  loss: 0.20740901\n",
      "epoch: 13  batch: 16  loss: 0.22199774\n",
      "epoch: 13  batch: 17  loss: 0.29816714\n",
      "epoch: 13  batch: 18  loss: 0.19046247\n",
      "epoch: 13  batch: 19  loss: 0.23281321\n",
      "epoch: 13  batch: 20  loss: 0.26905581\n",
      "epoch: 13  batch: 21  loss: 0.25107220\n",
      "epoch: 13  batch: 22  loss: 0.26248905\n",
      "epoch: 13  batch: 23  loss: 0.13796946\n",
      "epoch: 13  batch: 24  loss: 0.25465935\n",
      "epoch: 13  batch: 25  loss: 0.27455893\n",
      "epoch: 13  batch: 26  loss: 0.30966595\n",
      "epoch: 13  batch: 27  loss: 0.24761333\n",
      "epoch: 13  batch: 28  loss: 0.25661573\n",
      "epoch: 13  batch: 29  loss: 0.25813743\n",
      "epoch: 13  batch: 30  loss: 0.32127014\n",
      "epoch: 13  batch: 31  loss: 0.32638082\n",
      "epoch: 13  batch: 32  loss: 0.24695471\n",
      "epoch: 13  batch: 33  loss: 0.26597556\n",
      "epoch: 13  batch: 34  loss: 0.23752859\n",
      "epoch: 13  batch: 35  loss: 0.29375905\n",
      "epoch: 13  batch: 36  loss: 0.23381642\n",
      "epoch: 13  batch: 37  loss: 0.25480488\n",
      "epoch: 13  batch: 38  loss: 0.26637900\n",
      "epoch: 13  batch: 39  loss: 0.25706977\n",
      "epoch: 13  batch: 40  loss: 0.17229265\n",
      "epoch: 13  batch: 41  loss: 0.25048625\n",
      "epoch: 13  batch: 42  loss: 0.32292157\n",
      "epoch: 13  batch: 43  loss: 0.27062282\n",
      "epoch: 13  batch: 44  loss: 0.39631623\n",
      "epoch: 13  batch: 45  loss: 0.25976098\n",
      "epoch: 13  batch: 46  loss: 0.19297904\n",
      "epoch: 13  batch: 47  loss: 0.25648177\n",
      "epoch: 13  batch: 48  loss: 0.23989502\n",
      "epoch: 13  batch: 49  loss: 0.26160812\n",
      "epoch: 13  batch: 50  loss: 0.22576539\n",
      "epoch: 13  batch: 51  loss: 0.21551569\n",
      "epoch: 13  batch: 52  loss: 0.23919725\n",
      "epoch: 13  batch: 53  loss: 0.22006536\n",
      "epoch: 13  batch: 54  loss: 0.32873529\n",
      "epoch: 13  batch: 55  loss: 0.36162338\n",
      "epoch: 13  batch: 56  loss: 0.25692481\n",
      "epoch: 13  batch: 57  loss: 0.23776601\n",
      "epoch: 13  batch: 58  loss: 0.25680521\n",
      "epoch: 13  batch: 59  loss: 0.23191381\n",
      "epoch: 13  batch: 60  loss: 0.23761545\n",
      "epoch: 13  batch: 61  loss: 0.23115270\n",
      "epoch: 13  batch: 62  loss: 0.28477645\n",
      "epoch: 13  batch: 63  loss: 0.24715510\n",
      "epoch: 13  batch: 64  loss: 0.23914316\n",
      "epoch: 13  batch: 65  loss: 0.30683631\n",
      "epoch: 13  batch: 66  loss: 0.23372896\n",
      "epoch: 13  batch: 67  loss: 0.33238241\n",
      "epoch: 13  batch: 68  loss: 0.26530424\n",
      "epoch: 13  batch: 69  loss: 0.24437954\n",
      "epoch: 13  batch: 70  loss: 0.22487007\n",
      "epoch: 13  batch: 71  loss: 0.21897902\n",
      "epoch: 13  batch: 72  loss: 0.27021149\n",
      "epoch: 13  batch: 73  loss: 0.27833167\n",
      "epoch: 13  batch: 74  loss: 0.23195431\n",
      "epoch: 13  batch: 75  loss: 0.21273556\n",
      "epoch: 13  batch: 76  loss: 0.33568358\n",
      "epoch: 13  batch: 77  loss: 0.24563971\n",
      "epoch: 13  batch: 78  loss: 0.23910193\n",
      "epoch: 13  batch: 79  loss: 0.26580572\n",
      "epoch: 13  batch: 80  loss: 0.24125801\n",
      "epoch: 13  batch: 81  loss: 0.32626227\n",
      "epoch: 13  batch: 82  loss: 0.23408087\n",
      "epoch: 13  batch: 83  loss: 0.25159046\n",
      "epoch: 13  batch: 84  loss: 0.27351856\n",
      "epoch: 13  batch: 85  loss: 0.20384547\n",
      "epoch: 13  batch: 86  loss: 0.20729916\n",
      "epoch: 13  batch: 87  loss: 0.28293580\n",
      "epoch: 14  batch: 1  loss: 0.23728938\n",
      "epoch: 14  batch: 2  loss: 0.24928129\n",
      "epoch: 14  batch: 3  loss: 0.25004137\n",
      "epoch: 14  batch: 4  loss: 0.29865044\n",
      "epoch: 14  batch: 5  loss: 0.24503870\n",
      "epoch: 14  batch: 6  loss: 0.23972964\n",
      "epoch: 14  batch: 7  loss: 0.21636544\n",
      "epoch: 14  batch: 8  loss: 0.37373647\n",
      "epoch: 14  batch: 9  loss: 0.26909968\n",
      "epoch: 14  batch: 10  loss: 0.22121496\n",
      "epoch: 14  batch: 11  loss: 0.20220615\n",
      "epoch: 14  batch: 12  loss: 0.25308883\n",
      "epoch: 14  batch: 13  loss: 0.26504612\n",
      "epoch: 14  batch: 14  loss: 0.32203981\n",
      "epoch: 14  batch: 15  loss: 0.26558122\n",
      "epoch: 14  batch: 16  loss: 0.29654187\n",
      "epoch: 14  batch: 17  loss: 0.21199074\n",
      "epoch: 14  batch: 18  loss: 0.23355593\n",
      "epoch: 14  batch: 19  loss: 0.27574223\n",
      "epoch: 14  batch: 20  loss: 0.28172040\n",
      "epoch: 14  batch: 21  loss: 0.27148083\n",
      "epoch: 14  batch: 22  loss: 0.25132650\n",
      "epoch: 14  batch: 23  loss: 0.23478261\n",
      "epoch: 14  batch: 24  loss: 0.31976998\n",
      "epoch: 14  batch: 25  loss: 0.25495085\n",
      "epoch: 14  batch: 26  loss: 0.27234969\n",
      "epoch: 14  batch: 27  loss: 0.19960433\n",
      "epoch: 14  batch: 28  loss: 0.25229034\n",
      "epoch: 14  batch: 29  loss: 0.24221884\n",
      "epoch: 14  batch: 30  loss: 0.29399166\n",
      "epoch: 14  batch: 31  loss: 0.28813380\n",
      "epoch: 14  batch: 32  loss: 0.17580368\n",
      "epoch: 14  batch: 33  loss: 0.27736562\n",
      "epoch: 14  batch: 34  loss: 0.27869028\n",
      "epoch: 14  batch: 35  loss: 0.35383806\n",
      "epoch: 14  batch: 36  loss: 0.24952611\n",
      "epoch: 14  batch: 37  loss: 0.22530460\n",
      "epoch: 14  batch: 38  loss: 0.23469226\n",
      "epoch: 14  batch: 39  loss: 0.23781857\n",
      "epoch: 14  batch: 40  loss: 0.27253628\n",
      "epoch: 14  batch: 41  loss: 0.18895383\n",
      "epoch: 14  batch: 42  loss: 0.19929060\n",
      "epoch: 14  batch: 43  loss: 0.25192398\n",
      "epoch: 14  batch: 44  loss: 0.26061699\n",
      "epoch: 14  batch: 45  loss: 0.29013616\n",
      "epoch: 14  batch: 46  loss: 0.26295146\n",
      "epoch: 14  batch: 47  loss: 0.31407192\n",
      "epoch: 14  batch: 48  loss: 0.24637920\n",
      "epoch: 14  batch: 49  loss: 0.32082140\n",
      "epoch: 14  batch: 50  loss: 0.25169146\n",
      "epoch: 14  batch: 51  loss: 0.26577872\n",
      "epoch: 14  batch: 52  loss: 0.16412383\n",
      "epoch: 14  batch: 53  loss: 0.24480434\n",
      "epoch: 14  batch: 54  loss: 0.28521994\n",
      "epoch: 14  batch: 55  loss: 0.25088048\n",
      "epoch: 14  batch: 56  loss: 0.21286282\n",
      "epoch: 14  batch: 57  loss: 0.27188385\n",
      "epoch: 14  batch: 58  loss: 0.29403600\n",
      "epoch: 14  batch: 59  loss: 0.27856836\n",
      "epoch: 14  batch: 60  loss: 0.20823492\n",
      "epoch: 14  batch: 61  loss: 0.31377321\n",
      "epoch: 14  batch: 62  loss: 0.19436328\n",
      "epoch: 14  batch: 63  loss: 0.22469242\n",
      "epoch: 14  batch: 64  loss: 0.25118968\n",
      "epoch: 14  batch: 65  loss: 0.23839901\n",
      "epoch: 14  batch: 66  loss: 0.25784943\n",
      "epoch: 14  batch: 67  loss: 0.41158926\n",
      "epoch: 14  batch: 68  loss: 0.24346018\n",
      "epoch: 14  batch: 69  loss: 0.27005315\n",
      "epoch: 14  batch: 70  loss: 0.26836482\n",
      "epoch: 14  batch: 71  loss: 0.23486583\n",
      "epoch: 14  batch: 72  loss: 0.38558909\n",
      "epoch: 14  batch: 73  loss: 0.24499916\n",
      "epoch: 14  batch: 74  loss: 0.23651373\n",
      "epoch: 14  batch: 75  loss: 0.28974706\n",
      "epoch: 14  batch: 76  loss: 0.26425597\n",
      "epoch: 14  batch: 77  loss: 0.21536395\n",
      "epoch: 14  batch: 78  loss: 0.23041408\n",
      "epoch: 14  batch: 79  loss: 0.33093587\n",
      "epoch: 14  batch: 80  loss: 0.25073859\n",
      "epoch: 14  batch: 81  loss: 0.30026430\n",
      "epoch: 14  batch: 82  loss: 0.27677679\n",
      "epoch: 14  batch: 83  loss: 0.33192623\n",
      "epoch: 14  batch: 84  loss: 0.26880786\n",
      "epoch: 14  batch: 85  loss: 0.16708852\n",
      "epoch: 14  batch: 86  loss: 0.28394553\n",
      "epoch: 14  batch: 87  loss: 0.18073307\n",
      "epoch: 15  batch: 1  loss: 0.24020661\n",
      "epoch: 15  batch: 2  loss: 0.24851684\n",
      "epoch: 15  batch: 3  loss: 0.26343527\n",
      "epoch: 15  batch: 4  loss: 0.24695638\n",
      "epoch: 15  batch: 5  loss: 0.33876660\n",
      "epoch: 15  batch: 6  loss: 0.27742666\n",
      "epoch: 15  batch: 7  loss: 0.24528219\n",
      "epoch: 15  batch: 8  loss: 0.22842140\n",
      "epoch: 15  batch: 9  loss: 0.18924683\n",
      "epoch: 15  batch: 10  loss: 0.26323500\n",
      "epoch: 15  batch: 11  loss: 0.30012977\n",
      "epoch: 15  batch: 12  loss: 0.29177466\n",
      "epoch: 15  batch: 13  loss: 0.23867884\n",
      "epoch: 15  batch: 14  loss: 0.28127342\n",
      "epoch: 15  batch: 15  loss: 0.22552490\n",
      "epoch: 15  batch: 16  loss: 0.22876795\n",
      "epoch: 15  batch: 17  loss: 0.22605467\n",
      "epoch: 15  batch: 18  loss: 0.26572293\n",
      "epoch: 15  batch: 19  loss: 0.22746211\n",
      "epoch: 15  batch: 20  loss: 0.33025870\n",
      "epoch: 15  batch: 21  loss: 0.36108744\n",
      "epoch: 15  batch: 22  loss: 0.26468086\n",
      "epoch: 15  batch: 23  loss: 0.27516454\n",
      "epoch: 15  batch: 24  loss: 0.22408052\n",
      "epoch: 15  batch: 25  loss: 0.19885536\n",
      "epoch: 15  batch: 26  loss: 0.21068412\n",
      "epoch: 15  batch: 27  loss: 0.23534998\n",
      "epoch: 15  batch: 28  loss: 0.23881572\n",
      "epoch: 15  batch: 29  loss: 0.32378650\n",
      "epoch: 15  batch: 30  loss: 0.27542984\n",
      "epoch: 15  batch: 31  loss: 0.28272527\n",
      "epoch: 15  batch: 32  loss: 0.19289163\n",
      "epoch: 15  batch: 33  loss: 0.27378172\n",
      "epoch: 15  batch: 34  loss: 0.22932458\n",
      "epoch: 15  batch: 35  loss: 0.22618861\n",
      "epoch: 15  batch: 36  loss: 0.35054296\n",
      "epoch: 15  batch: 37  loss: 0.38904688\n",
      "epoch: 15  batch: 38  loss: 0.22361694\n",
      "epoch: 15  batch: 39  loss: 0.22786656\n",
      "epoch: 15  batch: 40  loss: 0.29622418\n",
      "epoch: 15  batch: 41  loss: 0.28176680\n",
      "epoch: 15  batch: 42  loss: 0.24218993\n",
      "epoch: 15  batch: 43  loss: 0.21659191\n",
      "epoch: 15  batch: 44  loss: 0.35778457\n",
      "epoch: 15  batch: 45  loss: 0.32326871\n",
      "epoch: 15  batch: 46  loss: 0.34382564\n",
      "epoch: 15  batch: 47  loss: 0.30465305\n",
      "epoch: 15  batch: 48  loss: 0.20744191\n",
      "epoch: 15  batch: 49  loss: 0.23583075\n",
      "epoch: 15  batch: 50  loss: 0.20005742\n",
      "epoch: 15  batch: 51  loss: 0.33242306\n",
      "epoch: 15  batch: 52  loss: 0.29668593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15  batch: 53  loss: 0.18711297\n",
      "epoch: 15  batch: 54  loss: 0.31147185\n",
      "epoch: 15  batch: 55  loss: 0.34367597\n",
      "epoch: 15  batch: 56  loss: 0.25339267\n",
      "epoch: 15  batch: 57  loss: 0.25248015\n",
      "epoch: 15  batch: 58  loss: 0.30370420\n",
      "epoch: 15  batch: 59  loss: 0.24517398\n",
      "epoch: 15  batch: 60  loss: 0.21199809\n",
      "epoch: 15  batch: 61  loss: 0.18550436\n",
      "epoch: 15  batch: 62  loss: 0.33314738\n",
      "epoch: 15  batch: 63  loss: 0.28228754\n",
      "epoch: 15  batch: 64  loss: 0.34733152\n",
      "epoch: 15  batch: 65  loss: 0.17870417\n",
      "epoch: 15  batch: 66  loss: 0.24759249\n",
      "epoch: 15  batch: 67  loss: 0.22121313\n",
      "epoch: 15  batch: 68  loss: 0.27279022\n",
      "epoch: 15  batch: 69  loss: 0.23498604\n",
      "epoch: 15  batch: 70  loss: 0.25586340\n",
      "epoch: 15  batch: 71  loss: 0.35831594\n",
      "epoch: 15  batch: 72  loss: 0.21419351\n",
      "epoch: 15  batch: 73  loss: 0.28262424\n",
      "epoch: 15  batch: 74  loss: 0.23807022\n",
      "epoch: 15  batch: 75  loss: 0.23585398\n",
      "epoch: 15  batch: 76  loss: 0.20727998\n",
      "epoch: 15  batch: 77  loss: 0.23852549\n",
      "epoch: 15  batch: 78  loss: 0.34164515\n",
      "epoch: 15  batch: 79  loss: 0.24570012\n",
      "epoch: 15  batch: 80  loss: 0.21582019\n",
      "epoch: 15  batch: 81  loss: 0.23998894\n",
      "epoch: 15  batch: 82  loss: 0.26752514\n",
      "epoch: 15  batch: 83  loss: 0.26543117\n",
      "epoch: 15  batch: 84  loss: 0.32072514\n",
      "epoch: 15  batch: 85  loss: 0.20013045\n",
      "epoch: 15  batch: 86  loss: 0.24693131\n",
      "epoch: 15  batch: 87  loss: 0.22949468\n",
      "epoch: 16  batch: 1  loss: 0.26815861\n",
      "epoch: 16  batch: 2  loss: 0.30653217\n",
      "epoch: 16  batch: 3  loss: 0.29375720\n",
      "epoch: 16  batch: 4  loss: 0.25975668\n",
      "epoch: 16  batch: 5  loss: 0.17872275\n",
      "epoch: 16  batch: 6  loss: 0.21604539\n",
      "epoch: 16  batch: 7  loss: 0.16549079\n",
      "epoch: 16  batch: 8  loss: 0.69953895\n",
      "epoch: 16  batch: 9  loss: 0.21219586\n",
      "epoch: 16  batch: 10  loss: 0.21738729\n",
      "epoch: 16  batch: 11  loss: 0.21359931\n",
      "epoch: 16  batch: 12  loss: 0.23834792\n",
      "epoch: 16  batch: 13  loss: 0.28888279\n",
      "epoch: 16  batch: 14  loss: 0.31223100\n",
      "epoch: 16  batch: 15  loss: 0.21220241\n",
      "epoch: 16  batch: 16  loss: 0.23192890\n",
      "epoch: 16  batch: 17  loss: 0.26278645\n",
      "epoch: 16  batch: 18  loss: 0.21212906\n",
      "epoch: 16  batch: 19  loss: 0.24653320\n",
      "epoch: 16  batch: 20  loss: 0.21555617\n",
      "epoch: 16  batch: 21  loss: 0.30379778\n",
      "epoch: 16  batch: 22  loss: 0.27947983\n",
      "epoch: 16  batch: 23  loss: 0.21917520\n",
      "epoch: 16  batch: 24  loss: 0.23228219\n",
      "epoch: 16  batch: 25  loss: 0.25654045\n",
      "epoch: 16  batch: 26  loss: 0.28430521\n",
      "epoch: 16  batch: 27  loss: 0.25563657\n",
      "epoch: 16  batch: 28  loss: 0.28196776\n",
      "epoch: 16  batch: 29  loss: 0.21501344\n",
      "epoch: 16  batch: 30  loss: 0.20811711\n",
      "epoch: 16  batch: 31  loss: 0.18762141\n",
      "epoch: 16  batch: 32  loss: 0.29475105\n",
      "epoch: 16  batch: 33  loss: 0.25187716\n",
      "epoch: 16  batch: 34  loss: 0.19545610\n",
      "epoch: 16  batch: 35  loss: 0.31643075\n",
      "epoch: 16  batch: 36  loss: 0.27155036\n",
      "epoch: 16  batch: 37  loss: 0.32142171\n",
      "epoch: 16  batch: 38  loss: 0.23766431\n",
      "epoch: 16  batch: 39  loss: 0.19001129\n",
      "epoch: 16  batch: 40  loss: 0.28960612\n",
      "epoch: 16  batch: 41  loss: 0.23523302\n",
      "epoch: 16  batch: 42  loss: 0.20554289\n",
      "epoch: 16  batch: 43  loss: 0.24390665\n",
      "epoch: 16  batch: 44  loss: 0.24691948\n",
      "epoch: 16  batch: 45  loss: 0.20916571\n",
      "epoch: 16  batch: 46  loss: 0.31571391\n",
      "epoch: 16  batch: 47  loss: 0.30170029\n",
      "epoch: 16  batch: 48  loss: 0.21311736\n",
      "epoch: 16  batch: 49  loss: 0.20471914\n",
      "epoch: 16  batch: 50  loss: 0.24720639\n",
      "epoch: 16  batch: 51  loss: 0.22614266\n",
      "epoch: 16  batch: 52  loss: 0.23857787\n",
      "epoch: 16  batch: 53  loss: 0.27288002\n",
      "epoch: 16  batch: 54  loss: 0.23615648\n",
      "epoch: 16  batch: 55  loss: 0.25308651\n",
      "epoch: 16  batch: 56  loss: 0.29905114\n",
      "epoch: 16  batch: 57  loss: 0.24598359\n",
      "epoch: 16  batch: 58  loss: 0.18640374\n",
      "epoch: 16  batch: 59  loss: 0.30459177\n",
      "epoch: 16  batch: 60  loss: 0.22675896\n",
      "epoch: 16  batch: 61  loss: 0.23423330\n",
      "epoch: 16  batch: 62  loss: 0.32789791\n",
      "epoch: 16  batch: 63  loss: 0.24171211\n",
      "epoch: 16  batch: 64  loss: 0.21986496\n",
      "epoch: 16  batch: 65  loss: 0.22698629\n",
      "epoch: 16  batch: 66  loss: 0.23418464\n",
      "epoch: 16  batch: 67  loss: 0.21645425\n",
      "epoch: 16  batch: 68  loss: 0.15757543\n",
      "epoch: 16  batch: 69  loss: 0.19444565\n",
      "epoch: 16  batch: 70  loss: 0.36032075\n",
      "epoch: 16  batch: 71  loss: 0.28022048\n",
      "epoch: 16  batch: 72  loss: 0.28167981\n",
      "epoch: 16  batch: 73  loss: 0.27305230\n",
      "epoch: 16  batch: 74  loss: 0.36663592\n",
      "epoch: 16  batch: 75  loss: 0.32321957\n",
      "epoch: 16  batch: 76  loss: 0.24733825\n",
      "epoch: 16  batch: 77  loss: 0.25029942\n",
      "epoch: 16  batch: 78  loss: 0.30809054\n",
      "epoch: 16  batch: 79  loss: 0.24545690\n",
      "epoch: 16  batch: 80  loss: 0.25035959\n",
      "epoch: 16  batch: 81  loss: 0.29373711\n",
      "epoch: 16  batch: 82  loss: 0.22709675\n",
      "epoch: 16  batch: 83  loss: 0.20004995\n",
      "epoch: 16  batch: 84  loss: 0.22552347\n",
      "epoch: 16  batch: 85  loss: 0.25370136\n",
      "epoch: 16  batch: 86  loss: 0.24528404\n",
      "epoch: 16  batch: 87  loss: 0.24511121\n",
      "epoch: 17  batch: 1  loss: 0.17649068\n",
      "epoch: 17  batch: 2  loss: 0.20153572\n",
      "epoch: 17  batch: 3  loss: 0.28222686\n",
      "epoch: 17  batch: 4  loss: 0.17452113\n",
      "epoch: 17  batch: 5  loss: 0.22495575\n",
      "epoch: 17  batch: 6  loss: 0.20921317\n",
      "epoch: 17  batch: 7  loss: 0.21645895\n",
      "epoch: 17  batch: 8  loss: 0.24674959\n",
      "epoch: 17  batch: 9  loss: 0.17560591\n",
      "epoch: 17  batch: 10  loss: 0.21966735\n",
      "epoch: 17  batch: 11  loss: 0.20243527\n",
      "epoch: 17  batch: 12  loss: 0.25765130\n",
      "epoch: 17  batch: 13  loss: 0.26709303\n",
      "epoch: 17  batch: 14  loss: 0.28425896\n",
      "epoch: 17  batch: 15  loss: 0.21521890\n",
      "epoch: 17  batch: 16  loss: 0.28312242\n",
      "epoch: 17  batch: 17  loss: 0.24694398\n",
      "epoch: 17  batch: 18  loss: 0.24597223\n",
      "epoch: 17  batch: 19  loss: 0.22818853\n",
      "epoch: 17  batch: 20  loss: 0.19198079\n",
      "epoch: 17  batch: 21  loss: 0.25551471\n",
      "epoch: 17  batch: 22  loss: 0.26414824\n",
      "epoch: 17  batch: 23  loss: 0.31055152\n",
      "epoch: 17  batch: 24  loss: 0.23611610\n",
      "epoch: 17  batch: 25  loss: 0.23427239\n",
      "epoch: 17  batch: 26  loss: 0.26654717\n",
      "epoch: 17  batch: 27  loss: 0.29655930\n",
      "epoch: 17  batch: 28  loss: 0.20380171\n",
      "epoch: 17  batch: 29  loss: 0.25195712\n",
      "epoch: 17  batch: 30  loss: 0.28789556\n",
      "epoch: 17  batch: 31  loss: 0.26780069\n",
      "epoch: 17  batch: 32  loss: 0.26221213\n",
      "epoch: 17  batch: 33  loss: 0.23995595\n",
      "epoch: 17  batch: 34  loss: 0.27467525\n",
      "epoch: 17  batch: 35  loss: 0.22524683\n",
      "epoch: 17  batch: 36  loss: 0.22175421\n",
      "epoch: 17  batch: 37  loss: 0.20964114\n",
      "epoch: 17  batch: 38  loss: 0.28649375\n",
      "epoch: 17  batch: 39  loss: 0.29775003\n",
      "epoch: 17  batch: 40  loss: 0.27586347\n",
      "epoch: 17  batch: 41  loss: 0.23899442\n",
      "epoch: 17  batch: 42  loss: 0.29882610\n",
      "epoch: 17  batch: 43  loss: 0.26144025\n",
      "epoch: 17  batch: 44  loss: 0.19406871\n",
      "epoch: 17  batch: 45  loss: 0.22367404\n",
      "epoch: 17  batch: 46  loss: 0.20989844\n",
      "epoch: 17  batch: 47  loss: 0.26309499\n",
      "epoch: 17  batch: 48  loss: 0.26246786\n",
      "epoch: 17  batch: 49  loss: 0.23857065\n",
      "epoch: 17  batch: 50  loss: 0.26093593\n",
      "epoch: 17  batch: 51  loss: 0.25253099\n",
      "epoch: 17  batch: 52  loss: 0.26912186\n",
      "epoch: 17  batch: 53  loss: 0.26995277\n",
      "epoch: 17  batch: 54  loss: 0.16618453\n",
      "epoch: 17  batch: 55  loss: 0.24920081\n",
      "epoch: 17  batch: 56  loss: 0.26439527\n",
      "epoch: 17  batch: 57  loss: 0.21987070\n",
      "epoch: 17  batch: 58  loss: 0.21893601\n",
      "epoch: 17  batch: 59  loss: 0.25634369\n",
      "epoch: 17  batch: 60  loss: 0.18875781\n",
      "epoch: 17  batch: 61  loss: 0.23592727\n",
      "epoch: 17  batch: 62  loss: 0.19475406\n",
      "epoch: 17  batch: 63  loss: 0.17003331\n",
      "epoch: 17  batch: 64  loss: 0.28958324\n",
      "epoch: 17  batch: 65  loss: 0.33851084\n",
      "epoch: 17  batch: 66  loss: 0.35863131\n",
      "epoch: 17  batch: 67  loss: 0.27574006\n",
      "epoch: 17  batch: 68  loss: 0.23896840\n",
      "epoch: 17  batch: 69  loss: 0.15895185\n",
      "epoch: 17  batch: 70  loss: 0.29302302\n",
      "epoch: 17  batch: 71  loss: 0.16273420\n",
      "epoch: 17  batch: 72  loss: 0.24498893\n",
      "epoch: 17  batch: 73  loss: 0.14989294\n",
      "epoch: 17  batch: 74  loss: 0.20131803\n",
      "epoch: 17  batch: 75  loss: 0.20334403\n",
      "epoch: 17  batch: 76  loss: 0.17030196\n",
      "epoch: 17  batch: 77  loss: 0.26299849\n",
      "epoch: 17  batch: 78  loss: 0.28958073\n",
      "epoch: 17  batch: 79  loss: 0.24891731\n",
      "epoch: 17  batch: 80  loss: 0.23726436\n",
      "epoch: 17  batch: 81  loss: 0.20766129\n",
      "epoch: 17  batch: 82  loss: 0.20276886\n",
      "epoch: 17  batch: 83  loss: 0.17263857\n",
      "epoch: 17  batch: 84  loss: 0.18702832\n",
      "epoch: 17  batch: 85  loss: 0.17746440\n",
      "epoch: 17  batch: 86  loss: 0.27293569\n",
      "epoch: 17  batch: 87  loss: 0.22885518\n",
      "epoch: 18  batch: 1  loss: 0.18010990\n",
      "epoch: 18  batch: 2  loss: 0.25695825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18  batch: 3  loss: 0.20957199\n",
      "epoch: 18  batch: 4  loss: 0.20398459\n",
      "epoch: 18  batch: 5  loss: 0.18209389\n",
      "epoch: 18  batch: 6  loss: 0.24688573\n",
      "epoch: 18  batch: 7  loss: 0.21448934\n",
      "epoch: 18  batch: 8  loss: 0.18220466\n",
      "epoch: 18  batch: 9  loss: 0.18279342\n",
      "epoch: 18  batch: 10  loss: 0.16843431\n",
      "epoch: 18  batch: 11  loss: 0.21949175\n",
      "epoch: 18  batch: 12  loss: 0.19740966\n",
      "epoch: 18  batch: 13  loss: 0.27844572\n",
      "epoch: 18  batch: 14  loss: 0.19374883\n",
      "epoch: 18  batch: 15  loss: 0.23784697\n",
      "epoch: 18  batch: 16  loss: 0.18000215\n",
      "epoch: 18  batch: 17  loss: 0.26802930\n",
      "epoch: 18  batch: 18  loss: 0.22803514\n",
      "epoch: 18  batch: 19  loss: 0.24684435\n",
      "epoch: 18  batch: 20  loss: 0.26117486\n",
      "epoch: 18  batch: 21  loss: 0.26650509\n",
      "epoch: 18  batch: 22  loss: 0.23915043\n",
      "epoch: 18  batch: 23  loss: 0.17368436\n",
      "epoch: 18  batch: 24  loss: 0.24276239\n",
      "epoch: 18  batch: 25  loss: 0.27307975\n",
      "epoch: 18  batch: 26  loss: 0.20291194\n",
      "epoch: 18  batch: 27  loss: 0.30063176\n",
      "epoch: 18  batch: 28  loss: 0.17515826\n",
      "epoch: 18  batch: 29  loss: 0.21504496\n",
      "epoch: 18  batch: 30  loss: 0.16123872\n",
      "epoch: 18  batch: 31  loss: 0.20069794\n",
      "epoch: 18  batch: 32  loss: 0.24524941\n",
      "epoch: 18  batch: 33  loss: 0.16298473\n",
      "epoch: 18  batch: 34  loss: 0.18428363\n",
      "epoch: 18  batch: 35  loss: 0.19580245\n",
      "epoch: 18  batch: 36  loss: 0.17230465\n",
      "epoch: 18  batch: 37  loss: 0.17572276\n",
      "epoch: 18  batch: 38  loss: 0.29506895\n",
      "epoch: 18  batch: 39  loss: 0.20439871\n",
      "epoch: 18  batch: 40  loss: 0.19392307\n",
      "epoch: 18  batch: 41  loss: 0.29065686\n",
      "epoch: 18  batch: 42  loss: 0.19317621\n",
      "epoch: 18  batch: 43  loss: 0.21964879\n",
      "epoch: 18  batch: 44  loss: 0.26311368\n",
      "epoch: 18  batch: 45  loss: 0.24401815\n",
      "epoch: 18  batch: 46  loss: 0.28748858\n",
      "epoch: 18  batch: 47  loss: 0.30806854\n",
      "epoch: 18  batch: 48  loss: 0.18837398\n",
      "epoch: 18  batch: 49  loss: 0.19918948\n",
      "epoch: 18  batch: 50  loss: 0.33287132\n",
      "epoch: 18  batch: 51  loss: 0.18062013\n",
      "epoch: 18  batch: 52  loss: 0.21348821\n",
      "epoch: 18  batch: 53  loss: 0.27255610\n",
      "epoch: 18  batch: 54  loss: 0.21435608\n",
      "epoch: 18  batch: 55  loss: 0.26777592\n",
      "epoch: 18  batch: 56  loss: 0.25624993\n",
      "epoch: 18  batch: 57  loss: 0.23103926\n",
      "epoch: 18  batch: 58  loss: 0.26979899\n",
      "epoch: 18  batch: 59  loss: 0.16830166\n",
      "epoch: 18  batch: 60  loss: 0.26177496\n",
      "epoch: 18  batch: 61  loss: 0.20986535\n",
      "epoch: 18  batch: 62  loss: 0.26216805\n",
      "epoch: 18  batch: 63  loss: 0.20717357\n",
      "epoch: 18  batch: 64  loss: 0.47146967\n",
      "epoch: 18  batch: 65  loss: 0.21340047\n",
      "epoch: 18  batch: 66  loss: 0.20801212\n",
      "epoch: 18  batch: 67  loss: 0.21977155\n",
      "epoch: 18  batch: 68  loss: 0.24190581\n",
      "epoch: 18  batch: 69  loss: 0.23095757\n",
      "epoch: 18  batch: 70  loss: 0.30550605\n",
      "epoch: 18  batch: 71  loss: 0.31305471\n",
      "epoch: 18  batch: 72  loss: 0.15330271\n",
      "epoch: 18  batch: 73  loss: 0.27909154\n",
      "epoch: 18  batch: 74  loss: 0.19185281\n",
      "epoch: 18  batch: 75  loss: 0.26681250\n",
      "epoch: 18  batch: 76  loss: 0.20637020\n",
      "epoch: 18  batch: 77  loss: 0.18555452\n",
      "epoch: 18  batch: 78  loss: 0.20704356\n",
      "epoch: 18  batch: 79  loss: 0.26928553\n",
      "epoch: 18  batch: 80  loss: 0.20099680\n",
      "epoch: 18  batch: 81  loss: 0.26111120\n",
      "epoch: 18  batch: 82  loss: 0.23817585\n",
      "epoch: 18  batch: 83  loss: 0.23374744\n",
      "epoch: 18  batch: 84  loss: 0.27092534\n",
      "epoch: 18  batch: 85  loss: 0.32595769\n",
      "epoch: 18  batch: 86  loss: 0.20653866\n",
      "epoch: 18  batch: 87  loss: 0.22673611\n",
      "epoch: 19  batch: 1  loss: 0.23402609\n",
      "epoch: 19  batch: 2  loss: 0.24040283\n",
      "epoch: 19  batch: 3  loss: 0.21599042\n",
      "epoch: 19  batch: 4  loss: 0.16801445\n",
      "epoch: 19  batch: 5  loss: 0.20447920\n",
      "epoch: 19  batch: 6  loss: 0.25444448\n",
      "epoch: 19  batch: 7  loss: 0.22675429\n",
      "epoch: 19  batch: 8  loss: 0.26765501\n",
      "epoch: 19  batch: 9  loss: 0.21530813\n",
      "epoch: 19  batch: 10  loss: 0.25593084\n",
      "epoch: 19  batch: 11  loss: 0.24934818\n",
      "epoch: 19  batch: 12  loss: 0.29449767\n",
      "epoch: 19  batch: 13  loss: 0.31702101\n",
      "epoch: 19  batch: 14  loss: 0.27842399\n",
      "epoch: 19  batch: 15  loss: 0.27367747\n",
      "epoch: 19  batch: 16  loss: 0.23739079\n",
      "epoch: 19  batch: 17  loss: 0.21595208\n",
      "epoch: 19  batch: 18  loss: 0.21883297\n",
      "epoch: 19  batch: 19  loss: 0.24746260\n",
      "epoch: 19  batch: 20  loss: 0.28399405\n",
      "epoch: 19  batch: 21  loss: 0.14197250\n",
      "epoch: 19  batch: 22  loss: 0.23295026\n",
      "epoch: 19  batch: 23  loss: 0.19662337\n",
      "epoch: 19  batch: 24  loss: 0.22287022\n",
      "epoch: 19  batch: 25  loss: 0.17818446\n",
      "epoch: 19  batch: 26  loss: 0.22804506\n",
      "epoch: 19  batch: 27  loss: 0.21804038\n",
      "epoch: 19  batch: 28  loss: 0.31088921\n",
      "epoch: 19  batch: 29  loss: 0.18854870\n",
      "epoch: 19  batch: 30  loss: 0.16427742\n",
      "epoch: 19  batch: 31  loss: 0.23303296\n",
      "epoch: 19  batch: 32  loss: 0.22587848\n",
      "epoch: 19  batch: 33  loss: 0.32594943\n",
      "epoch: 19  batch: 34  loss: 0.17751564\n",
      "epoch: 19  batch: 35  loss: 0.21788175\n",
      "epoch: 19  batch: 36  loss: 0.29583997\n",
      "epoch: 19  batch: 37  loss: 0.30137783\n",
      "epoch: 19  batch: 38  loss: 0.23516595\n",
      "epoch: 19  batch: 39  loss: 0.18947558\n",
      "epoch: 19  batch: 40  loss: 0.18150868\n",
      "epoch: 19  batch: 41  loss: 0.19855487\n",
      "epoch: 19  batch: 42  loss: 0.18413879\n",
      "epoch: 19  batch: 43  loss: 0.20620981\n",
      "epoch: 19  batch: 44  loss: 0.19380081\n",
      "epoch: 19  batch: 45  loss: 0.18040904\n",
      "epoch: 19  batch: 46  loss: 0.22107658\n",
      "epoch: 19  batch: 47  loss: 0.21948476\n",
      "epoch: 19  batch: 48  loss: 0.18119203\n",
      "epoch: 19  batch: 49  loss: 0.26528120\n",
      "epoch: 19  batch: 50  loss: 0.21391810\n",
      "epoch: 19  batch: 51  loss: 0.27773103\n",
      "epoch: 19  batch: 52  loss: 0.29214519\n",
      "epoch: 19  batch: 53  loss: 0.24886490\n",
      "epoch: 19  batch: 54  loss: 0.20080301\n",
      "epoch: 19  batch: 55  loss: 0.28591311\n",
      "epoch: 19  batch: 56  loss: 0.24063261\n",
      "epoch: 19  batch: 57  loss: 0.16022943\n",
      "epoch: 19  batch: 58  loss: 0.22998001\n",
      "epoch: 19  batch: 59  loss: 0.30896279\n",
      "epoch: 19  batch: 60  loss: 0.19045654\n",
      "epoch: 19  batch: 61  loss: 0.25312105\n",
      "epoch: 19  batch: 62  loss: 0.26461634\n",
      "epoch: 19  batch: 63  loss: 0.23064481\n",
      "epoch: 19  batch: 64  loss: 0.26290706\n",
      "epoch: 19  batch: 65  loss: 0.34144965\n",
      "epoch: 19  batch: 66  loss: 0.25936827\n",
      "epoch: 19  batch: 67  loss: 0.21866700\n",
      "epoch: 19  batch: 68  loss: 0.32035765\n",
      "epoch: 19  batch: 69  loss: 0.21036482\n",
      "epoch: 19  batch: 70  loss: 0.25508338\n",
      "epoch: 19  batch: 71  loss: 0.24055274\n",
      "epoch: 19  batch: 72  loss: 0.19327323\n",
      "epoch: 19  batch: 73  loss: 0.23719370\n",
      "epoch: 19  batch: 74  loss: 0.27673703\n",
      "epoch: 19  batch: 75  loss: 0.15457200\n",
      "epoch: 19  batch: 76  loss: 0.20214650\n",
      "epoch: 19  batch: 77  loss: 0.15830719\n",
      "epoch: 19  batch: 78  loss: 0.18479189\n",
      "epoch: 19  batch: 79  loss: 0.26916835\n",
      "epoch: 19  batch: 80  loss: 0.19045094\n",
      "epoch: 19  batch: 81  loss: 0.20692538\n",
      "epoch: 19  batch: 82  loss: 0.24496385\n",
      "epoch: 19  batch: 83  loss: 0.16653532\n",
      "epoch: 19  batch: 84  loss: 0.35380331\n",
      "epoch: 19  batch: 85  loss: 0.25510773\n",
      "epoch: 19  batch: 86  loss: 0.16190515\n",
      "epoch: 19  batch: 87  loss: 0.21295749\n",
      "epoch: 20  batch: 1  loss: 0.16800456\n",
      "epoch: 20  batch: 2  loss: 0.20660368\n",
      "epoch: 20  batch: 3  loss: 0.23247182\n",
      "epoch: 20  batch: 4  loss: 0.22851847\n",
      "epoch: 20  batch: 5  loss: 0.22688770\n",
      "epoch: 20  batch: 6  loss: 0.25022829\n",
      "epoch: 20  batch: 7  loss: 0.25907937\n",
      "epoch: 20  batch: 8  loss: 0.21080782\n",
      "epoch: 20  batch: 9  loss: 0.25110546\n",
      "epoch: 20  batch: 10  loss: 0.31269729\n",
      "epoch: 20  batch: 11  loss: 0.23135661\n",
      "epoch: 20  batch: 12  loss: 0.28891513\n",
      "epoch: 20  batch: 13  loss: 0.22343843\n",
      "epoch: 20  batch: 14  loss: 0.18237710\n",
      "epoch: 20  batch: 15  loss: 0.19290207\n",
      "epoch: 20  batch: 16  loss: 0.18219708\n",
      "epoch: 20  batch: 17  loss: 0.23196222\n",
      "epoch: 20  batch: 18  loss: 0.23613077\n",
      "epoch: 20  batch: 19  loss: 0.26067549\n",
      "epoch: 20  batch: 20  loss: 0.20809290\n",
      "epoch: 20  batch: 21  loss: 0.24090366\n",
      "epoch: 20  batch: 22  loss: 0.22688405\n",
      "epoch: 20  batch: 23  loss: 0.19840056\n",
      "epoch: 20  batch: 24  loss: 0.21664643\n",
      "epoch: 20  batch: 25  loss: 0.21599859\n",
      "epoch: 20  batch: 26  loss: 0.24506712\n",
      "epoch: 20  batch: 27  loss: 0.18248804\n",
      "epoch: 20  batch: 28  loss: 0.17597222\n",
      "epoch: 20  batch: 29  loss: 0.31475666\n",
      "epoch: 20  batch: 30  loss: 0.19282536\n",
      "epoch: 20  batch: 31  loss: 0.16068017\n",
      "epoch: 20  batch: 32  loss: 0.21535538\n",
      "epoch: 20  batch: 33  loss: 0.16308963\n",
      "epoch: 20  batch: 34  loss: 0.26903981\n",
      "epoch: 20  batch: 35  loss: 0.19832520\n",
      "epoch: 20  batch: 36  loss: 0.27835816\n",
      "epoch: 20  batch: 37  loss: 0.22131367\n",
      "epoch: 20  batch: 38  loss: 0.28767985\n",
      "epoch: 20  batch: 39  loss: 0.18513650\n",
      "epoch: 20  batch: 40  loss: 0.24140914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20  batch: 41  loss: 0.21596852\n",
      "epoch: 20  batch: 42  loss: 0.20533650\n",
      "epoch: 20  batch: 43  loss: 0.22055091\n",
      "epoch: 20  batch: 44  loss: 0.21076496\n",
      "epoch: 20  batch: 45  loss: 0.16588522\n",
      "epoch: 20  batch: 46  loss: 0.19838502\n",
      "epoch: 20  batch: 47  loss: 0.22781494\n",
      "epoch: 20  batch: 48  loss: 0.22285023\n",
      "epoch: 20  batch: 49  loss: 0.23866968\n",
      "epoch: 20  batch: 50  loss: 0.28755051\n",
      "epoch: 20  batch: 51  loss: 0.29485515\n",
      "epoch: 20  batch: 52  loss: 0.24660088\n",
      "epoch: 20  batch: 53  loss: 0.18068492\n",
      "epoch: 20  batch: 54  loss: 0.30674514\n",
      "epoch: 20  batch: 55  loss: 0.22485124\n",
      "epoch: 20  batch: 56  loss: 0.25826585\n",
      "epoch: 20  batch: 57  loss: 0.24983348\n",
      "epoch: 20  batch: 58  loss: 0.29296809\n",
      "epoch: 20  batch: 59  loss: 0.18853067\n",
      "epoch: 20  batch: 60  loss: 0.20259504\n",
      "epoch: 20  batch: 61  loss: 0.19333673\n",
      "epoch: 20  batch: 62  loss: 0.24510741\n",
      "epoch: 20  batch: 63  loss: 0.22312152\n",
      "epoch: 20  batch: 64  loss: 0.20037091\n",
      "epoch: 20  batch: 65  loss: 0.12977974\n",
      "epoch: 20  batch: 66  loss: 0.27182212\n",
      "epoch: 20  batch: 67  loss: 0.22535548\n",
      "epoch: 20  batch: 68  loss: 0.22629321\n",
      "epoch: 20  batch: 69  loss: 0.32033160\n",
      "epoch: 20  batch: 70  loss: 0.25249171\n",
      "epoch: 20  batch: 71  loss: 0.21262376\n",
      "epoch: 20  batch: 72  loss: 0.25349012\n",
      "epoch: 20  batch: 73  loss: 0.20945565\n",
      "epoch: 20  batch: 74  loss: 0.16584589\n",
      "epoch: 20  batch: 75  loss: 0.23449305\n",
      "epoch: 20  batch: 76  loss: 0.21043546\n",
      "epoch: 20  batch: 77  loss: 0.20827505\n",
      "epoch: 20  batch: 78  loss: 0.20998199\n",
      "epoch: 20  batch: 79  loss: 0.22706634\n",
      "epoch: 20  batch: 80  loss: 0.17141172\n",
      "epoch: 20  batch: 81  loss: 0.23543541\n",
      "epoch: 20  batch: 82  loss: 0.27246755\n",
      "epoch: 20  batch: 83  loss: 0.21371199\n",
      "epoch: 20  batch: 84  loss: 0.20546326\n",
      "epoch: 20  batch: 85  loss: 0.15033825\n",
      "epoch: 20  batch: 86  loss: 0.21423852\n",
      "epoch: 20  batch: 87  loss: 0.14732793\n",
      "epoch: 21  batch: 1  loss: 0.24021153\n",
      "epoch: 21  batch: 2  loss: 0.24952577\n",
      "epoch: 21  batch: 3  loss: 0.15567464\n",
      "epoch: 21  batch: 4  loss: 0.19868565\n",
      "epoch: 21  batch: 5  loss: 0.20737779\n",
      "epoch: 21  batch: 6  loss: 0.16263616\n",
      "epoch: 21  batch: 7  loss: 0.19861861\n",
      "epoch: 21  batch: 8  loss: 0.24189501\n",
      "epoch: 21  batch: 9  loss: 0.20789796\n",
      "epoch: 21  batch: 10  loss: 0.19949540\n",
      "epoch: 21  batch: 11  loss: 0.19218872\n",
      "epoch: 21  batch: 12  loss: 0.16848791\n",
      "epoch: 21  batch: 13  loss: 0.21259090\n",
      "epoch: 21  batch: 14  loss: 0.26867813\n",
      "epoch: 21  batch: 15  loss: 0.25800586\n",
      "epoch: 21  batch: 16  loss: 0.23019226\n",
      "epoch: 21  batch: 17  loss: 0.28055471\n",
      "epoch: 21  batch: 18  loss: 0.20583691\n",
      "epoch: 21  batch: 19  loss: 0.15388323\n",
      "epoch: 21  batch: 20  loss: 0.29150981\n",
      "epoch: 21  batch: 21  loss: 0.19201672\n",
      "epoch: 21  batch: 22  loss: 0.21052688\n",
      "epoch: 21  batch: 23  loss: 0.18773741\n",
      "epoch: 21  batch: 24  loss: 0.26786271\n",
      "epoch: 21  batch: 25  loss: 0.21851197\n",
      "epoch: 21  batch: 26  loss: 0.17296033\n",
      "epoch: 21  batch: 27  loss: 0.26350039\n",
      "epoch: 21  batch: 28  loss: 0.16580871\n",
      "epoch: 21  batch: 29  loss: 0.18263891\n",
      "epoch: 21  batch: 30  loss: 0.22816551\n",
      "epoch: 21  batch: 31  loss: 0.21194465\n",
      "epoch: 21  batch: 32  loss: 0.21463954\n",
      "epoch: 21  batch: 33  loss: 0.28687534\n",
      "epoch: 21  batch: 34  loss: 0.18958917\n",
      "epoch: 21  batch: 35  loss: 0.18494916\n",
      "epoch: 21  batch: 36  loss: 0.17055665\n",
      "epoch: 21  batch: 37  loss: 0.20267713\n",
      "epoch: 21  batch: 38  loss: 0.18313329\n",
      "epoch: 21  batch: 39  loss: 0.16153739\n",
      "epoch: 21  batch: 40  loss: 0.14092802\n",
      "epoch: 21  batch: 41  loss: 0.19757661\n",
      "epoch: 21  batch: 42  loss: 0.25342029\n",
      "epoch: 21  batch: 43  loss: 0.19380380\n",
      "epoch: 21  batch: 44  loss: 0.22604428\n",
      "epoch: 21  batch: 45  loss: 0.20426381\n",
      "epoch: 21  batch: 46  loss: 0.19547260\n",
      "epoch: 21  batch: 47  loss: 0.17287312\n",
      "epoch: 21  batch: 48  loss: 0.22239387\n",
      "epoch: 21  batch: 49  loss: 0.18584137\n",
      "epoch: 21  batch: 50  loss: 0.18058974\n",
      "epoch: 21  batch: 51  loss: 0.22133482\n",
      "epoch: 21  batch: 52  loss: 0.18644486\n",
      "epoch: 21  batch: 53  loss: 0.21953380\n",
      "epoch: 21  batch: 54  loss: 0.19211930\n",
      "epoch: 21  batch: 55  loss: 0.30818203\n",
      "epoch: 21  batch: 56  loss: 0.16095082\n",
      "epoch: 21  batch: 57  loss: 0.21088719\n",
      "epoch: 21  batch: 58  loss: 0.24140880\n",
      "epoch: 21  batch: 59  loss: 0.22161959\n",
      "epoch: 21  batch: 60  loss: 0.22187842\n",
      "epoch: 21  batch: 61  loss: 0.20898184\n",
      "epoch: 21  batch: 62  loss: 0.23295844\n",
      "epoch: 21  batch: 63  loss: 0.25174713\n",
      "epoch: 21  batch: 64  loss: 0.20596102\n",
      "epoch: 21  batch: 65  loss: 0.16896434\n",
      "epoch: 21  batch: 66  loss: 0.21796539\n",
      "epoch: 21  batch: 67  loss: 0.19204533\n",
      "epoch: 21  batch: 68  loss: 0.20669904\n",
      "epoch: 21  batch: 69  loss: 0.16354552\n",
      "epoch: 21  batch: 70  loss: 0.20859602\n",
      "epoch: 21  batch: 71  loss: 0.22277865\n",
      "epoch: 21  batch: 72  loss: 0.19108367\n",
      "epoch: 21  batch: 73  loss: 0.23245931\n",
      "epoch: 21  batch: 74  loss: 0.16309406\n",
      "epoch: 21  batch: 75  loss: 0.21414948\n",
      "epoch: 21  batch: 76  loss: 0.19090103\n",
      "epoch: 21  batch: 77  loss: 0.20568134\n",
      "epoch: 21  batch: 78  loss: 0.22943084\n",
      "epoch: 21  batch: 79  loss: 0.19773459\n",
      "epoch: 21  batch: 80  loss: 0.15014622\n",
      "epoch: 21  batch: 81  loss: 0.12521780\n",
      "epoch: 21  batch: 82  loss: 0.21770199\n",
      "epoch: 21  batch: 83  loss: 0.20557728\n",
      "epoch: 21  batch: 84  loss: 0.19532348\n",
      "epoch: 21  batch: 85  loss: 0.17892238\n",
      "epoch: 21  batch: 86  loss: 0.19271366\n",
      "epoch: 21  batch: 87  loss: 0.21166842\n",
      "epoch: 22  batch: 1  loss: 0.17704940\n",
      "epoch: 22  batch: 2  loss: 0.20787241\n",
      "epoch: 22  batch: 3  loss: 0.18562019\n",
      "epoch: 22  batch: 4  loss: 0.17036092\n",
      "epoch: 22  batch: 5  loss: 0.26831183\n",
      "epoch: 22  batch: 6  loss: 0.18298288\n",
      "epoch: 22  batch: 7  loss: 0.21697396\n",
      "epoch: 22  batch: 8  loss: 0.25636312\n",
      "epoch: 22  batch: 9  loss: 0.26813948\n",
      "epoch: 22  batch: 10  loss: 0.21383655\n",
      "epoch: 22  batch: 11  loss: 0.21621142\n",
      "epoch: 22  batch: 12  loss: 0.23975952\n",
      "epoch: 22  batch: 13  loss: 0.16683051\n",
      "epoch: 22  batch: 14  loss: 0.22384888\n",
      "epoch: 22  batch: 15  loss: 0.17151932\n",
      "epoch: 22  batch: 16  loss: 0.20112236\n",
      "epoch: 22  batch: 17  loss: 0.25530156\n",
      "epoch: 22  batch: 18  loss: 0.19474946\n",
      "epoch: 22  batch: 19  loss: 0.18247402\n",
      "epoch: 22  batch: 20  loss: 0.21936166\n",
      "epoch: 22  batch: 21  loss: 0.17994416\n",
      "epoch: 22  batch: 22  loss: 0.20191334\n",
      "epoch: 22  batch: 23  loss: 0.23909596\n",
      "epoch: 22  batch: 24  loss: 0.13380565\n",
      "epoch: 22  batch: 25  loss: 0.25630251\n",
      "epoch: 22  batch: 26  loss: 0.19672778\n",
      "epoch: 22  batch: 27  loss: 0.16057412\n",
      "epoch: 22  batch: 28  loss: 0.20285827\n",
      "epoch: 22  batch: 29  loss: 0.21170455\n",
      "epoch: 22  batch: 30  loss: 0.20660913\n",
      "epoch: 22  batch: 31  loss: 0.15740478\n",
      "epoch: 22  batch: 32  loss: 0.18360667\n",
      "epoch: 22  batch: 33  loss: 0.23569699\n",
      "epoch: 22  batch: 34  loss: 0.20970616\n",
      "epoch: 22  batch: 35  loss: 0.18177228\n",
      "epoch: 22  batch: 36  loss: 0.30314305\n",
      "epoch: 22  batch: 37  loss: 0.23101607\n",
      "epoch: 22  batch: 38  loss: 0.24343736\n",
      "epoch: 22  batch: 39  loss: 0.18846980\n",
      "epoch: 22  batch: 40  loss: 0.21286868\n",
      "epoch: 22  batch: 41  loss: 0.21764377\n",
      "epoch: 22  batch: 42  loss: 0.14643949\n",
      "epoch: 22  batch: 43  loss: 0.22347891\n",
      "epoch: 22  batch: 44  loss: 0.20978500\n",
      "epoch: 22  batch: 45  loss: 0.18244961\n",
      "epoch: 22  batch: 46  loss: 0.20141186\n",
      "epoch: 22  batch: 47  loss: 0.21521637\n",
      "epoch: 22  batch: 48  loss: 0.16513319\n",
      "epoch: 22  batch: 49  loss: 0.26041794\n",
      "epoch: 22  batch: 50  loss: 0.19051629\n",
      "epoch: 22  batch: 51  loss: 0.15183222\n",
      "epoch: 22  batch: 52  loss: 0.20492505\n",
      "epoch: 22  batch: 53  loss: 0.19836237\n",
      "epoch: 22  batch: 54  loss: 0.19223030\n",
      "epoch: 22  batch: 55  loss: 0.21147837\n",
      "epoch: 22  batch: 56  loss: 0.16765101\n",
      "epoch: 22  batch: 57  loss: 0.23617673\n",
      "epoch: 22  batch: 58  loss: 0.19484258\n",
      "epoch: 22  batch: 59  loss: 0.18644738\n",
      "epoch: 22  batch: 60  loss: 0.21828398\n",
      "epoch: 22  batch: 61  loss: 0.18453951\n",
      "epoch: 22  batch: 62  loss: 0.18859540\n",
      "epoch: 22  batch: 63  loss: 0.16910996\n",
      "epoch: 22  batch: 64  loss: 0.19700852\n",
      "epoch: 22  batch: 65  loss: 0.18522076\n",
      "epoch: 22  batch: 66  loss: 0.21105234\n",
      "epoch: 22  batch: 67  loss: 0.17484337\n",
      "epoch: 22  batch: 68  loss: 0.23929746\n",
      "epoch: 22  batch: 69  loss: 0.23566924\n",
      "epoch: 22  batch: 70  loss: 0.21510473\n",
      "epoch: 22  batch: 71  loss: 0.19467759\n",
      "epoch: 22  batch: 72  loss: 0.16934665\n",
      "epoch: 22  batch: 73  loss: 0.19196567\n",
      "epoch: 22  batch: 74  loss: 0.18078239\n",
      "epoch: 22  batch: 75  loss: 0.23934744\n",
      "epoch: 22  batch: 76  loss: 0.18647312\n",
      "epoch: 22  batch: 77  loss: 0.19796756\n",
      "epoch: 22  batch: 78  loss: 0.23386605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22  batch: 79  loss: 0.23697998\n",
      "epoch: 22  batch: 80  loss: 0.18680115\n",
      "epoch: 22  batch: 81  loss: 0.19189444\n",
      "epoch: 22  batch: 82  loss: 0.26494560\n",
      "epoch: 22  batch: 83  loss: 0.26690209\n",
      "epoch: 22  batch: 84  loss: 0.20358348\n",
      "epoch: 22  batch: 85  loss: 0.17442325\n",
      "epoch: 22  batch: 86  loss: 0.22032373\n",
      "epoch: 22  batch: 87  loss: 0.16445336\n",
      "epoch: 23  batch: 1  loss: 0.18337904\n",
      "epoch: 23  batch: 2  loss: 0.17178260\n",
      "epoch: 23  batch: 3  loss: 0.18344365\n",
      "epoch: 23  batch: 4  loss: 0.15412243\n",
      "epoch: 23  batch: 5  loss: 0.17480588\n",
      "epoch: 23  batch: 6  loss: 0.24947521\n",
      "epoch: 23  batch: 7  loss: 0.15336783\n",
      "epoch: 23  batch: 8  loss: 0.22662450\n",
      "epoch: 23  batch: 9  loss: 0.24582399\n",
      "epoch: 23  batch: 10  loss: 0.22006319\n",
      "epoch: 23  batch: 11  loss: 0.22698346\n",
      "epoch: 23  batch: 12  loss: 0.19838703\n",
      "epoch: 23  batch: 13  loss: 0.21436971\n",
      "epoch: 23  batch: 14  loss: 0.22272372\n",
      "epoch: 23  batch: 15  loss: 0.15935524\n",
      "epoch: 23  batch: 16  loss: 0.15690155\n",
      "epoch: 23  batch: 17  loss: 0.18938945\n",
      "epoch: 23  batch: 18  loss: 0.23305231\n",
      "epoch: 23  batch: 19  loss: 0.24142292\n",
      "epoch: 23  batch: 20  loss: 0.28034937\n",
      "epoch: 23  batch: 21  loss: 0.15369198\n",
      "epoch: 23  batch: 22  loss: 0.20502765\n",
      "epoch: 23  batch: 23  loss: 0.18361925\n",
      "epoch: 23  batch: 24  loss: 0.22073703\n",
      "epoch: 23  batch: 25  loss: 0.29813272\n",
      "epoch: 23  batch: 26  loss: 0.26328713\n",
      "epoch: 23  batch: 27  loss: 0.17943788\n",
      "epoch: 23  batch: 28  loss: 0.23316094\n",
      "epoch: 23  batch: 29  loss: 0.15725365\n",
      "epoch: 23  batch: 30  loss: 0.19089058\n",
      "epoch: 23  batch: 31  loss: 0.17143108\n",
      "epoch: 23  batch: 32  loss: 0.28313074\n",
      "epoch: 23  batch: 33  loss: 0.17186767\n",
      "epoch: 23  batch: 34  loss: 0.25878778\n",
      "epoch: 23  batch: 35  loss: 0.17160594\n",
      "epoch: 23  batch: 36  loss: 0.15889356\n",
      "epoch: 23  batch: 37  loss: 0.25460631\n",
      "epoch: 23  batch: 38  loss: 0.23176731\n",
      "epoch: 23  batch: 39  loss: 0.15318300\n",
      "epoch: 23  batch: 40  loss: 0.24554543\n",
      "epoch: 23  batch: 41  loss: 0.29775482\n",
      "epoch: 23  batch: 42  loss: 0.21567304\n",
      "epoch: 23  batch: 43  loss: 0.19504914\n",
      "epoch: 23  batch: 44  loss: 0.24845363\n",
      "epoch: 23  batch: 45  loss: 0.25492638\n",
      "epoch: 23  batch: 46  loss: 0.23978361\n",
      "epoch: 23  batch: 47  loss: 0.25050700\n",
      "epoch: 23  batch: 48  loss: 0.28376052\n",
      "epoch: 23  batch: 49  loss: 0.29502034\n",
      "epoch: 23  batch: 50  loss: 0.17877224\n",
      "epoch: 23  batch: 51  loss: 0.28425428\n",
      "epoch: 23  batch: 52  loss: 0.26751253\n",
      "epoch: 23  batch: 53  loss: 0.18318854\n",
      "epoch: 23  batch: 54  loss: 0.22489505\n",
      "epoch: 23  batch: 55  loss: 0.25687304\n",
      "epoch: 23  batch: 56  loss: 0.15313128\n",
      "epoch: 23  batch: 57  loss: 0.20839116\n",
      "epoch: 23  batch: 58  loss: 0.19531566\n",
      "epoch: 23  batch: 59  loss: 0.17287020\n",
      "epoch: 23  batch: 60  loss: 0.20281227\n",
      "epoch: 23  batch: 61  loss: 0.18691976\n",
      "epoch: 23  batch: 62  loss: 0.18439567\n",
      "epoch: 23  batch: 63  loss: 0.19606307\n",
      "epoch: 23  batch: 64  loss: 0.15768929\n",
      "epoch: 23  batch: 65  loss: 0.16552746\n",
      "epoch: 23  batch: 66  loss: 0.19268259\n",
      "epoch: 23  batch: 67  loss: 0.24575256\n",
      "epoch: 23  batch: 68  loss: 0.20633940\n",
      "epoch: 23  batch: 69  loss: 0.13205646\n",
      "epoch: 23  batch: 70  loss: 0.18536280\n",
      "epoch: 23  batch: 71  loss: 0.20441888\n",
      "epoch: 23  batch: 72  loss: 0.21189117\n",
      "epoch: 23  batch: 73  loss: 0.15135963\n",
      "epoch: 23  batch: 74  loss: 0.23969744\n",
      "epoch: 23  batch: 75  loss: 0.22342619\n",
      "epoch: 23  batch: 76  loss: 0.15282078\n",
      "epoch: 23  batch: 77  loss: 0.14423211\n",
      "epoch: 23  batch: 78  loss: 0.17644776\n",
      "epoch: 23  batch: 79  loss: 0.27914202\n",
      "epoch: 23  batch: 80  loss: 0.25466800\n",
      "epoch: 23  batch: 81  loss: 0.23244083\n",
      "epoch: 23  batch: 82  loss: 0.17575465\n",
      "epoch: 23  batch: 83  loss: 0.15743567\n",
      "epoch: 23  batch: 84  loss: 0.16822654\n",
      "epoch: 23  batch: 85  loss: 0.15940934\n",
      "epoch: 23  batch: 86  loss: 0.23216482\n",
      "epoch: 23  batch: 87  loss: 0.20400560\n",
      "epoch: 24  batch: 1  loss: 0.31623945\n",
      "epoch: 24  batch: 2  loss: 0.28259799\n",
      "epoch: 24  batch: 3  loss: 0.23632547\n",
      "epoch: 24  batch: 4  loss: 0.16689034\n",
      "epoch: 24  batch: 5  loss: 0.17670909\n",
      "epoch: 24  batch: 6  loss: 0.18023281\n",
      "epoch: 24  batch: 7  loss: 0.16705741\n",
      "epoch: 24  batch: 8  loss: 0.13245004\n",
      "epoch: 24  batch: 9  loss: 0.19403709\n",
      "epoch: 24  batch: 10  loss: 0.15559918\n",
      "epoch: 24  batch: 11  loss: 0.14344433\n",
      "epoch: 24  batch: 12  loss: 0.16259257\n",
      "epoch: 24  batch: 13  loss: 0.21659988\n",
      "epoch: 24  batch: 14  loss: 0.24421646\n",
      "epoch: 24  batch: 15  loss: 0.17560737\n",
      "epoch: 24  batch: 16  loss: 0.21387529\n",
      "epoch: 24  batch: 17  loss: 0.19230573\n",
      "epoch: 24  batch: 18  loss: 0.17287423\n",
      "epoch: 24  batch: 19  loss: 0.16647550\n",
      "epoch: 24  batch: 20  loss: 0.17273405\n",
      "epoch: 24  batch: 21  loss: 0.25087342\n",
      "epoch: 24  batch: 22  loss: 0.21038072\n",
      "epoch: 24  batch: 23  loss: 0.19069003\n",
      "epoch: 24  batch: 24  loss: 0.15654348\n",
      "epoch: 24  batch: 25  loss: 0.25714511\n",
      "epoch: 24  batch: 26  loss: 0.22928745\n",
      "epoch: 24  batch: 27  loss: 0.17876220\n",
      "epoch: 24  batch: 28  loss: 0.20743869\n",
      "epoch: 24  batch: 29  loss: 0.16484812\n",
      "epoch: 24  batch: 30  loss: 0.19662666\n",
      "epoch: 24  batch: 31  loss: 0.17177421\n",
      "epoch: 24  batch: 32  loss: 0.37583518\n",
      "epoch: 24  batch: 33  loss: 0.18186793\n",
      "epoch: 24  batch: 34  loss: 0.12847319\n",
      "epoch: 24  batch: 35  loss: 0.16562581\n",
      "epoch: 24  batch: 36  loss: 0.22724092\n",
      "epoch: 24  batch: 37  loss: 0.22486351\n",
      "epoch: 24  batch: 38  loss: 0.25975272\n",
      "epoch: 24  batch: 39  loss: 0.15329476\n",
      "epoch: 24  batch: 40  loss: 0.19133942\n",
      "epoch: 24  batch: 41  loss: 0.30872288\n",
      "epoch: 24  batch: 42  loss: 0.19909497\n",
      "epoch: 24  batch: 43  loss: 0.15148416\n",
      "epoch: 24  batch: 44  loss: 0.18347293\n",
      "epoch: 24  batch: 45  loss: 0.21523485\n",
      "epoch: 24  batch: 46  loss: 0.16056284\n",
      "epoch: 24  batch: 47  loss: 0.18939859\n",
      "epoch: 24  batch: 48  loss: 0.28780183\n",
      "epoch: 24  batch: 49  loss: 0.18969852\n",
      "epoch: 24  batch: 50  loss: 0.13874179\n",
      "epoch: 24  batch: 51  loss: 0.21886390\n",
      "epoch: 24  batch: 52  loss: 0.13968402\n",
      "epoch: 24  batch: 53  loss: 0.15286157\n",
      "epoch: 24  batch: 54  loss: 0.17604296\n",
      "epoch: 24  batch: 55  loss: 0.15767767\n",
      "epoch: 24  batch: 56  loss: 0.13605617\n",
      "epoch: 24  batch: 57  loss: 0.19066992\n",
      "epoch: 24  batch: 58  loss: 0.16650334\n",
      "epoch: 24  batch: 59  loss: 0.25721070\n",
      "epoch: 24  batch: 60  loss: 0.25817633\n",
      "epoch: 24  batch: 61  loss: 0.17788668\n",
      "epoch: 24  batch: 62  loss: 0.19886263\n",
      "epoch: 24  batch: 63  loss: 0.21199554\n",
      "epoch: 24  batch: 64  loss: 0.13919169\n",
      "epoch: 24  batch: 65  loss: 0.19105577\n",
      "epoch: 24  batch: 66  loss: 0.22981615\n",
      "epoch: 24  batch: 67  loss: 0.17391011\n",
      "epoch: 24  batch: 68  loss: 0.25796029\n",
      "epoch: 24  batch: 69  loss: 0.20476539\n",
      "epoch: 24  batch: 70  loss: 0.33825216\n",
      "epoch: 24  batch: 71  loss: 0.26854062\n",
      "epoch: 24  batch: 72  loss: 0.16848193\n",
      "epoch: 24  batch: 73  loss: 0.17104717\n",
      "epoch: 24  batch: 74  loss: 0.30115587\n",
      "epoch: 24  batch: 75  loss: 0.17806521\n",
      "epoch: 24  batch: 76  loss: 0.17563143\n",
      "epoch: 24  batch: 77  loss: 0.24876049\n",
      "epoch: 24  batch: 78  loss: 0.18783925\n",
      "epoch: 24  batch: 79  loss: 0.19840172\n",
      "epoch: 24  batch: 80  loss: 0.19866258\n",
      "epoch: 24  batch: 81  loss: 0.12615672\n",
      "epoch: 24  batch: 82  loss: 0.24358429\n",
      "epoch: 24  batch: 83  loss: 0.21640378\n",
      "epoch: 24  batch: 84  loss: 0.20530365\n",
      "epoch: 24  batch: 85  loss: 0.18614344\n",
      "epoch: 24  batch: 86  loss: 0.15655999\n",
      "epoch: 24  batch: 87  loss: 0.21866491\n",
      "epoch: 25  batch: 1  loss: 0.17464550\n",
      "epoch: 25  batch: 2  loss: 0.13651937\n",
      "epoch: 25  batch: 3  loss: 0.18262088\n",
      "epoch: 25  batch: 4  loss: 0.17856343\n",
      "epoch: 25  batch: 5  loss: 0.16399854\n",
      "epoch: 25  batch: 6  loss: 0.15178029\n",
      "epoch: 25  batch: 7  loss: 0.21006709\n",
      "epoch: 25  batch: 8  loss: 0.25228637\n",
      "epoch: 25  batch: 9  loss: 0.19282493\n",
      "epoch: 25  batch: 10  loss: 0.18772864\n",
      "epoch: 25  batch: 11  loss: 0.24852906\n",
      "epoch: 25  batch: 12  loss: 0.21717454\n",
      "epoch: 25  batch: 13  loss: 0.20870082\n",
      "epoch: 25  batch: 14  loss: 0.17604743\n",
      "epoch: 25  batch: 15  loss: 0.22367609\n",
      "epoch: 25  batch: 16  loss: 0.20496342\n",
      "epoch: 25  batch: 17  loss: 0.20687091\n",
      "epoch: 25  batch: 18  loss: 0.27977347\n",
      "epoch: 25  batch: 19  loss: 0.19547842\n",
      "epoch: 25  batch: 20  loss: 0.19739565\n",
      "epoch: 25  batch: 21  loss: 0.20427045\n",
      "epoch: 25  batch: 22  loss: 0.14584960\n",
      "epoch: 25  batch: 23  loss: 0.19339465\n",
      "epoch: 25  batch: 24  loss: 0.19189389\n",
      "epoch: 25  batch: 25  loss: 0.16853209\n",
      "epoch: 25  batch: 26  loss: 0.17631289\n",
      "epoch: 25  batch: 27  loss: 0.23519801\n",
      "epoch: 25  batch: 28  loss: 0.16405642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25  batch: 29  loss: 0.18019371\n",
      "epoch: 25  batch: 30  loss: 0.20786460\n",
      "epoch: 25  batch: 31  loss: 0.15758070\n",
      "epoch: 25  batch: 32  loss: 0.17151079\n",
      "epoch: 25  batch: 33  loss: 0.17401934\n",
      "epoch: 25  batch: 34  loss: 0.13079149\n",
      "epoch: 25  batch: 35  loss: 0.15936121\n",
      "epoch: 25  batch: 36  loss: 0.15529530\n",
      "epoch: 25  batch: 37  loss: 0.18013582\n",
      "epoch: 25  batch: 38  loss: 0.22297654\n",
      "epoch: 25  batch: 39  loss: 0.16810609\n",
      "epoch: 25  batch: 40  loss: 0.20345147\n",
      "epoch: 25  batch: 41  loss: 0.18968803\n",
      "epoch: 25  batch: 42  loss: 0.24817534\n",
      "epoch: 25  batch: 43  loss: 0.20193113\n",
      "epoch: 25  batch: 44  loss: 0.18488339\n",
      "epoch: 25  batch: 45  loss: 0.21048775\n",
      "epoch: 25  batch: 46  loss: 0.16242461\n",
      "epoch: 25  batch: 47  loss: 0.27666622\n",
      "epoch: 25  batch: 48  loss: 0.19190916\n",
      "epoch: 25  batch: 49  loss: 0.16255106\n",
      "epoch: 25  batch: 50  loss: 0.14589153\n",
      "epoch: 25  batch: 51  loss: 0.21331495\n",
      "epoch: 25  batch: 52  loss: 0.17695867\n",
      "epoch: 25  batch: 53  loss: 0.19921981\n",
      "epoch: 25  batch: 54  loss: 0.13618302\n",
      "epoch: 25  batch: 55  loss: 0.19084486\n",
      "epoch: 25  batch: 56  loss: 0.15220749\n",
      "epoch: 25  batch: 57  loss: 0.23272860\n",
      "epoch: 25  batch: 58  loss: 0.19460119\n",
      "epoch: 25  batch: 59  loss: 0.22441033\n",
      "epoch: 25  batch: 60  loss: 0.17713930\n",
      "epoch: 25  batch: 61  loss: 0.19477773\n",
      "epoch: 25  batch: 62  loss: 0.18774612\n",
      "epoch: 25  batch: 63  loss: 0.16481391\n",
      "epoch: 25  batch: 64  loss: 0.20204434\n",
      "epoch: 25  batch: 65  loss: 0.15988301\n",
      "epoch: 25  batch: 66  loss: 0.23281994\n",
      "epoch: 25  batch: 67  loss: 0.17597885\n",
      "epoch: 25  batch: 68  loss: 0.27323312\n",
      "epoch: 25  batch: 69  loss: 0.19751863\n",
      "epoch: 25  batch: 70  loss: 0.24983890\n",
      "epoch: 25  batch: 71  loss: 0.20465280\n",
      "epoch: 25  batch: 72  loss: 0.20182234\n",
      "epoch: 25  batch: 73  loss: 0.16154371\n",
      "epoch: 25  batch: 74  loss: 0.18786511\n",
      "epoch: 25  batch: 75  loss: 0.16354987\n",
      "epoch: 25  batch: 76  loss: 0.18859686\n",
      "epoch: 25  batch: 77  loss: 0.21672015\n",
      "epoch: 25  batch: 78  loss: 0.20076570\n",
      "epoch: 25  batch: 79  loss: 0.31912842\n",
      "epoch: 25  batch: 80  loss: 0.19693740\n",
      "epoch: 25  batch: 81  loss: 0.17812121\n",
      "epoch: 25  batch: 82  loss: 0.21860078\n",
      "epoch: 25  batch: 83  loss: 0.14724754\n",
      "epoch: 25  batch: 84  loss: 0.19646707\n",
      "epoch: 25  batch: 85  loss: 0.19490656\n",
      "epoch: 25  batch: 86  loss: 0.17008258\n",
      "epoch: 25  batch: 87  loss: 0.32405123\n",
      "epoch: 26  batch: 1  loss: 0.19476460\n",
      "epoch: 26  batch: 2  loss: 0.20594607\n",
      "epoch: 26  batch: 3  loss: 0.17733043\n",
      "epoch: 26  batch: 4  loss: 0.24286819\n",
      "epoch: 26  batch: 5  loss: 0.19417824\n",
      "epoch: 26  batch: 6  loss: 0.14511432\n",
      "epoch: 26  batch: 7  loss: 0.18391715\n",
      "epoch: 26  batch: 8  loss: 0.18317609\n",
      "epoch: 26  batch: 9  loss: 0.14559759\n",
      "epoch: 26  batch: 10  loss: 0.26867008\n",
      "epoch: 26  batch: 11  loss: 0.26071861\n",
      "epoch: 26  batch: 12  loss: 0.31424558\n",
      "epoch: 26  batch: 13  loss: 0.19411181\n",
      "epoch: 26  batch: 14  loss: 0.21739571\n",
      "epoch: 26  batch: 15  loss: 0.18637168\n",
      "epoch: 26  batch: 16  loss: 0.14528094\n",
      "epoch: 26  batch: 17  loss: 0.15204291\n",
      "epoch: 26  batch: 18  loss: 0.19539231\n",
      "epoch: 26  batch: 19  loss: 0.23995486\n",
      "epoch: 26  batch: 20  loss: 0.20636694\n",
      "epoch: 26  batch: 21  loss: 0.16718833\n",
      "epoch: 26  batch: 22  loss: 0.25256768\n",
      "epoch: 26  batch: 23  loss: 0.20555565\n",
      "epoch: 26  batch: 24  loss: 0.15265071\n",
      "epoch: 26  batch: 25  loss: 0.15705284\n",
      "epoch: 26  batch: 26  loss: 0.24417390\n",
      "epoch: 26  batch: 27  loss: 0.15402636\n",
      "epoch: 26  batch: 28  loss: 0.15276901\n",
      "epoch: 26  batch: 29  loss: 0.20619828\n",
      "epoch: 26  batch: 30  loss: 0.17702040\n",
      "epoch: 26  batch: 31  loss: 0.16072834\n",
      "epoch: 26  batch: 32  loss: 0.26217532\n",
      "epoch: 26  batch: 33  loss: 0.22346173\n",
      "epoch: 26  batch: 34  loss: 0.21233302\n",
      "epoch: 26  batch: 35  loss: 0.18261348\n",
      "epoch: 26  batch: 36  loss: 0.24801564\n",
      "epoch: 26  batch: 37  loss: 0.30418122\n",
      "epoch: 26  batch: 38  loss: 0.26905692\n",
      "epoch: 26  batch: 39  loss: 0.22523190\n",
      "epoch: 26  batch: 40  loss: 0.17200290\n",
      "epoch: 26  batch: 41  loss: 0.12918067\n",
      "epoch: 26  batch: 42  loss: 0.24982002\n",
      "epoch: 26  batch: 43  loss: 0.17433028\n",
      "epoch: 26  batch: 44  loss: 0.21093188\n",
      "epoch: 26  batch: 45  loss: 0.18609582\n",
      "epoch: 26  batch: 46  loss: 0.20121664\n",
      "epoch: 26  batch: 47  loss: 0.19434516\n",
      "epoch: 26  batch: 48  loss: 0.20933998\n",
      "epoch: 26  batch: 49  loss: 0.15921874\n",
      "epoch: 26  batch: 50  loss: 0.20776263\n",
      "epoch: 26  batch: 51  loss: 0.22144111\n",
      "epoch: 26  batch: 52  loss: 0.14824006\n",
      "epoch: 26  batch: 53  loss: 0.22348745\n",
      "epoch: 26  batch: 54  loss: 0.18561929\n",
      "epoch: 26  batch: 55  loss: 0.14755704\n",
      "epoch: 26  batch: 56  loss: 0.17773893\n",
      "epoch: 26  batch: 57  loss: 0.20814560\n",
      "epoch: 26  batch: 58  loss: 0.14405577\n",
      "epoch: 26  batch: 59  loss: 0.19138150\n",
      "epoch: 26  batch: 60  loss: 0.15535322\n",
      "epoch: 26  batch: 61  loss: 0.18299593\n",
      "epoch: 26  batch: 62  loss: 0.22743002\n",
      "epoch: 26  batch: 63  loss: 0.26909336\n",
      "epoch: 26  batch: 64  loss: 0.20999181\n",
      "epoch: 26  batch: 65  loss: 0.20689362\n",
      "epoch: 26  batch: 66  loss: 0.18344001\n",
      "epoch: 26  batch: 67  loss: 0.28019586\n",
      "epoch: 26  batch: 68  loss: 0.22453187\n",
      "epoch: 26  batch: 69  loss: 0.20469250\n",
      "epoch: 26  batch: 70  loss: 0.19189821\n",
      "epoch: 26  batch: 71  loss: 0.16294187\n",
      "epoch: 26  batch: 72  loss: 0.13896549\n",
      "epoch: 26  batch: 73  loss: 0.19989142\n",
      "epoch: 26  batch: 74  loss: 0.23456551\n",
      "epoch: 26  batch: 75  loss: 0.18595350\n",
      "epoch: 26  batch: 76  loss: 0.21217181\n",
      "epoch: 26  batch: 77  loss: 0.20413794\n",
      "epoch: 26  batch: 78  loss: 0.17417970\n",
      "epoch: 26  batch: 79  loss: 0.20565061\n",
      "epoch: 26  batch: 80  loss: 0.15637548\n",
      "epoch: 26  batch: 81  loss: 0.17350826\n",
      "epoch: 26  batch: 82  loss: 0.16908325\n",
      "epoch: 26  batch: 83  loss: 0.25169936\n",
      "epoch: 26  batch: 84  loss: 0.26101092\n",
      "epoch: 26  batch: 85  loss: 0.24506480\n",
      "epoch: 26  batch: 86  loss: 0.19071905\n",
      "epoch: 26  batch: 87  loss: 0.17126246\n",
      "epoch: 27  batch: 1  loss: 0.15887280\n",
      "epoch: 27  batch: 2  loss: 0.26852846\n",
      "epoch: 27  batch: 3  loss: 0.16308963\n",
      "epoch: 27  batch: 4  loss: 0.23637356\n",
      "epoch: 27  batch: 5  loss: 0.14921328\n",
      "epoch: 27  batch: 6  loss: 0.22748475\n",
      "epoch: 27  batch: 7  loss: 0.18027578\n",
      "epoch: 27  batch: 8  loss: 0.15380578\n",
      "epoch: 27  batch: 9  loss: 0.20281033\n",
      "epoch: 27  batch: 10  loss: 0.18235102\n",
      "epoch: 27  batch: 11  loss: 0.18294321\n",
      "epoch: 27  batch: 12  loss: 0.12208668\n",
      "epoch: 27  batch: 13  loss: 0.19451278\n",
      "epoch: 27  batch: 14  loss: 0.16642377\n",
      "epoch: 27  batch: 15  loss: 0.10855308\n",
      "epoch: 27  batch: 16  loss: 0.14134915\n",
      "epoch: 27  batch: 17  loss: 0.15337123\n",
      "epoch: 27  batch: 18  loss: 0.13678651\n",
      "epoch: 27  batch: 19  loss: 0.19205867\n",
      "epoch: 27  batch: 20  loss: 0.14317307\n",
      "epoch: 27  batch: 21  loss: 0.20870420\n",
      "epoch: 27  batch: 22  loss: 0.13753237\n",
      "epoch: 27  batch: 23  loss: 0.13055377\n",
      "epoch: 27  batch: 24  loss: 0.14148353\n",
      "epoch: 27  batch: 25  loss: 0.18588264\n",
      "epoch: 27  batch: 26  loss: 0.14800051\n",
      "epoch: 27  batch: 27  loss: 0.18659224\n",
      "epoch: 27  batch: 28  loss: 0.16036540\n",
      "epoch: 27  batch: 29  loss: 0.16560717\n",
      "epoch: 27  batch: 30  loss: 0.19469513\n",
      "epoch: 27  batch: 31  loss: 0.11637696\n",
      "epoch: 27  batch: 32  loss: 0.07916913\n",
      "epoch: 27  batch: 33  loss: 0.15645172\n",
      "epoch: 27  batch: 34  loss: 0.15271869\n",
      "epoch: 27  batch: 35  loss: 0.13828915\n",
      "epoch: 27  batch: 36  loss: 0.12159228\n",
      "epoch: 27  batch: 37  loss: 0.17174681\n",
      "epoch: 27  batch: 38  loss: 0.14016199\n",
      "epoch: 27  batch: 39  loss: 0.16081318\n",
      "epoch: 27  batch: 40  loss: 0.14817330\n",
      "epoch: 27  batch: 41  loss: 0.15873668\n",
      "epoch: 27  batch: 42  loss: 0.16480844\n",
      "epoch: 27  batch: 43  loss: 0.15964134\n",
      "epoch: 27  batch: 44  loss: 0.16875717\n",
      "epoch: 27  batch: 45  loss: 0.18305266\n",
      "epoch: 27  batch: 46  loss: 0.17463905\n",
      "epoch: 27  batch: 47  loss: 0.18647137\n",
      "epoch: 27  batch: 48  loss: 0.11134584\n",
      "epoch: 27  batch: 49  loss: 0.12950093\n",
      "epoch: 27  batch: 50  loss: 0.17722408\n",
      "epoch: 27  batch: 51  loss: 0.13449970\n",
      "epoch: 27  batch: 52  loss: 0.22959745\n",
      "epoch: 27  batch: 53  loss: 0.20011008\n",
      "epoch: 27  batch: 54  loss: 0.15615411\n",
      "epoch: 27  batch: 55  loss: 0.16285858\n",
      "epoch: 27  batch: 56  loss: 0.20968398\n",
      "epoch: 27  batch: 57  loss: 0.12239746\n",
      "epoch: 27  batch: 58  loss: 0.13713109\n",
      "epoch: 27  batch: 59  loss: 0.16242568\n",
      "epoch: 27  batch: 60  loss: 0.11531860\n",
      "epoch: 27  batch: 61  loss: 0.12058575\n",
      "epoch: 27  batch: 62  loss: 0.12306418\n",
      "epoch: 27  batch: 63  loss: 0.13485287\n",
      "epoch: 27  batch: 64  loss: 0.16219635\n",
      "epoch: 27  batch: 65  loss: 0.14547694\n",
      "epoch: 27  batch: 66  loss: 0.13281089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27  batch: 67  loss: 0.11173886\n",
      "epoch: 27  batch: 68  loss: 0.12804504\n",
      "epoch: 27  batch: 69  loss: 0.32099825\n",
      "epoch: 27  batch: 70  loss: 0.13093546\n",
      "epoch: 27  batch: 71  loss: 0.08391856\n",
      "epoch: 27  batch: 72  loss: 0.11946651\n",
      "epoch: 27  batch: 73  loss: 0.18281174\n",
      "epoch: 27  batch: 74  loss: 0.10747457\n",
      "epoch: 27  batch: 75  loss: 0.15885034\n",
      "epoch: 27  batch: 76  loss: 0.18459623\n",
      "epoch: 27  batch: 77  loss: 0.16247559\n",
      "epoch: 27  batch: 78  loss: 0.17919494\n",
      "epoch: 27  batch: 79  loss: 0.12561220\n",
      "epoch: 27  batch: 80  loss: 0.20426217\n",
      "epoch: 27  batch: 81  loss: 0.15329668\n",
      "epoch: 27  batch: 82  loss: 0.13566342\n",
      "epoch: 27  batch: 83  loss: 0.19783880\n",
      "epoch: 27  batch: 84  loss: 0.20883374\n",
      "epoch: 27  batch: 85  loss: 0.12118259\n",
      "epoch: 27  batch: 86  loss: 0.17267683\n",
      "epoch: 27  batch: 87  loss: 0.15626749\n",
      "epoch: 28  batch: 1  loss: 0.09942370\n",
      "epoch: 28  batch: 2  loss: 0.15874232\n",
      "epoch: 28  batch: 3  loss: 0.14608668\n",
      "epoch: 28  batch: 4  loss: 0.11024240\n",
      "epoch: 28  batch: 5  loss: 0.14268933\n",
      "epoch: 28  batch: 6  loss: 0.15125085\n",
      "epoch: 28  batch: 7  loss: 0.10401379\n",
      "epoch: 28  batch: 8  loss: 0.13795033\n",
      "epoch: 28  batch: 9  loss: 0.14086069\n",
      "epoch: 28  batch: 10  loss: 0.10824116\n",
      "epoch: 28  batch: 11  loss: 0.11402562\n",
      "epoch: 28  batch: 12  loss: 0.16434753\n",
      "epoch: 28  batch: 13  loss: 0.13125855\n",
      "epoch: 28  batch: 14  loss: 0.16033618\n",
      "epoch: 28  batch: 15  loss: 0.10635557\n",
      "epoch: 28  batch: 16  loss: 0.09700970\n",
      "epoch: 28  batch: 17  loss: 0.14416809\n",
      "epoch: 28  batch: 18  loss: 0.11936352\n",
      "epoch: 28  batch: 19  loss: 0.12995644\n",
      "epoch: 28  batch: 20  loss: 0.12232554\n",
      "epoch: 28  batch: 21  loss: 0.15670431\n",
      "epoch: 28  batch: 22  loss: 0.12679908\n",
      "epoch: 28  batch: 23  loss: 0.12999094\n",
      "epoch: 28  batch: 24  loss: 0.12955689\n",
      "epoch: 28  batch: 25  loss: 0.09655396\n",
      "epoch: 28  batch: 26  loss: 0.17615178\n",
      "epoch: 28  batch: 27  loss: 0.12706770\n",
      "epoch: 28  batch: 28  loss: 0.16371576\n",
      "epoch: 28  batch: 29  loss: 0.14149688\n",
      "epoch: 28  batch: 30  loss: 0.17506155\n",
      "epoch: 28  batch: 31  loss: 0.16386001\n",
      "epoch: 28  batch: 32  loss: 0.08624535\n",
      "epoch: 28  batch: 33  loss: 0.13847871\n",
      "epoch: 28  batch: 34  loss: 0.15645476\n",
      "epoch: 28  batch: 35  loss: 0.14131157\n",
      "epoch: 28  batch: 36  loss: 0.13730405\n",
      "epoch: 28  batch: 37  loss: 0.12455899\n",
      "epoch: 28  batch: 38  loss: 0.18166362\n",
      "epoch: 28  batch: 39  loss: 0.09443162\n",
      "epoch: 28  batch: 40  loss: 0.18860343\n",
      "epoch: 28  batch: 41  loss: 0.17243521\n",
      "epoch: 28  batch: 42  loss: 0.12127587\n",
      "epoch: 28  batch: 43  loss: 0.11480820\n",
      "epoch: 28  batch: 44  loss: 0.17853056\n",
      "epoch: 28  batch: 45  loss: 0.11705671\n",
      "epoch: 28  batch: 46  loss: 0.11340607\n",
      "epoch: 28  batch: 47  loss: 0.14511783\n",
      "epoch: 28  batch: 48  loss: 0.15628019\n",
      "epoch: 28  batch: 49  loss: 0.11267934\n",
      "epoch: 28  batch: 50  loss: 0.15321290\n",
      "epoch: 28  batch: 51  loss: 0.13118243\n",
      "epoch: 28  batch: 52  loss: 0.12704545\n",
      "epoch: 28  batch: 53  loss: 0.09672976\n",
      "epoch: 28  batch: 54  loss: 0.12368042\n",
      "epoch: 28  batch: 55  loss: 0.14500447\n",
      "epoch: 28  batch: 56  loss: 0.11937892\n",
      "epoch: 28  batch: 57  loss: 0.13824242\n",
      "epoch: 28  batch: 58  loss: 0.09644871\n",
      "epoch: 28  batch: 59  loss: 0.14098340\n",
      "epoch: 28  batch: 60  loss: 0.12575610\n",
      "epoch: 28  batch: 61  loss: 0.07964769\n",
      "epoch: 28  batch: 62  loss: 0.23969996\n",
      "epoch: 28  batch: 63  loss: 0.10190352\n",
      "epoch: 28  batch: 64  loss: 0.20633529\n",
      "epoch: 28  batch: 65  loss: 0.15900703\n",
      "epoch: 28  batch: 66  loss: 0.12386345\n",
      "epoch: 28  batch: 67  loss: 0.13016880\n",
      "epoch: 28  batch: 68  loss: 0.16677934\n",
      "epoch: 28  batch: 69  loss: 0.13197592\n",
      "epoch: 28  batch: 70  loss: 0.18506686\n",
      "epoch: 28  batch: 71  loss: 0.12824324\n",
      "epoch: 28  batch: 72  loss: 0.13700898\n",
      "epoch: 28  batch: 73  loss: 0.17771652\n",
      "epoch: 28  batch: 74  loss: 0.15161435\n",
      "epoch: 28  batch: 75  loss: 0.16606982\n",
      "epoch: 28  batch: 76  loss: 0.18597692\n",
      "epoch: 28  batch: 77  loss: 0.17256178\n",
      "epoch: 28  batch: 78  loss: 0.11705927\n",
      "epoch: 28  batch: 79  loss: 0.10708033\n",
      "epoch: 28  batch: 80  loss: 0.14946970\n",
      "epoch: 28  batch: 81  loss: 0.13409995\n",
      "epoch: 28  batch: 82  loss: 0.16672090\n",
      "epoch: 28  batch: 83  loss: 0.12967294\n",
      "epoch: 28  batch: 84  loss: 0.12225209\n",
      "epoch: 28  batch: 85  loss: 0.14190979\n",
      "epoch: 28  batch: 86  loss: 0.12185584\n",
      "epoch: 28  batch: 87  loss: 0.29722303\n",
      "epoch: 29  batch: 1  loss: 0.16604105\n",
      "epoch: 29  batch: 2  loss: 0.10641681\n",
      "epoch: 29  batch: 3  loss: 0.15185630\n",
      "epoch: 29  batch: 4  loss: 0.12708431\n",
      "epoch: 29  batch: 5  loss: 0.10243951\n",
      "epoch: 29  batch: 6  loss: 0.13521074\n",
      "epoch: 29  batch: 7  loss: 0.14387359\n",
      "epoch: 29  batch: 8  loss: 0.13090692\n",
      "epoch: 29  batch: 9  loss: 0.15807109\n",
      "epoch: 29  batch: 10  loss: 0.20643620\n",
      "epoch: 29  batch: 11  loss: 0.19712484\n",
      "epoch: 29  batch: 12  loss: 0.11777103\n",
      "epoch: 29  batch: 13  loss: 0.14598542\n",
      "epoch: 29  batch: 14  loss: 0.15288909\n",
      "epoch: 29  batch: 15  loss: 0.14721945\n",
      "epoch: 29  batch: 16  loss: 0.17706446\n",
      "epoch: 29  batch: 17  loss: 0.15811704\n",
      "epoch: 29  batch: 18  loss: 0.13493203\n",
      "epoch: 29  batch: 19  loss: 0.14602588\n",
      "epoch: 29  batch: 20  loss: 0.13952729\n",
      "epoch: 29  batch: 21  loss: 0.17067921\n",
      "epoch: 29  batch: 22  loss: 0.11658456\n",
      "epoch: 29  batch: 23  loss: 0.15274134\n",
      "epoch: 29  batch: 24  loss: 0.13332441\n",
      "epoch: 29  batch: 25  loss: 0.10143587\n",
      "epoch: 29  batch: 26  loss: 0.15672714\n",
      "epoch: 29  batch: 27  loss: 0.08779506\n",
      "epoch: 29  batch: 28  loss: 0.10700519\n",
      "epoch: 29  batch: 29  loss: 0.13352537\n",
      "epoch: 29  batch: 30  loss: 0.14937519\n",
      "epoch: 29  batch: 31  loss: 0.13989766\n",
      "epoch: 29  batch: 32  loss: 0.19959378\n",
      "epoch: 29  batch: 33  loss: 0.12397814\n",
      "epoch: 29  batch: 34  loss: 0.13908485\n",
      "epoch: 29  batch: 35  loss: 0.12155347\n",
      "epoch: 29  batch: 36  loss: 0.13790148\n",
      "epoch: 29  batch: 37  loss: 0.14407639\n",
      "epoch: 29  batch: 38  loss: 0.15177611\n",
      "epoch: 29  batch: 39  loss: 0.09531384\n",
      "epoch: 29  batch: 40  loss: 0.14015359\n",
      "epoch: 29  batch: 41  loss: 0.14642306\n",
      "epoch: 29  batch: 42  loss: 0.10699514\n",
      "epoch: 29  batch: 43  loss: 0.16945818\n",
      "epoch: 29  batch: 44  loss: 0.12726921\n",
      "epoch: 29  batch: 45  loss: 0.16140920\n",
      "epoch: 29  batch: 46  loss: 0.14425470\n",
      "epoch: 29  batch: 47  loss: 0.07166973\n",
      "epoch: 29  batch: 48  loss: 0.15424262\n",
      "epoch: 29  batch: 49  loss: 0.08559740\n",
      "epoch: 29  batch: 50  loss: 0.14246252\n",
      "epoch: 29  batch: 51  loss: 0.08784474\n",
      "epoch: 29  batch: 52  loss: 0.11549774\n",
      "epoch: 29  batch: 53  loss: 0.11611234\n",
      "epoch: 29  batch: 54  loss: 0.12378284\n",
      "epoch: 29  batch: 55  loss: 0.12242816\n",
      "epoch: 29  batch: 56  loss: 0.13140701\n",
      "epoch: 29  batch: 57  loss: 0.14853446\n",
      "epoch: 29  batch: 58  loss: 0.10383274\n",
      "epoch: 29  batch: 59  loss: 0.11181541\n",
      "epoch: 29  batch: 60  loss: 0.10618139\n",
      "epoch: 29  batch: 61  loss: 0.17219821\n",
      "epoch: 29  batch: 62  loss: 0.10336017\n",
      "epoch: 29  batch: 63  loss: 0.14653391\n",
      "epoch: 29  batch: 64  loss: 0.14707246\n",
      "epoch: 29  batch: 65  loss: 0.10942307\n",
      "epoch: 29  batch: 66  loss: 0.12077170\n",
      "epoch: 29  batch: 67  loss: 0.13596383\n",
      "epoch: 29  batch: 68  loss: 0.12479474\n",
      "epoch: 29  batch: 69  loss: 0.14204529\n",
      "epoch: 29  batch: 70  loss: 0.15975432\n",
      "epoch: 29  batch: 71  loss: 0.19277145\n",
      "epoch: 29  batch: 72  loss: 0.14357595\n",
      "epoch: 29  batch: 73  loss: 0.11207849\n",
      "epoch: 29  batch: 74  loss: 0.12437867\n",
      "epoch: 29  batch: 75  loss: 0.11891998\n",
      "epoch: 29  batch: 76  loss: 0.17910649\n",
      "epoch: 29  batch: 77  loss: 0.12436971\n",
      "epoch: 29  batch: 78  loss: 0.08984163\n",
      "epoch: 29  batch: 79  loss: 0.12935123\n",
      "epoch: 29  batch: 80  loss: 0.12214084\n",
      "epoch: 29  batch: 81  loss: 0.10226199\n",
      "epoch: 29  batch: 82  loss: 0.11469067\n",
      "epoch: 29  batch: 83  loss: 0.17229071\n",
      "epoch: 29  batch: 84  loss: 0.09700632\n",
      "epoch: 29  batch: 85  loss: 0.11732861\n",
      "epoch: 29  batch: 86  loss: 0.16653682\n",
      "epoch: 29  batch: 87  loss: 0.14936173\n",
      "epoch: 30  batch: 1  loss: 0.12748389\n",
      "epoch: 30  batch: 2  loss: 0.18562260\n",
      "epoch: 30  batch: 3  loss: 0.10871446\n",
      "epoch: 30  batch: 4  loss: 0.13314722\n",
      "epoch: 30  batch: 5  loss: 0.15104425\n",
      "epoch: 30  batch: 6  loss: 0.22054891\n",
      "epoch: 30  batch: 7  loss: 0.12656669\n",
      "epoch: 30  batch: 8  loss: 0.16739917\n",
      "epoch: 30  batch: 9  loss: 0.14329413\n",
      "epoch: 30  batch: 10  loss: 0.11086501\n",
      "epoch: 30  batch: 11  loss: 0.10149325\n",
      "epoch: 30  batch: 12  loss: 0.20610455\n",
      "epoch: 30  batch: 13  loss: 0.18366496\n",
      "epoch: 30  batch: 14  loss: 0.11792117\n",
      "epoch: 30  batch: 15  loss: 0.09599087\n",
      "epoch: 30  batch: 16  loss: 0.10469770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30  batch: 17  loss: 0.13680176\n",
      "epoch: 30  batch: 18  loss: 0.12102819\n",
      "epoch: 30  batch: 19  loss: 0.13845949\n",
      "epoch: 30  batch: 20  loss: 0.11362288\n",
      "epoch: 30  batch: 21  loss: 0.14167570\n",
      "epoch: 30  batch: 22  loss: 0.10328884\n",
      "epoch: 30  batch: 23  loss: 0.12684838\n",
      "epoch: 30  batch: 24  loss: 0.09709343\n",
      "epoch: 30  batch: 25  loss: 0.12775734\n",
      "epoch: 30  batch: 26  loss: 0.07845780\n",
      "epoch: 30  batch: 27  loss: 0.15967382\n",
      "epoch: 30  batch: 28  loss: 0.14561382\n",
      "epoch: 30  batch: 29  loss: 0.14441663\n",
      "epoch: 30  batch: 30  loss: 0.16096884\n",
      "epoch: 30  batch: 31  loss: 0.12367704\n",
      "epoch: 30  batch: 32  loss: 0.12634456\n",
      "epoch: 30  batch: 33  loss: 0.14411424\n",
      "epoch: 30  batch: 34  loss: 0.13053285\n",
      "epoch: 30  batch: 35  loss: 0.12841992\n",
      "epoch: 30  batch: 36  loss: 0.11175688\n",
      "epoch: 30  batch: 37  loss: 0.12213740\n",
      "epoch: 30  batch: 38  loss: 0.17465001\n",
      "epoch: 30  batch: 39  loss: 0.11680284\n",
      "epoch: 30  batch: 40  loss: 0.17215820\n",
      "epoch: 30  batch: 41  loss: 0.13804115\n",
      "epoch: 30  batch: 42  loss: 0.10953845\n",
      "epoch: 30  batch: 43  loss: 0.11639381\n",
      "epoch: 30  batch: 44  loss: 0.12461017\n",
      "epoch: 30  batch: 45  loss: 0.16795337\n",
      "epoch: 30  batch: 46  loss: 0.10203601\n",
      "epoch: 30  batch: 47  loss: 0.13150182\n",
      "epoch: 30  batch: 48  loss: 0.13792743\n",
      "epoch: 30  batch: 49  loss: 0.11973095\n",
      "epoch: 30  batch: 50  loss: 0.20689230\n",
      "epoch: 30  batch: 51  loss: 0.08091444\n",
      "epoch: 30  batch: 52  loss: 0.13206132\n",
      "epoch: 30  batch: 53  loss: 0.13417956\n",
      "epoch: 30  batch: 54  loss: 0.11315946\n",
      "epoch: 30  batch: 55  loss: 0.10793511\n",
      "epoch: 30  batch: 56  loss: 0.10655037\n",
      "epoch: 30  batch: 57  loss: 0.16384707\n",
      "epoch: 30  batch: 58  loss: 0.11993186\n",
      "epoch: 30  batch: 59  loss: 0.17209759\n",
      "epoch: 30  batch: 60  loss: 0.11724927\n",
      "epoch: 30  batch: 61  loss: 0.09944205\n",
      "epoch: 30  batch: 62  loss: 0.14352192\n",
      "epoch: 30  batch: 63  loss: 0.19511572\n",
      "epoch: 30  batch: 64  loss: 0.15332852\n",
      "epoch: 30  batch: 65  loss: 0.14477398\n",
      "epoch: 30  batch: 66  loss: 0.17041466\n",
      "epoch: 30  batch: 67  loss: 0.12235705\n",
      "epoch: 30  batch: 68  loss: 0.13015096\n",
      "epoch: 30  batch: 69  loss: 0.13319048\n",
      "epoch: 30  batch: 70  loss: 0.11292067\n",
      "epoch: 30  batch: 71  loss: 0.12544140\n",
      "epoch: 30  batch: 72  loss: 0.12620273\n",
      "epoch: 30  batch: 73  loss: 0.14206950\n",
      "epoch: 30  batch: 74  loss: 0.15531133\n",
      "epoch: 30  batch: 75  loss: 0.14903668\n",
      "epoch: 30  batch: 76  loss: 0.10866049\n",
      "epoch: 30  batch: 77  loss: 0.14744662\n",
      "epoch: 30  batch: 78  loss: 0.22477357\n",
      "epoch: 30  batch: 79  loss: 0.09686601\n",
      "epoch: 30  batch: 80  loss: 0.13932589\n",
      "epoch: 30  batch: 81  loss: 0.11454192\n",
      "epoch: 30  batch: 82  loss: 0.14922820\n",
      "epoch: 30  batch: 83  loss: 0.10305206\n",
      "epoch: 30  batch: 84  loss: 0.16373581\n",
      "epoch: 30  batch: 85  loss: 0.08744655\n",
      "epoch: 30  batch: 86  loss: 0.20001994\n",
      "epoch: 30  batch: 87  loss: 0.18243669\n",
      "epoch: 31  batch: 1  loss: 0.10393291\n",
      "epoch: 31  batch: 2  loss: 0.08858103\n",
      "epoch: 31  batch: 3  loss: 0.08223694\n",
      "epoch: 31  batch: 4  loss: 0.13082241\n",
      "epoch: 31  batch: 5  loss: 0.10209922\n",
      "epoch: 31  batch: 6  loss: 0.14446370\n",
      "epoch: 31  batch: 7  loss: 0.15039006\n",
      "epoch: 31  batch: 8  loss: 0.10013138\n",
      "epoch: 31  batch: 9  loss: 0.14463517\n",
      "epoch: 31  batch: 10  loss: 0.12178478\n",
      "epoch: 31  batch: 11  loss: 0.14035039\n",
      "epoch: 31  batch: 12  loss: 0.22539121\n",
      "epoch: 31  batch: 13  loss: 0.10565741\n",
      "epoch: 31  batch: 14  loss: 0.10656750\n",
      "epoch: 31  batch: 15  loss: 0.12463380\n",
      "epoch: 31  batch: 16  loss: 0.13537626\n",
      "epoch: 31  batch: 17  loss: 0.15839060\n",
      "epoch: 31  batch: 18  loss: 0.11120307\n",
      "epoch: 31  batch: 19  loss: 0.10557982\n",
      "epoch: 31  batch: 20  loss: 0.12018529\n",
      "epoch: 31  batch: 21  loss: 0.13035583\n",
      "epoch: 31  batch: 22  loss: 0.11886903\n",
      "epoch: 31  batch: 23  loss: 0.12667735\n",
      "epoch: 31  batch: 24  loss: 0.11219545\n",
      "epoch: 31  batch: 25  loss: 0.14675564\n",
      "epoch: 31  batch: 26  loss: 0.15703164\n",
      "epoch: 31  batch: 27  loss: 0.13884507\n",
      "epoch: 31  batch: 28  loss: 0.13830975\n",
      "epoch: 31  batch: 29  loss: 0.14047652\n",
      "epoch: 31  batch: 30  loss: 0.09349018\n",
      "epoch: 31  batch: 31  loss: 0.14360859\n",
      "epoch: 31  batch: 32  loss: 0.15367585\n",
      "epoch: 31  batch: 33  loss: 0.17400219\n",
      "epoch: 31  batch: 34  loss: 0.15240195\n",
      "epoch: 31  batch: 35  loss: 0.10844460\n",
      "epoch: 31  batch: 36  loss: 0.13696307\n",
      "epoch: 31  batch: 37  loss: 0.13490897\n",
      "epoch: 31  batch: 38  loss: 0.11683983\n",
      "epoch: 31  batch: 39  loss: 0.12788942\n",
      "epoch: 31  batch: 40  loss: 0.11148600\n",
      "epoch: 31  batch: 41  loss: 0.10698249\n",
      "epoch: 31  batch: 42  loss: 0.14176698\n",
      "epoch: 31  batch: 43  loss: 0.10232950\n",
      "epoch: 31  batch: 44  loss: 0.11144038\n",
      "epoch: 31  batch: 45  loss: 0.10513072\n",
      "epoch: 31  batch: 46  loss: 0.15979657\n",
      "epoch: 31  batch: 47  loss: 0.11221415\n",
      "epoch: 31  batch: 48  loss: 0.12929367\n",
      "epoch: 31  batch: 49  loss: 0.11163705\n",
      "epoch: 31  batch: 50  loss: 0.10590280\n",
      "epoch: 31  batch: 51  loss: 0.14045802\n",
      "epoch: 31  batch: 52  loss: 0.11113436\n",
      "epoch: 31  batch: 53  loss: 0.11743605\n",
      "epoch: 31  batch: 54  loss: 0.18136619\n",
      "epoch: 31  batch: 55  loss: 0.12039627\n",
      "epoch: 31  batch: 56  loss: 0.14012903\n",
      "epoch: 31  batch: 57  loss: 0.13227877\n",
      "epoch: 31  batch: 58  loss: 0.20862949\n",
      "epoch: 31  batch: 59  loss: 0.14856981\n",
      "epoch: 31  batch: 60  loss: 0.12441943\n",
      "epoch: 31  batch: 61  loss: 0.13773496\n",
      "epoch: 31  batch: 62  loss: 0.08683810\n",
      "epoch: 31  batch: 63  loss: 0.13325037\n",
      "epoch: 31  batch: 64  loss: 0.13384151\n",
      "epoch: 31  batch: 65  loss: 0.18163827\n",
      "epoch: 31  batch: 66  loss: 0.08136280\n",
      "epoch: 31  batch: 67  loss: 0.13121128\n",
      "epoch: 31  batch: 68  loss: 0.16042927\n",
      "epoch: 31  batch: 69  loss: 0.13373944\n",
      "epoch: 31  batch: 70  loss: 0.13578385\n",
      "epoch: 31  batch: 71  loss: 0.10720682\n",
      "epoch: 31  batch: 72  loss: 0.11101557\n",
      "epoch: 31  batch: 73  loss: 0.12054157\n",
      "epoch: 31  batch: 74  loss: 0.11805473\n",
      "epoch: 31  batch: 75  loss: 0.13539834\n",
      "epoch: 31  batch: 76  loss: 0.16950116\n",
      "epoch: 31  batch: 77  loss: 0.13637263\n",
      "epoch: 31  batch: 78  loss: 0.10030134\n",
      "epoch: 31  batch: 79  loss: 0.13279611\n",
      "epoch: 31  batch: 80  loss: 0.13517201\n",
      "epoch: 31  batch: 81  loss: 0.14576647\n",
      "epoch: 31  batch: 82  loss: 0.13294977\n",
      "epoch: 31  batch: 83  loss: 0.12497018\n",
      "epoch: 31  batch: 84  loss: 0.15332042\n",
      "epoch: 31  batch: 85  loss: 0.10610352\n",
      "epoch: 31  batch: 86  loss: 0.12747931\n",
      "epoch: 31  batch: 87  loss: 0.13297983\n",
      "epoch: 32  batch: 1  loss: 0.09686629\n",
      "epoch: 32  batch: 2  loss: 0.13211027\n",
      "epoch: 32  batch: 3  loss: 0.11402390\n",
      "epoch: 32  batch: 4  loss: 0.09339446\n",
      "epoch: 32  batch: 5  loss: 0.15729934\n",
      "epoch: 32  batch: 6  loss: 0.11159589\n",
      "epoch: 32  batch: 7  loss: 0.15907371\n",
      "epoch: 32  batch: 8  loss: 0.10833358\n",
      "epoch: 32  batch: 9  loss: 0.16597733\n",
      "epoch: 32  batch: 10  loss: 0.14127484\n",
      "epoch: 32  batch: 11  loss: 0.12129986\n",
      "epoch: 32  batch: 12  loss: 0.09278692\n",
      "epoch: 32  batch: 13  loss: 0.10753502\n",
      "epoch: 32  batch: 14  loss: 0.14262648\n",
      "epoch: 32  batch: 15  loss: 0.13863319\n",
      "epoch: 32  batch: 16  loss: 0.16689001\n",
      "epoch: 32  batch: 17  loss: 0.14955224\n",
      "epoch: 32  batch: 18  loss: 0.15092073\n",
      "epoch: 32  batch: 19  loss: 0.12765220\n",
      "epoch: 32  batch: 20  loss: 0.13478820\n",
      "epoch: 32  batch: 21  loss: 0.11487152\n",
      "epoch: 32  batch: 22  loss: 0.15822326\n",
      "epoch: 32  batch: 23  loss: 0.18848054\n",
      "epoch: 32  batch: 24  loss: 0.14433928\n",
      "epoch: 32  batch: 25  loss: 0.09146406\n",
      "epoch: 32  batch: 26  loss: 0.11341909\n",
      "epoch: 32  batch: 27  loss: 0.13904156\n",
      "epoch: 32  batch: 28  loss: 0.10767170\n",
      "epoch: 32  batch: 29  loss: 0.11847548\n",
      "epoch: 32  batch: 30  loss: 0.13328475\n",
      "epoch: 32  batch: 31  loss: 0.09964688\n",
      "epoch: 32  batch: 32  loss: 0.12868941\n",
      "epoch: 32  batch: 33  loss: 0.08579545\n",
      "epoch: 32  batch: 34  loss: 0.13516985\n",
      "epoch: 32  batch: 35  loss: 0.12865685\n",
      "epoch: 32  batch: 36  loss: 0.07976930\n",
      "epoch: 32  batch: 37  loss: 0.11197218\n",
      "epoch: 32  batch: 38  loss: 0.13502745\n",
      "epoch: 32  batch: 39  loss: 0.11425062\n",
      "epoch: 32  batch: 40  loss: 0.09346002\n",
      "epoch: 32  batch: 41  loss: 0.12120298\n",
      "epoch: 32  batch: 42  loss: 0.10766602\n",
      "epoch: 32  batch: 43  loss: 0.14481732\n",
      "epoch: 32  batch: 44  loss: 0.14390153\n",
      "epoch: 32  batch: 45  loss: 0.08838572\n",
      "epoch: 32  batch: 46  loss: 0.12241188\n",
      "epoch: 32  batch: 47  loss: 0.16623034\n",
      "epoch: 32  batch: 48  loss: 0.12324286\n",
      "epoch: 32  batch: 49  loss: 0.08596039\n",
      "epoch: 32  batch: 50  loss: 0.09468095\n",
      "epoch: 32  batch: 51  loss: 0.14218763\n",
      "epoch: 32  batch: 52  loss: 0.22331367\n",
      "epoch: 32  batch: 53  loss: 0.17320201\n",
      "epoch: 32  batch: 54  loss: 0.10021409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32  batch: 55  loss: 0.13546589\n",
      "epoch: 32  batch: 56  loss: 0.12101427\n",
      "epoch: 32  batch: 57  loss: 0.08124587\n",
      "epoch: 32  batch: 58  loss: 0.13605629\n",
      "epoch: 32  batch: 59  loss: 0.16415295\n",
      "epoch: 32  batch: 60  loss: 0.07790607\n",
      "epoch: 32  batch: 61  loss: 0.09069174\n",
      "epoch: 32  batch: 62  loss: 0.12167978\n",
      "epoch: 32  batch: 63  loss: 0.12255730\n",
      "epoch: 32  batch: 64  loss: 0.09758373\n",
      "epoch: 32  batch: 65  loss: 0.14150646\n",
      "epoch: 32  batch: 66  loss: 0.16152774\n",
      "epoch: 32  batch: 67  loss: 0.11954693\n",
      "epoch: 32  batch: 68  loss: 0.10786483\n",
      "epoch: 32  batch: 69  loss: 0.13822538\n",
      "epoch: 32  batch: 70  loss: 0.11586829\n",
      "epoch: 32  batch: 71  loss: 0.10554039\n",
      "epoch: 32  batch: 72  loss: 0.17213380\n",
      "epoch: 32  batch: 73  loss: 0.12687109\n",
      "epoch: 32  batch: 74  loss: 0.11987592\n",
      "epoch: 32  batch: 75  loss: 0.08913563\n",
      "epoch: 32  batch: 76  loss: 0.12370446\n",
      "epoch: 32  batch: 77  loss: 0.11693705\n",
      "epoch: 32  batch: 78  loss: 0.11765458\n",
      "epoch: 32  batch: 79  loss: 0.10624304\n",
      "epoch: 32  batch: 80  loss: 0.11850943\n",
      "epoch: 32  batch: 81  loss: 0.13636395\n",
      "epoch: 32  batch: 82  loss: 0.13890703\n",
      "epoch: 32  batch: 83  loss: 0.09346323\n",
      "epoch: 32  batch: 84  loss: 0.17719492\n",
      "epoch: 32  batch: 85  loss: 0.13175149\n",
      "epoch: 32  batch: 86  loss: 0.09806055\n",
      "epoch: 32  batch: 87  loss: 0.12169988\n",
      "epoch: 33  batch: 1  loss: 0.11049437\n",
      "epoch: 33  batch: 2  loss: 0.12419704\n",
      "epoch: 33  batch: 3  loss: 0.09971192\n",
      "epoch: 33  batch: 4  loss: 0.16491552\n",
      "epoch: 33  batch: 5  loss: 0.07468972\n",
      "epoch: 33  batch: 6  loss: 0.09081674\n",
      "epoch: 33  batch: 7  loss: 0.10420998\n",
      "epoch: 33  batch: 8  loss: 0.14237586\n",
      "epoch: 33  batch: 9  loss: 0.13058360\n",
      "epoch: 33  batch: 10  loss: 0.14657216\n",
      "epoch: 33  batch: 11  loss: 0.10563623\n",
      "epoch: 33  batch: 12  loss: 0.09253272\n",
      "epoch: 33  batch: 13  loss: 0.08161920\n",
      "epoch: 33  batch: 14  loss: 0.12583989\n",
      "epoch: 33  batch: 15  loss: 0.09539826\n",
      "epoch: 33  batch: 16  loss: 0.09103574\n",
      "epoch: 33  batch: 17  loss: 0.16016208\n",
      "epoch: 33  batch: 18  loss: 0.10268471\n",
      "epoch: 33  batch: 19  loss: 0.15603441\n",
      "epoch: 33  batch: 20  loss: 0.10678771\n",
      "epoch: 33  batch: 21  loss: 0.18356071\n",
      "epoch: 33  batch: 22  loss: 0.10373484\n",
      "epoch: 33  batch: 23  loss: 0.10262799\n",
      "epoch: 33  batch: 24  loss: 0.18387759\n",
      "epoch: 33  batch: 25  loss: 0.09920681\n",
      "epoch: 33  batch: 26  loss: 0.12921745\n",
      "epoch: 33  batch: 27  loss: 0.13028225\n",
      "epoch: 33  batch: 28  loss: 0.11824995\n",
      "epoch: 33  batch: 29  loss: 0.11905912\n",
      "epoch: 33  batch: 30  loss: 0.08266672\n",
      "epoch: 33  batch: 31  loss: 0.16667689\n",
      "epoch: 33  batch: 32  loss: 0.09753903\n",
      "epoch: 33  batch: 33  loss: 0.15918134\n",
      "epoch: 33  batch: 34  loss: 0.14815071\n",
      "epoch: 33  batch: 35  loss: 0.17148221\n",
      "epoch: 33  batch: 36  loss: 0.14345005\n",
      "epoch: 33  batch: 37  loss: 0.09665997\n",
      "epoch: 33  batch: 38  loss: 0.13665721\n",
      "epoch: 33  batch: 39  loss: 0.12764578\n",
      "epoch: 33  batch: 40  loss: 0.08616234\n",
      "epoch: 33  batch: 41  loss: 0.13741654\n",
      "epoch: 33  batch: 42  loss: 0.10474577\n",
      "epoch: 33  batch: 43  loss: 0.15082698\n",
      "epoch: 33  batch: 44  loss: 0.10454626\n",
      "epoch: 33  batch: 45  loss: 0.10218145\n",
      "epoch: 33  batch: 46  loss: 0.12090696\n",
      "epoch: 33  batch: 47  loss: 0.15661462\n",
      "epoch: 33  batch: 48  loss: 0.13730103\n",
      "epoch: 33  batch: 49  loss: 0.15904976\n",
      "epoch: 33  batch: 50  loss: 0.08997449\n",
      "epoch: 33  batch: 51  loss: 0.10329606\n",
      "epoch: 33  batch: 52  loss: 0.09249894\n",
      "epoch: 33  batch: 53  loss: 0.12550259\n",
      "epoch: 33  batch: 54  loss: 0.12169397\n",
      "epoch: 33  batch: 55  loss: 0.07900470\n",
      "epoch: 33  batch: 56  loss: 0.12024659\n",
      "epoch: 33  batch: 57  loss: 0.11624274\n",
      "epoch: 33  batch: 58  loss: 0.15558554\n",
      "epoch: 33  batch: 59  loss: 0.15060261\n",
      "epoch: 33  batch: 60  loss: 0.16416499\n",
      "epoch: 33  batch: 61  loss: 0.10059106\n",
      "epoch: 33  batch: 62  loss: 0.10193679\n",
      "epoch: 33  batch: 63  loss: 0.09009700\n",
      "epoch: 33  batch: 64  loss: 0.11118980\n",
      "epoch: 33  batch: 65  loss: 0.09151705\n",
      "epoch: 33  batch: 66  loss: 0.22889753\n",
      "epoch: 33  batch: 67  loss: 0.14820294\n",
      "epoch: 33  batch: 68  loss: 0.09735990\n",
      "epoch: 33  batch: 69  loss: 0.11518339\n",
      "epoch: 33  batch: 70  loss: 0.09890059\n",
      "epoch: 33  batch: 71  loss: 0.11936745\n",
      "epoch: 33  batch: 72  loss: 0.14202824\n",
      "epoch: 33  batch: 73  loss: 0.16199523\n",
      "epoch: 33  batch: 74  loss: 0.10318183\n",
      "epoch: 33  batch: 75  loss: 0.10736044\n",
      "epoch: 33  batch: 76  loss: 0.13394412\n",
      "epoch: 33  batch: 77  loss: 0.09123502\n",
      "epoch: 33  batch: 78  loss: 0.08043645\n",
      "epoch: 33  batch: 79  loss: 0.19820142\n",
      "epoch: 33  batch: 80  loss: 0.10614096\n",
      "epoch: 33  batch: 81  loss: 0.10028066\n",
      "epoch: 33  batch: 82  loss: 0.11628564\n",
      "epoch: 33  batch: 83  loss: 0.08782210\n",
      "epoch: 33  batch: 84  loss: 0.11744672\n",
      "epoch: 33  batch: 85  loss: 0.13203758\n",
      "epoch: 33  batch: 86  loss: 0.11006516\n",
      "epoch: 33  batch: 87  loss: 0.08191599\n",
      "epoch: 34  batch: 1  loss: 0.08024026\n",
      "epoch: 34  batch: 2  loss: 0.12445076\n",
      "epoch: 34  batch: 3  loss: 0.09281489\n",
      "epoch: 34  batch: 4  loss: 0.13572739\n",
      "epoch: 34  batch: 5  loss: 0.09509532\n",
      "epoch: 34  batch: 6  loss: 0.10206623\n",
      "epoch: 34  batch: 7  loss: 0.08669332\n",
      "epoch: 34  batch: 8  loss: 0.13809240\n",
      "epoch: 34  batch: 9  loss: 0.11865351\n",
      "epoch: 34  batch: 10  loss: 0.15979062\n",
      "epoch: 34  batch: 11  loss: 0.08190282\n",
      "epoch: 34  batch: 12  loss: 0.10626765\n",
      "epoch: 34  batch: 13  loss: 0.12238901\n",
      "epoch: 34  batch: 14  loss: 0.13138494\n",
      "epoch: 34  batch: 15  loss: 0.10684735\n",
      "epoch: 34  batch: 16  loss: 0.15143760\n",
      "epoch: 34  batch: 17  loss: 0.16360793\n",
      "epoch: 34  batch: 18  loss: 0.17635477\n",
      "epoch: 34  batch: 19  loss: 0.11609528\n",
      "epoch: 34  batch: 20  loss: 0.13765049\n",
      "epoch: 34  batch: 21  loss: 0.07703703\n",
      "epoch: 34  batch: 22  loss: 0.11330628\n",
      "epoch: 34  batch: 23  loss: 0.10950966\n",
      "epoch: 34  batch: 24  loss: 0.10606142\n",
      "epoch: 34  batch: 25  loss: 0.10162087\n",
      "epoch: 34  batch: 26  loss: 0.06524650\n",
      "epoch: 34  batch: 27  loss: 0.10573033\n",
      "epoch: 34  batch: 28  loss: 0.10120863\n",
      "epoch: 34  batch: 29  loss: 0.10552916\n",
      "epoch: 34  batch: 30  loss: 0.11302979\n",
      "epoch: 34  batch: 31  loss: 0.09412508\n",
      "epoch: 34  batch: 32  loss: 0.11552545\n",
      "epoch: 34  batch: 33  loss: 0.12633827\n",
      "epoch: 34  batch: 34  loss: 0.09305630\n",
      "epoch: 34  batch: 35  loss: 0.11923741\n",
      "epoch: 34  batch: 36  loss: 0.14553185\n",
      "epoch: 34  batch: 37  loss: 0.13291308\n",
      "epoch: 34  batch: 38  loss: 0.09389070\n",
      "epoch: 34  batch: 39  loss: 0.10680611\n",
      "epoch: 34  batch: 40  loss: 0.18590149\n",
      "epoch: 34  batch: 41  loss: 0.10251264\n",
      "epoch: 34  batch: 42  loss: 0.10279451\n",
      "epoch: 34  batch: 43  loss: 0.11343431\n",
      "epoch: 34  batch: 44  loss: 0.13485543\n",
      "epoch: 34  batch: 45  loss: 0.10120208\n",
      "epoch: 34  batch: 46  loss: 0.12118550\n",
      "epoch: 34  batch: 47  loss: 0.12072626\n",
      "epoch: 34  batch: 48  loss: 0.09333669\n",
      "epoch: 34  batch: 49  loss: 0.17457567\n",
      "epoch: 34  batch: 50  loss: 0.13066669\n",
      "epoch: 34  batch: 51  loss: 0.07011392\n",
      "epoch: 34  batch: 52  loss: 0.08357289\n",
      "epoch: 34  batch: 53  loss: 0.10957706\n",
      "epoch: 34  batch: 54  loss: 0.10443036\n",
      "epoch: 34  batch: 55  loss: 0.07835551\n",
      "epoch: 34  batch: 56  loss: 0.13496740\n",
      "epoch: 34  batch: 57  loss: 0.07383288\n",
      "epoch: 34  batch: 58  loss: 0.09621000\n",
      "epoch: 34  batch: 59  loss: 0.09995989\n",
      "epoch: 34  batch: 60  loss: 0.22477199\n",
      "epoch: 34  batch: 61  loss: 0.14183418\n",
      "epoch: 34  batch: 62  loss: 0.07764287\n",
      "epoch: 34  batch: 63  loss: 0.09845835\n",
      "epoch: 34  batch: 64  loss: 0.11934252\n",
      "epoch: 34  batch: 65  loss: 0.07611266\n",
      "epoch: 34  batch: 66  loss: 0.12172097\n",
      "epoch: 34  batch: 67  loss: 0.17763533\n",
      "epoch: 34  batch: 68  loss: 0.08057485\n",
      "epoch: 34  batch: 69  loss: 0.10815379\n",
      "epoch: 34  batch: 70  loss: 0.10652446\n",
      "epoch: 34  batch: 71  loss: 0.17204572\n",
      "epoch: 34  batch: 72  loss: 0.14238003\n",
      "epoch: 34  batch: 73  loss: 0.13529432\n",
      "epoch: 34  batch: 74  loss: 0.11226137\n",
      "epoch: 34  batch: 75  loss: 0.08442469\n",
      "epoch: 34  batch: 76  loss: 0.13264744\n",
      "epoch: 34  batch: 77  loss: 0.12526891\n",
      "epoch: 34  batch: 78  loss: 0.11590093\n",
      "epoch: 34  batch: 79  loss: 0.10988216\n",
      "epoch: 34  batch: 80  loss: 0.09172507\n",
      "epoch: 34  batch: 81  loss: 0.11980022\n",
      "epoch: 34  batch: 82  loss: 0.09000902\n",
      "epoch: 34  batch: 83  loss: 0.14211947\n",
      "epoch: 34  batch: 84  loss: 0.10253950\n",
      "epoch: 34  batch: 85  loss: 0.09038231\n",
      "epoch: 34  batch: 86  loss: 0.10755496\n",
      "epoch: 34  batch: 87  loss: 0.14660609\n",
      "epoch: 35  batch: 1  loss: 0.11221533\n",
      "epoch: 35  batch: 2  loss: 0.11036927\n",
      "epoch: 35  batch: 3  loss: 0.11330339\n",
      "epoch: 35  batch: 4  loss: 0.10046399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35  batch: 5  loss: 0.09336382\n",
      "epoch: 35  batch: 6  loss: 0.11690604\n",
      "epoch: 35  batch: 7  loss: 0.07640157\n",
      "epoch: 35  batch: 8  loss: 0.12688001\n",
      "epoch: 35  batch: 9  loss: 0.12694326\n",
      "epoch: 35  batch: 10  loss: 0.07109984\n",
      "epoch: 35  batch: 11  loss: 0.10708898\n",
      "epoch: 35  batch: 12  loss: 0.13470185\n",
      "epoch: 35  batch: 13  loss: 0.09716039\n",
      "epoch: 35  batch: 14  loss: 0.12394092\n",
      "epoch: 35  batch: 15  loss: 0.12012316\n",
      "epoch: 35  batch: 16  loss: 0.06956463\n",
      "epoch: 35  batch: 17  loss: 0.14908782\n",
      "epoch: 35  batch: 18  loss: 0.14188468\n",
      "epoch: 35  batch: 19  loss: 0.16946222\n",
      "epoch: 35  batch: 20  loss: 0.16089989\n",
      "epoch: 35  batch: 21  loss: 0.09458071\n",
      "epoch: 35  batch: 22  loss: 0.12220079\n",
      "epoch: 35  batch: 23  loss: 0.10213499\n",
      "epoch: 35  batch: 24  loss: 0.11634850\n",
      "epoch: 35  batch: 25  loss: 0.11785508\n",
      "epoch: 35  batch: 26  loss: 0.08897390\n",
      "epoch: 35  batch: 27  loss: 0.09202460\n",
      "epoch: 35  batch: 28  loss: 0.09328450\n",
      "epoch: 35  batch: 29  loss: 0.06929407\n",
      "epoch: 35  batch: 30  loss: 0.09160618\n",
      "epoch: 35  batch: 31  loss: 0.09738448\n",
      "epoch: 35  batch: 32  loss: 0.11763815\n",
      "epoch: 35  batch: 33  loss: 0.07323936\n",
      "epoch: 35  batch: 34  loss: 0.09533646\n",
      "epoch: 35  batch: 35  loss: 0.09041458\n",
      "epoch: 35  batch: 36  loss: 0.19827169\n",
      "epoch: 35  batch: 37  loss: 0.14316989\n",
      "epoch: 35  batch: 38  loss: 0.11831930\n",
      "epoch: 35  batch: 39  loss: 0.11175749\n",
      "epoch: 35  batch: 40  loss: 0.11326830\n",
      "epoch: 35  batch: 41  loss: 0.10007843\n",
      "epoch: 35  batch: 42  loss: 0.08442564\n",
      "epoch: 35  batch: 43  loss: 0.12995841\n",
      "epoch: 35  batch: 44  loss: 0.13527213\n",
      "epoch: 35  batch: 45  loss: 0.12311100\n",
      "epoch: 35  batch: 46  loss: 0.09392811\n",
      "epoch: 35  batch: 47  loss: 0.11941867\n",
      "epoch: 35  batch: 48  loss: 0.11022999\n",
      "epoch: 35  batch: 49  loss: 0.12586620\n",
      "epoch: 35  batch: 50  loss: 0.11581867\n",
      "epoch: 35  batch: 51  loss: 0.10340327\n",
      "epoch: 35  batch: 52  loss: 0.09287872\n",
      "epoch: 35  batch: 53  loss: 0.06770833\n",
      "epoch: 35  batch: 54  loss: 0.13239245\n",
      "epoch: 35  batch: 55  loss: 0.11133908\n",
      "epoch: 35  batch: 56  loss: 0.12260006\n",
      "epoch: 35  batch: 57  loss: 0.08856763\n",
      "epoch: 35  batch: 58  loss: 0.11965486\n",
      "epoch: 35  batch: 59  loss: 0.11458509\n",
      "epoch: 35  batch: 60  loss: 0.07050263\n",
      "epoch: 35  batch: 61  loss: 0.10031084\n",
      "epoch: 35  batch: 62  loss: 0.15218085\n",
      "epoch: 35  batch: 63  loss: 0.10591288\n",
      "epoch: 35  batch: 64  loss: 0.08984877\n",
      "epoch: 35  batch: 65  loss: 0.08707596\n",
      "epoch: 35  batch: 66  loss: 0.08677206\n",
      "epoch: 35  batch: 67  loss: 0.12290089\n",
      "epoch: 35  batch: 68  loss: 0.10400713\n",
      "epoch: 35  batch: 69  loss: 0.10924383\n",
      "epoch: 35  batch: 70  loss: 0.15271598\n",
      "epoch: 35  batch: 71  loss: 0.09897940\n",
      "epoch: 35  batch: 72  loss: 0.09796039\n",
      "epoch: 35  batch: 73  loss: 0.10036797\n",
      "epoch: 35  batch: 74  loss: 0.10250652\n",
      "epoch: 35  batch: 75  loss: 0.18381454\n",
      "epoch: 35  batch: 76  loss: 0.09731778\n",
      "epoch: 35  batch: 77  loss: 0.11047436\n",
      "epoch: 35  batch: 78  loss: 0.10842516\n",
      "epoch: 35  batch: 79  loss: 0.09857274\n",
      "epoch: 35  batch: 80  loss: 0.07592243\n",
      "epoch: 35  batch: 81  loss: 0.10191800\n",
      "epoch: 35  batch: 82  loss: 0.14391492\n",
      "epoch: 35  batch: 83  loss: 0.13283671\n",
      "epoch: 35  batch: 84  loss: 0.12082143\n",
      "epoch: 35  batch: 85  loss: 0.11033160\n",
      "epoch: 35  batch: 86  loss: 0.10469060\n",
      "epoch: 35  batch: 87  loss: 0.10401038\n",
      "epoch: 36  batch: 1  loss: 0.08614562\n",
      "epoch: 36  batch: 2  loss: 0.09942982\n",
      "epoch: 36  batch: 3  loss: 0.17390455\n",
      "epoch: 36  batch: 4  loss: 0.09566052\n",
      "epoch: 36  batch: 5  loss: 0.09885552\n",
      "epoch: 36  batch: 6  loss: 0.06494456\n",
      "epoch: 36  batch: 7  loss: 0.11511691\n",
      "epoch: 36  batch: 8  loss: 0.10663097\n",
      "epoch: 36  batch: 9  loss: 0.13363223\n",
      "epoch: 36  batch: 10  loss: 0.07577526\n",
      "epoch: 36  batch: 11  loss: 0.07698750\n",
      "epoch: 36  batch: 12  loss: 0.08523329\n",
      "epoch: 36  batch: 13  loss: 0.14094670\n",
      "epoch: 36  batch: 14  loss: 0.08765297\n",
      "epoch: 36  batch: 15  loss: 0.09802265\n",
      "epoch: 36  batch: 16  loss: 0.06881139\n",
      "epoch: 36  batch: 17  loss: 0.11158104\n",
      "epoch: 36  batch: 18  loss: 0.08834378\n",
      "epoch: 36  batch: 19  loss: 0.12685293\n",
      "epoch: 36  batch: 20  loss: 0.09671975\n",
      "epoch: 36  batch: 21  loss: 0.09661561\n",
      "epoch: 36  batch: 22  loss: 0.07441702\n",
      "epoch: 36  batch: 23  loss: 0.07877301\n",
      "epoch: 36  batch: 24  loss: 0.09033731\n",
      "epoch: 36  batch: 25  loss: 0.12174720\n",
      "epoch: 36  batch: 26  loss: 0.10482992\n",
      "epoch: 36  batch: 27  loss: 0.10176373\n",
      "epoch: 36  batch: 28  loss: 0.12383518\n",
      "epoch: 36  batch: 29  loss: 0.07746097\n",
      "epoch: 36  batch: 30  loss: 0.10656194\n",
      "epoch: 36  batch: 31  loss: 0.10363573\n",
      "epoch: 36  batch: 32  loss: 0.07529792\n",
      "epoch: 36  batch: 33  loss: 0.13270132\n",
      "epoch: 36  batch: 34  loss: 0.09298891\n",
      "epoch: 36  batch: 35  loss: 0.17455450\n",
      "epoch: 36  batch: 36  loss: 0.07325535\n",
      "epoch: 36  batch: 37  loss: 0.08752186\n",
      "epoch: 36  batch: 38  loss: 0.18453930\n",
      "epoch: 36  batch: 39  loss: 0.08010999\n",
      "epoch: 36  batch: 40  loss: 0.13925867\n",
      "epoch: 36  batch: 41  loss: 0.09387982\n",
      "epoch: 36  batch: 42  loss: 0.09817726\n",
      "epoch: 36  batch: 43  loss: 0.09518706\n",
      "epoch: 36  batch: 44  loss: 0.12952098\n",
      "epoch: 36  batch: 45  loss: 0.12164365\n",
      "epoch: 36  batch: 46  loss: 0.10533752\n",
      "epoch: 36  batch: 47  loss: 0.14515173\n",
      "epoch: 36  batch: 48  loss: 0.15555398\n",
      "epoch: 36  batch: 49  loss: 0.11768428\n",
      "epoch: 36  batch: 50  loss: 0.07707842\n",
      "epoch: 36  batch: 51  loss: 0.12152517\n",
      "epoch: 36  batch: 52  loss: 0.09491678\n",
      "epoch: 36  batch: 53  loss: 0.11140247\n",
      "epoch: 36  batch: 54  loss: 0.13975230\n",
      "epoch: 36  batch: 55  loss: 0.09466639\n",
      "epoch: 36  batch: 56  loss: 0.08062802\n",
      "epoch: 36  batch: 57  loss: 0.10979958\n",
      "epoch: 36  batch: 58  loss: 0.10857536\n",
      "epoch: 36  batch: 59  loss: 0.10803482\n",
      "epoch: 36  batch: 60  loss: 0.14015985\n",
      "epoch: 36  batch: 61  loss: 0.07787976\n",
      "epoch: 36  batch: 62  loss: 0.09919611\n",
      "epoch: 36  batch: 63  loss: 0.09792294\n",
      "epoch: 36  batch: 64  loss: 0.10699388\n",
      "epoch: 36  batch: 65  loss: 0.10812768\n",
      "epoch: 36  batch: 66  loss: 0.11203858\n",
      "epoch: 36  batch: 67  loss: 0.09082510\n",
      "epoch: 36  batch: 68  loss: 0.08086807\n",
      "epoch: 36  batch: 69  loss: 0.10218778\n",
      "epoch: 36  batch: 70  loss: 0.16520004\n",
      "epoch: 36  batch: 71  loss: 0.10650161\n",
      "epoch: 36  batch: 72  loss: 0.13806148\n",
      "epoch: 36  batch: 73  loss: 0.07769809\n",
      "epoch: 36  batch: 74  loss: 0.11211776\n",
      "epoch: 36  batch: 75  loss: 0.09080724\n",
      "epoch: 36  batch: 76  loss: 0.06836989\n",
      "epoch: 36  batch: 77  loss: 0.08760000\n",
      "epoch: 36  batch: 78  loss: 0.10857492\n",
      "epoch: 36  batch: 79  loss: 0.08215782\n",
      "epoch: 36  batch: 80  loss: 0.08171684\n",
      "epoch: 36  batch: 81  loss: 0.16305380\n",
      "epoch: 36  batch: 82  loss: 0.14835960\n",
      "epoch: 36  batch: 83  loss: 0.10829622\n",
      "epoch: 36  batch: 84  loss: 0.09778211\n",
      "epoch: 36  batch: 85  loss: 0.09448315\n",
      "epoch: 36  batch: 86  loss: 0.13104005\n",
      "epoch: 36  batch: 87  loss: 0.11167390\n",
      "epoch: 37  batch: 1  loss: 0.12170824\n",
      "epoch: 37  batch: 2  loss: 0.09549820\n",
      "epoch: 37  batch: 3  loss: 0.09333569\n",
      "epoch: 37  batch: 4  loss: 0.08818556\n",
      "epoch: 37  batch: 5  loss: 0.07306816\n",
      "epoch: 37  batch: 6  loss: 0.10028627\n",
      "epoch: 37  batch: 7  loss: 0.16759245\n",
      "epoch: 37  batch: 8  loss: 0.08565594\n",
      "epoch: 37  batch: 9  loss: 0.10448538\n",
      "epoch: 37  batch: 10  loss: 0.08367540\n",
      "epoch: 37  batch: 11  loss: 0.10505600\n",
      "epoch: 37  batch: 12  loss: 0.09606011\n",
      "epoch: 37  batch: 13  loss: 0.13749743\n",
      "epoch: 37  batch: 14  loss: 0.19386555\n",
      "epoch: 37  batch: 15  loss: 0.08083747\n",
      "epoch: 37  batch: 16  loss: 0.19060269\n",
      "epoch: 37  batch: 17  loss: 0.11972627\n",
      "epoch: 37  batch: 18  loss: 0.07375902\n",
      "epoch: 37  batch: 19  loss: 0.09171090\n",
      "epoch: 37  batch: 20  loss: 0.09278090\n",
      "epoch: 37  batch: 21  loss: 0.08780142\n",
      "epoch: 37  batch: 22  loss: 0.09343656\n",
      "epoch: 37  batch: 23  loss: 0.14515099\n",
      "epoch: 37  batch: 24  loss: 0.13644940\n",
      "epoch: 37  batch: 25  loss: 0.10525143\n",
      "epoch: 37  batch: 26  loss: 0.15670897\n",
      "epoch: 37  batch: 27  loss: 0.11403324\n",
      "epoch: 37  batch: 28  loss: 0.07910961\n",
      "epoch: 37  batch: 29  loss: 0.09103858\n",
      "epoch: 37  batch: 30  loss: 0.10267068\n",
      "epoch: 37  batch: 31  loss: 0.13074724\n",
      "epoch: 37  batch: 32  loss: 0.10197803\n",
      "epoch: 37  batch: 33  loss: 0.10945408\n",
      "epoch: 37  batch: 34  loss: 0.09488267\n",
      "epoch: 37  batch: 35  loss: 0.08749118\n",
      "epoch: 37  batch: 36  loss: 0.18319839\n",
      "epoch: 37  batch: 37  loss: 0.11593271\n",
      "epoch: 37  batch: 38  loss: 0.07159530\n",
      "epoch: 37  batch: 39  loss: 0.12310166\n",
      "epoch: 37  batch: 40  loss: 0.16218592\n",
      "epoch: 37  batch: 41  loss: 0.08299638\n",
      "epoch: 37  batch: 42  loss: 0.09308779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37  batch: 43  loss: 0.09380364\n",
      "epoch: 37  batch: 44  loss: 0.09570495\n",
      "epoch: 37  batch: 45  loss: 0.09555857\n",
      "epoch: 37  batch: 46  loss: 0.06833939\n",
      "epoch: 37  batch: 47  loss: 0.11692411\n",
      "epoch: 37  batch: 48  loss: 0.08740495\n",
      "epoch: 37  batch: 49  loss: 0.09388324\n",
      "epoch: 37  batch: 50  loss: 0.13618371\n",
      "epoch: 37  batch: 51  loss: 0.08644474\n",
      "epoch: 37  batch: 52  loss: 0.12870763\n",
      "epoch: 37  batch: 53  loss: 0.09048243\n",
      "epoch: 37  batch: 54  loss: 0.12314309\n",
      "epoch: 37  batch: 55  loss: 0.11798462\n",
      "epoch: 37  batch: 56  loss: 0.09248448\n",
      "epoch: 37  batch: 57  loss: 0.07769892\n",
      "epoch: 37  batch: 58  loss: 0.11226008\n",
      "epoch: 37  batch: 59  loss: 0.08902353\n",
      "epoch: 37  batch: 60  loss: 0.07603320\n",
      "epoch: 37  batch: 61  loss: 0.09691919\n",
      "epoch: 37  batch: 62  loss: 0.10089747\n",
      "epoch: 37  batch: 63  loss: 0.10296117\n",
      "epoch: 37  batch: 64  loss: 0.08506911\n",
      "epoch: 37  batch: 65  loss: 0.10127056\n",
      "epoch: 37  batch: 66  loss: 0.10010070\n",
      "epoch: 37  batch: 67  loss: 0.13918506\n",
      "epoch: 37  batch: 68  loss: 0.09418800\n",
      "epoch: 37  batch: 69  loss: 0.12428015\n",
      "epoch: 37  batch: 70  loss: 0.08719095\n",
      "epoch: 37  batch: 71  loss: 0.12687980\n",
      "epoch: 37  batch: 72  loss: 0.11244892\n",
      "epoch: 37  batch: 73  loss: 0.08818536\n",
      "epoch: 37  batch: 74  loss: 0.06768623\n",
      "epoch: 37  batch: 75  loss: 0.11973477\n",
      "epoch: 37  batch: 76  loss: 0.08385520\n",
      "epoch: 37  batch: 77  loss: 0.11791712\n",
      "epoch: 37  batch: 78  loss: 0.11049552\n",
      "epoch: 37  batch: 79  loss: 0.09877837\n",
      "epoch: 37  batch: 80  loss: 0.11732140\n",
      "epoch: 37  batch: 81  loss: 0.17855410\n",
      "epoch: 37  batch: 82  loss: 0.12529962\n",
      "epoch: 37  batch: 83  loss: 0.08275384\n",
      "epoch: 37  batch: 84  loss: 0.09484708\n",
      "epoch: 37  batch: 85  loss: 0.12512323\n",
      "epoch: 37  batch: 86  loss: 0.12773666\n",
      "epoch: 37  batch: 87  loss: 0.11000211\n",
      "epoch: 38  batch: 1  loss: 0.10853195\n",
      "epoch: 38  batch: 2  loss: 0.11716703\n",
      "epoch: 38  batch: 3  loss: 0.08237392\n",
      "epoch: 38  batch: 4  loss: 0.12703787\n",
      "epoch: 38  batch: 5  loss: 0.11032306\n",
      "epoch: 38  batch: 6  loss: 0.12627502\n",
      "epoch: 38  batch: 7  loss: 0.08148149\n",
      "epoch: 38  batch: 8  loss: 0.16065650\n",
      "epoch: 38  batch: 9  loss: 0.11407377\n",
      "epoch: 38  batch: 10  loss: 0.13572863\n",
      "epoch: 38  batch: 11  loss: 0.10319890\n",
      "epoch: 38  batch: 12  loss: 0.09802449\n",
      "epoch: 38  batch: 13  loss: 0.09041788\n",
      "epoch: 38  batch: 14  loss: 0.10226025\n",
      "epoch: 38  batch: 15  loss: 0.10681768\n",
      "epoch: 38  batch: 16  loss: 0.11070026\n",
      "epoch: 38  batch: 17  loss: 0.09801086\n",
      "epoch: 38  batch: 18  loss: 0.13849409\n",
      "epoch: 38  batch: 19  loss: 0.10951316\n",
      "epoch: 38  batch: 20  loss: 0.10770021\n",
      "epoch: 38  batch: 21  loss: 0.13460483\n",
      "epoch: 38  batch: 22  loss: 0.10100666\n",
      "epoch: 38  batch: 23  loss: 0.08279131\n",
      "epoch: 38  batch: 24  loss: 0.10269655\n",
      "epoch: 38  batch: 25  loss: 0.13605809\n",
      "epoch: 38  batch: 26  loss: 0.08740553\n",
      "epoch: 38  batch: 27  loss: 0.10771776\n",
      "epoch: 38  batch: 28  loss: 0.12736350\n",
      "epoch: 38  batch: 29  loss: 0.12330649\n",
      "epoch: 38  batch: 30  loss: 0.11930607\n",
      "epoch: 38  batch: 31  loss: 0.15542416\n",
      "epoch: 38  batch: 32  loss: 0.14349900\n",
      "epoch: 38  batch: 33  loss: 0.07244934\n",
      "epoch: 38  batch: 34  loss: 0.08097158\n",
      "epoch: 38  batch: 35  loss: 0.09535946\n",
      "epoch: 38  batch: 36  loss: 0.07504604\n",
      "epoch: 38  batch: 37  loss: 0.08645926\n",
      "epoch: 38  batch: 38  loss: 0.05748379\n",
      "epoch: 38  batch: 39  loss: 0.10636622\n",
      "epoch: 38  batch: 40  loss: 0.10500399\n",
      "epoch: 38  batch: 41  loss: 0.10959123\n",
      "epoch: 38  batch: 42  loss: 0.07129588\n",
      "epoch: 38  batch: 43  loss: 0.11241183\n",
      "epoch: 38  batch: 44  loss: 0.16488321\n",
      "epoch: 38  batch: 45  loss: 0.09059108\n",
      "epoch: 38  batch: 46  loss: 0.11296789\n",
      "epoch: 38  batch: 47  loss: 0.06043131\n",
      "epoch: 38  batch: 48  loss: 0.11000480\n",
      "epoch: 38  batch: 49  loss: 0.11332493\n",
      "epoch: 38  batch: 50  loss: 0.13005655\n",
      "epoch: 38  batch: 51  loss: 0.10339780\n",
      "epoch: 38  batch: 52  loss: 0.09322838\n",
      "epoch: 38  batch: 53  loss: 0.08417655\n",
      "epoch: 38  batch: 54  loss: 0.13135143\n",
      "epoch: 38  batch: 55  loss: 0.10106079\n",
      "epoch: 38  batch: 56  loss: 0.11490891\n",
      "epoch: 38  batch: 57  loss: 0.08641154\n",
      "epoch: 38  batch: 58  loss: 0.10546171\n",
      "epoch: 38  batch: 59  loss: 0.09163657\n",
      "epoch: 38  batch: 60  loss: 0.09537943\n",
      "epoch: 38  batch: 61  loss: 0.11602486\n",
      "epoch: 38  batch: 62  loss: 0.12036876\n",
      "epoch: 38  batch: 63  loss: 0.11618362\n",
      "epoch: 38  batch: 64  loss: 0.10302558\n",
      "epoch: 38  batch: 65  loss: 0.09708062\n",
      "epoch: 38  batch: 66  loss: 0.09076777\n",
      "epoch: 38  batch: 67  loss: 0.10625903\n",
      "epoch: 38  batch: 68  loss: 0.09721263\n",
      "epoch: 38  batch: 69  loss: 0.09052243\n",
      "epoch: 38  batch: 70  loss: 0.09154846\n",
      "epoch: 38  batch: 71  loss: 0.09241102\n",
      "epoch: 38  batch: 72  loss: 0.07437878\n",
      "epoch: 38  batch: 73  loss: 0.07498577\n",
      "epoch: 38  batch: 74  loss: 0.08076236\n",
      "epoch: 38  batch: 75  loss: 0.09330224\n",
      "epoch: 38  batch: 76  loss: 0.09405158\n",
      "epoch: 38  batch: 77  loss: 0.10959887\n",
      "epoch: 38  batch: 78  loss: 0.10041072\n",
      "epoch: 38  batch: 79  loss: 0.07940208\n",
      "epoch: 38  batch: 80  loss: 0.07105824\n",
      "epoch: 38  batch: 81  loss: 0.13350037\n",
      "epoch: 38  batch: 82  loss: 0.09407764\n",
      "epoch: 38  batch: 83  loss: 0.15164039\n",
      "epoch: 38  batch: 84  loss: 0.12846892\n",
      "epoch: 38  batch: 85  loss: 0.11938225\n",
      "epoch: 38  batch: 86  loss: 0.11589064\n",
      "epoch: 38  batch: 87  loss: 0.09270682\n",
      "epoch: 39  batch: 1  loss: 0.09629619\n",
      "epoch: 39  batch: 2  loss: 0.11726830\n",
      "epoch: 39  batch: 3  loss: 0.07580167\n",
      "epoch: 39  batch: 4  loss: 0.07154872\n",
      "epoch: 39  batch: 5  loss: 0.11094970\n",
      "epoch: 39  batch: 6  loss: 0.08879307\n",
      "epoch: 39  batch: 7  loss: 0.10332428\n",
      "epoch: 39  batch: 8  loss: 0.09234495\n",
      "epoch: 39  batch: 9  loss: 0.09125032\n",
      "epoch: 39  batch: 10  loss: 0.07551868\n",
      "epoch: 39  batch: 11  loss: 0.13390023\n",
      "epoch: 39  batch: 12  loss: 0.14209315\n",
      "epoch: 39  batch: 13  loss: 0.10334259\n",
      "epoch: 39  batch: 14  loss: 0.12919241\n",
      "epoch: 39  batch: 15  loss: 0.07385612\n",
      "epoch: 39  batch: 16  loss: 0.07178070\n",
      "epoch: 39  batch: 17  loss: 0.13055836\n",
      "epoch: 39  batch: 18  loss: 0.11743399\n",
      "epoch: 39  batch: 19  loss: 0.14796254\n",
      "epoch: 39  batch: 20  loss: 0.08354355\n",
      "epoch: 39  batch: 21  loss: 0.07848609\n",
      "epoch: 39  batch: 22  loss: 0.13516128\n",
      "epoch: 39  batch: 23  loss: 0.09647149\n",
      "epoch: 39  batch: 24  loss: 0.11734070\n",
      "epoch: 39  batch: 25  loss: 0.09903565\n",
      "epoch: 39  batch: 26  loss: 0.06813827\n",
      "epoch: 39  batch: 27  loss: 0.09614811\n",
      "epoch: 39  batch: 28  loss: 0.08095253\n",
      "epoch: 39  batch: 29  loss: 0.07580314\n",
      "epoch: 39  batch: 30  loss: 0.08194768\n",
      "epoch: 39  batch: 31  loss: 0.11168124\n",
      "epoch: 39  batch: 32  loss: 0.07062384\n",
      "epoch: 39  batch: 33  loss: 0.12572740\n",
      "epoch: 39  batch: 34  loss: 0.10503279\n",
      "epoch: 39  batch: 35  loss: 0.09792835\n",
      "epoch: 39  batch: 36  loss: 0.10193748\n",
      "epoch: 39  batch: 37  loss: 0.06856446\n",
      "epoch: 39  batch: 38  loss: 0.10093580\n",
      "epoch: 39  batch: 39  loss: 0.08807334\n",
      "epoch: 39  batch: 40  loss: 0.12595625\n",
      "epoch: 39  batch: 41  loss: 0.09380985\n",
      "epoch: 39  batch: 42  loss: 0.06787369\n",
      "epoch: 39  batch: 43  loss: 0.08899669\n",
      "epoch: 39  batch: 44  loss: 0.09163309\n",
      "epoch: 39  batch: 45  loss: 0.09651019\n",
      "epoch: 39  batch: 46  loss: 0.09298954\n",
      "epoch: 39  batch: 47  loss: 0.10882991\n",
      "epoch: 39  batch: 48  loss: 0.14078707\n",
      "epoch: 39  batch: 49  loss: 0.10670279\n",
      "epoch: 39  batch: 50  loss: 0.09145540\n",
      "epoch: 39  batch: 51  loss: 0.06744675\n",
      "epoch: 39  batch: 52  loss: 0.09774306\n",
      "epoch: 39  batch: 53  loss: 0.06425890\n",
      "epoch: 39  batch: 54  loss: 0.11181957\n",
      "epoch: 39  batch: 55  loss: 0.09003284\n",
      "epoch: 39  batch: 56  loss: 0.09292248\n",
      "epoch: 39  batch: 57  loss: 0.14114352\n",
      "epoch: 39  batch: 58  loss: 0.06941500\n",
      "epoch: 39  batch: 59  loss: 0.14785354\n",
      "epoch: 39  batch: 60  loss: 0.13016552\n",
      "epoch: 39  batch: 61  loss: 0.08348779\n",
      "epoch: 39  batch: 62  loss: 0.06990492\n",
      "epoch: 39  batch: 63  loss: 0.10456128\n",
      "epoch: 39  batch: 64  loss: 0.08068039\n",
      "epoch: 39  batch: 65  loss: 0.11196707\n",
      "epoch: 39  batch: 66  loss: 0.13194436\n",
      "epoch: 39  batch: 67  loss: 0.10121225\n",
      "epoch: 39  batch: 68  loss: 0.14129400\n",
      "epoch: 39  batch: 69  loss: 0.11169829\n",
      "epoch: 39  batch: 70  loss: 0.13108741\n",
      "epoch: 39  batch: 71  loss: 0.08034492\n",
      "epoch: 39  batch: 72  loss: 0.10545497\n",
      "epoch: 39  batch: 73  loss: 0.11524462\n",
      "epoch: 39  batch: 74  loss: 0.10113686\n",
      "epoch: 39  batch: 75  loss: 0.10322156\n",
      "epoch: 39  batch: 76  loss: 0.07281636\n",
      "epoch: 39  batch: 77  loss: 0.08105533\n",
      "epoch: 39  batch: 78  loss: 0.09473067\n",
      "epoch: 39  batch: 79  loss: 0.11632960\n",
      "epoch: 39  batch: 80  loss: 0.07003481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39  batch: 81  loss: 0.07218578\n",
      "epoch: 39  batch: 82  loss: 0.09001074\n",
      "epoch: 39  batch: 83  loss: 0.08460309\n",
      "epoch: 39  batch: 84  loss: 0.11884997\n",
      "epoch: 39  batch: 85  loss: 0.09375095\n",
      "epoch: 39  batch: 86  loss: 0.09917933\n",
      "epoch: 39  batch: 87  loss: 0.09143468\n",
      "epoch: 40  batch: 1  loss: 0.11178950\n",
      "epoch: 40  batch: 2  loss: 0.09433305\n",
      "epoch: 40  batch: 3  loss: 0.08046553\n",
      "epoch: 40  batch: 4  loss: 0.08039279\n",
      "epoch: 40  batch: 5  loss: 0.10746840\n",
      "epoch: 40  batch: 6  loss: 0.10127327\n",
      "epoch: 40  batch: 7  loss: 0.09379966\n",
      "epoch: 40  batch: 8  loss: 0.08681628\n",
      "epoch: 40  batch: 9  loss: 0.07891457\n",
      "epoch: 40  batch: 10  loss: 0.08154693\n",
      "epoch: 40  batch: 11  loss: 0.15129627\n",
      "epoch: 40  batch: 12  loss: 0.05400154\n",
      "epoch: 40  batch: 13  loss: 0.07283517\n",
      "epoch: 40  batch: 14  loss: 0.09142148\n",
      "epoch: 40  batch: 15  loss: 0.09326974\n",
      "epoch: 40  batch: 16  loss: 0.11030943\n",
      "epoch: 40  batch: 17  loss: 0.07806513\n",
      "epoch: 40  batch: 18  loss: 0.07661429\n",
      "epoch: 40  batch: 19  loss: 0.08956750\n",
      "epoch: 40  batch: 20  loss: 0.11130051\n",
      "epoch: 40  batch: 21  loss: 0.09384505\n",
      "epoch: 40  batch: 22  loss: 0.09589534\n",
      "epoch: 40  batch: 23  loss: 0.06209525\n",
      "epoch: 40  batch: 24  loss: 0.08038030\n",
      "epoch: 40  batch: 25  loss: 0.10890292\n",
      "epoch: 40  batch: 26  loss: 0.12360189\n",
      "epoch: 40  batch: 27  loss: 0.14752914\n",
      "epoch: 40  batch: 28  loss: 0.13427888\n",
      "epoch: 40  batch: 29  loss: 0.06980159\n",
      "epoch: 40  batch: 30  loss: 0.07994805\n",
      "epoch: 40  batch: 31  loss: 0.08944415\n",
      "epoch: 40  batch: 32  loss: 0.08355380\n",
      "epoch: 40  batch: 33  loss: 0.07577800\n",
      "epoch: 40  batch: 34  loss: 0.10311711\n",
      "epoch: 40  batch: 35  loss: 0.10555829\n",
      "epoch: 40  batch: 36  loss: 0.07372724\n",
      "epoch: 40  batch: 37  loss: 0.06636997\n",
      "epoch: 40  batch: 38  loss: 0.07819064\n",
      "epoch: 40  batch: 39  loss: 0.19056390\n",
      "epoch: 40  batch: 40  loss: 0.12488844\n",
      "epoch: 40  batch: 41  loss: 0.08909180\n",
      "epoch: 40  batch: 42  loss: 0.12370168\n",
      "epoch: 40  batch: 43  loss: 0.08789670\n",
      "epoch: 40  batch: 44  loss: 0.06358671\n",
      "epoch: 40  batch: 45  loss: 0.08514755\n",
      "epoch: 40  batch: 46  loss: 0.08333315\n",
      "epoch: 40  batch: 47  loss: 0.08136827\n",
      "epoch: 40  batch: 48  loss: 0.07966358\n",
      "epoch: 40  batch: 49  loss: 0.11530720\n",
      "epoch: 40  batch: 50  loss: 0.08671667\n",
      "epoch: 40  batch: 51  loss: 0.10465762\n",
      "epoch: 40  batch: 52  loss: 0.08550701\n",
      "epoch: 40  batch: 53  loss: 0.08946151\n",
      "epoch: 40  batch: 54  loss: 0.08798209\n",
      "epoch: 40  batch: 55  loss: 0.07444792\n",
      "epoch: 40  batch: 56  loss: 0.08168872\n",
      "epoch: 40  batch: 57  loss: 0.06619612\n",
      "epoch: 40  batch: 58  loss: 0.10980319\n",
      "epoch: 40  batch: 59  loss: 0.07233847\n",
      "epoch: 40  batch: 60  loss: 0.07385229\n",
      "epoch: 40  batch: 61  loss: 0.07105611\n",
      "epoch: 40  batch: 62  loss: 0.05898754\n",
      "epoch: 40  batch: 63  loss: 0.09845616\n",
      "epoch: 40  batch: 64  loss: 0.06138985\n",
      "epoch: 40  batch: 65  loss: 0.06160021\n",
      "epoch: 40  batch: 66  loss: 0.05133309\n",
      "epoch: 40  batch: 67  loss: 0.10189732\n",
      "epoch: 40  batch: 68  loss: 0.10685977\n",
      "epoch: 40  batch: 69  loss: 0.15094921\n",
      "epoch: 40  batch: 70  loss: 0.13951586\n",
      "epoch: 40  batch: 71  loss: 0.08218302\n",
      "epoch: 40  batch: 72  loss: 0.07844421\n",
      "epoch: 40  batch: 73  loss: 0.09627315\n",
      "epoch: 40  batch: 74  loss: 0.08855802\n",
      "epoch: 40  batch: 75  loss: 0.14888564\n",
      "epoch: 40  batch: 76  loss: 0.16060506\n",
      "epoch: 40  batch: 77  loss: 0.09610957\n",
      "epoch: 40  batch: 78  loss: 0.10948059\n",
      "epoch: 40  batch: 79  loss: 0.09223583\n",
      "epoch: 40  batch: 80  loss: 0.09366901\n",
      "epoch: 40  batch: 81  loss: 0.09962690\n",
      "epoch: 40  batch: 82  loss: 0.08308322\n",
      "epoch: 40  batch: 83  loss: 0.08356472\n",
      "epoch: 40  batch: 84  loss: 0.10803110\n",
      "epoch: 40  batch: 85  loss: 0.09741513\n",
      "epoch: 40  batch: 86  loss: 0.15519944\n",
      "epoch: 40  batch: 87  loss: 0.06966217\n",
      "epoch: 41  batch: 1  loss: 0.13521637\n",
      "epoch: 41  batch: 2  loss: 0.06424902\n",
      "epoch: 41  batch: 3  loss: 0.08108217\n",
      "epoch: 41  batch: 4  loss: 0.07890173\n",
      "epoch: 41  batch: 5  loss: 0.06892623\n",
      "epoch: 41  batch: 6  loss: 0.07089837\n",
      "epoch: 41  batch: 7  loss: 0.09695986\n",
      "epoch: 41  batch: 8  loss: 0.06701367\n",
      "epoch: 41  batch: 9  loss: 0.09194500\n",
      "epoch: 41  batch: 10  loss: 0.06969815\n",
      "epoch: 41  batch: 11  loss: 0.07733215\n",
      "epoch: 41  batch: 12  loss: 0.08318470\n",
      "epoch: 41  batch: 13  loss: 0.12580141\n",
      "epoch: 41  batch: 14  loss: 0.06950127\n",
      "epoch: 41  batch: 15  loss: 0.12208170\n",
      "epoch: 41  batch: 16  loss: 0.09325683\n",
      "epoch: 41  batch: 17  loss: 0.08464949\n",
      "epoch: 41  batch: 18  loss: 0.10564979\n",
      "epoch: 41  batch: 19  loss: 0.09913628\n",
      "epoch: 41  batch: 20  loss: 0.07248568\n",
      "epoch: 41  batch: 21  loss: 0.09700589\n",
      "epoch: 41  batch: 22  loss: 0.08717056\n",
      "epoch: 41  batch: 23  loss: 0.06859298\n",
      "epoch: 41  batch: 24  loss: 0.13447210\n",
      "epoch: 41  batch: 25  loss: 0.11150371\n",
      "epoch: 41  batch: 26  loss: 0.08145536\n",
      "epoch: 41  batch: 27  loss: 0.07243125\n",
      "epoch: 41  batch: 28  loss: 0.10932688\n",
      "epoch: 41  batch: 29  loss: 0.08176865\n",
      "epoch: 41  batch: 30  loss: 0.07106284\n",
      "epoch: 41  batch: 31  loss: 0.08058026\n",
      "epoch: 41  batch: 32  loss: 0.05324800\n",
      "epoch: 41  batch: 33  loss: 0.10223023\n",
      "epoch: 41  batch: 34  loss: 0.08248180\n",
      "epoch: 41  batch: 35  loss: 0.07989185\n",
      "epoch: 41  batch: 36  loss: 0.09971179\n",
      "epoch: 41  batch: 37  loss: 0.05670043\n",
      "epoch: 41  batch: 38  loss: 0.08655844\n",
      "epoch: 41  batch: 39  loss: 0.12085128\n",
      "epoch: 41  batch: 40  loss: 0.08630837\n",
      "epoch: 41  batch: 41  loss: 0.09225646\n",
      "epoch: 41  batch: 42  loss: 0.06920190\n",
      "epoch: 41  batch: 43  loss: 0.10224999\n",
      "epoch: 41  batch: 44  loss: 0.05946491\n",
      "epoch: 41  batch: 45  loss: 0.07794700\n",
      "epoch: 41  batch: 46  loss: 0.08905379\n",
      "epoch: 41  batch: 47  loss: 0.14649455\n",
      "epoch: 41  batch: 48  loss: 0.09901883\n",
      "epoch: 41  batch: 49  loss: 0.08641323\n",
      "epoch: 41  batch: 50  loss: 0.10097076\n",
      "epoch: 41  batch: 51  loss: 0.11129116\n",
      "epoch: 41  batch: 52  loss: 0.07867699\n",
      "epoch: 41  batch: 53  loss: 0.13052063\n",
      "epoch: 41  batch: 54  loss: 0.09179144\n",
      "epoch: 41  batch: 55  loss: 0.05425774\n",
      "epoch: 41  batch: 56  loss: 0.09630753\n",
      "epoch: 41  batch: 57  loss: 0.09890683\n",
      "epoch: 41  batch: 58  loss: 0.07830576\n",
      "epoch: 41  batch: 59  loss: 0.09870998\n",
      "epoch: 41  batch: 60  loss: 0.10512340\n",
      "epoch: 41  batch: 61  loss: 0.08102481\n",
      "epoch: 41  batch: 62  loss: 0.14743669\n",
      "epoch: 41  batch: 63  loss: 0.09035878\n",
      "epoch: 41  batch: 64  loss: 0.09897465\n",
      "epoch: 41  batch: 65  loss: 0.20637724\n",
      "epoch: 41  batch: 66  loss: 0.07805879\n",
      "epoch: 41  batch: 67  loss: 0.12846927\n",
      "epoch: 41  batch: 68  loss: 0.09634385\n",
      "epoch: 41  batch: 69  loss: 0.10488321\n",
      "epoch: 41  batch: 70  loss: 0.09400518\n",
      "epoch: 41  batch: 71  loss: 0.05737101\n",
      "epoch: 41  batch: 72  loss: 0.07347962\n",
      "epoch: 41  batch: 73  loss: 0.09659585\n",
      "epoch: 41  batch: 74  loss: 0.09219582\n",
      "epoch: 41  batch: 75  loss: 0.07625768\n",
      "epoch: 41  batch: 76  loss: 0.11021613\n",
      "epoch: 41  batch: 77  loss: 0.06509151\n",
      "epoch: 41  batch: 78  loss: 0.05066198\n",
      "epoch: 41  batch: 79  loss: 0.08470239\n",
      "epoch: 41  batch: 80  loss: 0.09125353\n",
      "epoch: 41  batch: 81  loss: 0.07142458\n",
      "epoch: 41  batch: 82  loss: 0.05808486\n",
      "epoch: 41  batch: 83  loss: 0.07726940\n",
      "epoch: 41  batch: 84  loss: 0.09960002\n",
      "epoch: 41  batch: 85  loss: 0.07214438\n",
      "epoch: 41  batch: 86  loss: 0.06159662\n",
      "epoch: 41  batch: 87  loss: 0.05740442\n",
      "epoch: 42  batch: 1  loss: 0.08246998\n",
      "epoch: 42  batch: 2  loss: 0.08900130\n",
      "epoch: 42  batch: 3  loss: 0.07419676\n",
      "epoch: 42  batch: 4  loss: 0.06941802\n",
      "epoch: 42  batch: 5  loss: 0.09927280\n",
      "epoch: 42  batch: 6  loss: 0.07343015\n",
      "epoch: 42  batch: 7  loss: 0.10209408\n",
      "epoch: 42  batch: 8  loss: 0.07525198\n",
      "epoch: 42  batch: 9  loss: 0.08777998\n",
      "epoch: 42  batch: 10  loss: 0.08384262\n",
      "epoch: 42  batch: 11  loss: 0.06152389\n",
      "epoch: 42  batch: 12  loss: 0.09696174\n",
      "epoch: 42  batch: 13  loss: 0.06417261\n",
      "epoch: 42  batch: 14  loss: 0.12295604\n",
      "epoch: 42  batch: 15  loss: 0.12875162\n",
      "epoch: 42  batch: 16  loss: 0.07657961\n",
      "epoch: 42  batch: 17  loss: 0.07980223\n",
      "epoch: 42  batch: 18  loss: 0.07331152\n",
      "epoch: 42  batch: 19  loss: 0.09184787\n",
      "epoch: 42  batch: 20  loss: 0.09413701\n",
      "epoch: 42  batch: 21  loss: 0.07228288\n",
      "epoch: 42  batch: 22  loss: 0.08253076\n",
      "epoch: 42  batch: 23  loss: 0.10647336\n",
      "epoch: 42  batch: 24  loss: 0.04933014\n",
      "epoch: 42  batch: 25  loss: 0.11821628\n",
      "epoch: 42  batch: 26  loss: 0.07779957\n",
      "epoch: 42  batch: 27  loss: 0.07491641\n",
      "epoch: 42  batch: 28  loss: 0.08316538\n",
      "epoch: 42  batch: 29  loss: 0.10314090\n",
      "epoch: 42  batch: 30  loss: 0.12518562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42  batch: 31  loss: 0.07437979\n",
      "epoch: 42  batch: 32  loss: 0.07141001\n",
      "epoch: 42  batch: 33  loss: 0.08869378\n",
      "epoch: 42  batch: 34  loss: 0.09598949\n",
      "epoch: 42  batch: 35  loss: 0.08316411\n",
      "epoch: 42  batch: 36  loss: 0.06280545\n",
      "epoch: 42  batch: 37  loss: 0.10890961\n",
      "epoch: 42  batch: 38  loss: 0.08135238\n",
      "epoch: 42  batch: 39  loss: 0.10878353\n",
      "epoch: 42  batch: 40  loss: 0.09191138\n",
      "epoch: 42  batch: 41  loss: 0.10040189\n",
      "epoch: 42  batch: 42  loss: 0.11644690\n",
      "epoch: 42  batch: 43  loss: 0.12168585\n",
      "epoch: 42  batch: 44  loss: 0.07421657\n",
      "epoch: 42  batch: 45  loss: 0.07745843\n",
      "epoch: 42  batch: 46  loss: 0.11600365\n",
      "epoch: 42  batch: 47  loss: 0.09095866\n",
      "epoch: 42  batch: 48  loss: 0.13175635\n",
      "epoch: 42  batch: 49  loss: 0.10649545\n",
      "epoch: 42  batch: 50  loss: 0.07713323\n",
      "epoch: 42  batch: 51  loss: 0.13159198\n",
      "epoch: 42  batch: 52  loss: 0.08077754\n",
      "epoch: 42  batch: 53  loss: 0.08867271\n",
      "epoch: 42  batch: 54  loss: 0.08908340\n",
      "epoch: 42  batch: 55  loss: 0.08700438\n",
      "epoch: 42  batch: 56  loss: 0.09713359\n",
      "epoch: 42  batch: 57  loss: 0.08283272\n",
      "epoch: 42  batch: 58  loss: 0.06997102\n",
      "epoch: 42  batch: 59  loss: 0.08707798\n",
      "epoch: 42  batch: 60  loss: 0.06755788\n",
      "epoch: 42  batch: 61  loss: 0.06560335\n",
      "epoch: 42  batch: 62  loss: 0.06435869\n",
      "epoch: 42  batch: 63  loss: 0.09992646\n",
      "epoch: 42  batch: 64  loss: 0.07319023\n",
      "epoch: 42  batch: 65  loss: 0.07016423\n",
      "epoch: 42  batch: 66  loss: 0.09613905\n",
      "epoch: 42  batch: 67  loss: 0.08570479\n",
      "epoch: 42  batch: 68  loss: 0.08289830\n",
      "epoch: 42  batch: 69  loss: 0.07709841\n",
      "epoch: 42  batch: 70  loss: 0.07121678\n",
      "epoch: 42  batch: 71  loss: 0.17374255\n",
      "epoch: 42  batch: 72  loss: 0.08578322\n",
      "epoch: 42  batch: 73  loss: 0.09716371\n",
      "epoch: 42  batch: 74  loss: 0.10907301\n",
      "epoch: 42  batch: 75  loss: 0.09131794\n",
      "epoch: 42  batch: 76  loss: 0.09876785\n",
      "epoch: 42  batch: 77  loss: 0.05745078\n",
      "epoch: 42  batch: 78  loss: 0.08303144\n",
      "epoch: 42  batch: 79  loss: 0.07354447\n",
      "epoch: 42  batch: 80  loss: 0.14321481\n",
      "epoch: 42  batch: 81  loss: 0.09766340\n",
      "epoch: 42  batch: 82  loss: 0.06889158\n",
      "epoch: 42  batch: 83  loss: 0.06139528\n",
      "epoch: 42  batch: 84  loss: 0.09154066\n",
      "epoch: 42  batch: 85  loss: 0.05707601\n",
      "epoch: 42  batch: 86  loss: 0.09153575\n",
      "epoch: 42  batch: 87  loss: 0.07952441\n",
      "epoch: 43  batch: 1  loss: 0.08171061\n",
      "epoch: 43  batch: 2  loss: 0.07799739\n",
      "epoch: 43  batch: 3  loss: 0.07367264\n",
      "epoch: 43  batch: 4  loss: 0.07511765\n",
      "epoch: 43  batch: 5  loss: 0.06749117\n",
      "epoch: 43  batch: 6  loss: 0.09502939\n",
      "epoch: 43  batch: 7  loss: 0.09897997\n",
      "epoch: 43  batch: 8  loss: 0.12483268\n",
      "epoch: 43  batch: 9  loss: 0.09212820\n",
      "epoch: 43  batch: 10  loss: 0.07721617\n",
      "epoch: 43  batch: 11  loss: 0.11016031\n",
      "epoch: 43  batch: 12  loss: 0.06529385\n",
      "epoch: 43  batch: 13  loss: 0.12923923\n",
      "epoch: 43  batch: 14  loss: 0.11512264\n",
      "epoch: 43  batch: 15  loss: 0.07870533\n",
      "epoch: 43  batch: 16  loss: 0.08767847\n",
      "epoch: 43  batch: 17  loss: 0.07908178\n",
      "epoch: 43  batch: 18  loss: 0.12652901\n",
      "epoch: 43  batch: 19  loss: 0.05759871\n",
      "epoch: 43  batch: 20  loss: 0.10692511\n",
      "epoch: 43  batch: 21  loss: 0.07060558\n",
      "epoch: 43  batch: 22  loss: 0.11856209\n",
      "epoch: 43  batch: 23  loss: 0.09138414\n",
      "epoch: 43  batch: 24  loss: 0.11258035\n",
      "epoch: 43  batch: 25  loss: 0.07834025\n",
      "epoch: 43  batch: 26  loss: 0.14547510\n",
      "epoch: 43  batch: 27  loss: 0.06204052\n",
      "epoch: 43  batch: 28  loss: 0.08030848\n",
      "epoch: 43  batch: 29  loss: 0.08953700\n",
      "epoch: 43  batch: 30  loss: 0.05825289\n",
      "epoch: 43  batch: 31  loss: 0.06968075\n",
      "epoch: 43  batch: 32  loss: 0.06886681\n",
      "epoch: 43  batch: 33  loss: 0.07808629\n",
      "epoch: 43  batch: 34  loss: 0.07243554\n",
      "epoch: 43  batch: 35  loss: 0.11402766\n",
      "epoch: 43  batch: 36  loss: 0.05257424\n",
      "epoch: 43  batch: 37  loss: 0.08878046\n",
      "epoch: 43  batch: 38  loss: 0.07589415\n",
      "epoch: 43  batch: 39  loss: 0.07770901\n",
      "epoch: 43  batch: 40  loss: 0.10577215\n",
      "epoch: 43  batch: 41  loss: 0.07538534\n",
      "epoch: 43  batch: 42  loss: 0.10061661\n",
      "epoch: 43  batch: 43  loss: 0.09290281\n",
      "epoch: 43  batch: 44  loss: 0.12326438\n",
      "epoch: 43  batch: 45  loss: 0.07389625\n",
      "epoch: 43  batch: 46  loss: 0.07697110\n",
      "epoch: 43  batch: 47  loss: 0.08314190\n",
      "epoch: 43  batch: 48  loss: 0.11204500\n",
      "epoch: 43  batch: 49  loss: 0.08088419\n",
      "epoch: 43  batch: 50  loss: 0.08558390\n",
      "epoch: 43  batch: 51  loss: 0.11127210\n",
      "epoch: 43  batch: 52  loss: 0.09836447\n",
      "epoch: 43  batch: 53  loss: 0.05899255\n",
      "epoch: 43  batch: 54  loss: 0.05321911\n",
      "epoch: 43  batch: 55  loss: 0.08858742\n",
      "epoch: 43  batch: 56  loss: 0.09801606\n",
      "epoch: 43  batch: 57  loss: 0.08970082\n",
      "epoch: 43  batch: 58  loss: 0.09943429\n",
      "epoch: 43  batch: 59  loss: 0.09233806\n",
      "epoch: 43  batch: 60  loss: 0.08866230\n",
      "epoch: 43  batch: 61  loss: 0.11008398\n",
      "epoch: 43  batch: 62  loss: 0.13106382\n",
      "epoch: 43  batch: 63  loss: 0.09314384\n",
      "epoch: 43  batch: 64  loss: 0.07759268\n",
      "epoch: 43  batch: 65  loss: 0.07926832\n",
      "epoch: 43  batch: 66  loss: 0.08248334\n",
      "epoch: 43  batch: 67  loss: 0.07599651\n",
      "epoch: 43  batch: 68  loss: 0.10472271\n",
      "epoch: 43  batch: 69  loss: 0.09272870\n",
      "epoch: 43  batch: 70  loss: 0.06050526\n",
      "epoch: 43  batch: 71  loss: 0.08352201\n",
      "epoch: 43  batch: 72  loss: 0.07824168\n",
      "epoch: 43  batch: 73  loss: 0.10911011\n",
      "epoch: 43  batch: 74  loss: 0.10749150\n",
      "epoch: 43  batch: 75  loss: 0.11420838\n",
      "epoch: 43  batch: 76  loss: 0.07798927\n",
      "epoch: 43  batch: 77  loss: 0.07084904\n",
      "epoch: 43  batch: 78  loss: 0.07218938\n",
      "epoch: 43  batch: 79  loss: 0.13118231\n",
      "epoch: 43  batch: 80  loss: 0.08706143\n",
      "epoch: 43  batch: 81  loss: 0.08469698\n",
      "epoch: 43  batch: 82  loss: 0.04744574\n",
      "epoch: 43  batch: 83  loss: 0.08900077\n",
      "epoch: 43  batch: 84  loss: 0.10216933\n",
      "epoch: 43  batch: 85  loss: 0.07830890\n",
      "epoch: 43  batch: 86  loss: 0.09431318\n",
      "epoch: 43  batch: 87  loss: 0.06209249\n",
      "epoch: 44  batch: 1  loss: 0.05314377\n",
      "epoch: 44  batch: 2  loss: 0.09774440\n",
      "epoch: 44  batch: 3  loss: 0.07483532\n",
      "epoch: 44  batch: 4  loss: 0.07479555\n",
      "epoch: 44  batch: 5  loss: 0.09125050\n",
      "epoch: 44  batch: 6  loss: 0.06822944\n",
      "epoch: 44  batch: 7  loss: 0.06634684\n",
      "epoch: 44  batch: 8  loss: 0.06036315\n",
      "epoch: 44  batch: 9  loss: 0.13170613\n",
      "epoch: 44  batch: 10  loss: 0.08435518\n",
      "epoch: 44  batch: 11  loss: 0.12315081\n",
      "epoch: 44  batch: 12  loss: 0.07116730\n",
      "epoch: 44  batch: 13  loss: 0.07385920\n",
      "epoch: 44  batch: 14  loss: 0.10427143\n",
      "epoch: 44  batch: 15  loss: 0.12000512\n",
      "epoch: 44  batch: 16  loss: 0.10392109\n",
      "epoch: 44  batch: 17  loss: 0.11760293\n",
      "epoch: 44  batch: 18  loss: 0.06461562\n",
      "epoch: 44  batch: 19  loss: 0.08113378\n",
      "epoch: 44  batch: 20  loss: 0.10171849\n",
      "epoch: 44  batch: 21  loss: 0.09290916\n",
      "epoch: 44  batch: 22  loss: 0.05604413\n",
      "epoch: 44  batch: 23  loss: 0.07094330\n",
      "epoch: 44  batch: 24  loss: 0.10903934\n",
      "epoch: 44  batch: 25  loss: 0.05413314\n",
      "epoch: 44  batch: 26  loss: 0.09995455\n",
      "epoch: 44  batch: 27  loss: 0.08678324\n",
      "epoch: 44  batch: 28  loss: 0.08216029\n",
      "epoch: 44  batch: 29  loss: 0.08437613\n",
      "epoch: 44  batch: 30  loss: 0.06087041\n",
      "epoch: 44  batch: 31  loss: 0.07406559\n",
      "epoch: 44  batch: 32  loss: 0.09437690\n",
      "epoch: 44  batch: 33  loss: 0.08825726\n",
      "epoch: 44  batch: 34  loss: 0.08614507\n",
      "epoch: 44  batch: 35  loss: 0.09499408\n",
      "epoch: 44  batch: 36  loss: 0.07524052\n",
      "epoch: 44  batch: 37  loss: 0.13686477\n",
      "epoch: 44  batch: 38  loss: 0.09388630\n",
      "epoch: 44  batch: 39  loss: 0.13885151\n",
      "epoch: 44  batch: 40  loss: 0.11137534\n",
      "epoch: 44  batch: 41  loss: 0.10765645\n",
      "epoch: 44  batch: 42  loss: 0.06221079\n",
      "epoch: 44  batch: 43  loss: 0.07162685\n",
      "epoch: 44  batch: 44  loss: 0.10373975\n",
      "epoch: 44  batch: 45  loss: 0.09112369\n",
      "epoch: 44  batch: 46  loss: 0.05909659\n",
      "epoch: 44  batch: 47  loss: 0.07294735\n",
      "epoch: 44  batch: 48  loss: 0.07012968\n",
      "epoch: 44  batch: 49  loss: 0.05803175\n",
      "epoch: 44  batch: 50  loss: 0.05814679\n",
      "epoch: 44  batch: 51  loss: 0.09053690\n",
      "epoch: 44  batch: 52  loss: 0.07256213\n",
      "epoch: 44  batch: 53  loss: 0.08091681\n",
      "epoch: 44  batch: 54  loss: 0.06555371\n",
      "epoch: 44  batch: 55  loss: 0.06905738\n",
      "epoch: 44  batch: 56  loss: 0.07976710\n",
      "epoch: 44  batch: 57  loss: 0.08417775\n",
      "epoch: 44  batch: 58  loss: 0.06473266\n",
      "epoch: 44  batch: 59  loss: 0.08713389\n",
      "epoch: 44  batch: 60  loss: 0.10697465\n",
      "epoch: 44  batch: 61  loss: 0.08692270\n",
      "epoch: 44  batch: 62  loss: 0.07846926\n",
      "epoch: 44  batch: 63  loss: 0.10364139\n",
      "epoch: 44  batch: 64  loss: 0.07986770\n",
      "epoch: 44  batch: 65  loss: 0.10720216\n",
      "epoch: 44  batch: 66  loss: 0.06208291\n",
      "epoch: 44  batch: 67  loss: 0.14515391\n",
      "epoch: 44  batch: 68  loss: 0.07687695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44  batch: 69  loss: 0.16143459\n",
      "epoch: 44  batch: 70  loss: 0.10471667\n",
      "epoch: 44  batch: 71  loss: 0.07490622\n",
      "epoch: 44  batch: 72  loss: 0.11873348\n",
      "epoch: 44  batch: 73  loss: 0.10844462\n",
      "epoch: 44  batch: 74  loss: 0.08763713\n",
      "epoch: 44  batch: 75  loss: 0.06241404\n",
      "epoch: 44  batch: 76  loss: 0.15113218\n",
      "epoch: 44  batch: 77  loss: 0.08171483\n",
      "epoch: 44  batch: 78  loss: 0.07600483\n",
      "epoch: 44  batch: 79  loss: 0.12596619\n",
      "epoch: 44  batch: 80  loss: 0.07096736\n",
      "epoch: 44  batch: 81  loss: 0.10951031\n",
      "epoch: 44  batch: 82  loss: 0.05894650\n",
      "epoch: 44  batch: 83  loss: 0.07884516\n",
      "epoch: 44  batch: 84  loss: 0.12000113\n",
      "epoch: 44  batch: 85  loss: 0.08560770\n",
      "epoch: 44  batch: 86  loss: 0.07363595\n",
      "epoch: 44  batch: 87  loss: 0.07337152\n",
      "epoch: 45  batch: 1  loss: 0.09719487\n",
      "epoch: 45  batch: 2  loss: 0.09626967\n",
      "epoch: 45  batch: 3  loss: 0.10077588\n",
      "epoch: 45  batch: 4  loss: 0.07052408\n",
      "epoch: 45  batch: 5  loss: 0.09364486\n",
      "epoch: 45  batch: 6  loss: 0.06695782\n",
      "epoch: 45  batch: 7  loss: 0.09242062\n",
      "epoch: 45  batch: 8  loss: 0.08661557\n",
      "epoch: 45  batch: 9  loss: 0.07304925\n",
      "epoch: 45  batch: 10  loss: 0.08221010\n",
      "epoch: 45  batch: 11  loss: 0.09093852\n",
      "epoch: 45  batch: 12  loss: 0.08165272\n",
      "epoch: 45  batch: 13  loss: 0.06641407\n",
      "epoch: 45  batch: 14  loss: 0.14157143\n",
      "epoch: 45  batch: 15  loss: 0.09117961\n",
      "epoch: 45  batch: 16  loss: 0.07916928\n",
      "epoch: 45  batch: 17  loss: 0.08729690\n",
      "epoch: 45  batch: 18  loss: 0.19881445\n",
      "epoch: 45  batch: 19  loss: 0.06552885\n",
      "epoch: 45  batch: 20  loss: 0.09176701\n",
      "epoch: 45  batch: 21  loss: 0.12381643\n",
      "epoch: 45  batch: 22  loss: 0.07969984\n",
      "epoch: 45  batch: 23  loss: 0.14098004\n",
      "epoch: 45  batch: 24  loss: 0.06571954\n",
      "epoch: 45  batch: 25  loss: 0.08804899\n",
      "epoch: 45  batch: 26  loss: 0.06793839\n",
      "epoch: 45  batch: 27  loss: 0.08561879\n",
      "epoch: 45  batch: 28  loss: 0.06803934\n",
      "epoch: 45  batch: 29  loss: 0.12354829\n",
      "epoch: 45  batch: 30  loss: 0.09131075\n",
      "epoch: 45  batch: 31  loss: 0.11350249\n",
      "epoch: 45  batch: 32  loss: 0.05831025\n",
      "epoch: 45  batch: 33  loss: 0.09892687\n",
      "epoch: 45  batch: 34  loss: 0.09271272\n",
      "epoch: 45  batch: 35  loss: 0.09155931\n",
      "epoch: 45  batch: 36  loss: 0.08939669\n",
      "epoch: 45  batch: 37  loss: 0.07422179\n",
      "epoch: 45  batch: 38  loss: 0.08473891\n",
      "epoch: 45  batch: 39  loss: 0.09450717\n",
      "epoch: 45  batch: 40  loss: 0.07920264\n",
      "epoch: 45  batch: 41  loss: 0.08980612\n",
      "epoch: 45  batch: 42  loss: 0.11692636\n",
      "epoch: 45  batch: 43  loss: 0.05763308\n",
      "epoch: 45  batch: 44  loss: 0.07678466\n",
      "epoch: 45  batch: 45  loss: 0.07785989\n",
      "epoch: 45  batch: 46  loss: 0.07737478\n",
      "epoch: 45  batch: 47  loss: 0.10168634\n",
      "epoch: 45  batch: 48  loss: 0.09136029\n",
      "epoch: 45  batch: 49  loss: 0.10799092\n",
      "epoch: 45  batch: 50  loss: 0.09850761\n",
      "epoch: 45  batch: 51  loss: 0.08244900\n",
      "epoch: 45  batch: 52  loss: 0.09850635\n",
      "epoch: 45  batch: 53  loss: 0.05973527\n",
      "epoch: 45  batch: 54  loss: 0.11019094\n",
      "epoch: 45  batch: 55  loss: 0.07163185\n",
      "epoch: 45  batch: 56  loss: 0.06431883\n",
      "epoch: 45  batch: 57  loss: 0.10124660\n",
      "epoch: 45  batch: 58  loss: 0.05106911\n",
      "epoch: 45  batch: 59  loss: 0.09679195\n",
      "epoch: 45  batch: 60  loss: 0.09697231\n",
      "epoch: 45  batch: 61  loss: 0.07196363\n",
      "epoch: 45  batch: 62  loss: 0.10772987\n",
      "epoch: 45  batch: 63  loss: 0.10608040\n",
      "epoch: 45  batch: 64  loss: 0.08805829\n",
      "epoch: 45  batch: 65  loss: 0.09404863\n",
      "epoch: 45  batch: 66  loss: 0.07649981\n",
      "epoch: 45  batch: 67  loss: 0.08547046\n",
      "epoch: 45  batch: 68  loss: 0.05875963\n",
      "epoch: 45  batch: 69  loss: 0.09129214\n",
      "epoch: 45  batch: 70  loss: 0.10504544\n",
      "epoch: 45  batch: 71  loss: 0.08142179\n",
      "epoch: 45  batch: 72  loss: 0.05662992\n",
      "epoch: 45  batch: 73  loss: 0.12275872\n",
      "epoch: 45  batch: 74  loss: 0.06152753\n",
      "epoch: 45  batch: 75  loss: 0.07786452\n",
      "epoch: 45  batch: 76  loss: 0.05794391\n",
      "epoch: 45  batch: 77  loss: 0.06314280\n",
      "epoch: 45  batch: 78  loss: 0.08129331\n",
      "epoch: 45  batch: 79  loss: 0.09301638\n",
      "epoch: 45  batch: 80  loss: 0.07460087\n",
      "epoch: 45  batch: 81  loss: 0.07054929\n",
      "epoch: 45  batch: 82  loss: 0.06694940\n",
      "epoch: 45  batch: 83  loss: 0.07136399\n",
      "epoch: 45  batch: 84  loss: 0.04958041\n",
      "epoch: 45  batch: 85  loss: 0.06524527\n",
      "epoch: 45  batch: 86  loss: 0.07592747\n",
      "epoch: 45  batch: 87  loss: 0.08553956\n",
      "epoch: 46  batch: 1  loss: 0.07268490\n",
      "epoch: 46  batch: 2  loss: 0.05611493\n",
      "epoch: 46  batch: 3  loss: 0.07150919\n",
      "epoch: 46  batch: 4  loss: 0.07815663\n",
      "epoch: 46  batch: 5  loss: 0.07441263\n",
      "epoch: 46  batch: 6  loss: 0.08256686\n",
      "epoch: 46  batch: 7  loss: 0.11433696\n",
      "epoch: 46  batch: 8  loss: 0.07985183\n",
      "epoch: 46  batch: 9  loss: 0.10160019\n",
      "epoch: 46  batch: 10  loss: 0.06981368\n",
      "epoch: 46  batch: 11  loss: 0.09822723\n",
      "epoch: 46  batch: 12  loss: 0.10661997\n",
      "epoch: 46  batch: 13  loss: 0.10470924\n",
      "epoch: 46  batch: 14  loss: 0.08118597\n",
      "epoch: 46  batch: 15  loss: 0.08468482\n",
      "epoch: 46  batch: 16  loss: 0.11402730\n",
      "epoch: 46  batch: 17  loss: 0.08983877\n",
      "epoch: 46  batch: 18  loss: 0.08740482\n",
      "epoch: 46  batch: 19  loss: 0.07975663\n",
      "epoch: 46  batch: 20  loss: 0.06630142\n",
      "epoch: 46  batch: 21  loss: 0.06200351\n",
      "epoch: 46  batch: 22  loss: 0.06320535\n",
      "epoch: 46  batch: 23  loss: 0.05819823\n",
      "epoch: 46  batch: 24  loss: 0.08143556\n",
      "epoch: 46  batch: 25  loss: 0.07582738\n",
      "epoch: 46  batch: 26  loss: 0.10902759\n",
      "epoch: 46  batch: 27  loss: 0.11967827\n",
      "epoch: 46  batch: 28  loss: 0.06305212\n",
      "epoch: 46  batch: 29  loss: 0.09540068\n",
      "epoch: 46  batch: 30  loss: 0.05737441\n",
      "epoch: 46  batch: 31  loss: 0.07843769\n",
      "epoch: 46  batch: 32  loss: 0.08671602\n",
      "epoch: 46  batch: 33  loss: 0.07087563\n",
      "epoch: 46  batch: 34  loss: 0.06960141\n",
      "epoch: 46  batch: 35  loss: 0.06745049\n",
      "epoch: 46  batch: 36  loss: 0.10721064\n",
      "epoch: 46  batch: 37  loss: 0.06447789\n",
      "epoch: 46  batch: 38  loss: 0.07600634\n",
      "epoch: 46  batch: 39  loss: 0.11505588\n",
      "epoch: 46  batch: 40  loss: 0.09805711\n",
      "epoch: 46  batch: 41  loss: 0.11256642\n",
      "epoch: 46  batch: 42  loss: 0.07215498\n",
      "epoch: 46  batch: 43  loss: 0.07434020\n",
      "epoch: 46  batch: 44  loss: 0.12122896\n",
      "epoch: 46  batch: 45  loss: 0.06835264\n",
      "epoch: 46  batch: 46  loss: 0.05927471\n",
      "epoch: 46  batch: 47  loss: 0.08688150\n",
      "epoch: 46  batch: 48  loss: 0.10583409\n",
      "epoch: 46  batch: 49  loss: 0.07477494\n",
      "epoch: 46  batch: 50  loss: 0.07792001\n",
      "epoch: 46  batch: 51  loss: 0.06468265\n",
      "epoch: 46  batch: 52  loss: 0.08335548\n",
      "epoch: 46  batch: 53  loss: 0.13517295\n",
      "epoch: 46  batch: 54  loss: 0.07041625\n",
      "epoch: 46  batch: 55  loss: 0.07674462\n",
      "epoch: 46  batch: 56  loss: 0.10475510\n",
      "epoch: 46  batch: 57  loss: 0.08379886\n",
      "epoch: 46  batch: 58  loss: 0.06904838\n",
      "epoch: 46  batch: 59  loss: 0.06152257\n",
      "epoch: 46  batch: 60  loss: 0.07797508\n",
      "epoch: 46  batch: 61  loss: 0.09608711\n",
      "epoch: 46  batch: 62  loss: 0.11145566\n",
      "epoch: 46  batch: 63  loss: 0.08046300\n",
      "epoch: 46  batch: 64  loss: 0.07590605\n",
      "epoch: 46  batch: 65  loss: 0.11547852\n",
      "epoch: 46  batch: 66  loss: 0.09126939\n",
      "epoch: 46  batch: 67  loss: 0.16120616\n",
      "epoch: 46  batch: 68  loss: 0.10176845\n",
      "epoch: 46  batch: 69  loss: 0.08699777\n",
      "epoch: 46  batch: 70  loss: 0.09442034\n",
      "epoch: 46  batch: 71  loss: 0.10159052\n",
      "epoch: 46  batch: 72  loss: 0.09938976\n",
      "epoch: 46  batch: 73  loss: 0.11371828\n",
      "epoch: 46  batch: 74  loss: 0.09468276\n",
      "epoch: 46  batch: 75  loss: 0.05344701\n",
      "epoch: 46  batch: 76  loss: 0.08974491\n",
      "epoch: 46  batch: 77  loss: 0.05967401\n",
      "epoch: 46  batch: 78  loss: 0.10807402\n",
      "epoch: 46  batch: 79  loss: 0.11691099\n",
      "epoch: 46  batch: 80  loss: 0.07241080\n",
      "epoch: 46  batch: 81  loss: 0.08643492\n",
      "epoch: 46  batch: 82  loss: 0.06409369\n",
      "epoch: 46  batch: 83  loss: 0.06642410\n",
      "epoch: 46  batch: 84  loss: 0.07306570\n",
      "epoch: 46  batch: 85  loss: 0.09078079\n",
      "epoch: 46  batch: 86  loss: 0.08292447\n",
      "epoch: 46  batch: 87  loss: 0.08869491\n",
      "epoch: 47  batch: 1  loss: 0.06205280\n",
      "epoch: 47  batch: 2  loss: 0.05698469\n",
      "epoch: 47  batch: 3  loss: 0.07699575\n",
      "epoch: 47  batch: 4  loss: 0.07769546\n",
      "epoch: 47  batch: 5  loss: 0.10786156\n",
      "epoch: 47  batch: 6  loss: 0.14603603\n",
      "epoch: 47  batch: 7  loss: 0.07934573\n",
      "epoch: 47  batch: 8  loss: 0.05816755\n",
      "epoch: 47  batch: 9  loss: 0.10994712\n",
      "epoch: 47  batch: 10  loss: 0.09685836\n",
      "epoch: 47  batch: 11  loss: 0.07662020\n",
      "epoch: 47  batch: 12  loss: 0.08233893\n",
      "epoch: 47  batch: 13  loss: 0.08299176\n",
      "epoch: 47  batch: 14  loss: 0.07224540\n",
      "epoch: 47  batch: 15  loss: 0.07061166\n",
      "epoch: 47  batch: 16  loss: 0.10386794\n",
      "epoch: 47  batch: 17  loss: 0.10380773\n",
      "epoch: 47  batch: 18  loss: 0.06340222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47  batch: 19  loss: 0.07445034\n",
      "epoch: 47  batch: 20  loss: 0.09401233\n",
      "epoch: 47  batch: 21  loss: 0.07953206\n",
      "epoch: 47  batch: 22  loss: 0.08200450\n",
      "epoch: 47  batch: 23  loss: 0.09256651\n",
      "epoch: 47  batch: 24  loss: 0.06212158\n",
      "epoch: 47  batch: 25  loss: 0.12380181\n",
      "epoch: 47  batch: 26  loss: 0.06687200\n",
      "epoch: 47  batch: 27  loss: 0.07855541\n",
      "epoch: 47  batch: 28  loss: 0.14122240\n",
      "epoch: 47  batch: 29  loss: 0.07907075\n",
      "epoch: 47  batch: 30  loss: 0.11697505\n",
      "epoch: 47  batch: 31  loss: 0.06870796\n",
      "epoch: 47  batch: 32  loss: 0.11537502\n",
      "epoch: 47  batch: 33  loss: 0.09364299\n",
      "epoch: 47  batch: 34  loss: 0.08378079\n",
      "epoch: 47  batch: 35  loss: 0.07853840\n",
      "epoch: 47  batch: 36  loss: 0.08497114\n",
      "epoch: 47  batch: 37  loss: 0.08140418\n",
      "epoch: 47  batch: 38  loss: 0.09093946\n",
      "epoch: 47  batch: 39  loss: 0.09056252\n",
      "epoch: 47  batch: 40  loss: 0.06208075\n",
      "epoch: 47  batch: 41  loss: 0.12417063\n",
      "epoch: 47  batch: 42  loss: 0.09282370\n",
      "epoch: 47  batch: 43  loss: 0.07040719\n",
      "epoch: 47  batch: 44  loss: 0.09831087\n",
      "epoch: 47  batch: 45  loss: 0.11778942\n",
      "epoch: 47  batch: 46  loss: 0.10626088\n",
      "epoch: 47  batch: 47  loss: 0.12536593\n",
      "epoch: 47  batch: 48  loss: 0.07443359\n",
      "epoch: 47  batch: 49  loss: 0.06730984\n",
      "epoch: 47  batch: 50  loss: 0.11170005\n",
      "epoch: 47  batch: 51  loss: 0.07762396\n",
      "epoch: 47  batch: 52  loss: 0.07790508\n",
      "epoch: 47  batch: 53  loss: 0.06929500\n",
      "epoch: 47  batch: 54  loss: 0.06526332\n",
      "epoch: 47  batch: 55  loss: 0.07648150\n",
      "epoch: 47  batch: 56  loss: 0.05504589\n",
      "epoch: 47  batch: 57  loss: 0.09008985\n",
      "epoch: 47  batch: 58  loss: 0.07102453\n",
      "epoch: 47  batch: 59  loss: 0.08185071\n",
      "epoch: 47  batch: 60  loss: 0.09397041\n",
      "epoch: 47  batch: 61  loss: 0.07647373\n",
      "epoch: 47  batch: 62  loss: 0.07245641\n",
      "epoch: 47  batch: 63  loss: 0.07369421\n",
      "epoch: 47  batch: 64  loss: 0.07480238\n",
      "epoch: 47  batch: 65  loss: 0.07175179\n",
      "epoch: 47  batch: 66  loss: 0.08955493\n",
      "epoch: 47  batch: 67  loss: 0.09308896\n",
      "epoch: 47  batch: 68  loss: 0.09932808\n",
      "epoch: 47  batch: 69  loss: 0.10317621\n",
      "epoch: 47  batch: 70  loss: 0.04957249\n",
      "epoch: 47  batch: 71  loss: 0.11592758\n",
      "epoch: 47  batch: 72  loss: 0.08198365\n",
      "epoch: 47  batch: 73  loss: 0.11965038\n",
      "epoch: 47  batch: 74  loss: 0.06866905\n",
      "epoch: 47  batch: 75  loss: 0.08923949\n",
      "epoch: 47  batch: 76  loss: 0.05709814\n",
      "epoch: 47  batch: 77  loss: 0.07717984\n",
      "epoch: 47  batch: 78  loss: 0.11612266\n",
      "epoch: 47  batch: 79  loss: 0.11860002\n",
      "epoch: 47  batch: 80  loss: 0.10855295\n",
      "epoch: 47  batch: 81  loss: 0.07851414\n",
      "epoch: 47  batch: 82  loss: 0.11532293\n",
      "epoch: 47  batch: 83  loss: 0.09016851\n",
      "epoch: 47  batch: 84  loss: 0.11433854\n",
      "epoch: 47  batch: 85  loss: 0.07889872\n",
      "epoch: 47  batch: 86  loss: 0.10933927\n",
      "epoch: 47  batch: 87  loss: 0.08718680\n",
      "epoch: 48  batch: 1  loss: 0.05588192\n",
      "epoch: 48  batch: 2  loss: 0.09528482\n",
      "epoch: 48  batch: 3  loss: 0.09148559\n",
      "epoch: 48  batch: 4  loss: 0.08168753\n",
      "epoch: 48  batch: 5  loss: 0.06760238\n",
      "epoch: 48  batch: 6  loss: 0.10568693\n",
      "epoch: 48  batch: 7  loss: 0.10821348\n",
      "epoch: 48  batch: 8  loss: 0.04700463\n",
      "epoch: 48  batch: 9  loss: 0.09333435\n",
      "epoch: 48  batch: 10  loss: 0.06961671\n",
      "epoch: 48  batch: 11  loss: 0.09549303\n",
      "epoch: 48  batch: 12  loss: 0.10547972\n",
      "epoch: 48  batch: 13  loss: 0.08397397\n",
      "epoch: 48  batch: 14  loss: 0.06008281\n",
      "epoch: 48  batch: 15  loss: 0.14837481\n",
      "epoch: 48  batch: 16  loss: 0.07717999\n",
      "epoch: 48  batch: 17  loss: 0.07979698\n",
      "epoch: 48  batch: 18  loss: 0.05929764\n",
      "epoch: 48  batch: 19  loss: 0.09294355\n",
      "epoch: 48  batch: 20  loss: 0.07738415\n",
      "epoch: 48  batch: 21  loss: 0.07440874\n",
      "epoch: 48  batch: 22  loss: 0.06562512\n",
      "epoch: 48  batch: 23  loss: 0.10200145\n",
      "epoch: 48  batch: 24  loss: 0.07946293\n",
      "epoch: 48  batch: 25  loss: 0.08312226\n",
      "epoch: 48  batch: 26  loss: 0.08584914\n",
      "epoch: 48  batch: 27  loss: 0.07632950\n",
      "epoch: 48  batch: 28  loss: 0.09630445\n",
      "epoch: 48  batch: 29  loss: 0.09069440\n",
      "epoch: 48  batch: 30  loss: 0.08258192\n",
      "epoch: 48  batch: 31  loss: 0.07484073\n",
      "epoch: 48  batch: 32  loss: 0.06261671\n",
      "epoch: 48  batch: 33  loss: 0.09477904\n",
      "epoch: 48  batch: 34  loss: 0.11504239\n",
      "epoch: 48  batch: 35  loss: 0.07747871\n",
      "epoch: 48  batch: 36  loss: 0.12039539\n",
      "epoch: 48  batch: 37  loss: 0.10005347\n",
      "epoch: 48  batch: 38  loss: 0.08459911\n",
      "epoch: 48  batch: 39  loss: 0.06896090\n",
      "epoch: 48  batch: 40  loss: 0.12548643\n",
      "epoch: 48  batch: 41  loss: 0.06195392\n",
      "epoch: 48  batch: 42  loss: 0.07441268\n",
      "epoch: 48  batch: 43  loss: 0.08022713\n",
      "epoch: 48  batch: 44  loss: 0.07067225\n",
      "epoch: 48  batch: 45  loss: 0.07060056\n",
      "epoch: 48  batch: 46  loss: 0.07494188\n",
      "epoch: 48  batch: 47  loss: 0.05256798\n",
      "epoch: 48  batch: 48  loss: 0.12594104\n",
      "epoch: 48  batch: 49  loss: 0.08803017\n",
      "epoch: 48  batch: 50  loss: 0.05608626\n",
      "epoch: 48  batch: 51  loss: 0.07893015\n",
      "epoch: 48  batch: 52  loss: 0.08737781\n",
      "epoch: 48  batch: 53  loss: 0.08725161\n",
      "epoch: 48  batch: 54  loss: 0.05069894\n",
      "epoch: 48  batch: 55  loss: 0.08678850\n",
      "epoch: 48  batch: 56  loss: 0.08951911\n",
      "epoch: 48  batch: 57  loss: 0.08893991\n",
      "epoch: 48  batch: 58  loss: 0.12728840\n",
      "epoch: 48  batch: 59  loss: 0.06548487\n",
      "epoch: 48  batch: 60  loss: 0.13300729\n",
      "epoch: 48  batch: 61  loss: 0.06662684\n",
      "epoch: 48  batch: 62  loss: 0.06403840\n",
      "epoch: 48  batch: 63  loss: 0.09323099\n",
      "epoch: 48  batch: 64  loss: 0.08577861\n",
      "epoch: 48  batch: 65  loss: 0.08054747\n",
      "epoch: 48  batch: 66  loss: 0.14436565\n",
      "epoch: 48  batch: 67  loss: 0.08438674\n",
      "epoch: 48  batch: 68  loss: 0.07198710\n",
      "epoch: 48  batch: 69  loss: 0.08063997\n",
      "epoch: 48  batch: 70  loss: 0.08438791\n",
      "epoch: 48  batch: 71  loss: 0.11974075\n",
      "epoch: 48  batch: 72  loss: 0.08391913\n",
      "epoch: 48  batch: 73  loss: 0.09611558\n",
      "epoch: 48  batch: 74  loss: 0.11106253\n",
      "epoch: 48  batch: 75  loss: 0.07420562\n",
      "epoch: 48  batch: 76  loss: 0.17717862\n",
      "epoch: 48  batch: 77  loss: 0.07645439\n",
      "epoch: 48  batch: 78  loss: 0.13545041\n",
      "epoch: 48  batch: 79  loss: 0.06579585\n",
      "epoch: 48  batch: 80  loss: 0.07108997\n",
      "epoch: 48  batch: 81  loss: 0.08591916\n",
      "epoch: 48  batch: 82  loss: 0.08773024\n",
      "epoch: 48  batch: 83  loss: 0.11028440\n",
      "epoch: 48  batch: 84  loss: 0.08569293\n",
      "epoch: 48  batch: 85  loss: 0.07613371\n",
      "epoch: 48  batch: 86  loss: 0.05852070\n",
      "epoch: 48  batch: 87  loss: 0.09492195\n",
      "epoch: 49  batch: 1  loss: 0.06950981\n",
      "epoch: 49  batch: 2  loss: 0.14204605\n",
      "epoch: 49  batch: 3  loss: 0.09535872\n",
      "epoch: 49  batch: 4  loss: 0.08472878\n",
      "epoch: 49  batch: 5  loss: 0.08957712\n",
      "epoch: 49  batch: 6  loss: 0.07061526\n",
      "epoch: 49  batch: 7  loss: 0.05331654\n",
      "epoch: 49  batch: 8  loss: 0.08102306\n",
      "epoch: 49  batch: 9  loss: 0.07254540\n",
      "epoch: 49  batch: 10  loss: 0.11825065\n",
      "epoch: 49  batch: 11  loss: 0.11450329\n",
      "epoch: 49  batch: 12  loss: 0.06412822\n",
      "epoch: 49  batch: 13  loss: 0.11699108\n",
      "epoch: 49  batch: 14  loss: 0.09811682\n",
      "epoch: 49  batch: 15  loss: 0.09012175\n",
      "epoch: 49  batch: 16  loss: 0.09096725\n",
      "epoch: 49  batch: 17  loss: 0.07474729\n",
      "epoch: 49  batch: 18  loss: 0.12854563\n",
      "epoch: 49  batch: 19  loss: 0.09514394\n",
      "epoch: 49  batch: 20  loss: 0.06318294\n",
      "epoch: 49  batch: 21  loss: 0.08050022\n",
      "epoch: 49  batch: 22  loss: 0.07476190\n",
      "epoch: 49  batch: 23  loss: 0.06345695\n",
      "epoch: 49  batch: 24  loss: 0.07725202\n",
      "epoch: 49  batch: 25  loss: 0.07398660\n",
      "epoch: 49  batch: 26  loss: 0.09673093\n",
      "epoch: 49  batch: 27  loss: 0.06420416\n",
      "epoch: 49  batch: 28  loss: 0.06909577\n",
      "epoch: 49  batch: 29  loss: 0.09454801\n",
      "epoch: 49  batch: 30  loss: 0.09365087\n",
      "epoch: 49  batch: 31  loss: 0.09960210\n",
      "epoch: 49  batch: 32  loss: 0.08520326\n",
      "epoch: 49  batch: 33  loss: 0.09222860\n",
      "epoch: 49  batch: 34  loss: 0.07786007\n",
      "epoch: 49  batch: 35  loss: 0.07099422\n",
      "epoch: 49  batch: 36  loss: 0.08771558\n",
      "epoch: 49  batch: 37  loss: 0.16404271\n",
      "epoch: 49  batch: 38  loss: 0.09870795\n",
      "epoch: 49  batch: 39  loss: 0.09277271\n",
      "epoch: 49  batch: 40  loss: 0.11352311\n",
      "epoch: 49  batch: 41  loss: 0.07478718\n",
      "epoch: 49  batch: 42  loss: 0.04641833\n",
      "epoch: 49  batch: 43  loss: 0.07518242\n",
      "epoch: 49  batch: 44  loss: 0.08157174\n",
      "epoch: 49  batch: 45  loss: 0.11073136\n",
      "epoch: 49  batch: 46  loss: 0.09258743\n",
      "epoch: 49  batch: 47  loss: 0.05415617\n",
      "epoch: 49  batch: 48  loss: 0.08231171\n",
      "epoch: 49  batch: 49  loss: 0.06549297\n",
      "epoch: 49  batch: 50  loss: 0.06056714\n",
      "epoch: 49  batch: 51  loss: 0.10591589\n",
      "epoch: 49  batch: 52  loss: 0.10350902\n",
      "epoch: 49  batch: 53  loss: 0.07352866\n",
      "epoch: 49  batch: 54  loss: 0.05919582\n",
      "epoch: 49  batch: 55  loss: 0.07269165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49  batch: 56  loss: 0.09336254\n",
      "epoch: 49  batch: 57  loss: 0.06546074\n",
      "epoch: 49  batch: 58  loss: 0.07102795\n",
      "epoch: 49  batch: 59  loss: 0.06285049\n",
      "epoch: 49  batch: 60  loss: 0.06368556\n",
      "epoch: 49  batch: 61  loss: 0.07463388\n",
      "epoch: 49  batch: 62  loss: 0.08661523\n",
      "epoch: 49  batch: 63  loss: 0.05946285\n",
      "epoch: 49  batch: 64  loss: 0.05839478\n",
      "epoch: 49  batch: 65  loss: 0.11648872\n",
      "epoch: 49  batch: 66  loss: 0.09027995\n",
      "epoch: 49  batch: 67  loss: 0.08569761\n",
      "epoch: 49  batch: 68  loss: 0.06906971\n",
      "epoch: 49  batch: 69  loss: 0.08912387\n",
      "epoch: 49  batch: 70  loss: 0.08179984\n",
      "epoch: 49  batch: 71  loss: 0.07023096\n",
      "epoch: 49  batch: 72  loss: 0.11766594\n",
      "epoch: 49  batch: 73  loss: 0.07593580\n",
      "epoch: 49  batch: 74  loss: 0.04960535\n",
      "epoch: 49  batch: 75  loss: 0.06763972\n",
      "epoch: 49  batch: 76  loss: 0.06195031\n",
      "epoch: 49  batch: 77  loss: 0.07207820\n",
      "epoch: 49  batch: 78  loss: 0.09622451\n",
      "epoch: 49  batch: 79  loss: 0.07972059\n",
      "epoch: 49  batch: 80  loss: 0.07869105\n",
      "epoch: 49  batch: 81  loss: 0.09296625\n",
      "epoch: 49  batch: 82  loss: 0.05864875\n",
      "epoch: 49  batch: 83  loss: 0.08809015\n",
      "epoch: 49  batch: 84  loss: 0.11306498\n",
      "epoch: 49  batch: 85  loss: 0.06657267\n",
      "epoch: 49  batch: 86  loss: 0.07225603\n",
      "epoch: 49  batch: 87  loss: 0.07086193\n",
      "epoch: 50  batch: 1  loss: 0.07741679\n",
      "epoch: 50  batch: 2  loss: 0.09146371\n",
      "epoch: 50  batch: 3  loss: 0.10543973\n",
      "epoch: 50  batch: 4  loss: 0.10335962\n",
      "epoch: 50  batch: 5  loss: 0.11153547\n",
      "epoch: 50  batch: 6  loss: 0.07826345\n",
      "epoch: 50  batch: 7  loss: 0.07994311\n",
      "epoch: 50  batch: 8  loss: 0.08099382\n",
      "epoch: 50  batch: 9  loss: 0.11509220\n",
      "epoch: 50  batch: 10  loss: 0.07385684\n",
      "epoch: 50  batch: 11  loss: 0.07759196\n",
      "epoch: 50  batch: 12  loss: 0.07084227\n",
      "epoch: 50  batch: 13  loss: 0.11926045\n",
      "epoch: 50  batch: 14  loss: 0.09608888\n",
      "epoch: 50  batch: 15  loss: 0.07118021\n",
      "epoch: 50  batch: 16  loss: 0.05748964\n",
      "epoch: 50  batch: 17  loss: 0.09936736\n",
      "epoch: 50  batch: 18  loss: 0.09391170\n",
      "epoch: 50  batch: 19  loss: 0.05764356\n",
      "epoch: 50  batch: 20  loss: 0.07621580\n",
      "epoch: 50  batch: 21  loss: 0.09780666\n",
      "epoch: 50  batch: 22  loss: 0.09615906\n",
      "epoch: 50  batch: 23  loss: 0.06763265\n",
      "epoch: 50  batch: 24  loss: 0.10648829\n",
      "epoch: 50  batch: 25  loss: 0.08046556\n",
      "epoch: 50  batch: 26  loss: 0.11200944\n",
      "epoch: 50  batch: 27  loss: 0.07059572\n",
      "epoch: 50  batch: 28  loss: 0.11249064\n",
      "epoch: 50  batch: 29  loss: 0.09356917\n",
      "epoch: 50  batch: 30  loss: 0.07380759\n",
      "epoch: 50  batch: 31  loss: 0.06116561\n",
      "epoch: 50  batch: 32  loss: 0.10824119\n",
      "epoch: 50  batch: 33  loss: 0.06583528\n",
      "epoch: 50  batch: 34  loss: 0.09848227\n",
      "epoch: 50  batch: 35  loss: 0.06418514\n",
      "epoch: 50  batch: 36  loss: 0.06410836\n",
      "epoch: 50  batch: 37  loss: 0.07231566\n",
      "epoch: 50  batch: 38  loss: 0.08367772\n",
      "epoch: 50  batch: 39  loss: 0.08582336\n",
      "epoch: 50  batch: 40  loss: 0.14582448\n",
      "epoch: 50  batch: 41  loss: 0.07808403\n",
      "epoch: 50  batch: 42  loss: 0.07364361\n",
      "epoch: 50  batch: 43  loss: 0.08404201\n",
      "epoch: 50  batch: 44  loss: 0.07125872\n",
      "epoch: 50  batch: 45  loss: 0.07403880\n",
      "epoch: 50  batch: 46  loss: 0.09486947\n",
      "epoch: 50  batch: 47  loss: 0.12605685\n",
      "epoch: 50  batch: 48  loss: 0.08096211\n",
      "epoch: 50  batch: 49  loss: 0.06971607\n",
      "epoch: 50  batch: 50  loss: 0.07836077\n",
      "epoch: 50  batch: 51  loss: 0.08532941\n",
      "epoch: 50  batch: 52  loss: 0.06431035\n",
      "epoch: 50  batch: 53  loss: 0.07399365\n",
      "epoch: 50  batch: 54  loss: 0.06423984\n",
      "epoch: 50  batch: 55  loss: 0.08570093\n",
      "epoch: 50  batch: 56  loss: 0.10517561\n",
      "epoch: 50  batch: 57  loss: 0.06921408\n",
      "epoch: 50  batch: 58  loss: 0.08696321\n",
      "epoch: 50  batch: 59  loss: 0.06830975\n",
      "epoch: 50  batch: 60  loss: 0.08909095\n",
      "epoch: 50  batch: 61  loss: 0.08438139\n",
      "epoch: 50  batch: 62  loss: 0.06795333\n",
      "epoch: 50  batch: 63  loss: 0.09584742\n",
      "epoch: 50  batch: 64  loss: 0.11493095\n",
      "epoch: 50  batch: 65  loss: 0.12277123\n",
      "epoch: 50  batch: 66  loss: 0.07843587\n",
      "epoch: 50  batch: 67  loss: 0.10288642\n",
      "epoch: 50  batch: 68  loss: 0.10811798\n",
      "epoch: 50  batch: 69  loss: 0.07634637\n",
      "epoch: 50  batch: 70  loss: 0.10160519\n",
      "epoch: 50  batch: 71  loss: 0.10974914\n",
      "epoch: 50  batch: 72  loss: 0.09545832\n",
      "epoch: 50  batch: 73  loss: 0.07512467\n",
      "epoch: 50  batch: 74  loss: 0.05502313\n",
      "epoch: 50  batch: 75  loss: 0.10175699\n",
      "epoch: 50  batch: 76  loss: 0.07954170\n",
      "epoch: 50  batch: 77  loss: 0.05748736\n",
      "epoch: 50  batch: 78  loss: 0.05759714\n",
      "epoch: 50  batch: 79  loss: 0.06051012\n",
      "epoch: 50  batch: 80  loss: 0.09030037\n",
      "epoch: 50  batch: 81  loss: 0.10910109\n",
      "epoch: 50  batch: 82  loss: 0.08028532\n",
      "epoch: 50  batch: 83  loss: 0.08272596\n",
      "epoch: 50  batch: 84  loss: 0.06310475\n",
      "epoch: 50  batch: 85  loss: 0.05678273\n",
      "epoch: 50  batch: 86  loss: 0.05429390\n",
      "epoch: 50  batch: 87  loss: 0.08467956\n",
      "epoch: 51  batch: 1  loss: 0.08664215\n",
      "epoch: 51  batch: 2  loss: 0.10214751\n",
      "epoch: 51  batch: 3  loss: 0.09060382\n",
      "epoch: 51  batch: 4  loss: 0.08918551\n",
      "epoch: 51  batch: 5  loss: 0.06528151\n",
      "epoch: 51  batch: 6  loss: 0.14742881\n",
      "epoch: 51  batch: 7  loss: 0.06043425\n",
      "epoch: 51  batch: 8  loss: 0.09856123\n",
      "epoch: 51  batch: 9  loss: 0.07021110\n",
      "epoch: 51  batch: 10  loss: 0.07775742\n",
      "epoch: 51  batch: 11  loss: 0.13331534\n",
      "epoch: 51  batch: 12  loss: 0.11250223\n",
      "epoch: 51  batch: 13  loss: 0.10564048\n",
      "epoch: 51  batch: 14  loss: 0.07398552\n",
      "epoch: 51  batch: 15  loss: 0.07213449\n",
      "epoch: 51  batch: 16  loss: 0.10369612\n",
      "epoch: 51  batch: 17  loss: 0.09429209\n",
      "epoch: 51  batch: 18  loss: 0.09336987\n",
      "epoch: 51  batch: 19  loss: 0.06540427\n",
      "epoch: 51  batch: 20  loss: 0.11682943\n",
      "epoch: 51  batch: 21  loss: 0.08146300\n",
      "epoch: 51  batch: 22  loss: 0.08404269\n",
      "epoch: 51  batch: 23  loss: 0.07553735\n",
      "epoch: 51  batch: 24  loss: 0.09446187\n",
      "epoch: 51  batch: 25  loss: 0.09790678\n",
      "epoch: 51  batch: 26  loss: 0.11792918\n",
      "epoch: 51  batch: 27  loss: 0.08648941\n",
      "epoch: 51  batch: 28  loss: 0.10045110\n",
      "epoch: 51  batch: 29  loss: 0.07237716\n",
      "epoch: 51  batch: 30  loss: 0.06082674\n",
      "epoch: 51  batch: 31  loss: 0.07392288\n",
      "epoch: 51  batch: 32  loss: 0.05624580\n",
      "epoch: 51  batch: 33  loss: 0.06236984\n",
      "epoch: 51  batch: 34  loss: 0.06591833\n",
      "epoch: 51  batch: 35  loss: 0.07303952\n",
      "epoch: 51  batch: 36  loss: 0.06001263\n",
      "epoch: 51  batch: 37  loss: 0.08369364\n",
      "epoch: 51  batch: 38  loss: 0.07862956\n",
      "epoch: 51  batch: 39  loss: 0.07725660\n",
      "epoch: 51  batch: 40  loss: 0.05805654\n",
      "epoch: 51  batch: 41  loss: 0.09877395\n",
      "epoch: 51  batch: 42  loss: 0.07940678\n",
      "epoch: 51  batch: 43  loss: 0.10820425\n",
      "epoch: 51  batch: 44  loss: 0.06419605\n",
      "epoch: 51  batch: 45  loss: 0.07451695\n",
      "epoch: 51  batch: 46  loss: 0.10628209\n",
      "epoch: 51  batch: 47  loss: 0.10586791\n",
      "epoch: 51  batch: 48  loss: 0.11772878\n",
      "epoch: 51  batch: 49  loss: 0.05495295\n",
      "epoch: 51  batch: 50  loss: 0.09042066\n",
      "epoch: 51  batch: 51  loss: 0.10274238\n",
      "epoch: 51  batch: 52  loss: 0.12484393\n",
      "epoch: 51  batch: 53  loss: 0.09205505\n",
      "epoch: 51  batch: 54  loss: 0.08953777\n",
      "epoch: 51  batch: 55  loss: 0.05149644\n",
      "epoch: 51  batch: 56  loss: 0.07984415\n",
      "epoch: 51  batch: 57  loss: 0.08951326\n",
      "epoch: 51  batch: 58  loss: 0.07273333\n",
      "epoch: 51  batch: 59  loss: 0.09912831\n",
      "epoch: 51  batch: 60  loss: 0.05567544\n",
      "epoch: 51  batch: 61  loss: 0.08253728\n",
      "epoch: 51  batch: 62  loss: 0.07156391\n",
      "epoch: 51  batch: 63  loss: 0.06233048\n",
      "epoch: 51  batch: 64  loss: 0.10886484\n",
      "epoch: 51  batch: 65  loss: 0.08005849\n",
      "epoch: 51  batch: 66  loss: 0.08566994\n",
      "epoch: 51  batch: 67  loss: 0.08327316\n",
      "epoch: 51  batch: 68  loss: 0.10359455\n",
      "epoch: 51  batch: 69  loss: 0.07503087\n",
      "epoch: 51  batch: 70  loss: 0.06678033\n",
      "epoch: 51  batch: 71  loss: 0.09035223\n",
      "epoch: 51  batch: 72  loss: 0.06168919\n",
      "epoch: 51  batch: 73  loss: 0.06553737\n",
      "epoch: 51  batch: 74  loss: 0.08628340\n",
      "epoch: 51  batch: 75  loss: 0.07665293\n",
      "epoch: 51  batch: 76  loss: 0.08008179\n",
      "epoch: 51  batch: 77  loss: 0.06833024\n",
      "epoch: 51  batch: 78  loss: 0.09233249\n",
      "epoch: 51  batch: 79  loss: 0.12114283\n",
      "epoch: 51  batch: 80  loss: 0.07336281\n",
      "epoch: 51  batch: 81  loss: 0.12828150\n",
      "epoch: 51  batch: 82  loss: 0.08559436\n",
      "epoch: 51  batch: 83  loss: 0.07243782\n",
      "epoch: 51  batch: 84  loss: 0.08783527\n",
      "epoch: 51  batch: 85  loss: 0.08789416\n",
      "epoch: 51  batch: 86  loss: 0.07373817\n",
      "epoch: 51  batch: 87  loss: 0.11189209\n",
      "epoch: 52  batch: 1  loss: 0.10683035\n",
      "epoch: 52  batch: 2  loss: 0.06542911\n",
      "epoch: 52  batch: 3  loss: 0.06697948\n",
      "epoch: 52  batch: 4  loss: 0.07697079\n",
      "epoch: 52  batch: 5  loss: 0.06668779\n",
      "epoch: 52  batch: 6  loss: 0.08419979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52  batch: 7  loss: 0.06728013\n",
      "epoch: 52  batch: 8  loss: 0.08949156\n",
      "epoch: 52  batch: 9  loss: 0.10311741\n",
      "epoch: 52  batch: 10  loss: 0.09467344\n",
      "epoch: 52  batch: 11  loss: 0.07943089\n",
      "epoch: 52  batch: 12  loss: 0.07102545\n",
      "epoch: 52  batch: 13  loss: 0.08958707\n",
      "epoch: 52  batch: 14  loss: 0.05766022\n",
      "epoch: 52  batch: 15  loss: 0.10519686\n",
      "epoch: 52  batch: 16  loss: 0.06928759\n",
      "epoch: 52  batch: 17  loss: 0.09268264\n",
      "epoch: 52  batch: 18  loss: 0.10516140\n",
      "epoch: 52  batch: 19  loss: 0.06695874\n",
      "epoch: 52  batch: 20  loss: 0.08299353\n",
      "epoch: 52  batch: 21  loss: 0.07682100\n",
      "epoch: 52  batch: 22  loss: 0.07317609\n",
      "epoch: 52  batch: 23  loss: 0.11241935\n",
      "epoch: 52  batch: 24  loss: 0.06314068\n",
      "epoch: 52  batch: 25  loss: 0.10285904\n",
      "epoch: 52  batch: 26  loss: 0.09973220\n",
      "epoch: 52  batch: 27  loss: 0.08146823\n",
      "epoch: 52  batch: 28  loss: 0.07360949\n",
      "epoch: 52  batch: 29  loss: 0.08959636\n",
      "epoch: 52  batch: 30  loss: 0.08357463\n",
      "epoch: 52  batch: 31  loss: 0.05279382\n",
      "epoch: 52  batch: 32  loss: 0.07534061\n",
      "epoch: 52  batch: 33  loss: 0.08019044\n",
      "epoch: 52  batch: 34  loss: 0.08338503\n",
      "epoch: 52  batch: 35  loss: 0.08242965\n",
      "epoch: 52  batch: 36  loss: 0.06673454\n",
      "epoch: 52  batch: 37  loss: 0.08585753\n",
      "epoch: 52  batch: 38  loss: 0.08401400\n",
      "epoch: 52  batch: 39  loss: 0.06234477\n",
      "epoch: 52  batch: 40  loss: 0.11705437\n",
      "epoch: 52  batch: 41  loss: 0.06568341\n",
      "epoch: 52  batch: 42  loss: 0.07904983\n",
      "epoch: 52  batch: 43  loss: 0.08252871\n",
      "epoch: 52  batch: 44  loss: 0.05826598\n",
      "epoch: 52  batch: 45  loss: 0.08323272\n",
      "epoch: 52  batch: 46  loss: 0.09416385\n",
      "epoch: 52  batch: 47  loss: 0.11565659\n",
      "epoch: 52  batch: 48  loss: 0.06526686\n",
      "epoch: 52  batch: 49  loss: 0.08513863\n",
      "epoch: 52  batch: 50  loss: 0.05644431\n",
      "epoch: 52  batch: 51  loss: 0.05931520\n",
      "epoch: 52  batch: 52  loss: 0.05997132\n",
      "epoch: 52  batch: 53  loss: 0.08476745\n",
      "epoch: 52  batch: 54  loss: 0.06933697\n",
      "epoch: 52  batch: 55  loss: 0.09614410\n",
      "epoch: 52  batch: 56  loss: 0.09774800\n",
      "epoch: 52  batch: 57  loss: 0.08521693\n",
      "epoch: 52  batch: 58  loss: 0.07318750\n",
      "epoch: 52  batch: 59  loss: 0.09399045\n",
      "epoch: 52  batch: 60  loss: 0.06053482\n",
      "epoch: 52  batch: 61  loss: 0.10423683\n",
      "epoch: 52  batch: 62  loss: 0.08591161\n",
      "epoch: 52  batch: 63  loss: 0.13697657\n",
      "epoch: 52  batch: 64  loss: 0.11429756\n",
      "epoch: 52  batch: 65  loss: 0.10343695\n",
      "epoch: 52  batch: 66  loss: 0.08616631\n",
      "epoch: 52  batch: 67  loss: 0.09123921\n",
      "epoch: 52  batch: 68  loss: 0.08212243\n",
      "epoch: 52  batch: 69  loss: 0.05950833\n",
      "epoch: 52  batch: 70  loss: 0.05650281\n",
      "epoch: 52  batch: 71  loss: 0.06165519\n",
      "epoch: 52  batch: 72  loss: 0.05610307\n",
      "epoch: 52  batch: 73  loss: 0.07691284\n",
      "epoch: 52  batch: 74  loss: 0.12172095\n",
      "epoch: 52  batch: 75  loss: 0.08555222\n",
      "epoch: 52  batch: 76  loss: 0.08311775\n",
      "epoch: 52  batch: 77  loss: 0.08056111\n",
      "epoch: 52  batch: 78  loss: 0.12253633\n",
      "epoch: 52  batch: 79  loss: 0.09456854\n",
      "epoch: 52  batch: 80  loss: 0.08343525\n",
      "epoch: 52  batch: 81  loss: 0.09392362\n",
      "epoch: 52  batch: 82  loss: 0.10086675\n",
      "epoch: 52  batch: 83  loss: 0.07727191\n",
      "epoch: 52  batch: 84  loss: 0.06502903\n",
      "epoch: 52  batch: 85  loss: 0.10345025\n",
      "epoch: 52  batch: 86  loss: 0.05090424\n",
      "epoch: 52  batch: 87  loss: 0.08713654\n",
      "epoch: 53  batch: 1  loss: 0.08071736\n",
      "epoch: 53  batch: 2  loss: 0.07848071\n",
      "epoch: 53  batch: 3  loss: 0.09616477\n",
      "epoch: 53  batch: 4  loss: 0.08971207\n",
      "epoch: 53  batch: 5  loss: 0.07275835\n",
      "epoch: 53  batch: 6  loss: 0.09274418\n",
      "epoch: 53  batch: 7  loss: 0.08199687\n",
      "epoch: 53  batch: 8  loss: 0.08357034\n",
      "epoch: 53  batch: 9  loss: 0.07442690\n",
      "epoch: 53  batch: 10  loss: 0.07513978\n",
      "epoch: 53  batch: 11  loss: 0.06983581\n",
      "epoch: 53  batch: 12  loss: 0.07742162\n",
      "epoch: 53  batch: 13  loss: 0.08801406\n",
      "epoch: 53  batch: 14  loss: 0.06418976\n",
      "epoch: 53  batch: 15  loss: 0.08086202\n",
      "epoch: 53  batch: 16  loss: 0.10329239\n",
      "epoch: 53  batch: 17  loss: 0.08848972\n",
      "epoch: 53  batch: 18  loss: 0.09766336\n",
      "epoch: 53  batch: 19  loss: 0.11876625\n",
      "epoch: 53  batch: 20  loss: 0.07098057\n",
      "epoch: 53  batch: 21  loss: 0.07714084\n",
      "epoch: 53  batch: 22  loss: 0.08312170\n",
      "epoch: 53  batch: 23  loss: 0.08150907\n",
      "epoch: 53  batch: 24  loss: 0.06673011\n",
      "epoch: 53  batch: 25  loss: 0.06758768\n",
      "epoch: 53  batch: 26  loss: 0.09644669\n",
      "epoch: 53  batch: 27  loss: 0.07261344\n",
      "epoch: 53  batch: 28  loss: 0.07417160\n",
      "epoch: 53  batch: 29  loss: 0.07498506\n",
      "epoch: 53  batch: 30  loss: 0.07043457\n",
      "epoch: 53  batch: 31  loss: 0.08876887\n",
      "epoch: 53  batch: 32  loss: 0.08821480\n",
      "epoch: 53  batch: 33  loss: 0.07894593\n",
      "epoch: 53  batch: 34  loss: 0.08106693\n",
      "epoch: 53  batch: 35  loss: 0.11594415\n",
      "epoch: 53  batch: 36  loss: 0.06647599\n",
      "epoch: 53  batch: 37  loss: 0.07811195\n",
      "epoch: 53  batch: 38  loss: 0.08841337\n",
      "epoch: 53  batch: 39  loss: 0.11337562\n",
      "epoch: 53  batch: 40  loss: 0.08260805\n",
      "epoch: 53  batch: 41  loss: 0.10461710\n",
      "epoch: 53  batch: 42  loss: 0.12261967\n",
      "epoch: 53  batch: 43  loss: 0.10524727\n",
      "epoch: 53  batch: 44  loss: 0.07010352\n",
      "epoch: 53  batch: 45  loss: 0.07831869\n",
      "epoch: 53  batch: 46  loss: 0.11275541\n",
      "epoch: 53  batch: 47  loss: 0.08719344\n",
      "epoch: 53  batch: 48  loss: 0.08169944\n",
      "epoch: 53  batch: 49  loss: 0.07378100\n",
      "epoch: 53  batch: 50  loss: 0.07142472\n",
      "epoch: 53  batch: 51  loss: 0.08863510\n",
      "epoch: 53  batch: 52  loss: 0.08834708\n",
      "epoch: 53  batch: 53  loss: 0.05757264\n",
      "epoch: 53  batch: 54  loss: 0.11528716\n",
      "epoch: 53  batch: 55  loss: 0.07499199\n",
      "epoch: 53  batch: 56  loss: 0.09382034\n",
      "epoch: 53  batch: 57  loss: 0.05686213\n",
      "epoch: 53  batch: 58  loss: 0.07957212\n",
      "epoch: 53  batch: 59  loss: 0.07507412\n",
      "epoch: 53  batch: 60  loss: 0.06630164\n",
      "epoch: 53  batch: 61  loss: 0.12414108\n",
      "epoch: 53  batch: 62  loss: 0.05698329\n",
      "epoch: 53  batch: 63  loss: 0.12795959\n",
      "epoch: 53  batch: 64  loss: 0.08351704\n",
      "epoch: 53  batch: 65  loss: 0.08824039\n",
      "epoch: 53  batch: 66  loss: 0.05267512\n",
      "epoch: 53  batch: 67  loss: 0.08474527\n",
      "epoch: 53  batch: 68  loss: 0.05890943\n",
      "epoch: 53  batch: 69  loss: 0.08586776\n",
      "epoch: 53  batch: 70  loss: 0.07840500\n",
      "epoch: 53  batch: 71  loss: 0.10850848\n",
      "epoch: 53  batch: 72  loss: 0.06577243\n",
      "epoch: 53  batch: 73  loss: 0.07871765\n",
      "epoch: 53  batch: 74  loss: 0.10387100\n",
      "epoch: 53  batch: 75  loss: 0.14441326\n",
      "epoch: 53  batch: 76  loss: 0.07149260\n",
      "epoch: 53  batch: 77  loss: 0.09478954\n",
      "epoch: 53  batch: 78  loss: 0.09874886\n",
      "epoch: 53  batch: 79  loss: 0.11256872\n",
      "epoch: 53  batch: 80  loss: 0.04761863\n",
      "epoch: 53  batch: 81  loss: 0.09505121\n",
      "epoch: 53  batch: 82  loss: 0.09236604\n",
      "epoch: 53  batch: 83  loss: 0.08447357\n",
      "epoch: 53  batch: 84  loss: 0.08939821\n",
      "epoch: 53  batch: 85  loss: 0.09225205\n",
      "epoch: 53  batch: 86  loss: 0.09624961\n",
      "epoch: 53  batch: 87  loss: 0.15851337\n",
      "epoch: 54  batch: 1  loss: 0.07250290\n",
      "epoch: 54  batch: 2  loss: 0.06548044\n",
      "epoch: 54  batch: 3  loss: 0.06744750\n",
      "epoch: 54  batch: 4  loss: 0.08353651\n",
      "epoch: 54  batch: 5  loss: 0.09321821\n",
      "epoch: 54  batch: 6  loss: 0.09270895\n",
      "epoch: 54  batch: 7  loss: 0.09908371\n",
      "epoch: 54  batch: 8  loss: 0.08134861\n",
      "epoch: 54  batch: 9  loss: 0.08249535\n",
      "epoch: 54  batch: 10  loss: 0.07053407\n",
      "epoch: 54  batch: 11  loss: 0.10086765\n",
      "epoch: 54  batch: 12  loss: 0.06122350\n",
      "epoch: 54  batch: 13  loss: 0.07351629\n",
      "epoch: 54  batch: 14  loss: 0.13127659\n",
      "epoch: 54  batch: 15  loss: 0.08146697\n",
      "epoch: 54  batch: 16  loss: 0.05896161\n",
      "epoch: 54  batch: 17  loss: 0.10860795\n",
      "epoch: 54  batch: 18  loss: 0.08511563\n",
      "epoch: 54  batch: 19  loss: 0.08344202\n",
      "epoch: 54  batch: 20  loss: 0.07260808\n",
      "epoch: 54  batch: 21  loss: 0.07055134\n",
      "epoch: 54  batch: 22  loss: 0.07782621\n",
      "epoch: 54  batch: 23  loss: 0.08784100\n",
      "epoch: 54  batch: 24  loss: 0.06096242\n",
      "epoch: 54  batch: 25  loss: 0.05885315\n",
      "epoch: 54  batch: 26  loss: 0.04833879\n",
      "epoch: 54  batch: 27  loss: 0.08142512\n",
      "epoch: 54  batch: 28  loss: 0.11856740\n",
      "epoch: 54  batch: 29  loss: 0.06045019\n",
      "epoch: 54  batch: 30  loss: 0.06303749\n",
      "epoch: 54  batch: 31  loss: 0.09242257\n",
      "epoch: 54  batch: 32  loss: 0.09367947\n",
      "epoch: 54  batch: 33  loss: 0.07086398\n",
      "epoch: 54  batch: 34  loss: 0.07973269\n",
      "epoch: 54  batch: 35  loss: 0.05665103\n",
      "epoch: 54  batch: 36  loss: 0.07186491\n",
      "epoch: 54  batch: 37  loss: 0.04813381\n",
      "epoch: 54  batch: 38  loss: 0.08083497\n",
      "epoch: 54  batch: 39  loss: 0.07433350\n",
      "epoch: 54  batch: 40  loss: 0.08052327\n",
      "epoch: 54  batch: 41  loss: 0.09520164\n",
      "epoch: 54  batch: 42  loss: 0.07542315\n",
      "epoch: 54  batch: 43  loss: 0.07291377\n",
      "epoch: 54  batch: 44  loss: 0.08756296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54  batch: 45  loss: 0.07985748\n",
      "epoch: 54  batch: 46  loss: 0.10119040\n",
      "epoch: 54  batch: 47  loss: 0.06530775\n",
      "epoch: 54  batch: 48  loss: 0.08024304\n",
      "epoch: 54  batch: 49  loss: 0.05316813\n",
      "epoch: 54  batch: 50  loss: 0.09674911\n",
      "epoch: 54  batch: 51  loss: 0.08156184\n",
      "epoch: 54  batch: 52  loss: 0.08085043\n",
      "epoch: 54  batch: 53  loss: 0.10653032\n",
      "epoch: 54  batch: 54  loss: 0.09730741\n",
      "epoch: 54  batch: 55  loss: 0.07120162\n",
      "epoch: 54  batch: 56  loss: 0.06271130\n",
      "epoch: 54  batch: 57  loss: 0.09883299\n",
      "epoch: 54  batch: 58  loss: 0.11753152\n",
      "epoch: 54  batch: 59  loss: 0.08616278\n",
      "epoch: 54  batch: 60  loss: 0.14315003\n",
      "epoch: 54  batch: 61  loss: 0.06540647\n",
      "epoch: 54  batch: 62  loss: 0.08077778\n",
      "epoch: 54  batch: 63  loss: 0.05812793\n",
      "epoch: 54  batch: 64  loss: 0.08377568\n",
      "epoch: 54  batch: 65  loss: 0.07043998\n",
      "epoch: 54  batch: 66  loss: 0.12985782\n",
      "epoch: 54  batch: 67  loss: 0.08162108\n",
      "epoch: 54  batch: 68  loss: 0.09449265\n",
      "epoch: 54  batch: 69  loss: 0.09326961\n",
      "epoch: 54  batch: 70  loss: 0.12233222\n",
      "epoch: 54  batch: 71  loss: 0.07872467\n",
      "epoch: 54  batch: 72  loss: 0.06809814\n",
      "epoch: 54  batch: 73  loss: 0.06591196\n",
      "epoch: 54  batch: 74  loss: 0.08424915\n",
      "epoch: 54  batch: 75  loss: 0.06509346\n",
      "epoch: 54  batch: 76  loss: 0.07837158\n",
      "epoch: 54  batch: 77  loss: 0.06196165\n",
      "epoch: 54  batch: 78  loss: 0.09061545\n",
      "epoch: 54  batch: 79  loss: 0.08508413\n",
      "epoch: 54  batch: 80  loss: 0.09489980\n",
      "epoch: 54  batch: 81  loss: 0.09316214\n",
      "epoch: 54  batch: 82  loss: 0.10404029\n",
      "epoch: 54  batch: 83  loss: 0.04910316\n",
      "epoch: 54  batch: 84  loss: 0.07419434\n",
      "epoch: 54  batch: 85  loss: 0.12208103\n",
      "epoch: 54  batch: 86  loss: 0.10839535\n",
      "epoch: 54  batch: 87  loss: 0.08306510\n",
      "epoch: 55  batch: 1  loss: 0.09499459\n",
      "epoch: 55  batch: 2  loss: 0.07076675\n",
      "epoch: 55  batch: 3  loss: 0.09954098\n",
      "epoch: 55  batch: 4  loss: 0.05377998\n",
      "epoch: 55  batch: 5  loss: 0.07576311\n",
      "epoch: 55  batch: 6  loss: 0.08583231\n",
      "epoch: 55  batch: 7  loss: 0.05790953\n",
      "epoch: 55  batch: 8  loss: 0.05937960\n",
      "epoch: 55  batch: 9  loss: 0.06604657\n",
      "epoch: 55  batch: 10  loss: 0.04786801\n",
      "epoch: 55  batch: 11  loss: 0.06674562\n",
      "epoch: 55  batch: 12  loss: 0.06258511\n",
      "epoch: 55  batch: 13  loss: 0.06781440\n",
      "epoch: 55  batch: 14  loss: 0.10048074\n",
      "epoch: 55  batch: 15  loss: 0.05725482\n",
      "epoch: 55  batch: 16  loss: 0.06696482\n",
      "epoch: 55  batch: 17  loss: 0.08182444\n",
      "epoch: 55  batch: 18  loss: 0.06245272\n",
      "epoch: 55  batch: 19  loss: 0.06201746\n",
      "epoch: 55  batch: 20  loss: 0.08784769\n",
      "epoch: 55  batch: 21  loss: 0.07241794\n",
      "epoch: 55  batch: 22  loss: 0.08390792\n",
      "epoch: 55  batch: 23  loss: 0.07003243\n",
      "epoch: 55  batch: 24  loss: 0.11318282\n",
      "epoch: 55  batch: 25  loss: 0.07579461\n",
      "epoch: 55  batch: 26  loss: 0.08304124\n",
      "epoch: 55  batch: 27  loss: 0.10474986\n",
      "epoch: 55  batch: 28  loss: 0.05598561\n",
      "epoch: 55  batch: 29  loss: 0.06155330\n",
      "epoch: 55  batch: 30  loss: 0.06259142\n",
      "epoch: 55  batch: 31  loss: 0.06454545\n",
      "epoch: 55  batch: 32  loss: 0.08215126\n",
      "epoch: 55  batch: 33  loss: 0.06560962\n",
      "epoch: 55  batch: 34  loss: 0.06376753\n",
      "epoch: 55  batch: 35  loss: 0.08246191\n",
      "epoch: 55  batch: 36  loss: 0.08646846\n",
      "epoch: 55  batch: 37  loss: 0.09116450\n",
      "epoch: 55  batch: 38  loss: 0.08198859\n",
      "epoch: 55  batch: 39  loss: 0.12049515\n",
      "epoch: 55  batch: 40  loss: 0.07242742\n",
      "epoch: 55  batch: 41  loss: 0.08350866\n",
      "epoch: 55  batch: 42  loss: 0.06070569\n",
      "epoch: 55  batch: 43  loss: 0.07289071\n",
      "epoch: 55  batch: 44  loss: 0.10125121\n",
      "epoch: 55  batch: 45  loss: 0.07535431\n",
      "epoch: 55  batch: 46  loss: 0.13048585\n",
      "epoch: 55  batch: 47  loss: 0.09849735\n",
      "epoch: 55  batch: 48  loss: 0.08288611\n",
      "epoch: 55  batch: 49  loss: 0.08094012\n",
      "epoch: 55  batch: 50  loss: 0.09063288\n",
      "epoch: 55  batch: 51  loss: 0.10395216\n",
      "epoch: 55  batch: 52  loss: 0.08715494\n",
      "epoch: 55  batch: 53  loss: 0.06279133\n",
      "epoch: 55  batch: 54  loss: 0.06381650\n",
      "epoch: 55  batch: 55  loss: 0.08631293\n",
      "epoch: 55  batch: 56  loss: 0.09093197\n",
      "epoch: 55  batch: 57  loss: 0.09156346\n",
      "epoch: 55  batch: 58  loss: 0.07251873\n",
      "epoch: 55  batch: 59  loss: 0.12063289\n",
      "epoch: 55  batch: 60  loss: 0.05956008\n",
      "epoch: 55  batch: 61  loss: 0.08958738\n",
      "epoch: 55  batch: 62  loss: 0.08128760\n",
      "epoch: 55  batch: 63  loss: 0.10905070\n",
      "epoch: 55  batch: 64  loss: 0.09012169\n",
      "epoch: 55  batch: 65  loss: 0.07421143\n",
      "epoch: 55  batch: 66  loss: 0.05801888\n",
      "epoch: 55  batch: 67  loss: 0.07633435\n",
      "epoch: 55  batch: 68  loss: 0.08057403\n",
      "epoch: 55  batch: 69  loss: 0.10227786\n",
      "epoch: 55  batch: 70  loss: 0.08679043\n",
      "epoch: 55  batch: 71  loss: 0.06319760\n",
      "epoch: 55  batch: 72  loss: 0.09782652\n",
      "epoch: 55  batch: 73  loss: 0.06858216\n",
      "epoch: 55  batch: 74  loss: 0.07325917\n",
      "epoch: 55  batch: 75  loss: 0.06500407\n",
      "epoch: 55  batch: 76  loss: 0.09638973\n",
      "epoch: 55  batch: 77  loss: 0.06285553\n",
      "epoch: 55  batch: 78  loss: 0.08742894\n",
      "epoch: 55  batch: 79  loss: 0.09527132\n",
      "epoch: 55  batch: 80  loss: 0.09050965\n",
      "epoch: 55  batch: 81  loss: 0.08317460\n",
      "epoch: 55  batch: 82  loss: 0.07741978\n",
      "epoch: 55  batch: 83  loss: 0.10579483\n",
      "epoch: 55  batch: 84  loss: 0.08606633\n",
      "epoch: 55  batch: 85  loss: 0.09016082\n",
      "epoch: 55  batch: 86  loss: 0.10609756\n",
      "epoch: 55  batch: 87  loss: 0.05310813\n",
      "epoch: 56  batch: 1  loss: 0.07387719\n",
      "epoch: 56  batch: 2  loss: 0.06862526\n",
      "epoch: 56  batch: 3  loss: 0.08501212\n",
      "epoch: 56  batch: 4  loss: 0.10977631\n",
      "epoch: 56  batch: 5  loss: 0.05910009\n",
      "epoch: 56  batch: 6  loss: 0.07936015\n",
      "epoch: 56  batch: 7  loss: 0.06956251\n",
      "epoch: 56  batch: 8  loss: 0.12249536\n",
      "epoch: 56  batch: 9  loss: 0.06156910\n",
      "epoch: 56  batch: 10  loss: 0.07794859\n",
      "epoch: 56  batch: 11  loss: 0.05906739\n",
      "epoch: 56  batch: 12  loss: 0.06843498\n",
      "epoch: 56  batch: 13  loss: 0.07639636\n",
      "epoch: 56  batch: 14  loss: 0.07576618\n",
      "epoch: 56  batch: 15  loss: 0.07125019\n",
      "epoch: 56  batch: 16  loss: 0.15696856\n",
      "epoch: 56  batch: 17  loss: 0.09115238\n",
      "epoch: 56  batch: 18  loss: 0.08517656\n",
      "epoch: 56  batch: 19  loss: 0.10191999\n",
      "epoch: 56  batch: 20  loss: 0.06772838\n",
      "epoch: 56  batch: 21  loss: 0.18510592\n",
      "epoch: 56  batch: 22  loss: 0.10853412\n",
      "epoch: 56  batch: 23  loss: 0.07743406\n",
      "epoch: 56  batch: 24  loss: 0.06797317\n",
      "epoch: 56  batch: 25  loss: 0.07756040\n",
      "epoch: 56  batch: 26  loss: 0.07111201\n",
      "epoch: 56  batch: 27  loss: 0.12128599\n",
      "epoch: 56  batch: 28  loss: 0.06908297\n",
      "epoch: 56  batch: 29  loss: 0.06342241\n",
      "epoch: 56  batch: 30  loss: 0.11478238\n",
      "epoch: 56  batch: 31  loss: 0.06214487\n",
      "epoch: 56  batch: 32  loss: 0.06428664\n",
      "epoch: 56  batch: 33  loss: 0.07927524\n",
      "epoch: 56  batch: 34  loss: 0.06307033\n",
      "epoch: 56  batch: 35  loss: 0.10219811\n",
      "epoch: 56  batch: 36  loss: 0.08498983\n",
      "epoch: 56  batch: 37  loss: 0.08255671\n",
      "epoch: 56  batch: 38  loss: 0.08730008\n",
      "epoch: 56  batch: 39  loss: 0.07659703\n",
      "epoch: 56  batch: 40  loss: 0.09253176\n",
      "epoch: 56  batch: 41  loss: 0.05994459\n",
      "epoch: 56  batch: 42  loss: 0.10573521\n",
      "epoch: 56  batch: 43  loss: 0.08549456\n",
      "epoch: 56  batch: 44  loss: 0.05981141\n",
      "epoch: 56  batch: 45  loss: 0.05931709\n",
      "epoch: 56  batch: 46  loss: 0.06249534\n",
      "epoch: 56  batch: 47  loss: 0.08835176\n",
      "epoch: 56  batch: 48  loss: 0.07718579\n",
      "epoch: 56  batch: 49  loss: 0.09179934\n",
      "epoch: 56  batch: 50  loss: 0.05447849\n",
      "epoch: 56  batch: 51  loss: 0.06887916\n",
      "epoch: 56  batch: 52  loss: 0.06229231\n",
      "epoch: 56  batch: 53  loss: 0.08847834\n",
      "epoch: 56  batch: 54  loss: 0.10237515\n",
      "epoch: 56  batch: 55  loss: 0.08113876\n",
      "epoch: 56  batch: 56  loss: 0.10661961\n",
      "epoch: 56  batch: 57  loss: 0.10846537\n",
      "epoch: 56  batch: 58  loss: 0.08169281\n",
      "epoch: 56  batch: 59  loss: 0.08164326\n",
      "epoch: 56  batch: 60  loss: 0.07322770\n",
      "epoch: 56  batch: 61  loss: 0.09305548\n",
      "epoch: 56  batch: 62  loss: 0.06833049\n",
      "epoch: 56  batch: 63  loss: 0.08498944\n",
      "epoch: 56  batch: 64  loss: 0.08226131\n",
      "epoch: 56  batch: 65  loss: 0.07392380\n",
      "epoch: 56  batch: 66  loss: 0.06266138\n",
      "epoch: 56  batch: 67  loss: 0.07660113\n",
      "epoch: 56  batch: 68  loss: 0.08027356\n",
      "epoch: 56  batch: 69  loss: 0.09169919\n",
      "epoch: 56  batch: 70  loss: 0.08049406\n",
      "epoch: 56  batch: 71  loss: 0.14882247\n",
      "epoch: 56  batch: 72  loss: 0.12598699\n",
      "epoch: 56  batch: 73  loss: 0.11421229\n",
      "epoch: 56  batch: 74  loss: 0.09622107\n",
      "epoch: 56  batch: 75  loss: 0.07814319\n",
      "epoch: 56  batch: 76  loss: 0.05890575\n",
      "epoch: 56  batch: 77  loss: 0.08882187\n",
      "epoch: 56  batch: 78  loss: 0.10910593\n",
      "epoch: 56  batch: 79  loss: 0.13988082\n",
      "epoch: 56  batch: 80  loss: 0.10459217\n",
      "epoch: 56  batch: 81  loss: 0.06059258\n",
      "epoch: 56  batch: 82  loss: 0.07351746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 56  batch: 83  loss: 0.06579392\n",
      "epoch: 56  batch: 84  loss: 0.07192761\n",
      "epoch: 56  batch: 85  loss: 0.08133831\n",
      "epoch: 56  batch: 86  loss: 0.07529797\n",
      "epoch: 56  batch: 87  loss: 0.05053570\n",
      "epoch: 57  batch: 1  loss: 0.10673321\n",
      "epoch: 57  batch: 2  loss: 0.06723166\n",
      "epoch: 57  batch: 3  loss: 0.06677458\n",
      "epoch: 57  batch: 4  loss: 0.08231669\n",
      "epoch: 57  batch: 5  loss: 0.09623136\n",
      "epoch: 57  batch: 6  loss: 0.06747834\n",
      "epoch: 57  batch: 7  loss: 0.12712257\n",
      "epoch: 57  batch: 8  loss: 0.05986818\n",
      "epoch: 57  batch: 9  loss: 0.10443386\n",
      "epoch: 57  batch: 10  loss: 0.11056041\n",
      "epoch: 57  batch: 11  loss: 0.08513759\n",
      "epoch: 57  batch: 12  loss: 0.08904330\n",
      "epoch: 57  batch: 13  loss: 0.07024772\n",
      "epoch: 57  batch: 14  loss: 0.06133140\n",
      "epoch: 57  batch: 15  loss: 0.08209400\n",
      "epoch: 57  batch: 16  loss: 0.08986396\n",
      "epoch: 57  batch: 17  loss: 0.05674395\n",
      "epoch: 57  batch: 18  loss: 0.05763689\n",
      "epoch: 57  batch: 19  loss: 0.10221851\n",
      "epoch: 57  batch: 20  loss: 0.11275097\n",
      "epoch: 57  batch: 21  loss: 0.07805806\n",
      "epoch: 57  batch: 22  loss: 0.08919691\n",
      "epoch: 57  batch: 23  loss: 0.10979126\n",
      "epoch: 57  batch: 24  loss: 0.06216948\n",
      "epoch: 57  batch: 25  loss: 0.06265339\n",
      "epoch: 57  batch: 26  loss: 0.08735622\n",
      "epoch: 57  batch: 27  loss: 0.08818939\n",
      "epoch: 57  batch: 28  loss: 0.09166104\n",
      "epoch: 57  batch: 29  loss: 0.11203892\n",
      "epoch: 57  batch: 30  loss: 0.08105366\n",
      "epoch: 57  batch: 31  loss: 0.08324178\n",
      "epoch: 57  batch: 32  loss: 0.07464765\n",
      "epoch: 57  batch: 33  loss: 0.06897835\n",
      "epoch: 57  batch: 34  loss: 0.09953698\n",
      "epoch: 57  batch: 35  loss: 0.08409327\n",
      "epoch: 57  batch: 36  loss: 0.06025407\n",
      "epoch: 57  batch: 37  loss: 0.08402456\n",
      "epoch: 57  batch: 38  loss: 0.11678038\n",
      "epoch: 57  batch: 39  loss: 0.07218539\n",
      "epoch: 57  batch: 40  loss: 0.04722219\n",
      "epoch: 57  batch: 41  loss: 0.06888250\n",
      "epoch: 57  batch: 42  loss: 0.09262351\n",
      "epoch: 57  batch: 43  loss: 0.06623773\n",
      "epoch: 57  batch: 44  loss: 0.07239167\n",
      "epoch: 57  batch: 45  loss: 0.08200043\n",
      "epoch: 57  batch: 46  loss: 0.06927469\n",
      "epoch: 57  batch: 47  loss: 0.13122949\n",
      "epoch: 57  batch: 48  loss: 0.07703166\n",
      "epoch: 57  batch: 49  loss: 0.08003943\n",
      "epoch: 57  batch: 50  loss: 0.08259682\n",
      "epoch: 57  batch: 51  loss: 0.08940233\n",
      "epoch: 57  batch: 52  loss: 0.08102562\n",
      "epoch: 57  batch: 53  loss: 0.05595204\n",
      "epoch: 57  batch: 54  loss: 0.06057279\n",
      "epoch: 57  batch: 55  loss: 0.08172696\n",
      "epoch: 57  batch: 56  loss: 0.05720784\n",
      "epoch: 57  batch: 57  loss: 0.06953864\n",
      "epoch: 57  batch: 58  loss: 0.13567503\n",
      "epoch: 57  batch: 59  loss: 0.07747755\n",
      "epoch: 57  batch: 60  loss: 0.08882420\n",
      "epoch: 57  batch: 61  loss: 0.09497680\n",
      "epoch: 57  batch: 62  loss: 0.11297926\n",
      "epoch: 57  batch: 63  loss: 0.06642528\n",
      "epoch: 57  batch: 64  loss: 0.10733265\n",
      "epoch: 57  batch: 65  loss: 0.07062425\n",
      "epoch: 57  batch: 66  loss: 0.09958083\n",
      "epoch: 57  batch: 67  loss: 0.07139947\n",
      "epoch: 57  batch: 68  loss: 0.09470528\n",
      "epoch: 57  batch: 69  loss: 0.11650626\n",
      "epoch: 57  batch: 70  loss: 0.13252193\n",
      "epoch: 57  batch: 71  loss: 0.07160459\n",
      "epoch: 57  batch: 72  loss: 0.14158119\n",
      "epoch: 57  batch: 73  loss: 0.06510885\n",
      "epoch: 57  batch: 74  loss: 0.11157800\n",
      "epoch: 57  batch: 75  loss: 0.06057556\n",
      "epoch: 57  batch: 76  loss: 0.12503859\n",
      "epoch: 57  batch: 77  loss: 0.09458423\n",
      "epoch: 57  batch: 78  loss: 0.04736221\n",
      "epoch: 57  batch: 79  loss: 0.07734850\n",
      "epoch: 57  batch: 80  loss: 0.06965452\n",
      "epoch: 57  batch: 81  loss: 0.07854290\n",
      "epoch: 57  batch: 82  loss: 0.09574933\n",
      "epoch: 57  batch: 83  loss: 0.08315302\n",
      "epoch: 57  batch: 84  loss: 0.06932112\n",
      "epoch: 57  batch: 85  loss: 0.06134604\n",
      "epoch: 57  batch: 86  loss: 0.05812206\n",
      "epoch: 57  batch: 87  loss: 0.06908676\n",
      "epoch: 58  batch: 1  loss: 0.07026380\n",
      "epoch: 58  batch: 2  loss: 0.10475618\n",
      "epoch: 58  batch: 3  loss: 0.09260919\n",
      "epoch: 58  batch: 4  loss: 0.06400807\n",
      "epoch: 58  batch: 5  loss: 0.08031593\n",
      "epoch: 58  batch: 6  loss: 0.07435120\n",
      "epoch: 58  batch: 7  loss: 0.09839174\n",
      "epoch: 58  batch: 8  loss: 0.07701226\n",
      "epoch: 58  batch: 9  loss: 0.08097882\n",
      "epoch: 58  batch: 10  loss: 0.09110455\n",
      "epoch: 58  batch: 11  loss: 0.08820248\n",
      "epoch: 58  batch: 12  loss: 0.11561688\n",
      "epoch: 58  batch: 13  loss: 0.06704523\n",
      "epoch: 58  batch: 14  loss: 0.08647872\n",
      "epoch: 58  batch: 15  loss: 0.07257645\n",
      "epoch: 58  batch: 16  loss: 0.05971123\n",
      "epoch: 58  batch: 17  loss: 0.08259023\n",
      "epoch: 58  batch: 18  loss: 0.06817422\n",
      "epoch: 58  batch: 19  loss: 0.06826944\n",
      "epoch: 58  batch: 20  loss: 0.09800462\n",
      "epoch: 58  batch: 21  loss: 0.07954566\n",
      "epoch: 58  batch: 22  loss: 0.05052146\n",
      "epoch: 58  batch: 23  loss: 0.05761701\n",
      "epoch: 58  batch: 24  loss: 0.09466993\n",
      "epoch: 58  batch: 25  loss: 0.09107347\n",
      "epoch: 58  batch: 26  loss: 0.08287211\n",
      "epoch: 58  batch: 27  loss: 0.07897921\n",
      "epoch: 58  batch: 28  loss: 0.07880297\n",
      "epoch: 58  batch: 29  loss: 0.10669297\n",
      "epoch: 58  batch: 30  loss: 0.11301854\n",
      "epoch: 58  batch: 31  loss: 0.10705483\n",
      "epoch: 58  batch: 32  loss: 0.10377362\n",
      "epoch: 58  batch: 33  loss: 0.06406061\n",
      "epoch: 58  batch: 34  loss: 0.06858229\n",
      "epoch: 58  batch: 35  loss: 0.09801498\n",
      "epoch: 58  batch: 36  loss: 0.16056246\n",
      "epoch: 58  batch: 37  loss: 0.08011971\n",
      "epoch: 58  batch: 38  loss: 0.12019584\n",
      "epoch: 58  batch: 39  loss: 0.08367361\n",
      "epoch: 58  batch: 40  loss: 0.07121437\n",
      "epoch: 58  batch: 41  loss: 0.09885829\n",
      "epoch: 58  batch: 42  loss: 0.10555512\n",
      "epoch: 58  batch: 43  loss: 0.05174923\n",
      "epoch: 58  batch: 44  loss: 0.07404014\n",
      "epoch: 58  batch: 45  loss: 0.06134332\n",
      "epoch: 58  batch: 46  loss: 0.05789757\n",
      "epoch: 58  batch: 47  loss: 0.07443656\n",
      "epoch: 58  batch: 48  loss: 0.12643956\n",
      "epoch: 58  batch: 49  loss: 0.09274102\n",
      "epoch: 58  batch: 50  loss: 0.07912549\n",
      "epoch: 58  batch: 51  loss: 0.06789348\n",
      "epoch: 58  batch: 52  loss: 0.09656606\n",
      "epoch: 58  batch: 53  loss: 0.05906051\n",
      "epoch: 58  batch: 54  loss: 0.09131762\n",
      "epoch: 58  batch: 55  loss: 0.06662564\n",
      "epoch: 58  batch: 56  loss: 0.09093452\n",
      "epoch: 58  batch: 57  loss: 0.07841723\n",
      "epoch: 58  batch: 58  loss: 0.07598619\n",
      "epoch: 58  batch: 59  loss: 0.07266214\n",
      "epoch: 58  batch: 60  loss: 0.08103124\n",
      "epoch: 58  batch: 61  loss: 0.08703223\n",
      "epoch: 58  batch: 62  loss: 0.10006651\n",
      "epoch: 58  batch: 63  loss: 0.05774274\n",
      "epoch: 58  batch: 64  loss: 0.08815337\n",
      "epoch: 58  batch: 65  loss: 0.07765716\n",
      "epoch: 58  batch: 66  loss: 0.04461660\n",
      "epoch: 58  batch: 67  loss: 0.07930209\n",
      "epoch: 58  batch: 68  loss: 0.08569541\n",
      "epoch: 58  batch: 69  loss: 0.08999003\n",
      "epoch: 58  batch: 70  loss: 0.17423637\n",
      "epoch: 58  batch: 71  loss: 0.05617332\n",
      "epoch: 58  batch: 72  loss: 0.08982831\n",
      "epoch: 58  batch: 73  loss: 0.06939580\n",
      "epoch: 58  batch: 74  loss: 0.10077626\n",
      "epoch: 58  batch: 75  loss: 0.07450739\n",
      "epoch: 58  batch: 76  loss: 0.06991464\n",
      "epoch: 58  batch: 77  loss: 0.09801838\n",
      "epoch: 58  batch: 78  loss: 0.10630760\n",
      "epoch: 58  batch: 79  loss: 0.12055547\n",
      "epoch: 58  batch: 80  loss: 0.07017015\n",
      "epoch: 58  batch: 81  loss: 0.07935951\n",
      "epoch: 58  batch: 82  loss: 0.04495593\n",
      "epoch: 58  batch: 83  loss: 0.06852888\n",
      "epoch: 58  batch: 84  loss: 0.08295843\n",
      "epoch: 58  batch: 85  loss: 0.09470597\n",
      "epoch: 58  batch: 86  loss: 0.05821860\n",
      "epoch: 58  batch: 87  loss: 0.08836617\n",
      "epoch: 59  batch: 1  loss: 0.08215288\n",
      "epoch: 59  batch: 2  loss: 0.06648804\n",
      "epoch: 59  batch: 3  loss: 0.06112377\n",
      "epoch: 59  batch: 4  loss: 0.10336655\n",
      "epoch: 59  batch: 5  loss: 0.07096729\n",
      "epoch: 59  batch: 6  loss: 0.07662923\n",
      "epoch: 59  batch: 7  loss: 0.10030604\n",
      "epoch: 59  batch: 8  loss: 0.08609682\n",
      "epoch: 59  batch: 9  loss: 0.07400105\n",
      "epoch: 59  batch: 10  loss: 0.08758286\n",
      "epoch: 59  batch: 11  loss: 0.09393327\n",
      "epoch: 59  batch: 12  loss: 0.06972240\n",
      "epoch: 59  batch: 13  loss: 0.07335398\n",
      "epoch: 59  batch: 14  loss: 0.08179522\n",
      "epoch: 59  batch: 15  loss: 0.07074291\n",
      "epoch: 59  batch: 16  loss: 0.06653783\n",
      "epoch: 59  batch: 17  loss: 0.06455121\n",
      "epoch: 59  batch: 18  loss: 0.09812696\n",
      "epoch: 59  batch: 19  loss: 0.06307038\n",
      "epoch: 59  batch: 20  loss: 0.10220296\n",
      "epoch: 59  batch: 21  loss: 0.07228973\n",
      "epoch: 59  batch: 22  loss: 0.09303828\n",
      "epoch: 59  batch: 23  loss: 0.07883807\n",
      "epoch: 59  batch: 24  loss: 0.08126183\n",
      "epoch: 59  batch: 25  loss: 0.05194892\n",
      "epoch: 59  batch: 26  loss: 0.08160929\n",
      "epoch: 59  batch: 27  loss: 0.07184153\n",
      "epoch: 59  batch: 28  loss: 0.05332170\n",
      "epoch: 59  batch: 29  loss: 0.05300907\n",
      "epoch: 59  batch: 30  loss: 0.08564546\n",
      "epoch: 59  batch: 31  loss: 0.07942539\n",
      "epoch: 59  batch: 32  loss: 0.08830564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 59  batch: 33  loss: 0.09921987\n",
      "epoch: 59  batch: 34  loss: 0.11185005\n",
      "epoch: 59  batch: 35  loss: 0.09789279\n",
      "epoch: 59  batch: 36  loss: 0.08270516\n",
      "epoch: 59  batch: 37  loss: 0.06270970\n",
      "epoch: 59  batch: 38  loss: 0.12253272\n",
      "epoch: 59  batch: 39  loss: 0.11001407\n",
      "epoch: 59  batch: 40  loss: 0.07532912\n",
      "epoch: 59  batch: 41  loss: 0.07979026\n",
      "epoch: 59  batch: 42  loss: 0.11090606\n",
      "epoch: 59  batch: 43  loss: 0.05951407\n",
      "epoch: 59  batch: 44  loss: 0.07517277\n",
      "epoch: 59  batch: 45  loss: 0.06043025\n",
      "epoch: 59  batch: 46  loss: 0.07726957\n",
      "epoch: 59  batch: 47  loss: 0.05694763\n",
      "epoch: 59  batch: 48  loss: 0.05241654\n",
      "epoch: 59  batch: 49  loss: 0.16165037\n",
      "epoch: 59  batch: 50  loss: 0.09257485\n",
      "epoch: 59  batch: 51  loss: 0.08478919\n",
      "epoch: 59  batch: 52  loss: 0.12498001\n",
      "epoch: 59  batch: 53  loss: 0.09712906\n",
      "epoch: 59  batch: 54  loss: 0.07323532\n",
      "epoch: 59  batch: 55  loss: 0.13140097\n",
      "epoch: 59  batch: 56  loss: 0.07203330\n",
      "epoch: 59  batch: 57  loss: 0.10881434\n",
      "epoch: 59  batch: 58  loss: 0.08404902\n",
      "epoch: 59  batch: 59  loss: 0.07177445\n",
      "epoch: 59  batch: 60  loss: 0.10251631\n",
      "epoch: 59  batch: 61  loss: 0.04943362\n",
      "epoch: 59  batch: 62  loss: 0.07686926\n",
      "epoch: 59  batch: 63  loss: 0.07559128\n",
      "epoch: 59  batch: 64  loss: 0.07516154\n",
      "epoch: 59  batch: 65  loss: 0.09816549\n",
      "epoch: 59  batch: 66  loss: 0.06918719\n",
      "epoch: 59  batch: 67  loss: 0.10208282\n",
      "epoch: 59  batch: 68  loss: 0.07108133\n",
      "epoch: 59  batch: 69  loss: 0.10658447\n",
      "epoch: 59  batch: 70  loss: 0.06332748\n",
      "epoch: 59  batch: 71  loss: 0.07600607\n",
      "epoch: 59  batch: 72  loss: 0.04710412\n",
      "epoch: 59  batch: 73  loss: 0.08572028\n",
      "epoch: 59  batch: 74  loss: 0.09446847\n",
      "epoch: 59  batch: 75  loss: 0.05936532\n",
      "epoch: 59  batch: 76  loss: 0.12246909\n",
      "epoch: 59  batch: 77  loss: 0.08483772\n",
      "epoch: 59  batch: 78  loss: 0.09118681\n",
      "epoch: 59  batch: 79  loss: 0.11611742\n",
      "epoch: 59  batch: 80  loss: 0.13704504\n",
      "epoch: 59  batch: 81  loss: 0.06552519\n",
      "epoch: 59  batch: 82  loss: 0.09227246\n",
      "epoch: 59  batch: 83  loss: 0.06086681\n",
      "epoch: 59  batch: 84  loss: 0.05655170\n",
      "epoch: 59  batch: 85  loss: 0.05510265\n",
      "epoch: 59  batch: 86  loss: 0.08088566\n",
      "epoch: 59  batch: 87  loss: 0.06979688\n",
      "epoch: 60  batch: 1  loss: 0.05655916\n",
      "epoch: 60  batch: 2  loss: 0.06340969\n",
      "epoch: 60  batch: 3  loss: 0.12658086\n",
      "epoch: 60  batch: 4  loss: 0.09036209\n",
      "epoch: 60  batch: 5  loss: 0.08053764\n",
      "epoch: 60  batch: 6  loss: 0.09380418\n",
      "epoch: 60  batch: 7  loss: 0.06120742\n",
      "epoch: 60  batch: 8  loss: 0.06772690\n",
      "epoch: 60  batch: 9  loss: 0.06830399\n",
      "epoch: 60  batch: 10  loss: 0.05796608\n",
      "epoch: 60  batch: 11  loss: 0.08240385\n",
      "epoch: 60  batch: 12  loss: 0.08026284\n",
      "epoch: 60  batch: 13  loss: 0.12174673\n",
      "epoch: 60  batch: 14  loss: 0.06269342\n",
      "epoch: 60  batch: 15  loss: 0.14314947\n",
      "epoch: 60  batch: 16  loss: 0.07274012\n",
      "epoch: 60  batch: 17  loss: 0.05504651\n",
      "epoch: 60  batch: 18  loss: 0.09659439\n",
      "epoch: 60  batch: 19  loss: 0.07774159\n",
      "epoch: 60  batch: 20  loss: 0.10480862\n",
      "epoch: 60  batch: 21  loss: 0.10050615\n",
      "epoch: 60  batch: 22  loss: 0.05931356\n",
      "epoch: 60  batch: 23  loss: 0.06330203\n",
      "epoch: 60  batch: 24  loss: 0.08420339\n",
      "epoch: 60  batch: 25  loss: 0.11012944\n",
      "epoch: 60  batch: 26  loss: 0.05947635\n",
      "epoch: 60  batch: 27  loss: 0.07161795\n",
      "epoch: 60  batch: 28  loss: 0.06511404\n",
      "epoch: 60  batch: 29  loss: 0.12612607\n",
      "epoch: 60  batch: 30  loss: 0.09675894\n",
      "epoch: 60  batch: 31  loss: 0.09311923\n",
      "epoch: 60  batch: 32  loss: 0.05965850\n",
      "epoch: 60  batch: 33  loss: 0.09242935\n",
      "epoch: 60  batch: 34  loss: 0.09437322\n",
      "epoch: 60  batch: 35  loss: 0.08454361\n",
      "epoch: 60  batch: 36  loss: 0.07542378\n",
      "epoch: 60  batch: 37  loss: 0.10228814\n",
      "epoch: 60  batch: 38  loss: 0.06772568\n",
      "epoch: 60  batch: 39  loss: 0.06912057\n",
      "epoch: 60  batch: 40  loss: 0.09479591\n",
      "epoch: 60  batch: 41  loss: 0.10415769\n",
      "epoch: 60  batch: 42  loss: 0.09879768\n",
      "epoch: 60  batch: 43  loss: 0.07251744\n",
      "epoch: 60  batch: 44  loss: 0.07523483\n",
      "epoch: 60  batch: 45  loss: 0.04927909\n",
      "epoch: 60  batch: 46  loss: 0.07059417\n",
      "epoch: 60  batch: 47  loss: 0.07061098\n",
      "epoch: 60  batch: 48  loss: 0.09768242\n",
      "epoch: 60  batch: 49  loss: 0.08882539\n",
      "epoch: 60  batch: 50  loss: 0.09713504\n",
      "epoch: 60  batch: 51  loss: 0.10660426\n",
      "epoch: 60  batch: 52  loss: 0.08743649\n",
      "epoch: 60  batch: 53  loss: 0.06943633\n",
      "epoch: 60  batch: 54  loss: 0.09096188\n",
      "epoch: 60  batch: 55  loss: 0.14673579\n",
      "epoch: 60  batch: 56  loss: 0.07360155\n",
      "epoch: 60  batch: 57  loss: 0.06451008\n",
      "epoch: 60  batch: 58  loss: 0.05095392\n",
      "epoch: 60  batch: 59  loss: 0.05586753\n",
      "epoch: 60  batch: 60  loss: 0.07671457\n",
      "epoch: 60  batch: 61  loss: 0.08986209\n",
      "epoch: 60  batch: 62  loss: 0.06118702\n",
      "epoch: 60  batch: 63  loss: 0.13108119\n",
      "epoch: 60  batch: 64  loss: 0.08435334\n",
      "epoch: 60  batch: 65  loss: 0.06377363\n",
      "epoch: 60  batch: 66  loss: 0.07720191\n",
      "epoch: 60  batch: 67  loss: 0.07956607\n",
      "epoch: 60  batch: 68  loss: 0.08108139\n",
      "epoch: 60  batch: 69  loss: 0.06471783\n",
      "epoch: 60  batch: 70  loss: 0.06442039\n",
      "epoch: 60  batch: 71  loss: 0.08294538\n",
      "epoch: 60  batch: 72  loss: 0.08939977\n",
      "epoch: 60  batch: 73  loss: 0.09326556\n",
      "epoch: 60  batch: 74  loss: 0.08210532\n",
      "epoch: 60  batch: 75  loss: 0.06310119\n",
      "epoch: 60  batch: 76  loss: 0.10323545\n",
      "epoch: 60  batch: 77  loss: 0.06817937\n",
      "epoch: 60  batch: 78  loss: 0.05496449\n",
      "epoch: 60  batch: 79  loss: 0.05860497\n",
      "epoch: 60  batch: 80  loss: 0.06586090\n",
      "epoch: 60  batch: 81  loss: 0.09837109\n",
      "epoch: 60  batch: 82  loss: 0.07534348\n",
      "epoch: 60  batch: 83  loss: 0.08727449\n",
      "epoch: 60  batch: 84  loss: 0.06780682\n",
      "epoch: 60  batch: 85  loss: 0.11001074\n",
      "epoch: 60  batch: 86  loss: 0.08328171\n",
      "epoch: 60  batch: 87  loss: 0.08475045\n",
      "epoch: 61  batch: 1  loss: 0.06663683\n",
      "epoch: 61  batch: 2  loss: 0.11761933\n",
      "epoch: 61  batch: 3  loss: 0.08025017\n",
      "epoch: 61  batch: 4  loss: 0.08936935\n",
      "epoch: 61  batch: 5  loss: 0.06778373\n",
      "epoch: 61  batch: 6  loss: 0.08020082\n",
      "epoch: 61  batch: 7  loss: 0.07985521\n",
      "epoch: 61  batch: 8  loss: 0.09998176\n",
      "epoch: 61  batch: 9  loss: 0.08115095\n",
      "epoch: 61  batch: 10  loss: 0.11297977\n",
      "epoch: 61  batch: 11  loss: 0.06738260\n",
      "epoch: 61  batch: 12  loss: 0.09099373\n",
      "epoch: 61  batch: 13  loss: 0.11163153\n",
      "epoch: 61  batch: 14  loss: 0.06591939\n",
      "epoch: 61  batch: 15  loss: 0.11058588\n",
      "epoch: 61  batch: 16  loss: 0.07232421\n",
      "epoch: 61  batch: 17  loss: 0.09226044\n",
      "epoch: 61  batch: 18  loss: 0.08434536\n",
      "epoch: 61  batch: 19  loss: 0.09534323\n",
      "epoch: 61  batch: 20  loss: 0.09136538\n",
      "epoch: 61  batch: 21  loss: 0.06920015\n",
      "epoch: 61  batch: 22  loss: 0.08825414\n",
      "epoch: 61  batch: 23  loss: 0.11772643\n",
      "epoch: 61  batch: 24  loss: 0.07759207\n",
      "epoch: 61  batch: 25  loss: 0.06106059\n",
      "epoch: 61  batch: 26  loss: 0.09808035\n",
      "epoch: 61  batch: 27  loss: 0.09413318\n",
      "epoch: 61  batch: 28  loss: 0.09803122\n",
      "epoch: 61  batch: 29  loss: 0.08077367\n",
      "epoch: 61  batch: 30  loss: 0.09006532\n",
      "epoch: 61  batch: 31  loss: 0.08568520\n",
      "epoch: 61  batch: 32  loss: 0.09495613\n",
      "epoch: 61  batch: 33  loss: 0.07918990\n",
      "epoch: 61  batch: 34  loss: 0.13256119\n",
      "epoch: 61  batch: 35  loss: 0.07944066\n",
      "epoch: 61  batch: 36  loss: 0.08736623\n",
      "epoch: 61  batch: 37  loss: 0.10582454\n",
      "epoch: 61  batch: 38  loss: 0.08349838\n",
      "epoch: 61  batch: 39  loss: 0.07664489\n",
      "epoch: 61  batch: 40  loss: 0.06826466\n",
      "epoch: 61  batch: 41  loss: 0.11996295\n",
      "epoch: 61  batch: 42  loss: 0.08780315\n",
      "epoch: 61  batch: 43  loss: 0.06995744\n",
      "epoch: 61  batch: 44  loss: 0.08637390\n",
      "epoch: 61  batch: 45  loss: 0.07000142\n",
      "epoch: 61  batch: 46  loss: 0.07319548\n",
      "epoch: 61  batch: 47  loss: 0.09438151\n",
      "epoch: 61  batch: 48  loss: 0.08290484\n",
      "epoch: 61  batch: 49  loss: 0.08464291\n",
      "epoch: 61  batch: 50  loss: 0.07331520\n",
      "epoch: 61  batch: 51  loss: 0.08931903\n",
      "epoch: 61  batch: 52  loss: 0.07032886\n",
      "epoch: 61  batch: 53  loss: 0.09661114\n",
      "epoch: 61  batch: 54  loss: 0.06721979\n",
      "epoch: 61  batch: 55  loss: 0.10246211\n",
      "epoch: 61  batch: 56  loss: 0.06938438\n",
      "epoch: 61  batch: 57  loss: 0.05169152\n",
      "epoch: 61  batch: 58  loss: 0.11715759\n",
      "epoch: 61  batch: 59  loss: 0.08232094\n",
      "epoch: 61  batch: 60  loss: 0.06099543\n",
      "epoch: 61  batch: 61  loss: 0.08683591\n",
      "epoch: 61  batch: 62  loss: 0.08423252\n",
      "epoch: 61  batch: 63  loss: 0.11147887\n",
      "epoch: 61  batch: 64  loss: 0.09933721\n",
      "epoch: 61  batch: 65  loss: 0.06672590\n",
      "epoch: 61  batch: 66  loss: 0.09474224\n",
      "epoch: 61  batch: 67  loss: 0.06173015\n",
      "epoch: 61  batch: 68  loss: 0.07393643\n",
      "epoch: 61  batch: 69  loss: 0.10258877\n",
      "epoch: 61  batch: 70  loss: 0.09836930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61  batch: 71  loss: 0.05515673\n",
      "epoch: 61  batch: 72  loss: 0.09993843\n",
      "epoch: 61  batch: 73  loss: 0.07877380\n",
      "epoch: 61  batch: 74  loss: 0.11237957\n",
      "epoch: 61  batch: 75  loss: 0.12374162\n",
      "epoch: 61  batch: 76  loss: 0.11393337\n",
      "epoch: 61  batch: 77  loss: 0.08952671\n",
      "epoch: 61  batch: 78  loss: 0.07303382\n",
      "epoch: 61  batch: 79  loss: 0.05140297\n",
      "epoch: 61  batch: 80  loss: 0.07512572\n",
      "epoch: 61  batch: 81  loss: 0.07811327\n",
      "epoch: 61  batch: 82  loss: 0.07919374\n",
      "epoch: 61  batch: 83  loss: 0.05998310\n",
      "epoch: 61  batch: 84  loss: 0.08964960\n",
      "epoch: 61  batch: 85  loss: 0.05031033\n",
      "epoch: 61  batch: 86  loss: 0.07861517\n",
      "epoch: 61  batch: 87  loss: 0.07313070\n",
      "epoch: 62  batch: 1  loss: 0.07940397\n",
      "epoch: 62  batch: 2  loss: 0.07853924\n",
      "epoch: 62  batch: 3  loss: 0.10219241\n",
      "epoch: 62  batch: 4  loss: 0.15763959\n",
      "epoch: 62  batch: 5  loss: 0.11687694\n",
      "epoch: 62  batch: 6  loss: 0.07485013\n",
      "epoch: 62  batch: 7  loss: 0.07809713\n",
      "epoch: 62  batch: 8  loss: 0.15482582\n",
      "epoch: 62  batch: 9  loss: 0.08867937\n",
      "epoch: 62  batch: 10  loss: 0.08084192\n",
      "epoch: 62  batch: 11  loss: 0.07010237\n",
      "epoch: 62  batch: 12  loss: 0.05557231\n",
      "epoch: 62  batch: 13  loss: 0.06221576\n",
      "epoch: 62  batch: 14  loss: 0.05090609\n",
      "epoch: 62  batch: 15  loss: 0.09657755\n",
      "epoch: 62  batch: 16  loss: 0.09170296\n",
      "epoch: 62  batch: 17  loss: 0.08173761\n",
      "epoch: 62  batch: 18  loss: 0.07233795\n",
      "epoch: 62  batch: 19  loss: 0.05766438\n",
      "epoch: 62  batch: 20  loss: 0.07396692\n",
      "epoch: 62  batch: 21  loss: 0.07811339\n",
      "epoch: 62  batch: 22  loss: 0.06024686\n",
      "epoch: 62  batch: 23  loss: 0.06629552\n",
      "epoch: 62  batch: 24  loss: 0.06795669\n",
      "epoch: 62  batch: 25  loss: 0.07853125\n",
      "epoch: 62  batch: 26  loss: 0.05500879\n",
      "epoch: 62  batch: 27  loss: 0.07095747\n",
      "epoch: 62  batch: 28  loss: 0.06834403\n",
      "epoch: 62  batch: 29  loss: 0.05942277\n",
      "epoch: 62  batch: 30  loss: 0.10051825\n",
      "epoch: 62  batch: 31  loss: 0.11006422\n",
      "epoch: 62  batch: 32  loss: 0.07990076\n",
      "epoch: 62  batch: 33  loss: 0.07323489\n",
      "epoch: 62  batch: 34  loss: 0.05829323\n",
      "epoch: 62  batch: 35  loss: 0.06599540\n",
      "epoch: 62  batch: 36  loss: 0.09307636\n",
      "epoch: 62  batch: 37  loss: 0.06511019\n",
      "epoch: 62  batch: 38  loss: 0.11446023\n",
      "epoch: 62  batch: 39  loss: 0.08887248\n",
      "epoch: 62  batch: 40  loss: 0.12527674\n",
      "epoch: 62  batch: 41  loss: 0.09083566\n",
      "epoch: 62  batch: 42  loss: 0.07466395\n",
      "epoch: 62  batch: 43  loss: 0.08439519\n",
      "epoch: 62  batch: 44  loss: 0.07360519\n",
      "epoch: 62  batch: 45  loss: 0.07456883\n",
      "epoch: 62  batch: 46  loss: 0.08795645\n",
      "epoch: 62  batch: 47  loss: 0.07020075\n",
      "epoch: 62  batch: 48  loss: 0.08629005\n",
      "epoch: 62  batch: 49  loss: 0.10289982\n",
      "epoch: 62  batch: 50  loss: 0.08588477\n",
      "epoch: 62  batch: 51  loss: 0.06070450\n",
      "epoch: 62  batch: 52  loss: 0.06688282\n",
      "epoch: 62  batch: 53  loss: 0.08486014\n",
      "epoch: 62  batch: 54  loss: 0.07460186\n",
      "epoch: 62  batch: 55  loss: 0.09350502\n",
      "epoch: 62  batch: 56  loss: 0.07563148\n",
      "epoch: 62  batch: 57  loss: 0.09971830\n",
      "epoch: 62  batch: 58  loss: 0.09580112\n",
      "epoch: 62  batch: 59  loss: 0.05840407\n",
      "epoch: 62  batch: 60  loss: 0.08354656\n",
      "epoch: 62  batch: 61  loss: 0.09814579\n",
      "epoch: 62  batch: 62  loss: 0.07903817\n",
      "epoch: 62  batch: 63  loss: 0.07665301\n",
      "epoch: 62  batch: 64  loss: 0.09155760\n",
      "epoch: 62  batch: 65  loss: 0.08904340\n",
      "epoch: 62  batch: 66  loss: 0.05689791\n",
      "epoch: 62  batch: 67  loss: 0.05190055\n",
      "epoch: 62  batch: 68  loss: 0.07312027\n",
      "epoch: 62  batch: 69  loss: 0.05982836\n",
      "epoch: 62  batch: 70  loss: 0.07189452\n",
      "epoch: 62  batch: 71  loss: 0.18368195\n",
      "epoch: 62  batch: 72  loss: 0.10414074\n",
      "epoch: 62  batch: 73  loss: 0.07482895\n",
      "epoch: 62  batch: 74  loss: 0.05173862\n",
      "epoch: 62  batch: 75  loss: 0.06974990\n",
      "epoch: 62  batch: 76  loss: 0.05982885\n",
      "epoch: 62  batch: 77  loss: 0.10146128\n",
      "epoch: 62  batch: 78  loss: 0.07320074\n",
      "epoch: 62  batch: 79  loss: 0.07314029\n",
      "epoch: 62  batch: 80  loss: 0.08115229\n",
      "epoch: 62  batch: 81  loss: 0.07288345\n",
      "epoch: 62  batch: 82  loss: 0.11562706\n",
      "epoch: 62  batch: 83  loss: 0.08138231\n",
      "epoch: 62  batch: 84  loss: 0.05847844\n",
      "epoch: 62  batch: 85  loss: 0.09919553\n",
      "epoch: 62  batch: 86  loss: 0.08145329\n",
      "epoch: 62  batch: 87  loss: 0.05569863\n",
      "epoch: 63  batch: 1  loss: 0.09842236\n",
      "epoch: 63  batch: 2  loss: 0.07108282\n",
      "epoch: 63  batch: 3  loss: 0.11140865\n",
      "epoch: 63  batch: 4  loss: 0.06977450\n",
      "epoch: 63  batch: 5  loss: 0.07320861\n",
      "epoch: 63  batch: 6  loss: 0.08749303\n",
      "epoch: 63  batch: 7  loss: 0.10264605\n",
      "epoch: 63  batch: 8  loss: 0.07325025\n",
      "epoch: 63  batch: 9  loss: 0.04679421\n",
      "epoch: 63  batch: 10  loss: 0.06576248\n",
      "epoch: 63  batch: 11  loss: 0.07701711\n",
      "epoch: 63  batch: 12  loss: 0.06615504\n",
      "epoch: 63  batch: 13  loss: 0.09993064\n",
      "epoch: 63  batch: 14  loss: 0.06348174\n",
      "epoch: 63  batch: 15  loss: 0.09092168\n",
      "epoch: 63  batch: 16  loss: 0.08605442\n",
      "epoch: 63  batch: 17  loss: 0.07238743\n",
      "epoch: 63  batch: 18  loss: 0.08453289\n",
      "epoch: 63  batch: 19  loss: 0.07393962\n",
      "epoch: 63  batch: 20  loss: 0.07137026\n",
      "epoch: 63  batch: 21  loss: 0.06097645\n",
      "epoch: 63  batch: 22  loss: 0.12931815\n",
      "epoch: 63  batch: 23  loss: 0.09361401\n",
      "epoch: 63  batch: 24  loss: 0.06810853\n",
      "epoch: 63  batch: 25  loss: 0.06041655\n",
      "epoch: 63  batch: 26  loss: 0.08554633\n",
      "epoch: 63  batch: 27  loss: 0.05497937\n",
      "epoch: 63  batch: 28  loss: 0.10289193\n",
      "epoch: 63  batch: 29  loss: 0.09810527\n",
      "epoch: 63  batch: 30  loss: 0.09786348\n",
      "epoch: 63  batch: 31  loss: 0.07578684\n",
      "epoch: 63  batch: 32  loss: 0.07551077\n",
      "epoch: 63  batch: 33  loss: 0.05399571\n",
      "epoch: 63  batch: 34  loss: 0.06069300\n",
      "epoch: 63  batch: 35  loss: 0.06946254\n",
      "epoch: 63  batch: 36  loss: 0.08614216\n",
      "epoch: 63  batch: 37  loss: 0.09428060\n",
      "epoch: 63  batch: 38  loss: 0.10632345\n",
      "epoch: 63  batch: 39  loss: 0.10288944\n",
      "epoch: 63  batch: 40  loss: 0.09666710\n",
      "epoch: 63  batch: 41  loss: 0.06216836\n",
      "epoch: 63  batch: 42  loss: 0.08471001\n",
      "epoch: 63  batch: 43  loss: 0.09306584\n",
      "epoch: 63  batch: 44  loss: 0.10796161\n",
      "epoch: 63  batch: 45  loss: 0.09099473\n",
      "epoch: 63  batch: 46  loss: 0.08916056\n",
      "epoch: 63  batch: 47  loss: 0.05181560\n",
      "epoch: 63  batch: 48  loss: 0.06657808\n",
      "epoch: 63  batch: 49  loss: 0.07351319\n",
      "epoch: 63  batch: 50  loss: 0.09238225\n",
      "epoch: 63  batch: 51  loss: 0.06732668\n",
      "epoch: 63  batch: 52  loss: 0.12786318\n",
      "epoch: 63  batch: 53  loss: 0.09394916\n",
      "epoch: 63  batch: 54  loss: 0.07976932\n",
      "epoch: 63  batch: 55  loss: 0.06965433\n",
      "epoch: 63  batch: 56  loss: 0.10622815\n",
      "epoch: 63  batch: 57  loss: 0.05878400\n",
      "epoch: 63  batch: 58  loss: 0.09789877\n",
      "epoch: 63  batch: 59  loss: 0.05693155\n",
      "epoch: 63  batch: 60  loss: 0.08362684\n",
      "epoch: 63  batch: 61  loss: 0.08361599\n",
      "epoch: 63  batch: 62  loss: 0.07441517\n",
      "epoch: 63  batch: 63  loss: 0.06407259\n",
      "epoch: 63  batch: 64  loss: 0.07854157\n",
      "epoch: 63  batch: 65  loss: 0.08148988\n",
      "epoch: 63  batch: 66  loss: 0.10899644\n",
      "epoch: 63  batch: 67  loss: 0.10840499\n",
      "epoch: 63  batch: 68  loss: 0.09847007\n",
      "epoch: 63  batch: 69  loss: 0.05285066\n",
      "epoch: 63  batch: 70  loss: 0.10642797\n",
      "epoch: 63  batch: 71  loss: 0.06762332\n",
      "epoch: 63  batch: 72  loss: 0.08451054\n",
      "epoch: 63  batch: 73  loss: 0.07837096\n",
      "epoch: 63  batch: 74  loss: 0.10192115\n",
      "epoch: 63  batch: 75  loss: 0.07970353\n",
      "epoch: 63  batch: 76  loss: 0.12428587\n",
      "epoch: 63  batch: 77  loss: 0.08013184\n",
      "epoch: 63  batch: 78  loss: 0.10322904\n",
      "epoch: 63  batch: 79  loss: 0.11686104\n",
      "epoch: 63  batch: 80  loss: 0.10199469\n",
      "epoch: 63  batch: 81  loss: 0.07378022\n",
      "epoch: 63  batch: 82  loss: 0.12038961\n",
      "epoch: 63  batch: 83  loss: 0.07662142\n",
      "epoch: 63  batch: 84  loss: 0.09313552\n",
      "epoch: 63  batch: 85  loss: 0.10230624\n",
      "epoch: 63  batch: 86  loss: 0.05618566\n",
      "epoch: 63  batch: 87  loss: 0.10510398\n",
      "epoch: 64  batch: 1  loss: 0.09933297\n",
      "epoch: 64  batch: 2  loss: 0.07259792\n",
      "epoch: 64  batch: 3  loss: 0.06610099\n",
      "epoch: 64  batch: 4  loss: 0.11236306\n",
      "epoch: 64  batch: 5  loss: 0.12778425\n",
      "epoch: 64  batch: 6  loss: 0.12519883\n",
      "epoch: 64  batch: 7  loss: 0.05829435\n",
      "epoch: 64  batch: 8  loss: 0.10060241\n",
      "epoch: 64  batch: 9  loss: 0.10712291\n",
      "epoch: 64  batch: 10  loss: 0.07311481\n",
      "epoch: 64  batch: 11  loss: 0.06994334\n",
      "epoch: 64  batch: 12  loss: 0.07354509\n",
      "epoch: 64  batch: 13  loss: 0.07477648\n",
      "epoch: 64  batch: 14  loss: 0.06071917\n",
      "epoch: 64  batch: 15  loss: 0.06901543\n",
      "epoch: 64  batch: 16  loss: 0.06177060\n",
      "epoch: 64  batch: 17  loss: 0.07795539\n",
      "epoch: 64  batch: 18  loss: 0.08978965\n",
      "epoch: 64  batch: 19  loss: 0.06271169\n",
      "epoch: 64  batch: 20  loss: 0.05894544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 64  batch: 21  loss: 0.12066910\n",
      "epoch: 64  batch: 22  loss: 0.06213122\n",
      "epoch: 64  batch: 23  loss: 0.07670143\n",
      "epoch: 64  batch: 24  loss: 0.10568478\n",
      "epoch: 64  batch: 25  loss: 0.10525841\n",
      "epoch: 64  batch: 26  loss: 0.07898101\n",
      "epoch: 64  batch: 27  loss: 0.08794651\n",
      "epoch: 64  batch: 28  loss: 0.05813245\n",
      "epoch: 64  batch: 29  loss: 0.07157790\n",
      "epoch: 64  batch: 30  loss: 0.09165988\n",
      "epoch: 64  batch: 31  loss: 0.06910482\n",
      "epoch: 64  batch: 32  loss: 0.09910504\n",
      "epoch: 64  batch: 33  loss: 0.07090345\n",
      "epoch: 64  batch: 34  loss: 0.08021556\n",
      "epoch: 64  batch: 35  loss: 0.08111342\n",
      "epoch: 64  batch: 36  loss: 0.08380582\n",
      "epoch: 64  batch: 37  loss: 0.07131823\n",
      "epoch: 64  batch: 38  loss: 0.07829220\n",
      "epoch: 64  batch: 39  loss: 0.05676060\n",
      "epoch: 64  batch: 40  loss: 0.13770264\n",
      "epoch: 64  batch: 41  loss: 0.06526849\n",
      "epoch: 64  batch: 42  loss: 0.09156255\n",
      "epoch: 64  batch: 43  loss: 0.10829963\n",
      "epoch: 64  batch: 44  loss: 0.10027336\n",
      "epoch: 64  batch: 45  loss: 0.06788901\n",
      "epoch: 64  batch: 46  loss: 0.08945689\n",
      "epoch: 64  batch: 47  loss: 0.04778180\n",
      "epoch: 64  batch: 48  loss: 0.05938185\n",
      "epoch: 64  batch: 49  loss: 0.06603096\n",
      "epoch: 64  batch: 50  loss: 0.06396283\n",
      "epoch: 64  batch: 51  loss: 0.07467614\n",
      "epoch: 64  batch: 52  loss: 0.09136691\n",
      "epoch: 64  batch: 53  loss: 0.07198965\n",
      "epoch: 64  batch: 54  loss: 0.04497103\n",
      "epoch: 64  batch: 55  loss: 0.06457307\n",
      "epoch: 64  batch: 56  loss: 0.06581630\n",
      "epoch: 64  batch: 57  loss: 0.07621785\n",
      "epoch: 64  batch: 58  loss: 0.07527716\n",
      "epoch: 64  batch: 59  loss: 0.10482691\n",
      "epoch: 64  batch: 60  loss: 0.05599259\n",
      "epoch: 64  batch: 61  loss: 0.08334036\n",
      "epoch: 64  batch: 62  loss: 0.09357603\n",
      "epoch: 64  batch: 63  loss: 0.07291093\n",
      "epoch: 64  batch: 64  loss: 0.10172787\n",
      "epoch: 64  batch: 65  loss: 0.05958653\n",
      "epoch: 64  batch: 66  loss: 0.04298571\n",
      "epoch: 64  batch: 67  loss: 0.08147493\n",
      "epoch: 64  batch: 68  loss: 0.07730479\n",
      "epoch: 64  batch: 69  loss: 0.06134143\n",
      "epoch: 64  batch: 70  loss: 0.05956453\n",
      "epoch: 64  batch: 71  loss: 0.07700880\n",
      "epoch: 64  batch: 72  loss: 0.07902549\n",
      "epoch: 64  batch: 73  loss: 0.11317959\n",
      "epoch: 64  batch: 74  loss: 0.11573435\n",
      "epoch: 64  batch: 75  loss: 0.06795981\n",
      "epoch: 64  batch: 76  loss: 0.06224302\n",
      "epoch: 64  batch: 77  loss: 0.08034088\n",
      "epoch: 64  batch: 78  loss: 0.14464080\n",
      "epoch: 64  batch: 79  loss: 0.11083233\n",
      "epoch: 64  batch: 80  loss: 0.10119533\n",
      "epoch: 64  batch: 81  loss: 0.07087234\n",
      "epoch: 64  batch: 82  loss: 0.13134523\n",
      "epoch: 64  batch: 83  loss: 0.08815499\n",
      "epoch: 64  batch: 84  loss: 0.07362359\n",
      "epoch: 64  batch: 85  loss: 0.07517885\n",
      "epoch: 64  batch: 86  loss: 0.06796230\n",
      "epoch: 64  batch: 87  loss: 0.08554718\n",
      "epoch: 65  batch: 1  loss: 0.09230556\n",
      "epoch: 65  batch: 2  loss: 0.07110101\n",
      "epoch: 65  batch: 3  loss: 0.11918965\n",
      "epoch: 65  batch: 4  loss: 0.07232682\n",
      "epoch: 65  batch: 5  loss: 0.07671171\n",
      "epoch: 65  batch: 6  loss: 0.06465599\n",
      "epoch: 65  batch: 7  loss: 0.11098030\n",
      "epoch: 65  batch: 8  loss: 0.06759230\n",
      "epoch: 65  batch: 9  loss: 0.09059468\n",
      "epoch: 65  batch: 10  loss: 0.08566213\n",
      "epoch: 65  batch: 11  loss: 0.07692930\n",
      "epoch: 65  batch: 12  loss: 0.07104353\n",
      "epoch: 65  batch: 13  loss: 0.10689675\n",
      "epoch: 65  batch: 14  loss: 0.05114749\n",
      "epoch: 65  batch: 15  loss: 0.06626116\n",
      "epoch: 65  batch: 16  loss: 0.07870898\n",
      "epoch: 65  batch: 17  loss: 0.07212459\n",
      "epoch: 65  batch: 18  loss: 0.05088964\n",
      "epoch: 65  batch: 19  loss: 0.07208172\n",
      "epoch: 65  batch: 20  loss: 0.08511933\n",
      "epoch: 65  batch: 21  loss: 0.05918866\n",
      "epoch: 65  batch: 22  loss: 0.09227475\n",
      "epoch: 65  batch: 23  loss: 0.06662787\n",
      "epoch: 65  batch: 24  loss: 0.05410273\n",
      "epoch: 65  batch: 25  loss: 0.06638603\n",
      "epoch: 65  batch: 26  loss: 0.08767005\n",
      "epoch: 65  batch: 27  loss: 0.06397793\n",
      "epoch: 65  batch: 28  loss: 0.07399978\n",
      "epoch: 65  batch: 29  loss: 0.07776621\n",
      "epoch: 65  batch: 30  loss: 0.10815644\n",
      "epoch: 65  batch: 31  loss: 0.12548117\n",
      "epoch: 65  batch: 32  loss: 0.09203169\n",
      "epoch: 65  batch: 33  loss: 0.09701297\n",
      "epoch: 65  batch: 34  loss: 0.07240411\n",
      "epoch: 65  batch: 35  loss: 0.10508694\n",
      "epoch: 65  batch: 36  loss: 0.06832866\n",
      "epoch: 65  batch: 37  loss: 0.10341734\n",
      "epoch: 65  batch: 38  loss: 0.05950191\n",
      "epoch: 65  batch: 39  loss: 0.07097176\n",
      "epoch: 65  batch: 40  loss: 0.07493204\n",
      "epoch: 65  batch: 41  loss: 0.12343439\n",
      "epoch: 65  batch: 42  loss: 0.08279183\n",
      "epoch: 65  batch: 43  loss: 0.08267043\n",
      "epoch: 65  batch: 44  loss: 0.06286430\n",
      "epoch: 65  batch: 45  loss: 0.10812234\n",
      "epoch: 65  batch: 46  loss: 0.09471462\n",
      "epoch: 65  batch: 47  loss: 0.11760752\n",
      "epoch: 65  batch: 48  loss: 0.06000378\n",
      "epoch: 65  batch: 49  loss: 0.11330382\n",
      "epoch: 65  batch: 50  loss: 0.05624691\n",
      "epoch: 65  batch: 51  loss: 0.08281739\n",
      "epoch: 65  batch: 52  loss: 0.11891289\n",
      "epoch: 65  batch: 53  loss: 0.06781526\n",
      "epoch: 65  batch: 54  loss: 0.06905952\n",
      "epoch: 65  batch: 55  loss: 0.07830410\n",
      "epoch: 65  batch: 56  loss: 0.10218943\n",
      "epoch: 65  batch: 57  loss: 0.10151494\n",
      "epoch: 65  batch: 58  loss: 0.08018403\n",
      "epoch: 65  batch: 59  loss: 0.08517253\n",
      "epoch: 65  batch: 60  loss: 0.06418455\n",
      "epoch: 65  batch: 61  loss: 0.08871105\n",
      "epoch: 65  batch: 62  loss: 0.11287190\n",
      "epoch: 65  batch: 63  loss: 0.08424413\n",
      "epoch: 65  batch: 64  loss: 0.08450100\n",
      "epoch: 65  batch: 65  loss: 0.06751728\n",
      "epoch: 65  batch: 66  loss: 0.06431398\n",
      "epoch: 65  batch: 67  loss: 0.08552393\n",
      "epoch: 65  batch: 68  loss: 0.05944881\n",
      "epoch: 65  batch: 69  loss: 0.09506905\n",
      "epoch: 65  batch: 70  loss: 0.06008280\n",
      "epoch: 65  batch: 71  loss: 0.09304225\n",
      "epoch: 65  batch: 72  loss: 0.09106487\n",
      "epoch: 65  batch: 73  loss: 0.06960143\n",
      "epoch: 65  batch: 74  loss: 0.10757916\n",
      "epoch: 65  batch: 75  loss: 0.08013920\n",
      "epoch: 65  batch: 76  loss: 0.07885928\n",
      "epoch: 65  batch: 77  loss: 0.06940911\n",
      "epoch: 65  batch: 78  loss: 0.11551546\n",
      "epoch: 65  batch: 79  loss: 0.06602850\n",
      "epoch: 65  batch: 80  loss: 0.06656566\n",
      "epoch: 65  batch: 81  loss: 0.06492160\n",
      "epoch: 65  batch: 82  loss: 0.10555985\n",
      "epoch: 65  batch: 83  loss: 0.09831431\n",
      "epoch: 65  batch: 84  loss: 0.12168574\n",
      "epoch: 65  batch: 85  loss: 0.08024174\n",
      "epoch: 65  batch: 86  loss: 0.12236932\n",
      "epoch: 65  batch: 87  loss: 0.16578421\n",
      "epoch: 66  batch: 1  loss: 0.05682164\n",
      "epoch: 66  batch: 2  loss: 0.07109254\n",
      "epoch: 66  batch: 3  loss: 0.07216946\n",
      "epoch: 66  batch: 4  loss: 0.09842037\n",
      "epoch: 66  batch: 5  loss: 0.08308058\n",
      "epoch: 66  batch: 6  loss: 0.08193824\n",
      "epoch: 66  batch: 7  loss: 0.06357602\n",
      "epoch: 66  batch: 8  loss: 0.09492853\n",
      "epoch: 66  batch: 9  loss: 0.09357381\n",
      "epoch: 66  batch: 10  loss: 0.09210253\n",
      "epoch: 66  batch: 11  loss: 0.06788030\n",
      "epoch: 66  batch: 12  loss: 0.06047424\n",
      "epoch: 66  batch: 13  loss: 0.06870541\n",
      "epoch: 66  batch: 14  loss: 0.07687723\n",
      "epoch: 66  batch: 15  loss: 0.08600849\n",
      "epoch: 66  batch: 16  loss: 0.05581068\n",
      "epoch: 66  batch: 17  loss: 0.07144842\n",
      "epoch: 66  batch: 18  loss: 0.08491347\n",
      "epoch: 66  batch: 19  loss: 0.06441446\n",
      "epoch: 66  batch: 20  loss: 0.09708545\n",
      "epoch: 66  batch: 21  loss: 0.06861173\n",
      "epoch: 66  batch: 22  loss: 0.10722153\n",
      "epoch: 66  batch: 23  loss: 0.09466755\n",
      "epoch: 66  batch: 24  loss: 0.07808343\n",
      "epoch: 66  batch: 25  loss: 0.09098967\n",
      "epoch: 66  batch: 26  loss: 0.11456445\n",
      "epoch: 66  batch: 27  loss: 0.08633855\n",
      "epoch: 66  batch: 28  loss: 0.09430768\n",
      "epoch: 66  batch: 29  loss: 0.08041956\n",
      "epoch: 66  batch: 30  loss: 0.06919534\n",
      "epoch: 66  batch: 31  loss: 0.14097783\n",
      "epoch: 66  batch: 32  loss: 0.06811080\n",
      "epoch: 66  batch: 33  loss: 0.07416056\n",
      "epoch: 66  batch: 34  loss: 0.05664667\n",
      "epoch: 66  batch: 35  loss: 0.07823440\n",
      "epoch: 66  batch: 36  loss: 0.08011635\n",
      "epoch: 66  batch: 37  loss: 0.07682934\n",
      "epoch: 66  batch: 38  loss: 0.05583362\n",
      "epoch: 66  batch: 39  loss: 0.05983001\n",
      "epoch: 66  batch: 40  loss: 0.09022642\n",
      "epoch: 66  batch: 41  loss: 0.07754376\n",
      "epoch: 66  batch: 42  loss: 0.07530680\n",
      "epoch: 66  batch: 43  loss: 0.07598738\n",
      "epoch: 66  batch: 44  loss: 0.09368604\n",
      "epoch: 66  batch: 45  loss: 0.10623758\n",
      "epoch: 66  batch: 46  loss: 0.13257459\n",
      "epoch: 66  batch: 47  loss: 0.10841796\n",
      "epoch: 66  batch: 48  loss: 0.08966785\n",
      "epoch: 66  batch: 49  loss: 0.07954771\n",
      "epoch: 66  batch: 50  loss: 0.07588658\n",
      "epoch: 66  batch: 51  loss: 0.05857342\n",
      "epoch: 66  batch: 52  loss: 0.17680216\n",
      "epoch: 66  batch: 53  loss: 0.09976974\n",
      "epoch: 66  batch: 54  loss: 0.06505869\n",
      "epoch: 66  batch: 55  loss: 0.07833470\n",
      "epoch: 66  batch: 56  loss: 0.09611031\n",
      "epoch: 66  batch: 57  loss: 0.05615735\n",
      "epoch: 66  batch: 58  loss: 0.06877475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66  batch: 59  loss: 0.08968363\n",
      "epoch: 66  batch: 60  loss: 0.08785478\n",
      "epoch: 66  batch: 61  loss: 0.14945266\n",
      "epoch: 66  batch: 62  loss: 0.07565079\n",
      "epoch: 66  batch: 63  loss: 0.08156464\n",
      "epoch: 66  batch: 64  loss: 0.11983119\n",
      "epoch: 66  batch: 65  loss: 0.07844619\n",
      "epoch: 66  batch: 66  loss: 0.07164977\n",
      "epoch: 66  batch: 67  loss: 0.07344236\n",
      "epoch: 66  batch: 68  loss: 0.05711959\n",
      "epoch: 66  batch: 69  loss: 0.09876364\n",
      "epoch: 66  batch: 70  loss: 0.08534066\n",
      "epoch: 66  batch: 71  loss: 0.10880617\n",
      "epoch: 66  batch: 72  loss: 0.07122596\n",
      "epoch: 66  batch: 73  loss: 0.08927491\n",
      "epoch: 66  batch: 74  loss: 0.07401317\n",
      "epoch: 66  batch: 75  loss: 0.09499276\n",
      "epoch: 66  batch: 76  loss: 0.08108170\n",
      "epoch: 66  batch: 77  loss: 0.06322242\n",
      "epoch: 66  batch: 78  loss: 0.11020706\n",
      "epoch: 66  batch: 79  loss: 0.09212550\n",
      "epoch: 66  batch: 80  loss: 0.09585750\n",
      "epoch: 66  batch: 81  loss: 0.08742863\n",
      "epoch: 66  batch: 82  loss: 0.08364940\n",
      "epoch: 66  batch: 83  loss: 0.10926977\n",
      "epoch: 66  batch: 84  loss: 0.08035202\n",
      "epoch: 66  batch: 85  loss: 0.07654103\n",
      "epoch: 66  batch: 86  loss: 0.08244044\n",
      "epoch: 66  batch: 87  loss: 0.08988202\n",
      "epoch: 67  batch: 1  loss: 0.05825398\n",
      "epoch: 67  batch: 2  loss: 0.07386699\n",
      "epoch: 67  batch: 3  loss: 0.06467544\n",
      "epoch: 67  batch: 4  loss: 0.08026799\n",
      "epoch: 67  batch: 5  loss: 0.08143249\n",
      "epoch: 67  batch: 6  loss: 0.07322951\n",
      "epoch: 67  batch: 7  loss: 0.07061038\n",
      "epoch: 67  batch: 8  loss: 0.05856948\n",
      "epoch: 67  batch: 9  loss: 0.07436518\n",
      "epoch: 67  batch: 10  loss: 0.06826960\n",
      "epoch: 67  batch: 11  loss: 0.06809246\n",
      "epoch: 67  batch: 12  loss: 0.07949094\n",
      "epoch: 67  batch: 13  loss: 0.11914095\n",
      "epoch: 67  batch: 14  loss: 0.07922541\n",
      "epoch: 67  batch: 15  loss: 0.05697868\n",
      "epoch: 67  batch: 16  loss: 0.10797986\n",
      "epoch: 67  batch: 17  loss: 0.12990057\n",
      "epoch: 67  batch: 18  loss: 0.05695624\n",
      "epoch: 67  batch: 19  loss: 0.07755331\n",
      "epoch: 67  batch: 20  loss: 0.07314060\n",
      "epoch: 67  batch: 21  loss: 0.07290925\n",
      "epoch: 67  batch: 22  loss: 0.11228666\n",
      "epoch: 67  batch: 23  loss: 0.07172606\n",
      "epoch: 67  batch: 24  loss: 0.07003267\n",
      "epoch: 67  batch: 25  loss: 0.07516345\n",
      "epoch: 67  batch: 26  loss: 0.08088995\n",
      "epoch: 67  batch: 27  loss: 0.09195435\n",
      "epoch: 67  batch: 28  loss: 0.06902085\n",
      "epoch: 67  batch: 29  loss: 0.11680301\n",
      "epoch: 67  batch: 30  loss: 0.07282467\n",
      "epoch: 67  batch: 31  loss: 0.07545303\n",
      "epoch: 67  batch: 32  loss: 0.09369963\n",
      "epoch: 67  batch: 33  loss: 0.12110364\n",
      "epoch: 67  batch: 34  loss: 0.14008299\n",
      "epoch: 67  batch: 35  loss: 0.06707837\n",
      "epoch: 67  batch: 36  loss: 0.09071732\n",
      "epoch: 67  batch: 37  loss: 0.09628164\n",
      "epoch: 67  batch: 38  loss: 0.07920481\n",
      "epoch: 67  batch: 39  loss: 0.09318145\n",
      "epoch: 67  batch: 40  loss: 0.07846491\n",
      "epoch: 67  batch: 41  loss: 0.05770614\n",
      "epoch: 67  batch: 42  loss: 0.09863054\n",
      "epoch: 67  batch: 43  loss: 0.07128812\n",
      "epoch: 67  batch: 44  loss: 0.12632120\n",
      "epoch: 67  batch: 45  loss: 0.10781265\n",
      "epoch: 67  batch: 46  loss: 0.06343421\n",
      "epoch: 67  batch: 47  loss: 0.10128213\n",
      "epoch: 67  batch: 48  loss: 0.07879533\n",
      "epoch: 67  batch: 49  loss: 0.08006506\n",
      "epoch: 67  batch: 50  loss: 0.08917477\n",
      "epoch: 67  batch: 51  loss: 0.10238118\n",
      "epoch: 67  batch: 52  loss: 0.11226185\n",
      "epoch: 67  batch: 53  loss: 0.07066791\n",
      "epoch: 67  batch: 54  loss: 0.11222061\n",
      "epoch: 67  batch: 55  loss: 0.06514157\n",
      "epoch: 67  batch: 56  loss: 0.05704758\n",
      "epoch: 67  batch: 57  loss: 0.05785186\n",
      "epoch: 67  batch: 58  loss: 0.12275989\n",
      "epoch: 67  batch: 59  loss: 0.07566268\n",
      "epoch: 67  batch: 60  loss: 0.06033170\n",
      "epoch: 67  batch: 61  loss: 0.10486136\n",
      "epoch: 67  batch: 62  loss: 0.05978305\n",
      "epoch: 67  batch: 63  loss: 0.13531490\n",
      "epoch: 67  batch: 64  loss: 0.07965671\n",
      "epoch: 67  batch: 65  loss: 0.08616314\n",
      "epoch: 67  batch: 66  loss: 0.11944519\n",
      "epoch: 67  batch: 67  loss: 0.06484727\n",
      "epoch: 67  batch: 68  loss: 0.08650362\n",
      "epoch: 67  batch: 69  loss: 0.06183264\n",
      "epoch: 67  batch: 70  loss: 0.12009732\n",
      "epoch: 67  batch: 71  loss: 0.07899182\n",
      "epoch: 67  batch: 72  loss: 0.08986342\n",
      "epoch: 67  batch: 73  loss: 0.06215382\n",
      "epoch: 67  batch: 74  loss: 0.06997703\n",
      "epoch: 67  batch: 75  loss: 0.05246580\n",
      "epoch: 67  batch: 76  loss: 0.08650138\n",
      "epoch: 67  batch: 77  loss: 0.07859294\n",
      "epoch: 67  batch: 78  loss: 0.08119835\n",
      "epoch: 67  batch: 79  loss: 0.06578000\n",
      "epoch: 67  batch: 80  loss: 0.09021831\n",
      "epoch: 67  batch: 81  loss: 0.05365672\n",
      "epoch: 67  batch: 82  loss: 0.07352518\n",
      "epoch: 67  batch: 83  loss: 0.05769220\n",
      "epoch: 67  batch: 84  loss: 0.05810786\n",
      "epoch: 67  batch: 85  loss: 0.09488742\n",
      "epoch: 67  batch: 86  loss: 0.09501567\n",
      "epoch: 67  batch: 87  loss: 0.07817142\n",
      "epoch: 68  batch: 1  loss: 0.10819763\n",
      "epoch: 68  batch: 2  loss: 0.04988993\n",
      "epoch: 68  batch: 3  loss: 0.08219819\n",
      "epoch: 68  batch: 4  loss: 0.08050314\n",
      "epoch: 68  batch: 5  loss: 0.10605873\n",
      "epoch: 68  batch: 6  loss: 0.08963434\n",
      "epoch: 68  batch: 7  loss: 0.06400629\n",
      "epoch: 68  batch: 8  loss: 0.12151400\n",
      "epoch: 68  batch: 9  loss: 0.09032897\n",
      "epoch: 68  batch: 10  loss: 0.14523320\n",
      "epoch: 68  batch: 11  loss: 0.11677063\n",
      "epoch: 68  batch: 12  loss: 0.06594789\n",
      "epoch: 68  batch: 13  loss: 0.07022373\n",
      "epoch: 68  batch: 14  loss: 0.08410587\n",
      "epoch: 68  batch: 15  loss: 0.07219253\n",
      "epoch: 68  batch: 16  loss: 0.12609486\n",
      "epoch: 68  batch: 17  loss: 0.08109139\n",
      "epoch: 68  batch: 18  loss: 0.11264218\n",
      "epoch: 68  batch: 19  loss: 0.06478071\n",
      "epoch: 68  batch: 20  loss: 0.09430156\n",
      "epoch: 68  batch: 21  loss: 0.05083263\n",
      "epoch: 68  batch: 22  loss: 0.12205924\n",
      "epoch: 68  batch: 23  loss: 0.04616016\n",
      "epoch: 68  batch: 24  loss: 0.07304703\n",
      "epoch: 68  batch: 25  loss: 0.09040883\n",
      "epoch: 68  batch: 26  loss: 0.10640736\n",
      "epoch: 68  batch: 27  loss: 0.13424292\n",
      "epoch: 68  batch: 28  loss: 0.09745456\n",
      "epoch: 68  batch: 29  loss: 0.16134062\n",
      "epoch: 68  batch: 30  loss: 0.10851540\n",
      "epoch: 68  batch: 31  loss: 0.09661945\n",
      "epoch: 68  batch: 32  loss: 0.06716701\n",
      "epoch: 68  batch: 33  loss: 0.07073185\n",
      "epoch: 68  batch: 34  loss: 0.07879733\n",
      "epoch: 68  batch: 35  loss: 0.04467222\n",
      "epoch: 68  batch: 36  loss: 0.07766467\n",
      "epoch: 68  batch: 37  loss: 0.12658267\n",
      "epoch: 68  batch: 38  loss: 0.09165888\n",
      "epoch: 68  batch: 39  loss: 0.08259893\n",
      "epoch: 68  batch: 40  loss: 0.07625620\n",
      "epoch: 68  batch: 41  loss: 0.07171382\n",
      "epoch: 68  batch: 42  loss: 0.14510286\n",
      "epoch: 68  batch: 43  loss: 0.07653710\n",
      "epoch: 68  batch: 44  loss: 0.06617367\n",
      "epoch: 68  batch: 45  loss: 0.06972526\n",
      "epoch: 68  batch: 46  loss: 0.05706777\n",
      "epoch: 68  batch: 47  loss: 0.08154216\n",
      "epoch: 68  batch: 48  loss: 0.08241846\n",
      "epoch: 68  batch: 49  loss: 0.08849859\n",
      "epoch: 68  batch: 50  loss: 0.10494143\n",
      "epoch: 68  batch: 51  loss: 0.07868872\n",
      "epoch: 68  batch: 52  loss: 0.07609859\n",
      "epoch: 68  batch: 53  loss: 0.10301442\n",
      "epoch: 68  batch: 54  loss: 0.10083370\n",
      "epoch: 68  batch: 55  loss: 0.08554979\n",
      "epoch: 68  batch: 56  loss: 0.11292101\n",
      "epoch: 68  batch: 57  loss: 0.07533228\n",
      "epoch: 68  batch: 58  loss: 0.09509794\n",
      "epoch: 68  batch: 59  loss: 0.07340213\n",
      "epoch: 68  batch: 60  loss: 0.08001374\n",
      "epoch: 68  batch: 61  loss: 0.07782608\n",
      "epoch: 68  batch: 62  loss: 0.09466221\n",
      "epoch: 68  batch: 63  loss: 0.07478120\n",
      "epoch: 68  batch: 64  loss: 0.08364687\n",
      "epoch: 68  batch: 65  loss: 0.12155876\n",
      "epoch: 68  batch: 66  loss: 0.07282622\n",
      "epoch: 68  batch: 67  loss: 0.10208099\n",
      "epoch: 68  batch: 68  loss: 0.08332013\n",
      "epoch: 68  batch: 69  loss: 0.07084575\n",
      "epoch: 68  batch: 70  loss: 0.07688718\n",
      "epoch: 68  batch: 71  loss: 0.08966936\n",
      "epoch: 68  batch: 72  loss: 0.09726739\n",
      "epoch: 68  batch: 73  loss: 0.07401064\n",
      "epoch: 68  batch: 74  loss: 0.09079479\n",
      "epoch: 68  batch: 75  loss: 0.06967965\n",
      "epoch: 68  batch: 76  loss: 0.06246563\n",
      "epoch: 68  batch: 77  loss: 0.09676244\n",
      "epoch: 68  batch: 78  loss: 0.05576988\n",
      "epoch: 68  batch: 79  loss: 0.05954692\n",
      "epoch: 68  batch: 80  loss: 0.09508431\n",
      "epoch: 68  batch: 81  loss: 0.05979146\n",
      "epoch: 68  batch: 82  loss: 0.08425380\n",
      "epoch: 68  batch: 83  loss: 0.06715778\n",
      "epoch: 68  batch: 84  loss: 0.08037597\n",
      "epoch: 68  batch: 85  loss: 0.10841187\n",
      "epoch: 68  batch: 86  loss: 0.06874131\n",
      "epoch: 68  batch: 87  loss: 0.06418733\n",
      "epoch: 69  batch: 1  loss: 0.06590843\n",
      "epoch: 69  batch: 2  loss: 0.07761291\n",
      "epoch: 69  batch: 3  loss: 0.07753304\n",
      "epoch: 69  batch: 4  loss: 0.05314449\n",
      "epoch: 69  batch: 5  loss: 0.10092290\n",
      "epoch: 69  batch: 6  loss: 0.06031489\n",
      "epoch: 69  batch: 7  loss: 0.08360391\n",
      "epoch: 69  batch: 8  loss: 0.08321884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69  batch: 9  loss: 0.09830634\n",
      "epoch: 69  batch: 10  loss: 0.05393367\n",
      "epoch: 69  batch: 11  loss: 0.09082820\n",
      "epoch: 69  batch: 12  loss: 0.10515527\n",
      "epoch: 69  batch: 13  loss: 0.07037519\n",
      "epoch: 69  batch: 14  loss: 0.11464547\n",
      "epoch: 69  batch: 15  loss: 0.07773196\n",
      "epoch: 69  batch: 16  loss: 0.07006790\n",
      "epoch: 69  batch: 17  loss: 0.07338644\n",
      "epoch: 69  batch: 18  loss: 0.07068131\n",
      "epoch: 69  batch: 19  loss: 0.10274088\n",
      "epoch: 69  batch: 20  loss: 0.07385810\n",
      "epoch: 69  batch: 21  loss: 0.10827193\n",
      "epoch: 69  batch: 22  loss: 0.08212060\n",
      "epoch: 69  batch: 23  loss: 0.10119101\n",
      "epoch: 69  batch: 24  loss: 0.11813487\n",
      "epoch: 69  batch: 25  loss: 0.07708119\n",
      "epoch: 69  batch: 26  loss: 0.08232057\n",
      "epoch: 69  batch: 27  loss: 0.11844217\n",
      "epoch: 69  batch: 28  loss: 0.07660248\n",
      "epoch: 69  batch: 29  loss: 0.08646028\n",
      "epoch: 69  batch: 30  loss: 0.12772952\n",
      "epoch: 69  batch: 31  loss: 0.10521962\n",
      "epoch: 69  batch: 32  loss: 0.14383917\n",
      "epoch: 69  batch: 33  loss: 0.07871117\n",
      "epoch: 69  batch: 34  loss: 0.13945645\n",
      "epoch: 69  batch: 35  loss: 0.07802946\n",
      "epoch: 69  batch: 36  loss: 0.09170932\n",
      "epoch: 69  batch: 37  loss: 0.09332087\n",
      "epoch: 69  batch: 38  loss: 0.07560798\n",
      "epoch: 69  batch: 39  loss: 0.11295086\n",
      "epoch: 69  batch: 40  loss: 0.09782225\n",
      "epoch: 69  batch: 41  loss: 0.04975130\n",
      "epoch: 69  batch: 42  loss: 0.05770400\n",
      "epoch: 69  batch: 43  loss: 0.06420413\n",
      "epoch: 69  batch: 44  loss: 0.08243490\n",
      "epoch: 69  batch: 45  loss: 0.11549193\n",
      "epoch: 69  batch: 46  loss: 0.07229152\n",
      "epoch: 69  batch: 47  loss: 0.08800750\n",
      "epoch: 69  batch: 48  loss: 0.06026125\n",
      "epoch: 69  batch: 49  loss: 0.08754436\n",
      "epoch: 69  batch: 50  loss: 0.06899798\n",
      "epoch: 69  batch: 51  loss: 0.08551235\n",
      "epoch: 69  batch: 52  loss: 0.06543680\n",
      "epoch: 69  batch: 53  loss: 0.07084584\n",
      "epoch: 69  batch: 54  loss: 0.07769480\n",
      "epoch: 69  batch: 55  loss: 0.06530973\n",
      "epoch: 69  batch: 56  loss: 0.09782628\n",
      "epoch: 69  batch: 57  loss: 0.07975047\n",
      "epoch: 69  batch: 58  loss: 0.07146783\n",
      "epoch: 69  batch: 59  loss: 0.07776707\n",
      "epoch: 69  batch: 60  loss: 0.09095091\n",
      "epoch: 69  batch: 61  loss: 0.06112938\n",
      "epoch: 69  batch: 62  loss: 0.06883162\n",
      "epoch: 69  batch: 63  loss: 0.08156264\n",
      "epoch: 69  batch: 64  loss: 0.08376883\n",
      "epoch: 69  batch: 65  loss: 0.07266191\n",
      "epoch: 69  batch: 66  loss: 0.08023640\n",
      "epoch: 69  batch: 67  loss: 0.10699399\n",
      "epoch: 69  batch: 68  loss: 0.07639171\n",
      "epoch: 69  batch: 69  loss: 0.12628421\n",
      "epoch: 69  batch: 70  loss: 0.10501653\n",
      "epoch: 69  batch: 71  loss: 0.08820879\n",
      "epoch: 69  batch: 72  loss: 0.07827409\n",
      "epoch: 69  batch: 73  loss: 0.06828862\n",
      "epoch: 69  batch: 74  loss: 0.14133509\n",
      "epoch: 69  batch: 75  loss: 0.05819097\n",
      "epoch: 69  batch: 76  loss: 0.06937050\n",
      "epoch: 69  batch: 77  loss: 0.10122691\n",
      "epoch: 69  batch: 78  loss: 0.07722434\n",
      "epoch: 69  batch: 79  loss: 0.06874011\n",
      "epoch: 69  batch: 80  loss: 0.10549748\n",
      "epoch: 69  batch: 81  loss: 0.05896542\n",
      "epoch: 69  batch: 82  loss: 0.11586838\n",
      "epoch: 69  batch: 83  loss: 0.06125535\n",
      "epoch: 69  batch: 84  loss: 0.07910135\n",
      "epoch: 69  batch: 85  loss: 0.07333722\n",
      "epoch: 69  batch: 86  loss: 0.08843432\n",
      "epoch: 69  batch: 87  loss: 0.06610461\n",
      "epoch: 70  batch: 1  loss: 0.07544251\n",
      "epoch: 70  batch: 2  loss: 0.08481725\n",
      "epoch: 70  batch: 3  loss: 0.05685445\n",
      "epoch: 70  batch: 4  loss: 0.07215442\n",
      "epoch: 70  batch: 5  loss: 0.06511327\n",
      "epoch: 70  batch: 6  loss: 0.07267749\n",
      "epoch: 70  batch: 7  loss: 0.07048655\n",
      "epoch: 70  batch: 8  loss: 0.10149754\n",
      "epoch: 70  batch: 9  loss: 0.13279058\n",
      "epoch: 70  batch: 10  loss: 0.09636343\n",
      "epoch: 70  batch: 11  loss: 0.08446816\n",
      "epoch: 70  batch: 12  loss: 0.07865112\n",
      "epoch: 70  batch: 13  loss: 0.07980958\n",
      "epoch: 70  batch: 14  loss: 0.06724290\n",
      "epoch: 70  batch: 15  loss: 0.08768903\n",
      "epoch: 70  batch: 16  loss: 0.12959240\n",
      "epoch: 70  batch: 17  loss: 0.06880838\n",
      "epoch: 70  batch: 18  loss: 0.06974225\n",
      "epoch: 70  batch: 19  loss: 0.08414954\n",
      "epoch: 70  batch: 20  loss: 0.05874035\n",
      "epoch: 70  batch: 21  loss: 0.09809561\n",
      "epoch: 70  batch: 22  loss: 0.06040908\n",
      "epoch: 70  batch: 23  loss: 0.05622149\n",
      "epoch: 70  batch: 24  loss: 0.06551640\n",
      "epoch: 70  batch: 25  loss: 0.07457514\n",
      "epoch: 70  batch: 26  loss: 0.05792323\n",
      "epoch: 70  batch: 27  loss: 0.08206251\n",
      "epoch: 70  batch: 28  loss: 0.10042512\n",
      "epoch: 70  batch: 29  loss: 0.08172987\n",
      "epoch: 70  batch: 30  loss: 0.10880128\n",
      "epoch: 70  batch: 31  loss: 0.06588406\n",
      "epoch: 70  batch: 32  loss: 0.06246675\n",
      "epoch: 70  batch: 33  loss: 0.09667718\n",
      "epoch: 70  batch: 34  loss: 0.06363612\n",
      "epoch: 70  batch: 35  loss: 0.08377820\n",
      "epoch: 70  batch: 36  loss: 0.07099419\n",
      "epoch: 70  batch: 37  loss: 0.07827408\n",
      "epoch: 70  batch: 38  loss: 0.08235129\n",
      "epoch: 70  batch: 39  loss: 0.11653560\n",
      "epoch: 70  batch: 40  loss: 0.06797248\n",
      "epoch: 70  batch: 41  loss: 0.09745496\n",
      "epoch: 70  batch: 42  loss: 0.08502811\n",
      "epoch: 70  batch: 43  loss: 0.07548852\n",
      "epoch: 70  batch: 44  loss: 0.05060029\n",
      "epoch: 70  batch: 45  loss: 0.07103900\n",
      "epoch: 70  batch: 46  loss: 0.08359621\n",
      "epoch: 70  batch: 47  loss: 0.09064540\n",
      "epoch: 70  batch: 48  loss: 0.05674465\n",
      "epoch: 70  batch: 49  loss: 0.07101067\n",
      "epoch: 70  batch: 50  loss: 0.10074817\n",
      "epoch: 70  batch: 51  loss: 0.09176727\n",
      "epoch: 70  batch: 52  loss: 0.08293909\n",
      "epoch: 70  batch: 53  loss: 0.08635564\n",
      "epoch: 70  batch: 54  loss: 0.07329467\n",
      "epoch: 70  batch: 55  loss: 0.08301133\n",
      "epoch: 70  batch: 56  loss: 0.09691864\n",
      "epoch: 70  batch: 57  loss: 0.08435169\n",
      "epoch: 70  batch: 58  loss: 0.09402820\n",
      "epoch: 70  batch: 59  loss: 0.06554739\n",
      "epoch: 70  batch: 60  loss: 0.10934277\n",
      "epoch: 70  batch: 61  loss: 0.09300337\n",
      "epoch: 70  batch: 62  loss: 0.08412023\n",
      "epoch: 70  batch: 63  loss: 0.08709200\n",
      "epoch: 70  batch: 64  loss: 0.06463843\n",
      "epoch: 70  batch: 65  loss: 0.06678012\n",
      "epoch: 70  batch: 66  loss: 0.06486202\n",
      "epoch: 70  batch: 67  loss: 0.06185813\n",
      "epoch: 70  batch: 68  loss: 0.07668939\n",
      "epoch: 70  batch: 69  loss: 0.06822661\n",
      "epoch: 70  batch: 70  loss: 0.07335421\n",
      "epoch: 70  batch: 71  loss: 0.08042544\n",
      "epoch: 70  batch: 72  loss: 0.08731898\n",
      "epoch: 70  batch: 73  loss: 0.14692290\n",
      "epoch: 70  batch: 74  loss: 0.06524377\n",
      "epoch: 70  batch: 75  loss: 0.09224910\n",
      "epoch: 70  batch: 76  loss: 0.09449428\n",
      "epoch: 70  batch: 77  loss: 0.09950189\n",
      "epoch: 70  batch: 78  loss: 0.09193691\n",
      "epoch: 70  batch: 79  loss: 0.10354639\n",
      "epoch: 70  batch: 80  loss: 0.08292008\n",
      "epoch: 70  batch: 81  loss: 0.05958620\n",
      "epoch: 70  batch: 82  loss: 0.10166070\n",
      "epoch: 70  batch: 83  loss: 0.09792300\n",
      "epoch: 70  batch: 84  loss: 0.07900260\n",
      "epoch: 70  batch: 85  loss: 0.11075456\n",
      "epoch: 70  batch: 86  loss: 0.10815518\n",
      "epoch: 70  batch: 87  loss: 0.10264553\n",
      "epoch: 71  batch: 1  loss: 0.05514422\n",
      "epoch: 71  batch: 2  loss: 0.06322593\n",
      "epoch: 71  batch: 3  loss: 0.05147082\n",
      "epoch: 71  batch: 4  loss: 0.06432432\n",
      "epoch: 71  batch: 5  loss: 0.09089771\n",
      "epoch: 71  batch: 6  loss: 0.07064470\n",
      "epoch: 71  batch: 7  loss: 0.07676776\n",
      "epoch: 71  batch: 8  loss: 0.13976403\n",
      "epoch: 71  batch: 9  loss: 0.08311600\n",
      "epoch: 71  batch: 10  loss: 0.08024414\n",
      "epoch: 71  batch: 11  loss: 0.07639361\n",
      "epoch: 71  batch: 12  loss: 0.10027242\n",
      "epoch: 71  batch: 13  loss: 0.14486815\n",
      "epoch: 71  batch: 14  loss: 0.07766929\n",
      "epoch: 71  batch: 15  loss: 0.11324753\n",
      "epoch: 71  batch: 16  loss: 0.08807052\n",
      "epoch: 71  batch: 17  loss: 0.13148801\n",
      "epoch: 71  batch: 18  loss: 0.08738480\n",
      "epoch: 71  batch: 19  loss: 0.09918518\n",
      "epoch: 71  batch: 20  loss: 0.07619942\n",
      "epoch: 71  batch: 21  loss: 0.08611777\n",
      "epoch: 71  batch: 22  loss: 0.08628932\n",
      "epoch: 71  batch: 23  loss: 0.11389685\n",
      "epoch: 71  batch: 24  loss: 0.09493609\n",
      "epoch: 71  batch: 25  loss: 0.07925314\n",
      "epoch: 71  batch: 26  loss: 0.06268421\n",
      "epoch: 71  batch: 27  loss: 0.07546466\n",
      "epoch: 71  batch: 28  loss: 0.06926509\n",
      "epoch: 71  batch: 29  loss: 0.07985354\n",
      "epoch: 71  batch: 30  loss: 0.08085974\n",
      "epoch: 71  batch: 31  loss: 0.06208919\n",
      "epoch: 71  batch: 32  loss: 0.06519795\n",
      "epoch: 71  batch: 33  loss: 0.09760892\n",
      "epoch: 71  batch: 34  loss: 0.06888033\n",
      "epoch: 71  batch: 35  loss: 0.06429093\n",
      "epoch: 71  batch: 36  loss: 0.05524780\n",
      "epoch: 71  batch: 37  loss: 0.06302699\n",
      "epoch: 71  batch: 38  loss: 0.05663157\n",
      "epoch: 71  batch: 39  loss: 0.07688525\n",
      "epoch: 71  batch: 40  loss: 0.08089055\n",
      "epoch: 71  batch: 41  loss: 0.07759993\n",
      "epoch: 71  batch: 42  loss: 0.07545266\n",
      "epoch: 71  batch: 43  loss: 0.08374685\n",
      "epoch: 71  batch: 44  loss: 0.10046177\n",
      "epoch: 71  batch: 45  loss: 0.13168916\n",
      "epoch: 71  batch: 46  loss: 0.09317055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 71  batch: 47  loss: 0.16692430\n",
      "epoch: 71  batch: 48  loss: 0.08937969\n",
      "epoch: 71  batch: 49  loss: 0.06127343\n",
      "epoch: 71  batch: 50  loss: 0.11679760\n",
      "epoch: 71  batch: 51  loss: 0.05820940\n",
      "epoch: 71  batch: 52  loss: 0.09646578\n",
      "epoch: 71  batch: 53  loss: 0.08864415\n",
      "epoch: 71  batch: 54  loss: 0.11276005\n",
      "epoch: 71  batch: 55  loss: 0.09440949\n",
      "epoch: 71  batch: 56  loss: 0.09642646\n",
      "epoch: 71  batch: 57  loss: 0.06725334\n",
      "epoch: 71  batch: 58  loss: 0.07875369\n",
      "epoch: 71  batch: 59  loss: 0.07560570\n",
      "epoch: 71  batch: 60  loss: 0.06287480\n",
      "epoch: 71  batch: 61  loss: 0.14022607\n",
      "epoch: 71  batch: 62  loss: 0.06959889\n",
      "epoch: 71  batch: 63  loss: 0.10110316\n",
      "epoch: 71  batch: 64  loss: 0.07164003\n",
      "epoch: 71  batch: 65  loss: 0.07113085\n",
      "epoch: 71  batch: 66  loss: 0.06912266\n",
      "epoch: 71  batch: 67  loss: 0.09006255\n",
      "epoch: 71  batch: 68  loss: 0.08890042\n",
      "epoch: 71  batch: 69  loss: 0.07548429\n",
      "epoch: 71  batch: 70  loss: 0.07676698\n",
      "epoch: 71  batch: 71  loss: 0.12894040\n",
      "epoch: 71  batch: 72  loss: 0.08228005\n",
      "epoch: 71  batch: 73  loss: 0.07488122\n",
      "epoch: 71  batch: 74  loss: 0.08670766\n",
      "epoch: 71  batch: 75  loss: 0.07523567\n",
      "epoch: 71  batch: 76  loss: 0.06690531\n",
      "epoch: 71  batch: 77  loss: 0.06143116\n",
      "epoch: 71  batch: 78  loss: 0.05176498\n",
      "epoch: 71  batch: 79  loss: 0.08914321\n",
      "epoch: 71  batch: 80  loss: 0.07199425\n",
      "epoch: 71  batch: 81  loss: 0.11687851\n",
      "epoch: 71  batch: 82  loss: 0.11863904\n",
      "epoch: 71  batch: 83  loss: 0.09739561\n",
      "epoch: 71  batch: 84  loss: 0.05729629\n",
      "epoch: 71  batch: 85  loss: 0.07707504\n",
      "epoch: 71  batch: 86  loss: 0.07863477\n",
      "epoch: 71  batch: 87  loss: 0.14476737\n",
      "epoch: 72  batch: 1  loss: 0.08413494\n",
      "epoch: 72  batch: 2  loss: 0.09378499\n",
      "epoch: 72  batch: 3  loss: 0.08920960\n",
      "epoch: 72  batch: 4  loss: 0.13442224\n",
      "epoch: 72  batch: 5  loss: 0.07718791\n",
      "epoch: 72  batch: 6  loss: 0.07246191\n",
      "epoch: 72  batch: 7  loss: 0.08118369\n",
      "epoch: 72  batch: 8  loss: 0.05675369\n",
      "epoch: 72  batch: 9  loss: 0.10226648\n",
      "epoch: 72  batch: 10  loss: 0.08251727\n",
      "epoch: 72  batch: 11  loss: 0.06120517\n",
      "epoch: 72  batch: 12  loss: 0.09416337\n",
      "epoch: 72  batch: 13  loss: 0.06413601\n",
      "epoch: 72  batch: 14  loss: 0.10390050\n",
      "epoch: 72  batch: 15  loss: 0.05032703\n",
      "epoch: 72  batch: 16  loss: 0.08787768\n",
      "epoch: 72  batch: 17  loss: 0.09008853\n",
      "epoch: 72  batch: 18  loss: 0.05974927\n",
      "epoch: 72  batch: 19  loss: 0.12056354\n",
      "epoch: 72  batch: 20  loss: 0.08407502\n",
      "epoch: 72  batch: 21  loss: 0.08526397\n",
      "epoch: 72  batch: 22  loss: 0.09281369\n",
      "epoch: 72  batch: 23  loss: 0.12412892\n",
      "epoch: 72  batch: 24  loss: 0.08323261\n",
      "epoch: 72  batch: 25  loss: 0.08215933\n",
      "epoch: 72  batch: 26  loss: 0.05748724\n",
      "epoch: 72  batch: 27  loss: 0.04213014\n",
      "epoch: 72  batch: 28  loss: 0.07663299\n",
      "epoch: 72  batch: 29  loss: 0.07465558\n",
      "epoch: 72  batch: 30  loss: 0.08951440\n",
      "epoch: 72  batch: 31  loss: 0.06186219\n",
      "epoch: 72  batch: 32  loss: 0.10134106\n",
      "epoch: 72  batch: 33  loss: 0.09112787\n",
      "epoch: 72  batch: 34  loss: 0.08877734\n",
      "epoch: 72  batch: 35  loss: 0.07007682\n",
      "epoch: 72  batch: 36  loss: 0.08183321\n",
      "epoch: 72  batch: 37  loss: 0.05892711\n",
      "epoch: 72  batch: 38  loss: 0.05823890\n",
      "epoch: 72  batch: 39  loss: 0.08524801\n",
      "epoch: 72  batch: 40  loss: 0.07756446\n",
      "epoch: 72  batch: 41  loss: 0.07464542\n",
      "epoch: 72  batch: 42  loss: 0.10449760\n",
      "epoch: 72  batch: 43  loss: 0.09038274\n",
      "epoch: 72  batch: 44  loss: 0.07557887\n",
      "epoch: 72  batch: 45  loss: 0.08175429\n",
      "epoch: 72  batch: 46  loss: 0.06431487\n",
      "epoch: 72  batch: 47  loss: 0.09125314\n",
      "epoch: 72  batch: 48  loss: 0.08782036\n",
      "epoch: 72  batch: 49  loss: 0.06487075\n",
      "epoch: 72  batch: 50  loss: 0.09593184\n",
      "epoch: 72  batch: 51  loss: 0.07466443\n",
      "epoch: 72  batch: 52  loss: 0.06926896\n",
      "epoch: 72  batch: 53  loss: 0.06974522\n",
      "epoch: 72  batch: 54  loss: 0.08214269\n",
      "epoch: 72  batch: 55  loss: 0.08076533\n",
      "epoch: 72  batch: 56  loss: 0.13716489\n",
      "epoch: 72  batch: 57  loss: 0.08228261\n",
      "epoch: 72  batch: 58  loss: 0.08367988\n",
      "epoch: 72  batch: 59  loss: 0.07841939\n",
      "epoch: 72  batch: 60  loss: 0.12716746\n",
      "epoch: 72  batch: 61  loss: 0.08991101\n",
      "epoch: 72  batch: 62  loss: 0.07947965\n",
      "epoch: 72  batch: 63  loss: 0.06569324\n",
      "epoch: 72  batch: 64  loss: 0.09341627\n",
      "epoch: 72  batch: 65  loss: 0.06497867\n",
      "epoch: 72  batch: 66  loss: 0.07795330\n",
      "epoch: 72  batch: 67  loss: 0.08041865\n",
      "epoch: 72  batch: 68  loss: 0.06390588\n",
      "epoch: 72  batch: 69  loss: 0.08294719\n",
      "epoch: 72  batch: 70  loss: 0.05984730\n",
      "epoch: 72  batch: 71  loss: 0.07307369\n",
      "epoch: 72  batch: 72  loss: 0.09788216\n",
      "epoch: 72  batch: 73  loss: 0.12407999\n",
      "epoch: 72  batch: 74  loss: 0.09334362\n",
      "epoch: 72  batch: 75  loss: 0.07104410\n",
      "epoch: 72  batch: 76  loss: 0.07498683\n",
      "epoch: 72  batch: 77  loss: 0.14126921\n",
      "epoch: 72  batch: 78  loss: 0.08110530\n",
      "epoch: 72  batch: 79  loss: 0.07349252\n",
      "epoch: 72  batch: 80  loss: 0.08617076\n",
      "epoch: 72  batch: 81  loss: 0.07604221\n",
      "epoch: 72  batch: 82  loss: 0.08755843\n",
      "epoch: 72  batch: 83  loss: 0.06936196\n",
      "epoch: 72  batch: 84  loss: 0.07780542\n",
      "epoch: 72  batch: 85  loss: 0.07487921\n",
      "epoch: 72  batch: 86  loss: 0.10395063\n",
      "epoch: 72  batch: 87  loss: 0.11029730\n",
      "epoch: 73  batch: 1  loss: 0.08416196\n",
      "epoch: 73  batch: 2  loss: 0.08328176\n",
      "epoch: 73  batch: 3  loss: 0.06260090\n",
      "epoch: 73  batch: 4  loss: 0.05183715\n",
      "epoch: 73  batch: 5  loss: 0.08312180\n",
      "epoch: 73  batch: 6  loss: 0.07497894\n",
      "epoch: 73  batch: 7  loss: 0.05581120\n",
      "epoch: 73  batch: 8  loss: 0.07708050\n",
      "epoch: 73  batch: 9  loss: 0.08857790\n",
      "epoch: 73  batch: 10  loss: 0.05878877\n",
      "epoch: 73  batch: 11  loss: 0.06003160\n",
      "epoch: 73  batch: 12  loss: 0.11393915\n",
      "epoch: 73  batch: 13  loss: 0.06268705\n",
      "epoch: 73  batch: 14  loss: 0.13617209\n",
      "epoch: 73  batch: 15  loss: 0.09257671\n",
      "epoch: 73  batch: 16  loss: 0.07690852\n",
      "epoch: 73  batch: 17  loss: 0.06830777\n",
      "epoch: 73  batch: 18  loss: 0.09546421\n",
      "epoch: 73  batch: 19  loss: 0.07721294\n",
      "epoch: 73  batch: 20  loss: 0.09638502\n",
      "epoch: 73  batch: 21  loss: 0.07850455\n",
      "epoch: 73  batch: 22  loss: 0.13688660\n",
      "epoch: 73  batch: 23  loss: 0.09913222\n",
      "epoch: 73  batch: 24  loss: 0.05952248\n",
      "epoch: 73  batch: 25  loss: 0.06658413\n",
      "epoch: 73  batch: 26  loss: 0.06914416\n",
      "epoch: 73  batch: 27  loss: 0.09895533\n",
      "epoch: 73  batch: 28  loss: 0.07249931\n",
      "epoch: 73  batch: 29  loss: 0.07990862\n",
      "epoch: 73  batch: 30  loss: 0.12343312\n",
      "epoch: 73  batch: 31  loss: 0.05697639\n",
      "epoch: 73  batch: 32  loss: 0.07538215\n",
      "epoch: 73  batch: 33  loss: 0.08300555\n",
      "epoch: 73  batch: 34  loss: 0.07562466\n",
      "epoch: 73  batch: 35  loss: 0.11662906\n",
      "epoch: 73  batch: 36  loss: 0.09631423\n",
      "epoch: 73  batch: 37  loss: 0.09733739\n",
      "epoch: 73  batch: 38  loss: 0.07872514\n",
      "epoch: 73  batch: 39  loss: 0.07916799\n",
      "epoch: 73  batch: 40  loss: 0.07540244\n",
      "epoch: 73  batch: 41  loss: 0.08809333\n",
      "epoch: 73  batch: 42  loss: 0.06205663\n",
      "epoch: 73  batch: 43  loss: 0.06005435\n",
      "epoch: 73  batch: 44  loss: 0.08773666\n",
      "epoch: 73  batch: 45  loss: 0.06841382\n",
      "epoch: 73  batch: 46  loss: 0.08247920\n",
      "epoch: 73  batch: 47  loss: 0.04849674\n",
      "epoch: 73  batch: 48  loss: 0.06475481\n",
      "epoch: 73  batch: 49  loss: 0.08546062\n",
      "epoch: 73  batch: 50  loss: 0.07642905\n",
      "epoch: 73  batch: 51  loss: 0.12808600\n",
      "epoch: 73  batch: 52  loss: 0.06506240\n",
      "epoch: 73  batch: 53  loss: 0.05464523\n",
      "epoch: 73  batch: 54  loss: 0.05409127\n",
      "epoch: 73  batch: 55  loss: 0.07861592\n",
      "epoch: 73  batch: 56  loss: 0.08503595\n",
      "epoch: 73  batch: 57  loss: 0.09215666\n",
      "epoch: 73  batch: 58  loss: 0.08176193\n",
      "epoch: 73  batch: 59  loss: 0.09160778\n",
      "epoch: 73  batch: 60  loss: 0.06504939\n",
      "epoch: 73  batch: 61  loss: 0.09397686\n",
      "epoch: 73  batch: 62  loss: 0.10701972\n",
      "epoch: 73  batch: 63  loss: 0.10960497\n",
      "epoch: 73  batch: 64  loss: 0.11625670\n",
      "epoch: 73  batch: 65  loss: 0.05656346\n",
      "epoch: 73  batch: 66  loss: 0.08077428\n",
      "epoch: 73  batch: 67  loss: 0.11059801\n",
      "epoch: 73  batch: 68  loss: 0.08470214\n",
      "epoch: 73  batch: 69  loss: 0.06949089\n",
      "epoch: 73  batch: 70  loss: 0.09593453\n",
      "epoch: 73  batch: 71  loss: 0.06709239\n",
      "epoch: 73  batch: 72  loss: 0.09019077\n",
      "epoch: 73  batch: 73  loss: 0.13782375\n",
      "epoch: 73  batch: 74  loss: 0.07111416\n",
      "epoch: 73  batch: 75  loss: 0.09843070\n",
      "epoch: 73  batch: 76  loss: 0.07627013\n",
      "epoch: 73  batch: 77  loss: 0.07120215\n",
      "epoch: 73  batch: 78  loss: 0.07018945\n",
      "epoch: 73  batch: 79  loss: 0.08041258\n",
      "epoch: 73  batch: 80  loss: 0.09814309\n",
      "epoch: 73  batch: 81  loss: 0.07256740\n",
      "epoch: 73  batch: 82  loss: 0.11479454\n",
      "epoch: 73  batch: 83  loss: 0.12356753\n",
      "epoch: 73  batch: 84  loss: 0.06175995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 73  batch: 85  loss: 0.05589545\n",
      "epoch: 73  batch: 86  loss: 0.09323891\n",
      "epoch: 73  batch: 87  loss: 0.09081458\n",
      "epoch: 74  batch: 1  loss: 0.06011747\n",
      "epoch: 74  batch: 2  loss: 0.09124643\n",
      "epoch: 74  batch: 3  loss: 0.11756114\n",
      "epoch: 74  batch: 4  loss: 0.05542787\n",
      "epoch: 74  batch: 5  loss: 0.08677235\n",
      "epoch: 74  batch: 6  loss: 0.08445847\n",
      "epoch: 74  batch: 7  loss: 0.08248741\n",
      "epoch: 74  batch: 8  loss: 0.07098972\n",
      "epoch: 74  batch: 9  loss: 0.15156133\n",
      "epoch: 74  batch: 10  loss: 0.04226658\n",
      "epoch: 74  batch: 11  loss: 0.08658430\n",
      "epoch: 74  batch: 12  loss: 0.10037369\n",
      "epoch: 74  batch: 13  loss: 0.10909742\n",
      "epoch: 74  batch: 14  loss: 0.05896116\n",
      "epoch: 74  batch: 15  loss: 0.10541980\n",
      "epoch: 74  batch: 16  loss: 0.09784273\n",
      "epoch: 74  batch: 17  loss: 0.11009590\n",
      "epoch: 74  batch: 18  loss: 0.06898160\n",
      "epoch: 74  batch: 19  loss: 0.06691520\n",
      "epoch: 74  batch: 20  loss: 0.06852763\n",
      "epoch: 74  batch: 21  loss: 0.10783621\n",
      "epoch: 74  batch: 22  loss: 0.07569215\n",
      "epoch: 74  batch: 23  loss: 0.08062354\n",
      "epoch: 74  batch: 24  loss: 0.06752916\n",
      "epoch: 74  batch: 25  loss: 0.14825568\n",
      "epoch: 74  batch: 26  loss: 0.07023899\n",
      "epoch: 74  batch: 27  loss: 0.06710654\n",
      "epoch: 74  batch: 28  loss: 0.06432091\n",
      "epoch: 74  batch: 29  loss: 0.07131358\n",
      "epoch: 74  batch: 30  loss: 0.06275032\n",
      "epoch: 74  batch: 31  loss: 0.09759936\n",
      "epoch: 74  batch: 32  loss: 0.07497171\n",
      "epoch: 74  batch: 33  loss: 0.07075973\n",
      "epoch: 74  batch: 34  loss: 0.07313703\n",
      "epoch: 74  batch: 35  loss: 0.08694737\n",
      "epoch: 74  batch: 36  loss: 0.07308798\n",
      "epoch: 74  batch: 37  loss: 0.09435573\n",
      "epoch: 74  batch: 38  loss: 0.08332923\n",
      "epoch: 74  batch: 39  loss: 0.11334489\n",
      "epoch: 74  batch: 40  loss: 0.06577030\n",
      "epoch: 74  batch: 41  loss: 0.06801265\n",
      "epoch: 74  batch: 42  loss: 0.05983150\n",
      "epoch: 74  batch: 43  loss: 0.09974203\n",
      "epoch: 74  batch: 44  loss: 0.10112305\n",
      "epoch: 74  batch: 45  loss: 0.05772181\n",
      "epoch: 74  batch: 46  loss: 0.07556005\n",
      "epoch: 74  batch: 47  loss: 0.07878623\n",
      "epoch: 74  batch: 48  loss: 0.08261224\n",
      "epoch: 74  batch: 49  loss: 0.08627507\n",
      "epoch: 74  batch: 50  loss: 0.08618969\n",
      "epoch: 74  batch: 51  loss: 0.07347789\n",
      "epoch: 74  batch: 52  loss: 0.08029684\n",
      "epoch: 74  batch: 53  loss: 0.08489016\n",
      "epoch: 74  batch: 54  loss: 0.07627985\n",
      "epoch: 74  batch: 55  loss: 0.07934529\n",
      "epoch: 74  batch: 56  loss: 0.10490615\n",
      "epoch: 74  batch: 57  loss: 0.08903734\n",
      "epoch: 74  batch: 58  loss: 0.07890228\n",
      "epoch: 74  batch: 59  loss: 0.09848168\n",
      "epoch: 74  batch: 60  loss: 0.06759262\n",
      "epoch: 74  batch: 61  loss: 0.07728440\n",
      "epoch: 74  batch: 62  loss: 0.08900438\n",
      "epoch: 74  batch: 63  loss: 0.14478216\n",
      "epoch: 74  batch: 64  loss: 0.09004090\n",
      "epoch: 74  batch: 65  loss: 0.07295180\n",
      "epoch: 74  batch: 66  loss: 0.04916828\n",
      "epoch: 74  batch: 67  loss: 0.06764524\n",
      "epoch: 74  batch: 68  loss: 0.07813229\n",
      "epoch: 74  batch: 69  loss: 0.09635569\n",
      "epoch: 74  batch: 70  loss: 0.07381757\n",
      "epoch: 74  batch: 71  loss: 0.08597223\n",
      "epoch: 74  batch: 72  loss: 0.05990856\n",
      "epoch: 74  batch: 73  loss: 0.08780011\n",
      "epoch: 74  batch: 74  loss: 0.09896572\n",
      "epoch: 74  batch: 75  loss: 0.06476113\n",
      "epoch: 74  batch: 76  loss: 0.09127085\n",
      "epoch: 74  batch: 77  loss: 0.07955989\n",
      "epoch: 74  batch: 78  loss: 0.08045345\n",
      "epoch: 74  batch: 79  loss: 0.04879387\n",
      "epoch: 74  batch: 80  loss: 0.09115108\n",
      "epoch: 74  batch: 81  loss: 0.08035361\n",
      "epoch: 74  batch: 82  loss: 0.08979531\n",
      "epoch: 74  batch: 83  loss: 0.06783042\n",
      "epoch: 74  batch: 84  loss: 0.10783347\n",
      "epoch: 74  batch: 85  loss: 0.08063824\n",
      "epoch: 74  batch: 86  loss: 0.05818719\n",
      "epoch: 74  batch: 87  loss: 0.08608742\n",
      "epoch: 75  batch: 1  loss: 0.07856576\n",
      "epoch: 75  batch: 2  loss: 0.10167353\n",
      "epoch: 75  batch: 3  loss: 0.08429773\n",
      "epoch: 75  batch: 4  loss: 0.08292677\n",
      "epoch: 75  batch: 5  loss: 0.08316036\n",
      "epoch: 75  batch: 6  loss: 0.06423591\n",
      "epoch: 75  batch: 7  loss: 0.09804885\n",
      "epoch: 75  batch: 8  loss: 0.05200374\n",
      "epoch: 75  batch: 9  loss: 0.06435260\n",
      "epoch: 75  batch: 10  loss: 0.05982597\n",
      "epoch: 75  batch: 11  loss: 0.13527238\n",
      "epoch: 75  batch: 12  loss: 0.06357543\n",
      "epoch: 75  batch: 13  loss: 0.09366038\n",
      "epoch: 75  batch: 14  loss: 0.07861983\n",
      "epoch: 75  batch: 15  loss: 0.08884954\n",
      "epoch: 75  batch: 16  loss: 0.07554657\n",
      "epoch: 75  batch: 17  loss: 0.07340637\n",
      "epoch: 75  batch: 18  loss: 0.10605375\n",
      "epoch: 75  batch: 19  loss: 0.07548229\n",
      "epoch: 75  batch: 20  loss: 0.06395717\n",
      "epoch: 75  batch: 21  loss: 0.06482926\n",
      "epoch: 75  batch: 22  loss: 0.07123251\n",
      "epoch: 75  batch: 23  loss: 0.06365094\n",
      "epoch: 75  batch: 24  loss: 0.07116643\n",
      "epoch: 75  batch: 25  loss: 0.06002297\n",
      "epoch: 75  batch: 26  loss: 0.06030384\n",
      "epoch: 75  batch: 27  loss: 0.10581243\n",
      "epoch: 75  batch: 28  loss: 0.09831213\n",
      "epoch: 75  batch: 29  loss: 0.14318764\n",
      "epoch: 75  batch: 30  loss: 0.07101949\n",
      "epoch: 75  batch: 31  loss: 0.07730366\n",
      "epoch: 75  batch: 32  loss: 0.11290670\n",
      "epoch: 75  batch: 33  loss: 0.09124545\n",
      "epoch: 75  batch: 34  loss: 0.07671328\n",
      "epoch: 75  batch: 35  loss: 0.08378900\n",
      "epoch: 75  batch: 36  loss: 0.06829479\n",
      "epoch: 75  batch: 37  loss: 0.08040890\n",
      "epoch: 75  batch: 38  loss: 0.06357957\n",
      "epoch: 75  batch: 39  loss: 0.08951070\n",
      "epoch: 75  batch: 40  loss: 0.08268670\n",
      "epoch: 75  batch: 41  loss: 0.06071789\n",
      "epoch: 75  batch: 42  loss: 0.06901720\n",
      "epoch: 75  batch: 43  loss: 0.05461279\n",
      "epoch: 75  batch: 44  loss: 0.07864477\n",
      "epoch: 75  batch: 45  loss: 0.06286810\n",
      "epoch: 75  batch: 46  loss: 0.07377460\n",
      "epoch: 75  batch: 47  loss: 0.07725947\n",
      "epoch: 75  batch: 48  loss: 0.08762194\n",
      "epoch: 75  batch: 49  loss: 0.10685282\n",
      "epoch: 75  batch: 50  loss: 0.05347200\n",
      "epoch: 75  batch: 51  loss: 0.07675770\n",
      "epoch: 75  batch: 52  loss: 0.07207663\n",
      "epoch: 75  batch: 53  loss: 0.11360954\n",
      "epoch: 75  batch: 54  loss: 0.07913059\n",
      "epoch: 75  batch: 55  loss: 0.06310170\n",
      "epoch: 75  batch: 56  loss: 0.09194954\n",
      "epoch: 75  batch: 57  loss: 0.10799018\n",
      "epoch: 75  batch: 58  loss: 0.13502450\n",
      "epoch: 75  batch: 59  loss: 0.06628823\n",
      "epoch: 75  batch: 60  loss: 0.10563169\n",
      "epoch: 75  batch: 61  loss: 0.08201642\n",
      "epoch: 75  batch: 62  loss: 0.06696770\n",
      "epoch: 75  batch: 63  loss: 0.08210996\n",
      "epoch: 75  batch: 64  loss: 0.12463076\n",
      "epoch: 75  batch: 65  loss: 0.05561296\n",
      "epoch: 75  batch: 66  loss: 0.07750407\n",
      "epoch: 75  batch: 67  loss: 0.08894034\n",
      "epoch: 75  batch: 68  loss: 0.10661295\n",
      "epoch: 75  batch: 69  loss: 0.11341685\n",
      "epoch: 75  batch: 70  loss: 0.06745575\n",
      "epoch: 75  batch: 71  loss: 0.08244255\n",
      "epoch: 75  batch: 72  loss: 0.06429285\n",
      "epoch: 75  batch: 73  loss: 0.08285577\n",
      "epoch: 75  batch: 74  loss: 0.09071311\n",
      "epoch: 75  batch: 75  loss: 0.09085908\n",
      "epoch: 75  batch: 76  loss: 0.10303689\n",
      "epoch: 75  batch: 77  loss: 0.07157753\n",
      "epoch: 75  batch: 78  loss: 0.07998307\n",
      "epoch: 75  batch: 79  loss: 0.06490947\n",
      "epoch: 75  batch: 80  loss: 0.12923093\n",
      "epoch: 75  batch: 81  loss: 0.07301943\n",
      "epoch: 75  batch: 82  loss: 0.08652071\n",
      "epoch: 75  batch: 83  loss: 0.06104898\n",
      "epoch: 75  batch: 84  loss: 0.08836224\n",
      "epoch: 75  batch: 85  loss: 0.08035295\n",
      "epoch: 75  batch: 86  loss: 0.11307726\n",
      "epoch: 75  batch: 87  loss: 0.09658754\n",
      "epoch: 76  batch: 1  loss: 0.08732255\n",
      "epoch: 76  batch: 2  loss: 0.07049337\n",
      "epoch: 76  batch: 3  loss: 0.05730051\n",
      "epoch: 76  batch: 4  loss: 0.10237170\n",
      "epoch: 76  batch: 5  loss: 0.09517778\n",
      "epoch: 76  batch: 6  loss: 0.05646023\n",
      "epoch: 76  batch: 7  loss: 0.06636827\n",
      "epoch: 76  batch: 8  loss: 0.06742923\n",
      "epoch: 76  batch: 9  loss: 0.13187376\n",
      "epoch: 76  batch: 10  loss: 0.09460139\n",
      "epoch: 76  batch: 11  loss: 0.07148697\n",
      "epoch: 76  batch: 12  loss: 0.06950848\n",
      "epoch: 76  batch: 13  loss: 0.12887794\n",
      "epoch: 76  batch: 14  loss: 0.06704909\n",
      "epoch: 76  batch: 15  loss: 0.10177745\n",
      "epoch: 76  batch: 16  loss: 0.07726847\n",
      "epoch: 76  batch: 17  loss: 0.06108617\n",
      "epoch: 76  batch: 18  loss: 0.06598952\n",
      "epoch: 76  batch: 19  loss: 0.07757107\n",
      "epoch: 76  batch: 20  loss: 0.08355601\n",
      "epoch: 76  batch: 21  loss: 0.11752016\n",
      "epoch: 76  batch: 22  loss: 0.07527434\n",
      "epoch: 76  batch: 23  loss: 0.11075793\n",
      "epoch: 76  batch: 24  loss: 0.08664982\n",
      "epoch: 76  batch: 25  loss: 0.07971520\n",
      "epoch: 76  batch: 26  loss: 0.11664996\n",
      "epoch: 76  batch: 27  loss: 0.12386149\n",
      "epoch: 76  batch: 28  loss: 0.10687251\n",
      "epoch: 76  batch: 29  loss: 0.06981272\n",
      "epoch: 76  batch: 30  loss: 0.15671764\n",
      "epoch: 76  batch: 31  loss: 0.04863898\n",
      "epoch: 76  batch: 32  loss: 0.07346158\n",
      "epoch: 76  batch: 33  loss: 0.09015159\n",
      "epoch: 76  batch: 34  loss: 0.07464538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76  batch: 35  loss: 0.09776480\n",
      "epoch: 76  batch: 36  loss: 0.10394379\n",
      "epoch: 76  batch: 37  loss: 0.08304296\n",
      "epoch: 76  batch: 38  loss: 0.04998615\n",
      "epoch: 76  batch: 39  loss: 0.06572817\n",
      "epoch: 76  batch: 40  loss: 0.10901684\n",
      "epoch: 76  batch: 41  loss: 0.06847703\n",
      "epoch: 76  batch: 42  loss: 0.06836215\n",
      "epoch: 76  batch: 43  loss: 0.10005732\n",
      "epoch: 76  batch: 44  loss: 0.06410339\n",
      "epoch: 76  batch: 45  loss: 0.10038903\n",
      "epoch: 76  batch: 46  loss: 0.09854466\n",
      "epoch: 76  batch: 47  loss: 0.06440988\n",
      "epoch: 76  batch: 48  loss: 0.09119339\n",
      "epoch: 76  batch: 49  loss: 0.07280041\n",
      "epoch: 76  batch: 50  loss: 0.11403661\n",
      "epoch: 76  batch: 51  loss: 0.07342363\n",
      "epoch: 76  batch: 52  loss: 0.09980239\n",
      "epoch: 76  batch: 53  loss: 0.07413075\n",
      "epoch: 76  batch: 54  loss: 0.09045777\n",
      "epoch: 76  batch: 55  loss: 0.07166524\n",
      "epoch: 76  batch: 56  loss: 0.07845383\n",
      "epoch: 76  batch: 57  loss: 0.10502973\n",
      "epoch: 76  batch: 58  loss: 0.05278829\n",
      "epoch: 76  batch: 59  loss: 0.09250398\n",
      "epoch: 76  batch: 60  loss: 0.05386955\n",
      "epoch: 76  batch: 61  loss: 0.11268199\n",
      "epoch: 76  batch: 62  loss: 0.06496558\n",
      "epoch: 76  batch: 63  loss: 0.07510446\n",
      "epoch: 76  batch: 64  loss: 0.09569475\n",
      "epoch: 76  batch: 65  loss: 0.09344216\n",
      "epoch: 76  batch: 66  loss: 0.06647458\n",
      "epoch: 76  batch: 67  loss: 0.07316385\n",
      "epoch: 76  batch: 68  loss: 0.10322013\n",
      "epoch: 76  batch: 69  loss: 0.10360333\n",
      "epoch: 76  batch: 70  loss: 0.07545252\n",
      "epoch: 76  batch: 71  loss: 0.08063633\n",
      "epoch: 76  batch: 72  loss: 0.05735187\n",
      "epoch: 76  batch: 73  loss: 0.05117621\n",
      "epoch: 76  batch: 74  loss: 0.06649051\n",
      "epoch: 76  batch: 75  loss: 0.07717428\n",
      "epoch: 76  batch: 76  loss: 0.07790264\n",
      "epoch: 76  batch: 77  loss: 0.12915488\n",
      "epoch: 76  batch: 78  loss: 0.08731046\n",
      "epoch: 76  batch: 79  loss: 0.06617676\n",
      "epoch: 76  batch: 80  loss: 0.06848487\n",
      "epoch: 76  batch: 81  loss: 0.08311778\n",
      "epoch: 76  batch: 82  loss: 0.08988842\n",
      "epoch: 76  batch: 83  loss: 0.09573779\n",
      "epoch: 76  batch: 84  loss: 0.08914468\n",
      "epoch: 76  batch: 85  loss: 0.08072402\n",
      "epoch: 76  batch: 86  loss: 0.11482421\n",
      "epoch: 76  batch: 87  loss: 0.06217190\n",
      "epoch: 77  batch: 1  loss: 0.08189194\n",
      "epoch: 77  batch: 2  loss: 0.09626769\n",
      "epoch: 77  batch: 3  loss: 0.07657024\n",
      "epoch: 77  batch: 4  loss: 0.06458197\n",
      "epoch: 77  batch: 5  loss: 0.09119618\n",
      "epoch: 77  batch: 6  loss: 0.08120145\n",
      "epoch: 77  batch: 7  loss: 0.08037220\n",
      "epoch: 77  batch: 8  loss: 0.08967015\n",
      "epoch: 77  batch: 9  loss: 0.06436327\n",
      "epoch: 77  batch: 10  loss: 0.08185019\n",
      "epoch: 77  batch: 11  loss: 0.06118228\n",
      "epoch: 77  batch: 12  loss: 0.08275315\n",
      "epoch: 77  batch: 13  loss: 0.07957561\n",
      "epoch: 77  batch: 14  loss: 0.10273629\n",
      "epoch: 77  batch: 15  loss: 0.05997895\n",
      "epoch: 77  batch: 16  loss: 0.09885287\n",
      "epoch: 77  batch: 17  loss: 0.08639859\n",
      "epoch: 77  batch: 18  loss: 0.06489604\n",
      "epoch: 77  batch: 19  loss: 0.09183493\n",
      "epoch: 77  batch: 20  loss: 0.08927637\n",
      "epoch: 77  batch: 21  loss: 0.10446231\n",
      "epoch: 77  batch: 22  loss: 0.11234386\n",
      "epoch: 77  batch: 23  loss: 0.07389603\n",
      "epoch: 77  batch: 24  loss: 0.07243823\n",
      "epoch: 77  batch: 25  loss: 0.07162870\n",
      "epoch: 77  batch: 26  loss: 0.07276108\n",
      "epoch: 77  batch: 27  loss: 0.08152564\n",
      "epoch: 77  batch: 28  loss: 0.08406336\n",
      "epoch: 77  batch: 29  loss: 0.07564162\n",
      "epoch: 77  batch: 30  loss: 0.05944210\n",
      "epoch: 77  batch: 31  loss: 0.08355342\n",
      "epoch: 77  batch: 32  loss: 0.07601618\n",
      "epoch: 77  batch: 33  loss: 0.07257001\n",
      "epoch: 77  batch: 34  loss: 0.08863285\n",
      "epoch: 77  batch: 35  loss: 0.05578739\n",
      "epoch: 77  batch: 36  loss: 0.11123232\n",
      "epoch: 77  batch: 37  loss: 0.06267463\n",
      "epoch: 77  batch: 38  loss: 0.07167663\n",
      "epoch: 77  batch: 39  loss: 0.10068363\n",
      "epoch: 77  batch: 40  loss: 0.07297294\n",
      "epoch: 77  batch: 41  loss: 0.10953586\n",
      "epoch: 77  batch: 42  loss: 0.09382260\n",
      "epoch: 77  batch: 43  loss: 0.06926285\n",
      "epoch: 77  batch: 44  loss: 0.06086712\n",
      "epoch: 77  batch: 45  loss: 0.08635487\n",
      "epoch: 77  batch: 46  loss: 0.07642503\n",
      "epoch: 77  batch: 47  loss: 0.08209467\n",
      "epoch: 77  batch: 48  loss: 0.06913684\n",
      "epoch: 77  batch: 49  loss: 0.09055459\n",
      "epoch: 77  batch: 50  loss: 0.07040045\n",
      "epoch: 77  batch: 51  loss: 0.08033232\n",
      "epoch: 77  batch: 52  loss: 0.09707767\n",
      "epoch: 77  batch: 53  loss: 0.11941138\n",
      "epoch: 77  batch: 54  loss: 0.08431593\n",
      "epoch: 77  batch: 55  loss: 0.07896788\n",
      "epoch: 77  batch: 56  loss: 0.09320889\n",
      "epoch: 77  batch: 57  loss: 0.09455514\n",
      "epoch: 77  batch: 58  loss: 0.06942406\n",
      "epoch: 77  batch: 59  loss: 0.07245728\n",
      "epoch: 77  batch: 60  loss: 0.07868008\n",
      "epoch: 77  batch: 61  loss: 0.08055519\n",
      "epoch: 77  batch: 62  loss: 0.08432957\n",
      "epoch: 77  batch: 63  loss: 0.06953890\n",
      "epoch: 77  batch: 64  loss: 0.08816797\n",
      "epoch: 77  batch: 65  loss: 0.08090781\n",
      "epoch: 77  batch: 66  loss: 0.10153814\n",
      "epoch: 77  batch: 67  loss: 0.10009483\n",
      "epoch: 77  batch: 68  loss: 0.05886218\n",
      "epoch: 77  batch: 69  loss: 0.11198834\n",
      "epoch: 77  batch: 70  loss: 0.08460468\n",
      "epoch: 77  batch: 71  loss: 0.08943659\n",
      "epoch: 77  batch: 72  loss: 0.05102397\n",
      "epoch: 77  batch: 73  loss: 0.11231889\n",
      "epoch: 77  batch: 74  loss: 0.08435135\n",
      "epoch: 77  batch: 75  loss: 0.05471279\n",
      "epoch: 77  batch: 76  loss: 0.08629358\n",
      "epoch: 77  batch: 77  loss: 0.12354105\n",
      "epoch: 77  batch: 78  loss: 0.06785684\n",
      "epoch: 77  batch: 79  loss: 0.10826927\n",
      "epoch: 77  batch: 80  loss: 0.08640525\n",
      "epoch: 77  batch: 81  loss: 0.07886101\n",
      "epoch: 77  batch: 82  loss: 0.08717627\n",
      "epoch: 77  batch: 83  loss: 0.06564333\n",
      "epoch: 77  batch: 84  loss: 0.08102237\n",
      "epoch: 77  batch: 85  loss: 0.11769615\n",
      "epoch: 77  batch: 86  loss: 0.07015100\n",
      "epoch: 77  batch: 87  loss: 0.06837204\n",
      "epoch: 78  batch: 1  loss: 0.06830303\n",
      "epoch: 78  batch: 2  loss: 0.06898922\n",
      "epoch: 78  batch: 3  loss: 0.11744163\n",
      "epoch: 78  batch: 4  loss: 0.08076576\n",
      "epoch: 78  batch: 5  loss: 0.06925036\n",
      "epoch: 78  batch: 6  loss: 0.09567574\n",
      "epoch: 78  batch: 7  loss: 0.05661134\n",
      "epoch: 78  batch: 8  loss: 0.08451840\n",
      "epoch: 78  batch: 9  loss: 0.05776611\n",
      "epoch: 78  batch: 10  loss: 0.06312915\n",
      "epoch: 78  batch: 11  loss: 0.07005323\n",
      "epoch: 78  batch: 12  loss: 0.09276608\n",
      "epoch: 78  batch: 13  loss: 0.07414339\n",
      "epoch: 78  batch: 14  loss: 0.10708222\n",
      "epoch: 78  batch: 15  loss: 0.08622410\n",
      "epoch: 78  batch: 16  loss: 0.08038302\n",
      "epoch: 78  batch: 17  loss: 0.06482835\n",
      "epoch: 78  batch: 18  loss: 0.07872695\n",
      "epoch: 78  batch: 19  loss: 0.07529005\n",
      "epoch: 78  batch: 20  loss: 0.11345711\n",
      "epoch: 78  batch: 21  loss: 0.08126684\n",
      "epoch: 78  batch: 22  loss: 0.12015617\n",
      "epoch: 78  batch: 23  loss: 0.10597840\n",
      "epoch: 78  batch: 24  loss: 0.09504133\n",
      "epoch: 78  batch: 25  loss: 0.06369817\n",
      "epoch: 78  batch: 26  loss: 0.10070731\n",
      "epoch: 78  batch: 27  loss: 0.09069140\n",
      "epoch: 78  batch: 28  loss: 0.09003107\n",
      "epoch: 78  batch: 29  loss: 0.08281376\n",
      "epoch: 78  batch: 30  loss: 0.05410364\n",
      "epoch: 78  batch: 31  loss: 0.06418278\n",
      "epoch: 78  batch: 32  loss: 0.09778535\n",
      "epoch: 78  batch: 33  loss: 0.09442837\n",
      "epoch: 78  batch: 34  loss: 0.07962652\n",
      "epoch: 78  batch: 35  loss: 0.06666454\n",
      "epoch: 78  batch: 36  loss: 0.09383777\n",
      "epoch: 78  batch: 37  loss: 0.10984538\n",
      "epoch: 78  batch: 38  loss: 0.07962691\n",
      "epoch: 78  batch: 39  loss: 0.07899486\n",
      "epoch: 78  batch: 40  loss: 0.09928254\n",
      "epoch: 78  batch: 41  loss: 0.11157516\n",
      "epoch: 78  batch: 42  loss: 0.13909760\n",
      "epoch: 78  batch: 43  loss: 0.07223801\n",
      "epoch: 78  batch: 44  loss: 0.10708677\n",
      "epoch: 78  batch: 45  loss: 0.06862949\n",
      "epoch: 78  batch: 46  loss: 0.07941902\n",
      "epoch: 78  batch: 47  loss: 0.09742319\n",
      "epoch: 78  batch: 48  loss: 0.15345778\n",
      "epoch: 78  batch: 49  loss: 0.09821657\n",
      "epoch: 78  batch: 50  loss: 0.06711500\n",
      "epoch: 78  batch: 51  loss: 0.08281127\n",
      "epoch: 78  batch: 52  loss: 0.11159641\n",
      "epoch: 78  batch: 53  loss: 0.11352740\n",
      "epoch: 78  batch: 54  loss: 0.05505717\n",
      "epoch: 78  batch: 55  loss: 0.10881979\n",
      "epoch: 78  batch: 56  loss: 0.06252208\n",
      "epoch: 78  batch: 57  loss: 0.10352730\n",
      "epoch: 78  batch: 58  loss: 0.08981774\n",
      "epoch: 78  batch: 59  loss: 0.06898156\n",
      "epoch: 78  batch: 60  loss: 0.10575801\n",
      "epoch: 78  batch: 61  loss: 0.12225942\n",
      "epoch: 78  batch: 62  loss: 0.06428417\n",
      "epoch: 78  batch: 63  loss: 0.07004936\n",
      "epoch: 78  batch: 64  loss: 0.04995751\n",
      "epoch: 78  batch: 65  loss: 0.05119906\n",
      "epoch: 78  batch: 66  loss: 0.07567327\n",
      "epoch: 78  batch: 67  loss: 0.07827603\n",
      "epoch: 78  batch: 68  loss: 0.08103271\n",
      "epoch: 78  batch: 69  loss: 0.10313070\n",
      "epoch: 78  batch: 70  loss: 0.07968916\n",
      "epoch: 78  batch: 71  loss: 0.08123583\n",
      "epoch: 78  batch: 72  loss: 0.07798151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78  batch: 73  loss: 0.06662755\n",
      "epoch: 78  batch: 74  loss: 0.04791349\n",
      "epoch: 78  batch: 75  loss: 0.07927035\n",
      "epoch: 78  batch: 76  loss: 0.07684193\n",
      "epoch: 78  batch: 77  loss: 0.06614028\n",
      "epoch: 78  batch: 78  loss: 0.09284991\n",
      "epoch: 78  batch: 79  loss: 0.05346858\n",
      "epoch: 78  batch: 80  loss: 0.07032797\n",
      "epoch: 78  batch: 81  loss: 0.10951500\n",
      "epoch: 78  batch: 82  loss: 0.07342401\n",
      "epoch: 78  batch: 83  loss: 0.09517347\n",
      "epoch: 78  batch: 84  loss: 0.07080545\n",
      "epoch: 78  batch: 85  loss: 0.07028422\n",
      "epoch: 78  batch: 86  loss: 0.08742814\n",
      "epoch: 78  batch: 87  loss: 0.09791384\n",
      "epoch: 79  batch: 1  loss: 0.07143804\n",
      "epoch: 79  batch: 2  loss: 0.08348553\n",
      "epoch: 79  batch: 3  loss: 0.07903147\n",
      "epoch: 79  batch: 4  loss: 0.06688313\n",
      "epoch: 79  batch: 5  loss: 0.06263074\n",
      "epoch: 79  batch: 6  loss: 0.07103223\n",
      "epoch: 79  batch: 7  loss: 0.07605586\n",
      "epoch: 79  batch: 8  loss: 0.04856798\n",
      "epoch: 79  batch: 9  loss: 0.07900853\n",
      "epoch: 79  batch: 10  loss: 0.10223421\n",
      "epoch: 79  batch: 11  loss: 0.06469918\n",
      "epoch: 79  batch: 12  loss: 0.07397111\n",
      "epoch: 79  batch: 13  loss: 0.11328630\n",
      "epoch: 79  batch: 14  loss: 0.11803599\n",
      "epoch: 79  batch: 15  loss: 0.08373377\n",
      "epoch: 79  batch: 16  loss: 0.13098089\n",
      "epoch: 79  batch: 17  loss: 0.10244035\n",
      "epoch: 79  batch: 18  loss: 0.09508340\n",
      "epoch: 79  batch: 19  loss: 0.08011872\n",
      "epoch: 79  batch: 20  loss: 0.06461031\n",
      "epoch: 79  batch: 21  loss: 0.11516573\n",
      "epoch: 79  batch: 22  loss: 0.09745807\n",
      "epoch: 79  batch: 23  loss: 0.07288624\n",
      "epoch: 79  batch: 24  loss: 0.07404013\n",
      "epoch: 79  batch: 25  loss: 0.06931753\n",
      "epoch: 79  batch: 26  loss: 0.08803947\n",
      "epoch: 79  batch: 27  loss: 0.07897194\n",
      "epoch: 79  batch: 28  loss: 0.07776278\n",
      "epoch: 79  batch: 29  loss: 0.08235757\n",
      "epoch: 79  batch: 30  loss: 0.05338838\n",
      "epoch: 79  batch: 31  loss: 0.08770984\n",
      "epoch: 79  batch: 32  loss: 0.12476581\n",
      "epoch: 79  batch: 33  loss: 0.14446993\n",
      "epoch: 79  batch: 34  loss: 0.06282266\n",
      "epoch: 79  batch: 35  loss: 0.07874088\n",
      "epoch: 79  batch: 36  loss: 0.07383970\n",
      "epoch: 79  batch: 37  loss: 0.10549836\n",
      "epoch: 79  batch: 38  loss: 0.07420246\n",
      "epoch: 79  batch: 39  loss: 0.07582588\n",
      "epoch: 79  batch: 40  loss: 0.08178291\n",
      "epoch: 79  batch: 41  loss: 0.07538889\n",
      "epoch: 79  batch: 42  loss: 0.08597569\n",
      "epoch: 79  batch: 43  loss: 0.06489387\n",
      "epoch: 79  batch: 44  loss: 0.08722823\n",
      "epoch: 79  batch: 45  loss: 0.08811276\n",
      "epoch: 79  batch: 46  loss: 0.08017990\n",
      "epoch: 79  batch: 47  loss: 0.06734766\n",
      "epoch: 79  batch: 48  loss: 0.07196870\n",
      "epoch: 79  batch: 49  loss: 0.10656007\n",
      "epoch: 79  batch: 50  loss: 0.06038051\n",
      "epoch: 79  batch: 51  loss: 0.07152766\n",
      "epoch: 79  batch: 52  loss: 0.05968292\n",
      "epoch: 79  batch: 53  loss: 0.08776806\n",
      "epoch: 79  batch: 54  loss: 0.09177969\n",
      "epoch: 79  batch: 55  loss: 0.06634273\n",
      "epoch: 79  batch: 56  loss: 0.07376627\n",
      "epoch: 79  batch: 57  loss: 0.08201510\n",
      "epoch: 79  batch: 58  loss: 0.08799182\n",
      "epoch: 79  batch: 59  loss: 0.12624083\n",
      "epoch: 79  batch: 60  loss: 0.07883506\n",
      "epoch: 79  batch: 61  loss: 0.07669403\n",
      "epoch: 79  batch: 62  loss: 0.05742995\n",
      "epoch: 79  batch: 63  loss: 0.06964328\n",
      "epoch: 79  batch: 64  loss: 0.05918532\n",
      "epoch: 79  batch: 65  loss: 0.12563394\n",
      "epoch: 79  batch: 66  loss: 0.06002874\n",
      "epoch: 79  batch: 67  loss: 0.09623982\n",
      "epoch: 79  batch: 68  loss: 0.08237521\n",
      "epoch: 79  batch: 69  loss: 0.08281823\n",
      "epoch: 79  batch: 70  loss: 0.06822588\n",
      "epoch: 79  batch: 71  loss: 0.05204616\n",
      "epoch: 79  batch: 72  loss: 0.13021773\n",
      "epoch: 79  batch: 73  loss: 0.06530453\n",
      "epoch: 79  batch: 74  loss: 0.10390171\n",
      "epoch: 79  batch: 75  loss: 0.10119121\n",
      "epoch: 79  batch: 76  loss: 0.06019321\n",
      "epoch: 79  batch: 77  loss: 0.10067040\n",
      "epoch: 79  batch: 78  loss: 0.08578815\n",
      "epoch: 79  batch: 79  loss: 0.07970384\n",
      "epoch: 79  batch: 80  loss: 0.07233224\n",
      "epoch: 79  batch: 81  loss: 0.07590277\n",
      "epoch: 79  batch: 82  loss: 0.08970495\n",
      "epoch: 79  batch: 83  loss: 0.07901563\n",
      "epoch: 79  batch: 84  loss: 0.10380729\n",
      "epoch: 79  batch: 85  loss: 0.08976439\n",
      "epoch: 79  batch: 86  loss: 0.07583023\n",
      "epoch: 79  batch: 87  loss: 0.09900529\n",
      "epoch: 80  batch: 1  loss: 0.08005300\n",
      "epoch: 80  batch: 2  loss: 0.06207151\n",
      "epoch: 80  batch: 3  loss: 0.07943255\n",
      "epoch: 80  batch: 4  loss: 0.06647381\n",
      "epoch: 80  batch: 5  loss: 0.07816170\n",
      "epoch: 80  batch: 6  loss: 0.09726652\n",
      "epoch: 80  batch: 7  loss: 0.08083440\n",
      "epoch: 80  batch: 8  loss: 0.09355146\n",
      "epoch: 80  batch: 9  loss: 0.11273924\n",
      "epoch: 80  batch: 10  loss: 0.15279503\n",
      "epoch: 80  batch: 11  loss: 0.10656740\n",
      "epoch: 80  batch: 12  loss: 0.10586261\n",
      "epoch: 80  batch: 13  loss: 0.06267706\n",
      "epoch: 80  batch: 14  loss: 0.10000993\n",
      "epoch: 80  batch: 15  loss: 0.12288228\n",
      "epoch: 80  batch: 16  loss: 0.06552896\n",
      "epoch: 80  batch: 17  loss: 0.08029824\n",
      "epoch: 80  batch: 18  loss: 0.08838377\n",
      "epoch: 80  batch: 19  loss: 0.08212186\n",
      "epoch: 80  batch: 20  loss: 0.12716556\n",
      "epoch: 80  batch: 21  loss: 0.05449359\n",
      "epoch: 80  batch: 22  loss: 0.06550036\n",
      "epoch: 80  batch: 23  loss: 0.05431146\n",
      "epoch: 80  batch: 24  loss: 0.08416484\n",
      "epoch: 80  batch: 25  loss: 0.06594181\n",
      "epoch: 80  batch: 26  loss: 0.06804328\n",
      "epoch: 80  batch: 27  loss: 0.07810014\n",
      "epoch: 80  batch: 28  loss: 0.11048380\n",
      "epoch: 80  batch: 29  loss: 0.06868129\n",
      "epoch: 80  batch: 30  loss: 0.06948922\n",
      "epoch: 80  batch: 31  loss: 0.08957309\n",
      "epoch: 80  batch: 32  loss: 0.08916253\n",
      "epoch: 80  batch: 33  loss: 0.06716714\n",
      "epoch: 80  batch: 34  loss: 0.14851564\n",
      "epoch: 80  batch: 35  loss: 0.06792226\n",
      "epoch: 80  batch: 36  loss: 0.10040777\n",
      "epoch: 80  batch: 37  loss: 0.08840314\n",
      "epoch: 80  batch: 38  loss: 0.08644648\n",
      "epoch: 80  batch: 39  loss: 0.06857771\n",
      "epoch: 80  batch: 40  loss: 0.05853964\n",
      "epoch: 80  batch: 41  loss: 0.09448757\n",
      "epoch: 80  batch: 42  loss: 0.06983571\n",
      "epoch: 80  batch: 43  loss: 0.07519934\n",
      "epoch: 80  batch: 44  loss: 0.05259792\n",
      "epoch: 80  batch: 45  loss: 0.06317467\n",
      "epoch: 80  batch: 46  loss: 0.06007468\n",
      "epoch: 80  batch: 47  loss: 0.06258506\n",
      "epoch: 80  batch: 48  loss: 0.08703113\n",
      "epoch: 80  batch: 49  loss: 0.10099231\n",
      "epoch: 80  batch: 50  loss: 0.13078311\n",
      "epoch: 80  batch: 51  loss: 0.07751779\n",
      "epoch: 80  batch: 52  loss: 0.08005295\n",
      "epoch: 80  batch: 53  loss: 0.10030777\n",
      "epoch: 80  batch: 54  loss: 0.09617797\n",
      "epoch: 80  batch: 55  loss: 0.05202517\n",
      "epoch: 80  batch: 56  loss: 0.08186089\n",
      "epoch: 80  batch: 57  loss: 0.09081877\n",
      "epoch: 80  batch: 58  loss: 0.10750272\n",
      "epoch: 80  batch: 59  loss: 0.08429319\n",
      "epoch: 80  batch: 60  loss: 0.08458181\n",
      "epoch: 80  batch: 61  loss: 0.06246241\n",
      "epoch: 80  batch: 62  loss: 0.07809491\n",
      "epoch: 80  batch: 63  loss: 0.12477632\n",
      "epoch: 80  batch: 64  loss: 0.05634892\n",
      "epoch: 80  batch: 65  loss: 0.04252765\n",
      "epoch: 80  batch: 66  loss: 0.07980901\n",
      "epoch: 80  batch: 67  loss: 0.06868023\n",
      "epoch: 80  batch: 68  loss: 0.11594534\n",
      "epoch: 80  batch: 69  loss: 0.09147502\n",
      "epoch: 80  batch: 70  loss: 0.06991180\n",
      "epoch: 80  batch: 71  loss: 0.06782502\n",
      "epoch: 80  batch: 72  loss: 0.07189993\n",
      "epoch: 80  batch: 73  loss: 0.04761851\n",
      "epoch: 80  batch: 74  loss: 0.10343076\n",
      "epoch: 80  batch: 75  loss: 0.08445228\n",
      "epoch: 80  batch: 76  loss: 0.07589272\n",
      "epoch: 80  batch: 77  loss: 0.08335559\n",
      "epoch: 80  batch: 78  loss: 0.05518105\n",
      "epoch: 80  batch: 79  loss: 0.10042334\n",
      "epoch: 80  batch: 80  loss: 0.12690906\n",
      "epoch: 80  batch: 81  loss: 0.06225768\n",
      "epoch: 80  batch: 82  loss: 0.07275151\n",
      "epoch: 80  batch: 83  loss: 0.11178488\n",
      "epoch: 80  batch: 84  loss: 0.05605855\n",
      "epoch: 80  batch: 85  loss: 0.08038022\n",
      "epoch: 80  batch: 86  loss: 0.08554143\n",
      "epoch: 80  batch: 87  loss: 0.12638713\n",
      "epoch: 81  batch: 1  loss: 0.05081514\n",
      "epoch: 81  batch: 2  loss: 0.08622173\n",
      "epoch: 81  batch: 3  loss: 0.08016207\n",
      "epoch: 81  batch: 4  loss: 0.06562117\n",
      "epoch: 81  batch: 5  loss: 0.06561667\n",
      "epoch: 81  batch: 6  loss: 0.08247400\n",
      "epoch: 81  batch: 7  loss: 0.07370377\n",
      "epoch: 81  batch: 8  loss: 0.10549849\n",
      "epoch: 81  batch: 9  loss: 0.08470497\n",
      "epoch: 81  batch: 10  loss: 0.07886588\n",
      "epoch: 81  batch: 11  loss: 0.12540862\n",
      "epoch: 81  batch: 12  loss: 0.09719464\n",
      "epoch: 81  batch: 13  loss: 0.06519331\n",
      "epoch: 81  batch: 14  loss: 0.06523166\n",
      "epoch: 81  batch: 15  loss: 0.08026936\n",
      "epoch: 81  batch: 16  loss: 0.11409617\n",
      "epoch: 81  batch: 17  loss: 0.10008319\n",
      "epoch: 81  batch: 18  loss: 0.05692145\n",
      "epoch: 81  batch: 19  loss: 0.05727304\n",
      "epoch: 81  batch: 20  loss: 0.06557223\n",
      "epoch: 81  batch: 21  loss: 0.09677944\n",
      "epoch: 81  batch: 22  loss: 0.08775475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81  batch: 23  loss: 0.05551105\n",
      "epoch: 81  batch: 24  loss: 0.07266979\n",
      "epoch: 81  batch: 25  loss: 0.09850424\n",
      "epoch: 81  batch: 26  loss: 0.05369231\n",
      "epoch: 81  batch: 27  loss: 0.08214894\n",
      "epoch: 81  batch: 28  loss: 0.06859182\n",
      "epoch: 81  batch: 29  loss: 0.05246771\n",
      "epoch: 81  batch: 30  loss: 0.08339734\n",
      "epoch: 81  batch: 31  loss: 0.06361991\n",
      "epoch: 81  batch: 32  loss: 0.07214756\n",
      "epoch: 81  batch: 33  loss: 0.07123716\n",
      "epoch: 81  batch: 34  loss: 0.09548944\n",
      "epoch: 81  batch: 35  loss: 0.07357035\n",
      "epoch: 81  batch: 36  loss: 0.07960730\n",
      "epoch: 81  batch: 37  loss: 0.07707943\n",
      "epoch: 81  batch: 38  loss: 0.08213290\n",
      "epoch: 81  batch: 39  loss: 0.14742331\n",
      "epoch: 81  batch: 40  loss: 0.10277465\n",
      "epoch: 81  batch: 41  loss: 0.06748376\n",
      "epoch: 81  batch: 42  loss: 0.05338206\n",
      "epoch: 81  batch: 43  loss: 0.06047450\n",
      "epoch: 81  batch: 44  loss: 0.08595575\n",
      "epoch: 81  batch: 45  loss: 0.06527255\n",
      "epoch: 81  batch: 46  loss: 0.09966795\n",
      "epoch: 81  batch: 47  loss: 0.06319290\n",
      "epoch: 81  batch: 48  loss: 0.06982896\n",
      "epoch: 81  batch: 49  loss: 0.08443415\n",
      "epoch: 81  batch: 50  loss: 0.07512110\n",
      "epoch: 81  batch: 51  loss: 0.08923195\n",
      "epoch: 81  batch: 52  loss: 0.08629652\n",
      "epoch: 81  batch: 53  loss: 0.07076465\n",
      "epoch: 81  batch: 54  loss: 0.11377110\n",
      "epoch: 81  batch: 55  loss: 0.07292538\n",
      "epoch: 81  batch: 56  loss: 0.09460825\n",
      "epoch: 81  batch: 57  loss: 0.07167601\n",
      "epoch: 81  batch: 58  loss: 0.09941646\n",
      "epoch: 81  batch: 59  loss: 0.14134888\n",
      "epoch: 81  batch: 60  loss: 0.06515986\n",
      "epoch: 81  batch: 61  loss: 0.06988080\n",
      "epoch: 81  batch: 62  loss: 0.09597548\n",
      "epoch: 81  batch: 63  loss: 0.06206178\n",
      "epoch: 81  batch: 64  loss: 0.05622726\n",
      "epoch: 81  batch: 65  loss: 0.10262374\n",
      "epoch: 81  batch: 66  loss: 0.06465415\n",
      "epoch: 81  batch: 67  loss: 0.10519309\n",
      "epoch: 81  batch: 68  loss: 0.10394473\n",
      "epoch: 81  batch: 69  loss: 0.10510766\n",
      "epoch: 81  batch: 70  loss: 0.10652068\n",
      "epoch: 81  batch: 71  loss: 0.07209058\n",
      "epoch: 81  batch: 72  loss: 0.09248707\n",
      "epoch: 81  batch: 73  loss: 0.06420077\n",
      "epoch: 81  batch: 74  loss: 0.09868953\n",
      "epoch: 81  batch: 75  loss: 0.09035249\n",
      "epoch: 81  batch: 76  loss: 0.09527708\n",
      "epoch: 81  batch: 77  loss: 0.07581022\n",
      "epoch: 81  batch: 78  loss: 0.06384520\n",
      "epoch: 81  batch: 79  loss: 0.11899590\n",
      "epoch: 81  batch: 80  loss: 0.09419629\n",
      "epoch: 81  batch: 81  loss: 0.11618344\n",
      "epoch: 81  batch: 82  loss: 0.07002820\n",
      "epoch: 81  batch: 83  loss: 0.07645463\n",
      "epoch: 81  batch: 84  loss: 0.07763871\n",
      "epoch: 81  batch: 85  loss: 0.05952634\n",
      "epoch: 81  batch: 86  loss: 0.10150535\n",
      "epoch: 81  batch: 87  loss: 0.07394608\n",
      "epoch: 82  batch: 1  loss: 0.08259527\n",
      "epoch: 82  batch: 2  loss: 0.09196061\n",
      "epoch: 82  batch: 3  loss: 0.13374069\n",
      "epoch: 82  batch: 4  loss: 0.05465782\n",
      "epoch: 82  batch: 5  loss: 0.05966843\n",
      "epoch: 82  batch: 6  loss: 0.09692649\n",
      "epoch: 82  batch: 7  loss: 0.06159343\n",
      "epoch: 82  batch: 8  loss: 0.06629085\n",
      "epoch: 82  batch: 9  loss: 0.09825957\n",
      "epoch: 82  batch: 10  loss: 0.09926867\n",
      "epoch: 82  batch: 11  loss: 0.06013599\n",
      "epoch: 82  batch: 12  loss: 0.09179127\n",
      "epoch: 82  batch: 13  loss: 0.09512880\n",
      "epoch: 82  batch: 14  loss: 0.09157078\n",
      "epoch: 82  batch: 15  loss: 0.09412331\n",
      "epoch: 82  batch: 16  loss: 0.11650295\n",
      "epoch: 82  batch: 17  loss: 0.05915083\n",
      "epoch: 82  batch: 18  loss: 0.09530389\n",
      "epoch: 82  batch: 19  loss: 0.08308564\n",
      "epoch: 82  batch: 20  loss: 0.06721403\n",
      "epoch: 82  batch: 21  loss: 0.05921568\n",
      "epoch: 82  batch: 22  loss: 0.07321666\n",
      "epoch: 82  batch: 23  loss: 0.09772254\n",
      "epoch: 82  batch: 24  loss: 0.04876034\n",
      "epoch: 82  batch: 25  loss: 0.08273216\n",
      "epoch: 82  batch: 26  loss: 0.08274067\n",
      "epoch: 82  batch: 27  loss: 0.07239535\n",
      "epoch: 82  batch: 28  loss: 0.05248886\n",
      "epoch: 82  batch: 29  loss: 0.07829530\n",
      "epoch: 82  batch: 30  loss: 0.09769190\n",
      "epoch: 82  batch: 31  loss: 0.06178626\n",
      "epoch: 82  batch: 32  loss: 0.10003784\n",
      "epoch: 82  batch: 33  loss: 0.09094355\n",
      "epoch: 82  batch: 34  loss: 0.06240706\n",
      "epoch: 82  batch: 35  loss: 0.06401694\n",
      "epoch: 82  batch: 36  loss: 0.07533664\n",
      "epoch: 82  batch: 37  loss: 0.09229922\n",
      "epoch: 82  batch: 38  loss: 0.09073492\n",
      "epoch: 82  batch: 39  loss: 0.06803577\n",
      "epoch: 82  batch: 40  loss: 0.08365116\n",
      "epoch: 82  batch: 41  loss: 0.07577907\n",
      "epoch: 82  batch: 42  loss: 0.05926190\n",
      "epoch: 82  batch: 43  loss: 0.08461341\n",
      "epoch: 82  batch: 44  loss: 0.09232838\n",
      "epoch: 82  batch: 45  loss: 0.07102624\n",
      "epoch: 82  batch: 46  loss: 0.09757807\n",
      "epoch: 82  batch: 47  loss: 0.08619459\n",
      "epoch: 82  batch: 48  loss: 0.09647669\n",
      "epoch: 82  batch: 49  loss: 0.07600906\n",
      "epoch: 82  batch: 50  loss: 0.06799754\n",
      "epoch: 82  batch: 51  loss: 0.07468137\n",
      "epoch: 82  batch: 52  loss: 0.10975809\n",
      "epoch: 82  batch: 53  loss: 0.08456059\n",
      "epoch: 82  batch: 54  loss: 0.07015898\n",
      "epoch: 82  batch: 55  loss: 0.14120637\n",
      "epoch: 82  batch: 56  loss: 0.07191936\n",
      "epoch: 82  batch: 57  loss: 0.11424817\n",
      "epoch: 82  batch: 58  loss: 0.10454744\n",
      "epoch: 82  batch: 59  loss: 0.11536117\n",
      "epoch: 82  batch: 60  loss: 0.17258403\n",
      "epoch: 82  batch: 61  loss: 0.09540396\n",
      "epoch: 82  batch: 62  loss: 0.05877646\n",
      "epoch: 82  batch: 63  loss: 0.05965371\n",
      "epoch: 82  batch: 64  loss: 0.07353514\n",
      "epoch: 82  batch: 65  loss: 0.06702598\n",
      "epoch: 82  batch: 66  loss: 0.10279972\n",
      "epoch: 82  batch: 67  loss: 0.08742980\n",
      "epoch: 82  batch: 68  loss: 0.08033368\n",
      "epoch: 82  batch: 69  loss: 0.08110690\n",
      "epoch: 82  batch: 70  loss: 0.07354806\n",
      "epoch: 82  batch: 71  loss: 0.09231967\n",
      "epoch: 82  batch: 72  loss: 0.07987136\n",
      "epoch: 82  batch: 73  loss: 0.07680115\n",
      "epoch: 82  batch: 74  loss: 0.09039930\n",
      "epoch: 82  batch: 75  loss: 0.05859497\n",
      "epoch: 82  batch: 76  loss: 0.05573676\n",
      "epoch: 82  batch: 77  loss: 0.05202962\n",
      "epoch: 82  batch: 78  loss: 0.08177418\n",
      "epoch: 82  batch: 79  loss: 0.09348799\n",
      "epoch: 82  batch: 80  loss: 0.07685170\n",
      "epoch: 82  batch: 81  loss: 0.04585309\n",
      "epoch: 82  batch: 82  loss: 0.06946730\n",
      "epoch: 82  batch: 83  loss: 0.07780413\n",
      "epoch: 82  batch: 84  loss: 0.07024238\n",
      "epoch: 82  batch: 85  loss: 0.08478572\n",
      "epoch: 82  batch: 86  loss: 0.06786060\n",
      "epoch: 82  batch: 87  loss: 0.07906836\n",
      "epoch: 83  batch: 1  loss: 0.07564520\n",
      "epoch: 83  batch: 2  loss: 0.07737304\n",
      "epoch: 83  batch: 3  loss: 0.06373178\n",
      "epoch: 83  batch: 4  loss: 0.08466659\n",
      "epoch: 83  batch: 5  loss: 0.10662337\n",
      "epoch: 83  batch: 6  loss: 0.08561713\n",
      "epoch: 83  batch: 7  loss: 0.09085174\n",
      "epoch: 83  batch: 8  loss: 0.10145794\n",
      "epoch: 83  batch: 9  loss: 0.09830808\n",
      "epoch: 83  batch: 10  loss: 0.12608780\n",
      "epoch: 83  batch: 11  loss: 0.07809860\n",
      "epoch: 83  batch: 12  loss: 0.05369313\n",
      "epoch: 83  batch: 13  loss: 0.06202188\n",
      "epoch: 83  batch: 14  loss: 0.09513464\n",
      "epoch: 83  batch: 15  loss: 0.05486974\n",
      "epoch: 83  batch: 16  loss: 0.08280674\n",
      "epoch: 83  batch: 17  loss: 0.05903179\n",
      "epoch: 83  batch: 18  loss: 0.06532200\n",
      "epoch: 83  batch: 19  loss: 0.10422849\n",
      "epoch: 83  batch: 20  loss: 0.06952061\n",
      "epoch: 83  batch: 21  loss: 0.05758163\n",
      "epoch: 83  batch: 22  loss: 0.11998975\n",
      "epoch: 83  batch: 23  loss: 0.06105066\n",
      "epoch: 83  batch: 24  loss: 0.08051507\n",
      "epoch: 83  batch: 25  loss: 0.06149250\n",
      "epoch: 83  batch: 26  loss: 0.11283556\n",
      "epoch: 83  batch: 27  loss: 0.08473732\n",
      "epoch: 83  batch: 28  loss: 0.07614956\n",
      "epoch: 83  batch: 29  loss: 0.07641396\n",
      "epoch: 83  batch: 30  loss: 0.10717081\n",
      "epoch: 83  batch: 31  loss: 0.12555581\n",
      "epoch: 83  batch: 32  loss: 0.05682387\n",
      "epoch: 83  batch: 33  loss: 0.08045909\n",
      "epoch: 83  batch: 34  loss: 0.09427200\n",
      "epoch: 83  batch: 35  loss: 0.08675227\n",
      "epoch: 83  batch: 36  loss: 0.06908241\n",
      "epoch: 83  batch: 37  loss: 0.07621729\n",
      "epoch: 83  batch: 38  loss: 0.08653355\n",
      "epoch: 83  batch: 39  loss: 0.06116239\n",
      "epoch: 83  batch: 40  loss: 0.10149481\n",
      "epoch: 83  batch: 41  loss: 0.16073553\n",
      "epoch: 83  batch: 42  loss: 0.08096753\n",
      "epoch: 83  batch: 43  loss: 0.11339977\n",
      "epoch: 83  batch: 44  loss: 0.13205181\n",
      "epoch: 83  batch: 45  loss: 0.10565373\n",
      "epoch: 83  batch: 46  loss: 0.07149189\n",
      "epoch: 83  batch: 47  loss: 0.07471465\n",
      "epoch: 83  batch: 48  loss: 0.10269683\n",
      "epoch: 83  batch: 49  loss: 0.09910913\n",
      "epoch: 83  batch: 50  loss: 0.07576510\n",
      "epoch: 83  batch: 51  loss: 0.06259157\n",
      "epoch: 83  batch: 52  loss: 0.04949001\n",
      "epoch: 83  batch: 53  loss: 0.07943888\n",
      "epoch: 83  batch: 54  loss: 0.06818365\n",
      "epoch: 83  batch: 55  loss: 0.07249896\n",
      "epoch: 83  batch: 56  loss: 0.09818232\n",
      "epoch: 83  batch: 57  loss: 0.06770606\n",
      "epoch: 83  batch: 58  loss: 0.07534771\n",
      "epoch: 83  batch: 59  loss: 0.05888980\n",
      "epoch: 83  batch: 60  loss: 0.08081158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 83  batch: 61  loss: 0.06020219\n",
      "epoch: 83  batch: 62  loss: 0.10623959\n",
      "epoch: 83  batch: 63  loss: 0.09374472\n",
      "epoch: 83  batch: 64  loss: 0.07071444\n",
      "epoch: 83  batch: 65  loss: 0.06744780\n",
      "epoch: 83  batch: 66  loss: 0.06134681\n",
      "epoch: 83  batch: 67  loss: 0.06556979\n",
      "epoch: 83  batch: 68  loss: 0.08589520\n",
      "epoch: 83  batch: 69  loss: 0.06467924\n",
      "epoch: 83  batch: 70  loss: 0.08988978\n",
      "epoch: 83  batch: 71  loss: 0.09524039\n",
      "epoch: 83  batch: 72  loss: 0.08488327\n",
      "epoch: 83  batch: 73  loss: 0.06654430\n",
      "epoch: 83  batch: 74  loss: 0.06772476\n",
      "epoch: 83  batch: 75  loss: 0.07588585\n",
      "epoch: 83  batch: 76  loss: 0.10495232\n",
      "epoch: 83  batch: 77  loss: 0.09921174\n",
      "epoch: 83  batch: 78  loss: 0.04721938\n",
      "epoch: 83  batch: 79  loss: 0.08537523\n",
      "epoch: 83  batch: 80  loss: 0.08237803\n",
      "epoch: 83  batch: 81  loss: 0.11096174\n",
      "epoch: 83  batch: 82  loss: 0.06842653\n",
      "epoch: 83  batch: 83  loss: 0.10073009\n",
      "epoch: 83  batch: 84  loss: 0.10960918\n",
      "epoch: 83  batch: 85  loss: 0.10641509\n",
      "epoch: 83  batch: 86  loss: 0.09897725\n",
      "epoch: 83  batch: 87  loss: 0.06909068\n",
      "epoch: 84  batch: 1  loss: 0.09332709\n",
      "epoch: 84  batch: 2  loss: 0.07640539\n",
      "epoch: 84  batch: 3  loss: 0.09704918\n",
      "epoch: 84  batch: 4  loss: 0.07094589\n",
      "epoch: 84  batch: 5  loss: 0.11318152\n",
      "epoch: 84  batch: 6  loss: 0.08409334\n",
      "epoch: 84  batch: 7  loss: 0.07081782\n",
      "epoch: 84  batch: 8  loss: 0.09586241\n",
      "epoch: 84  batch: 9  loss: 0.04486567\n",
      "epoch: 84  batch: 10  loss: 0.09677676\n",
      "epoch: 84  batch: 11  loss: 0.04865800\n",
      "epoch: 84  batch: 12  loss: 0.05291557\n",
      "epoch: 84  batch: 13  loss: 0.05391999\n",
      "epoch: 84  batch: 14  loss: 0.07706954\n",
      "epoch: 84  batch: 15  loss: 0.11042690\n",
      "epoch: 84  batch: 16  loss: 0.05349346\n",
      "epoch: 84  batch: 17  loss: 0.09900850\n",
      "epoch: 84  batch: 18  loss: 0.07834967\n",
      "epoch: 84  batch: 19  loss: 0.07710802\n",
      "epoch: 84  batch: 20  loss: 0.07476303\n",
      "epoch: 84  batch: 21  loss: 0.10281034\n",
      "epoch: 84  batch: 22  loss: 0.09887739\n",
      "epoch: 84  batch: 23  loss: 0.10890211\n",
      "epoch: 84  batch: 24  loss: 0.07515207\n",
      "epoch: 84  batch: 25  loss: 0.05912888\n",
      "epoch: 84  batch: 26  loss: 0.07340124\n",
      "epoch: 84  batch: 27  loss: 0.08568276\n",
      "epoch: 84  batch: 28  loss: 0.09284066\n",
      "epoch: 84  batch: 29  loss: 0.06974295\n",
      "epoch: 84  batch: 30  loss: 0.15955652\n",
      "epoch: 84  batch: 31  loss: 0.09197877\n",
      "epoch: 84  batch: 32  loss: 0.11155301\n",
      "epoch: 84  batch: 33  loss: 0.08126812\n",
      "epoch: 84  batch: 34  loss: 0.08016768\n",
      "epoch: 84  batch: 35  loss: 0.06573869\n",
      "epoch: 84  batch: 36  loss: 0.07120254\n",
      "epoch: 84  batch: 37  loss: 0.07119335\n",
      "epoch: 84  batch: 38  loss: 0.11915282\n",
      "epoch: 84  batch: 39  loss: 0.06812238\n",
      "epoch: 84  batch: 40  loss: 0.07142784\n",
      "epoch: 84  batch: 41  loss: 0.10788437\n",
      "epoch: 84  batch: 42  loss: 0.04280011\n",
      "epoch: 84  batch: 43  loss: 0.06217097\n",
      "epoch: 84  batch: 44  loss: 0.13565755\n",
      "epoch: 84  batch: 45  loss: 0.08086815\n",
      "epoch: 84  batch: 46  loss: 0.08162809\n",
      "epoch: 84  batch: 47  loss: 0.07968207\n",
      "epoch: 84  batch: 48  loss: 0.06931596\n",
      "epoch: 84  batch: 49  loss: 0.11125401\n",
      "epoch: 84  batch: 50  loss: 0.11039081\n",
      "epoch: 84  batch: 51  loss: 0.07270403\n",
      "epoch: 84  batch: 52  loss: 0.06947446\n",
      "epoch: 84  batch: 53  loss: 0.07712585\n",
      "epoch: 84  batch: 54  loss: 0.06136721\n",
      "epoch: 84  batch: 55  loss: 0.07798967\n",
      "epoch: 84  batch: 56  loss: 0.07033727\n",
      "epoch: 84  batch: 57  loss: 0.07080445\n",
      "epoch: 84  batch: 58  loss: 0.07759387\n",
      "epoch: 84  batch: 59  loss: 0.06214801\n",
      "epoch: 84  batch: 60  loss: 0.07261211\n",
      "epoch: 84  batch: 61  loss: 0.05858781\n",
      "epoch: 84  batch: 62  loss: 0.04922633\n",
      "epoch: 84  batch: 63  loss: 0.07056718\n",
      "epoch: 84  batch: 64  loss: 0.09489913\n",
      "epoch: 84  batch: 65  loss: 0.08283374\n",
      "epoch: 84  batch: 66  loss: 0.10471113\n",
      "epoch: 84  batch: 67  loss: 0.08652704\n",
      "epoch: 84  batch: 68  loss: 0.06808373\n",
      "epoch: 84  batch: 69  loss: 0.09404697\n",
      "epoch: 84  batch: 70  loss: 0.09480633\n",
      "epoch: 84  batch: 71  loss: 0.07261636\n",
      "epoch: 84  batch: 72  loss: 0.07362749\n",
      "epoch: 84  batch: 73  loss: 0.08944538\n",
      "epoch: 84  batch: 74  loss: 0.05621606\n",
      "epoch: 84  batch: 75  loss: 0.09185158\n",
      "epoch: 84  batch: 76  loss: 0.08408029\n",
      "epoch: 84  batch: 77  loss: 0.07230802\n",
      "epoch: 84  batch: 78  loss: 0.07437652\n",
      "epoch: 84  batch: 79  loss: 0.08295063\n",
      "epoch: 84  batch: 80  loss: 0.08716703\n",
      "epoch: 84  batch: 81  loss: 0.05827641\n",
      "epoch: 84  batch: 82  loss: 0.08522776\n",
      "epoch: 84  batch: 83  loss: 0.07781604\n",
      "epoch: 84  batch: 84  loss: 0.06283383\n",
      "epoch: 84  batch: 85  loss: 0.08833513\n",
      "epoch: 84  batch: 86  loss: 0.10001682\n",
      "epoch: 84  batch: 87  loss: 0.07198451\n",
      "epoch: 85  batch: 1  loss: 0.07664312\n",
      "epoch: 85  batch: 2  loss: 0.09386743\n",
      "epoch: 85  batch: 3  loss: 0.08083571\n",
      "epoch: 85  batch: 4  loss: 0.08422595\n",
      "epoch: 85  batch: 5  loss: 0.11773868\n",
      "epoch: 85  batch: 6  loss: 0.09338062\n",
      "epoch: 85  batch: 7  loss: 0.07596812\n",
      "epoch: 85  batch: 8  loss: 0.09865522\n",
      "epoch: 85  batch: 9  loss: 0.08682908\n",
      "epoch: 85  batch: 10  loss: 0.08962027\n",
      "epoch: 85  batch: 11  loss: 0.10745769\n",
      "epoch: 85  batch: 12  loss: 0.11866440\n",
      "epoch: 85  batch: 13  loss: 0.06377760\n",
      "epoch: 85  batch: 14  loss: 0.07613581\n",
      "epoch: 85  batch: 15  loss: 0.08249013\n",
      "epoch: 85  batch: 16  loss: 0.10100818\n",
      "epoch: 85  batch: 17  loss: 0.05438292\n",
      "epoch: 85  batch: 18  loss: 0.09021583\n",
      "epoch: 85  batch: 19  loss: 0.07247456\n",
      "epoch: 85  batch: 20  loss: 0.11325901\n",
      "epoch: 85  batch: 21  loss: 0.04968460\n",
      "epoch: 85  batch: 22  loss: 0.08104131\n",
      "epoch: 85  batch: 23  loss: 0.06537383\n",
      "epoch: 85  batch: 24  loss: 0.12676942\n",
      "epoch: 85  batch: 25  loss: 0.05457998\n",
      "epoch: 85  batch: 26  loss: 0.09013246\n",
      "epoch: 85  batch: 27  loss: 0.07059299\n",
      "epoch: 85  batch: 28  loss: 0.07333772\n",
      "epoch: 85  batch: 29  loss: 0.07161381\n",
      "epoch: 85  batch: 30  loss: 0.04888366\n",
      "epoch: 85  batch: 31  loss: 0.13386349\n",
      "epoch: 85  batch: 32  loss: 0.10419082\n",
      "epoch: 85  batch: 33  loss: 0.07162692\n",
      "epoch: 85  batch: 34  loss: 0.08529183\n",
      "epoch: 85  batch: 35  loss: 0.10049086\n",
      "epoch: 85  batch: 36  loss: 0.07377031\n",
      "epoch: 85  batch: 37  loss: 0.08817609\n",
      "epoch: 85  batch: 38  loss: 0.07597344\n",
      "epoch: 85  batch: 39  loss: 0.09326521\n",
      "epoch: 85  batch: 40  loss: 0.06403732\n",
      "epoch: 85  batch: 41  loss: 0.07425092\n",
      "epoch: 85  batch: 42  loss: 0.07827521\n",
      "epoch: 85  batch: 43  loss: 0.06111724\n",
      "epoch: 85  batch: 44  loss: 0.11981351\n",
      "epoch: 85  batch: 45  loss: 0.07705107\n",
      "epoch: 85  batch: 46  loss: 0.09582082\n",
      "epoch: 85  batch: 47  loss: 0.08262867\n",
      "epoch: 85  batch: 48  loss: 0.06861588\n",
      "epoch: 85  batch: 49  loss: 0.09219427\n",
      "epoch: 85  batch: 50  loss: 0.07682064\n",
      "epoch: 85  batch: 51  loss: 0.08187351\n",
      "epoch: 85  batch: 52  loss: 0.10270648\n",
      "epoch: 85  batch: 53  loss: 0.07809608\n",
      "epoch: 85  batch: 54  loss: 0.07502685\n",
      "epoch: 85  batch: 55  loss: 0.08632366\n",
      "epoch: 85  batch: 56  loss: 0.10405260\n",
      "epoch: 85  batch: 57  loss: 0.09600729\n",
      "epoch: 85  batch: 58  loss: 0.05840597\n",
      "epoch: 85  batch: 59  loss: 0.06869946\n",
      "epoch: 85  batch: 60  loss: 0.09697020\n",
      "epoch: 85  batch: 61  loss: 0.09113482\n",
      "epoch: 85  batch: 62  loss: 0.07289710\n",
      "epoch: 85  batch: 63  loss: 0.06041412\n",
      "epoch: 85  batch: 64  loss: 0.08960451\n",
      "epoch: 85  batch: 65  loss: 0.07480722\n",
      "epoch: 85  batch: 66  loss: 0.04164810\n",
      "epoch: 85  batch: 67  loss: 0.07178419\n",
      "epoch: 85  batch: 68  loss: 0.07582461\n",
      "epoch: 85  batch: 69  loss: 0.05668117\n",
      "epoch: 85  batch: 70  loss: 0.07609104\n",
      "epoch: 85  batch: 71  loss: 0.12928267\n",
      "epoch: 85  batch: 72  loss: 0.06641262\n",
      "epoch: 85  batch: 73  loss: 0.05466907\n",
      "epoch: 85  batch: 74  loss: 0.06265276\n",
      "epoch: 85  batch: 75  loss: 0.07856956\n",
      "epoch: 85  batch: 76  loss: 0.08667330\n",
      "epoch: 85  batch: 77  loss: 0.08032254\n",
      "epoch: 85  batch: 78  loss: 0.08768907\n",
      "epoch: 85  batch: 79  loss: 0.09841907\n",
      "epoch: 85  batch: 80  loss: 0.10018636\n",
      "epoch: 85  batch: 81  loss: 0.04964218\n",
      "epoch: 85  batch: 82  loss: 0.06839015\n",
      "epoch: 85  batch: 83  loss: 0.10593741\n",
      "epoch: 85  batch: 84  loss: 0.08381367\n",
      "epoch: 85  batch: 85  loss: 0.07669368\n",
      "epoch: 85  batch: 86  loss: 0.07384048\n",
      "epoch: 85  batch: 87  loss: 0.11726902\n",
      "epoch: 86  batch: 1  loss: 0.09869738\n",
      "epoch: 86  batch: 2  loss: 0.10436424\n",
      "epoch: 86  batch: 3  loss: 0.09297823\n",
      "epoch: 86  batch: 4  loss: 0.06208876\n",
      "epoch: 86  batch: 5  loss: 0.09178945\n",
      "epoch: 86  batch: 6  loss: 0.06552599\n",
      "epoch: 86  batch: 7  loss: 0.08894017\n",
      "epoch: 86  batch: 8  loss: 0.07700850\n",
      "epoch: 86  batch: 9  loss: 0.07258173\n",
      "epoch: 86  batch: 10  loss: 0.07433965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 86  batch: 11  loss: 0.08567254\n",
      "epoch: 86  batch: 12  loss: 0.05730542\n",
      "epoch: 86  batch: 13  loss: 0.08904431\n",
      "epoch: 86  batch: 14  loss: 0.12214532\n",
      "epoch: 86  batch: 15  loss: 0.09146579\n",
      "epoch: 86  batch: 16  loss: 0.07743473\n",
      "epoch: 86  batch: 17  loss: 0.07281091\n",
      "epoch: 86  batch: 18  loss: 0.06510076\n",
      "epoch: 86  batch: 19  loss: 0.08505138\n",
      "epoch: 86  batch: 20  loss: 0.08609287\n",
      "epoch: 86  batch: 21  loss: 0.10241891\n",
      "epoch: 86  batch: 22  loss: 0.11018687\n",
      "epoch: 86  batch: 23  loss: 0.07071511\n",
      "epoch: 86  batch: 24  loss: 0.06856364\n",
      "epoch: 86  batch: 25  loss: 0.07511953\n",
      "epoch: 86  batch: 26  loss: 0.07078826\n",
      "epoch: 86  batch: 27  loss: 0.05558997\n",
      "epoch: 86  batch: 28  loss: 0.09197737\n",
      "epoch: 86  batch: 29  loss: 0.06781463\n",
      "epoch: 86  batch: 30  loss: 0.09356483\n",
      "epoch: 86  batch: 31  loss: 0.09751082\n",
      "epoch: 86  batch: 32  loss: 0.06020821\n",
      "epoch: 86  batch: 33  loss: 0.05442505\n",
      "epoch: 86  batch: 34  loss: 0.07493857\n",
      "epoch: 86  batch: 35  loss: 0.07707474\n",
      "epoch: 86  batch: 36  loss: 0.08215244\n",
      "epoch: 86  batch: 37  loss: 0.07058080\n",
      "epoch: 86  batch: 38  loss: 0.10655624\n",
      "epoch: 86  batch: 39  loss: 0.05498011\n",
      "epoch: 86  batch: 40  loss: 0.09776715\n",
      "epoch: 86  batch: 41  loss: 0.08012561\n",
      "epoch: 86  batch: 42  loss: 0.06409112\n",
      "epoch: 86  batch: 43  loss: 0.11147939\n",
      "epoch: 86  batch: 44  loss: 0.07932907\n",
      "epoch: 86  batch: 45  loss: 0.10921225\n",
      "epoch: 86  batch: 46  loss: 0.10194422\n",
      "epoch: 86  batch: 47  loss: 0.11907846\n",
      "epoch: 86  batch: 48  loss: 0.06475110\n",
      "epoch: 86  batch: 49  loss: 0.07994304\n",
      "epoch: 86  batch: 50  loss: 0.05880833\n",
      "epoch: 86  batch: 51  loss: 0.09782843\n",
      "epoch: 86  batch: 52  loss: 0.12626487\n",
      "epoch: 86  batch: 53  loss: 0.10183122\n",
      "epoch: 86  batch: 54  loss: 0.07900851\n",
      "epoch: 86  batch: 55  loss: 0.09120294\n",
      "epoch: 86  batch: 56  loss: 0.07571284\n",
      "epoch: 86  batch: 57  loss: 0.11715869\n",
      "epoch: 86  batch: 58  loss: 0.10443766\n",
      "epoch: 86  batch: 59  loss: 0.08437501\n",
      "epoch: 86  batch: 60  loss: 0.08935431\n",
      "epoch: 86  batch: 61  loss: 0.10966685\n",
      "epoch: 86  batch: 62  loss: 0.08471160\n",
      "epoch: 86  batch: 63  loss: 0.07833558\n",
      "epoch: 86  batch: 64  loss: 0.08425708\n",
      "epoch: 86  batch: 65  loss: 0.05634259\n",
      "epoch: 86  batch: 66  loss: 0.08740509\n",
      "epoch: 86  batch: 67  loss: 0.05112894\n",
      "epoch: 86  batch: 68  loss: 0.07241519\n",
      "epoch: 86  batch: 69  loss: 0.13154757\n",
      "epoch: 86  batch: 70  loss: 0.07469635\n",
      "epoch: 86  batch: 71  loss: 0.07376233\n",
      "epoch: 86  batch: 72  loss: 0.06407152\n",
      "epoch: 86  batch: 73  loss: 0.06561972\n",
      "epoch: 86  batch: 74  loss: 0.09350151\n",
      "epoch: 86  batch: 75  loss: 0.10790390\n",
      "epoch: 86  batch: 76  loss: 0.06552117\n",
      "epoch: 86  batch: 77  loss: 0.07808419\n",
      "epoch: 86  batch: 78  loss: 0.07701688\n",
      "epoch: 86  batch: 79  loss: 0.05786114\n",
      "epoch: 86  batch: 80  loss: 0.08175585\n",
      "epoch: 86  batch: 81  loss: 0.07859682\n",
      "epoch: 86  batch: 82  loss: 0.06235437\n",
      "epoch: 86  batch: 83  loss: 0.07142457\n",
      "epoch: 86  batch: 84  loss: 0.07059484\n",
      "epoch: 86  batch: 85  loss: 0.07007789\n",
      "epoch: 86  batch: 86  loss: 0.07382561\n",
      "epoch: 86  batch: 87  loss: 0.06159506\n",
      "epoch: 87  batch: 1  loss: 0.06980608\n",
      "epoch: 87  batch: 2  loss: 0.08280604\n",
      "epoch: 87  batch: 3  loss: 0.07496885\n",
      "epoch: 87  batch: 4  loss: 0.08698526\n",
      "epoch: 87  batch: 5  loss: 0.08907392\n",
      "epoch: 87  batch: 6  loss: 0.07590891\n",
      "epoch: 87  batch: 7  loss: 0.10788397\n",
      "epoch: 87  batch: 8  loss: 0.07115351\n",
      "epoch: 87  batch: 9  loss: 0.12927029\n",
      "epoch: 87  batch: 10  loss: 0.08342172\n",
      "epoch: 87  batch: 11  loss: 0.10231109\n",
      "epoch: 87  batch: 12  loss: 0.09694235\n",
      "epoch: 87  batch: 13  loss: 0.07325219\n",
      "epoch: 87  batch: 14  loss: 0.08668999\n",
      "epoch: 87  batch: 15  loss: 0.11967286\n",
      "epoch: 87  batch: 16  loss: 0.10079902\n",
      "epoch: 87  batch: 17  loss: 0.05909866\n",
      "epoch: 87  batch: 18  loss: 0.11030655\n",
      "epoch: 87  batch: 19  loss: 0.10047348\n",
      "epoch: 87  batch: 20  loss: 0.09833174\n",
      "epoch: 87  batch: 21  loss: 0.08743364\n",
      "epoch: 87  batch: 22  loss: 0.09444368\n",
      "epoch: 87  batch: 23  loss: 0.07423573\n",
      "epoch: 87  batch: 24  loss: 0.08336017\n",
      "epoch: 87  batch: 25  loss: 0.06272916\n",
      "epoch: 87  batch: 26  loss: 0.06711569\n",
      "epoch: 87  batch: 27  loss: 0.06404498\n",
      "epoch: 87  batch: 28  loss: 0.10736848\n",
      "epoch: 87  batch: 29  loss: 0.08299939\n",
      "epoch: 87  batch: 30  loss: 0.09356226\n",
      "epoch: 87  batch: 31  loss: 0.06588601\n",
      "epoch: 87  batch: 32  loss: 0.11485226\n",
      "epoch: 87  batch: 33  loss: 0.10830951\n",
      "epoch: 87  batch: 34  loss: 0.07077131\n",
      "epoch: 87  batch: 35  loss: 0.06929141\n",
      "epoch: 87  batch: 36  loss: 0.08183621\n",
      "epoch: 87  batch: 37  loss: 0.06259290\n",
      "epoch: 87  batch: 38  loss: 0.09874344\n",
      "epoch: 87  batch: 39  loss: 0.06130281\n",
      "epoch: 87  batch: 40  loss: 0.06951927\n",
      "epoch: 87  batch: 41  loss: 0.08051410\n",
      "epoch: 87  batch: 42  loss: 0.08784394\n",
      "epoch: 87  batch: 43  loss: 0.07848166\n",
      "epoch: 87  batch: 44  loss: 0.10562526\n",
      "epoch: 87  batch: 45  loss: 0.07855764\n",
      "epoch: 87  batch: 46  loss: 0.12570389\n",
      "epoch: 87  batch: 47  loss: 0.09214758\n",
      "epoch: 87  batch: 48  loss: 0.11044314\n",
      "epoch: 87  batch: 49  loss: 0.07721743\n",
      "epoch: 87  batch: 50  loss: 0.11944158\n",
      "epoch: 87  batch: 51  loss: 0.07700113\n",
      "epoch: 87  batch: 52  loss: 0.07661693\n",
      "epoch: 87  batch: 53  loss: 0.07531675\n",
      "epoch: 87  batch: 54  loss: 0.07518424\n",
      "epoch: 87  batch: 55  loss: 0.06002911\n",
      "epoch: 87  batch: 56  loss: 0.09523774\n",
      "epoch: 87  batch: 57  loss: 0.07865863\n",
      "epoch: 87  batch: 58  loss: 0.06084234\n",
      "epoch: 87  batch: 59  loss: 0.08696878\n",
      "epoch: 87  batch: 60  loss: 0.06432007\n",
      "epoch: 87  batch: 61  loss: 0.07684919\n",
      "epoch: 87  batch: 62  loss: 0.07257117\n",
      "epoch: 87  batch: 63  loss: 0.09752997\n",
      "epoch: 87  batch: 64  loss: 0.08657292\n",
      "epoch: 87  batch: 65  loss: 0.07020251\n",
      "epoch: 87  batch: 66  loss: 0.06035706\n",
      "epoch: 87  batch: 67  loss: 0.08250140\n",
      "epoch: 87  batch: 68  loss: 0.06684363\n",
      "epoch: 87  batch: 69  loss: 0.08587637\n",
      "epoch: 87  batch: 70  loss: 0.06040015\n",
      "epoch: 87  batch: 71  loss: 0.08885542\n",
      "epoch: 87  batch: 72  loss: 0.08053910\n",
      "epoch: 87  batch: 73  loss: 0.06197000\n",
      "epoch: 87  batch: 74  loss: 0.11251798\n",
      "epoch: 87  batch: 75  loss: 0.11576783\n",
      "epoch: 87  batch: 76  loss: 0.11389280\n",
      "epoch: 87  batch: 77  loss: 0.05967485\n",
      "epoch: 87  batch: 78  loss: 0.04949114\n",
      "epoch: 87  batch: 79  loss: 0.09862623\n",
      "epoch: 87  batch: 80  loss: 0.09462529\n",
      "epoch: 87  batch: 81  loss: 0.10746478\n",
      "epoch: 87  batch: 82  loss: 0.06022753\n",
      "epoch: 87  batch: 83  loss: 0.06792378\n",
      "epoch: 87  batch: 84  loss: 0.06679956\n",
      "epoch: 87  batch: 85  loss: 0.10856305\n",
      "epoch: 87  batch: 86  loss: 0.08650468\n",
      "epoch: 87  batch: 87  loss: 0.10142335\n",
      "epoch: 88  batch: 1  loss: 0.05999595\n",
      "epoch: 88  batch: 2  loss: 0.06164293\n",
      "epoch: 88  batch: 3  loss: 0.09123416\n",
      "epoch: 88  batch: 4  loss: 0.08174318\n",
      "epoch: 88  batch: 5  loss: 0.11032685\n",
      "epoch: 88  batch: 6  loss: 0.07540824\n",
      "epoch: 88  batch: 7  loss: 0.08178130\n",
      "epoch: 88  batch: 8  loss: 0.11394385\n",
      "epoch: 88  batch: 9  loss: 0.05514752\n",
      "epoch: 88  batch: 10  loss: 0.11454116\n",
      "epoch: 88  batch: 11  loss: 0.08129953\n",
      "epoch: 88  batch: 12  loss: 0.05864840\n",
      "epoch: 88  batch: 13  loss: 0.07634996\n",
      "epoch: 88  batch: 14  loss: 0.08888509\n",
      "epoch: 88  batch: 15  loss: 0.11969209\n",
      "epoch: 88  batch: 16  loss: 0.06979671\n",
      "epoch: 88  batch: 17  loss: 0.07939004\n",
      "epoch: 88  batch: 18  loss: 0.06917580\n",
      "epoch: 88  batch: 19  loss: 0.06855447\n",
      "epoch: 88  batch: 20  loss: 0.07904525\n",
      "epoch: 88  batch: 21  loss: 0.10270885\n",
      "epoch: 88  batch: 22  loss: 0.10882813\n",
      "epoch: 88  batch: 23  loss: 0.05761562\n",
      "epoch: 88  batch: 24  loss: 0.11303334\n",
      "epoch: 88  batch: 25  loss: 0.10129146\n",
      "epoch: 88  batch: 26  loss: 0.10358940\n",
      "epoch: 88  batch: 27  loss: 0.08028649\n",
      "epoch: 88  batch: 28  loss: 0.07738767\n",
      "epoch: 88  batch: 29  loss: 0.10334397\n",
      "epoch: 88  batch: 30  loss: 0.07976040\n",
      "epoch: 88  batch: 31  loss: 0.05130297\n",
      "epoch: 88  batch: 32  loss: 0.11227031\n",
      "epoch: 88  batch: 33  loss: 0.06912553\n",
      "epoch: 88  batch: 34  loss: 0.05777592\n",
      "epoch: 88  batch: 35  loss: 0.08410738\n",
      "epoch: 88  batch: 36  loss: 0.10031734\n",
      "epoch: 88  batch: 37  loss: 0.06343836\n",
      "epoch: 88  batch: 38  loss: 0.07181168\n",
      "epoch: 88  batch: 39  loss: 0.07983556\n",
      "epoch: 88  batch: 40  loss: 0.08053319\n",
      "epoch: 88  batch: 41  loss: 0.06596611\n",
      "epoch: 88  batch: 42  loss: 0.08103878\n",
      "epoch: 88  batch: 43  loss: 0.06599176\n",
      "epoch: 88  batch: 44  loss: 0.07871973\n",
      "epoch: 88  batch: 45  loss: 0.06127651\n",
      "epoch: 88  batch: 46  loss: 0.08302725\n",
      "epoch: 88  batch: 47  loss: 0.07187352\n",
      "epoch: 88  batch: 48  loss: 0.09057796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88  batch: 49  loss: 0.09307534\n",
      "epoch: 88  batch: 50  loss: 0.04801597\n",
      "epoch: 88  batch: 51  loss: 0.06729885\n",
      "epoch: 88  batch: 52  loss: 0.06546681\n",
      "epoch: 88  batch: 53  loss: 0.11273990\n",
      "epoch: 88  batch: 54  loss: 0.08647896\n",
      "epoch: 88  batch: 55  loss: 0.07736731\n",
      "epoch: 88  batch: 56  loss: 0.14079043\n",
      "epoch: 88  batch: 57  loss: 0.10876540\n",
      "epoch: 88  batch: 58  loss: 0.09184945\n",
      "epoch: 88  batch: 59  loss: 0.05871923\n",
      "epoch: 88  batch: 60  loss: 0.10101823\n",
      "epoch: 88  batch: 61  loss: 0.11200195\n",
      "epoch: 88  batch: 62  loss: 0.08923878\n",
      "epoch: 88  batch: 63  loss: 0.08801086\n",
      "epoch: 88  batch: 64  loss: 0.11417091\n",
      "epoch: 88  batch: 65  loss: 0.11190377\n",
      "epoch: 88  batch: 66  loss: 0.06716182\n",
      "epoch: 88  batch: 67  loss: 0.10746664\n",
      "epoch: 88  batch: 68  loss: 0.05919110\n",
      "epoch: 88  batch: 69  loss: 0.08899751\n",
      "epoch: 88  batch: 70  loss: 0.08841038\n",
      "epoch: 88  batch: 71  loss: 0.07642398\n",
      "epoch: 88  batch: 72  loss: 0.07455534\n",
      "epoch: 88  batch: 73  loss: 0.09516401\n",
      "epoch: 88  batch: 74  loss: 0.08792443\n",
      "epoch: 88  batch: 75  loss: 0.09374691\n",
      "epoch: 88  batch: 76  loss: 0.08105209\n",
      "epoch: 88  batch: 77  loss: 0.06884145\n",
      "epoch: 88  batch: 78  loss: 0.07256793\n",
      "epoch: 88  batch: 79  loss: 0.08895781\n",
      "epoch: 88  batch: 80  loss: 0.09786168\n",
      "epoch: 88  batch: 81  loss: 0.07170410\n",
      "epoch: 88  batch: 82  loss: 0.09071571\n",
      "epoch: 88  batch: 83  loss: 0.11159260\n",
      "epoch: 88  batch: 84  loss: 0.08832390\n",
      "epoch: 88  batch: 85  loss: 0.07706334\n",
      "epoch: 88  batch: 86  loss: 0.06480365\n",
      "epoch: 88  batch: 87  loss: 0.08525235\n",
      "epoch: 89  batch: 1  loss: 0.08058905\n",
      "epoch: 89  batch: 2  loss: 0.10078477\n",
      "epoch: 89  batch: 3  loss: 0.07929944\n",
      "epoch: 89  batch: 4  loss: 0.05928383\n",
      "epoch: 89  batch: 5  loss: 0.07632023\n",
      "epoch: 89  batch: 6  loss: 0.06921541\n",
      "epoch: 89  batch: 7  loss: 0.09892564\n",
      "epoch: 89  batch: 8  loss: 0.06721878\n",
      "epoch: 89  batch: 9  loss: 0.10693984\n",
      "epoch: 89  batch: 10  loss: 0.11361004\n",
      "epoch: 89  batch: 11  loss: 0.08326655\n",
      "epoch: 89  batch: 12  loss: 0.12445686\n",
      "epoch: 89  batch: 13  loss: 0.09576053\n",
      "epoch: 89  batch: 14  loss: 0.08565231\n",
      "epoch: 89  batch: 15  loss: 0.06821653\n",
      "epoch: 89  batch: 16  loss: 0.06981516\n",
      "epoch: 89  batch: 17  loss: 0.12570758\n",
      "epoch: 89  batch: 18  loss: 0.09438448\n",
      "epoch: 89  batch: 19  loss: 0.08699262\n",
      "epoch: 89  batch: 20  loss: 0.10706980\n",
      "epoch: 89  batch: 21  loss: 0.07413030\n",
      "epoch: 89  batch: 22  loss: 0.07597720\n",
      "epoch: 89  batch: 23  loss: 0.09527625\n",
      "epoch: 89  batch: 24  loss: 0.06664791\n",
      "epoch: 89  batch: 25  loss: 0.06185503\n",
      "epoch: 89  batch: 26  loss: 0.10784657\n",
      "epoch: 89  batch: 27  loss: 0.09051108\n",
      "epoch: 89  batch: 28  loss: 0.05158463\n",
      "epoch: 89  batch: 29  loss: 0.08591649\n",
      "epoch: 89  batch: 30  loss: 0.09052658\n",
      "epoch: 89  batch: 31  loss: 0.05795758\n",
      "epoch: 89  batch: 32  loss: 0.07502750\n",
      "epoch: 89  batch: 33  loss: 0.08852144\n",
      "epoch: 89  batch: 34  loss: 0.06970890\n",
      "epoch: 89  batch: 35  loss: 0.08751480\n",
      "epoch: 89  batch: 36  loss: 0.06530111\n",
      "epoch: 89  batch: 37  loss: 0.09783935\n",
      "epoch: 89  batch: 38  loss: 0.10282909\n",
      "epoch: 89  batch: 39  loss: 0.08227638\n",
      "epoch: 89  batch: 40  loss: 0.06776731\n",
      "epoch: 89  batch: 41  loss: 0.09863991\n",
      "epoch: 89  batch: 42  loss: 0.06147670\n",
      "epoch: 89  batch: 43  loss: 0.08087046\n",
      "epoch: 89  batch: 44  loss: 0.06151826\n",
      "epoch: 89  batch: 45  loss: 0.05339875\n",
      "epoch: 89  batch: 46  loss: 0.08856452\n",
      "epoch: 89  batch: 47  loss: 0.06750280\n",
      "epoch: 89  batch: 48  loss: 0.06597636\n",
      "epoch: 89  batch: 49  loss: 0.10970213\n",
      "epoch: 89  batch: 50  loss: 0.09663428\n",
      "epoch: 89  batch: 51  loss: 0.10314216\n",
      "epoch: 89  batch: 52  loss: 0.07458978\n",
      "epoch: 89  batch: 53  loss: 0.08894432\n",
      "epoch: 89  batch: 54  loss: 0.07133093\n",
      "epoch: 89  batch: 55  loss: 0.08132954\n",
      "epoch: 89  batch: 56  loss: 0.07193645\n",
      "epoch: 89  batch: 57  loss: 0.07581660\n",
      "epoch: 89  batch: 58  loss: 0.06028367\n",
      "epoch: 89  batch: 59  loss: 0.07402767\n",
      "epoch: 89  batch: 60  loss: 0.07275897\n",
      "epoch: 89  batch: 61  loss: 0.14303532\n",
      "epoch: 89  batch: 62  loss: 0.09247731\n",
      "epoch: 89  batch: 63  loss: 0.06740647\n",
      "epoch: 89  batch: 64  loss: 0.07811512\n",
      "epoch: 89  batch: 65  loss: 0.09701391\n",
      "epoch: 89  batch: 66  loss: 0.08079418\n",
      "epoch: 89  batch: 67  loss: 0.06755557\n",
      "epoch: 89  batch: 68  loss: 0.07930159\n",
      "epoch: 89  batch: 69  loss: 0.07187391\n",
      "epoch: 89  batch: 70  loss: 0.07354511\n",
      "epoch: 89  batch: 71  loss: 0.09211784\n",
      "epoch: 89  batch: 72  loss: 0.08506484\n",
      "epoch: 89  batch: 73  loss: 0.07497559\n",
      "epoch: 89  batch: 74  loss: 0.12118803\n",
      "epoch: 89  batch: 75  loss: 0.07952333\n",
      "epoch: 89  batch: 76  loss: 0.13679050\n",
      "epoch: 89  batch: 77  loss: 0.09962939\n",
      "epoch: 89  batch: 78  loss: 0.07993733\n",
      "epoch: 89  batch: 79  loss: 0.06850737\n",
      "epoch: 89  batch: 80  loss: 0.09934255\n",
      "epoch: 89  batch: 81  loss: 0.04729561\n",
      "epoch: 89  batch: 82  loss: 0.11722272\n",
      "epoch: 89  batch: 83  loss: 0.10995127\n",
      "epoch: 89  batch: 84  loss: 0.08688796\n",
      "epoch: 89  batch: 85  loss: 0.09294011\n",
      "epoch: 89  batch: 86  loss: 0.08059973\n",
      "epoch: 89  batch: 87  loss: 0.06567391\n",
      "epoch: 90  batch: 1  loss: 0.08025648\n",
      "epoch: 90  batch: 2  loss: 0.05469045\n",
      "epoch: 90  batch: 3  loss: 0.07242200\n",
      "epoch: 90  batch: 4  loss: 0.08896966\n",
      "epoch: 90  batch: 5  loss: 0.08893563\n",
      "epoch: 90  batch: 6  loss: 0.05972337\n",
      "epoch: 90  batch: 7  loss: 0.08990619\n",
      "epoch: 90  batch: 8  loss: 0.05816403\n",
      "epoch: 90  batch: 9  loss: 0.06415088\n",
      "epoch: 90  batch: 10  loss: 0.08761940\n",
      "epoch: 90  batch: 11  loss: 0.09176549\n",
      "epoch: 90  batch: 12  loss: 0.06457809\n",
      "epoch: 90  batch: 13  loss: 0.06353774\n",
      "epoch: 90  batch: 14  loss: 0.10847309\n",
      "epoch: 90  batch: 15  loss: 0.06970116\n",
      "epoch: 90  batch: 16  loss: 0.08061858\n",
      "epoch: 90  batch: 17  loss: 0.07597313\n",
      "epoch: 90  batch: 18  loss: 0.05679289\n",
      "epoch: 90  batch: 19  loss: 0.11951035\n",
      "epoch: 90  batch: 20  loss: 0.07548969\n",
      "epoch: 90  batch: 21  loss: 0.09654889\n",
      "epoch: 90  batch: 22  loss: 0.13318709\n",
      "epoch: 90  batch: 23  loss: 0.09458223\n",
      "epoch: 90  batch: 24  loss: 0.06497895\n",
      "epoch: 90  batch: 25  loss: 0.11130106\n",
      "epoch: 90  batch: 26  loss: 0.07557358\n",
      "epoch: 90  batch: 27  loss: 0.12100194\n",
      "epoch: 90  batch: 28  loss: 0.08328751\n",
      "epoch: 90  batch: 29  loss: 0.06599830\n",
      "epoch: 90  batch: 30  loss: 0.11204463\n",
      "epoch: 90  batch: 31  loss: 0.08791880\n",
      "epoch: 90  batch: 32  loss: 0.08402798\n",
      "epoch: 90  batch: 33  loss: 0.09723391\n",
      "epoch: 90  batch: 34  loss: 0.06024587\n",
      "epoch: 90  batch: 35  loss: 0.16026872\n",
      "epoch: 90  batch: 36  loss: 0.06655917\n",
      "epoch: 90  batch: 37  loss: 0.16018337\n",
      "epoch: 90  batch: 38  loss: 0.10310073\n",
      "epoch: 90  batch: 39  loss: 0.08058856\n",
      "epoch: 90  batch: 40  loss: 0.08961193\n",
      "epoch: 90  batch: 41  loss: 0.07035737\n",
      "epoch: 90  batch: 42  loss: 0.08949703\n",
      "epoch: 90  batch: 43  loss: 0.07235607\n",
      "epoch: 90  batch: 44  loss: 0.06904520\n",
      "epoch: 90  batch: 45  loss: 0.07508830\n",
      "epoch: 90  batch: 46  loss: 0.07366613\n",
      "epoch: 90  batch: 47  loss: 0.13503784\n",
      "epoch: 90  batch: 48  loss: 0.06669068\n",
      "epoch: 90  batch: 49  loss: 0.08670192\n",
      "epoch: 90  batch: 50  loss: 0.06502674\n",
      "epoch: 90  batch: 51  loss: 0.10822593\n",
      "epoch: 90  batch: 52  loss: 0.09866095\n",
      "epoch: 90  batch: 53  loss: 0.08345577\n",
      "epoch: 90  batch: 54  loss: 0.06418440\n",
      "epoch: 90  batch: 55  loss: 0.06524734\n",
      "epoch: 90  batch: 56  loss: 0.05884313\n",
      "epoch: 90  batch: 57  loss: 0.13340484\n",
      "epoch: 90  batch: 58  loss: 0.07623686\n",
      "epoch: 90  batch: 59  loss: 0.07487441\n",
      "epoch: 90  batch: 60  loss: 0.10202345\n",
      "epoch: 90  batch: 61  loss: 0.07325615\n",
      "epoch: 90  batch: 62  loss: 0.07463761\n",
      "epoch: 90  batch: 63  loss: 0.05732628\n",
      "epoch: 90  batch: 64  loss: 0.07207245\n",
      "epoch: 90  batch: 65  loss: 0.11745965\n",
      "epoch: 90  batch: 66  loss: 0.11588927\n",
      "epoch: 90  batch: 67  loss: 0.09910811\n",
      "epoch: 90  batch: 68  loss: 0.05342084\n",
      "epoch: 90  batch: 69  loss: 0.12747383\n",
      "epoch: 90  batch: 70  loss: 0.05499575\n",
      "epoch: 90  batch: 71  loss: 0.08663935\n",
      "epoch: 90  batch: 72  loss: 0.05308785\n",
      "epoch: 90  batch: 73  loss: 0.05981659\n",
      "epoch: 90  batch: 74  loss: 0.09544706\n",
      "epoch: 90  batch: 75  loss: 0.07563545\n",
      "epoch: 90  batch: 76  loss: 0.09030169\n",
      "epoch: 90  batch: 77  loss: 0.06099282\n",
      "epoch: 90  batch: 78  loss: 0.09818798\n",
      "epoch: 90  batch: 79  loss: 0.07043470\n",
      "epoch: 90  batch: 80  loss: 0.06913869\n",
      "epoch: 90  batch: 81  loss: 0.05810728\n",
      "epoch: 90  batch: 82  loss: 0.10204379\n",
      "epoch: 90  batch: 83  loss: 0.06409065\n",
      "epoch: 90  batch: 84  loss: 0.06097031\n",
      "epoch: 90  batch: 85  loss: 0.08268958\n",
      "epoch: 90  batch: 86  loss: 0.13362068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 90  batch: 87  loss: 0.12826806\n",
      "epoch: 91  batch: 1  loss: 0.16787769\n",
      "epoch: 91  batch: 2  loss: 0.10140710\n",
      "epoch: 91  batch: 3  loss: 0.06096653\n",
      "epoch: 91  batch: 4  loss: 0.06806222\n",
      "epoch: 91  batch: 5  loss: 0.06496518\n",
      "epoch: 91  batch: 6  loss: 0.06348873\n",
      "epoch: 91  batch: 7  loss: 0.10182127\n",
      "epoch: 91  batch: 8  loss: 0.14515510\n",
      "epoch: 91  batch: 9  loss: 0.12048930\n",
      "epoch: 91  batch: 10  loss: 0.12695204\n",
      "epoch: 91  batch: 11  loss: 0.07295365\n",
      "epoch: 91  batch: 12  loss: 0.05783412\n",
      "epoch: 91  batch: 13  loss: 0.08114716\n",
      "epoch: 91  batch: 14  loss: 0.07652646\n",
      "epoch: 91  batch: 15  loss: 0.07659130\n",
      "epoch: 91  batch: 16  loss: 0.07122618\n",
      "epoch: 91  batch: 17  loss: 0.06188985\n",
      "epoch: 91  batch: 18  loss: 0.09169506\n",
      "epoch: 91  batch: 19  loss: 0.06249136\n",
      "epoch: 91  batch: 20  loss: 0.07581171\n",
      "epoch: 91  batch: 21  loss: 0.06376503\n",
      "epoch: 91  batch: 22  loss: 0.10614585\n",
      "epoch: 91  batch: 23  loss: 0.10401801\n",
      "epoch: 91  batch: 24  loss: 0.11241277\n",
      "epoch: 91  batch: 25  loss: 0.09836918\n",
      "epoch: 91  batch: 26  loss: 0.04946996\n",
      "epoch: 91  batch: 27  loss: 0.07562724\n",
      "epoch: 91  batch: 28  loss: 0.12267623\n",
      "epoch: 91  batch: 29  loss: 0.08858503\n",
      "epoch: 91  batch: 30  loss: 0.09363736\n",
      "epoch: 91  batch: 31  loss: 0.12154583\n",
      "epoch: 91  batch: 32  loss: 0.05793547\n",
      "epoch: 91  batch: 33  loss: 0.06452107\n",
      "epoch: 91  batch: 34  loss: 0.06937061\n",
      "epoch: 91  batch: 35  loss: 0.07820911\n",
      "epoch: 91  batch: 36  loss: 0.06728287\n",
      "epoch: 91  batch: 37  loss: 0.08585422\n",
      "epoch: 91  batch: 38  loss: 0.08327676\n",
      "epoch: 91  batch: 39  loss: 0.07310591\n",
      "epoch: 91  batch: 40  loss: 0.11148942\n",
      "epoch: 91  batch: 41  loss: 0.06074650\n",
      "epoch: 91  batch: 42  loss: 0.09368464\n",
      "epoch: 91  batch: 43  loss: 0.08716660\n",
      "epoch: 91  batch: 44  loss: 0.10268582\n",
      "epoch: 91  batch: 45  loss: 0.07317021\n",
      "epoch: 91  batch: 46  loss: 0.07266589\n",
      "epoch: 91  batch: 47  loss: 0.07696778\n",
      "epoch: 91  batch: 48  loss: 0.06730828\n",
      "epoch: 91  batch: 49  loss: 0.06185865\n",
      "epoch: 91  batch: 50  loss: 0.08031322\n",
      "epoch: 91  batch: 51  loss: 0.05926739\n",
      "epoch: 91  batch: 52  loss: 0.08131459\n",
      "epoch: 91  batch: 53  loss: 0.07187602\n",
      "epoch: 91  batch: 54  loss: 0.07714186\n",
      "epoch: 91  batch: 55  loss: 0.11370599\n",
      "epoch: 91  batch: 56  loss: 0.07926482\n",
      "epoch: 91  batch: 57  loss: 0.11334039\n",
      "epoch: 91  batch: 58  loss: 0.05766680\n",
      "epoch: 91  batch: 59  loss: 0.08515456\n",
      "epoch: 91  batch: 60  loss: 0.07995085\n",
      "epoch: 91  batch: 61  loss: 0.07293210\n",
      "epoch: 91  batch: 62  loss: 0.07403670\n",
      "epoch: 91  batch: 63  loss: 0.07713280\n",
      "epoch: 91  batch: 64  loss: 0.07937418\n",
      "epoch: 91  batch: 65  loss: 0.06335628\n",
      "epoch: 91  batch: 66  loss: 0.10235420\n",
      "epoch: 91  batch: 67  loss: 0.09915520\n",
      "epoch: 91  batch: 68  loss: 0.07531676\n",
      "epoch: 91  batch: 69  loss: 0.05730756\n",
      "epoch: 91  batch: 70  loss: 0.10196673\n",
      "epoch: 91  batch: 71  loss: 0.08464759\n",
      "epoch: 91  batch: 72  loss: 0.09459034\n",
      "epoch: 91  batch: 73  loss: 0.06598771\n",
      "epoch: 91  batch: 74  loss: 0.05540443\n",
      "epoch: 91  batch: 75  loss: 0.08819722\n",
      "epoch: 91  batch: 76  loss: 0.12101103\n",
      "epoch: 91  batch: 77  loss: 0.05787655\n",
      "epoch: 91  batch: 78  loss: 0.12292030\n",
      "epoch: 91  batch: 79  loss: 0.06870591\n",
      "epoch: 91  batch: 80  loss: 0.10662305\n",
      "epoch: 91  batch: 81  loss: 0.11173345\n",
      "epoch: 91  batch: 82  loss: 0.05422549\n",
      "epoch: 91  batch: 83  loss: 0.08492149\n",
      "epoch: 91  batch: 84  loss: 0.10018222\n",
      "epoch: 91  batch: 85  loss: 0.10983313\n",
      "epoch: 91  batch: 86  loss: 0.04584579\n",
      "epoch: 91  batch: 87  loss: 0.07765601\n",
      "epoch: 92  batch: 1  loss: 0.06743287\n",
      "epoch: 92  batch: 2  loss: 0.07984394\n",
      "epoch: 92  batch: 3  loss: 0.07277532\n",
      "epoch: 92  batch: 4  loss: 0.08326749\n",
      "epoch: 92  batch: 5  loss: 0.07659400\n",
      "epoch: 92  batch: 6  loss: 0.07287910\n",
      "epoch: 92  batch: 7  loss: 0.07585298\n",
      "epoch: 92  batch: 8  loss: 0.08677619\n",
      "epoch: 92  batch: 9  loss: 0.07657244\n",
      "epoch: 92  batch: 10  loss: 0.07593569\n",
      "epoch: 92  batch: 11  loss: 0.10227542\n",
      "epoch: 92  batch: 12  loss: 0.06894974\n",
      "epoch: 92  batch: 13  loss: 0.07567686\n",
      "epoch: 92  batch: 14  loss: 0.07529814\n",
      "epoch: 92  batch: 15  loss: 0.08170018\n",
      "epoch: 92  batch: 16  loss: 0.06498785\n",
      "epoch: 92  batch: 17  loss: 0.07645768\n",
      "epoch: 92  batch: 18  loss: 0.07649185\n",
      "epoch: 92  batch: 19  loss: 0.10717484\n",
      "epoch: 92  batch: 20  loss: 0.07791493\n",
      "epoch: 92  batch: 21  loss: 0.07111190\n",
      "epoch: 92  batch: 22  loss: 0.05769064\n",
      "epoch: 92  batch: 23  loss: 0.05608034\n",
      "epoch: 92  batch: 24  loss: 0.07717872\n",
      "epoch: 92  batch: 25  loss: 0.06286234\n",
      "epoch: 92  batch: 26  loss: 0.09185084\n",
      "epoch: 92  batch: 27  loss: 0.10615721\n",
      "epoch: 92  batch: 28  loss: 0.11279351\n",
      "epoch: 92  batch: 29  loss: 0.06404710\n",
      "epoch: 92  batch: 30  loss: 0.06869521\n",
      "epoch: 92  batch: 31  loss: 0.06253437\n",
      "epoch: 92  batch: 32  loss: 0.08912567\n",
      "epoch: 92  batch: 33  loss: 0.05352100\n",
      "epoch: 92  batch: 34  loss: 0.09720922\n",
      "epoch: 92  batch: 35  loss: 0.12977652\n",
      "epoch: 92  batch: 36  loss: 0.06490086\n",
      "epoch: 92  batch: 37  loss: 0.08577598\n",
      "epoch: 92  batch: 38  loss: 0.13868862\n",
      "epoch: 92  batch: 39  loss: 0.07666252\n",
      "epoch: 92  batch: 40  loss: 0.08529872\n",
      "epoch: 92  batch: 41  loss: 0.07437530\n",
      "epoch: 92  batch: 42  loss: 0.05130196\n",
      "epoch: 92  batch: 43  loss: 0.05529292\n",
      "epoch: 92  batch: 44  loss: 0.10440447\n",
      "epoch: 92  batch: 45  loss: 0.07042291\n",
      "epoch: 92  batch: 46  loss: 0.07170441\n",
      "epoch: 92  batch: 47  loss: 0.10499801\n",
      "epoch: 92  batch: 48  loss: 0.06527742\n",
      "epoch: 92  batch: 49  loss: 0.08382346\n",
      "epoch: 92  batch: 50  loss: 0.09013066\n",
      "epoch: 92  batch: 51  loss: 0.09772317\n",
      "epoch: 92  batch: 52  loss: 0.08974103\n",
      "epoch: 92  batch: 53  loss: 0.04839059\n",
      "epoch: 92  batch: 54  loss: 0.07713519\n",
      "epoch: 92  batch: 55  loss: 0.05576862\n",
      "epoch: 92  batch: 56  loss: 0.09163029\n",
      "epoch: 92  batch: 57  loss: 0.06558484\n",
      "epoch: 92  batch: 58  loss: 0.08596566\n",
      "epoch: 92  batch: 59  loss: 0.06127995\n",
      "epoch: 92  batch: 60  loss: 0.10575944\n",
      "epoch: 92  batch: 61  loss: 0.07727469\n",
      "epoch: 92  batch: 62  loss: 0.10674814\n",
      "epoch: 92  batch: 63  loss: 0.06674556\n",
      "epoch: 92  batch: 64  loss: 0.06354743\n",
      "epoch: 92  batch: 65  loss: 0.10064461\n",
      "epoch: 92  batch: 66  loss: 0.06423483\n",
      "epoch: 92  batch: 67  loss: 0.06792423\n",
      "epoch: 92  batch: 68  loss: 0.07355940\n",
      "epoch: 92  batch: 69  loss: 0.08006356\n",
      "epoch: 92  batch: 70  loss: 0.07619321\n",
      "epoch: 92  batch: 71  loss: 0.08470730\n",
      "epoch: 92  batch: 72  loss: 0.05421094\n",
      "epoch: 92  batch: 73  loss: 0.06082997\n",
      "epoch: 92  batch: 74  loss: 0.07632539\n",
      "epoch: 92  batch: 75  loss: 0.08671667\n",
      "epoch: 92  batch: 76  loss: 0.08667840\n",
      "epoch: 92  batch: 77  loss: 0.06084921\n",
      "epoch: 92  batch: 78  loss: 0.11905860\n",
      "epoch: 92  batch: 79  loss: 0.17083433\n",
      "epoch: 92  batch: 80  loss: 0.06044428\n",
      "epoch: 92  batch: 81  loss: 0.05628851\n",
      "epoch: 92  batch: 82  loss: 0.11326571\n",
      "epoch: 92  batch: 83  loss: 0.07743599\n",
      "epoch: 92  batch: 84  loss: 0.14987008\n",
      "epoch: 92  batch: 85  loss: 0.08384757\n",
      "epoch: 92  batch: 86  loss: 0.07644523\n",
      "epoch: 92  batch: 87  loss: 0.07550725\n",
      "epoch: 93  batch: 1  loss: 0.09899548\n",
      "epoch: 93  batch: 2  loss: 0.07633613\n",
      "epoch: 93  batch: 3  loss: 0.09049375\n",
      "epoch: 93  batch: 4  loss: 0.09238149\n",
      "epoch: 93  batch: 5  loss: 0.10690275\n",
      "epoch: 93  batch: 6  loss: 0.05635802\n",
      "epoch: 93  batch: 7  loss: 0.07745606\n",
      "epoch: 93  batch: 8  loss: 0.06825848\n",
      "epoch: 93  batch: 9  loss: 0.13790056\n",
      "epoch: 93  batch: 10  loss: 0.06481323\n",
      "epoch: 93  batch: 11  loss: 0.09261423\n",
      "epoch: 93  batch: 12  loss: 0.05415365\n",
      "epoch: 93  batch: 13  loss: 0.08927801\n",
      "epoch: 93  batch: 14  loss: 0.05897998\n",
      "epoch: 93  batch: 15  loss: 0.11613845\n",
      "epoch: 93  batch: 16  loss: 0.11914121\n",
      "epoch: 93  batch: 17  loss: 0.10639455\n",
      "epoch: 93  batch: 18  loss: 0.08137513\n",
      "epoch: 93  batch: 19  loss: 0.06964469\n",
      "epoch: 93  batch: 20  loss: 0.07258143\n",
      "epoch: 93  batch: 21  loss: 0.08467025\n",
      "epoch: 93  batch: 22  loss: 0.05176774\n",
      "epoch: 93  batch: 23  loss: 0.09077586\n",
      "epoch: 93  batch: 24  loss: 0.06823421\n",
      "epoch: 93  batch: 25  loss: 0.09096992\n",
      "epoch: 93  batch: 26  loss: 0.09973340\n",
      "epoch: 93  batch: 27  loss: 0.07206389\n",
      "epoch: 93  batch: 28  loss: 0.09281962\n",
      "epoch: 93  batch: 29  loss: 0.12822913\n",
      "epoch: 93  batch: 30  loss: 0.05288641\n",
      "epoch: 93  batch: 31  loss: 0.10168353\n",
      "epoch: 93  batch: 32  loss: 0.06813987\n",
      "epoch: 93  batch: 33  loss: 0.07109956\n",
      "epoch: 93  batch: 34  loss: 0.08213389\n",
      "epoch: 93  batch: 35  loss: 0.07355439\n",
      "epoch: 93  batch: 36  loss: 0.08539860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 93  batch: 37  loss: 0.08210994\n",
      "epoch: 93  batch: 38  loss: 0.08505169\n",
      "epoch: 93  batch: 39  loss: 0.06626649\n",
      "epoch: 93  batch: 40  loss: 0.10817797\n",
      "epoch: 93  batch: 41  loss: 0.05943838\n",
      "epoch: 93  batch: 42  loss: 0.07130593\n",
      "epoch: 93  batch: 43  loss: 0.06270351\n",
      "epoch: 93  batch: 44  loss: 0.08131107\n",
      "epoch: 93  batch: 45  loss: 0.11869900\n",
      "epoch: 93  batch: 46  loss: 0.07788587\n",
      "epoch: 93  batch: 47  loss: 0.07346950\n",
      "epoch: 93  batch: 48  loss: 0.05654580\n",
      "epoch: 93  batch: 49  loss: 0.07730880\n",
      "epoch: 93  batch: 50  loss: 0.05555683\n",
      "epoch: 93  batch: 51  loss: 0.08796443\n",
      "epoch: 93  batch: 52  loss: 0.07404236\n",
      "epoch: 93  batch: 53  loss: 0.07000884\n",
      "epoch: 93  batch: 54  loss: 0.04686208\n",
      "epoch: 93  batch: 55  loss: 0.08480320\n",
      "epoch: 93  batch: 56  loss: 0.13257796\n",
      "epoch: 93  batch: 57  loss: 0.08087046\n",
      "epoch: 93  batch: 58  loss: 0.08279481\n",
      "epoch: 93  batch: 59  loss: 0.09625032\n",
      "epoch: 93  batch: 60  loss: 0.10623934\n",
      "epoch: 93  batch: 61  loss: 0.07256235\n",
      "epoch: 93  batch: 62  loss: 0.08110837\n",
      "epoch: 93  batch: 63  loss: 0.06227146\n",
      "epoch: 93  batch: 64  loss: 0.07356492\n",
      "epoch: 93  batch: 65  loss: 0.07595868\n",
      "epoch: 93  batch: 66  loss: 0.08861151\n",
      "epoch: 93  batch: 67  loss: 0.06589114\n",
      "epoch: 93  batch: 68  loss: 0.06793728\n",
      "epoch: 93  batch: 69  loss: 0.09416957\n",
      "epoch: 93  batch: 70  loss: 0.09302927\n",
      "epoch: 93  batch: 71  loss: 0.08981278\n",
      "epoch: 93  batch: 72  loss: 0.08884306\n",
      "epoch: 93  batch: 73  loss: 0.07176711\n",
      "epoch: 93  batch: 74  loss: 0.09051567\n",
      "epoch: 93  batch: 75  loss: 0.06143678\n",
      "epoch: 93  batch: 76  loss: 0.04973102\n",
      "epoch: 93  batch: 77  loss: 0.06244058\n",
      "epoch: 93  batch: 78  loss: 0.06329899\n",
      "epoch: 93  batch: 79  loss: 0.05111591\n",
      "epoch: 93  batch: 80  loss: 0.08401354\n",
      "epoch: 93  batch: 81  loss: 0.07112350\n",
      "epoch: 93  batch: 82  loss: 0.04706808\n",
      "epoch: 93  batch: 83  loss: 0.07342713\n",
      "epoch: 93  batch: 84  loss: 0.06597678\n",
      "epoch: 93  batch: 85  loss: 0.15405278\n",
      "epoch: 93  batch: 86  loss: 0.08487599\n",
      "epoch: 93  batch: 87  loss: 0.10974307\n",
      "epoch: 94  batch: 1  loss: 0.08825941\n",
      "epoch: 94  batch: 2  loss: 0.08354168\n",
      "epoch: 94  batch: 3  loss: 0.06739285\n",
      "epoch: 94  batch: 4  loss: 0.06535554\n",
      "epoch: 94  batch: 5  loss: 0.09854195\n",
      "epoch: 94  batch: 6  loss: 0.04738693\n",
      "epoch: 94  batch: 7  loss: 0.07444213\n",
      "epoch: 94  batch: 8  loss: 0.07840303\n",
      "epoch: 94  batch: 9  loss: 0.09766167\n",
      "epoch: 94  batch: 10  loss: 0.09053269\n",
      "epoch: 94  batch: 11  loss: 0.08573207\n",
      "epoch: 94  batch: 12  loss: 0.05868226\n",
      "epoch: 94  batch: 13  loss: 0.07921010\n",
      "epoch: 94  batch: 14  loss: 0.06730738\n",
      "epoch: 94  batch: 15  loss: 0.10734635\n",
      "epoch: 94  batch: 16  loss: 0.10261094\n",
      "epoch: 94  batch: 17  loss: 0.06109530\n",
      "epoch: 94  batch: 18  loss: 0.07932419\n",
      "epoch: 94  batch: 19  loss: 0.04991381\n",
      "epoch: 94  batch: 20  loss: 0.06576313\n",
      "epoch: 94  batch: 21  loss: 0.08984451\n",
      "epoch: 94  batch: 22  loss: 0.07461314\n",
      "epoch: 94  batch: 23  loss: 0.06441206\n",
      "epoch: 94  batch: 24  loss: 0.08726764\n",
      "epoch: 94  batch: 25  loss: 0.09193029\n",
      "epoch: 94  batch: 26  loss: 0.08428172\n",
      "epoch: 94  batch: 27  loss: 0.06476448\n",
      "epoch: 94  batch: 28  loss: 0.10363977\n",
      "epoch: 94  batch: 29  loss: 0.08688667\n",
      "epoch: 94  batch: 30  loss: 0.07938024\n",
      "epoch: 94  batch: 31  loss: 0.09329411\n",
      "epoch: 94  batch: 32  loss: 0.09460700\n",
      "epoch: 94  batch: 33  loss: 0.09123877\n",
      "epoch: 94  batch: 34  loss: 0.08331878\n",
      "epoch: 94  batch: 35  loss: 0.07572108\n",
      "epoch: 94  batch: 36  loss: 0.09632866\n",
      "epoch: 94  batch: 37  loss: 0.07868029\n",
      "epoch: 94  batch: 38  loss: 0.10173374\n",
      "epoch: 94  batch: 39  loss: 0.06852298\n",
      "epoch: 94  batch: 40  loss: 0.05378552\n",
      "epoch: 94  batch: 41  loss: 0.10438634\n",
      "epoch: 94  batch: 42  loss: 0.08035034\n",
      "epoch: 94  batch: 43  loss: 0.06553721\n",
      "epoch: 94  batch: 44  loss: 0.09584300\n",
      "epoch: 94  batch: 45  loss: 0.08185964\n",
      "epoch: 94  batch: 46  loss: 0.06593736\n",
      "epoch: 94  batch: 47  loss: 0.07319540\n",
      "epoch: 94  batch: 48  loss: 0.08300517\n",
      "epoch: 94  batch: 49  loss: 0.05751229\n",
      "epoch: 94  batch: 50  loss: 0.09410346\n",
      "epoch: 94  batch: 51  loss: 0.07239695\n",
      "epoch: 94  batch: 52  loss: 0.09891289\n",
      "epoch: 94  batch: 53  loss: 0.09837059\n",
      "epoch: 94  batch: 54  loss: 0.08396411\n",
      "epoch: 94  batch: 55  loss: 0.07842544\n",
      "epoch: 94  batch: 56  loss: 0.06265646\n",
      "epoch: 94  batch: 57  loss: 0.07402109\n",
      "epoch: 94  batch: 58  loss: 0.10905515\n",
      "epoch: 94  batch: 59  loss: 0.07933194\n",
      "epoch: 94  batch: 60  loss: 0.06133031\n",
      "epoch: 94  batch: 61  loss: 0.07863981\n",
      "epoch: 94  batch: 62  loss: 0.05612508\n",
      "epoch: 94  batch: 63  loss: 0.07700285\n",
      "epoch: 94  batch: 64  loss: 0.09334799\n",
      "epoch: 94  batch: 65  loss: 0.05593105\n",
      "epoch: 94  batch: 66  loss: 0.08799500\n",
      "epoch: 94  batch: 67  loss: 0.04931825\n",
      "epoch: 94  batch: 68  loss: 0.08808570\n",
      "epoch: 94  batch: 69  loss: 0.06021328\n",
      "epoch: 94  batch: 70  loss: 0.08058362\n",
      "epoch: 94  batch: 71  loss: 0.10332282\n",
      "epoch: 94  batch: 72  loss: 0.08671499\n",
      "epoch: 94  batch: 73  loss: 0.06782220\n",
      "epoch: 94  batch: 74  loss: 0.08465268\n",
      "epoch: 94  batch: 75  loss: 0.14202234\n",
      "epoch: 94  batch: 76  loss: 0.05913107\n",
      "epoch: 94  batch: 77  loss: 0.09091688\n",
      "epoch: 94  batch: 78  loss: 0.06571200\n",
      "epoch: 94  batch: 79  loss: 0.10494472\n",
      "epoch: 94  batch: 80  loss: 0.07490726\n",
      "epoch: 94  batch: 81  loss: 0.10195681\n",
      "epoch: 94  batch: 82  loss: 0.09441939\n",
      "epoch: 94  batch: 83  loss: 0.09544621\n",
      "epoch: 94  batch: 84  loss: 0.10940896\n",
      "epoch: 94  batch: 85  loss: 0.10438711\n",
      "epoch: 94  batch: 86  loss: 0.08296911\n",
      "epoch: 94  batch: 87  loss: 0.07526379\n",
      "epoch: 95  batch: 1  loss: 0.07620437\n",
      "epoch: 95  batch: 2  loss: 0.08132140\n",
      "epoch: 95  batch: 3  loss: 0.07690875\n",
      "epoch: 95  batch: 4  loss: 0.16526914\n",
      "epoch: 95  batch: 5  loss: 0.07418787\n",
      "epoch: 95  batch: 6  loss: 0.07666396\n",
      "epoch: 95  batch: 7  loss: 0.06982691\n",
      "epoch: 95  batch: 8  loss: 0.08240381\n",
      "epoch: 95  batch: 9  loss: 0.06908756\n",
      "epoch: 95  batch: 10  loss: 0.05623160\n",
      "epoch: 95  batch: 11  loss: 0.10138674\n",
      "epoch: 95  batch: 12  loss: 0.07772356\n",
      "epoch: 95  batch: 13  loss: 0.07558362\n",
      "epoch: 95  batch: 14  loss: 0.11008125\n",
      "epoch: 95  batch: 15  loss: 0.05256879\n",
      "epoch: 95  batch: 16  loss: 0.07295062\n",
      "epoch: 95  batch: 17  loss: 0.08764657\n",
      "epoch: 95  batch: 18  loss: 0.09348707\n",
      "epoch: 95  batch: 19  loss: 0.12149543\n",
      "epoch: 95  batch: 20  loss: 0.06130749\n",
      "epoch: 95  batch: 21  loss: 0.08447251\n",
      "epoch: 95  batch: 22  loss: 0.07725709\n",
      "epoch: 95  batch: 23  loss: 0.11635365\n",
      "epoch: 95  batch: 24  loss: 0.07757396\n",
      "epoch: 95  batch: 25  loss: 0.06835859\n",
      "epoch: 95  batch: 26  loss: 0.08173245\n",
      "epoch: 95  batch: 27  loss: 0.10453980\n",
      "epoch: 95  batch: 28  loss: 0.08592460\n",
      "epoch: 95  batch: 29  loss: 0.06612475\n",
      "epoch: 95  batch: 30  loss: 0.08875671\n",
      "epoch: 95  batch: 31  loss: 0.08615038\n",
      "epoch: 95  batch: 32  loss: 0.10395586\n",
      "epoch: 95  batch: 33  loss: 0.10895473\n",
      "epoch: 95  batch: 34  loss: 0.07858346\n",
      "epoch: 95  batch: 35  loss: 0.07479178\n",
      "epoch: 95  batch: 36  loss: 0.08405268\n",
      "epoch: 95  batch: 37  loss: 0.10112112\n",
      "epoch: 95  batch: 38  loss: 0.09624115\n",
      "epoch: 95  batch: 39  loss: 0.09591323\n",
      "epoch: 95  batch: 40  loss: 0.16105752\n",
      "epoch: 95  batch: 41  loss: 0.07113218\n",
      "epoch: 95  batch: 42  loss: 0.13241792\n",
      "epoch: 95  batch: 43  loss: 0.06782389\n",
      "epoch: 95  batch: 44  loss: 0.08677254\n",
      "epoch: 95  batch: 45  loss: 0.10245578\n",
      "epoch: 95  batch: 46  loss: 0.06024164\n",
      "epoch: 95  batch: 47  loss: 0.09171947\n",
      "epoch: 95  batch: 48  loss: 0.06401618\n",
      "epoch: 95  batch: 49  loss: 0.06475075\n",
      "epoch: 95  batch: 50  loss: 0.09369109\n",
      "epoch: 95  batch: 51  loss: 0.11487705\n",
      "epoch: 95  batch: 52  loss: 0.07233120\n",
      "epoch: 95  batch: 53  loss: 0.06899486\n",
      "epoch: 95  batch: 54  loss: 0.07370208\n",
      "epoch: 95  batch: 55  loss: 0.07126555\n",
      "epoch: 95  batch: 56  loss: 0.09238730\n",
      "epoch: 95  batch: 57  loss: 0.05795432\n",
      "epoch: 95  batch: 58  loss: 0.08589725\n",
      "epoch: 95  batch: 59  loss: 0.08185228\n",
      "epoch: 95  batch: 60  loss: 0.09288945\n",
      "epoch: 95  batch: 61  loss: 0.05970222\n",
      "epoch: 95  batch: 62  loss: 0.07033334\n",
      "epoch: 95  batch: 63  loss: 0.09544893\n",
      "epoch: 95  batch: 64  loss: 0.07977642\n",
      "epoch: 95  batch: 65  loss: 0.05686989\n",
      "epoch: 95  batch: 66  loss: 0.06778196\n",
      "epoch: 95  batch: 67  loss: 0.07535248\n",
      "epoch: 95  batch: 68  loss: 0.05916227\n",
      "epoch: 95  batch: 69  loss: 0.07485776\n",
      "epoch: 95  batch: 70  loss: 0.07908131\n",
      "epoch: 95  batch: 71  loss: 0.12923542\n",
      "epoch: 95  batch: 72  loss: 0.06736931\n",
      "epoch: 95  batch: 73  loss: 0.07903462\n",
      "epoch: 95  batch: 74  loss: 0.11175744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95  batch: 75  loss: 0.11953637\n",
      "epoch: 95  batch: 76  loss: 0.06581743\n",
      "epoch: 95  batch: 77  loss: 0.07240579\n",
      "epoch: 95  batch: 78  loss: 0.09715544\n",
      "epoch: 95  batch: 79  loss: 0.05425647\n",
      "epoch: 95  batch: 80  loss: 0.08076657\n",
      "epoch: 95  batch: 81  loss: 0.08631536\n",
      "epoch: 95  batch: 82  loss: 0.08400733\n",
      "epoch: 95  batch: 83  loss: 0.08868895\n",
      "epoch: 95  batch: 84  loss: 0.10468013\n",
      "epoch: 95  batch: 85  loss: 0.07699784\n",
      "epoch: 95  batch: 86  loss: 0.07369342\n",
      "epoch: 95  batch: 87  loss: 0.09484727\n",
      "epoch: 96  batch: 1  loss: 0.12000352\n",
      "epoch: 96  batch: 2  loss: 0.12231343\n",
      "epoch: 96  batch: 3  loss: 0.07466689\n",
      "epoch: 96  batch: 4  loss: 0.10271232\n",
      "epoch: 96  batch: 5  loss: 0.07557192\n",
      "epoch: 96  batch: 6  loss: 0.06360223\n",
      "epoch: 96  batch: 7  loss: 0.09421123\n",
      "epoch: 96  batch: 8  loss: 0.07238753\n",
      "epoch: 96  batch: 9  loss: 0.06564122\n",
      "epoch: 96  batch: 10  loss: 0.07407597\n",
      "epoch: 96  batch: 11  loss: 0.12797618\n",
      "epoch: 96  batch: 12  loss: 0.08847488\n",
      "epoch: 96  batch: 13  loss: 0.03962551\n",
      "epoch: 96  batch: 14  loss: 0.04907916\n",
      "epoch: 96  batch: 15  loss: 0.05139891\n",
      "epoch: 96  batch: 16  loss: 0.09568600\n",
      "epoch: 96  batch: 17  loss: 0.07266131\n",
      "epoch: 96  batch: 18  loss: 0.05528648\n",
      "epoch: 96  batch: 19  loss: 0.06011545\n",
      "epoch: 96  batch: 20  loss: 0.14599659\n",
      "epoch: 96  batch: 21  loss: 0.09825254\n",
      "epoch: 96  batch: 22  loss: 0.06039938\n",
      "epoch: 96  batch: 23  loss: 0.12460227\n",
      "epoch: 96  batch: 24  loss: 0.04936019\n",
      "epoch: 96  batch: 25  loss: 0.05935435\n",
      "epoch: 96  batch: 26  loss: 0.07563883\n",
      "epoch: 96  batch: 27  loss: 0.06405213\n",
      "epoch: 96  batch: 28  loss: 0.10257693\n",
      "epoch: 96  batch: 29  loss: 0.08256969\n",
      "epoch: 96  batch: 30  loss: 0.07929763\n",
      "epoch: 96  batch: 31  loss: 0.09070659\n",
      "epoch: 96  batch: 32  loss: 0.11108755\n",
      "epoch: 96  batch: 33  loss: 0.08714667\n",
      "epoch: 96  batch: 34  loss: 0.05742465\n",
      "epoch: 96  batch: 35  loss: 0.10004675\n",
      "epoch: 96  batch: 36  loss: 0.08760629\n",
      "epoch: 96  batch: 37  loss: 0.07278369\n",
      "epoch: 96  batch: 38  loss: 0.07319842\n",
      "epoch: 96  batch: 39  loss: 0.10688372\n",
      "epoch: 96  batch: 40  loss: 0.05757738\n",
      "epoch: 96  batch: 41  loss: 0.08211190\n",
      "epoch: 96  batch: 42  loss: 0.08293827\n",
      "epoch: 96  batch: 43  loss: 0.06900802\n",
      "epoch: 96  batch: 44  loss: 0.08468298\n",
      "epoch: 96  batch: 45  loss: 0.10029032\n",
      "epoch: 96  batch: 46  loss: 0.05364263\n",
      "epoch: 96  batch: 47  loss: 0.07322311\n",
      "epoch: 96  batch: 48  loss: 0.09960940\n",
      "epoch: 96  batch: 49  loss: 0.09104589\n",
      "epoch: 96  batch: 50  loss: 0.07812818\n",
      "epoch: 96  batch: 51  loss: 0.11340261\n",
      "epoch: 96  batch: 52  loss: 0.07450804\n",
      "epoch: 96  batch: 53  loss: 0.12293929\n",
      "epoch: 96  batch: 54  loss: 0.08582321\n",
      "epoch: 96  batch: 55  loss: 0.07196663\n",
      "epoch: 96  batch: 56  loss: 0.08500342\n",
      "epoch: 96  batch: 57  loss: 0.08086995\n",
      "epoch: 96  batch: 58  loss: 0.06096369\n",
      "epoch: 96  batch: 59  loss: 0.06511955\n",
      "epoch: 96  batch: 60  loss: 0.07070915\n",
      "epoch: 96  batch: 61  loss: 0.05975509\n",
      "epoch: 96  batch: 62  loss: 0.08853559\n",
      "epoch: 96  batch: 63  loss: 0.07977055\n",
      "epoch: 96  batch: 64  loss: 0.08780782\n",
      "epoch: 96  batch: 65  loss: 0.08234299\n",
      "epoch: 96  batch: 66  loss: 0.08715806\n",
      "epoch: 96  batch: 67  loss: 0.06991046\n",
      "epoch: 96  batch: 68  loss: 0.05773395\n",
      "epoch: 96  batch: 69  loss: 0.08866198\n",
      "epoch: 96  batch: 70  loss: 0.10296798\n",
      "epoch: 96  batch: 71  loss: 0.06847651\n",
      "epoch: 96  batch: 72  loss: 0.06246880\n",
      "epoch: 96  batch: 73  loss: 0.05014497\n",
      "epoch: 96  batch: 74  loss: 0.07526268\n",
      "epoch: 96  batch: 75  loss: 0.06986906\n",
      "epoch: 96  batch: 76  loss: 0.08991943\n",
      "epoch: 96  batch: 77  loss: 0.08846288\n",
      "epoch: 96  batch: 78  loss: 0.05541471\n",
      "epoch: 96  batch: 79  loss: 0.06883769\n",
      "epoch: 96  batch: 80  loss: 0.05433125\n",
      "epoch: 96  batch: 81  loss: 0.10255711\n",
      "epoch: 96  batch: 82  loss: 0.13414000\n",
      "epoch: 96  batch: 83  loss: 0.09773380\n",
      "epoch: 96  batch: 84  loss: 0.07914313\n",
      "epoch: 96  batch: 85  loss: 0.05626718\n",
      "epoch: 96  batch: 86  loss: 0.07331867\n",
      "epoch: 96  batch: 87  loss: 0.08855274\n",
      "epoch: 97  batch: 1  loss: 0.09827880\n",
      "epoch: 97  batch: 2  loss: 0.08107739\n",
      "epoch: 97  batch: 3  loss: 0.09711471\n",
      "epoch: 97  batch: 4  loss: 0.09140739\n",
      "epoch: 97  batch: 5  loss: 0.07476337\n",
      "epoch: 97  batch: 6  loss: 0.09898535\n",
      "epoch: 97  batch: 7  loss: 0.11781137\n",
      "epoch: 97  batch: 8  loss: 0.06322084\n",
      "epoch: 97  batch: 9  loss: 0.06597419\n",
      "epoch: 97  batch: 10  loss: 0.08473716\n",
      "epoch: 97  batch: 11  loss: 0.06337196\n",
      "epoch: 97  batch: 12  loss: 0.11204759\n",
      "epoch: 97  batch: 13  loss: 0.09783641\n",
      "epoch: 97  batch: 14  loss: 0.07046552\n",
      "epoch: 97  batch: 15  loss: 0.09002281\n",
      "epoch: 97  batch: 16  loss: 0.07244442\n",
      "epoch: 97  batch: 17  loss: 0.05377836\n",
      "epoch: 97  batch: 18  loss: 0.12164968\n",
      "epoch: 97  batch: 19  loss: 0.10082638\n",
      "epoch: 97  batch: 20  loss: 0.06089499\n",
      "epoch: 97  batch: 21  loss: 0.09170118\n",
      "epoch: 97  batch: 22  loss: 0.05942349\n",
      "epoch: 97  batch: 23  loss: 0.08411861\n",
      "epoch: 97  batch: 24  loss: 0.11004727\n",
      "epoch: 97  batch: 25  loss: 0.11254305\n",
      "epoch: 97  batch: 26  loss: 0.07732847\n",
      "epoch: 97  batch: 27  loss: 0.06668864\n",
      "epoch: 97  batch: 28  loss: 0.08034156\n",
      "epoch: 97  batch: 29  loss: 0.11179702\n",
      "epoch: 97  batch: 30  loss: 0.06513637\n",
      "epoch: 97  batch: 31  loss: 0.08039560\n",
      "epoch: 97  batch: 32  loss: 0.06055445\n",
      "epoch: 97  batch: 33  loss: 0.10270890\n",
      "epoch: 97  batch: 34  loss: 0.09798901\n",
      "epoch: 97  batch: 35  loss: 0.05510717\n",
      "epoch: 97  batch: 36  loss: 0.06544048\n",
      "epoch: 97  batch: 37  loss: 0.08075582\n",
      "epoch: 97  batch: 38  loss: 0.06335440\n",
      "epoch: 97  batch: 39  loss: 0.09152753\n",
      "epoch: 97  batch: 40  loss: 0.10210948\n",
      "epoch: 97  batch: 41  loss: 0.06583261\n",
      "epoch: 97  batch: 42  loss: 0.09471729\n",
      "epoch: 97  batch: 43  loss: 0.08913766\n",
      "epoch: 97  batch: 44  loss: 0.09187103\n",
      "epoch: 97  batch: 45  loss: 0.10173162\n",
      "epoch: 97  batch: 46  loss: 0.09643593\n",
      "epoch: 97  batch: 47  loss: 0.11035635\n",
      "epoch: 97  batch: 48  loss: 0.07283857\n",
      "epoch: 97  batch: 49  loss: 0.11944419\n",
      "epoch: 97  batch: 50  loss: 0.07087234\n",
      "epoch: 97  batch: 51  loss: 0.08236174\n",
      "epoch: 97  batch: 52  loss: 0.10522206\n",
      "epoch: 97  batch: 53  loss: 0.07644325\n",
      "epoch: 97  batch: 54  loss: 0.06002681\n",
      "epoch: 97  batch: 55  loss: 0.08160640\n",
      "epoch: 97  batch: 56  loss: 0.07759307\n",
      "epoch: 97  batch: 57  loss: 0.10250408\n",
      "epoch: 97  batch: 58  loss: 0.09856454\n",
      "epoch: 97  batch: 59  loss: 0.05576005\n",
      "epoch: 97  batch: 60  loss: 0.07919122\n",
      "epoch: 97  batch: 61  loss: 0.07182796\n",
      "epoch: 97  batch: 62  loss: 0.06187283\n",
      "epoch: 97  batch: 63  loss: 0.09622660\n",
      "epoch: 97  batch: 64  loss: 0.05221933\n",
      "epoch: 97  batch: 65  loss: 0.05750076\n",
      "epoch: 97  batch: 66  loss: 0.07844508\n",
      "epoch: 97  batch: 67  loss: 0.08136880\n",
      "epoch: 97  batch: 68  loss: 0.08706195\n",
      "epoch: 97  batch: 69  loss: 0.11977631\n",
      "epoch: 97  batch: 70  loss: 0.09161583\n",
      "epoch: 97  batch: 71  loss: 0.08922264\n",
      "epoch: 97  batch: 72  loss: 0.06607774\n",
      "epoch: 97  batch: 73  loss: 0.06238946\n",
      "epoch: 97  batch: 74  loss: 0.11700644\n",
      "epoch: 97  batch: 75  loss: 0.09145982\n",
      "epoch: 97  batch: 76  loss: 0.11439063\n",
      "epoch: 97  batch: 77  loss: 0.06588037\n",
      "epoch: 97  batch: 78  loss: 0.08584461\n",
      "epoch: 97  batch: 79  loss: 0.08383101\n",
      "epoch: 97  batch: 80  loss: 0.08240440\n",
      "epoch: 97  batch: 81  loss: 0.09666319\n",
      "epoch: 97  batch: 82  loss: 0.08700520\n",
      "epoch: 97  batch: 83  loss: 0.05163698\n",
      "epoch: 97  batch: 84  loss: 0.10083324\n",
      "epoch: 97  batch: 85  loss: 0.06112618\n",
      "epoch: 97  batch: 86  loss: 0.07928436\n",
      "epoch: 97  batch: 87  loss: 0.05704803\n",
      "epoch: 98  batch: 1  loss: 0.11623611\n",
      "epoch: 98  batch: 2  loss: 0.06612928\n",
      "epoch: 98  batch: 3  loss: 0.10045901\n",
      "epoch: 98  batch: 4  loss: 0.07312486\n",
      "epoch: 98  batch: 5  loss: 0.10269602\n",
      "epoch: 98  batch: 6  loss: 0.10388266\n",
      "epoch: 98  batch: 7  loss: 0.07325719\n",
      "epoch: 98  batch: 8  loss: 0.12125887\n",
      "epoch: 98  batch: 9  loss: 0.08396569\n",
      "epoch: 98  batch: 10  loss: 0.09671824\n",
      "epoch: 98  batch: 11  loss: 0.05261101\n",
      "epoch: 98  batch: 12  loss: 0.05595024\n",
      "epoch: 98  batch: 13  loss: 0.08786702\n",
      "epoch: 98  batch: 14  loss: 0.06966059\n",
      "epoch: 98  batch: 15  loss: 0.05942207\n",
      "epoch: 98  batch: 16  loss: 0.05521169\n",
      "epoch: 98  batch: 17  loss: 0.07269469\n",
      "epoch: 98  batch: 18  loss: 0.05077165\n",
      "epoch: 98  batch: 19  loss: 0.13632277\n",
      "epoch: 98  batch: 20  loss: 0.06639373\n",
      "epoch: 98  batch: 21  loss: 0.06789458\n",
      "epoch: 98  batch: 22  loss: 0.10826987\n",
      "epoch: 98  batch: 23  loss: 0.06370278\n",
      "epoch: 98  batch: 24  loss: 0.06325405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 98  batch: 25  loss: 0.05381195\n",
      "epoch: 98  batch: 26  loss: 0.07586343\n",
      "epoch: 98  batch: 27  loss: 0.06206360\n",
      "epoch: 98  batch: 28  loss: 0.07962026\n",
      "epoch: 98  batch: 29  loss: 0.10923927\n",
      "epoch: 98  batch: 30  loss: 0.06807301\n",
      "epoch: 98  batch: 31  loss: 0.05848409\n",
      "epoch: 98  batch: 32  loss: 0.07494394\n",
      "epoch: 98  batch: 33  loss: 0.08985691\n",
      "epoch: 98  batch: 34  loss: 0.07685786\n",
      "epoch: 98  batch: 35  loss: 0.08585846\n",
      "epoch: 98  batch: 36  loss: 0.06007855\n",
      "epoch: 98  batch: 37  loss: 0.12023044\n",
      "epoch: 98  batch: 38  loss: 0.05392581\n",
      "epoch: 98  batch: 39  loss: 0.09889907\n",
      "epoch: 98  batch: 40  loss: 0.07587734\n",
      "epoch: 98  batch: 41  loss: 0.08106979\n",
      "epoch: 98  batch: 42  loss: 0.09218402\n",
      "epoch: 98  batch: 43  loss: 0.08235539\n",
      "epoch: 98  batch: 44  loss: 0.07122029\n",
      "epoch: 98  batch: 45  loss: 0.06235308\n",
      "epoch: 98  batch: 46  loss: 0.06418959\n",
      "epoch: 98  batch: 47  loss: 0.10187604\n",
      "epoch: 98  batch: 48  loss: 0.06030186\n",
      "epoch: 98  batch: 49  loss: 0.05681067\n",
      "epoch: 98  batch: 50  loss: 0.08447061\n",
      "epoch: 98  batch: 51  loss: 0.08231882\n",
      "epoch: 98  batch: 52  loss: 0.12691639\n",
      "epoch: 98  batch: 53  loss: 0.05837650\n",
      "epoch: 98  batch: 54  loss: 0.07042563\n",
      "epoch: 98  batch: 55  loss: 0.07114176\n",
      "epoch: 98  batch: 56  loss: 0.05600480\n",
      "epoch: 98  batch: 57  loss: 0.12648748\n",
      "epoch: 98  batch: 58  loss: 0.06215444\n",
      "epoch: 98  batch: 59  loss: 0.09849716\n",
      "epoch: 98  batch: 60  loss: 0.09254827\n",
      "epoch: 98  batch: 61  loss: 0.10280922\n",
      "epoch: 98  batch: 62  loss: 0.08776534\n",
      "epoch: 98  batch: 63  loss: 0.09675087\n",
      "epoch: 98  batch: 64  loss: 0.11059102\n",
      "epoch: 98  batch: 65  loss: 0.09522299\n",
      "epoch: 98  batch: 66  loss: 0.08437203\n",
      "epoch: 98  batch: 67  loss: 0.09438782\n",
      "epoch: 98  batch: 68  loss: 0.09766456\n",
      "epoch: 98  batch: 69  loss: 0.09130894\n",
      "epoch: 98  batch: 70  loss: 0.05991323\n",
      "epoch: 98  batch: 71  loss: 0.11321576\n",
      "epoch: 98  batch: 72  loss: 0.08977338\n",
      "epoch: 98  batch: 73  loss: 0.04671630\n",
      "epoch: 98  batch: 74  loss: 0.05908501\n",
      "epoch: 98  batch: 75  loss: 0.09590951\n",
      "epoch: 98  batch: 76  loss: 0.08832503\n",
      "epoch: 98  batch: 77  loss: 0.07759494\n",
      "epoch: 98  batch: 78  loss: 0.07398464\n",
      "epoch: 98  batch: 79  loss: 0.08329742\n",
      "epoch: 98  batch: 80  loss: 0.06937374\n",
      "epoch: 98  batch: 81  loss: 0.06240135\n",
      "epoch: 98  batch: 82  loss: 0.07285894\n",
      "epoch: 98  batch: 83  loss: 0.07460524\n",
      "epoch: 98  batch: 84  loss: 0.07242715\n",
      "epoch: 98  batch: 85  loss: 0.07607897\n",
      "epoch: 98  batch: 86  loss: 0.07040201\n",
      "epoch: 98  batch: 87  loss: 0.07963722\n",
      "epoch: 99  batch: 1  loss: 0.08440448\n",
      "epoch: 99  batch: 2  loss: 0.08224334\n",
      "epoch: 99  batch: 3  loss: 0.05402729\n",
      "epoch: 99  batch: 4  loss: 0.13318035\n",
      "epoch: 99  batch: 5  loss: 0.09488983\n",
      "epoch: 99  batch: 6  loss: 0.13638406\n",
      "epoch: 99  batch: 7  loss: 0.07818773\n",
      "epoch: 99  batch: 8  loss: 0.05725726\n",
      "epoch: 99  batch: 9  loss: 0.08207946\n",
      "epoch: 99  batch: 10  loss: 0.07400383\n",
      "epoch: 99  batch: 11  loss: 0.09683011\n",
      "epoch: 99  batch: 12  loss: 0.12703556\n",
      "epoch: 99  batch: 13  loss: 0.08492998\n",
      "epoch: 99  batch: 14  loss: 0.07985427\n",
      "epoch: 99  batch: 15  loss: 0.08234628\n",
      "epoch: 99  batch: 16  loss: 0.06791776\n",
      "epoch: 99  batch: 17  loss: 0.06448506\n",
      "epoch: 99  batch: 18  loss: 0.07095487\n",
      "epoch: 99  batch: 19  loss: 0.17698804\n",
      "epoch: 99  batch: 20  loss: 0.11680322\n",
      "epoch: 99  batch: 21  loss: 0.08779577\n",
      "epoch: 99  batch: 22  loss: 0.06066230\n",
      "epoch: 99  batch: 23  loss: 0.06865353\n",
      "epoch: 99  batch: 24  loss: 0.09681837\n",
      "epoch: 99  batch: 25  loss: 0.06754841\n",
      "epoch: 99  batch: 26  loss: 0.12819114\n",
      "epoch: 99  batch: 27  loss: 0.09451045\n",
      "epoch: 99  batch: 28  loss: 0.07330380\n",
      "epoch: 99  batch: 29  loss: 0.08716612\n",
      "epoch: 99  batch: 30  loss: 0.10214345\n",
      "epoch: 99  batch: 31  loss: 0.09309136\n",
      "epoch: 99  batch: 32  loss: 0.08022565\n",
      "epoch: 99  batch: 33  loss: 0.07844054\n",
      "epoch: 99  batch: 34  loss: 0.06812489\n",
      "epoch: 99  batch: 35  loss: 0.07529474\n",
      "epoch: 99  batch: 36  loss: 0.05249487\n",
      "epoch: 99  batch: 37  loss: 0.09594322\n",
      "epoch: 99  batch: 38  loss: 0.10426629\n",
      "epoch: 99  batch: 39  loss: 0.06637996\n",
      "epoch: 99  batch: 40  loss: 0.05441835\n",
      "epoch: 99  batch: 41  loss: 0.07584348\n",
      "epoch: 99  batch: 42  loss: 0.06355864\n",
      "epoch: 99  batch: 43  loss: 0.07507107\n",
      "epoch: 99  batch: 44  loss: 0.07501095\n",
      "epoch: 99  batch: 45  loss: 0.08921258\n",
      "epoch: 99  batch: 46  loss: 0.05389868\n",
      "epoch: 99  batch: 47  loss: 0.11180484\n",
      "epoch: 99  batch: 48  loss: 0.09395459\n",
      "epoch: 99  batch: 49  loss: 0.08487144\n",
      "epoch: 99  batch: 50  loss: 0.11147546\n",
      "epoch: 99  batch: 51  loss: 0.09192389\n",
      "epoch: 99  batch: 52  loss: 0.06846155\n",
      "epoch: 99  batch: 53  loss: 0.08932705\n",
      "epoch: 99  batch: 54  loss: 0.07531596\n",
      "epoch: 99  batch: 55  loss: 0.06514724\n",
      "epoch: 99  batch: 56  loss: 0.10712891\n",
      "epoch: 99  batch: 57  loss: 0.05348881\n",
      "epoch: 99  batch: 58  loss: 0.07262923\n",
      "epoch: 99  batch: 59  loss: 0.09488384\n",
      "epoch: 99  batch: 60  loss: 0.07907543\n",
      "epoch: 99  batch: 61  loss: 0.07410540\n",
      "epoch: 99  batch: 62  loss: 0.07144520\n",
      "epoch: 99  batch: 63  loss: 0.15248604\n",
      "epoch: 99  batch: 64  loss: 0.07341792\n",
      "epoch: 99  batch: 65  loss: 0.07454296\n",
      "epoch: 99  batch: 66  loss: 0.08693220\n",
      "epoch: 99  batch: 67  loss: 0.06699112\n",
      "epoch: 99  batch: 68  loss: 0.07862291\n",
      "epoch: 99  batch: 69  loss: 0.08019437\n",
      "epoch: 99  batch: 70  loss: 0.05730876\n",
      "epoch: 99  batch: 71  loss: 0.10690908\n",
      "epoch: 99  batch: 72  loss: 0.13331522\n",
      "epoch: 99  batch: 73  loss: 0.07443792\n",
      "epoch: 99  batch: 74  loss: 0.07149246\n",
      "epoch: 99  batch: 75  loss: 0.06422886\n",
      "epoch: 99  batch: 76  loss: 0.08681931\n",
      "epoch: 99  batch: 77  loss: 0.10649309\n",
      "epoch: 99  batch: 78  loss: 0.07902214\n",
      "epoch: 99  batch: 79  loss: 0.06615123\n",
      "epoch: 99  batch: 80  loss: 0.05838785\n",
      "epoch: 99  batch: 81  loss: 0.07169537\n",
      "epoch: 99  batch: 82  loss: 0.06973154\n",
      "epoch: 99  batch: 83  loss: 0.11626934\n",
      "epoch: 99  batch: 84  loss: 0.09487357\n",
      "epoch: 99  batch: 85  loss: 0.07338084\n",
      "epoch: 99  batch: 86  loss: 0.07067247\n",
      "epoch: 99  batch: 87  loss: 0.07393513\n",
      "epoch: 100  batch: 1  loss: 0.06672500\n",
      "epoch: 100  batch: 2  loss: 0.09750416\n",
      "epoch: 100  batch: 3  loss: 0.08675846\n",
      "epoch: 100  batch: 4  loss: 0.10871279\n",
      "epoch: 100  batch: 5  loss: 0.08853611\n",
      "epoch: 100  batch: 6  loss: 0.09615661\n",
      "epoch: 100  batch: 7  loss: 0.09124996\n",
      "epoch: 100  batch: 8  loss: 0.07336824\n",
      "epoch: 100  batch: 9  loss: 0.12122089\n",
      "epoch: 100  batch: 10  loss: 0.08989379\n",
      "epoch: 100  batch: 11  loss: 0.11900382\n",
      "epoch: 100  batch: 12  loss: 0.09156406\n",
      "epoch: 100  batch: 13  loss: 0.08060753\n",
      "epoch: 100  batch: 14  loss: 0.11951744\n",
      "epoch: 100  batch: 15  loss: 0.08387516\n",
      "epoch: 100  batch: 16  loss: 0.10472938\n",
      "epoch: 100  batch: 17  loss: 0.07382748\n",
      "epoch: 100  batch: 18  loss: 0.07565267\n",
      "epoch: 100  batch: 19  loss: 0.12090542\n",
      "epoch: 100  batch: 20  loss: 0.06743068\n",
      "epoch: 100  batch: 21  loss: 0.08997568\n",
      "epoch: 100  batch: 22  loss: 0.06264573\n",
      "epoch: 100  batch: 23  loss: 0.10224499\n",
      "epoch: 100  batch: 24  loss: 0.10921442\n",
      "epoch: 100  batch: 25  loss: 0.07988383\n",
      "epoch: 100  batch: 26  loss: 0.05926670\n",
      "epoch: 100  batch: 27  loss: 0.09703570\n",
      "epoch: 100  batch: 28  loss: 0.06100415\n",
      "epoch: 100  batch: 29  loss: 0.06559121\n",
      "epoch: 100  batch: 30  loss: 0.04748961\n",
      "epoch: 100  batch: 31  loss: 0.08134783\n",
      "epoch: 100  batch: 32  loss: 0.07542143\n",
      "epoch: 100  batch: 33  loss: 0.08777455\n",
      "epoch: 100  batch: 34  loss: 0.11927423\n",
      "epoch: 100  batch: 35  loss: 0.11506945\n",
      "epoch: 100  batch: 36  loss: 0.07295173\n",
      "epoch: 100  batch: 37  loss: 0.06899674\n",
      "epoch: 100  batch: 38  loss: 0.05737408\n",
      "epoch: 100  batch: 39  loss: 0.08897009\n",
      "epoch: 100  batch: 40  loss: 0.07063279\n",
      "epoch: 100  batch: 41  loss: 0.13451728\n",
      "epoch: 100  batch: 42  loss: 0.07002886\n",
      "epoch: 100  batch: 43  loss: 0.08191018\n",
      "epoch: 100  batch: 44  loss: 0.06594118\n",
      "epoch: 100  batch: 45  loss: 0.05793162\n",
      "epoch: 100  batch: 46  loss: 0.12268169\n",
      "epoch: 100  batch: 47  loss: 0.07236613\n",
      "epoch: 100  batch: 48  loss: 0.05528911\n",
      "epoch: 100  batch: 49  loss: 0.06644988\n",
      "epoch: 100  batch: 50  loss: 0.06339697\n",
      "epoch: 100  batch: 51  loss: 0.14448804\n",
      "epoch: 100  batch: 52  loss: 0.05902780\n",
      "epoch: 100  batch: 53  loss: 0.06043439\n",
      "epoch: 100  batch: 54  loss: 0.07496137\n",
      "epoch: 100  batch: 55  loss: 0.09124162\n",
      "epoch: 100  batch: 56  loss: 0.05344102\n",
      "epoch: 100  batch: 57  loss: 0.08558607\n",
      "epoch: 100  batch: 58  loss: 0.06964114\n",
      "epoch: 100  batch: 59  loss: 0.06134129\n",
      "epoch: 100  batch: 60  loss: 0.05265756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100  batch: 61  loss: 0.14439224\n",
      "epoch: 100  batch: 62  loss: 0.09037038\n",
      "epoch: 100  batch: 63  loss: 0.07325628\n",
      "epoch: 100  batch: 64  loss: 0.07176489\n",
      "epoch: 100  batch: 65  loss: 0.06266612\n",
      "epoch: 100  batch: 66  loss: 0.07885760\n",
      "epoch: 100  batch: 67  loss: 0.09293542\n",
      "epoch: 100  batch: 68  loss: 0.05785795\n",
      "epoch: 100  batch: 69  loss: 0.06815896\n",
      "epoch: 100  batch: 70  loss: 0.11406173\n",
      "epoch: 100  batch: 71  loss: 0.08743019\n",
      "epoch: 100  batch: 72  loss: 0.10238069\n",
      "epoch: 100  batch: 73  loss: 0.05356326\n",
      "epoch: 100  batch: 74  loss: 0.08653554\n",
      "epoch: 100  batch: 75  loss: 0.06107134\n",
      "epoch: 100  batch: 76  loss: 0.08057736\n",
      "epoch: 100  batch: 77  loss: 0.07177099\n",
      "epoch: 100  batch: 78  loss: 0.14775351\n",
      "epoch: 100  batch: 79  loss: 0.07077699\n",
      "epoch: 100  batch: 80  loss: 0.07475540\n",
      "epoch: 100  batch: 81  loss: 0.10149741\n",
      "epoch: 100  batch: 82  loss: 0.08691780\n",
      "epoch: 100  batch: 83  loss: 0.06076246\n",
      "epoch: 100  batch: 84  loss: 0.10850236\n",
      "epoch: 100  batch: 85  loss: 0.08116211\n",
      "epoch: 100  batch: 86  loss: 0.09743026\n",
      "epoch: 100  batch: 87  loss: 0.09919881\n",
      "epoch: 101  batch: 1  loss: 0.08540544\n",
      "epoch: 101  batch: 2  loss: 0.10264880\n",
      "epoch: 101  batch: 3  loss: 0.07874043\n",
      "epoch: 101  batch: 4  loss: 0.08571937\n",
      "epoch: 101  batch: 5  loss: 0.11959150\n",
      "epoch: 101  batch: 6  loss: 0.08342141\n",
      "epoch: 101  batch: 7  loss: 0.08284856\n",
      "epoch: 101  batch: 8  loss: 0.15162106\n",
      "epoch: 101  batch: 9  loss: 0.10083185\n",
      "epoch: 101  batch: 10  loss: 0.07629007\n",
      "epoch: 101  batch: 11  loss: 0.07008459\n",
      "epoch: 101  batch: 12  loss: 0.06804464\n",
      "epoch: 101  batch: 13  loss: 0.10381395\n",
      "epoch: 101  batch: 14  loss: 0.08209541\n",
      "epoch: 101  batch: 15  loss: 0.08956164\n",
      "epoch: 101  batch: 16  loss: 0.15377501\n",
      "epoch: 101  batch: 17  loss: 0.06874947\n",
      "epoch: 101  batch: 18  loss: 0.06844804\n",
      "epoch: 101  batch: 19  loss: 0.06934249\n",
      "epoch: 101  batch: 20  loss: 0.10049418\n",
      "epoch: 101  batch: 21  loss: 0.09809477\n",
      "epoch: 101  batch: 22  loss: 0.10196912\n",
      "epoch: 101  batch: 23  loss: 0.07763042\n",
      "epoch: 101  batch: 24  loss: 0.06768309\n",
      "epoch: 101  batch: 25  loss: 0.07948839\n",
      "epoch: 101  batch: 26  loss: 0.09504336\n",
      "epoch: 101  batch: 27  loss: 0.11392494\n",
      "epoch: 101  batch: 28  loss: 0.06811495\n",
      "epoch: 101  batch: 29  loss: 0.10358019\n",
      "epoch: 101  batch: 30  loss: 0.06636023\n",
      "epoch: 101  batch: 31  loss: 0.06261604\n",
      "epoch: 101  batch: 32  loss: 0.08227141\n",
      "epoch: 101  batch: 33  loss: 0.12526837\n",
      "epoch: 101  batch: 34  loss: 0.11149126\n",
      "epoch: 101  batch: 35  loss: 0.08790987\n",
      "epoch: 101  batch: 36  loss: 0.12219793\n",
      "epoch: 101  batch: 37  loss: 0.10200254\n",
      "epoch: 101  batch: 38  loss: 0.08280995\n",
      "epoch: 101  batch: 39  loss: 0.06430840\n",
      "epoch: 101  batch: 40  loss: 0.07314406\n",
      "epoch: 101  batch: 41  loss: 0.08853231\n",
      "epoch: 101  batch: 42  loss: 0.06996629\n",
      "epoch: 101  batch: 43  loss: 0.09128117\n",
      "epoch: 101  batch: 44  loss: 0.05472156\n",
      "epoch: 101  batch: 45  loss: 0.07904069\n",
      "epoch: 101  batch: 46  loss: 0.05958079\n",
      "epoch: 101  batch: 47  loss: 0.09371056\n",
      "epoch: 101  batch: 48  loss: 0.10161133\n",
      "epoch: 101  batch: 49  loss: 0.10922175\n",
      "epoch: 101  batch: 50  loss: 0.09235332\n",
      "epoch: 101  batch: 51  loss: 0.07547872\n",
      "epoch: 101  batch: 52  loss: 0.05832781\n",
      "epoch: 101  batch: 53  loss: 0.08702900\n",
      "epoch: 101  batch: 54  loss: 0.07422052\n",
      "epoch: 101  batch: 55  loss: 0.08044998\n",
      "epoch: 101  batch: 56  loss: 0.09998430\n",
      "epoch: 101  batch: 57  loss: 0.08691128\n",
      "epoch: 101  batch: 58  loss: 0.06120924\n",
      "epoch: 101  batch: 59  loss: 0.07052636\n",
      "epoch: 101  batch: 60  loss: 0.06262913\n",
      "epoch: 101  batch: 61  loss: 0.06935200\n",
      "epoch: 101  batch: 62  loss: 0.10704711\n",
      "epoch: 101  batch: 63  loss: 0.07392110\n",
      "epoch: 101  batch: 64  loss: 0.07632618\n",
      "epoch: 101  batch: 65  loss: 0.08253324\n",
      "epoch: 101  batch: 66  loss: 0.09209710\n",
      "epoch: 101  batch: 67  loss: 0.07390594\n",
      "epoch: 101  batch: 68  loss: 0.08085845\n",
      "epoch: 101  batch: 69  loss: 0.08947381\n",
      "epoch: 101  batch: 70  loss: 0.14358684\n",
      "epoch: 101  batch: 71  loss: 0.09273910\n",
      "epoch: 101  batch: 72  loss: 0.06973784\n",
      "epoch: 101  batch: 73  loss: 0.08221933\n",
      "epoch: 101  batch: 74  loss: 0.09647759\n",
      "epoch: 101  batch: 75  loss: 0.09004421\n",
      "epoch: 101  batch: 76  loss: 0.06753796\n",
      "epoch: 101  batch: 77  loss: 0.06797820\n",
      "epoch: 101  batch: 78  loss: 0.08457409\n",
      "epoch: 101  batch: 79  loss: 0.06589450\n",
      "epoch: 101  batch: 80  loss: 0.07438248\n",
      "epoch: 101  batch: 81  loss: 0.09107567\n",
      "epoch: 101  batch: 82  loss: 0.06584492\n",
      "epoch: 101  batch: 83  loss: 0.06473237\n",
      "epoch: 101  batch: 84  loss: 0.09109850\n",
      "epoch: 101  batch: 85  loss: 0.09713057\n",
      "epoch: 101  batch: 86  loss: 0.07831566\n",
      "epoch: 101  batch: 87  loss: 0.09457497\n",
      "epoch: 102  batch: 1  loss: 0.09676773\n",
      "epoch: 102  batch: 2  loss: 0.12398015\n",
      "epoch: 102  batch: 3  loss: 0.09261365\n",
      "epoch: 102  batch: 4  loss: 0.07135659\n",
      "epoch: 102  batch: 5  loss: 0.09525800\n",
      "epoch: 102  batch: 6  loss: 0.09910575\n",
      "epoch: 102  batch: 7  loss: 0.08208958\n",
      "epoch: 102  batch: 8  loss: 0.13406597\n",
      "epoch: 102  batch: 9  loss: 0.05229500\n",
      "epoch: 102  batch: 10  loss: 0.06721740\n",
      "epoch: 102  batch: 11  loss: 0.07315940\n",
      "epoch: 102  batch: 12  loss: 0.06826352\n",
      "epoch: 102  batch: 13  loss: 0.06389537\n",
      "epoch: 102  batch: 14  loss: 0.05125478\n",
      "epoch: 102  batch: 15  loss: 0.08520383\n",
      "epoch: 102  batch: 16  loss: 0.09127810\n",
      "epoch: 102  batch: 17  loss: 0.07751720\n",
      "epoch: 102  batch: 18  loss: 0.06203191\n",
      "epoch: 102  batch: 19  loss: 0.09788612\n",
      "epoch: 102  batch: 20  loss: 0.09863457\n",
      "epoch: 102  batch: 21  loss: 0.12454765\n",
      "epoch: 102  batch: 22  loss: 0.07424199\n",
      "epoch: 102  batch: 23  loss: 0.07369354\n",
      "epoch: 102  batch: 24  loss: 0.05432884\n",
      "epoch: 102  batch: 25  loss: 0.08283807\n",
      "epoch: 102  batch: 26  loss: 0.08743239\n",
      "epoch: 102  batch: 27  loss: 0.09745562\n",
      "epoch: 102  batch: 28  loss: 0.09397984\n",
      "epoch: 102  batch: 29  loss: 0.08837473\n",
      "epoch: 102  batch: 30  loss: 0.12702368\n",
      "epoch: 102  batch: 31  loss: 0.06938368\n",
      "epoch: 102  batch: 32  loss: 0.07982031\n",
      "epoch: 102  batch: 33  loss: 0.08192629\n",
      "epoch: 102  batch: 34  loss: 0.07010031\n",
      "epoch: 102  batch: 35  loss: 0.09162920\n",
      "epoch: 102  batch: 36  loss: 0.07371476\n",
      "epoch: 102  batch: 37  loss: 0.10121168\n",
      "epoch: 102  batch: 38  loss: 0.07947568\n",
      "epoch: 102  batch: 39  loss: 0.08605316\n",
      "epoch: 102  batch: 40  loss: 0.06249827\n",
      "epoch: 102  batch: 41  loss: 0.06195015\n",
      "epoch: 102  batch: 42  loss: 0.07706545\n",
      "epoch: 102  batch: 43  loss: 0.07729151\n",
      "epoch: 102  batch: 44  loss: 0.10630297\n",
      "epoch: 102  batch: 45  loss: 0.08393797\n",
      "epoch: 102  batch: 46  loss: 0.09776173\n",
      "epoch: 102  batch: 47  loss: 0.09407513\n",
      "epoch: 102  batch: 48  loss: 0.06282732\n",
      "epoch: 102  batch: 49  loss: 0.06068087\n",
      "epoch: 102  batch: 50  loss: 0.12477536\n",
      "epoch: 102  batch: 51  loss: 0.07763237\n",
      "epoch: 102  batch: 52  loss: 0.06631424\n",
      "epoch: 102  batch: 53  loss: 0.08958954\n",
      "epoch: 102  batch: 54  loss: 0.07222578\n",
      "epoch: 102  batch: 55  loss: 0.09326716\n",
      "epoch: 102  batch: 56  loss: 0.07725842\n",
      "epoch: 102  batch: 57  loss: 0.06886732\n",
      "epoch: 102  batch: 58  loss: 0.10802697\n",
      "epoch: 102  batch: 59  loss: 0.08216696\n",
      "epoch: 102  batch: 60  loss: 0.06884947\n",
      "epoch: 102  batch: 61  loss: 0.07435421\n",
      "epoch: 102  batch: 62  loss: 0.08253439\n",
      "epoch: 102  batch: 63  loss: 0.09330345\n",
      "epoch: 102  batch: 64  loss: 0.07594679\n",
      "epoch: 102  batch: 65  loss: 0.08523785\n",
      "epoch: 102  batch: 66  loss: 0.08191612\n",
      "epoch: 102  batch: 67  loss: 0.05375785\n",
      "epoch: 102  batch: 68  loss: 0.05830675\n",
      "epoch: 102  batch: 69  loss: 0.10484024\n",
      "epoch: 102  batch: 70  loss: 0.08950878\n",
      "epoch: 102  batch: 71  loss: 0.05483928\n",
      "epoch: 102  batch: 72  loss: 0.07818835\n",
      "epoch: 102  batch: 73  loss: 0.07859678\n",
      "epoch: 102  batch: 74  loss: 0.07570527\n",
      "epoch: 102  batch: 75  loss: 0.06535361\n",
      "epoch: 102  batch: 76  loss: 0.05965916\n",
      "epoch: 102  batch: 77  loss: 0.09170703\n",
      "epoch: 102  batch: 78  loss: 0.04893481\n",
      "epoch: 102  batch: 79  loss: 0.09596081\n",
      "epoch: 102  batch: 80  loss: 0.08343354\n",
      "epoch: 102  batch: 81  loss: 0.06650066\n",
      "epoch: 102  batch: 82  loss: 0.09734655\n",
      "epoch: 102  batch: 83  loss: 0.06923994\n",
      "epoch: 102  batch: 84  loss: 0.10867371\n",
      "epoch: 102  batch: 85  loss: 0.08394996\n",
      "epoch: 102  batch: 86  loss: 0.07635190\n",
      "epoch: 102  batch: 87  loss: 0.06564954\n",
      "epoch: 103  batch: 1  loss: 0.05027635\n",
      "epoch: 103  batch: 2  loss: 0.06918833\n",
      "epoch: 103  batch: 3  loss: 0.07388402\n",
      "epoch: 103  batch: 4  loss: 0.08434168\n",
      "epoch: 103  batch: 5  loss: 0.09732320\n",
      "epoch: 103  batch: 6  loss: 0.07643779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103  batch: 7  loss: 0.11933089\n",
      "epoch: 103  batch: 8  loss: 0.07745196\n",
      "epoch: 103  batch: 9  loss: 0.11308847\n",
      "epoch: 103  batch: 10  loss: 0.06948445\n",
      "epoch: 103  batch: 11  loss: 0.07142451\n",
      "epoch: 103  batch: 12  loss: 0.10615437\n",
      "epoch: 103  batch: 13  loss: 0.09089556\n",
      "epoch: 103  batch: 14  loss: 0.05364005\n",
      "epoch: 103  batch: 15  loss: 0.09154636\n",
      "epoch: 103  batch: 16  loss: 0.08053312\n",
      "epoch: 103  batch: 17  loss: 0.09899449\n",
      "epoch: 103  batch: 18  loss: 0.07527226\n",
      "epoch: 103  batch: 19  loss: 0.10278340\n",
      "epoch: 103  batch: 20  loss: 0.07685546\n",
      "epoch: 103  batch: 21  loss: 0.06310277\n",
      "epoch: 103  batch: 22  loss: 0.10502719\n",
      "epoch: 103  batch: 23  loss: 0.11978960\n",
      "epoch: 103  batch: 24  loss: 0.07199966\n",
      "epoch: 103  batch: 25  loss: 0.07224157\n",
      "epoch: 103  batch: 26  loss: 0.07185598\n",
      "epoch: 103  batch: 27  loss: 0.08808408\n",
      "epoch: 103  batch: 28  loss: 0.06480671\n",
      "epoch: 103  batch: 29  loss: 0.07209776\n",
      "epoch: 103  batch: 30  loss: 0.08574200\n",
      "epoch: 103  batch: 31  loss: 0.10262782\n",
      "epoch: 103  batch: 32  loss: 0.05577573\n",
      "epoch: 103  batch: 33  loss: 0.07212530\n",
      "epoch: 103  batch: 34  loss: 0.07380454\n",
      "epoch: 103  batch: 35  loss: 0.11714192\n",
      "epoch: 103  batch: 36  loss: 0.06939222\n",
      "epoch: 103  batch: 37  loss: 0.09985679\n",
      "epoch: 103  batch: 38  loss: 0.08641562\n",
      "epoch: 103  batch: 39  loss: 0.08152667\n",
      "epoch: 103  batch: 40  loss: 0.06278695\n",
      "epoch: 103  batch: 41  loss: 0.05338711\n",
      "epoch: 103  batch: 42  loss: 0.11027268\n",
      "epoch: 103  batch: 43  loss: 0.07090625\n",
      "epoch: 103  batch: 44  loss: 0.07460319\n",
      "epoch: 103  batch: 45  loss: 0.07797930\n",
      "epoch: 103  batch: 46  loss: 0.06624940\n",
      "epoch: 103  batch: 47  loss: 0.09336592\n",
      "epoch: 103  batch: 48  loss: 0.07849442\n",
      "epoch: 103  batch: 49  loss: 0.09692769\n",
      "epoch: 103  batch: 50  loss: 0.10900622\n",
      "epoch: 103  batch: 51  loss: 0.06727203\n",
      "epoch: 103  batch: 52  loss: 0.06267408\n",
      "epoch: 103  batch: 53  loss: 0.07814778\n",
      "epoch: 103  batch: 54  loss: 0.04435401\n",
      "epoch: 103  batch: 55  loss: 0.08236340\n",
      "epoch: 103  batch: 56  loss: 0.06404147\n",
      "epoch: 103  batch: 57  loss: 0.09768463\n",
      "epoch: 103  batch: 58  loss: 0.13089751\n",
      "epoch: 103  batch: 59  loss: 0.06911603\n",
      "epoch: 103  batch: 60  loss: 0.11696006\n",
      "epoch: 103  batch: 61  loss: 0.07306234\n",
      "epoch: 103  batch: 62  loss: 0.06907590\n",
      "epoch: 103  batch: 63  loss: 0.11264198\n",
      "epoch: 103  batch: 64  loss: 0.07203504\n",
      "epoch: 103  batch: 65  loss: 0.10929634\n",
      "epoch: 103  batch: 66  loss: 0.08303533\n",
      "epoch: 103  batch: 67  loss: 0.10209996\n",
      "epoch: 103  batch: 68  loss: 0.08985855\n",
      "epoch: 103  batch: 69  loss: 0.10926433\n",
      "epoch: 103  batch: 70  loss: 0.10843002\n",
      "epoch: 103  batch: 71  loss: 0.04748011\n",
      "epoch: 103  batch: 72  loss: 0.12532657\n",
      "epoch: 103  batch: 73  loss: 0.13684127\n",
      "epoch: 103  batch: 74  loss: 0.07999967\n",
      "epoch: 103  batch: 75  loss: 0.04876377\n",
      "epoch: 103  batch: 76  loss: 0.07079333\n",
      "epoch: 103  batch: 77  loss: 0.05980059\n",
      "epoch: 103  batch: 78  loss: 0.06036070\n",
      "epoch: 103  batch: 79  loss: 0.07755822\n",
      "epoch: 103  batch: 80  loss: 0.06312868\n",
      "epoch: 103  batch: 81  loss: 0.05699124\n",
      "epoch: 103  batch: 82  loss: 0.07596222\n",
      "epoch: 103  batch: 83  loss: 0.12163305\n",
      "epoch: 103  batch: 84  loss: 0.07440800\n",
      "epoch: 103  batch: 85  loss: 0.08518232\n",
      "epoch: 103  batch: 86  loss: 0.08954886\n",
      "epoch: 103  batch: 87  loss: 0.07712616\n",
      "epoch: 104  batch: 1  loss: 0.05909454\n",
      "epoch: 104  batch: 2  loss: 0.06895597\n",
      "epoch: 104  batch: 3  loss: 0.06684384\n",
      "epoch: 104  batch: 4  loss: 0.08019812\n",
      "epoch: 104  batch: 5  loss: 0.07941750\n",
      "epoch: 104  batch: 6  loss: 0.09215220\n",
      "epoch: 104  batch: 7  loss: 0.05113561\n",
      "epoch: 104  batch: 8  loss: 0.09187353\n",
      "epoch: 104  batch: 9  loss: 0.08440058\n",
      "epoch: 104  batch: 10  loss: 0.09761679\n",
      "epoch: 104  batch: 11  loss: 0.08028559\n",
      "epoch: 104  batch: 12  loss: 0.08422589\n",
      "epoch: 104  batch: 13  loss: 0.12358911\n",
      "epoch: 104  batch: 14  loss: 0.06118821\n",
      "epoch: 104  batch: 15  loss: 0.11665262\n",
      "epoch: 104  batch: 16  loss: 0.08127502\n",
      "epoch: 104  batch: 17  loss: 0.11034869\n",
      "epoch: 104  batch: 18  loss: 0.08784479\n",
      "epoch: 104  batch: 19  loss: 0.11881824\n",
      "epoch: 104  batch: 20  loss: 0.06601819\n",
      "epoch: 104  batch: 21  loss: 0.06937059\n",
      "epoch: 104  batch: 22  loss: 0.07518671\n",
      "epoch: 104  batch: 23  loss: 0.07310200\n",
      "epoch: 104  batch: 24  loss: 0.07777108\n",
      "epoch: 104  batch: 25  loss: 0.08623593\n",
      "epoch: 104  batch: 26  loss: 0.06302724\n",
      "epoch: 104  batch: 27  loss: 0.06106428\n",
      "epoch: 104  batch: 28  loss: 0.07294042\n",
      "epoch: 104  batch: 29  loss: 0.06174997\n",
      "epoch: 104  batch: 30  loss: 0.07618991\n",
      "epoch: 104  batch: 31  loss: 0.13229947\n",
      "epoch: 104  batch: 32  loss: 0.10907205\n",
      "epoch: 104  batch: 33  loss: 0.07419591\n",
      "epoch: 104  batch: 34  loss: 0.06941864\n",
      "epoch: 104  batch: 35  loss: 0.06954618\n",
      "epoch: 104  batch: 36  loss: 0.12938631\n",
      "epoch: 104  batch: 37  loss: 0.07406903\n",
      "epoch: 104  batch: 38  loss: 0.08528716\n",
      "epoch: 104  batch: 39  loss: 0.09093400\n",
      "epoch: 104  batch: 40  loss: 0.10380144\n",
      "epoch: 104  batch: 41  loss: 0.11009732\n",
      "epoch: 104  batch: 42  loss: 0.06834140\n",
      "epoch: 104  batch: 43  loss: 0.06850435\n",
      "epoch: 104  batch: 44  loss: 0.07452136\n",
      "epoch: 104  batch: 45  loss: 0.07122582\n",
      "epoch: 104  batch: 46  loss: 0.13658838\n",
      "epoch: 104  batch: 47  loss: 0.10529100\n",
      "epoch: 104  batch: 48  loss: 0.07599847\n",
      "epoch: 104  batch: 49  loss: 0.05331215\n",
      "epoch: 104  batch: 50  loss: 0.05262727\n",
      "epoch: 104  batch: 51  loss: 0.11374350\n",
      "epoch: 104  batch: 52  loss: 0.06876575\n",
      "epoch: 104  batch: 53  loss: 0.05701426\n",
      "epoch: 104  batch: 54  loss: 0.09712795\n",
      "epoch: 104  batch: 55  loss: 0.06948319\n",
      "epoch: 104  batch: 56  loss: 0.07761789\n",
      "epoch: 104  batch: 57  loss: 0.07754411\n",
      "epoch: 104  batch: 58  loss: 0.09792807\n",
      "epoch: 104  batch: 59  loss: 0.09026396\n",
      "epoch: 104  batch: 60  loss: 0.10359090\n",
      "epoch: 104  batch: 61  loss: 0.07104100\n",
      "epoch: 104  batch: 62  loss: 0.09803769\n",
      "epoch: 104  batch: 63  loss: 0.09452157\n",
      "epoch: 104  batch: 64  loss: 0.07073658\n",
      "epoch: 104  batch: 65  loss: 0.09332680\n",
      "epoch: 104  batch: 66  loss: 0.11255868\n",
      "epoch: 104  batch: 67  loss: 0.05706983\n",
      "epoch: 104  batch: 68  loss: 0.07781979\n",
      "epoch: 104  batch: 69  loss: 0.06207672\n",
      "epoch: 104  batch: 70  loss: 0.07818288\n",
      "epoch: 104  batch: 71  loss: 0.05050287\n",
      "epoch: 104  batch: 72  loss: 0.11845759\n",
      "epoch: 104  batch: 73  loss: 0.08304701\n",
      "epoch: 104  batch: 74  loss: 0.06579070\n",
      "epoch: 104  batch: 75  loss: 0.07606980\n",
      "epoch: 104  batch: 76  loss: 0.06973154\n",
      "epoch: 104  batch: 77  loss: 0.04467434\n",
      "epoch: 104  batch: 78  loss: 0.10862890\n",
      "epoch: 104  batch: 79  loss: 0.09054326\n",
      "epoch: 104  batch: 80  loss: 0.06597053\n",
      "epoch: 104  batch: 81  loss: 0.09112027\n",
      "epoch: 104  batch: 82  loss: 0.05426491\n",
      "epoch: 104  batch: 83  loss: 0.11206283\n",
      "epoch: 104  batch: 84  loss: 0.07584180\n",
      "epoch: 104  batch: 85  loss: 0.05214547\n",
      "epoch: 104  batch: 86  loss: 0.08522278\n",
      "epoch: 104  batch: 87  loss: 0.05552655\n",
      "epoch: 105  batch: 1  loss: 0.07212614\n",
      "epoch: 105  batch: 2  loss: 0.05846520\n",
      "epoch: 105  batch: 3  loss: 0.07688431\n",
      "epoch: 105  batch: 4  loss: 0.07803283\n",
      "epoch: 105  batch: 5  loss: 0.11275654\n",
      "epoch: 105  batch: 6  loss: 0.05412813\n",
      "epoch: 105  batch: 7  loss: 0.06471673\n",
      "epoch: 105  batch: 8  loss: 0.10191381\n",
      "epoch: 105  batch: 9  loss: 0.07344297\n",
      "epoch: 105  batch: 10  loss: 0.09700588\n",
      "epoch: 105  batch: 11  loss: 0.07845221\n",
      "epoch: 105  batch: 12  loss: 0.06776819\n",
      "epoch: 105  batch: 13  loss: 0.07978095\n",
      "epoch: 105  batch: 14  loss: 0.09446019\n",
      "epoch: 105  batch: 15  loss: 0.08127264\n",
      "epoch: 105  batch: 16  loss: 0.08594200\n",
      "epoch: 105  batch: 17  loss: 0.05876619\n",
      "epoch: 105  batch: 18  loss: 0.07205179\n",
      "epoch: 105  batch: 19  loss: 0.06322629\n",
      "epoch: 105  batch: 20  loss: 0.09704506\n",
      "epoch: 105  batch: 21  loss: 0.12187891\n",
      "epoch: 105  batch: 22  loss: 0.06487560\n",
      "epoch: 105  batch: 23  loss: 0.10848740\n",
      "epoch: 105  batch: 24  loss: 0.08731100\n",
      "epoch: 105  batch: 25  loss: 0.05665946\n",
      "epoch: 105  batch: 26  loss: 0.06453636\n",
      "epoch: 105  batch: 27  loss: 0.08368053\n",
      "epoch: 105  batch: 28  loss: 0.10229476\n",
      "epoch: 105  batch: 29  loss: 0.05807156\n",
      "epoch: 105  batch: 30  loss: 0.08322415\n",
      "epoch: 105  batch: 31  loss: 0.06894109\n",
      "epoch: 105  batch: 32  loss: 0.09022893\n",
      "epoch: 105  batch: 33  loss: 0.05472342\n",
      "epoch: 105  batch: 34  loss: 0.10613610\n",
      "epoch: 105  batch: 35  loss: 0.08854526\n",
      "epoch: 105  batch: 36  loss: 0.06544206\n",
      "epoch: 105  batch: 37  loss: 0.06582167\n",
      "epoch: 105  batch: 38  loss: 0.11196063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 105  batch: 39  loss: 0.06708823\n",
      "epoch: 105  batch: 40  loss: 0.12227206\n",
      "epoch: 105  batch: 41  loss: 0.08163281\n",
      "epoch: 105  batch: 42  loss: 0.10692452\n",
      "epoch: 105  batch: 43  loss: 0.07238971\n",
      "epoch: 105  batch: 44  loss: 0.07981921\n",
      "epoch: 105  batch: 45  loss: 0.09386007\n",
      "epoch: 105  batch: 46  loss: 0.07170933\n",
      "epoch: 105  batch: 47  loss: 0.08356217\n",
      "epoch: 105  batch: 48  loss: 0.05525863\n",
      "epoch: 105  batch: 49  loss: 0.08229253\n",
      "epoch: 105  batch: 50  loss: 0.08851048\n",
      "epoch: 105  batch: 51  loss: 0.07894333\n",
      "epoch: 105  batch: 52  loss: 0.07916678\n",
      "epoch: 105  batch: 53  loss: 0.08337769\n",
      "epoch: 105  batch: 54  loss: 0.11362970\n",
      "epoch: 105  batch: 55  loss: 0.07226780\n",
      "epoch: 105  batch: 56  loss: 0.08897947\n",
      "epoch: 105  batch: 57  loss: 0.14035702\n",
      "epoch: 105  batch: 58  loss: 0.07083104\n",
      "epoch: 105  batch: 59  loss: 0.07674942\n",
      "epoch: 105  batch: 60  loss: 0.07885639\n",
      "epoch: 105  batch: 61  loss: 0.08605136\n",
      "epoch: 105  batch: 62  loss: 0.07980818\n",
      "epoch: 105  batch: 63  loss: 0.07239538\n",
      "epoch: 105  batch: 64  loss: 0.09659581\n",
      "epoch: 105  batch: 65  loss: 0.06844380\n",
      "epoch: 105  batch: 66  loss: 0.07675608\n",
      "epoch: 105  batch: 67  loss: 0.05118449\n",
      "epoch: 105  batch: 68  loss: 0.09939813\n",
      "epoch: 105  batch: 69  loss: 0.13599955\n",
      "epoch: 105  batch: 70  loss: 0.11096733\n",
      "epoch: 105  batch: 71  loss: 0.09210452\n",
      "epoch: 105  batch: 72  loss: 0.08722118\n",
      "epoch: 105  batch: 73  loss: 0.06728289\n",
      "epoch: 105  batch: 74  loss: 0.06891306\n",
      "epoch: 105  batch: 75  loss: 0.08594909\n",
      "epoch: 105  batch: 76  loss: 0.07970805\n",
      "epoch: 105  batch: 77  loss: 0.06321695\n",
      "epoch: 105  batch: 78  loss: 0.07808878\n",
      "epoch: 105  batch: 79  loss: 0.06258001\n",
      "epoch: 105  batch: 80  loss: 0.11843235\n",
      "epoch: 105  batch: 81  loss: 0.09524236\n",
      "epoch: 105  batch: 82  loss: 0.06181214\n",
      "epoch: 105  batch: 83  loss: 0.11808068\n",
      "epoch: 105  batch: 84  loss: 0.09209447\n",
      "epoch: 105  batch: 85  loss: 0.08166689\n",
      "epoch: 105  batch: 86  loss: 0.08058946\n",
      "epoch: 105  batch: 87  loss: 0.09834624\n",
      "epoch: 106  batch: 1  loss: 0.08814581\n",
      "epoch: 106  batch: 2  loss: 0.06958624\n",
      "epoch: 106  batch: 3  loss: 0.08233085\n",
      "epoch: 106  batch: 4  loss: 0.07041682\n",
      "epoch: 106  batch: 5  loss: 0.08616357\n",
      "epoch: 106  batch: 6  loss: 0.09211032\n",
      "epoch: 106  batch: 7  loss: 0.09603070\n",
      "epoch: 106  batch: 8  loss: 0.10928228\n",
      "epoch: 106  batch: 9  loss: 0.11850116\n",
      "epoch: 106  batch: 10  loss: 0.05443898\n",
      "epoch: 106  batch: 11  loss: 0.09605504\n",
      "epoch: 106  batch: 12  loss: 0.06852727\n",
      "epoch: 106  batch: 13  loss: 0.09808438\n",
      "epoch: 106  batch: 14  loss: 0.05095127\n",
      "epoch: 106  batch: 15  loss: 0.07462791\n",
      "epoch: 106  batch: 16  loss: 0.12226981\n",
      "epoch: 106  batch: 17  loss: 0.10167045\n",
      "epoch: 106  batch: 18  loss: 0.10397144\n",
      "epoch: 106  batch: 19  loss: 0.08822805\n",
      "epoch: 106  batch: 20  loss: 0.07355263\n",
      "epoch: 106  batch: 21  loss: 0.06720249\n",
      "epoch: 106  batch: 22  loss: 0.11758737\n",
      "epoch: 106  batch: 23  loss: 0.05003240\n",
      "epoch: 106  batch: 24  loss: 0.09178429\n",
      "epoch: 106  batch: 25  loss: 0.10731289\n",
      "epoch: 106  batch: 26  loss: 0.06916406\n",
      "epoch: 106  batch: 27  loss: 0.07575322\n",
      "epoch: 106  batch: 28  loss: 0.09131803\n",
      "epoch: 106  batch: 29  loss: 0.07472482\n",
      "epoch: 106  batch: 30  loss: 0.06735520\n",
      "epoch: 106  batch: 31  loss: 0.06397878\n",
      "epoch: 106  batch: 32  loss: 0.06427012\n",
      "epoch: 106  batch: 33  loss: 0.05598299\n",
      "epoch: 106  batch: 34  loss: 0.08381637\n",
      "epoch: 106  batch: 35  loss: 0.06594394\n",
      "epoch: 106  batch: 36  loss: 0.10070263\n",
      "epoch: 106  batch: 37  loss: 0.07603598\n",
      "epoch: 106  batch: 38  loss: 0.07601185\n",
      "epoch: 106  batch: 39  loss: 0.06445518\n",
      "epoch: 106  batch: 40  loss: 0.06808926\n",
      "epoch: 106  batch: 41  loss: 0.07025109\n",
      "epoch: 106  batch: 42  loss: 0.08694606\n",
      "epoch: 106  batch: 43  loss: 0.06636508\n",
      "epoch: 106  batch: 44  loss: 0.08710945\n",
      "epoch: 106  batch: 45  loss: 0.07095762\n",
      "epoch: 106  batch: 46  loss: 0.06687718\n",
      "epoch: 106  batch: 47  loss: 0.07360030\n",
      "epoch: 106  batch: 48  loss: 0.06965455\n",
      "epoch: 106  batch: 49  loss: 0.09036298\n",
      "epoch: 106  batch: 50  loss: 0.11968532\n",
      "epoch: 106  batch: 51  loss: 0.05991007\n",
      "epoch: 106  batch: 52  loss: 0.09590425\n",
      "epoch: 106  batch: 53  loss: 0.06576607\n",
      "epoch: 106  batch: 54  loss: 0.08354947\n",
      "epoch: 106  batch: 55  loss: 0.09174397\n",
      "epoch: 106  batch: 56  loss: 0.05811505\n",
      "epoch: 106  batch: 57  loss: 0.08272775\n",
      "epoch: 106  batch: 58  loss: 0.06463958\n",
      "epoch: 106  batch: 59  loss: 0.09973154\n",
      "epoch: 106  batch: 60  loss: 0.06796034\n",
      "epoch: 106  batch: 61  loss: 0.11848257\n",
      "epoch: 106  batch: 62  loss: 0.07688372\n",
      "epoch: 106  batch: 63  loss: 0.05197107\n",
      "epoch: 106  batch: 64  loss: 0.07839432\n",
      "epoch: 106  batch: 65  loss: 0.07940164\n",
      "epoch: 106  batch: 66  loss: 0.09649924\n",
      "epoch: 106  batch: 67  loss: 0.10347708\n",
      "epoch: 106  batch: 68  loss: 0.05481697\n",
      "epoch: 106  batch: 69  loss: 0.09594478\n",
      "epoch: 106  batch: 70  loss: 0.08352489\n",
      "epoch: 106  batch: 71  loss: 0.12033228\n",
      "epoch: 106  batch: 72  loss: 0.07011786\n",
      "epoch: 106  batch: 73  loss: 0.04981460\n",
      "epoch: 106  batch: 74  loss: 0.09913212\n",
      "epoch: 106  batch: 75  loss: 0.05634577\n",
      "epoch: 106  batch: 76  loss: 0.09182555\n",
      "epoch: 106  batch: 77  loss: 0.05380563\n",
      "epoch: 106  batch: 78  loss: 0.09765816\n",
      "epoch: 106  batch: 79  loss: 0.06848311\n",
      "epoch: 106  batch: 80  loss: 0.10449071\n",
      "epoch: 106  batch: 81  loss: 0.07916380\n",
      "epoch: 106  batch: 82  loss: 0.09806801\n",
      "epoch: 106  batch: 83  loss: 0.05822033\n",
      "epoch: 106  batch: 84  loss: 0.11601285\n",
      "epoch: 106  batch: 85  loss: 0.06866621\n",
      "epoch: 106  batch: 86  loss: 0.07632427\n",
      "epoch: 106  batch: 87  loss: 0.08068887\n",
      "epoch: 107  batch: 1  loss: 0.07987753\n",
      "epoch: 107  batch: 2  loss: 0.07749923\n",
      "epoch: 107  batch: 3  loss: 0.05169424\n",
      "epoch: 107  batch: 4  loss: 0.11410760\n",
      "epoch: 107  batch: 5  loss: 0.11783425\n",
      "epoch: 107  batch: 6  loss: 0.09323086\n",
      "epoch: 107  batch: 7  loss: 0.08623178\n",
      "epoch: 107  batch: 8  loss: 0.11882952\n",
      "epoch: 107  batch: 9  loss: 0.11629677\n",
      "epoch: 107  batch: 10  loss: 0.06956183\n",
      "epoch: 107  batch: 11  loss: 0.07619624\n",
      "epoch: 107  batch: 12  loss: 0.08531864\n",
      "epoch: 107  batch: 13  loss: 0.07989420\n",
      "epoch: 107  batch: 14  loss: 0.08257982\n",
      "epoch: 107  batch: 15  loss: 0.10941483\n",
      "epoch: 107  batch: 16  loss: 0.06182680\n",
      "epoch: 107  batch: 17  loss: 0.05413408\n",
      "epoch: 107  batch: 18  loss: 0.07618983\n",
      "epoch: 107  batch: 19  loss: 0.08701703\n",
      "epoch: 107  batch: 20  loss: 0.06976387\n",
      "epoch: 107  batch: 21  loss: 0.07157192\n",
      "epoch: 107  batch: 22  loss: 0.15423691\n",
      "epoch: 107  batch: 23  loss: 0.07847084\n",
      "epoch: 107  batch: 24  loss: 0.07343417\n",
      "epoch: 107  batch: 25  loss: 0.05677902\n",
      "epoch: 107  batch: 26  loss: 0.07393661\n",
      "epoch: 107  batch: 27  loss: 0.06351320\n",
      "epoch: 107  batch: 28  loss: 0.05790715\n",
      "epoch: 107  batch: 29  loss: 0.07859483\n",
      "epoch: 107  batch: 30  loss: 0.07865994\n",
      "epoch: 107  batch: 31  loss: 0.07208797\n",
      "epoch: 107  batch: 32  loss: 0.06740293\n",
      "epoch: 107  batch: 33  loss: 0.06965347\n",
      "epoch: 107  batch: 34  loss: 0.07907119\n",
      "epoch: 107  batch: 35  loss: 0.08140621\n",
      "epoch: 107  batch: 36  loss: 0.07152610\n",
      "epoch: 107  batch: 37  loss: 0.10353588\n",
      "epoch: 107  batch: 38  loss: 0.08280546\n",
      "epoch: 107  batch: 39  loss: 0.06206021\n",
      "epoch: 107  batch: 40  loss: 0.08120597\n",
      "epoch: 107  batch: 41  loss: 0.06794013\n",
      "epoch: 107  batch: 42  loss: 0.09271899\n",
      "epoch: 107  batch: 43  loss: 0.11692630\n",
      "epoch: 107  batch: 44  loss: 0.06946799\n",
      "epoch: 107  batch: 45  loss: 0.07077724\n",
      "epoch: 107  batch: 46  loss: 0.09280556\n",
      "epoch: 107  batch: 47  loss: 0.07649236\n",
      "epoch: 107  batch: 48  loss: 0.15124825\n",
      "epoch: 107  batch: 49  loss: 0.07705192\n",
      "epoch: 107  batch: 50  loss: 0.08083458\n",
      "epoch: 107  batch: 51  loss: 0.05580669\n",
      "epoch: 107  batch: 52  loss: 0.11729244\n",
      "epoch: 107  batch: 53  loss: 0.07397941\n",
      "epoch: 107  batch: 54  loss: 0.08982432\n",
      "epoch: 107  batch: 55  loss: 0.07506803\n",
      "epoch: 107  batch: 56  loss: 0.06760679\n",
      "epoch: 107  batch: 57  loss: 0.11893899\n",
      "epoch: 107  batch: 58  loss: 0.08278345\n",
      "epoch: 107  batch: 59  loss: 0.08020358\n",
      "epoch: 107  batch: 60  loss: 0.06532734\n",
      "epoch: 107  batch: 61  loss: 0.09075305\n",
      "epoch: 107  batch: 62  loss: 0.10416921\n",
      "epoch: 107  batch: 63  loss: 0.10315697\n",
      "epoch: 107  batch: 64  loss: 0.07758530\n",
      "epoch: 107  batch: 65  loss: 0.11181174\n",
      "epoch: 107  batch: 66  loss: 0.14540467\n",
      "epoch: 107  batch: 67  loss: 0.08818357\n",
      "epoch: 107  batch: 68  loss: 0.05396432\n",
      "epoch: 107  batch: 69  loss: 0.12667891\n",
      "epoch: 107  batch: 70  loss: 0.07920902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 107  batch: 71  loss: 0.07387669\n",
      "epoch: 107  batch: 72  loss: 0.09236459\n",
      "epoch: 107  batch: 73  loss: 0.09285388\n",
      "epoch: 107  batch: 74  loss: 0.07579149\n",
      "epoch: 107  batch: 75  loss: 0.06259294\n",
      "epoch: 107  batch: 76  loss: 0.08015227\n",
      "epoch: 107  batch: 77  loss: 0.08879016\n",
      "epoch: 107  batch: 78  loss: 0.08800561\n",
      "epoch: 107  batch: 79  loss: 0.07283517\n",
      "epoch: 107  batch: 80  loss: 0.09465522\n",
      "epoch: 107  batch: 81  loss: 0.07795621\n",
      "epoch: 107  batch: 82  loss: 0.06230579\n",
      "epoch: 107  batch: 83  loss: 0.10478303\n",
      "epoch: 107  batch: 84  loss: 0.09594613\n",
      "epoch: 107  batch: 85  loss: 0.06719348\n",
      "epoch: 107  batch: 86  loss: 0.06208622\n",
      "epoch: 107  batch: 87  loss: 0.05930498\n",
      "epoch: 108  batch: 1  loss: 0.06385328\n",
      "epoch: 108  batch: 2  loss: 0.07682217\n",
      "epoch: 108  batch: 3  loss: 0.09351369\n",
      "epoch: 108  batch: 4  loss: 0.08011696\n",
      "epoch: 108  batch: 5  loss: 0.05090416\n",
      "epoch: 108  batch: 6  loss: 0.09492669\n",
      "epoch: 108  batch: 7  loss: 0.07838159\n",
      "epoch: 108  batch: 8  loss: 0.11437493\n",
      "epoch: 108  batch: 9  loss: 0.05517426\n",
      "epoch: 108  batch: 10  loss: 0.06510230\n",
      "epoch: 108  batch: 11  loss: 0.08551537\n",
      "epoch: 108  batch: 12  loss: 0.07537020\n",
      "epoch: 108  batch: 13  loss: 0.06369602\n",
      "epoch: 108  batch: 14  loss: 0.06052929\n",
      "epoch: 108  batch: 15  loss: 0.07539037\n",
      "epoch: 108  batch: 16  loss: 0.08095707\n",
      "epoch: 108  batch: 17  loss: 0.08127585\n",
      "epoch: 108  batch: 18  loss: 0.06162828\n",
      "epoch: 108  batch: 19  loss: 0.07282895\n",
      "epoch: 108  batch: 20  loss: 0.06652989\n",
      "epoch: 108  batch: 21  loss: 0.12386551\n",
      "epoch: 108  batch: 22  loss: 0.10864534\n",
      "epoch: 108  batch: 23  loss: 0.08180283\n",
      "epoch: 108  batch: 24  loss: 0.09905407\n",
      "epoch: 108  batch: 25  loss: 0.09558634\n",
      "epoch: 108  batch: 26  loss: 0.06854464\n",
      "epoch: 108  batch: 27  loss: 0.10097985\n",
      "epoch: 108  batch: 28  loss: 0.09349202\n",
      "epoch: 108  batch: 29  loss: 0.13716526\n",
      "epoch: 108  batch: 30  loss: 0.08213603\n",
      "epoch: 108  batch: 31  loss: 0.08085527\n",
      "epoch: 108  batch: 32  loss: 0.07744047\n",
      "epoch: 108  batch: 33  loss: 0.05638131\n",
      "epoch: 108  batch: 34  loss: 0.07608847\n",
      "epoch: 108  batch: 35  loss: 0.08301654\n",
      "epoch: 108  batch: 36  loss: 0.09338754\n",
      "epoch: 108  batch: 37  loss: 0.06833571\n",
      "epoch: 108  batch: 38  loss: 0.07967801\n",
      "epoch: 108  batch: 39  loss: 0.11618119\n",
      "epoch: 108  batch: 40  loss: 0.07381407\n",
      "epoch: 108  batch: 41  loss: 0.05541817\n",
      "epoch: 108  batch: 42  loss: 0.07795187\n",
      "epoch: 108  batch: 43  loss: 0.06857972\n",
      "epoch: 108  batch: 44  loss: 0.06987198\n",
      "epoch: 108  batch: 45  loss: 0.08336255\n",
      "epoch: 108  batch: 46  loss: 0.07168231\n",
      "epoch: 108  batch: 47  loss: 0.10057981\n",
      "epoch: 108  batch: 48  loss: 0.07643311\n",
      "epoch: 108  batch: 49  loss: 0.09813165\n",
      "epoch: 108  batch: 50  loss: 0.07372828\n",
      "epoch: 108  batch: 51  loss: 0.05451659\n",
      "epoch: 108  batch: 52  loss: 0.09228837\n",
      "epoch: 108  batch: 53  loss: 0.10681923\n",
      "epoch: 108  batch: 54  loss: 0.06893963\n",
      "epoch: 108  batch: 55  loss: 0.07840274\n",
      "epoch: 108  batch: 56  loss: 0.06397109\n",
      "epoch: 108  batch: 57  loss: 0.07023281\n",
      "epoch: 108  batch: 58  loss: 0.07086857\n",
      "epoch: 108  batch: 59  loss: 0.11505643\n",
      "epoch: 108  batch: 60  loss: 0.13026834\n",
      "epoch: 108  batch: 61  loss: 0.08883490\n",
      "epoch: 108  batch: 62  loss: 0.06180066\n",
      "epoch: 108  batch: 63  loss: 0.08368782\n",
      "epoch: 108  batch: 64  loss: 0.12317736\n",
      "epoch: 108  batch: 65  loss: 0.06648159\n",
      "epoch: 108  batch: 66  loss: 0.06999836\n",
      "epoch: 108  batch: 67  loss: 0.09303240\n",
      "epoch: 108  batch: 68  loss: 0.06630775\n",
      "epoch: 108  batch: 69  loss: 0.07607499\n",
      "epoch: 108  batch: 70  loss: 0.08033284\n",
      "epoch: 108  batch: 71  loss: 0.10315546\n",
      "epoch: 108  batch: 72  loss: 0.10421232\n",
      "epoch: 108  batch: 73  loss: 0.06681067\n",
      "epoch: 108  batch: 74  loss: 0.07450794\n",
      "epoch: 108  batch: 75  loss: 0.05415257\n",
      "epoch: 108  batch: 76  loss: 0.05410514\n",
      "epoch: 108  batch: 77  loss: 0.07666298\n",
      "epoch: 108  batch: 78  loss: 0.06511652\n",
      "epoch: 108  batch: 79  loss: 0.08584686\n",
      "epoch: 108  batch: 80  loss: 0.09693427\n",
      "epoch: 108  batch: 81  loss: 0.08322865\n",
      "epoch: 108  batch: 82  loss: 0.07645033\n",
      "epoch: 108  batch: 83  loss: 0.06008210\n",
      "epoch: 108  batch: 84  loss: 0.07995860\n",
      "epoch: 108  batch: 85  loss: 0.07089922\n",
      "epoch: 108  batch: 86  loss: 0.05374487\n",
      "epoch: 108  batch: 87  loss: 0.10976806\n",
      "epoch: 109  batch: 1  loss: 0.13202102\n",
      "epoch: 109  batch: 2  loss: 0.06114681\n",
      "epoch: 109  batch: 3  loss: 0.07828733\n",
      "epoch: 109  batch: 4  loss: 0.07577278\n",
      "epoch: 109  batch: 5  loss: 0.08694149\n",
      "epoch: 109  batch: 6  loss: 0.09786125\n",
      "epoch: 109  batch: 7  loss: 0.06914168\n",
      "epoch: 109  batch: 8  loss: 0.06712048\n",
      "epoch: 109  batch: 9  loss: 0.11347818\n",
      "epoch: 109  batch: 10  loss: 0.08654562\n",
      "epoch: 109  batch: 11  loss: 0.09145352\n",
      "epoch: 109  batch: 12  loss: 0.06171999\n",
      "epoch: 109  batch: 13  loss: 0.07506129\n",
      "epoch: 109  batch: 14  loss: 0.05998619\n",
      "epoch: 109  batch: 15  loss: 0.08837193\n",
      "epoch: 109  batch: 16  loss: 0.06963582\n",
      "epoch: 109  batch: 17  loss: 0.07137091\n",
      "epoch: 109  batch: 18  loss: 0.09120188\n",
      "epoch: 109  batch: 19  loss: 0.11315238\n",
      "epoch: 109  batch: 20  loss: 0.12442429\n",
      "epoch: 109  batch: 21  loss: 0.07716552\n",
      "epoch: 109  batch: 22  loss: 0.06193774\n",
      "epoch: 109  batch: 23  loss: 0.05276270\n",
      "epoch: 109  batch: 24  loss: 0.06034306\n",
      "epoch: 109  batch: 25  loss: 0.09644961\n",
      "epoch: 109  batch: 26  loss: 0.12905388\n",
      "epoch: 109  batch: 27  loss: 0.06245413\n",
      "epoch: 109  batch: 28  loss: 0.07329744\n",
      "epoch: 109  batch: 29  loss: 0.07066838\n",
      "epoch: 109  batch: 30  loss: 0.07537939\n",
      "epoch: 109  batch: 31  loss: 0.09816901\n",
      "epoch: 109  batch: 32  loss: 0.06352220\n",
      "epoch: 109  batch: 33  loss: 0.05676563\n",
      "epoch: 109  batch: 34  loss: 0.08977817\n",
      "epoch: 109  batch: 35  loss: 0.07084006\n",
      "epoch: 109  batch: 36  loss: 0.10711806\n",
      "epoch: 109  batch: 37  loss: 0.07163539\n",
      "epoch: 109  batch: 38  loss: 0.06633100\n",
      "epoch: 109  batch: 39  loss: 0.11193031\n",
      "epoch: 109  batch: 40  loss: 0.08671014\n",
      "epoch: 109  batch: 41  loss: 0.07343309\n",
      "epoch: 109  batch: 42  loss: 0.06312795\n",
      "epoch: 109  batch: 43  loss: 0.06428472\n",
      "epoch: 109  batch: 44  loss: 0.07318599\n",
      "epoch: 109  batch: 45  loss: 0.10067244\n",
      "epoch: 109  batch: 46  loss: 0.08097894\n",
      "epoch: 109  batch: 47  loss: 0.09026110\n",
      "epoch: 109  batch: 48  loss: 0.08230786\n",
      "epoch: 109  batch: 49  loss: 0.12356668\n",
      "epoch: 109  batch: 50  loss: 0.11396440\n",
      "epoch: 109  batch: 51  loss: 0.06137156\n",
      "epoch: 109  batch: 52  loss: 0.12246375\n",
      "epoch: 109  batch: 53  loss: 0.06752035\n",
      "epoch: 109  batch: 54  loss: 0.08479826\n",
      "epoch: 109  batch: 55  loss: 0.05910116\n",
      "epoch: 109  batch: 56  loss: 0.14334248\n",
      "epoch: 109  batch: 57  loss: 0.10523097\n",
      "epoch: 109  batch: 58  loss: 0.05520948\n",
      "epoch: 109  batch: 59  loss: 0.07456098\n",
      "epoch: 109  batch: 60  loss: 0.07756542\n",
      "epoch: 109  batch: 61  loss: 0.06435531\n",
      "epoch: 109  batch: 62  loss: 0.07469464\n",
      "epoch: 109  batch: 63  loss: 0.12329371\n",
      "epoch: 109  batch: 64  loss: 0.10342893\n",
      "epoch: 109  batch: 65  loss: 0.06998028\n",
      "epoch: 109  batch: 66  loss: 0.05800142\n",
      "epoch: 109  batch: 67  loss: 0.06773441\n",
      "epoch: 109  batch: 68  loss: 0.07360020\n",
      "epoch: 109  batch: 69  loss: 0.08632661\n",
      "epoch: 109  batch: 70  loss: 0.07424573\n",
      "epoch: 109  batch: 71  loss: 0.09115008\n",
      "epoch: 109  batch: 72  loss: 0.08495562\n",
      "epoch: 109  batch: 73  loss: 0.07175477\n",
      "epoch: 109  batch: 74  loss: 0.10791453\n",
      "epoch: 109  batch: 75  loss: 0.09040799\n",
      "epoch: 109  batch: 76  loss: 0.06841440\n",
      "epoch: 109  batch: 77  loss: 0.07067132\n",
      "epoch: 109  batch: 78  loss: 0.06664295\n",
      "epoch: 109  batch: 79  loss: 0.06760460\n",
      "epoch: 109  batch: 80  loss: 0.11494106\n",
      "epoch: 109  batch: 81  loss: 0.05399354\n",
      "epoch: 109  batch: 82  loss: 0.09431490\n",
      "epoch: 109  batch: 83  loss: 0.07686523\n",
      "epoch: 109  batch: 84  loss: 0.08980944\n",
      "epoch: 109  batch: 85  loss: 0.08634445\n",
      "epoch: 109  batch: 86  loss: 0.08366708\n",
      "epoch: 109  batch: 87  loss: 0.08453584\n",
      "epoch: 110  batch: 1  loss: 0.08424243\n",
      "epoch: 110  batch: 2  loss: 0.10410150\n",
      "epoch: 110  batch: 3  loss: 0.12186560\n",
      "epoch: 110  batch: 4  loss: 0.06539233\n",
      "epoch: 110  batch: 5  loss: 0.06393814\n",
      "epoch: 110  batch: 6  loss: 0.08339200\n",
      "epoch: 110  batch: 7  loss: 0.04963474\n",
      "epoch: 110  batch: 8  loss: 0.06840611\n",
      "epoch: 110  batch: 9  loss: 0.09950487\n",
      "epoch: 110  batch: 10  loss: 0.09836401\n",
      "epoch: 110  batch: 11  loss: 0.08998790\n",
      "epoch: 110  batch: 12  loss: 0.12248456\n",
      "epoch: 110  batch: 13  loss: 0.06328224\n",
      "epoch: 110  batch: 14  loss: 0.07496421\n",
      "epoch: 110  batch: 15  loss: 0.10171579\n",
      "epoch: 110  batch: 16  loss: 0.06619941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 110  batch: 17  loss: 0.08357053\n",
      "epoch: 110  batch: 18  loss: 0.08935834\n",
      "epoch: 110  batch: 19  loss: 0.07980040\n",
      "epoch: 110  batch: 20  loss: 0.11159072\n",
      "epoch: 110  batch: 21  loss: 0.07225572\n",
      "epoch: 110  batch: 22  loss: 0.07560068\n",
      "epoch: 110  batch: 23  loss: 0.10229854\n",
      "epoch: 110  batch: 24  loss: 0.11648147\n",
      "epoch: 110  batch: 25  loss: 0.11250677\n",
      "epoch: 110  batch: 26  loss: 0.06591970\n",
      "epoch: 110  batch: 27  loss: 0.09266760\n",
      "epoch: 110  batch: 28  loss: 0.07075963\n",
      "epoch: 110  batch: 29  loss: 0.09175897\n",
      "epoch: 110  batch: 30  loss: 0.06211071\n",
      "epoch: 110  batch: 31  loss: 0.09328306\n",
      "epoch: 110  batch: 32  loss: 0.07519203\n",
      "epoch: 110  batch: 33  loss: 0.04777550\n",
      "epoch: 110  batch: 34  loss: 0.10233556\n",
      "epoch: 110  batch: 35  loss: 0.09419354\n",
      "epoch: 110  batch: 36  loss: 0.06376420\n",
      "epoch: 110  batch: 37  loss: 0.07098167\n",
      "epoch: 110  batch: 38  loss: 0.09111965\n",
      "epoch: 110  batch: 39  loss: 0.09513113\n",
      "epoch: 110  batch: 40  loss: 0.08295951\n",
      "epoch: 110  batch: 41  loss: 0.06590074\n",
      "epoch: 110  batch: 42  loss: 0.08682639\n",
      "epoch: 110  batch: 43  loss: 0.09828866\n",
      "epoch: 110  batch: 44  loss: 0.05061116\n",
      "epoch: 110  batch: 45  loss: 0.06334563\n",
      "epoch: 110  batch: 46  loss: 0.06385268\n",
      "epoch: 110  batch: 47  loss: 0.06624464\n",
      "epoch: 110  batch: 48  loss: 0.10542417\n",
      "epoch: 110  batch: 49  loss: 0.09603477\n",
      "epoch: 110  batch: 50  loss: 0.11195558\n",
      "epoch: 110  batch: 51  loss: 0.05762364\n",
      "epoch: 110  batch: 52  loss: 0.06027928\n",
      "epoch: 110  batch: 53  loss: 0.07046209\n",
      "epoch: 110  batch: 54  loss: 0.05800255\n",
      "epoch: 110  batch: 55  loss: 0.06916898\n",
      "epoch: 110  batch: 56  loss: 0.07350317\n",
      "epoch: 110  batch: 57  loss: 0.07699902\n",
      "epoch: 110  batch: 58  loss: 0.09491129\n",
      "epoch: 110  batch: 59  loss: 0.05748183\n",
      "epoch: 110  batch: 60  loss: 0.09972708\n",
      "epoch: 110  batch: 61  loss: 0.07975142\n",
      "epoch: 110  batch: 62  loss: 0.07339513\n",
      "epoch: 110  batch: 63  loss: 0.09248976\n",
      "epoch: 110  batch: 64  loss: 0.11904116\n",
      "epoch: 110  batch: 65  loss: 0.06718360\n",
      "epoch: 110  batch: 66  loss: 0.05979933\n",
      "epoch: 110  batch: 67  loss: 0.10661074\n",
      "epoch: 110  batch: 68  loss: 0.12142203\n",
      "epoch: 110  batch: 69  loss: 0.08224059\n",
      "epoch: 110  batch: 70  loss: 0.09819838\n",
      "epoch: 110  batch: 71  loss: 0.11556671\n",
      "epoch: 110  batch: 72  loss: 0.11722402\n",
      "epoch: 110  batch: 73  loss: 0.12482344\n",
      "epoch: 110  batch: 74  loss: 0.09560420\n",
      "epoch: 110  batch: 75  loss: 0.11534596\n",
      "epoch: 110  batch: 76  loss: 0.08012057\n",
      "epoch: 110  batch: 77  loss: 0.06376907\n",
      "epoch: 110  batch: 78  loss: 0.06289008\n",
      "epoch: 110  batch: 79  loss: 0.06520144\n",
      "epoch: 110  batch: 80  loss: 0.06987863\n",
      "epoch: 110  batch: 81  loss: 0.07944692\n",
      "epoch: 110  batch: 82  loss: 0.06963612\n",
      "epoch: 110  batch: 83  loss: 0.05918055\n",
      "epoch: 110  batch: 84  loss: 0.12805560\n",
      "epoch: 110  batch: 85  loss: 0.06176193\n",
      "epoch: 110  batch: 86  loss: 0.06916575\n",
      "epoch: 110  batch: 87  loss: 0.07477485\n",
      "epoch: 111  batch: 1  loss: 0.09388204\n",
      "epoch: 111  batch: 2  loss: 0.09193343\n",
      "epoch: 111  batch: 3  loss: 0.07110594\n",
      "epoch: 111  batch: 4  loss: 0.05279710\n",
      "epoch: 111  batch: 5  loss: 0.13678423\n",
      "epoch: 111  batch: 6  loss: 0.07546889\n",
      "epoch: 111  batch: 7  loss: 0.10074500\n",
      "epoch: 111  batch: 8  loss: 0.06632391\n",
      "epoch: 111  batch: 9  loss: 0.10161915\n",
      "epoch: 111  batch: 10  loss: 0.07008917\n",
      "epoch: 111  batch: 11  loss: 0.11061370\n",
      "epoch: 111  batch: 12  loss: 0.12400256\n",
      "epoch: 111  batch: 13  loss: 0.07017782\n",
      "epoch: 111  batch: 14  loss: 0.11856345\n",
      "epoch: 111  batch: 15  loss: 0.06833389\n",
      "epoch: 111  batch: 16  loss: 0.05625614\n",
      "epoch: 111  batch: 17  loss: 0.11184170\n",
      "epoch: 111  batch: 18  loss: 0.05958673\n",
      "epoch: 111  batch: 19  loss: 0.08682439\n",
      "epoch: 111  batch: 20  loss: 0.08741548\n",
      "epoch: 111  batch: 21  loss: 0.08418006\n",
      "epoch: 111  batch: 22  loss: 0.08992386\n",
      "epoch: 111  batch: 23  loss: 0.10781857\n",
      "epoch: 111  batch: 24  loss: 0.12050778\n",
      "epoch: 111  batch: 25  loss: 0.08567369\n",
      "epoch: 111  batch: 26  loss: 0.09431579\n",
      "epoch: 111  batch: 27  loss: 0.14057039\n",
      "epoch: 111  batch: 28  loss: 0.09287973\n",
      "epoch: 111  batch: 29  loss: 0.08211497\n",
      "epoch: 111  batch: 30  loss: 0.09661836\n",
      "epoch: 111  batch: 31  loss: 0.07927114\n",
      "epoch: 111  batch: 32  loss: 0.07222365\n",
      "epoch: 111  batch: 33  loss: 0.07149853\n",
      "epoch: 111  batch: 34  loss: 0.12800667\n",
      "epoch: 111  batch: 35  loss: 0.08713675\n",
      "epoch: 111  batch: 36  loss: 0.10523773\n",
      "epoch: 111  batch: 37  loss: 0.07518478\n",
      "epoch: 111  batch: 38  loss: 0.08519979\n",
      "epoch: 111  batch: 39  loss: 0.16940837\n",
      "epoch: 111  batch: 40  loss: 0.07023121\n",
      "epoch: 111  batch: 41  loss: 0.08950136\n",
      "epoch: 111  batch: 42  loss: 0.07336284\n",
      "epoch: 111  batch: 43  loss: 0.06771202\n",
      "epoch: 111  batch: 44  loss: 0.05799381\n",
      "epoch: 111  batch: 45  loss: 0.09266631\n",
      "epoch: 111  batch: 46  loss: 0.08829845\n",
      "epoch: 111  batch: 47  loss: 0.10843400\n",
      "epoch: 111  batch: 48  loss: 0.05444475\n",
      "epoch: 111  batch: 49  loss: 0.08363301\n",
      "epoch: 111  batch: 50  loss: 0.06470326\n",
      "epoch: 111  batch: 51  loss: 0.07796153\n",
      "epoch: 111  batch: 52  loss: 0.06506126\n",
      "epoch: 111  batch: 53  loss: 0.09572366\n",
      "epoch: 111  batch: 54  loss: 0.08154359\n",
      "epoch: 111  batch: 55  loss: 0.07297658\n",
      "epoch: 111  batch: 56  loss: 0.08815842\n",
      "epoch: 111  batch: 57  loss: 0.08806227\n",
      "epoch: 111  batch: 58  loss: 0.08003885\n",
      "epoch: 111  batch: 59  loss: 0.05401226\n",
      "epoch: 111  batch: 60  loss: 0.06345209\n",
      "epoch: 111  batch: 61  loss: 0.08098472\n",
      "epoch: 111  batch: 62  loss: 0.06823516\n",
      "epoch: 111  batch: 63  loss: 0.05771949\n",
      "epoch: 111  batch: 64  loss: 0.06250497\n",
      "epoch: 111  batch: 65  loss: 0.12107414\n",
      "epoch: 111  batch: 66  loss: 0.07167342\n",
      "epoch: 111  batch: 67  loss: 0.06592932\n",
      "epoch: 111  batch: 68  loss: 0.09481241\n",
      "epoch: 111  batch: 69  loss: 0.05267493\n",
      "epoch: 111  batch: 70  loss: 0.08352976\n",
      "epoch: 111  batch: 71  loss: 0.07744279\n",
      "epoch: 111  batch: 72  loss: 0.06866221\n",
      "epoch: 111  batch: 73  loss: 0.09828287\n",
      "epoch: 111  batch: 74  loss: 0.07728150\n",
      "epoch: 111  batch: 75  loss: 0.04387612\n",
      "epoch: 111  batch: 76  loss: 0.07281289\n",
      "epoch: 111  batch: 77  loss: 0.10771148\n",
      "epoch: 111  batch: 78  loss: 0.07587162\n",
      "epoch: 111  batch: 79  loss: 0.07535955\n",
      "epoch: 111  batch: 80  loss: 0.15780133\n",
      "epoch: 111  batch: 81  loss: 0.07569040\n",
      "epoch: 111  batch: 82  loss: 0.06632383\n",
      "epoch: 111  batch: 83  loss: 0.08111535\n",
      "epoch: 111  batch: 84  loss: 0.12973978\n",
      "epoch: 111  batch: 85  loss: 0.05324177\n",
      "epoch: 111  batch: 86  loss: 0.05734631\n",
      "epoch: 111  batch: 87  loss: 0.09542158\n",
      "epoch: 112  batch: 1  loss: 0.04872121\n",
      "epoch: 112  batch: 2  loss: 0.08548799\n",
      "epoch: 112  batch: 3  loss: 0.10429848\n",
      "epoch: 112  batch: 4  loss: 0.08523557\n",
      "epoch: 112  batch: 5  loss: 0.09199114\n",
      "epoch: 112  batch: 6  loss: 0.08631653\n",
      "epoch: 112  batch: 7  loss: 0.03676233\n",
      "epoch: 112  batch: 8  loss: 0.06307181\n",
      "epoch: 112  batch: 9  loss: 0.08048791\n",
      "epoch: 112  batch: 10  loss: 0.07108925\n",
      "epoch: 112  batch: 11  loss: 0.08950558\n",
      "epoch: 112  batch: 12  loss: 0.11095957\n",
      "epoch: 112  batch: 13  loss: 0.06193203\n",
      "epoch: 112  batch: 14  loss: 0.10462151\n",
      "epoch: 112  batch: 15  loss: 0.08551635\n",
      "epoch: 112  batch: 16  loss: 0.05934113\n",
      "epoch: 112  batch: 17  loss: 0.07470149\n",
      "epoch: 112  batch: 18  loss: 0.11335055\n",
      "epoch: 112  batch: 19  loss: 0.06189576\n",
      "epoch: 112  batch: 20  loss: 0.08620150\n",
      "epoch: 112  batch: 21  loss: 0.06762438\n",
      "epoch: 112  batch: 22  loss: 0.07899402\n",
      "epoch: 112  batch: 23  loss: 0.06264935\n",
      "epoch: 112  batch: 24  loss: 0.11044193\n",
      "epoch: 112  batch: 25  loss: 0.08609553\n",
      "epoch: 112  batch: 26  loss: 0.06223893\n",
      "epoch: 112  batch: 27  loss: 0.07994678\n",
      "epoch: 112  batch: 28  loss: 0.05190715\n",
      "epoch: 112  batch: 29  loss: 0.09176282\n",
      "epoch: 112  batch: 30  loss: 0.07178785\n",
      "epoch: 112  batch: 31  loss: 0.06589270\n",
      "epoch: 112  batch: 32  loss: 0.07363753\n",
      "epoch: 112  batch: 33  loss: 0.10052351\n",
      "epoch: 112  batch: 34  loss: 0.08282425\n",
      "epoch: 112  batch: 35  loss: 0.09170961\n",
      "epoch: 112  batch: 36  loss: 0.10809287\n",
      "epoch: 112  batch: 37  loss: 0.06987741\n",
      "epoch: 112  batch: 38  loss: 0.07222070\n",
      "epoch: 112  batch: 39  loss: 0.08608960\n",
      "epoch: 112  batch: 40  loss: 0.12737656\n",
      "epoch: 112  batch: 41  loss: 0.10139534\n",
      "epoch: 112  batch: 42  loss: 0.10039301\n",
      "epoch: 112  batch: 43  loss: 0.10799880\n",
      "epoch: 112  batch: 44  loss: 0.07674152\n",
      "epoch: 112  batch: 45  loss: 0.06214572\n",
      "epoch: 112  batch: 46  loss: 0.04790165\n",
      "epoch: 112  batch: 47  loss: 0.06371527\n",
      "epoch: 112  batch: 48  loss: 0.10045917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112  batch: 49  loss: 0.11767345\n",
      "epoch: 112  batch: 50  loss: 0.05052925\n",
      "epoch: 112  batch: 51  loss: 0.06907854\n",
      "epoch: 112  batch: 52  loss: 0.09837879\n",
      "epoch: 112  batch: 53  loss: 0.07167761\n",
      "epoch: 112  batch: 54  loss: 0.05524573\n",
      "epoch: 112  batch: 55  loss: 0.14120054\n",
      "epoch: 112  batch: 56  loss: 0.09267922\n",
      "epoch: 112  batch: 57  loss: 0.08569948\n",
      "epoch: 112  batch: 58  loss: 0.07055660\n",
      "epoch: 112  batch: 59  loss: 0.07733858\n",
      "epoch: 112  batch: 60  loss: 0.07474046\n",
      "epoch: 112  batch: 61  loss: 0.07886814\n",
      "epoch: 112  batch: 62  loss: 0.07356430\n",
      "epoch: 112  batch: 63  loss: 0.06375466\n",
      "epoch: 112  batch: 64  loss: 0.06630903\n",
      "epoch: 112  batch: 65  loss: 0.06948597\n",
      "epoch: 112  batch: 66  loss: 0.08385795\n",
      "epoch: 112  batch: 67  loss: 0.04867116\n",
      "epoch: 112  batch: 68  loss: 0.07289723\n",
      "epoch: 112  batch: 69  loss: 0.08640696\n",
      "epoch: 112  batch: 70  loss: 0.07468646\n",
      "epoch: 112  batch: 71  loss: 0.06732347\n",
      "epoch: 112  batch: 72  loss: 0.07033236\n",
      "epoch: 112  batch: 73  loss: 0.08700427\n",
      "epoch: 112  batch: 74  loss: 0.08032531\n",
      "epoch: 112  batch: 75  loss: 0.05822311\n",
      "epoch: 112  batch: 76  loss: 0.14041063\n",
      "epoch: 112  batch: 77  loss: 0.11134525\n",
      "epoch: 112  batch: 78  loss: 0.10203831\n",
      "epoch: 112  batch: 79  loss: 0.05499371\n",
      "epoch: 112  batch: 80  loss: 0.05880598\n",
      "epoch: 112  batch: 81  loss: 0.06441662\n",
      "epoch: 112  batch: 82  loss: 0.09205661\n",
      "epoch: 112  batch: 83  loss: 0.07608647\n",
      "epoch: 112  batch: 84  loss: 0.09781282\n",
      "epoch: 112  batch: 85  loss: 0.05894918\n",
      "epoch: 112  batch: 86  loss: 0.07228687\n",
      "epoch: 112  batch: 87  loss: 0.05970731\n",
      "epoch: 113  batch: 1  loss: 0.07064365\n",
      "epoch: 113  batch: 2  loss: 0.09032081\n",
      "epoch: 113  batch: 3  loss: 0.05284063\n",
      "epoch: 113  batch: 4  loss: 0.05152342\n",
      "epoch: 113  batch: 5  loss: 0.10899819\n",
      "epoch: 113  batch: 6  loss: 0.07565288\n",
      "epoch: 113  batch: 7  loss: 0.08297530\n",
      "epoch: 113  batch: 8  loss: 0.09227038\n",
      "epoch: 113  batch: 9  loss: 0.10700173\n",
      "epoch: 113  batch: 10  loss: 0.05934681\n",
      "epoch: 113  batch: 11  loss: 0.08645575\n",
      "epoch: 113  batch: 12  loss: 0.07680482\n",
      "epoch: 113  batch: 13  loss: 0.09033272\n",
      "epoch: 113  batch: 14  loss: 0.08008139\n",
      "epoch: 113  batch: 15  loss: 0.08436245\n",
      "epoch: 113  batch: 16  loss: 0.05291582\n",
      "epoch: 113  batch: 17  loss: 0.06374669\n",
      "epoch: 113  batch: 18  loss: 0.08890210\n",
      "epoch: 113  batch: 19  loss: 0.08194177\n",
      "epoch: 113  batch: 20  loss: 0.09507284\n",
      "epoch: 113  batch: 21  loss: 0.09450317\n",
      "epoch: 113  batch: 22  loss: 0.07902605\n",
      "epoch: 113  batch: 23  loss: 0.12910514\n",
      "epoch: 113  batch: 24  loss: 0.10497943\n",
      "epoch: 113  batch: 25  loss: 0.06949364\n",
      "epoch: 113  batch: 26  loss: 0.10099801\n",
      "epoch: 113  batch: 27  loss: 0.12379520\n",
      "epoch: 113  batch: 28  loss: 0.07569494\n",
      "epoch: 113  batch: 29  loss: 0.09950946\n",
      "epoch: 113  batch: 30  loss: 0.07125496\n",
      "epoch: 113  batch: 31  loss: 0.06438526\n",
      "epoch: 113  batch: 32  loss: 0.06903887\n",
      "epoch: 113  batch: 33  loss: 0.05705815\n",
      "epoch: 113  batch: 34  loss: 0.06632012\n",
      "epoch: 113  batch: 35  loss: 0.08940110\n",
      "epoch: 113  batch: 36  loss: 0.07612947\n",
      "epoch: 113  batch: 37  loss: 0.06044607\n",
      "epoch: 113  batch: 38  loss: 0.08098759\n",
      "epoch: 113  batch: 39  loss: 0.05733007\n",
      "epoch: 113  batch: 40  loss: 0.06790283\n",
      "epoch: 113  batch: 41  loss: 0.07030797\n",
      "epoch: 113  batch: 42  loss: 0.06540745\n",
      "epoch: 113  batch: 43  loss: 0.05080506\n",
      "epoch: 113  batch: 44  loss: 0.06373440\n",
      "epoch: 113  batch: 45  loss: 0.11204760\n",
      "epoch: 113  batch: 46  loss: 0.06588244\n",
      "epoch: 113  batch: 47  loss: 0.10802650\n",
      "epoch: 113  batch: 48  loss: 0.07240097\n",
      "epoch: 113  batch: 49  loss: 0.07963546\n",
      "epoch: 113  batch: 50  loss: 0.06446480\n",
      "epoch: 113  batch: 51  loss: 0.07164712\n",
      "epoch: 113  batch: 52  loss: 0.09327341\n",
      "epoch: 113  batch: 53  loss: 0.10250165\n",
      "epoch: 113  batch: 54  loss: 0.05725086\n",
      "epoch: 113  batch: 55  loss: 0.07703739\n",
      "epoch: 113  batch: 56  loss: 0.09685754\n",
      "epoch: 113  batch: 57  loss: 0.07846286\n",
      "epoch: 113  batch: 58  loss: 0.09466366\n",
      "epoch: 113  batch: 59  loss: 0.09271339\n",
      "epoch: 113  batch: 60  loss: 0.08036271\n",
      "epoch: 113  batch: 61  loss: 0.07099973\n",
      "epoch: 113  batch: 62  loss: 0.06102156\n",
      "epoch: 113  batch: 63  loss: 0.04979030\n",
      "epoch: 113  batch: 64  loss: 0.05515755\n",
      "epoch: 113  batch: 65  loss: 0.12236328\n",
      "epoch: 113  batch: 66  loss: 0.11936437\n",
      "epoch: 113  batch: 67  loss: 0.11973384\n",
      "epoch: 113  batch: 68  loss: 0.12032308\n",
      "epoch: 113  batch: 69  loss: 0.05687291\n",
      "epoch: 113  batch: 70  loss: 0.09280063\n",
      "epoch: 113  batch: 71  loss: 0.08345552\n",
      "epoch: 113  batch: 72  loss: 0.12107538\n",
      "epoch: 113  batch: 73  loss: 0.12594797\n",
      "epoch: 113  batch: 74  loss: 0.06878924\n",
      "epoch: 113  batch: 75  loss: 0.08231296\n",
      "epoch: 113  batch: 76  loss: 0.06655457\n",
      "epoch: 113  batch: 77  loss: 0.06253751\n",
      "epoch: 113  batch: 78  loss: 0.08074529\n",
      "epoch: 113  batch: 79  loss: 0.05839172\n",
      "epoch: 113  batch: 80  loss: 0.05625593\n",
      "epoch: 113  batch: 81  loss: 0.07914323\n",
      "epoch: 113  batch: 82  loss: 0.07631522\n",
      "epoch: 113  batch: 83  loss: 0.09201665\n",
      "epoch: 113  batch: 84  loss: 0.08139711\n",
      "epoch: 113  batch: 85  loss: 0.08779229\n",
      "epoch: 113  batch: 86  loss: 0.10124961\n",
      "epoch: 113  batch: 87  loss: 0.09551170\n",
      "epoch: 114  batch: 1  loss: 0.13633923\n",
      "epoch: 114  batch: 2  loss: 0.07134111\n",
      "epoch: 114  batch: 3  loss: 0.07209408\n",
      "epoch: 114  batch: 4  loss: 0.09835094\n",
      "epoch: 114  batch: 5  loss: 0.12073789\n",
      "epoch: 114  batch: 6  loss: 0.05489362\n",
      "epoch: 114  batch: 7  loss: 0.07672793\n",
      "epoch: 114  batch: 8  loss: 0.06302521\n",
      "epoch: 114  batch: 9  loss: 0.08460748\n",
      "epoch: 114  batch: 10  loss: 0.08063250\n",
      "epoch: 114  batch: 11  loss: 0.11411778\n",
      "epoch: 114  batch: 12  loss: 0.10003702\n",
      "epoch: 114  batch: 13  loss: 0.06588516\n",
      "epoch: 114  batch: 14  loss: 0.06837575\n",
      "epoch: 114  batch: 15  loss: 0.08828323\n",
      "epoch: 114  batch: 16  loss: 0.06360958\n",
      "epoch: 114  batch: 17  loss: 0.06433776\n",
      "epoch: 114  batch: 18  loss: 0.08688849\n",
      "epoch: 114  batch: 19  loss: 0.06567433\n",
      "epoch: 114  batch: 20  loss: 0.11083927\n",
      "epoch: 114  batch: 21  loss: 0.06858460\n",
      "epoch: 114  batch: 22  loss: 0.11048593\n",
      "epoch: 114  batch: 23  loss: 0.08656881\n",
      "epoch: 114  batch: 24  loss: 0.09297867\n",
      "epoch: 114  batch: 25  loss: 0.05247900\n",
      "epoch: 114  batch: 26  loss: 0.07159623\n",
      "epoch: 114  batch: 27  loss: 0.09597841\n",
      "epoch: 114  batch: 28  loss: 0.06100092\n",
      "epoch: 114  batch: 29  loss: 0.06912861\n",
      "epoch: 114  batch: 30  loss: 0.06455012\n",
      "epoch: 114  batch: 31  loss: 0.08434182\n",
      "epoch: 114  batch: 32  loss: 0.09453943\n",
      "epoch: 114  batch: 33  loss: 0.09805541\n",
      "epoch: 114  batch: 34  loss: 0.15918773\n",
      "epoch: 114  batch: 35  loss: 0.06583311\n",
      "epoch: 114  batch: 36  loss: 0.07895671\n",
      "epoch: 114  batch: 37  loss: 0.06492627\n",
      "epoch: 114  batch: 38  loss: 0.11177173\n",
      "epoch: 114  batch: 39  loss: 0.11181905\n",
      "epoch: 114  batch: 40  loss: 0.07327352\n",
      "epoch: 114  batch: 41  loss: 0.07236839\n",
      "epoch: 114  batch: 42  loss: 0.08729351\n",
      "epoch: 114  batch: 43  loss: 0.05814090\n",
      "epoch: 114  batch: 44  loss: 0.06681683\n",
      "epoch: 114  batch: 45  loss: 0.10471494\n",
      "epoch: 114  batch: 46  loss: 0.08437678\n",
      "epoch: 114  batch: 47  loss: 0.07524840\n",
      "epoch: 114  batch: 48  loss: 0.08056023\n",
      "epoch: 114  batch: 49  loss: 0.08343366\n",
      "epoch: 114  batch: 50  loss: 0.06658337\n",
      "epoch: 114  batch: 51  loss: 0.08693755\n",
      "epoch: 114  batch: 52  loss: 0.07573168\n",
      "epoch: 114  batch: 53  loss: 0.06656298\n",
      "epoch: 114  batch: 54  loss: 0.07566882\n",
      "epoch: 114  batch: 55  loss: 0.08830842\n",
      "epoch: 114  batch: 56  loss: 0.09673224\n",
      "epoch: 114  batch: 57  loss: 0.08911286\n",
      "epoch: 114  batch: 58  loss: 0.07895284\n",
      "epoch: 114  batch: 59  loss: 0.07538050\n",
      "epoch: 114  batch: 60  loss: 0.06558058\n",
      "epoch: 114  batch: 61  loss: 0.07400627\n",
      "epoch: 114  batch: 62  loss: 0.09082799\n",
      "epoch: 114  batch: 63  loss: 0.07434490\n",
      "epoch: 114  batch: 64  loss: 0.07420429\n",
      "epoch: 114  batch: 65  loss: 0.07077489\n",
      "epoch: 114  batch: 66  loss: 0.11478337\n",
      "epoch: 114  batch: 67  loss: 0.09932739\n",
      "epoch: 114  batch: 68  loss: 0.09433681\n",
      "epoch: 114  batch: 69  loss: 0.07610612\n",
      "epoch: 114  batch: 70  loss: 0.07143695\n",
      "epoch: 114  batch: 71  loss: 0.13661419\n",
      "epoch: 114  batch: 72  loss: 0.05986927\n",
      "epoch: 114  batch: 73  loss: 0.09007411\n",
      "epoch: 114  batch: 74  loss: 0.10532607\n",
      "epoch: 114  batch: 75  loss: 0.06926756\n",
      "epoch: 114  batch: 76  loss: 0.05531246\n",
      "epoch: 114  batch: 77  loss: 0.06367227\n",
      "epoch: 114  batch: 78  loss: 0.09079719\n",
      "epoch: 114  batch: 79  loss: 0.12740114\n",
      "epoch: 114  batch: 80  loss: 0.08311504\n",
      "epoch: 114  batch: 81  loss: 0.07110576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114  batch: 82  loss: 0.09796268\n",
      "epoch: 114  batch: 83  loss: 0.07428862\n",
      "epoch: 114  batch: 84  loss: 0.09519878\n",
      "epoch: 114  batch: 85  loss: 0.08861358\n",
      "epoch: 114  batch: 86  loss: 0.06948487\n",
      "epoch: 114  batch: 87  loss: 0.07093823\n",
      "epoch: 115  batch: 1  loss: 0.10910871\n",
      "epoch: 115  batch: 2  loss: 0.09138799\n",
      "epoch: 115  batch: 3  loss: 0.06948222\n",
      "epoch: 115  batch: 4  loss: 0.08715488\n",
      "epoch: 115  batch: 5  loss: 0.08424179\n",
      "epoch: 115  batch: 6  loss: 0.07639734\n",
      "epoch: 115  batch: 7  loss: 0.08256955\n",
      "epoch: 115  batch: 8  loss: 0.06367046\n",
      "epoch: 115  batch: 9  loss: 0.08852627\n",
      "epoch: 115  batch: 10  loss: 0.05741537\n",
      "epoch: 115  batch: 11  loss: 0.05822810\n",
      "epoch: 115  batch: 12  loss: 0.07753912\n",
      "epoch: 115  batch: 13  loss: 0.10416461\n",
      "epoch: 115  batch: 14  loss: 0.07534108\n",
      "epoch: 115  batch: 15  loss: 0.08713351\n",
      "epoch: 115  batch: 16  loss: 0.06386593\n",
      "epoch: 115  batch: 17  loss: 0.06432523\n",
      "epoch: 115  batch: 18  loss: 0.04746212\n",
      "epoch: 115  batch: 19  loss: 0.10238193\n",
      "epoch: 115  batch: 20  loss: 0.05972905\n",
      "epoch: 115  batch: 21  loss: 0.06034944\n",
      "epoch: 115  batch: 22  loss: 0.10333741\n",
      "epoch: 115  batch: 23  loss: 0.06994485\n",
      "epoch: 115  batch: 24  loss: 0.08887020\n",
      "epoch: 115  batch: 25  loss: 0.11441096\n",
      "epoch: 115  batch: 26  loss: 0.08322443\n",
      "epoch: 115  batch: 27  loss: 0.09711997\n",
      "epoch: 115  batch: 28  loss: 0.08308443\n",
      "epoch: 115  batch: 29  loss: 0.10409462\n",
      "epoch: 115  batch: 30  loss: 0.06736904\n",
      "epoch: 115  batch: 31  loss: 0.05849214\n",
      "epoch: 115  batch: 32  loss: 0.06460368\n",
      "epoch: 115  batch: 33  loss: 0.07114339\n",
      "epoch: 115  batch: 34  loss: 0.11660647\n",
      "epoch: 115  batch: 35  loss: 0.07651964\n",
      "epoch: 115  batch: 36  loss: 0.10230028\n",
      "epoch: 115  batch: 37  loss: 0.14439879\n",
      "epoch: 115  batch: 38  loss: 0.07858453\n",
      "epoch: 115  batch: 39  loss: 0.06781782\n",
      "epoch: 115  batch: 40  loss: 0.12592378\n",
      "epoch: 115  batch: 41  loss: 0.07541922\n",
      "epoch: 115  batch: 42  loss: 0.06797748\n",
      "epoch: 115  batch: 43  loss: 0.06436683\n",
      "epoch: 115  batch: 44  loss: 0.12091164\n",
      "epoch: 115  batch: 45  loss: 0.10486677\n",
      "epoch: 115  batch: 46  loss: 0.04964289\n",
      "epoch: 115  batch: 47  loss: 0.11111987\n",
      "epoch: 115  batch: 48  loss: 0.05878759\n",
      "epoch: 115  batch: 49  loss: 0.06710944\n",
      "epoch: 115  batch: 50  loss: 0.06611415\n",
      "epoch: 115  batch: 51  loss: 0.09438483\n",
      "epoch: 115  batch: 52  loss: 0.09593953\n",
      "epoch: 115  batch: 53  loss: 0.12687075\n",
      "epoch: 115  batch: 54  loss: 0.07385433\n",
      "epoch: 115  batch: 55  loss: 0.10799611\n",
      "epoch: 115  batch: 56  loss: 0.09676265\n",
      "epoch: 115  batch: 57  loss: 0.10868578\n",
      "epoch: 115  batch: 58  loss: 0.10009838\n",
      "epoch: 115  batch: 59  loss: 0.08364432\n",
      "epoch: 115  batch: 60  loss: 0.10280658\n",
      "epoch: 115  batch: 61  loss: 0.10858527\n",
      "epoch: 115  batch: 62  loss: 0.08425087\n",
      "epoch: 115  batch: 63  loss: 0.12009201\n",
      "epoch: 115  batch: 64  loss: 0.08656611\n",
      "epoch: 115  batch: 65  loss: 0.06864404\n",
      "epoch: 115  batch: 66  loss: 0.09305526\n",
      "epoch: 115  batch: 67  loss: 0.10804735\n",
      "epoch: 115  batch: 68  loss: 0.10858919\n",
      "epoch: 115  batch: 69  loss: 0.07201917\n",
      "epoch: 115  batch: 70  loss: 0.08166139\n",
      "epoch: 115  batch: 71  loss: 0.09689338\n",
      "epoch: 115  batch: 72  loss: 0.07781631\n",
      "epoch: 115  batch: 73  loss: 0.09729353\n",
      "epoch: 115  batch: 74  loss: 0.07748664\n",
      "epoch: 115  batch: 75  loss: 0.19122405\n",
      "epoch: 115  batch: 76  loss: 0.09202427\n",
      "epoch: 115  batch: 77  loss: 0.08549377\n",
      "epoch: 115  batch: 78  loss: 0.06691622\n",
      "epoch: 115  batch: 79  loss: 0.06489032\n",
      "epoch: 115  batch: 80  loss: 0.06686548\n",
      "epoch: 115  batch: 81  loss: 0.07707807\n",
      "epoch: 115  batch: 82  loss: 0.05716368\n",
      "epoch: 115  batch: 83  loss: 0.07771514\n",
      "epoch: 115  batch: 84  loss: 0.06401733\n",
      "epoch: 115  batch: 85  loss: 0.08496733\n",
      "epoch: 115  batch: 86  loss: 0.07101204\n",
      "epoch: 115  batch: 87  loss: 0.08323303\n",
      "epoch: 116  batch: 1  loss: 0.06328239\n",
      "epoch: 116  batch: 2  loss: 0.06045153\n",
      "epoch: 116  batch: 3  loss: 0.06708875\n",
      "epoch: 116  batch: 4  loss: 0.07143481\n",
      "epoch: 116  batch: 5  loss: 0.08605025\n",
      "epoch: 116  batch: 6  loss: 0.06087563\n",
      "epoch: 116  batch: 7  loss: 0.09958505\n",
      "epoch: 116  batch: 8  loss: 0.08860033\n",
      "epoch: 116  batch: 9  loss: 0.14433353\n",
      "epoch: 116  batch: 10  loss: 0.07823452\n",
      "epoch: 116  batch: 11  loss: 0.08652867\n",
      "epoch: 116  batch: 12  loss: 0.06688457\n",
      "epoch: 116  batch: 13  loss: 0.08496565\n",
      "epoch: 116  batch: 14  loss: 0.07393171\n",
      "epoch: 116  batch: 15  loss: 0.17734112\n",
      "epoch: 116  batch: 16  loss: 0.07455694\n",
      "epoch: 116  batch: 17  loss: 0.08308266\n",
      "epoch: 116  batch: 18  loss: 0.06898174\n",
      "epoch: 116  batch: 19  loss: 0.11739057\n",
      "epoch: 116  batch: 20  loss: 0.08381275\n",
      "epoch: 116  batch: 21  loss: 0.07348139\n",
      "epoch: 116  batch: 22  loss: 0.09659502\n",
      "epoch: 116  batch: 23  loss: 0.12619704\n",
      "epoch: 116  batch: 24  loss: 0.08830209\n",
      "epoch: 116  batch: 25  loss: 0.09940790\n",
      "epoch: 116  batch: 26  loss: 0.06752260\n",
      "epoch: 116  batch: 27  loss: 0.09016711\n",
      "epoch: 116  batch: 28  loss: 0.12149592\n",
      "epoch: 116  batch: 29  loss: 0.06129270\n",
      "epoch: 116  batch: 30  loss: 0.06078072\n",
      "epoch: 116  batch: 31  loss: 0.10235029\n",
      "epoch: 116  batch: 32  loss: 0.12408165\n",
      "epoch: 116  batch: 33  loss: 0.13153096\n",
      "epoch: 116  batch: 34  loss: 0.07281227\n",
      "epoch: 116  batch: 35  loss: 0.06770896\n",
      "epoch: 116  batch: 36  loss: 0.10366490\n",
      "epoch: 116  batch: 37  loss: 0.06952521\n",
      "epoch: 116  batch: 38  loss: 0.06714725\n",
      "epoch: 116  batch: 39  loss: 0.07055122\n",
      "epoch: 116  batch: 40  loss: 0.09311315\n",
      "epoch: 116  batch: 41  loss: 0.06246113\n",
      "epoch: 116  batch: 42  loss: 0.09029809\n",
      "epoch: 116  batch: 43  loss: 0.07270507\n",
      "epoch: 116  batch: 44  loss: 0.10223094\n",
      "epoch: 116  batch: 45  loss: 0.08767112\n",
      "epoch: 116  batch: 46  loss: 0.07437080\n",
      "epoch: 116  batch: 47  loss: 0.11438137\n",
      "epoch: 116  batch: 48  loss: 0.09736066\n",
      "epoch: 116  batch: 49  loss: 0.07700301\n",
      "epoch: 116  batch: 50  loss: 0.06491178\n",
      "epoch: 116  batch: 51  loss: 0.06122843\n",
      "epoch: 116  batch: 52  loss: 0.06130746\n",
      "epoch: 116  batch: 53  loss: 0.09027879\n",
      "epoch: 116  batch: 54  loss: 0.11780145\n",
      "epoch: 116  batch: 55  loss: 0.08798769\n",
      "epoch: 116  batch: 56  loss: 0.09220055\n",
      "epoch: 116  batch: 57  loss: 0.05618272\n",
      "epoch: 116  batch: 58  loss: 0.06559483\n",
      "epoch: 116  batch: 59  loss: 0.07259849\n",
      "epoch: 116  batch: 60  loss: 0.07960544\n",
      "epoch: 116  batch: 61  loss: 0.06894743\n",
      "epoch: 116  batch: 62  loss: 0.08045056\n",
      "epoch: 116  batch: 63  loss: 0.08869357\n",
      "epoch: 116  batch: 64  loss: 0.07243087\n",
      "epoch: 116  batch: 65  loss: 0.09386604\n",
      "epoch: 116  batch: 66  loss: 0.07340857\n",
      "epoch: 116  batch: 67  loss: 0.07749944\n",
      "epoch: 116  batch: 68  loss: 0.08014541\n",
      "epoch: 116  batch: 69  loss: 0.08830497\n",
      "epoch: 116  batch: 70  loss: 0.07436090\n",
      "epoch: 116  batch: 71  loss: 0.12005264\n",
      "epoch: 116  batch: 72  loss: 0.08156972\n",
      "epoch: 116  batch: 73  loss: 0.10004643\n",
      "epoch: 116  batch: 74  loss: 0.05412259\n",
      "epoch: 116  batch: 75  loss: 0.07651333\n",
      "epoch: 116  batch: 76  loss: 0.06341670\n",
      "epoch: 116  batch: 77  loss: 0.10413402\n",
      "epoch: 116  batch: 78  loss: 0.09945760\n",
      "epoch: 116  batch: 79  loss: 0.08737988\n",
      "epoch: 116  batch: 80  loss: 0.11241117\n",
      "epoch: 116  batch: 81  loss: 0.07695653\n",
      "epoch: 116  batch: 82  loss: 0.05848501\n",
      "epoch: 116  batch: 83  loss: 0.12187240\n",
      "epoch: 116  batch: 84  loss: 0.05947805\n",
      "epoch: 116  batch: 85  loss: 0.08176224\n",
      "epoch: 116  batch: 86  loss: 0.09533514\n",
      "epoch: 116  batch: 87  loss: 0.07809544\n",
      "epoch: 117  batch: 1  loss: 0.07927243\n",
      "epoch: 117  batch: 2  loss: 0.17959994\n",
      "epoch: 117  batch: 3  loss: 0.08368023\n",
      "epoch: 117  batch: 4  loss: 0.07501917\n",
      "epoch: 117  batch: 5  loss: 0.06340402\n",
      "epoch: 117  batch: 6  loss: 0.06802778\n",
      "epoch: 117  batch: 7  loss: 0.05765914\n",
      "epoch: 117  batch: 8  loss: 0.11091478\n",
      "epoch: 117  batch: 9  loss: 0.06969195\n",
      "epoch: 117  batch: 10  loss: 0.08498790\n",
      "epoch: 117  batch: 11  loss: 0.11287626\n",
      "epoch: 117  batch: 12  loss: 0.08474537\n",
      "epoch: 117  batch: 13  loss: 0.08915585\n",
      "epoch: 117  batch: 14  loss: 0.11271737\n",
      "epoch: 117  batch: 15  loss: 0.05043229\n",
      "epoch: 117  batch: 16  loss: 0.06971548\n",
      "epoch: 117  batch: 17  loss: 0.12851630\n",
      "epoch: 117  batch: 18  loss: 0.06504850\n",
      "epoch: 117  batch: 19  loss: 0.06043382\n",
      "epoch: 117  batch: 20  loss: 0.05196965\n",
      "epoch: 117  batch: 21  loss: 0.11847846\n",
      "epoch: 117  batch: 22  loss: 0.10075538\n",
      "epoch: 117  batch: 23  loss: 0.12015558\n",
      "epoch: 117  batch: 24  loss: 0.09227480\n",
      "epoch: 117  batch: 25  loss: 0.07799436\n",
      "epoch: 117  batch: 26  loss: 0.05515095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 117  batch: 27  loss: 0.07589096\n",
      "epoch: 117  batch: 28  loss: 0.07277144\n",
      "epoch: 117  batch: 29  loss: 0.07850558\n",
      "epoch: 117  batch: 30  loss: 0.09053490\n",
      "epoch: 117  batch: 31  loss: 0.08521552\n",
      "epoch: 117  batch: 32  loss: 0.09043734\n",
      "epoch: 117  batch: 33  loss: 0.09525046\n",
      "epoch: 117  batch: 34  loss: 0.08985665\n",
      "epoch: 117  batch: 35  loss: 0.08742148\n",
      "epoch: 117  batch: 36  loss: 0.09876376\n",
      "epoch: 117  batch: 37  loss: 0.05023477\n",
      "epoch: 117  batch: 38  loss: 0.08318736\n",
      "epoch: 117  batch: 39  loss: 0.07229359\n",
      "epoch: 117  batch: 40  loss: 0.05915974\n",
      "epoch: 117  batch: 41  loss: 0.07348777\n",
      "epoch: 117  batch: 42  loss: 0.10206090\n",
      "epoch: 117  batch: 43  loss: 0.10717710\n",
      "epoch: 117  batch: 44  loss: 0.04810014\n",
      "epoch: 117  batch: 45  loss: 0.05113397\n",
      "epoch: 117  batch: 46  loss: 0.08172217\n",
      "epoch: 117  batch: 47  loss: 0.05861230\n",
      "epoch: 117  batch: 48  loss: 0.09443320\n",
      "epoch: 117  batch: 49  loss: 0.06416377\n",
      "epoch: 117  batch: 50  loss: 0.05791977\n",
      "epoch: 117  batch: 51  loss: 0.08712745\n",
      "epoch: 117  batch: 52  loss: 0.08558004\n",
      "epoch: 117  batch: 53  loss: 0.05997695\n",
      "epoch: 117  batch: 54  loss: 0.11736756\n",
      "epoch: 117  batch: 55  loss: 0.10113553\n",
      "epoch: 117  batch: 56  loss: 0.08681820\n",
      "epoch: 117  batch: 57  loss: 0.10210200\n",
      "epoch: 117  batch: 58  loss: 0.09176600\n",
      "epoch: 117  batch: 59  loss: 0.08621312\n",
      "epoch: 117  batch: 60  loss: 0.09556928\n",
      "epoch: 117  batch: 61  loss: 0.07853400\n",
      "epoch: 117  batch: 62  loss: 0.10805075\n",
      "epoch: 117  batch: 63  loss: 0.11603143\n",
      "epoch: 117  batch: 64  loss: 0.07464648\n",
      "epoch: 117  batch: 65  loss: 0.11454335\n",
      "epoch: 117  batch: 66  loss: 0.06706229\n",
      "epoch: 117  batch: 67  loss: 0.06360082\n",
      "epoch: 117  batch: 68  loss: 0.10737610\n",
      "epoch: 117  batch: 69  loss: 0.06820755\n",
      "epoch: 117  batch: 70  loss: 0.07564027\n",
      "epoch: 117  batch: 71  loss: 0.10272928\n",
      "epoch: 117  batch: 72  loss: 0.07323686\n",
      "epoch: 117  batch: 73  loss: 0.08080030\n",
      "epoch: 117  batch: 74  loss: 0.07610986\n",
      "epoch: 117  batch: 75  loss: 0.06778052\n",
      "epoch: 117  batch: 76  loss: 0.07789972\n",
      "epoch: 117  batch: 77  loss: 0.06424069\n",
      "epoch: 117  batch: 78  loss: 0.10822503\n",
      "epoch: 117  batch: 79  loss: 0.10219828\n",
      "epoch: 117  batch: 80  loss: 0.07768183\n",
      "epoch: 117  batch: 81  loss: 0.06461781\n",
      "epoch: 117  batch: 82  loss: 0.11512423\n",
      "epoch: 117  batch: 83  loss: 0.08905323\n",
      "epoch: 117  batch: 84  loss: 0.07879277\n",
      "epoch: 117  batch: 85  loss: 0.05881261\n",
      "epoch: 117  batch: 86  loss: 0.05123518\n",
      "epoch: 117  batch: 87  loss: 0.04708219\n",
      "epoch: 118  batch: 1  loss: 0.10000256\n",
      "epoch: 118  batch: 2  loss: 0.07058211\n",
      "epoch: 118  batch: 3  loss: 0.06365315\n",
      "epoch: 118  batch: 4  loss: 0.06802578\n",
      "epoch: 118  batch: 5  loss: 0.09503759\n",
      "epoch: 118  batch: 6  loss: 0.06467694\n",
      "epoch: 118  batch: 7  loss: 0.08598661\n",
      "epoch: 118  batch: 8  loss: 0.07598411\n",
      "epoch: 118  batch: 9  loss: 0.11227719\n",
      "epoch: 118  batch: 10  loss: 0.08710825\n",
      "epoch: 118  batch: 11  loss: 0.08258769\n",
      "epoch: 118  batch: 12  loss: 0.11251878\n",
      "epoch: 118  batch: 13  loss: 0.05541469\n",
      "epoch: 118  batch: 14  loss: 0.07493860\n",
      "epoch: 118  batch: 15  loss: 0.11844678\n",
      "epoch: 118  batch: 16  loss: 0.08625345\n",
      "epoch: 118  batch: 17  loss: 0.09806017\n",
      "epoch: 118  batch: 18  loss: 0.04766134\n",
      "epoch: 118  batch: 19  loss: 0.08280437\n",
      "epoch: 118  batch: 20  loss: 0.09414906\n",
      "epoch: 118  batch: 21  loss: 0.10039483\n",
      "epoch: 118  batch: 22  loss: 0.07789011\n",
      "epoch: 118  batch: 23  loss: 0.12250468\n",
      "epoch: 118  batch: 24  loss: 0.08011524\n",
      "epoch: 118  batch: 25  loss: 0.08947764\n",
      "epoch: 118  batch: 26  loss: 0.06950592\n",
      "epoch: 118  batch: 27  loss: 0.07823833\n",
      "epoch: 118  batch: 28  loss: 0.07696363\n",
      "epoch: 118  batch: 29  loss: 0.05917610\n",
      "epoch: 118  batch: 30  loss: 0.09247518\n",
      "epoch: 118  batch: 31  loss: 0.09133319\n",
      "epoch: 118  batch: 32  loss: 0.09686331\n",
      "epoch: 118  batch: 33  loss: 0.06228204\n",
      "epoch: 118  batch: 34  loss: 0.06425230\n",
      "epoch: 118  batch: 35  loss: 0.10313402\n",
      "epoch: 118  batch: 36  loss: 0.08038530\n",
      "epoch: 118  batch: 37  loss: 0.08629999\n",
      "epoch: 118  batch: 38  loss: 0.11219839\n",
      "epoch: 118  batch: 39  loss: 0.10388909\n",
      "epoch: 118  batch: 40  loss: 0.08673942\n",
      "epoch: 118  batch: 41  loss: 0.08887020\n",
      "epoch: 118  batch: 42  loss: 0.07470278\n",
      "epoch: 118  batch: 43  loss: 0.06557979\n",
      "epoch: 118  batch: 44  loss: 0.07339508\n",
      "epoch: 118  batch: 45  loss: 0.06095349\n",
      "epoch: 118  batch: 46  loss: 0.07680360\n",
      "epoch: 118  batch: 47  loss: 0.10464962\n",
      "epoch: 118  batch: 48  loss: 0.07306798\n",
      "epoch: 118  batch: 49  loss: 0.06009524\n",
      "epoch: 118  batch: 50  loss: 0.11146877\n",
      "epoch: 118  batch: 51  loss: 0.06473044\n",
      "epoch: 118  batch: 52  loss: 0.07046433\n",
      "epoch: 118  batch: 53  loss: 0.09113017\n",
      "epoch: 118  batch: 54  loss: 0.08383340\n",
      "epoch: 118  batch: 55  loss: 0.07311820\n",
      "epoch: 118  batch: 56  loss: 0.06863397\n",
      "epoch: 118  batch: 57  loss: 0.08993157\n",
      "epoch: 118  batch: 58  loss: 0.09903792\n",
      "epoch: 118  batch: 59  loss: 0.08435962\n",
      "epoch: 118  batch: 60  loss: 0.04999716\n",
      "epoch: 118  batch: 61  loss: 0.12493333\n",
      "epoch: 118  batch: 62  loss: 0.06857772\n",
      "epoch: 118  batch: 63  loss: 0.10520506\n",
      "epoch: 118  batch: 64  loss: 0.07519772\n",
      "epoch: 118  batch: 65  loss: 0.09831822\n",
      "epoch: 118  batch: 66  loss: 0.05729554\n",
      "epoch: 118  batch: 67  loss: 0.07232471\n",
      "epoch: 118  batch: 68  loss: 0.09881540\n",
      "epoch: 118  batch: 69  loss: 0.06948154\n",
      "epoch: 118  batch: 70  loss: 0.12196293\n",
      "epoch: 118  batch: 71  loss: 0.10592709\n",
      "epoch: 118  batch: 72  loss: 0.07154896\n",
      "epoch: 118  batch: 73  loss: 0.11552568\n",
      "epoch: 118  batch: 74  loss: 0.10746492\n",
      "epoch: 118  batch: 75  loss: 0.07810963\n",
      "epoch: 118  batch: 76  loss: 0.11307894\n",
      "epoch: 118  batch: 77  loss: 0.15115173\n",
      "epoch: 118  batch: 78  loss: 0.10925664\n",
      "epoch: 118  batch: 79  loss: 0.08040097\n",
      "epoch: 118  batch: 80  loss: 0.09849891\n",
      "epoch: 118  batch: 81  loss: 0.07214184\n",
      "epoch: 118  batch: 82  loss: 0.11234219\n",
      "epoch: 118  batch: 83  loss: 0.08137715\n",
      "epoch: 118  batch: 84  loss: 0.07513196\n",
      "epoch: 118  batch: 85  loss: 0.08346004\n",
      "epoch: 118  batch: 86  loss: 0.07318472\n",
      "epoch: 118  batch: 87  loss: 0.07652352\n",
      "epoch: 119  batch: 1  loss: 0.09304836\n",
      "epoch: 119  batch: 2  loss: 0.12172811\n",
      "epoch: 119  batch: 3  loss: 0.05316377\n",
      "epoch: 119  batch: 4  loss: 0.10659600\n",
      "epoch: 119  batch: 5  loss: 0.06680287\n",
      "epoch: 119  batch: 6  loss: 0.06073719\n",
      "epoch: 119  batch: 7  loss: 0.07259724\n",
      "epoch: 119  batch: 8  loss: 0.07153101\n",
      "epoch: 119  batch: 9  loss: 0.13055792\n",
      "epoch: 119  batch: 10  loss: 0.06156345\n",
      "epoch: 119  batch: 11  loss: 0.08419567\n",
      "epoch: 119  batch: 12  loss: 0.07522825\n",
      "epoch: 119  batch: 13  loss: 0.08868814\n",
      "epoch: 119  batch: 14  loss: 0.07297499\n",
      "epoch: 119  batch: 15  loss: 0.08876397\n",
      "epoch: 119  batch: 16  loss: 0.12088154\n",
      "epoch: 119  batch: 17  loss: 0.07701530\n",
      "epoch: 119  batch: 18  loss: 0.07996710\n",
      "epoch: 119  batch: 19  loss: 0.09409536\n",
      "epoch: 119  batch: 20  loss: 0.06553786\n",
      "epoch: 119  batch: 21  loss: 0.11688178\n",
      "epoch: 119  batch: 22  loss: 0.07159499\n",
      "epoch: 119  batch: 23  loss: 0.04959621\n",
      "epoch: 119  batch: 24  loss: 0.08391488\n",
      "epoch: 119  batch: 25  loss: 0.08859197\n",
      "epoch: 119  batch: 26  loss: 0.06772255\n",
      "epoch: 119  batch: 27  loss: 0.07233541\n",
      "epoch: 119  batch: 28  loss: 0.09277257\n",
      "epoch: 119  batch: 29  loss: 0.07363953\n",
      "epoch: 119  batch: 30  loss: 0.08009177\n",
      "epoch: 119  batch: 31  loss: 0.09785181\n",
      "epoch: 119  batch: 32  loss: 0.06363528\n",
      "epoch: 119  batch: 33  loss: 0.08481811\n",
      "epoch: 119  batch: 34  loss: 0.07920033\n",
      "epoch: 119  batch: 35  loss: 0.06522717\n",
      "epoch: 119  batch: 36  loss: 0.09815843\n",
      "epoch: 119  batch: 37  loss: 0.07180664\n",
      "epoch: 119  batch: 38  loss: 0.12238262\n",
      "epoch: 119  batch: 39  loss: 0.08134648\n",
      "epoch: 119  batch: 40  loss: 0.07892736\n",
      "epoch: 119  batch: 41  loss: 0.09781169\n",
      "epoch: 119  batch: 42  loss: 0.07792450\n",
      "epoch: 119  batch: 43  loss: 0.07082669\n",
      "epoch: 119  batch: 44  loss: 0.05395222\n",
      "epoch: 119  batch: 45  loss: 0.06505669\n",
      "epoch: 119  batch: 46  loss: 0.08284130\n",
      "epoch: 119  batch: 47  loss: 0.06988815\n",
      "epoch: 119  batch: 48  loss: 0.07667881\n",
      "epoch: 119  batch: 49  loss: 0.10046761\n",
      "epoch: 119  batch: 50  loss: 0.09304990\n",
      "epoch: 119  batch: 51  loss: 0.07287481\n",
      "epoch: 119  batch: 52  loss: 0.08583523\n",
      "epoch: 119  batch: 53  loss: 0.05252061\n",
      "epoch: 119  batch: 54  loss: 0.08378504\n",
      "epoch: 119  batch: 55  loss: 0.05891984\n",
      "epoch: 119  batch: 56  loss: 0.10838564\n",
      "epoch: 119  batch: 57  loss: 0.06812574\n",
      "epoch: 119  batch: 58  loss: 0.07361637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 119  batch: 59  loss: 0.07665364\n",
      "epoch: 119  batch: 60  loss: 0.09027454\n",
      "epoch: 119  batch: 61  loss: 0.07968143\n",
      "epoch: 119  batch: 62  loss: 0.07744803\n",
      "epoch: 119  batch: 63  loss: 0.06933990\n",
      "epoch: 119  batch: 64  loss: 0.08973074\n",
      "epoch: 119  batch: 65  loss: 0.10611326\n",
      "epoch: 119  batch: 66  loss: 0.08863351\n",
      "epoch: 119  batch: 67  loss: 0.07398555\n",
      "epoch: 119  batch: 68  loss: 0.09357092\n",
      "epoch: 119  batch: 69  loss: 0.06612796\n",
      "epoch: 119  batch: 70  loss: 0.08797021\n",
      "epoch: 119  batch: 71  loss: 0.08094779\n",
      "epoch: 119  batch: 72  loss: 0.08490996\n",
      "epoch: 119  batch: 73  loss: 0.08282498\n",
      "epoch: 119  batch: 74  loss: 0.05835548\n",
      "epoch: 119  batch: 75  loss: 0.06936416\n",
      "epoch: 119  batch: 76  loss: 0.07164739\n",
      "epoch: 119  batch: 77  loss: 0.09144387\n",
      "epoch: 119  batch: 78  loss: 0.10776390\n",
      "epoch: 119  batch: 79  loss: 0.06261299\n",
      "epoch: 119  batch: 80  loss: 0.04526278\n",
      "epoch: 119  batch: 81  loss: 0.08795290\n",
      "epoch: 119  batch: 82  loss: 0.06055338\n",
      "epoch: 119  batch: 83  loss: 0.09296361\n",
      "epoch: 119  batch: 84  loss: 0.11081988\n",
      "epoch: 119  batch: 85  loss: 0.07200649\n",
      "epoch: 119  batch: 86  loss: 0.07909729\n",
      "epoch: 119  batch: 87  loss: 0.09499711\n",
      "epoch: 120  batch: 1  loss: 0.06022055\n",
      "epoch: 120  batch: 2  loss: 0.10339485\n",
      "epoch: 120  batch: 3  loss: 0.07588963\n",
      "epoch: 120  batch: 4  loss: 0.05956174\n",
      "epoch: 120  batch: 5  loss: 0.15009749\n",
      "epoch: 120  batch: 6  loss: 0.10008015\n",
      "epoch: 120  batch: 7  loss: 0.06706420\n",
      "epoch: 120  batch: 8  loss: 0.06906335\n",
      "epoch: 120  batch: 9  loss: 0.08031131\n",
      "epoch: 120  batch: 10  loss: 0.10506266\n",
      "epoch: 120  batch: 11  loss: 0.05681474\n",
      "epoch: 120  batch: 12  loss: 0.08402922\n",
      "epoch: 120  batch: 13  loss: 0.06468502\n",
      "epoch: 120  batch: 14  loss: 0.05609849\n",
      "epoch: 120  batch: 15  loss: 0.13871470\n",
      "epoch: 120  batch: 16  loss: 0.07013375\n",
      "epoch: 120  batch: 17  loss: 0.07313829\n",
      "epoch: 120  batch: 18  loss: 0.09476957\n",
      "epoch: 120  batch: 19  loss: 0.07005059\n",
      "epoch: 120  batch: 20  loss: 0.07797806\n",
      "epoch: 120  batch: 21  loss: 0.07518107\n",
      "epoch: 120  batch: 22  loss: 0.13181974\n",
      "epoch: 120  batch: 23  loss: 0.08493569\n",
      "epoch: 120  batch: 24  loss: 0.11774658\n",
      "epoch: 120  batch: 25  loss: 0.08089028\n",
      "epoch: 120  batch: 26  loss: 0.07795630\n",
      "epoch: 120  batch: 27  loss: 0.07851862\n",
      "epoch: 120  batch: 28  loss: 0.09064794\n",
      "epoch: 120  batch: 29  loss: 0.07115667\n",
      "epoch: 120  batch: 30  loss: 0.08332451\n",
      "epoch: 120  batch: 31  loss: 0.07912334\n",
      "epoch: 120  batch: 32  loss: 0.08044184\n",
      "epoch: 120  batch: 33  loss: 0.07924560\n",
      "epoch: 120  batch: 34  loss: 0.08697084\n",
      "epoch: 120  batch: 35  loss: 0.11508184\n",
      "epoch: 120  batch: 36  loss: 0.09688473\n",
      "epoch: 120  batch: 37  loss: 0.06955251\n",
      "epoch: 120  batch: 38  loss: 0.10914245\n",
      "epoch: 120  batch: 39  loss: 0.09266966\n",
      "epoch: 120  batch: 40  loss: 0.06216007\n",
      "epoch: 120  batch: 41  loss: 0.07227059\n",
      "epoch: 120  batch: 42  loss: 0.12267482\n",
      "epoch: 120  batch: 43  loss: 0.11687732\n",
      "epoch: 120  batch: 44  loss: 0.04635283\n",
      "epoch: 120  batch: 45  loss: 0.07057731\n",
      "epoch: 120  batch: 46  loss: 0.07087456\n",
      "epoch: 120  batch: 47  loss: 0.09328210\n",
      "epoch: 120  batch: 48  loss: 0.12792830\n",
      "epoch: 120  batch: 49  loss: 0.05393656\n",
      "epoch: 120  batch: 50  loss: 0.10332727\n",
      "epoch: 120  batch: 51  loss: 0.08279178\n",
      "epoch: 120  batch: 52  loss: 0.05813154\n",
      "epoch: 120  batch: 53  loss: 0.06665125\n",
      "epoch: 120  batch: 54  loss: 0.06805481\n",
      "epoch: 120  batch: 55  loss: 0.08059491\n",
      "epoch: 120  batch: 56  loss: 0.08139625\n",
      "epoch: 120  batch: 57  loss: 0.09662409\n",
      "epoch: 120  batch: 58  loss: 0.06790569\n",
      "epoch: 120  batch: 59  loss: 0.08670494\n",
      "epoch: 120  batch: 60  loss: 0.07327290\n",
      "epoch: 120  batch: 61  loss: 0.05675595\n",
      "epoch: 120  batch: 62  loss: 0.06219763\n",
      "epoch: 120  batch: 63  loss: 0.08074140\n",
      "epoch: 120  batch: 64  loss: 0.06709704\n",
      "epoch: 120  batch: 65  loss: 0.08699181\n",
      "epoch: 120  batch: 66  loss: 0.07743324\n",
      "epoch: 120  batch: 67  loss: 0.10734581\n",
      "epoch: 120  batch: 68  loss: 0.06308755\n",
      "epoch: 120  batch: 69  loss: 0.08237477\n",
      "epoch: 120  batch: 70  loss: 0.10877427\n",
      "epoch: 120  batch: 71  loss: 0.07046773\n",
      "epoch: 120  batch: 72  loss: 0.06919202\n",
      "epoch: 120  batch: 73  loss: 0.06306536\n",
      "epoch: 120  batch: 74  loss: 0.08412868\n",
      "epoch: 120  batch: 75  loss: 0.06926922\n",
      "epoch: 120  batch: 76  loss: 0.05394665\n",
      "epoch: 120  batch: 77  loss: 0.09647055\n",
      "epoch: 120  batch: 78  loss: 0.09628794\n",
      "epoch: 120  batch: 79  loss: 0.07574963\n",
      "epoch: 120  batch: 80  loss: 0.06144673\n",
      "epoch: 120  batch: 81  loss: 0.06110033\n",
      "epoch: 120  batch: 82  loss: 0.06105352\n",
      "epoch: 120  batch: 83  loss: 0.07651764\n",
      "epoch: 120  batch: 84  loss: 0.05920347\n",
      "epoch: 120  batch: 85  loss: 0.08619110\n",
      "epoch: 120  batch: 86  loss: 0.10619823\n",
      "epoch: 120  batch: 87  loss: 0.05311785\n",
      "epoch: 121  batch: 1  loss: 0.06065603\n",
      "epoch: 121  batch: 2  loss: 0.08010060\n",
      "epoch: 121  batch: 3  loss: 0.11454839\n",
      "epoch: 121  batch: 4  loss: 0.12873691\n",
      "epoch: 121  batch: 5  loss: 0.10851430\n",
      "epoch: 121  batch: 6  loss: 0.07670287\n",
      "epoch: 121  batch: 7  loss: 0.05727779\n",
      "epoch: 121  batch: 8  loss: 0.08966608\n",
      "epoch: 121  batch: 9  loss: 0.13846977\n",
      "epoch: 121  batch: 10  loss: 0.06716096\n",
      "epoch: 121  batch: 11  loss: 0.09985226\n",
      "epoch: 121  batch: 12  loss: 0.10347585\n",
      "epoch: 121  batch: 13  loss: 0.07776366\n",
      "epoch: 121  batch: 14  loss: 0.07642882\n",
      "epoch: 121  batch: 15  loss: 0.05955566\n",
      "epoch: 121  batch: 16  loss: 0.07353896\n",
      "epoch: 121  batch: 17  loss: 0.10317206\n",
      "epoch: 121  batch: 18  loss: 0.07280201\n",
      "epoch: 121  batch: 19  loss: 0.08618917\n",
      "epoch: 121  batch: 20  loss: 0.06112147\n",
      "epoch: 121  batch: 21  loss: 0.07882325\n",
      "epoch: 121  batch: 22  loss: 0.06985916\n",
      "epoch: 121  batch: 23  loss: 0.07109537\n",
      "epoch: 121  batch: 24  loss: 0.08494744\n",
      "epoch: 121  batch: 25  loss: 0.06049598\n",
      "epoch: 121  batch: 26  loss: 0.08683230\n",
      "epoch: 121  batch: 27  loss: 0.06800582\n",
      "epoch: 121  batch: 28  loss: 0.07065510\n",
      "epoch: 121  batch: 29  loss: 0.06813221\n",
      "epoch: 121  batch: 30  loss: 0.06631086\n",
      "epoch: 121  batch: 31  loss: 0.12698697\n",
      "epoch: 121  batch: 32  loss: 0.09708036\n",
      "epoch: 121  batch: 33  loss: 0.08189048\n",
      "epoch: 121  batch: 34  loss: 0.10413541\n",
      "epoch: 121  batch: 35  loss: 0.07710718\n",
      "epoch: 121  batch: 36  loss: 0.07829052\n",
      "epoch: 121  batch: 37  loss: 0.07174034\n",
      "epoch: 121  batch: 38  loss: 0.07069654\n",
      "epoch: 121  batch: 39  loss: 0.08436627\n",
      "epoch: 121  batch: 40  loss: 0.06609794\n",
      "epoch: 121  batch: 41  loss: 0.12712641\n",
      "epoch: 121  batch: 42  loss: 0.09301361\n",
      "epoch: 121  batch: 43  loss: 0.10906334\n",
      "epoch: 121  batch: 44  loss: 0.08114338\n",
      "epoch: 121  batch: 45  loss: 0.09575135\n",
      "epoch: 121  batch: 46  loss: 0.10716622\n",
      "epoch: 121  batch: 47  loss: 0.09397663\n",
      "epoch: 121  batch: 48  loss: 0.07193711\n",
      "epoch: 121  batch: 49  loss: 0.11730722\n",
      "epoch: 121  batch: 50  loss: 0.10652833\n",
      "epoch: 121  batch: 51  loss: 0.07128331\n",
      "epoch: 121  batch: 52  loss: 0.07110269\n",
      "epoch: 121  batch: 53  loss: 0.09174813\n",
      "epoch: 121  batch: 54  loss: 0.05798855\n",
      "epoch: 121  batch: 55  loss: 0.06562050\n",
      "epoch: 121  batch: 56  loss: 0.09135575\n",
      "epoch: 121  batch: 57  loss: 0.07584121\n",
      "epoch: 121  batch: 58  loss: 0.08829798\n",
      "epoch: 121  batch: 59  loss: 0.05558013\n",
      "epoch: 121  batch: 60  loss: 0.07722925\n",
      "epoch: 121  batch: 61  loss: 0.05264501\n",
      "epoch: 121  batch: 62  loss: 0.10948518\n",
      "epoch: 121  batch: 63  loss: 0.13786708\n",
      "epoch: 121  batch: 64  loss: 0.07568421\n",
      "epoch: 121  batch: 65  loss: 0.08055016\n",
      "epoch: 121  batch: 66  loss: 0.10616842\n",
      "epoch: 121  batch: 67  loss: 0.13861081\n",
      "epoch: 121  batch: 68  loss: 0.06492641\n",
      "epoch: 121  batch: 69  loss: 0.06795067\n",
      "epoch: 121  batch: 70  loss: 0.08567786\n",
      "epoch: 121  batch: 71  loss: 0.07871925\n",
      "epoch: 121  batch: 72  loss: 0.07030445\n",
      "epoch: 121  batch: 73  loss: 0.08118239\n",
      "epoch: 121  batch: 74  loss: 0.05658522\n",
      "epoch: 121  batch: 75  loss: 0.07107152\n",
      "epoch: 121  batch: 76  loss: 0.07683294\n",
      "epoch: 121  batch: 77  loss: 0.10028029\n",
      "epoch: 121  batch: 78  loss: 0.05949077\n",
      "epoch: 121  batch: 79  loss: 0.05543361\n",
      "epoch: 121  batch: 80  loss: 0.07649494\n",
      "epoch: 121  batch: 81  loss: 0.06920948\n",
      "epoch: 121  batch: 82  loss: 0.10705356\n",
      "epoch: 121  batch: 83  loss: 0.05838964\n",
      "epoch: 121  batch: 84  loss: 0.10405050\n",
      "epoch: 121  batch: 85  loss: 0.06110420\n",
      "epoch: 121  batch: 86  loss: 0.07168218\n",
      "epoch: 121  batch: 87  loss: 0.06215405\n",
      "epoch: 122  batch: 1  loss: 0.09524398\n",
      "epoch: 122  batch: 2  loss: 0.05125208\n",
      "epoch: 122  batch: 3  loss: 0.05051314\n",
      "epoch: 122  batch: 4  loss: 0.05973551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 122  batch: 5  loss: 0.11892293\n",
      "epoch: 122  batch: 6  loss: 0.07284976\n",
      "epoch: 122  batch: 7  loss: 0.08239125\n",
      "epoch: 122  batch: 8  loss: 0.06587406\n",
      "epoch: 122  batch: 9  loss: 0.07653882\n",
      "epoch: 122  batch: 10  loss: 0.08041796\n",
      "epoch: 122  batch: 11  loss: 0.07827583\n",
      "epoch: 122  batch: 12  loss: 0.08041300\n",
      "epoch: 122  batch: 13  loss: 0.06512569\n",
      "epoch: 122  batch: 14  loss: 0.10412404\n",
      "epoch: 122  batch: 15  loss: 0.08538679\n",
      "epoch: 122  batch: 16  loss: 0.09358739\n",
      "epoch: 122  batch: 17  loss: 0.08354262\n",
      "epoch: 122  batch: 18  loss: 0.07801670\n",
      "epoch: 122  batch: 19  loss: 0.10022189\n",
      "epoch: 122  batch: 20  loss: 0.06996261\n",
      "epoch: 122  batch: 21  loss: 0.06822660\n",
      "epoch: 122  batch: 22  loss: 0.08241403\n",
      "epoch: 122  batch: 23  loss: 0.08767402\n",
      "epoch: 122  batch: 24  loss: 0.06716102\n",
      "epoch: 122  batch: 25  loss: 0.07196517\n",
      "epoch: 122  batch: 26  loss: 0.06675095\n",
      "epoch: 122  batch: 27  loss: 0.08252730\n",
      "epoch: 122  batch: 28  loss: 0.09293355\n",
      "epoch: 122  batch: 29  loss: 0.12987442\n",
      "epoch: 122  batch: 30  loss: 0.11954940\n",
      "epoch: 122  batch: 31  loss: 0.07822457\n",
      "epoch: 122  batch: 32  loss: 0.14716920\n",
      "epoch: 122  batch: 33  loss: 0.13686390\n",
      "epoch: 122  batch: 34  loss: 0.10593663\n",
      "epoch: 122  batch: 35  loss: 0.08659811\n",
      "epoch: 122  batch: 36  loss: 0.06192509\n",
      "epoch: 122  batch: 37  loss: 0.09576675\n",
      "epoch: 122  batch: 38  loss: 0.07413278\n",
      "epoch: 122  batch: 39  loss: 0.07843588\n",
      "epoch: 122  batch: 40  loss: 0.07579987\n",
      "epoch: 122  batch: 41  loss: 0.08061340\n",
      "epoch: 122  batch: 42  loss: 0.07769842\n",
      "epoch: 122  batch: 43  loss: 0.08802082\n",
      "epoch: 122  batch: 44  loss: 0.10474404\n",
      "epoch: 122  batch: 45  loss: 0.07720654\n",
      "epoch: 122  batch: 46  loss: 0.07386540\n",
      "epoch: 122  batch: 47  loss: 0.07278185\n",
      "epoch: 122  batch: 48  loss: 0.09009121\n",
      "epoch: 122  batch: 49  loss: 0.05642104\n",
      "epoch: 122  batch: 50  loss: 0.08774500\n",
      "epoch: 122  batch: 51  loss: 0.07292695\n",
      "epoch: 122  batch: 52  loss: 0.08010764\n",
      "epoch: 122  batch: 53  loss: 0.05623994\n",
      "epoch: 122  batch: 54  loss: 0.05732857\n",
      "epoch: 122  batch: 55  loss: 0.06539824\n",
      "epoch: 122  batch: 56  loss: 0.06718285\n",
      "epoch: 122  batch: 57  loss: 0.07594272\n",
      "epoch: 122  batch: 58  loss: 0.07345632\n",
      "epoch: 122  batch: 59  loss: 0.07771720\n",
      "epoch: 122  batch: 60  loss: 0.07976311\n",
      "epoch: 122  batch: 61  loss: 0.05844178\n",
      "epoch: 122  batch: 62  loss: 0.07924253\n",
      "epoch: 122  batch: 63  loss: 0.10692373\n",
      "epoch: 122  batch: 64  loss: 0.07162219\n",
      "epoch: 122  batch: 65  loss: 0.05952997\n",
      "epoch: 122  batch: 66  loss: 0.10335805\n",
      "epoch: 122  batch: 67  loss: 0.11728995\n",
      "epoch: 122  batch: 68  loss: 0.05796485\n",
      "epoch: 122  batch: 69  loss: 0.07844238\n",
      "epoch: 122  batch: 70  loss: 0.05631467\n",
      "epoch: 122  batch: 71  loss: 0.07192024\n",
      "epoch: 122  batch: 72  loss: 0.10082176\n",
      "epoch: 122  batch: 73  loss: 0.07075624\n",
      "epoch: 122  batch: 74  loss: 0.08259022\n",
      "epoch: 122  batch: 75  loss: 0.07804468\n",
      "epoch: 122  batch: 76  loss: 0.07133365\n",
      "epoch: 122  batch: 77  loss: 0.07463144\n",
      "epoch: 122  batch: 78  loss: 0.07929762\n",
      "epoch: 122  batch: 79  loss: 0.06945395\n",
      "epoch: 122  batch: 80  loss: 0.09021213\n",
      "epoch: 122  batch: 81  loss: 0.10177494\n",
      "epoch: 122  batch: 82  loss: 0.06795361\n",
      "epoch: 122  batch: 83  loss: 0.10165047\n",
      "epoch: 122  batch: 84  loss: 0.06371348\n",
      "epoch: 122  batch: 85  loss: 0.08877768\n",
      "epoch: 122  batch: 86  loss: 0.07022522\n",
      "epoch: 122  batch: 87  loss: 0.11339849\n",
      "epoch: 123  batch: 1  loss: 0.09691080\n",
      "epoch: 123  batch: 2  loss: 0.05751851\n",
      "epoch: 123  batch: 3  loss: 0.10361101\n",
      "epoch: 123  batch: 4  loss: 0.09515426\n",
      "epoch: 123  batch: 5  loss: 0.09027970\n",
      "epoch: 123  batch: 6  loss: 0.05270679\n",
      "epoch: 123  batch: 7  loss: 0.07483388\n",
      "epoch: 123  batch: 8  loss: 0.07125800\n",
      "epoch: 123  batch: 9  loss: 0.07067380\n",
      "epoch: 123  batch: 10  loss: 0.09484549\n",
      "epoch: 123  batch: 11  loss: 0.06460533\n",
      "epoch: 123  batch: 12  loss: 0.06154147\n",
      "epoch: 123  batch: 13  loss: 0.08112887\n",
      "epoch: 123  batch: 14  loss: 0.07378631\n",
      "epoch: 123  batch: 15  loss: 0.06764157\n",
      "epoch: 123  batch: 16  loss: 0.13026381\n",
      "epoch: 123  batch: 17  loss: 0.07939749\n",
      "epoch: 123  batch: 18  loss: 0.11320429\n",
      "epoch: 123  batch: 19  loss: 0.11341919\n",
      "epoch: 123  batch: 20  loss: 0.06520429\n",
      "epoch: 123  batch: 21  loss: 0.07515078\n",
      "epoch: 123  batch: 22  loss: 0.10951294\n",
      "epoch: 123  batch: 23  loss: 0.07129226\n",
      "epoch: 123  batch: 24  loss: 0.09168649\n",
      "epoch: 123  batch: 25  loss: 0.06388390\n",
      "epoch: 123  batch: 26  loss: 0.09540244\n",
      "epoch: 123  batch: 27  loss: 0.07721422\n",
      "epoch: 123  batch: 28  loss: 0.08620746\n",
      "epoch: 123  batch: 29  loss: 0.08602238\n",
      "epoch: 123  batch: 30  loss: 0.10301758\n",
      "epoch: 123  batch: 31  loss: 0.06610100\n",
      "epoch: 123  batch: 32  loss: 0.09845655\n",
      "epoch: 123  batch: 33  loss: 0.09390862\n",
      "epoch: 123  batch: 34  loss: 0.05563119\n",
      "epoch: 123  batch: 35  loss: 0.05389895\n",
      "epoch: 123  batch: 36  loss: 0.08200736\n",
      "epoch: 123  batch: 37  loss: 0.08528987\n",
      "epoch: 123  batch: 38  loss: 0.10892352\n",
      "epoch: 123  batch: 39  loss: 0.10077259\n",
      "epoch: 123  batch: 40  loss: 0.06636718\n",
      "epoch: 123  batch: 41  loss: 0.07437500\n",
      "epoch: 123  batch: 42  loss: 0.08615647\n",
      "epoch: 123  batch: 43  loss: 0.09427863\n",
      "epoch: 123  batch: 44  loss: 0.10468530\n",
      "epoch: 123  batch: 45  loss: 0.09099618\n",
      "epoch: 123  batch: 46  loss: 0.07016499\n",
      "epoch: 123  batch: 47  loss: 0.09408932\n",
      "epoch: 123  batch: 48  loss: 0.08145313\n",
      "epoch: 123  batch: 49  loss: 0.08224543\n",
      "epoch: 123  batch: 50  loss: 0.07302976\n",
      "epoch: 123  batch: 51  loss: 0.05444359\n",
      "epoch: 123  batch: 52  loss: 0.05504877\n",
      "epoch: 123  batch: 53  loss: 0.11930503\n",
      "epoch: 123  batch: 54  loss: 0.05647852\n",
      "epoch: 123  batch: 55  loss: 0.05333414\n",
      "epoch: 123  batch: 56  loss: 0.07761981\n",
      "epoch: 123  batch: 57  loss: 0.09177255\n",
      "epoch: 123  batch: 58  loss: 0.06425311\n",
      "epoch: 123  batch: 59  loss: 0.14651532\n",
      "epoch: 123  batch: 60  loss: 0.09218967\n",
      "epoch: 123  batch: 61  loss: 0.09492385\n",
      "epoch: 123  batch: 62  loss: 0.09562758\n",
      "epoch: 123  batch: 63  loss: 0.06714649\n",
      "epoch: 123  batch: 64  loss: 0.12028509\n",
      "epoch: 123  batch: 65  loss: 0.07380980\n",
      "epoch: 123  batch: 66  loss: 0.06213148\n",
      "epoch: 123  batch: 67  loss: 0.07925813\n",
      "epoch: 123  batch: 68  loss: 0.06784562\n",
      "epoch: 123  batch: 69  loss: 0.05991384\n",
      "epoch: 123  batch: 70  loss: 0.05976462\n",
      "epoch: 123  batch: 71  loss: 0.08820965\n",
      "epoch: 123  batch: 72  loss: 0.06071914\n",
      "epoch: 123  batch: 73  loss: 0.09209505\n",
      "epoch: 123  batch: 74  loss: 0.05800283\n",
      "epoch: 123  batch: 75  loss: 0.08545829\n",
      "epoch: 123  batch: 76  loss: 0.05973092\n",
      "epoch: 123  batch: 77  loss: 0.07503695\n",
      "epoch: 123  batch: 78  loss: 0.04589590\n",
      "epoch: 123  batch: 79  loss: 0.07122336\n",
      "epoch: 123  batch: 80  loss: 0.08894485\n",
      "epoch: 123  batch: 81  loss: 0.08035756\n",
      "epoch: 123  batch: 82  loss: 0.08073132\n",
      "epoch: 123  batch: 83  loss: 0.08747656\n",
      "epoch: 123  batch: 84  loss: 0.10339264\n",
      "epoch: 123  batch: 85  loss: 0.14670591\n",
      "epoch: 123  batch: 86  loss: 0.05538876\n",
      "epoch: 123  batch: 87  loss: 0.10628903\n",
      "epoch: 124  batch: 1  loss: 0.09743513\n",
      "epoch: 124  batch: 2  loss: 0.07687696\n",
      "epoch: 124  batch: 3  loss: 0.08457286\n",
      "epoch: 124  batch: 4  loss: 0.08436538\n",
      "epoch: 124  batch: 5  loss: 0.08781476\n",
      "epoch: 124  batch: 6  loss: 0.06114633\n",
      "epoch: 124  batch: 7  loss: 0.06540140\n",
      "epoch: 124  batch: 8  loss: 0.07352639\n",
      "epoch: 124  batch: 9  loss: 0.08304145\n",
      "epoch: 124  batch: 10  loss: 0.06436715\n",
      "epoch: 124  batch: 11  loss: 0.05617160\n",
      "epoch: 124  batch: 12  loss: 0.08288147\n",
      "epoch: 124  batch: 13  loss: 0.07780080\n",
      "epoch: 124  batch: 14  loss: 0.11823634\n",
      "epoch: 124  batch: 15  loss: 0.05276753\n",
      "epoch: 124  batch: 16  loss: 0.06280428\n",
      "epoch: 124  batch: 17  loss: 0.08695776\n",
      "epoch: 124  batch: 18  loss: 0.07629859\n",
      "epoch: 124  batch: 19  loss: 0.07798912\n",
      "epoch: 124  batch: 20  loss: 0.12702590\n",
      "epoch: 124  batch: 21  loss: 0.06857569\n",
      "epoch: 124  batch: 22  loss: 0.10568421\n",
      "epoch: 124  batch: 23  loss: 0.06190284\n",
      "epoch: 124  batch: 24  loss: 0.05969285\n",
      "epoch: 124  batch: 25  loss: 0.07861695\n",
      "epoch: 124  batch: 26  loss: 0.08249549\n",
      "epoch: 124  batch: 27  loss: 0.07094676\n",
      "epoch: 124  batch: 28  loss: 0.10828846\n",
      "epoch: 124  batch: 29  loss: 0.06082207\n",
      "epoch: 124  batch: 30  loss: 0.07759352\n",
      "epoch: 124  batch: 31  loss: 0.06824991\n",
      "epoch: 124  batch: 32  loss: 0.05180610\n",
      "epoch: 124  batch: 33  loss: 0.06450563\n",
      "epoch: 124  batch: 34  loss: 0.15201305\n",
      "epoch: 124  batch: 35  loss: 0.07685616\n",
      "epoch: 124  batch: 36  loss: 0.06018331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124  batch: 37  loss: 0.08863356\n",
      "epoch: 124  batch: 38  loss: 0.06188405\n",
      "epoch: 124  batch: 39  loss: 0.16682956\n",
      "epoch: 124  batch: 40  loss: 0.10557597\n",
      "epoch: 124  batch: 41  loss: 0.07477073\n",
      "epoch: 124  batch: 42  loss: 0.07290839\n",
      "epoch: 124  batch: 43  loss: 0.09557307\n",
      "epoch: 124  batch: 44  loss: 0.06768116\n",
      "epoch: 124  batch: 45  loss: 0.05634689\n",
      "epoch: 124  batch: 46  loss: 0.08515865\n",
      "epoch: 124  batch: 47  loss: 0.11475585\n",
      "epoch: 124  batch: 48  loss: 0.10269076\n",
      "epoch: 124  batch: 49  loss: 0.07216949\n",
      "epoch: 124  batch: 50  loss: 0.08355714\n",
      "epoch: 124  batch: 51  loss: 0.08041944\n",
      "epoch: 124  batch: 52  loss: 0.11616693\n",
      "epoch: 124  batch: 53  loss: 0.12429904\n",
      "epoch: 124  batch: 54  loss: 0.10271780\n",
      "epoch: 124  batch: 55  loss: 0.08025990\n",
      "epoch: 124  batch: 56  loss: 0.13314681\n",
      "epoch: 124  batch: 57  loss: 0.05911646\n",
      "epoch: 124  batch: 58  loss: 0.06642477\n",
      "epoch: 124  batch: 59  loss: 0.06617824\n",
      "epoch: 124  batch: 60  loss: 0.07463720\n",
      "epoch: 124  batch: 61  loss: 0.07277054\n",
      "epoch: 124  batch: 62  loss: 0.08607256\n",
      "epoch: 124  batch: 63  loss: 0.09567708\n",
      "epoch: 124  batch: 64  loss: 0.04950712\n",
      "epoch: 124  batch: 65  loss: 0.08111224\n",
      "epoch: 124  batch: 66  loss: 0.08536845\n",
      "epoch: 124  batch: 67  loss: 0.07964637\n",
      "epoch: 124  batch: 68  loss: 0.09091500\n",
      "epoch: 124  batch: 69  loss: 0.08346602\n",
      "epoch: 124  batch: 70  loss: 0.11023058\n",
      "epoch: 124  batch: 71  loss: 0.07027774\n",
      "epoch: 124  batch: 72  loss: 0.07787107\n",
      "epoch: 124  batch: 73  loss: 0.07202476\n",
      "epoch: 124  batch: 74  loss: 0.08582132\n",
      "epoch: 124  batch: 75  loss: 0.07316335\n",
      "epoch: 124  batch: 76  loss: 0.09904844\n",
      "epoch: 124  batch: 77  loss: 0.08752236\n",
      "epoch: 124  batch: 78  loss: 0.06705303\n",
      "epoch: 124  batch: 79  loss: 0.08923492\n",
      "epoch: 124  batch: 80  loss: 0.10115143\n",
      "epoch: 124  batch: 81  loss: 0.06258292\n",
      "epoch: 124  batch: 82  loss: 0.08321636\n",
      "epoch: 124  batch: 83  loss: 0.09382942\n",
      "epoch: 124  batch: 84  loss: 0.06154935\n",
      "epoch: 124  batch: 85  loss: 0.05611386\n",
      "epoch: 124  batch: 86  loss: 0.06242878\n",
      "epoch: 124  batch: 87  loss: 0.04106620\n",
      "epoch: 125  batch: 1  loss: 0.06309444\n",
      "epoch: 125  batch: 2  loss: 0.07650458\n",
      "epoch: 125  batch: 3  loss: 0.11619376\n",
      "epoch: 125  batch: 4  loss: 0.10542229\n",
      "epoch: 125  batch: 5  loss: 0.07809795\n",
      "epoch: 125  batch: 6  loss: 0.07763129\n",
      "epoch: 125  batch: 7  loss: 0.07471331\n",
      "epoch: 125  batch: 8  loss: 0.07555737\n",
      "epoch: 125  batch: 9  loss: 0.09928133\n",
      "epoch: 125  batch: 10  loss: 0.05609502\n",
      "epoch: 125  batch: 11  loss: 0.15851265\n",
      "epoch: 125  batch: 12  loss: 0.11287599\n",
      "epoch: 125  batch: 13  loss: 0.09839221\n",
      "epoch: 125  batch: 14  loss: 0.07213776\n",
      "epoch: 125  batch: 15  loss: 0.07201058\n",
      "epoch: 125  batch: 16  loss: 0.08159766\n",
      "epoch: 125  batch: 17  loss: 0.07097527\n",
      "epoch: 125  batch: 18  loss: 0.05413616\n",
      "epoch: 125  batch: 19  loss: 0.07296681\n",
      "epoch: 125  batch: 20  loss: 0.09026109\n",
      "epoch: 125  batch: 21  loss: 0.07743067\n",
      "epoch: 125  batch: 22  loss: 0.08903514\n",
      "epoch: 125  batch: 23  loss: 0.08216275\n",
      "epoch: 125  batch: 24  loss: 0.09229654\n",
      "epoch: 125  batch: 25  loss: 0.07088908\n",
      "epoch: 125  batch: 26  loss: 0.05826331\n",
      "epoch: 125  batch: 27  loss: 0.09782498\n",
      "epoch: 125  batch: 28  loss: 0.04304263\n",
      "epoch: 125  batch: 29  loss: 0.08086485\n",
      "epoch: 125  batch: 30  loss: 0.09536200\n",
      "epoch: 125  batch: 31  loss: 0.06671093\n",
      "epoch: 125  batch: 32  loss: 0.07638806\n",
      "epoch: 125  batch: 33  loss: 0.05704159\n",
      "epoch: 125  batch: 34  loss: 0.09695926\n",
      "epoch: 125  batch: 35  loss: 0.08753729\n",
      "epoch: 125  batch: 36  loss: 0.08136714\n",
      "epoch: 125  batch: 37  loss: 0.06805163\n",
      "epoch: 125  batch: 38  loss: 0.08135377\n",
      "epoch: 125  batch: 39  loss: 0.07390740\n",
      "epoch: 125  batch: 40  loss: 0.14297394\n",
      "epoch: 125  batch: 41  loss: 0.07381028\n",
      "epoch: 125  batch: 42  loss: 0.13990286\n",
      "epoch: 125  batch: 43  loss: 0.08670206\n",
      "epoch: 125  batch: 44  loss: 0.08499873\n",
      "epoch: 125  batch: 45  loss: 0.12582004\n",
      "epoch: 125  batch: 46  loss: 0.08462582\n",
      "epoch: 125  batch: 47  loss: 0.08197661\n",
      "epoch: 125  batch: 48  loss: 0.07633324\n",
      "epoch: 125  batch: 49  loss: 0.08097050\n",
      "epoch: 125  batch: 50  loss: 0.06379644\n",
      "epoch: 125  batch: 51  loss: 0.07251906\n",
      "epoch: 125  batch: 52  loss: 0.07077274\n",
      "epoch: 125  batch: 53  loss: 0.09302353\n",
      "epoch: 125  batch: 54  loss: 0.07352977\n",
      "epoch: 125  batch: 55  loss: 0.08782222\n",
      "epoch: 125  batch: 56  loss: 0.16763714\n",
      "epoch: 125  batch: 57  loss: 0.06984106\n",
      "epoch: 125  batch: 58  loss: 0.06500427\n",
      "epoch: 125  batch: 59  loss: 0.07770718\n",
      "epoch: 125  batch: 60  loss: 0.10455643\n",
      "epoch: 125  batch: 61  loss: 0.09244237\n",
      "epoch: 125  batch: 62  loss: 0.08049952\n",
      "epoch: 125  batch: 63  loss: 0.09588906\n",
      "epoch: 125  batch: 64  loss: 0.11533449\n",
      "epoch: 125  batch: 65  loss: 0.07934851\n",
      "epoch: 125  batch: 66  loss: 0.07956392\n",
      "epoch: 125  batch: 67  loss: 0.08805419\n",
      "epoch: 125  batch: 68  loss: 0.08609810\n",
      "epoch: 125  batch: 69  loss: 0.08422340\n",
      "epoch: 125  batch: 70  loss: 0.07036384\n",
      "epoch: 125  batch: 71  loss: 0.06290145\n",
      "epoch: 125  batch: 72  loss: 0.07553298\n",
      "epoch: 125  batch: 73  loss: 0.09179518\n",
      "epoch: 125  batch: 74  loss: 0.06370808\n",
      "epoch: 125  batch: 75  loss: 0.06746189\n",
      "epoch: 125  batch: 76  loss: 0.08551056\n",
      "epoch: 125  batch: 77  loss: 0.08398359\n",
      "epoch: 125  batch: 78  loss: 0.10930897\n",
      "epoch: 125  batch: 79  loss: 0.07601426\n",
      "epoch: 125  batch: 80  loss: 0.05019370\n",
      "epoch: 125  batch: 81  loss: 0.11766609\n",
      "epoch: 125  batch: 82  loss: 0.08786389\n",
      "epoch: 125  batch: 83  loss: 0.10307764\n",
      "epoch: 125  batch: 84  loss: 0.07481901\n",
      "epoch: 125  batch: 85  loss: 0.10258262\n",
      "epoch: 125  batch: 86  loss: 0.12236819\n",
      "epoch: 125  batch: 87  loss: 0.08970296\n",
      "epoch: 126  batch: 1  loss: 0.10108581\n",
      "epoch: 126  batch: 2  loss: 0.07985219\n",
      "epoch: 126  batch: 3  loss: 0.07571041\n",
      "epoch: 126  batch: 4  loss: 0.07164557\n",
      "epoch: 126  batch: 5  loss: 0.11841700\n",
      "epoch: 126  batch: 6  loss: 0.08182684\n",
      "epoch: 126  batch: 7  loss: 0.10546981\n",
      "epoch: 126  batch: 8  loss: 0.14854202\n",
      "epoch: 126  batch: 9  loss: 0.14116338\n",
      "epoch: 126  batch: 10  loss: 0.05469361\n",
      "epoch: 126  batch: 11  loss: 0.04777449\n",
      "epoch: 126  batch: 12  loss: 0.08159490\n",
      "epoch: 126  batch: 13  loss: 0.09106121\n",
      "epoch: 126  batch: 14  loss: 0.10960775\n",
      "epoch: 126  batch: 15  loss: 0.08606280\n",
      "epoch: 126  batch: 16  loss: 0.09825591\n",
      "epoch: 126  batch: 17  loss: 0.07270183\n",
      "epoch: 126  batch: 18  loss: 0.10058348\n",
      "epoch: 126  batch: 19  loss: 0.09139559\n",
      "epoch: 126  batch: 20  loss: 0.07831625\n",
      "epoch: 126  batch: 21  loss: 0.09341761\n",
      "epoch: 126  batch: 22  loss: 0.08852312\n",
      "epoch: 126  batch: 23  loss: 0.07402898\n",
      "epoch: 126  batch: 24  loss: 0.05468938\n",
      "epoch: 126  batch: 25  loss: 0.08814546\n",
      "epoch: 126  batch: 26  loss: 0.07845739\n",
      "epoch: 126  batch: 27  loss: 0.06073488\n",
      "epoch: 126  batch: 28  loss: 0.07649598\n",
      "epoch: 126  batch: 29  loss: 0.08444422\n",
      "epoch: 126  batch: 30  loss: 0.08516122\n",
      "epoch: 126  batch: 31  loss: 0.09096855\n",
      "epoch: 126  batch: 32  loss: 0.12075817\n",
      "epoch: 126  batch: 33  loss: 0.04818009\n",
      "epoch: 126  batch: 34  loss: 0.09325182\n",
      "epoch: 126  batch: 35  loss: 0.08986485\n",
      "epoch: 126  batch: 36  loss: 0.10299855\n",
      "epoch: 126  batch: 37  loss: 0.06632556\n",
      "epoch: 126  batch: 38  loss: 0.08549158\n",
      "epoch: 126  batch: 39  loss: 0.06395390\n",
      "epoch: 126  batch: 40  loss: 0.06548631\n",
      "epoch: 126  batch: 41  loss: 0.08436642\n",
      "epoch: 126  batch: 42  loss: 0.10843708\n",
      "epoch: 126  batch: 43  loss: 0.06774070\n",
      "epoch: 126  batch: 44  loss: 0.10537431\n",
      "epoch: 126  batch: 45  loss: 0.07070615\n",
      "epoch: 126  batch: 46  loss: 0.06485449\n",
      "epoch: 126  batch: 47  loss: 0.09355942\n",
      "epoch: 126  batch: 48  loss: 0.12574588\n",
      "epoch: 126  batch: 49  loss: 0.16424024\n",
      "epoch: 126  batch: 50  loss: 0.06522770\n",
      "epoch: 126  batch: 51  loss: 0.05932367\n",
      "epoch: 126  batch: 52  loss: 0.06745539\n",
      "epoch: 126  batch: 53  loss: 0.06719756\n",
      "epoch: 126  batch: 54  loss: 0.09452738\n",
      "epoch: 126  batch: 55  loss: 0.06882307\n",
      "epoch: 126  batch: 56  loss: 0.09946485\n",
      "epoch: 126  batch: 57  loss: 0.07520922\n",
      "epoch: 126  batch: 58  loss: 0.07792943\n",
      "epoch: 126  batch: 59  loss: 0.06257341\n",
      "epoch: 126  batch: 60  loss: 0.07638784\n",
      "epoch: 126  batch: 61  loss: 0.09789138\n",
      "epoch: 126  batch: 62  loss: 0.08179295\n",
      "epoch: 126  batch: 63  loss: 0.10020587\n",
      "epoch: 126  batch: 64  loss: 0.04936053\n",
      "epoch: 126  batch: 65  loss: 0.06366464\n",
      "epoch: 126  batch: 66  loss: 0.10151574\n",
      "epoch: 126  batch: 67  loss: 0.07393802\n",
      "epoch: 126  batch: 68  loss: 0.06201251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 126  batch: 69  loss: 0.07243105\n",
      "epoch: 126  batch: 70  loss: 0.07818829\n",
      "epoch: 126  batch: 71  loss: 0.05720397\n",
      "epoch: 126  batch: 72  loss: 0.07647393\n",
      "epoch: 126  batch: 73  loss: 0.09578414\n",
      "epoch: 126  batch: 74  loss: 0.05444153\n",
      "epoch: 126  batch: 75  loss: 0.06879126\n",
      "epoch: 126  batch: 76  loss: 0.06462561\n",
      "epoch: 126  batch: 77  loss: 0.07312710\n",
      "epoch: 126  batch: 78  loss: 0.09672455\n",
      "epoch: 126  batch: 79  loss: 0.06916215\n",
      "epoch: 126  batch: 80  loss: 0.10160437\n",
      "epoch: 126  batch: 81  loss: 0.07749718\n",
      "epoch: 126  batch: 82  loss: 0.07918605\n",
      "epoch: 126  batch: 83  loss: 0.05452640\n",
      "epoch: 126  batch: 84  loss: 0.06363252\n",
      "epoch: 126  batch: 85  loss: 0.07307252\n",
      "epoch: 126  batch: 86  loss: 0.06195432\n",
      "epoch: 126  batch: 87  loss: 0.11210462\n",
      "epoch: 127  batch: 1  loss: 0.07419401\n",
      "epoch: 127  batch: 2  loss: 0.08706149\n",
      "epoch: 127  batch: 3  loss: 0.09766363\n",
      "epoch: 127  batch: 4  loss: 0.06689334\n",
      "epoch: 127  batch: 5  loss: 0.08437137\n",
      "epoch: 127  batch: 6  loss: 0.05349433\n",
      "epoch: 127  batch: 7  loss: 0.08071794\n",
      "epoch: 127  batch: 8  loss: 0.09408563\n",
      "epoch: 127  batch: 9  loss: 0.07113868\n",
      "epoch: 127  batch: 10  loss: 0.06827906\n",
      "epoch: 127  batch: 11  loss: 0.05782708\n",
      "epoch: 127  batch: 12  loss: 0.11884478\n",
      "epoch: 127  batch: 13  loss: 0.07772993\n",
      "epoch: 127  batch: 14  loss: 0.09061474\n",
      "epoch: 127  batch: 15  loss: 0.09635994\n",
      "epoch: 127  batch: 16  loss: 0.07291331\n",
      "epoch: 127  batch: 17  loss: 0.09131916\n",
      "epoch: 127  batch: 18  loss: 0.09838596\n",
      "epoch: 127  batch: 19  loss: 0.05778632\n",
      "epoch: 127  batch: 20  loss: 0.06818663\n",
      "epoch: 127  batch: 21  loss: 0.09064295\n",
      "epoch: 127  batch: 22  loss: 0.10038262\n",
      "epoch: 127  batch: 23  loss: 0.05590110\n",
      "epoch: 127  batch: 24  loss: 0.18119387\n",
      "epoch: 127  batch: 25  loss: 0.07590847\n",
      "epoch: 127  batch: 26  loss: 0.05087433\n",
      "epoch: 127  batch: 27  loss: 0.14325772\n",
      "epoch: 127  batch: 28  loss: 0.08103368\n",
      "epoch: 127  batch: 29  loss: 0.07204131\n",
      "epoch: 127  batch: 30  loss: 0.11240923\n",
      "epoch: 127  batch: 31  loss: 0.07913881\n",
      "epoch: 127  batch: 32  loss: 0.08280200\n",
      "epoch: 127  batch: 33  loss: 0.07819441\n",
      "epoch: 127  batch: 34  loss: 0.06243032\n",
      "epoch: 127  batch: 35  loss: 0.04871304\n",
      "epoch: 127  batch: 36  loss: 0.07739253\n",
      "epoch: 127  batch: 37  loss: 0.04867372\n",
      "epoch: 127  batch: 38  loss: 0.08729051\n",
      "epoch: 127  batch: 39  loss: 0.07437701\n",
      "epoch: 127  batch: 40  loss: 0.07741848\n",
      "epoch: 127  batch: 41  loss: 0.04989867\n",
      "epoch: 127  batch: 42  loss: 0.06507474\n",
      "epoch: 127  batch: 43  loss: 0.06108057\n",
      "epoch: 127  batch: 44  loss: 0.05286782\n",
      "epoch: 127  batch: 45  loss: 0.07007071\n",
      "epoch: 127  batch: 46  loss: 0.09368014\n",
      "epoch: 127  batch: 47  loss: 0.09302142\n",
      "epoch: 127  batch: 48  loss: 0.07334097\n",
      "epoch: 127  batch: 49  loss: 0.05868186\n",
      "epoch: 127  batch: 50  loss: 0.07527895\n",
      "epoch: 127  batch: 51  loss: 0.09799177\n",
      "epoch: 127  batch: 52  loss: 0.13784614\n",
      "epoch: 127  batch: 53  loss: 0.07739023\n",
      "epoch: 127  batch: 54  loss: 0.06087242\n",
      "epoch: 127  batch: 55  loss: 0.09430095\n",
      "epoch: 127  batch: 56  loss: 0.07981022\n",
      "epoch: 127  batch: 57  loss: 0.11611763\n",
      "epoch: 127  batch: 58  loss: 0.08681153\n",
      "epoch: 127  batch: 59  loss: 0.11852519\n",
      "epoch: 127  batch: 60  loss: 0.07645311\n",
      "epoch: 127  batch: 61  loss: 0.06495117\n",
      "epoch: 127  batch: 62  loss: 0.08228908\n",
      "epoch: 127  batch: 63  loss: 0.07967939\n",
      "epoch: 127  batch: 64  loss: 0.06874978\n",
      "epoch: 127  batch: 65  loss: 0.10798256\n",
      "epoch: 127  batch: 66  loss: 0.12245204\n",
      "epoch: 127  batch: 67  loss: 0.06872324\n",
      "epoch: 127  batch: 68  loss: 0.06001050\n",
      "epoch: 127  batch: 69  loss: 0.05452692\n",
      "epoch: 127  batch: 70  loss: 0.08815902\n",
      "epoch: 127  batch: 71  loss: 0.05598035\n",
      "epoch: 127  batch: 72  loss: 0.07283952\n",
      "epoch: 127  batch: 73  loss: 0.10997418\n",
      "epoch: 127  batch: 74  loss: 0.10392568\n",
      "epoch: 127  batch: 75  loss: 0.07211568\n",
      "epoch: 127  batch: 76  loss: 0.10027827\n",
      "epoch: 127  batch: 77  loss: 0.06399731\n",
      "epoch: 127  batch: 78  loss: 0.05999213\n",
      "epoch: 127  batch: 79  loss: 0.14523770\n",
      "epoch: 127  batch: 80  loss: 0.07904585\n",
      "epoch: 127  batch: 81  loss: 0.06085490\n",
      "epoch: 127  batch: 82  loss: 0.08216943\n",
      "epoch: 127  batch: 83  loss: 0.07424003\n",
      "epoch: 127  batch: 84  loss: 0.10208701\n",
      "epoch: 127  batch: 85  loss: 0.09323636\n",
      "epoch: 127  batch: 86  loss: 0.07877954\n",
      "epoch: 127  batch: 87  loss: 0.06692868\n",
      "epoch: 128  batch: 1  loss: 0.07228576\n",
      "epoch: 128  batch: 2  loss: 0.09715255\n",
      "epoch: 128  batch: 3  loss: 0.06588336\n",
      "epoch: 128  batch: 4  loss: 0.05492273\n",
      "epoch: 128  batch: 5  loss: 0.07490966\n",
      "epoch: 128  batch: 6  loss: 0.07054114\n",
      "epoch: 128  batch: 7  loss: 0.09033079\n",
      "epoch: 128  batch: 8  loss: 0.06968403\n",
      "epoch: 128  batch: 9  loss: 0.05937326\n",
      "epoch: 128  batch: 10  loss: 0.06528804\n",
      "epoch: 128  batch: 11  loss: 0.05661605\n",
      "epoch: 128  batch: 12  loss: 0.13741472\n",
      "epoch: 128  batch: 13  loss: 0.12103600\n",
      "epoch: 128  batch: 14  loss: 0.09954176\n",
      "epoch: 128  batch: 15  loss: 0.06974195\n",
      "epoch: 128  batch: 16  loss: 0.07574953\n",
      "epoch: 128  batch: 17  loss: 0.10366715\n",
      "epoch: 128  batch: 18  loss: 0.05254607\n",
      "epoch: 128  batch: 19  loss: 0.06878154\n",
      "epoch: 128  batch: 20  loss: 0.08232735\n",
      "epoch: 128  batch: 21  loss: 0.06675187\n",
      "epoch: 128  batch: 22  loss: 0.09867220\n",
      "epoch: 128  batch: 23  loss: 0.09357978\n",
      "epoch: 128  batch: 24  loss: 0.08002721\n",
      "epoch: 128  batch: 25  loss: 0.09761000\n",
      "epoch: 128  batch: 26  loss: 0.07604296\n",
      "epoch: 128  batch: 27  loss: 0.09393743\n",
      "epoch: 128  batch: 28  loss: 0.07072143\n",
      "epoch: 128  batch: 29  loss: 0.07995825\n",
      "epoch: 128  batch: 30  loss: 0.07422262\n",
      "epoch: 128  batch: 31  loss: 0.07920515\n",
      "epoch: 128  batch: 32  loss: 0.10732970\n",
      "epoch: 128  batch: 33  loss: 0.07173859\n",
      "epoch: 128  batch: 34  loss: 0.05136428\n",
      "epoch: 128  batch: 35  loss: 0.09819449\n",
      "epoch: 128  batch: 36  loss: 0.09560158\n",
      "epoch: 128  batch: 37  loss: 0.06705466\n",
      "epoch: 128  batch: 38  loss: 0.07058446\n",
      "epoch: 128  batch: 39  loss: 0.06389616\n",
      "epoch: 128  batch: 40  loss: 0.07846280\n",
      "epoch: 128  batch: 41  loss: 0.05112702\n",
      "epoch: 128  batch: 42  loss: 0.09197665\n",
      "epoch: 128  batch: 43  loss: 0.10144686\n",
      "epoch: 128  batch: 44  loss: 0.08899602\n",
      "epoch: 128  batch: 45  loss: 0.10456961\n",
      "epoch: 128  batch: 46  loss: 0.05164877\n",
      "epoch: 128  batch: 47  loss: 0.08525193\n",
      "epoch: 128  batch: 48  loss: 0.08331735\n",
      "epoch: 128  batch: 49  loss: 0.06865112\n",
      "epoch: 128  batch: 50  loss: 0.08797957\n",
      "epoch: 128  batch: 51  loss: 0.07408103\n",
      "epoch: 128  batch: 52  loss: 0.08190450\n",
      "epoch: 128  batch: 53  loss: 0.06608383\n",
      "epoch: 128  batch: 54  loss: 0.07437969\n",
      "epoch: 128  batch: 55  loss: 0.08654746\n",
      "epoch: 128  batch: 56  loss: 0.07993195\n",
      "epoch: 128  batch: 57  loss: 0.06934540\n",
      "epoch: 128  batch: 58  loss: 0.08767910\n",
      "epoch: 128  batch: 59  loss: 0.10338075\n",
      "epoch: 128  batch: 60  loss: 0.09172682\n",
      "epoch: 128  batch: 61  loss: 0.06053302\n",
      "epoch: 128  batch: 62  loss: 0.11535858\n",
      "epoch: 128  batch: 63  loss: 0.08557494\n",
      "epoch: 128  batch: 64  loss: 0.07119616\n",
      "epoch: 128  batch: 65  loss: 0.10728701\n",
      "epoch: 128  batch: 66  loss: 0.15657844\n",
      "epoch: 128  batch: 67  loss: 0.06170171\n",
      "epoch: 128  batch: 68  loss: 0.05721093\n",
      "epoch: 128  batch: 69  loss: 0.09305986\n",
      "epoch: 128  batch: 70  loss: 0.06033058\n",
      "epoch: 128  batch: 71  loss: 0.06904073\n",
      "epoch: 128  batch: 72  loss: 0.09140450\n",
      "epoch: 128  batch: 73  loss: 0.09454396\n",
      "epoch: 128  batch: 74  loss: 0.08328493\n",
      "epoch: 128  batch: 75  loss: 0.12098327\n",
      "epoch: 128  batch: 76  loss: 0.08438656\n",
      "epoch: 128  batch: 77  loss: 0.06522449\n",
      "epoch: 128  batch: 78  loss: 0.08954839\n",
      "epoch: 128  batch: 79  loss: 0.10202245\n",
      "epoch: 128  batch: 80  loss: 0.07362561\n",
      "epoch: 128  batch: 81  loss: 0.09350917\n",
      "epoch: 128  batch: 82  loss: 0.07171305\n",
      "epoch: 128  batch: 83  loss: 0.08335011\n",
      "epoch: 128  batch: 84  loss: 0.07401177\n",
      "epoch: 128  batch: 85  loss: 0.10562908\n",
      "epoch: 128  batch: 86  loss: 0.11385465\n",
      "epoch: 128  batch: 87  loss: 0.05911240\n",
      "epoch: 129  batch: 1  loss: 0.06550903\n",
      "epoch: 129  batch: 2  loss: 0.05862138\n",
      "epoch: 129  batch: 3  loss: 0.06970703\n",
      "epoch: 129  batch: 4  loss: 0.09140472\n",
      "epoch: 129  batch: 5  loss: 0.09540345\n",
      "epoch: 129  batch: 6  loss: 0.07054384\n",
      "epoch: 129  batch: 7  loss: 0.10619528\n",
      "epoch: 129  batch: 8  loss: 0.09568445\n",
      "epoch: 129  batch: 9  loss: 0.14150928\n",
      "epoch: 129  batch: 10  loss: 0.07811767\n",
      "epoch: 129  batch: 11  loss: 0.08944279\n",
      "epoch: 129  batch: 12  loss: 0.08662087\n",
      "epoch: 129  batch: 13  loss: 0.11161750\n",
      "epoch: 129  batch: 14  loss: 0.06813893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129  batch: 15  loss: 0.07476408\n",
      "epoch: 129  batch: 16  loss: 0.06361263\n",
      "epoch: 129  batch: 17  loss: 0.08609930\n",
      "epoch: 129  batch: 18  loss: 0.06119625\n",
      "epoch: 129  batch: 19  loss: 0.07889403\n",
      "epoch: 129  batch: 20  loss: 0.08964765\n",
      "epoch: 129  batch: 21  loss: 0.09017181\n",
      "epoch: 129  batch: 22  loss: 0.07887796\n",
      "epoch: 129  batch: 23  loss: 0.05097403\n",
      "epoch: 129  batch: 24  loss: 0.06772385\n",
      "epoch: 129  batch: 25  loss: 0.07396613\n",
      "epoch: 129  batch: 26  loss: 0.06403809\n",
      "epoch: 129  batch: 27  loss: 0.11138433\n",
      "epoch: 129  batch: 28  loss: 0.08592732\n",
      "epoch: 129  batch: 29  loss: 0.08205397\n",
      "epoch: 129  batch: 30  loss: 0.06457879\n",
      "epoch: 129  batch: 31  loss: 0.08546351\n",
      "epoch: 129  batch: 32  loss: 0.07897085\n",
      "epoch: 129  batch: 33  loss: 0.06686273\n",
      "epoch: 129  batch: 34  loss: 0.06895582\n",
      "epoch: 129  batch: 35  loss: 0.10334387\n",
      "epoch: 129  batch: 36  loss: 0.06063139\n",
      "epoch: 129  batch: 37  loss: 0.06800158\n",
      "epoch: 129  batch: 38  loss: 0.06955414\n",
      "epoch: 129  batch: 39  loss: 0.08014818\n",
      "epoch: 129  batch: 40  loss: 0.08104334\n",
      "epoch: 129  batch: 41  loss: 0.06990474\n",
      "epoch: 129  batch: 42  loss: 0.09376283\n",
      "epoch: 129  batch: 43  loss: 0.06348522\n",
      "epoch: 129  batch: 44  loss: 0.09861197\n",
      "epoch: 129  batch: 45  loss: 0.06993806\n",
      "epoch: 129  batch: 46  loss: 0.05694585\n",
      "epoch: 129  batch: 47  loss: 0.07878172\n",
      "epoch: 129  batch: 48  loss: 0.09301139\n",
      "epoch: 129  batch: 49  loss: 0.07179410\n",
      "epoch: 129  batch: 50  loss: 0.06574277\n",
      "epoch: 129  batch: 51  loss: 0.08363990\n",
      "epoch: 129  batch: 52  loss: 0.06145605\n",
      "epoch: 129  batch: 53  loss: 0.05612520\n",
      "epoch: 129  batch: 54  loss: 0.08452944\n",
      "epoch: 129  batch: 55  loss: 0.07380406\n",
      "epoch: 129  batch: 56  loss: 0.07835419\n",
      "epoch: 129  batch: 57  loss: 0.05515948\n",
      "epoch: 129  batch: 58  loss: 0.08766866\n",
      "epoch: 129  batch: 59  loss: 0.07534056\n",
      "epoch: 129  batch: 60  loss: 0.07075661\n",
      "epoch: 129  batch: 61  loss: 0.07616455\n",
      "epoch: 129  batch: 62  loss: 0.11632024\n",
      "epoch: 129  batch: 63  loss: 0.08468555\n",
      "epoch: 129  batch: 64  loss: 0.06592404\n",
      "epoch: 129  batch: 65  loss: 0.12364129\n",
      "epoch: 129  batch: 66  loss: 0.10456242\n",
      "epoch: 129  batch: 67  loss: 0.06244529\n",
      "epoch: 129  batch: 68  loss: 0.07620922\n",
      "epoch: 129  batch: 69  loss: 0.08409455\n",
      "epoch: 129  batch: 70  loss: 0.05253636\n",
      "epoch: 129  batch: 71  loss: 0.06540317\n",
      "epoch: 129  batch: 72  loss: 0.08483496\n",
      "epoch: 129  batch: 73  loss: 0.08427374\n",
      "epoch: 129  batch: 74  loss: 0.10044338\n",
      "epoch: 129  batch: 75  loss: 0.08754860\n",
      "epoch: 129  batch: 76  loss: 0.10551620\n",
      "epoch: 129  batch: 77  loss: 0.11485577\n",
      "epoch: 129  batch: 78  loss: 0.07678128\n",
      "epoch: 129  batch: 79  loss: 0.08846552\n",
      "epoch: 129  batch: 80  loss: 0.08404797\n",
      "epoch: 129  batch: 81  loss: 0.10614928\n",
      "epoch: 129  batch: 82  loss: 0.08309800\n",
      "epoch: 129  batch: 83  loss: 0.06532440\n",
      "epoch: 129  batch: 84  loss: 0.14778922\n",
      "epoch: 129  batch: 85  loss: 0.09767353\n",
      "epoch: 129  batch: 86  loss: 0.08232829\n",
      "epoch: 129  batch: 87  loss: 0.06924711\n",
      "epoch: 130  batch: 1  loss: 0.07194703\n",
      "epoch: 130  batch: 2  loss: 0.05554215\n",
      "epoch: 130  batch: 3  loss: 0.10478482\n",
      "epoch: 130  batch: 4  loss: 0.06918732\n",
      "epoch: 130  batch: 5  loss: 0.06921536\n",
      "epoch: 130  batch: 6  loss: 0.08592121\n",
      "epoch: 130  batch: 7  loss: 0.09649938\n",
      "epoch: 130  batch: 8  loss: 0.13471781\n",
      "epoch: 130  batch: 9  loss: 0.08519641\n",
      "epoch: 130  batch: 10  loss: 0.06325408\n",
      "epoch: 130  batch: 11  loss: 0.06421874\n",
      "epoch: 130  batch: 12  loss: 0.05220953\n",
      "epoch: 130  batch: 13  loss: 0.06330439\n",
      "epoch: 130  batch: 14  loss: 0.07877201\n",
      "epoch: 130  batch: 15  loss: 0.06978547\n",
      "epoch: 130  batch: 16  loss: 0.07369465\n",
      "epoch: 130  batch: 17  loss: 0.05127391\n",
      "epoch: 130  batch: 18  loss: 0.07332917\n",
      "epoch: 130  batch: 19  loss: 0.06497920\n",
      "epoch: 130  batch: 20  loss: 0.09620330\n",
      "epoch: 130  batch: 21  loss: 0.13162164\n",
      "epoch: 130  batch: 22  loss: 0.07641419\n",
      "epoch: 130  batch: 23  loss: 0.08132072\n",
      "epoch: 130  batch: 24  loss: 0.05879719\n",
      "epoch: 130  batch: 25  loss: 0.07184795\n",
      "epoch: 130  batch: 26  loss: 0.09629954\n",
      "epoch: 130  batch: 27  loss: 0.09083179\n",
      "epoch: 130  batch: 28  loss: 0.07558496\n",
      "epoch: 130  batch: 29  loss: 0.11850598\n",
      "epoch: 130  batch: 30  loss: 0.10168647\n",
      "epoch: 130  batch: 31  loss: 0.08854282\n",
      "epoch: 130  batch: 32  loss: 0.06926670\n",
      "epoch: 130  batch: 33  loss: 0.06666157\n",
      "epoch: 130  batch: 34  loss: 0.07358977\n",
      "epoch: 130  batch: 35  loss: 0.06114585\n",
      "epoch: 130  batch: 36  loss: 0.09093514\n",
      "epoch: 130  batch: 37  loss: 0.07677580\n",
      "epoch: 130  batch: 38  loss: 0.07945599\n",
      "epoch: 130  batch: 39  loss: 0.09226703\n",
      "epoch: 130  batch: 40  loss: 0.05799837\n",
      "epoch: 130  batch: 41  loss: 0.07593817\n",
      "epoch: 130  batch: 42  loss: 0.11161541\n",
      "epoch: 130  batch: 43  loss: 0.07809414\n",
      "epoch: 130  batch: 44  loss: 0.06998865\n",
      "epoch: 130  batch: 45  loss: 0.06252874\n",
      "epoch: 130  batch: 46  loss: 0.06723693\n",
      "epoch: 130  batch: 47  loss: 0.09662569\n",
      "epoch: 130  batch: 48  loss: 0.07573308\n",
      "epoch: 130  batch: 49  loss: 0.08770061\n",
      "epoch: 130  batch: 50  loss: 0.06644981\n",
      "epoch: 130  batch: 51  loss: 0.08766434\n",
      "epoch: 130  batch: 52  loss: 0.10419177\n",
      "epoch: 130  batch: 53  loss: 0.08336560\n",
      "epoch: 130  batch: 54  loss: 0.10270078\n",
      "epoch: 130  batch: 55  loss: 0.09284499\n",
      "epoch: 130  batch: 56  loss: 0.07727250\n",
      "epoch: 130  batch: 57  loss: 0.09025256\n",
      "epoch: 130  batch: 58  loss: 0.07368093\n",
      "epoch: 130  batch: 59  loss: 0.08254731\n",
      "epoch: 130  batch: 60  loss: 0.10746588\n",
      "epoch: 130  batch: 61  loss: 0.06204275\n",
      "epoch: 130  batch: 62  loss: 0.09718221\n",
      "epoch: 130  batch: 63  loss: 0.07453059\n",
      "epoch: 130  batch: 64  loss: 0.11177307\n",
      "epoch: 130  batch: 65  loss: 0.10767525\n",
      "epoch: 130  batch: 66  loss: 0.06193915\n",
      "epoch: 130  batch: 67  loss: 0.08082417\n",
      "epoch: 130  batch: 68  loss: 0.10981772\n",
      "epoch: 130  batch: 69  loss: 0.06427231\n",
      "epoch: 130  batch: 70  loss: 0.11980340\n",
      "epoch: 130  batch: 71  loss: 0.05650402\n",
      "epoch: 130  batch: 72  loss: 0.11610391\n",
      "epoch: 130  batch: 73  loss: 0.07147179\n",
      "epoch: 130  batch: 74  loss: 0.07105336\n",
      "epoch: 130  batch: 75  loss: 0.04469681\n",
      "epoch: 130  batch: 76  loss: 0.08251499\n",
      "epoch: 130  batch: 77  loss: 0.08905564\n",
      "epoch: 130  batch: 78  loss: 0.08966187\n",
      "epoch: 130  batch: 79  loss: 0.05910829\n",
      "epoch: 130  batch: 80  loss: 0.09583139\n",
      "epoch: 130  batch: 81  loss: 0.08462714\n",
      "epoch: 130  batch: 82  loss: 0.08202429\n",
      "epoch: 130  batch: 83  loss: 0.05715868\n",
      "epoch: 130  batch: 84  loss: 0.07420809\n",
      "epoch: 130  batch: 85  loss: 0.09380570\n",
      "epoch: 130  batch: 86  loss: 0.09796211\n",
      "epoch: 130  batch: 87  loss: 0.09499650\n",
      "epoch: 131  batch: 1  loss: 0.09909511\n",
      "epoch: 131  batch: 2  loss: 0.07047862\n",
      "epoch: 131  batch: 3  loss: 0.07508943\n",
      "epoch: 131  batch: 4  loss: 0.07765357\n",
      "epoch: 131  batch: 5  loss: 0.07875764\n",
      "epoch: 131  batch: 6  loss: 0.12320532\n",
      "epoch: 131  batch: 7  loss: 0.06437486\n",
      "epoch: 131  batch: 8  loss: 0.12242185\n",
      "epoch: 131  batch: 9  loss: 0.09551255\n",
      "epoch: 131  batch: 10  loss: 0.08209705\n",
      "epoch: 131  batch: 11  loss: 0.09995019\n",
      "epoch: 131  batch: 12  loss: 0.05997523\n",
      "epoch: 131  batch: 13  loss: 0.05594422\n",
      "epoch: 131  batch: 14  loss: 0.07739342\n",
      "epoch: 131  batch: 15  loss: 0.09238895\n",
      "epoch: 131  batch: 16  loss: 0.07114657\n",
      "epoch: 131  batch: 17  loss: 0.10386376\n",
      "epoch: 131  batch: 18  loss: 0.09155663\n",
      "epoch: 131  batch: 19  loss: 0.04704550\n",
      "epoch: 131  batch: 20  loss: 0.07434105\n",
      "epoch: 131  batch: 21  loss: 0.09458251\n",
      "epoch: 131  batch: 22  loss: 0.08177822\n",
      "epoch: 131  batch: 23  loss: 0.06072560\n",
      "epoch: 131  batch: 24  loss: 0.08827382\n",
      "epoch: 131  batch: 25  loss: 0.06059538\n",
      "epoch: 131  batch: 26  loss: 0.06745204\n",
      "epoch: 131  batch: 27  loss: 0.05101356\n",
      "epoch: 131  batch: 28  loss: 0.08644137\n",
      "epoch: 131  batch: 29  loss: 0.09704083\n",
      "epoch: 131  batch: 30  loss: 0.07745754\n",
      "epoch: 131  batch: 31  loss: 0.08903834\n",
      "epoch: 131  batch: 32  loss: 0.11986234\n",
      "epoch: 131  batch: 33  loss: 0.07297891\n",
      "epoch: 131  batch: 34  loss: 0.05984737\n",
      "epoch: 131  batch: 35  loss: 0.07667294\n",
      "epoch: 131  batch: 36  loss: 0.08568332\n",
      "epoch: 131  batch: 37  loss: 0.09601522\n",
      "epoch: 131  batch: 38  loss: 0.08301479\n",
      "epoch: 131  batch: 39  loss: 0.06139880\n",
      "epoch: 131  batch: 40  loss: 0.06796787\n",
      "epoch: 131  batch: 41  loss: 0.05966980\n",
      "epoch: 131  batch: 42  loss: 0.07167224\n",
      "epoch: 131  batch: 43  loss: 0.06100140\n",
      "epoch: 131  batch: 44  loss: 0.07930259\n",
      "epoch: 131  batch: 45  loss: 0.08429633\n",
      "epoch: 131  batch: 46  loss: 0.07678933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 131  batch: 47  loss: 0.12678969\n",
      "epoch: 131  batch: 48  loss: 0.06865561\n",
      "epoch: 131  batch: 49  loss: 0.10702091\n",
      "epoch: 131  batch: 50  loss: 0.06804536\n",
      "epoch: 131  batch: 51  loss: 0.08591005\n",
      "epoch: 131  batch: 52  loss: 0.07999797\n",
      "epoch: 131  batch: 53  loss: 0.11381846\n",
      "epoch: 131  batch: 54  loss: 0.08925774\n",
      "epoch: 131  batch: 55  loss: 0.10354001\n",
      "epoch: 131  batch: 56  loss: 0.08985908\n",
      "epoch: 131  batch: 57  loss: 0.07670405\n",
      "epoch: 131  batch: 58  loss: 0.07298945\n",
      "epoch: 131  batch: 59  loss: 0.11419319\n",
      "epoch: 131  batch: 60  loss: 0.08555834\n",
      "epoch: 131  batch: 61  loss: 0.07917065\n",
      "epoch: 131  batch: 62  loss: 0.08665582\n",
      "epoch: 131  batch: 63  loss: 0.09525394\n",
      "epoch: 131  batch: 64  loss: 0.06194152\n",
      "epoch: 131  batch: 65  loss: 0.07579940\n",
      "epoch: 131  batch: 66  loss: 0.07822657\n",
      "epoch: 131  batch: 67  loss: 0.05180905\n",
      "epoch: 131  batch: 68  loss: 0.06472404\n",
      "epoch: 131  batch: 69  loss: 0.11613525\n",
      "epoch: 131  batch: 70  loss: 0.07503138\n",
      "epoch: 131  batch: 71  loss: 0.07309873\n",
      "epoch: 131  batch: 72  loss: 0.07815510\n",
      "epoch: 131  batch: 73  loss: 0.07643232\n",
      "epoch: 131  batch: 74  loss: 0.11982512\n",
      "epoch: 131  batch: 75  loss: 0.08180175\n",
      "epoch: 131  batch: 76  loss: 0.06536186\n",
      "epoch: 131  batch: 77  loss: 0.04648408\n",
      "epoch: 131  batch: 78  loss: 0.10566384\n",
      "epoch: 131  batch: 79  loss: 0.06926112\n",
      "epoch: 131  batch: 80  loss: 0.06451537\n",
      "epoch: 131  batch: 81  loss: 0.06804549\n",
      "epoch: 131  batch: 82  loss: 0.11923055\n",
      "epoch: 131  batch: 83  loss: 0.11552638\n",
      "epoch: 131  batch: 84  loss: 0.06945252\n",
      "epoch: 131  batch: 85  loss: 0.12013967\n",
      "epoch: 131  batch: 86  loss: 0.08987634\n",
      "epoch: 131  batch: 87  loss: 0.06853835\n",
      "epoch: 132  batch: 1  loss: 0.07820920\n",
      "epoch: 132  batch: 2  loss: 0.07393863\n",
      "epoch: 132  batch: 3  loss: 0.09200724\n",
      "epoch: 132  batch: 4  loss: 0.07572938\n",
      "epoch: 132  batch: 5  loss: 0.08795707\n",
      "epoch: 132  batch: 6  loss: 0.07868207\n",
      "epoch: 132  batch: 7  loss: 0.06560367\n",
      "epoch: 132  batch: 8  loss: 0.06357382\n",
      "epoch: 132  batch: 9  loss: 0.09532018\n",
      "epoch: 132  batch: 10  loss: 0.09027757\n",
      "epoch: 132  batch: 11  loss: 0.09360600\n",
      "epoch: 132  batch: 12  loss: 0.07804527\n",
      "epoch: 132  batch: 13  loss: 0.06967258\n",
      "epoch: 132  batch: 14  loss: 0.11809552\n",
      "epoch: 132  batch: 15  loss: 0.07654847\n",
      "epoch: 132  batch: 16  loss: 0.08089335\n",
      "epoch: 132  batch: 17  loss: 0.08267531\n",
      "epoch: 132  batch: 18  loss: 0.08207370\n",
      "epoch: 132  batch: 19  loss: 0.06891550\n",
      "epoch: 132  batch: 20  loss: 0.07068896\n",
      "epoch: 132  batch: 21  loss: 0.08439398\n",
      "epoch: 132  batch: 22  loss: 0.07828239\n",
      "epoch: 132  batch: 23  loss: 0.07437374\n",
      "epoch: 132  batch: 24  loss: 0.09757753\n",
      "epoch: 132  batch: 25  loss: 0.10117578\n",
      "epoch: 132  batch: 26  loss: 0.06533876\n",
      "epoch: 132  batch: 27  loss: 0.07344471\n",
      "epoch: 132  batch: 28  loss: 0.09061177\n",
      "epoch: 132  batch: 29  loss: 0.11790118\n",
      "epoch: 132  batch: 30  loss: 0.08365941\n",
      "epoch: 132  batch: 31  loss: 0.05935503\n",
      "epoch: 132  batch: 32  loss: 0.06185071\n",
      "epoch: 132  batch: 33  loss: 0.11404847\n",
      "epoch: 132  batch: 34  loss: 0.09130569\n",
      "epoch: 132  batch: 35  loss: 0.11450583\n",
      "epoch: 132  batch: 36  loss: 0.08494465\n",
      "epoch: 132  batch: 37  loss: 0.05672191\n",
      "epoch: 132  batch: 38  loss: 0.06030751\n",
      "epoch: 132  batch: 39  loss: 0.05948508\n",
      "epoch: 132  batch: 40  loss: 0.06083651\n",
      "epoch: 132  batch: 41  loss: 0.07049529\n",
      "epoch: 132  batch: 42  loss: 0.07187572\n",
      "epoch: 132  batch: 43  loss: 0.07201165\n",
      "epoch: 132  batch: 44  loss: 0.06577234\n",
      "epoch: 132  batch: 45  loss: 0.07255835\n",
      "epoch: 132  batch: 46  loss: 0.09143227\n",
      "epoch: 132  batch: 47  loss: 0.08193891\n",
      "epoch: 132  batch: 48  loss: 0.11770349\n",
      "epoch: 132  batch: 49  loss: 0.06181729\n",
      "epoch: 132  batch: 50  loss: 0.11345031\n",
      "epoch: 132  batch: 51  loss: 0.09540897\n",
      "epoch: 132  batch: 52  loss: 0.10141211\n",
      "epoch: 132  batch: 53  loss: 0.09197955\n",
      "epoch: 132  batch: 54  loss: 0.06627295\n",
      "epoch: 132  batch: 55  loss: 0.06700277\n",
      "epoch: 132  batch: 56  loss: 0.12572424\n",
      "epoch: 132  batch: 57  loss: 0.05620797\n",
      "epoch: 132  batch: 58  loss: 0.07578887\n",
      "epoch: 132  batch: 59  loss: 0.10211456\n",
      "epoch: 132  batch: 60  loss: 0.09693108\n",
      "epoch: 132  batch: 61  loss: 0.08107631\n",
      "epoch: 132  batch: 62  loss: 0.11473616\n",
      "epoch: 132  batch: 63  loss: 0.13296311\n",
      "epoch: 132  batch: 64  loss: 0.10174666\n",
      "epoch: 132  batch: 65  loss: 0.16607578\n",
      "epoch: 132  batch: 66  loss: 0.06275076\n",
      "epoch: 132  batch: 67  loss: 0.07820445\n",
      "epoch: 132  batch: 68  loss: 0.07959031\n",
      "epoch: 132  batch: 69  loss: 0.09599894\n",
      "epoch: 132  batch: 70  loss: 0.09754432\n",
      "epoch: 132  batch: 71  loss: 0.07225040\n",
      "epoch: 132  batch: 72  loss: 0.08904929\n",
      "epoch: 132  batch: 73  loss: 0.07882190\n",
      "epoch: 132  batch: 74  loss: 0.11672898\n",
      "epoch: 132  batch: 75  loss: 0.09348565\n",
      "epoch: 132  batch: 76  loss: 0.07781298\n",
      "epoch: 132  batch: 77  loss: 0.08079223\n",
      "epoch: 132  batch: 78  loss: 0.08776543\n",
      "epoch: 132  batch: 79  loss: 0.06115817\n",
      "epoch: 132  batch: 80  loss: 0.05944625\n",
      "epoch: 132  batch: 81  loss: 0.07789317\n",
      "epoch: 132  batch: 82  loss: 0.05762903\n",
      "epoch: 132  batch: 83  loss: 0.05400713\n",
      "epoch: 132  batch: 84  loss: 0.07179719\n",
      "epoch: 132  batch: 85  loss: 0.10236570\n",
      "epoch: 132  batch: 86  loss: 0.16313420\n",
      "epoch: 132  batch: 87  loss: 0.07100131\n",
      "epoch: 133  batch: 1  loss: 0.07760670\n",
      "epoch: 133  batch: 2  loss: 0.05962387\n",
      "epoch: 133  batch: 3  loss: 0.05837759\n",
      "epoch: 133  batch: 4  loss: 0.07158292\n",
      "epoch: 133  batch: 5  loss: 0.05296441\n",
      "epoch: 133  batch: 6  loss: 0.11320618\n",
      "epoch: 133  batch: 7  loss: 0.07821397\n",
      "epoch: 133  batch: 8  loss: 0.07452019\n",
      "epoch: 133  batch: 9  loss: 0.09297720\n",
      "epoch: 133  batch: 10  loss: 0.06885739\n",
      "epoch: 133  batch: 11  loss: 0.09645972\n",
      "epoch: 133  batch: 12  loss: 0.06548997\n",
      "epoch: 133  batch: 13  loss: 0.12782535\n",
      "epoch: 133  batch: 14  loss: 0.07784782\n",
      "epoch: 133  batch: 15  loss: 0.08808227\n",
      "epoch: 133  batch: 16  loss: 0.08354166\n",
      "epoch: 133  batch: 17  loss: 0.10938314\n",
      "epoch: 133  batch: 18  loss: 0.09565702\n",
      "epoch: 133  batch: 19  loss: 0.13973321\n",
      "epoch: 133  batch: 20  loss: 0.05485409\n",
      "epoch: 133  batch: 21  loss: 0.09788099\n",
      "epoch: 133  batch: 22  loss: 0.05516350\n",
      "epoch: 133  batch: 23  loss: 0.07636630\n",
      "epoch: 133  batch: 24  loss: 0.07162631\n",
      "epoch: 133  batch: 25  loss: 0.09377433\n",
      "epoch: 133  batch: 26  loss: 0.07110005\n",
      "epoch: 133  batch: 27  loss: 0.07718988\n",
      "epoch: 133  batch: 28  loss: 0.09059953\n",
      "epoch: 133  batch: 29  loss: 0.15276754\n",
      "epoch: 133  batch: 30  loss: 0.05014459\n",
      "epoch: 133  batch: 31  loss: 0.07991797\n",
      "epoch: 133  batch: 32  loss: 0.06769244\n",
      "epoch: 133  batch: 33  loss: 0.07681622\n",
      "epoch: 133  batch: 34  loss: 0.10832452\n",
      "epoch: 133  batch: 35  loss: 0.08362011\n",
      "epoch: 133  batch: 36  loss: 0.08717191\n",
      "epoch: 133  batch: 37  loss: 0.08988292\n",
      "epoch: 133  batch: 38  loss: 0.09913226\n",
      "epoch: 133  batch: 39  loss: 0.07933762\n",
      "epoch: 133  batch: 40  loss: 0.07053304\n",
      "epoch: 133  batch: 41  loss: 0.05796710\n",
      "epoch: 133  batch: 42  loss: 0.08635762\n",
      "epoch: 133  batch: 43  loss: 0.07892159\n",
      "epoch: 133  batch: 44  loss: 0.10232479\n",
      "epoch: 133  batch: 45  loss: 0.10388194\n",
      "epoch: 133  batch: 46  loss: 0.06405403\n",
      "epoch: 133  batch: 47  loss: 0.05443563\n",
      "epoch: 133  batch: 48  loss: 0.06538492\n",
      "epoch: 133  batch: 49  loss: 0.07769042\n",
      "epoch: 133  batch: 50  loss: 0.06495847\n",
      "epoch: 133  batch: 51  loss: 0.10889837\n",
      "epoch: 133  batch: 52  loss: 0.06687148\n",
      "epoch: 133  batch: 53  loss: 0.07214918\n",
      "epoch: 133  batch: 54  loss: 0.11321250\n",
      "epoch: 133  batch: 55  loss: 0.04984212\n",
      "epoch: 133  batch: 56  loss: 0.07913418\n",
      "epoch: 133  batch: 57  loss: 0.12788296\n",
      "epoch: 133  batch: 58  loss: 0.07567419\n",
      "epoch: 133  batch: 59  loss: 0.06462999\n",
      "epoch: 133  batch: 60  loss: 0.06289274\n",
      "epoch: 133  batch: 61  loss: 0.07450125\n",
      "epoch: 133  batch: 62  loss: 0.07026805\n",
      "epoch: 133  batch: 63  loss: 0.11250384\n",
      "epoch: 133  batch: 64  loss: 0.09875020\n",
      "epoch: 133  batch: 65  loss: 0.08756929\n",
      "epoch: 133  batch: 66  loss: 0.08570033\n",
      "epoch: 133  batch: 67  loss: 0.11004584\n",
      "epoch: 133  batch: 68  loss: 0.07727727\n",
      "epoch: 133  batch: 69  loss: 0.07059224\n",
      "epoch: 133  batch: 70  loss: 0.05695885\n",
      "epoch: 133  batch: 71  loss: 0.07259392\n",
      "epoch: 133  batch: 72  loss: 0.08313411\n",
      "epoch: 133  batch: 73  loss: 0.07122931\n",
      "epoch: 133  batch: 74  loss: 0.07480429\n",
      "epoch: 133  batch: 75  loss: 0.07259743\n",
      "epoch: 133  batch: 76  loss: 0.07013092\n",
      "epoch: 133  batch: 77  loss: 0.09478107\n",
      "epoch: 133  batch: 78  loss: 0.10224497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133  batch: 79  loss: 0.10390410\n",
      "epoch: 133  batch: 80  loss: 0.06135281\n",
      "epoch: 133  batch: 81  loss: 0.09646796\n",
      "epoch: 133  batch: 82  loss: 0.07860614\n",
      "epoch: 133  batch: 83  loss: 0.10186274\n",
      "epoch: 133  batch: 84  loss: 0.15613109\n",
      "epoch: 133  batch: 85  loss: 0.05887623\n",
      "epoch: 133  batch: 86  loss: 0.07657228\n",
      "epoch: 133  batch: 87  loss: 0.07774755\n",
      "epoch: 134  batch: 1  loss: 0.06901188\n",
      "epoch: 134  batch: 2  loss: 0.07101224\n",
      "epoch: 134  batch: 3  loss: 0.08351734\n",
      "epoch: 134  batch: 4  loss: 0.05632621\n",
      "epoch: 134  batch: 5  loss: 0.07045442\n",
      "epoch: 134  batch: 6  loss: 0.07646819\n",
      "epoch: 134  batch: 7  loss: 0.10548743\n",
      "epoch: 134  batch: 8  loss: 0.07986257\n",
      "epoch: 134  batch: 9  loss: 0.05633808\n",
      "epoch: 134  batch: 10  loss: 0.05248111\n",
      "epoch: 134  batch: 11  loss: 0.07408106\n",
      "epoch: 134  batch: 12  loss: 0.04531637\n",
      "epoch: 134  batch: 13  loss: 0.13737568\n",
      "epoch: 134  batch: 14  loss: 0.07891975\n",
      "epoch: 134  batch: 15  loss: 0.08169130\n",
      "epoch: 134  batch: 16  loss: 0.05498593\n",
      "epoch: 134  batch: 17  loss: 0.07048491\n",
      "epoch: 134  batch: 18  loss: 0.08684303\n",
      "epoch: 134  batch: 19  loss: 0.09671261\n",
      "epoch: 134  batch: 20  loss: 0.08971051\n",
      "epoch: 134  batch: 21  loss: 0.12548679\n",
      "epoch: 134  batch: 22  loss: 0.08363002\n",
      "epoch: 134  batch: 23  loss: 0.07054680\n",
      "epoch: 134  batch: 24  loss: 0.08426756\n",
      "epoch: 134  batch: 25  loss: 0.05489516\n",
      "epoch: 134  batch: 26  loss: 0.13671449\n",
      "epoch: 134  batch: 27  loss: 0.08454639\n",
      "epoch: 134  batch: 28  loss: 0.08185432\n",
      "epoch: 134  batch: 29  loss: 0.06428123\n",
      "epoch: 134  batch: 30  loss: 0.06627294\n",
      "epoch: 134  batch: 31  loss: 0.06463896\n",
      "epoch: 134  batch: 32  loss: 0.12245689\n",
      "epoch: 134  batch: 33  loss: 0.06325809\n",
      "epoch: 134  batch: 34  loss: 0.07306805\n",
      "epoch: 134  batch: 35  loss: 0.08652910\n",
      "epoch: 134  batch: 36  loss: 0.05827280\n",
      "epoch: 134  batch: 37  loss: 0.08284656\n",
      "epoch: 134  batch: 38  loss: 0.05866415\n",
      "epoch: 134  batch: 39  loss: 0.10192987\n",
      "epoch: 134  batch: 40  loss: 0.11072447\n",
      "epoch: 134  batch: 41  loss: 0.07800741\n",
      "epoch: 134  batch: 42  loss: 0.07069610\n",
      "epoch: 134  batch: 43  loss: 0.07481384\n",
      "epoch: 134  batch: 44  loss: 0.06804973\n",
      "epoch: 134  batch: 45  loss: 0.07747456\n",
      "epoch: 134  batch: 46  loss: 0.08234093\n",
      "epoch: 134  batch: 47  loss: 0.05531246\n",
      "epoch: 134  batch: 48  loss: 0.07850172\n",
      "epoch: 134  batch: 49  loss: 0.08172506\n",
      "epoch: 134  batch: 50  loss: 0.07302002\n",
      "epoch: 134  batch: 51  loss: 0.07661776\n",
      "epoch: 134  batch: 52  loss: 0.09791001\n",
      "epoch: 134  batch: 53  loss: 0.10263173\n",
      "epoch: 134  batch: 54  loss: 0.10754199\n",
      "epoch: 134  batch: 55  loss: 0.09050864\n",
      "epoch: 134  batch: 56  loss: 0.05111683\n",
      "epoch: 134  batch: 57  loss: 0.06314460\n",
      "epoch: 134  batch: 58  loss: 0.06287511\n",
      "epoch: 134  batch: 59  loss: 0.08079763\n",
      "epoch: 134  batch: 60  loss: 0.06710355\n",
      "epoch: 134  batch: 61  loss: 0.07218941\n",
      "epoch: 134  batch: 62  loss: 0.08492260\n",
      "epoch: 134  batch: 63  loss: 0.08457470\n",
      "epoch: 134  batch: 64  loss: 0.11094297\n",
      "epoch: 134  batch: 65  loss: 0.12674078\n",
      "epoch: 134  batch: 66  loss: 0.10801736\n",
      "epoch: 134  batch: 67  loss: 0.13063966\n",
      "epoch: 134  batch: 68  loss: 0.10033179\n",
      "epoch: 134  batch: 69  loss: 0.10210992\n",
      "epoch: 134  batch: 70  loss: 0.10720403\n",
      "epoch: 134  batch: 71  loss: 0.08027578\n",
      "epoch: 134  batch: 72  loss: 0.10574686\n",
      "epoch: 134  batch: 73  loss: 0.07467209\n",
      "epoch: 134  batch: 74  loss: 0.08027533\n",
      "epoch: 134  batch: 75  loss: 0.06181917\n",
      "epoch: 134  batch: 76  loss: 0.08048367\n",
      "epoch: 134  batch: 77  loss: 0.06608244\n",
      "epoch: 134  batch: 78  loss: 0.08957125\n",
      "epoch: 134  batch: 79  loss: 0.09481479\n",
      "epoch: 134  batch: 80  loss: 0.11439943\n",
      "epoch: 134  batch: 81  loss: 0.10127424\n",
      "epoch: 134  batch: 82  loss: 0.06211830\n",
      "epoch: 134  batch: 83  loss: 0.12408108\n",
      "epoch: 134  batch: 84  loss: 0.06019568\n",
      "epoch: 134  batch: 85  loss: 0.08845570\n",
      "epoch: 134  batch: 86  loss: 0.06683563\n",
      "epoch: 134  batch: 87  loss: 0.10637236\n",
      "epoch: 135  batch: 1  loss: 0.08511262\n",
      "epoch: 135  batch: 2  loss: 0.06712019\n",
      "epoch: 135  batch: 3  loss: 0.09294658\n",
      "epoch: 135  batch: 4  loss: 0.11957111\n",
      "epoch: 135  batch: 5  loss: 0.04939816\n",
      "epoch: 135  batch: 6  loss: 0.06202260\n",
      "epoch: 135  batch: 7  loss: 0.06579214\n",
      "epoch: 135  batch: 8  loss: 0.09096877\n",
      "epoch: 135  batch: 9  loss: 0.08135669\n",
      "epoch: 135  batch: 10  loss: 0.09730157\n",
      "epoch: 135  batch: 11  loss: 0.10901501\n",
      "epoch: 135  batch: 12  loss: 0.07884702\n",
      "epoch: 135  batch: 13  loss: 0.07831126\n",
      "epoch: 135  batch: 14  loss: 0.07021580\n",
      "epoch: 135  batch: 15  loss: 0.09713908\n",
      "epoch: 135  batch: 16  loss: 0.08668115\n",
      "epoch: 135  batch: 17  loss: 0.08010711\n",
      "epoch: 135  batch: 18  loss: 0.09331226\n",
      "epoch: 135  batch: 19  loss: 0.12595114\n",
      "epoch: 135  batch: 20  loss: 0.06165116\n",
      "epoch: 135  batch: 21  loss: 0.07550965\n",
      "epoch: 135  batch: 22  loss: 0.07713922\n",
      "epoch: 135  batch: 23  loss: 0.10542945\n",
      "epoch: 135  batch: 24  loss: 0.07014669\n",
      "epoch: 135  batch: 25  loss: 0.10612730\n",
      "epoch: 135  batch: 26  loss: 0.10718904\n",
      "epoch: 135  batch: 27  loss: 0.08527019\n",
      "epoch: 135  batch: 28  loss: 0.10698028\n",
      "epoch: 135  batch: 29  loss: 0.09264328\n",
      "epoch: 135  batch: 30  loss: 0.09037656\n",
      "epoch: 135  batch: 31  loss: 0.06216123\n",
      "epoch: 135  batch: 32  loss: 0.07321830\n",
      "epoch: 135  batch: 33  loss: 0.07649548\n",
      "epoch: 135  batch: 34  loss: 0.06594277\n",
      "epoch: 135  batch: 35  loss: 0.07232980\n",
      "epoch: 135  batch: 36  loss: 0.10386092\n",
      "epoch: 135  batch: 37  loss: 0.08142354\n",
      "epoch: 135  batch: 38  loss: 0.07055879\n",
      "epoch: 135  batch: 39  loss: 0.06262626\n",
      "epoch: 135  batch: 40  loss: 0.08764795\n",
      "epoch: 135  batch: 41  loss: 0.07171740\n",
      "epoch: 135  batch: 42  loss: 0.09395978\n",
      "epoch: 135  batch: 43  loss: 0.07124463\n",
      "epoch: 135  batch: 44  loss: 0.10033392\n",
      "epoch: 135  batch: 45  loss: 0.10539117\n",
      "epoch: 135  batch: 46  loss: 0.14273660\n",
      "epoch: 135  batch: 47  loss: 0.11300422\n",
      "epoch: 135  batch: 48  loss: 0.05715751\n",
      "epoch: 135  batch: 49  loss: 0.07712378\n",
      "epoch: 135  batch: 50  loss: 0.10743099\n",
      "epoch: 135  batch: 51  loss: 0.05403086\n",
      "epoch: 135  batch: 52  loss: 0.07521853\n",
      "epoch: 135  batch: 53  loss: 0.08977679\n",
      "epoch: 135  batch: 54  loss: 0.07882173\n",
      "epoch: 135  batch: 55  loss: 0.06978765\n",
      "epoch: 135  batch: 56  loss: 0.06677215\n",
      "epoch: 135  batch: 57  loss: 0.10618330\n",
      "epoch: 135  batch: 58  loss: 0.07706533\n",
      "epoch: 135  batch: 59  loss: 0.06883159\n",
      "epoch: 135  batch: 60  loss: 0.08818700\n",
      "epoch: 135  batch: 61  loss: 0.11802504\n",
      "epoch: 135  batch: 62  loss: 0.08132330\n",
      "epoch: 135  batch: 63  loss: 0.08190674\n",
      "epoch: 135  batch: 64  loss: 0.06718197\n",
      "epoch: 135  batch: 65  loss: 0.12194674\n",
      "epoch: 135  batch: 66  loss: 0.07594390\n",
      "epoch: 135  batch: 67  loss: 0.06744662\n",
      "epoch: 135  batch: 68  loss: 0.07283435\n",
      "epoch: 135  batch: 69  loss: 0.06530237\n",
      "epoch: 135  batch: 70  loss: 0.07060647\n",
      "epoch: 135  batch: 71  loss: 0.06575024\n",
      "epoch: 135  batch: 72  loss: 0.09577815\n",
      "epoch: 135  batch: 73  loss: 0.08824120\n",
      "epoch: 135  batch: 74  loss: 0.11031678\n",
      "epoch: 135  batch: 75  loss: 0.06630221\n",
      "epoch: 135  batch: 76  loss: 0.07941191\n",
      "epoch: 135  batch: 77  loss: 0.07084891\n",
      "epoch: 135  batch: 78  loss: 0.09138507\n",
      "epoch: 135  batch: 79  loss: 0.09594912\n",
      "epoch: 135  batch: 80  loss: 0.08811946\n",
      "epoch: 135  batch: 81  loss: 0.07310244\n",
      "epoch: 135  batch: 82  loss: 0.10678174\n",
      "epoch: 135  batch: 83  loss: 0.07737537\n",
      "epoch: 135  batch: 84  loss: 0.07395576\n",
      "epoch: 135  batch: 85  loss: 0.07674947\n",
      "epoch: 135  batch: 86  loss: 0.11141095\n",
      "epoch: 135  batch: 87  loss: 0.07898388\n",
      "epoch: 136  batch: 1  loss: 0.09468160\n",
      "epoch: 136  batch: 2  loss: 0.09034400\n",
      "epoch: 136  batch: 3  loss: 0.08145375\n",
      "epoch: 136  batch: 4  loss: 0.13537799\n",
      "epoch: 136  batch: 5  loss: 0.10233726\n",
      "epoch: 136  batch: 6  loss: 0.09981612\n",
      "epoch: 136  batch: 7  loss: 0.07834528\n",
      "epoch: 136  batch: 8  loss: 0.04605389\n",
      "epoch: 136  batch: 9  loss: 0.06657705\n",
      "epoch: 136  batch: 10  loss: 0.07065438\n",
      "epoch: 136  batch: 11  loss: 0.06927400\n",
      "epoch: 136  batch: 12  loss: 0.13147114\n",
      "epoch: 136  batch: 13  loss: 0.07783081\n",
      "epoch: 136  batch: 14  loss: 0.08503900\n",
      "epoch: 136  batch: 15  loss: 0.07929700\n",
      "epoch: 136  batch: 16  loss: 0.07106182\n",
      "epoch: 136  batch: 17  loss: 0.06144309\n",
      "epoch: 136  batch: 18  loss: 0.07520102\n",
      "epoch: 136  batch: 19  loss: 0.05939708\n",
      "epoch: 136  batch: 20  loss: 0.06636846\n",
      "epoch: 136  batch: 21  loss: 0.06573227\n",
      "epoch: 136  batch: 22  loss: 0.10005367\n",
      "epoch: 136  batch: 23  loss: 0.09771094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136  batch: 24  loss: 0.09265535\n",
      "epoch: 136  batch: 25  loss: 0.07287624\n",
      "epoch: 136  batch: 26  loss: 0.10247314\n",
      "epoch: 136  batch: 27  loss: 0.07524982\n",
      "epoch: 136  batch: 28  loss: 0.11813051\n",
      "epoch: 136  batch: 29  loss: 0.07589196\n",
      "epoch: 136  batch: 30  loss: 0.07057201\n",
      "epoch: 136  batch: 31  loss: 0.08351228\n",
      "epoch: 136  batch: 32  loss: 0.07857146\n",
      "epoch: 136  batch: 33  loss: 0.06320170\n",
      "epoch: 136  batch: 34  loss: 0.08866659\n",
      "epoch: 136  batch: 35  loss: 0.09016522\n",
      "epoch: 136  batch: 36  loss: 0.06272845\n",
      "epoch: 136  batch: 37  loss: 0.08683018\n",
      "epoch: 136  batch: 38  loss: 0.06649810\n",
      "epoch: 136  batch: 39  loss: 0.10717461\n",
      "epoch: 136  batch: 40  loss: 0.08124349\n",
      "epoch: 136  batch: 41  loss: 0.06597629\n",
      "epoch: 136  batch: 42  loss: 0.08952659\n",
      "epoch: 136  batch: 43  loss: 0.06218925\n",
      "epoch: 136  batch: 44  loss: 0.05678267\n",
      "epoch: 136  batch: 45  loss: 0.08177279\n",
      "epoch: 136  batch: 46  loss: 0.09892173\n",
      "epoch: 136  batch: 47  loss: 0.05301229\n",
      "epoch: 136  batch: 48  loss: 0.10028897\n",
      "epoch: 136  batch: 49  loss: 0.09797493\n",
      "epoch: 136  batch: 50  loss: 0.09120879\n",
      "epoch: 136  batch: 51  loss: 0.09104078\n",
      "epoch: 136  batch: 52  loss: 0.08768240\n",
      "epoch: 136  batch: 53  loss: 0.10024852\n",
      "epoch: 136  batch: 54  loss: 0.09213392\n",
      "epoch: 136  batch: 55  loss: 0.05119204\n",
      "epoch: 136  batch: 56  loss: 0.10637325\n",
      "epoch: 136  batch: 57  loss: 0.07440732\n",
      "epoch: 136  batch: 58  loss: 0.13475004\n",
      "epoch: 136  batch: 59  loss: 0.08212279\n",
      "epoch: 136  batch: 60  loss: 0.07234115\n",
      "epoch: 136  batch: 61  loss: 0.05804003\n",
      "epoch: 136  batch: 62  loss: 0.07794166\n",
      "epoch: 136  batch: 63  loss: 0.07839225\n",
      "epoch: 136  batch: 64  loss: 0.05704529\n",
      "epoch: 136  batch: 65  loss: 0.10122801\n",
      "epoch: 136  batch: 66  loss: 0.06718409\n",
      "epoch: 136  batch: 67  loss: 0.06028416\n",
      "epoch: 136  batch: 68  loss: 0.06838037\n",
      "epoch: 136  batch: 69  loss: 0.08030276\n",
      "epoch: 136  batch: 70  loss: 0.07165586\n",
      "epoch: 136  batch: 71  loss: 0.10240745\n",
      "epoch: 136  batch: 72  loss: 0.07805205\n",
      "epoch: 136  batch: 73  loss: 0.08819245\n",
      "epoch: 136  batch: 74  loss: 0.05932460\n",
      "epoch: 136  batch: 75  loss: 0.05765286\n",
      "epoch: 136  batch: 76  loss: 0.05905484\n",
      "epoch: 136  batch: 77  loss: 0.09464934\n",
      "epoch: 136  batch: 78  loss: 0.06535583\n",
      "epoch: 136  batch: 79  loss: 0.09646221\n",
      "epoch: 136  batch: 80  loss: 0.09317899\n",
      "epoch: 136  batch: 81  loss: 0.08237308\n",
      "epoch: 136  batch: 82  loss: 0.09159280\n",
      "epoch: 136  batch: 83  loss: 0.08782796\n",
      "epoch: 136  batch: 84  loss: 0.12221530\n",
      "epoch: 136  batch: 85  loss: 0.11431382\n",
      "epoch: 136  batch: 86  loss: 0.08315802\n",
      "epoch: 136  batch: 87  loss: 0.08147307\n",
      "epoch: 137  batch: 1  loss: 0.07129888\n",
      "epoch: 137  batch: 2  loss: 0.11476322\n",
      "epoch: 137  batch: 3  loss: 0.08156711\n",
      "epoch: 137  batch: 4  loss: 0.09634963\n",
      "epoch: 137  batch: 5  loss: 0.09263209\n",
      "epoch: 137  batch: 6  loss: 0.06220497\n",
      "epoch: 137  batch: 7  loss: 0.07892326\n",
      "epoch: 137  batch: 8  loss: 0.06147992\n",
      "epoch: 137  batch: 9  loss: 0.08483806\n",
      "epoch: 137  batch: 10  loss: 0.05836540\n",
      "epoch: 137  batch: 11  loss: 0.09788205\n",
      "epoch: 137  batch: 12  loss: 0.07909999\n",
      "epoch: 137  batch: 13  loss: 0.08010508\n",
      "epoch: 137  batch: 14  loss: 0.06826367\n",
      "epoch: 137  batch: 15  loss: 0.07701220\n",
      "epoch: 137  batch: 16  loss: 0.12763424\n",
      "epoch: 137  batch: 17  loss: 0.07089168\n",
      "epoch: 137  batch: 18  loss: 0.09975791\n",
      "epoch: 137  batch: 19  loss: 0.07311817\n",
      "epoch: 137  batch: 20  loss: 0.06514545\n",
      "epoch: 137  batch: 21  loss: 0.10509002\n",
      "epoch: 137  batch: 22  loss: 0.11110734\n",
      "epoch: 137  batch: 23  loss: 0.06295420\n",
      "epoch: 137  batch: 24  loss: 0.08052111\n",
      "epoch: 137  batch: 25  loss: 0.08392713\n",
      "epoch: 137  batch: 26  loss: 0.06927211\n",
      "epoch: 137  batch: 27  loss: 0.08287344\n",
      "epoch: 137  batch: 28  loss: 0.10523306\n",
      "epoch: 137  batch: 29  loss: 0.07860773\n",
      "epoch: 137  batch: 30  loss: 0.06183326\n",
      "epoch: 137  batch: 31  loss: 0.07733089\n",
      "epoch: 137  batch: 32  loss: 0.09489083\n",
      "epoch: 137  batch: 33  loss: 0.11768051\n",
      "epoch: 137  batch: 34  loss: 0.07648091\n",
      "epoch: 137  batch: 35  loss: 0.11923355\n",
      "epoch: 137  batch: 36  loss: 0.07533775\n",
      "epoch: 137  batch: 37  loss: 0.06386428\n",
      "epoch: 137  batch: 38  loss: 0.08163012\n",
      "epoch: 137  batch: 39  loss: 0.08970824\n",
      "epoch: 137  batch: 40  loss: 0.05541892\n",
      "epoch: 137  batch: 41  loss: 0.12124376\n",
      "epoch: 137  batch: 42  loss: 0.07475122\n",
      "epoch: 137  batch: 43  loss: 0.08492097\n",
      "epoch: 137  batch: 44  loss: 0.09885462\n",
      "epoch: 137  batch: 45  loss: 0.11327730\n",
      "epoch: 137  batch: 46  loss: 0.06729284\n",
      "epoch: 137  batch: 47  loss: 0.07102196\n",
      "epoch: 137  batch: 48  loss: 0.06867965\n",
      "epoch: 137  batch: 49  loss: 0.09796974\n",
      "epoch: 137  batch: 50  loss: 0.06227349\n",
      "epoch: 137  batch: 51  loss: 0.12068882\n",
      "epoch: 137  batch: 52  loss: 0.09589642\n",
      "epoch: 137  batch: 53  loss: 0.15809521\n",
      "epoch: 137  batch: 54  loss: 0.10136939\n",
      "epoch: 137  batch: 55  loss: 0.13632230\n",
      "epoch: 137  batch: 56  loss: 0.05429870\n",
      "epoch: 137  batch: 57  loss: 0.06489171\n",
      "epoch: 137  batch: 58  loss: 0.13627616\n",
      "epoch: 137  batch: 59  loss: 0.06100080\n",
      "epoch: 137  batch: 60  loss: 0.09716585\n",
      "epoch: 137  batch: 61  loss: 0.10259688\n",
      "epoch: 137  batch: 62  loss: 0.06732261\n",
      "epoch: 137  batch: 63  loss: 0.09866103\n",
      "epoch: 137  batch: 64  loss: 0.05873286\n",
      "epoch: 137  batch: 65  loss: 0.06178089\n",
      "epoch: 137  batch: 66  loss: 0.08885027\n",
      "epoch: 137  batch: 67  loss: 0.05741221\n",
      "epoch: 137  batch: 68  loss: 0.07785265\n",
      "epoch: 137  batch: 69  loss: 0.09908397\n",
      "epoch: 137  batch: 70  loss: 0.08403645\n",
      "epoch: 137  batch: 71  loss: 0.06150521\n",
      "epoch: 137  batch: 72  loss: 0.04919570\n",
      "epoch: 137  batch: 73  loss: 0.09677680\n",
      "epoch: 137  batch: 74  loss: 0.09336436\n",
      "epoch: 137  batch: 75  loss: 0.09955474\n",
      "epoch: 137  batch: 76  loss: 0.12103815\n",
      "epoch: 137  batch: 77  loss: 0.09406830\n",
      "epoch: 137  batch: 78  loss: 0.07244933\n",
      "epoch: 137  batch: 79  loss: 0.07121701\n",
      "epoch: 137  batch: 80  loss: 0.10127390\n",
      "epoch: 137  batch: 81  loss: 0.12820667\n",
      "epoch: 137  batch: 82  loss: 0.06538027\n",
      "epoch: 137  batch: 83  loss: 0.08090176\n",
      "epoch: 137  batch: 84  loss: 0.08089365\n",
      "epoch: 137  batch: 85  loss: 0.06611644\n",
      "epoch: 137  batch: 86  loss: 0.09824269\n",
      "epoch: 137  batch: 87  loss: 0.10208219\n",
      "epoch: 138  batch: 1  loss: 0.08089897\n",
      "epoch: 138  batch: 2  loss: 0.10439217\n",
      "epoch: 138  batch: 3  loss: 0.09843686\n",
      "epoch: 138  batch: 4  loss: 0.05010745\n",
      "epoch: 138  batch: 5  loss: 0.07351276\n",
      "epoch: 138  batch: 6  loss: 0.09719408\n",
      "epoch: 138  batch: 7  loss: 0.04730624\n",
      "epoch: 138  batch: 8  loss: 0.05271594\n",
      "epoch: 138  batch: 9  loss: 0.06416238\n",
      "epoch: 138  batch: 10  loss: 0.06602250\n",
      "epoch: 138  batch: 11  loss: 0.06063884\n",
      "epoch: 138  batch: 12  loss: 0.06488778\n",
      "epoch: 138  batch: 13  loss: 0.07460731\n",
      "epoch: 138  batch: 14  loss: 0.11055592\n",
      "epoch: 138  batch: 15  loss: 0.10364444\n",
      "epoch: 138  batch: 16  loss: 0.08123789\n",
      "epoch: 138  batch: 17  loss: 0.11738245\n",
      "epoch: 138  batch: 18  loss: 0.07474638\n",
      "epoch: 138  batch: 19  loss: 0.07506669\n",
      "epoch: 138  batch: 20  loss: 0.07583235\n",
      "epoch: 138  batch: 21  loss: 0.09959682\n",
      "epoch: 138  batch: 22  loss: 0.09408694\n",
      "epoch: 138  batch: 23  loss: 0.07369832\n",
      "epoch: 138  batch: 24  loss: 0.05493430\n",
      "epoch: 138  batch: 25  loss: 0.12714460\n",
      "epoch: 138  batch: 26  loss: 0.07721884\n",
      "epoch: 138  batch: 27  loss: 0.07441092\n",
      "epoch: 138  batch: 28  loss: 0.08888164\n",
      "epoch: 138  batch: 29  loss: 0.07662596\n",
      "epoch: 138  batch: 30  loss: 0.04824336\n",
      "epoch: 138  batch: 31  loss: 0.09437956\n",
      "epoch: 138  batch: 32  loss: 0.07378070\n",
      "epoch: 138  batch: 33  loss: 0.10741061\n",
      "epoch: 138  batch: 34  loss: 0.10103360\n",
      "epoch: 138  batch: 35  loss: 0.05769082\n",
      "epoch: 138  batch: 36  loss: 0.07000545\n",
      "epoch: 138  batch: 37  loss: 0.07142810\n",
      "epoch: 138  batch: 38  loss: 0.08623692\n",
      "epoch: 138  batch: 39  loss: 0.05847857\n",
      "epoch: 138  batch: 40  loss: 0.12090707\n",
      "epoch: 138  batch: 41  loss: 0.06457750\n",
      "epoch: 138  batch: 42  loss: 0.10119467\n",
      "epoch: 138  batch: 43  loss: 0.08593183\n",
      "epoch: 138  batch: 44  loss: 0.06008581\n",
      "epoch: 138  batch: 45  loss: 0.05542834\n",
      "epoch: 138  batch: 46  loss: 0.07605025\n",
      "epoch: 138  batch: 47  loss: 0.05812251\n",
      "epoch: 138  batch: 48  loss: 0.10009000\n",
      "epoch: 138  batch: 49  loss: 0.08056476\n",
      "epoch: 138  batch: 50  loss: 0.07787032\n",
      "epoch: 138  batch: 51  loss: 0.07667677\n",
      "epoch: 138  batch: 52  loss: 0.07625667\n",
      "epoch: 138  batch: 53  loss: 0.10334666\n",
      "epoch: 138  batch: 54  loss: 0.08436534\n",
      "epoch: 138  batch: 55  loss: 0.08566186\n",
      "epoch: 138  batch: 56  loss: 0.07601696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 138  batch: 57  loss: 0.07054925\n",
      "epoch: 138  batch: 58  loss: 0.09990247\n",
      "epoch: 138  batch: 59  loss: 0.06162630\n",
      "epoch: 138  batch: 60  loss: 0.09015469\n",
      "epoch: 138  batch: 61  loss: 0.07126036\n",
      "epoch: 138  batch: 62  loss: 0.07403507\n",
      "epoch: 138  batch: 63  loss: 0.09290636\n",
      "epoch: 138  batch: 64  loss: 0.06746950\n",
      "epoch: 138  batch: 65  loss: 0.10537318\n",
      "epoch: 138  batch: 66  loss: 0.06169306\n",
      "epoch: 138  batch: 67  loss: 0.11150542\n",
      "epoch: 138  batch: 68  loss: 0.07131617\n",
      "epoch: 138  batch: 69  loss: 0.07773776\n",
      "epoch: 138  batch: 70  loss: 0.08452122\n",
      "epoch: 138  batch: 71  loss: 0.11940257\n",
      "epoch: 138  batch: 72  loss: 0.05530268\n",
      "epoch: 138  batch: 73  loss: 0.14240626\n",
      "epoch: 138  batch: 74  loss: 0.11647410\n",
      "epoch: 138  batch: 75  loss: 0.09295110\n",
      "epoch: 138  batch: 76  loss: 0.08663461\n",
      "epoch: 138  batch: 77  loss: 0.16217323\n",
      "epoch: 138  batch: 78  loss: 0.08037964\n",
      "epoch: 138  batch: 79  loss: 0.10679206\n",
      "epoch: 138  batch: 80  loss: 0.08806904\n",
      "epoch: 138  batch: 81  loss: 0.09162752\n",
      "epoch: 138  batch: 82  loss: 0.05844086\n",
      "epoch: 138  batch: 83  loss: 0.09096280\n",
      "epoch: 138  batch: 84  loss: 0.12019503\n",
      "epoch: 138  batch: 85  loss: 0.06823435\n",
      "epoch: 138  batch: 86  loss: 0.10241747\n",
      "epoch: 138  batch: 87  loss: 0.09550694\n",
      "epoch: 139  batch: 1  loss: 0.06991588\n",
      "epoch: 139  batch: 2  loss: 0.07105039\n",
      "epoch: 139  batch: 3  loss: 0.05898695\n",
      "epoch: 139  batch: 4  loss: 0.06956141\n",
      "epoch: 139  batch: 5  loss: 0.12656228\n",
      "epoch: 139  batch: 6  loss: 0.07719948\n",
      "epoch: 139  batch: 7  loss: 0.11850251\n",
      "epoch: 139  batch: 8  loss: 0.05980854\n",
      "epoch: 139  batch: 9  loss: 0.06885762\n",
      "epoch: 139  batch: 10  loss: 0.11296224\n",
      "epoch: 139  batch: 11  loss: 0.07344048\n",
      "epoch: 139  batch: 12  loss: 0.15739913\n",
      "epoch: 139  batch: 13  loss: 0.08238412\n",
      "epoch: 139  batch: 14  loss: 0.06870675\n",
      "epoch: 139  batch: 15  loss: 0.07619988\n",
      "epoch: 139  batch: 16  loss: 0.07537908\n",
      "epoch: 139  batch: 17  loss: 0.06982017\n",
      "epoch: 139  batch: 18  loss: 0.06711203\n",
      "epoch: 139  batch: 19  loss: 0.11623212\n",
      "epoch: 139  batch: 20  loss: 0.07978824\n",
      "epoch: 139  batch: 21  loss: 0.06559058\n",
      "epoch: 139  batch: 22  loss: 0.09948031\n",
      "epoch: 139  batch: 23  loss: 0.09358686\n",
      "epoch: 139  batch: 24  loss: 0.07014595\n",
      "epoch: 139  batch: 25  loss: 0.05702307\n",
      "epoch: 139  batch: 26  loss: 0.07725082\n",
      "epoch: 139  batch: 27  loss: 0.08971686\n",
      "epoch: 139  batch: 28  loss: 0.10939769\n",
      "epoch: 139  batch: 29  loss: 0.08040527\n",
      "epoch: 139  batch: 30  loss: 0.06815673\n",
      "epoch: 139  batch: 31  loss: 0.06814189\n",
      "epoch: 139  batch: 32  loss: 0.09580216\n",
      "epoch: 139  batch: 33  loss: 0.08052251\n",
      "epoch: 139  batch: 34  loss: 0.11307957\n",
      "epoch: 139  batch: 35  loss: 0.08885083\n",
      "epoch: 139  batch: 36  loss: 0.10153641\n",
      "epoch: 139  batch: 37  loss: 0.07371559\n",
      "epoch: 139  batch: 38  loss: 0.06894244\n",
      "epoch: 139  batch: 39  loss: 0.10865641\n",
      "epoch: 139  batch: 40  loss: 0.09203552\n",
      "epoch: 139  batch: 41  loss: 0.05232079\n",
      "epoch: 139  batch: 42  loss: 0.08081878\n",
      "epoch: 139  batch: 43  loss: 0.08878689\n",
      "epoch: 139  batch: 44  loss: 0.09312876\n",
      "epoch: 139  batch: 45  loss: 0.11503996\n",
      "epoch: 139  batch: 46  loss: 0.07709888\n",
      "epoch: 139  batch: 47  loss: 0.06943187\n",
      "epoch: 139  batch: 48  loss: 0.12279726\n",
      "epoch: 139  batch: 49  loss: 0.08255567\n",
      "epoch: 139  batch: 50  loss: 0.05664513\n",
      "epoch: 139  batch: 51  loss: 0.10203203\n",
      "epoch: 139  batch: 52  loss: 0.11073244\n",
      "epoch: 139  batch: 53  loss: 0.07393537\n",
      "epoch: 139  batch: 54  loss: 0.09149569\n",
      "epoch: 139  batch: 55  loss: 0.09873229\n",
      "epoch: 139  batch: 56  loss: 0.07687281\n",
      "epoch: 139  batch: 57  loss: 0.09579096\n",
      "epoch: 139  batch: 58  loss: 0.08495047\n",
      "epoch: 139  batch: 59  loss: 0.05585992\n",
      "epoch: 139  batch: 60  loss: 0.07823892\n",
      "epoch: 139  batch: 61  loss: 0.08602566\n",
      "epoch: 139  batch: 62  loss: 0.05617546\n",
      "epoch: 139  batch: 63  loss: 0.10140154\n",
      "epoch: 139  batch: 64  loss: 0.07658417\n",
      "epoch: 139  batch: 65  loss: 0.10708005\n",
      "epoch: 139  batch: 66  loss: 0.07057904\n",
      "epoch: 139  batch: 67  loss: 0.07654145\n",
      "epoch: 139  batch: 68  loss: 0.09898726\n",
      "epoch: 139  batch: 69  loss: 0.09194873\n",
      "epoch: 139  batch: 70  loss: 0.07311728\n",
      "epoch: 139  batch: 71  loss: 0.07855072\n",
      "epoch: 139  batch: 72  loss: 0.09938858\n",
      "epoch: 139  batch: 73  loss: 0.10877602\n",
      "epoch: 139  batch: 74  loss: 0.09733498\n",
      "epoch: 139  batch: 75  loss: 0.11602148\n",
      "epoch: 139  batch: 76  loss: 0.08365633\n",
      "epoch: 139  batch: 77  loss: 0.12655136\n",
      "epoch: 139  batch: 78  loss: 0.06893186\n",
      "epoch: 139  batch: 79  loss: 0.06648938\n",
      "epoch: 139  batch: 80  loss: 0.04921104\n",
      "epoch: 139  batch: 81  loss: 0.09465512\n",
      "epoch: 139  batch: 82  loss: 0.07847564\n",
      "epoch: 139  batch: 83  loss: 0.08058170\n",
      "epoch: 139  batch: 84  loss: 0.08162239\n",
      "epoch: 139  batch: 85  loss: 0.04821458\n",
      "epoch: 139  batch: 86  loss: 0.05602902\n",
      "epoch: 139  batch: 87  loss: 0.09969600\n",
      "epoch: 140  batch: 1  loss: 0.07393526\n",
      "epoch: 140  batch: 2  loss: 0.10505142\n",
      "epoch: 140  batch: 3  loss: 0.08031826\n",
      "epoch: 140  batch: 4  loss: 0.07232489\n",
      "epoch: 140  batch: 5  loss: 0.05704385\n",
      "epoch: 140  batch: 6  loss: 0.11584473\n",
      "epoch: 140  batch: 7  loss: 0.08772296\n",
      "epoch: 140  batch: 8  loss: 0.06858978\n",
      "epoch: 140  batch: 9  loss: 0.05548570\n",
      "epoch: 140  batch: 10  loss: 0.10501902\n",
      "epoch: 140  batch: 11  loss: 0.07647178\n",
      "epoch: 140  batch: 12  loss: 0.08995236\n",
      "epoch: 140  batch: 13  loss: 0.08350160\n",
      "epoch: 140  batch: 14  loss: 0.07111268\n",
      "epoch: 140  batch: 15  loss: 0.05963987\n",
      "epoch: 140  batch: 16  loss: 0.07043518\n",
      "epoch: 140  batch: 17  loss: 0.06127190\n",
      "epoch: 140  batch: 18  loss: 0.09446097\n",
      "epoch: 140  batch: 19  loss: 0.04813560\n",
      "epoch: 140  batch: 20  loss: 0.05998058\n",
      "epoch: 140  batch: 21  loss: 0.09101417\n",
      "epoch: 140  batch: 22  loss: 0.16428035\n",
      "epoch: 140  batch: 23  loss: 0.09118751\n",
      "epoch: 140  batch: 24  loss: 0.10514539\n",
      "epoch: 140  batch: 25  loss: 0.08107362\n",
      "epoch: 140  batch: 26  loss: 0.06579442\n",
      "epoch: 140  batch: 27  loss: 0.05901102\n",
      "epoch: 140  batch: 28  loss: 0.14775614\n",
      "epoch: 140  batch: 29  loss: 0.07133427\n",
      "epoch: 140  batch: 30  loss: 0.06488041\n",
      "epoch: 140  batch: 31  loss: 0.13508835\n",
      "epoch: 140  batch: 32  loss: 0.06022646\n",
      "epoch: 140  batch: 33  loss: 0.06861037\n",
      "epoch: 140  batch: 34  loss: 0.07891422\n",
      "epoch: 140  batch: 35  loss: 0.13126056\n",
      "epoch: 140  batch: 36  loss: 0.08883277\n",
      "epoch: 140  batch: 37  loss: 0.08428583\n",
      "epoch: 140  batch: 38  loss: 0.09172337\n",
      "epoch: 140  batch: 39  loss: 0.08874241\n",
      "epoch: 140  batch: 40  loss: 0.06542700\n",
      "epoch: 140  batch: 41  loss: 0.06178710\n",
      "epoch: 140  batch: 42  loss: 0.06709950\n",
      "epoch: 140  batch: 43  loss: 0.06373312\n",
      "epoch: 140  batch: 44  loss: 0.10430102\n",
      "epoch: 140  batch: 45  loss: 0.08539025\n",
      "epoch: 140  batch: 46  loss: 0.06601337\n",
      "epoch: 140  batch: 47  loss: 0.06284070\n",
      "epoch: 140  batch: 48  loss: 0.07076692\n",
      "epoch: 140  batch: 49  loss: 0.08086339\n",
      "epoch: 140  batch: 50  loss: 0.08772355\n",
      "epoch: 140  batch: 51  loss: 0.06694950\n",
      "epoch: 140  batch: 52  loss: 0.06366717\n",
      "epoch: 140  batch: 53  loss: 0.08228793\n",
      "epoch: 140  batch: 54  loss: 0.07522720\n",
      "epoch: 140  batch: 55  loss: 0.10933943\n",
      "epoch: 140  batch: 56  loss: 0.08353703\n",
      "epoch: 140  batch: 57  loss: 0.07139750\n",
      "epoch: 140  batch: 58  loss: 0.07961420\n",
      "epoch: 140  batch: 59  loss: 0.05258334\n",
      "epoch: 140  batch: 60  loss: 0.07434337\n",
      "epoch: 140  batch: 61  loss: 0.07453050\n",
      "epoch: 140  batch: 62  loss: 0.08115400\n",
      "epoch: 140  batch: 63  loss: 0.10421605\n",
      "epoch: 140  batch: 64  loss: 0.08069101\n",
      "epoch: 140  batch: 65  loss: 0.10398234\n",
      "epoch: 140  batch: 66  loss: 0.08381062\n",
      "epoch: 140  batch: 67  loss: 0.12172239\n",
      "epoch: 140  batch: 68  loss: 0.06398741\n",
      "epoch: 140  batch: 69  loss: 0.10728338\n",
      "epoch: 140  batch: 70  loss: 0.05078826\n",
      "epoch: 140  batch: 71  loss: 0.07053577\n",
      "epoch: 140  batch: 72  loss: 0.07414882\n",
      "epoch: 140  batch: 73  loss: 0.11031867\n",
      "epoch: 140  batch: 74  loss: 0.15382011\n",
      "epoch: 140  batch: 75  loss: 0.08574386\n",
      "epoch: 140  batch: 76  loss: 0.09056179\n",
      "epoch: 140  batch: 77  loss: 0.06528101\n",
      "epoch: 140  batch: 78  loss: 0.06399487\n",
      "epoch: 140  batch: 79  loss: 0.08125842\n",
      "epoch: 140  batch: 80  loss: 0.07002098\n",
      "epoch: 140  batch: 81  loss: 0.08991504\n",
      "epoch: 140  batch: 82  loss: 0.09307574\n",
      "epoch: 140  batch: 83  loss: 0.06723164\n",
      "epoch: 140  batch: 84  loss: 0.06103798\n",
      "epoch: 140  batch: 85  loss: 0.10372029\n",
      "epoch: 140  batch: 86  loss: 0.07787024\n",
      "epoch: 140  batch: 87  loss: 0.07774835\n",
      "epoch: 141  batch: 1  loss: 0.06197711\n",
      "epoch: 141  batch: 2  loss: 0.06156458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141  batch: 3  loss: 0.05357453\n",
      "epoch: 141  batch: 4  loss: 0.07945877\n",
      "epoch: 141  batch: 5  loss: 0.06289098\n",
      "epoch: 141  batch: 6  loss: 0.08964821\n",
      "epoch: 141  batch: 7  loss: 0.07885917\n",
      "epoch: 141  batch: 8  loss: 0.06077536\n",
      "epoch: 141  batch: 9  loss: 0.08026933\n",
      "epoch: 141  batch: 10  loss: 0.05746641\n",
      "epoch: 141  batch: 11  loss: 0.06701986\n",
      "epoch: 141  batch: 12  loss: 0.07527016\n",
      "epoch: 141  batch: 13  loss: 0.08466171\n",
      "epoch: 141  batch: 14  loss: 0.06170746\n",
      "epoch: 141  batch: 15  loss: 0.09518927\n",
      "epoch: 141  batch: 16  loss: 0.11441822\n",
      "epoch: 141  batch: 17  loss: 0.05434658\n",
      "epoch: 141  batch: 18  loss: 0.10865843\n",
      "epoch: 141  batch: 19  loss: 0.06789038\n",
      "epoch: 141  batch: 20  loss: 0.09237265\n",
      "epoch: 141  batch: 21  loss: 0.08339768\n",
      "epoch: 141  batch: 22  loss: 0.08996646\n",
      "epoch: 141  batch: 23  loss: 0.10100295\n",
      "epoch: 141  batch: 24  loss: 0.07923443\n",
      "epoch: 141  batch: 25  loss: 0.05642070\n",
      "epoch: 141  batch: 26  loss: 0.05982754\n",
      "epoch: 141  batch: 27  loss: 0.07536000\n",
      "epoch: 141  batch: 28  loss: 0.10474978\n",
      "epoch: 141  batch: 29  loss: 0.06705716\n",
      "epoch: 141  batch: 30  loss: 0.07693882\n",
      "epoch: 141  batch: 31  loss: 0.10671805\n",
      "epoch: 141  batch: 32  loss: 0.06192927\n",
      "epoch: 141  batch: 33  loss: 0.07506396\n",
      "epoch: 141  batch: 34  loss: 0.07135317\n",
      "epoch: 141  batch: 35  loss: 0.07666656\n",
      "epoch: 141  batch: 36  loss: 0.07672913\n",
      "epoch: 141  batch: 37  loss: 0.09293795\n",
      "epoch: 141  batch: 38  loss: 0.09309012\n",
      "epoch: 141  batch: 39  loss: 0.08337514\n",
      "epoch: 141  batch: 40  loss: 0.11055367\n",
      "epoch: 141  batch: 41  loss: 0.06624881\n",
      "epoch: 141  batch: 42  loss: 0.06931473\n",
      "epoch: 141  batch: 43  loss: 0.07872439\n",
      "epoch: 141  batch: 44  loss: 0.09207400\n",
      "epoch: 141  batch: 45  loss: 0.05439126\n",
      "epoch: 141  batch: 46  loss: 0.06445161\n",
      "epoch: 141  batch: 47  loss: 0.08700183\n",
      "epoch: 141  batch: 48  loss: 0.06046775\n",
      "epoch: 141  batch: 49  loss: 0.06964070\n",
      "epoch: 141  batch: 50  loss: 0.05914557\n",
      "epoch: 141  batch: 51  loss: 0.09750716\n",
      "epoch: 141  batch: 52  loss: 0.06876051\n",
      "epoch: 141  batch: 53  loss: 0.06349890\n",
      "epoch: 141  batch: 54  loss: 0.07198502\n",
      "epoch: 141  batch: 55  loss: 0.06609217\n",
      "epoch: 141  batch: 56  loss: 0.09341766\n",
      "epoch: 141  batch: 57  loss: 0.08359975\n",
      "epoch: 141  batch: 58  loss: 0.09576945\n",
      "epoch: 141  batch: 59  loss: 0.07451678\n",
      "epoch: 141  batch: 60  loss: 0.08036069\n",
      "epoch: 141  batch: 61  loss: 0.07105808\n",
      "epoch: 141  batch: 62  loss: 0.10539570\n",
      "epoch: 141  batch: 63  loss: 0.05545625\n",
      "epoch: 141  batch: 64  loss: 0.11454050\n",
      "epoch: 141  batch: 65  loss: 0.08617473\n",
      "epoch: 141  batch: 66  loss: 0.09183527\n",
      "epoch: 141  batch: 67  loss: 0.09416635\n",
      "epoch: 141  batch: 68  loss: 0.08350226\n",
      "epoch: 141  batch: 69  loss: 0.07939339\n",
      "epoch: 141  batch: 70  loss: 0.06817239\n",
      "epoch: 141  batch: 71  loss: 0.09622667\n",
      "epoch: 141  batch: 72  loss: 0.08186659\n",
      "epoch: 141  batch: 73  loss: 0.11612720\n",
      "epoch: 141  batch: 74  loss: 0.07536922\n",
      "epoch: 141  batch: 75  loss: 0.08870190\n",
      "epoch: 141  batch: 76  loss: 0.05899672\n",
      "epoch: 141  batch: 77  loss: 0.08302124\n",
      "epoch: 141  batch: 78  loss: 0.07918814\n",
      "epoch: 141  batch: 79  loss: 0.12497873\n",
      "epoch: 141  batch: 80  loss: 0.09187952\n",
      "epoch: 141  batch: 81  loss: 0.11604788\n",
      "epoch: 141  batch: 82  loss: 0.07201287\n",
      "epoch: 141  batch: 83  loss: 0.09519930\n",
      "epoch: 141  batch: 84  loss: 0.07619958\n",
      "epoch: 141  batch: 85  loss: 0.10258307\n",
      "epoch: 141  batch: 86  loss: 0.08176100\n",
      "epoch: 141  batch: 87  loss: 0.09799211\n",
      "epoch: 142  batch: 1  loss: 0.08111004\n",
      "epoch: 142  batch: 2  loss: 0.09339587\n",
      "epoch: 142  batch: 3  loss: 0.10770175\n",
      "epoch: 142  batch: 4  loss: 0.06796914\n",
      "epoch: 142  batch: 5  loss: 0.11125181\n",
      "epoch: 142  batch: 6  loss: 0.08131035\n",
      "epoch: 142  batch: 7  loss: 0.10033087\n",
      "epoch: 142  batch: 8  loss: 0.08252949\n",
      "epoch: 142  batch: 9  loss: 0.07457770\n",
      "epoch: 142  batch: 10  loss: 0.11184696\n",
      "epoch: 142  batch: 11  loss: 0.06765728\n",
      "epoch: 142  batch: 12  loss: 0.07082171\n",
      "epoch: 142  batch: 13  loss: 0.07122799\n",
      "epoch: 142  batch: 14  loss: 0.07445448\n",
      "epoch: 142  batch: 15  loss: 0.06559296\n",
      "epoch: 142  batch: 16  loss: 0.08049373\n",
      "epoch: 142  batch: 17  loss: 0.07839598\n",
      "epoch: 142  batch: 18  loss: 0.07629444\n",
      "epoch: 142  batch: 19  loss: 0.07693878\n",
      "epoch: 142  batch: 20  loss: 0.07849848\n",
      "epoch: 142  batch: 21  loss: 0.10578874\n",
      "epoch: 142  batch: 22  loss: 0.06676149\n",
      "epoch: 142  batch: 23  loss: 0.12596408\n",
      "epoch: 142  batch: 24  loss: 0.06268007\n",
      "epoch: 142  batch: 25  loss: 0.11122325\n",
      "epoch: 142  batch: 26  loss: 0.06188766\n",
      "epoch: 142  batch: 27  loss: 0.11518756\n",
      "epoch: 142  batch: 28  loss: 0.07879116\n",
      "epoch: 142  batch: 29  loss: 0.07532818\n",
      "epoch: 142  batch: 30  loss: 0.10197283\n",
      "epoch: 142  batch: 31  loss: 0.07604425\n",
      "epoch: 142  batch: 32  loss: 0.05926696\n",
      "epoch: 142  batch: 33  loss: 0.10794219\n",
      "epoch: 142  batch: 34  loss: 0.04817041\n",
      "epoch: 142  batch: 35  loss: 0.06977423\n",
      "epoch: 142  batch: 36  loss: 0.09389302\n",
      "epoch: 142  batch: 37  loss: 0.09801406\n",
      "epoch: 142  batch: 38  loss: 0.11763404\n",
      "epoch: 142  batch: 39  loss: 0.07112221\n",
      "epoch: 142  batch: 40  loss: 0.05820761\n",
      "epoch: 142  batch: 41  loss: 0.07463068\n",
      "epoch: 142  batch: 42  loss: 0.08114118\n",
      "epoch: 142  batch: 43  loss: 0.09843665\n",
      "epoch: 142  batch: 44  loss: 0.08176713\n",
      "epoch: 142  batch: 45  loss: 0.05341481\n",
      "epoch: 142  batch: 46  loss: 0.08030245\n",
      "epoch: 142  batch: 47  loss: 0.07944686\n",
      "epoch: 142  batch: 48  loss: 0.07268919\n",
      "epoch: 142  batch: 49  loss: 0.07573847\n",
      "epoch: 142  batch: 50  loss: 0.05206442\n",
      "epoch: 142  batch: 51  loss: 0.07287781\n",
      "epoch: 142  batch: 52  loss: 0.17143069\n",
      "epoch: 142  batch: 53  loss: 0.06252685\n",
      "epoch: 142  batch: 54  loss: 0.07742732\n",
      "epoch: 142  batch: 55  loss: 0.07051715\n",
      "epoch: 142  batch: 56  loss: 0.12419154\n",
      "epoch: 142  batch: 57  loss: 0.05539979\n",
      "epoch: 142  batch: 58  loss: 0.11322402\n",
      "epoch: 142  batch: 59  loss: 0.11160920\n",
      "epoch: 142  batch: 60  loss: 0.10340439\n",
      "epoch: 142  batch: 61  loss: 0.07747358\n",
      "epoch: 142  batch: 62  loss: 0.05523656\n",
      "epoch: 142  batch: 63  loss: 0.06037786\n",
      "epoch: 142  batch: 64  loss: 0.07558881\n",
      "epoch: 142  batch: 65  loss: 0.08505518\n",
      "epoch: 142  batch: 66  loss: 0.07252342\n",
      "epoch: 142  batch: 67  loss: 0.10044685\n",
      "epoch: 142  batch: 68  loss: 0.06647513\n",
      "epoch: 142  batch: 69  loss: 0.07940458\n",
      "epoch: 142  batch: 70  loss: 0.07755860\n",
      "epoch: 142  batch: 71  loss: 0.04685290\n",
      "epoch: 142  batch: 72  loss: 0.07104071\n",
      "epoch: 142  batch: 73  loss: 0.07779346\n",
      "epoch: 142  batch: 74  loss: 0.07991342\n",
      "epoch: 142  batch: 75  loss: 0.08863391\n",
      "epoch: 142  batch: 76  loss: 0.08435242\n",
      "epoch: 142  batch: 77  loss: 0.08534671\n",
      "epoch: 142  batch: 78  loss: 0.07956801\n",
      "epoch: 142  batch: 79  loss: 0.05893125\n",
      "epoch: 142  batch: 80  loss: 0.11222929\n",
      "epoch: 142  batch: 81  loss: 0.08601129\n",
      "epoch: 142  batch: 82  loss: 0.10582621\n",
      "epoch: 142  batch: 83  loss: 0.09584180\n",
      "epoch: 142  batch: 84  loss: 0.11633956\n",
      "epoch: 142  batch: 85  loss: 0.08096363\n",
      "epoch: 142  batch: 86  loss: 0.05965355\n",
      "epoch: 142  batch: 87  loss: 0.05956395\n",
      "epoch: 143  batch: 1  loss: 0.06400170\n",
      "epoch: 143  batch: 2  loss: 0.05706348\n",
      "epoch: 143  batch: 3  loss: 0.08986554\n",
      "epoch: 143  batch: 4  loss: 0.08053368\n",
      "epoch: 143  batch: 5  loss: 0.04260496\n",
      "epoch: 143  batch: 6  loss: 0.06115262\n",
      "epoch: 143  batch: 7  loss: 0.11078978\n",
      "epoch: 143  batch: 8  loss: 0.06992590\n",
      "epoch: 143  batch: 9  loss: 0.08671728\n",
      "epoch: 143  batch: 10  loss: 0.06154186\n",
      "epoch: 143  batch: 11  loss: 0.05610122\n",
      "epoch: 143  batch: 12  loss: 0.10085326\n",
      "epoch: 143  batch: 13  loss: 0.12531197\n",
      "epoch: 143  batch: 14  loss: 0.07806294\n",
      "epoch: 143  batch: 15  loss: 0.07599653\n",
      "epoch: 143  batch: 16  loss: 0.08603026\n",
      "epoch: 143  batch: 17  loss: 0.06679264\n",
      "epoch: 143  batch: 18  loss: 0.07464270\n",
      "epoch: 143  batch: 19  loss: 0.05959843\n",
      "epoch: 143  batch: 20  loss: 0.08760292\n",
      "epoch: 143  batch: 21  loss: 0.07534199\n",
      "epoch: 143  batch: 22  loss: 0.09156560\n",
      "epoch: 143  batch: 23  loss: 0.08074125\n",
      "epoch: 143  batch: 24  loss: 0.05773532\n",
      "epoch: 143  batch: 25  loss: 0.07091631\n",
      "epoch: 143  batch: 26  loss: 0.08591606\n",
      "epoch: 143  batch: 27  loss: 0.08351544\n",
      "epoch: 143  batch: 28  loss: 0.09941050\n",
      "epoch: 143  batch: 29  loss: 0.06776888\n",
      "epoch: 143  batch: 30  loss: 0.12939768\n",
      "epoch: 143  batch: 31  loss: 0.10376015\n",
      "epoch: 143  batch: 32  loss: 0.05226966\n",
      "epoch: 143  batch: 33  loss: 0.07083758\n",
      "epoch: 143  batch: 34  loss: 0.07384456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143  batch: 35  loss: 0.10776497\n",
      "epoch: 143  batch: 36  loss: 0.08260675\n",
      "epoch: 143  batch: 37  loss: 0.07770289\n",
      "epoch: 143  batch: 38  loss: 0.08524362\n",
      "epoch: 143  batch: 39  loss: 0.10639249\n",
      "epoch: 143  batch: 40  loss: 0.07501084\n",
      "epoch: 143  batch: 41  loss: 0.08272208\n",
      "epoch: 143  batch: 42  loss: 0.08969716\n",
      "epoch: 143  batch: 43  loss: 0.09183495\n",
      "epoch: 143  batch: 44  loss: 0.06350338\n",
      "epoch: 143  batch: 45  loss: 0.09089896\n",
      "epoch: 143  batch: 46  loss: 0.11076073\n",
      "epoch: 143  batch: 47  loss: 0.06042471\n",
      "epoch: 143  batch: 48  loss: 0.11703210\n",
      "epoch: 143  batch: 49  loss: 0.07281522\n",
      "epoch: 143  batch: 50  loss: 0.08050495\n",
      "epoch: 143  batch: 51  loss: 0.06225877\n",
      "epoch: 143  batch: 52  loss: 0.11734992\n",
      "epoch: 143  batch: 53  loss: 0.08995348\n",
      "epoch: 143  batch: 54  loss: 0.07181188\n",
      "epoch: 143  batch: 55  loss: 0.09208607\n",
      "epoch: 143  batch: 56  loss: 0.07944020\n",
      "epoch: 143  batch: 57  loss: 0.07515532\n",
      "epoch: 143  batch: 58  loss: 0.10019381\n",
      "epoch: 143  batch: 59  loss: 0.08217488\n",
      "epoch: 143  batch: 60  loss: 0.10710557\n",
      "epoch: 143  batch: 61  loss: 0.06955537\n",
      "epoch: 143  batch: 62  loss: 0.06110404\n",
      "epoch: 143  batch: 63  loss: 0.07378464\n",
      "epoch: 143  batch: 64  loss: 0.05624332\n",
      "epoch: 143  batch: 65  loss: 0.08650536\n",
      "epoch: 143  batch: 66  loss: 0.06604870\n",
      "epoch: 143  batch: 67  loss: 0.07575749\n",
      "epoch: 143  batch: 68  loss: 0.15967387\n",
      "epoch: 143  batch: 69  loss: 0.13876139\n",
      "epoch: 143  batch: 70  loss: 0.05426563\n",
      "epoch: 143  batch: 71  loss: 0.08908447\n",
      "epoch: 143  batch: 72  loss: 0.09500487\n",
      "epoch: 143  batch: 73  loss: 0.10102396\n",
      "epoch: 143  batch: 74  loss: 0.10025211\n",
      "epoch: 143  batch: 75  loss: 0.07267099\n",
      "epoch: 143  batch: 76  loss: 0.05756623\n",
      "epoch: 143  batch: 77  loss: 0.05332670\n",
      "epoch: 143  batch: 78  loss: 0.08333749\n",
      "epoch: 143  batch: 79  loss: 0.08358745\n",
      "epoch: 143  batch: 80  loss: 0.05844690\n",
      "epoch: 143  batch: 81  loss: 0.09333804\n",
      "epoch: 143  batch: 82  loss: 0.07985739\n",
      "epoch: 143  batch: 83  loss: 0.06611224\n",
      "epoch: 143  batch: 84  loss: 0.09129579\n",
      "epoch: 143  batch: 85  loss: 0.05920047\n",
      "epoch: 143  batch: 86  loss: 0.07921600\n",
      "epoch: 143  batch: 87  loss: 0.10042960\n",
      "epoch: 144  batch: 1  loss: 0.07438558\n",
      "epoch: 144  batch: 2  loss: 0.06190168\n",
      "epoch: 144  batch: 3  loss: 0.08953185\n",
      "epoch: 144  batch: 4  loss: 0.07300153\n",
      "epoch: 144  batch: 5  loss: 0.09312584\n",
      "epoch: 144  batch: 6  loss: 0.07180228\n",
      "epoch: 144  batch: 7  loss: 0.07804351\n",
      "epoch: 144  batch: 8  loss: 0.07525664\n",
      "epoch: 144  batch: 9  loss: 0.08684357\n",
      "epoch: 144  batch: 10  loss: 0.09048180\n",
      "epoch: 144  batch: 11  loss: 0.13019122\n",
      "epoch: 144  batch: 12  loss: 0.08059245\n",
      "epoch: 144  batch: 13  loss: 0.12543650\n",
      "epoch: 144  batch: 14  loss: 0.06057249\n",
      "epoch: 144  batch: 15  loss: 0.09405834\n",
      "epoch: 144  batch: 16  loss: 0.08840463\n",
      "epoch: 144  batch: 17  loss: 0.10375088\n",
      "epoch: 144  batch: 18  loss: 0.10796792\n",
      "epoch: 144  batch: 19  loss: 0.09840298\n",
      "epoch: 144  batch: 20  loss: 0.08544526\n",
      "epoch: 144  batch: 21  loss: 0.08483569\n",
      "epoch: 144  batch: 22  loss: 0.07356148\n",
      "epoch: 144  batch: 23  loss: 0.07811490\n",
      "epoch: 144  batch: 24  loss: 0.09571979\n",
      "epoch: 144  batch: 25  loss: 0.07824763\n",
      "epoch: 144  batch: 26  loss: 0.10427586\n",
      "epoch: 144  batch: 27  loss: 0.10385708\n",
      "epoch: 144  batch: 28  loss: 0.04689959\n",
      "epoch: 144  batch: 29  loss: 0.08902603\n",
      "epoch: 144  batch: 30  loss: 0.09306913\n",
      "epoch: 144  batch: 31  loss: 0.13282168\n",
      "epoch: 144  batch: 32  loss: 0.07717724\n",
      "epoch: 144  batch: 33  loss: 0.08087283\n",
      "epoch: 144  batch: 34  loss: 0.06570248\n",
      "epoch: 144  batch: 35  loss: 0.09128992\n",
      "epoch: 144  batch: 36  loss: 0.07853206\n",
      "epoch: 144  batch: 37  loss: 0.06952386\n",
      "epoch: 144  batch: 38  loss: 0.06006499\n",
      "epoch: 144  batch: 39  loss: 0.05975617\n",
      "epoch: 144  batch: 40  loss: 0.08614576\n",
      "epoch: 144  batch: 41  loss: 0.08870276\n",
      "epoch: 144  batch: 42  loss: 0.08032231\n",
      "epoch: 144  batch: 43  loss: 0.06708895\n",
      "epoch: 144  batch: 44  loss: 0.08159515\n",
      "epoch: 144  batch: 45  loss: 0.05750037\n",
      "epoch: 144  batch: 46  loss: 0.07133701\n",
      "epoch: 144  batch: 47  loss: 0.07039960\n",
      "epoch: 144  batch: 48  loss: 0.07954196\n",
      "epoch: 144  batch: 49  loss: 0.09576387\n",
      "epoch: 144  batch: 50  loss: 0.07331427\n",
      "epoch: 144  batch: 51  loss: 0.07866254\n",
      "epoch: 144  batch: 52  loss: 0.07316393\n",
      "epoch: 144  batch: 53  loss: 0.07597987\n",
      "epoch: 144  batch: 54  loss: 0.09494887\n",
      "epoch: 144  batch: 55  loss: 0.08524437\n",
      "epoch: 144  batch: 56  loss: 0.10970879\n",
      "epoch: 144  batch: 57  loss: 0.08083182\n",
      "epoch: 144  batch: 58  loss: 0.07970441\n",
      "epoch: 144  batch: 59  loss: 0.07459718\n",
      "epoch: 144  batch: 60  loss: 0.06494543\n",
      "epoch: 144  batch: 61  loss: 0.08109279\n",
      "epoch: 144  batch: 62  loss: 0.10003839\n",
      "epoch: 144  batch: 63  loss: 0.08880713\n",
      "epoch: 144  batch: 64  loss: 0.09008366\n",
      "epoch: 144  batch: 65  loss: 0.06446695\n",
      "epoch: 144  batch: 66  loss: 0.12674594\n",
      "epoch: 144  batch: 67  loss: 0.08315589\n",
      "epoch: 144  batch: 68  loss: 0.11329626\n",
      "epoch: 144  batch: 69  loss: 0.07570758\n",
      "epoch: 144  batch: 70  loss: 0.07404654\n",
      "epoch: 144  batch: 71  loss: 0.07122593\n",
      "epoch: 144  batch: 72  loss: 0.05445975\n",
      "epoch: 144  batch: 73  loss: 0.06101708\n",
      "epoch: 144  batch: 74  loss: 0.06416976\n",
      "epoch: 144  batch: 75  loss: 0.10995536\n",
      "epoch: 144  batch: 76  loss: 0.10396787\n",
      "epoch: 144  batch: 77  loss: 0.12557383\n",
      "epoch: 144  batch: 78  loss: 0.08735468\n",
      "epoch: 144  batch: 79  loss: 0.06505691\n",
      "epoch: 144  batch: 80  loss: 0.06867446\n",
      "epoch: 144  batch: 81  loss: 0.10855599\n",
      "epoch: 144  batch: 82  loss: 0.08248660\n",
      "epoch: 144  batch: 83  loss: 0.06024160\n",
      "epoch: 144  batch: 84  loss: 0.06200793\n",
      "epoch: 144  batch: 85  loss: 0.09894662\n",
      "epoch: 144  batch: 86  loss: 0.09777149\n",
      "epoch: 144  batch: 87  loss: 0.07486537\n",
      "epoch: 145  batch: 1  loss: 0.06260999\n",
      "epoch: 145  batch: 2  loss: 0.06088677\n",
      "epoch: 145  batch: 3  loss: 0.09506363\n",
      "epoch: 145  batch: 4  loss: 0.07708165\n",
      "epoch: 145  batch: 5  loss: 0.05728063\n",
      "epoch: 145  batch: 6  loss: 0.09000657\n",
      "epoch: 145  batch: 7  loss: 0.09013098\n",
      "epoch: 145  batch: 8  loss: 0.06735134\n",
      "epoch: 145  batch: 9  loss: 0.11507318\n",
      "epoch: 145  batch: 10  loss: 0.06958397\n",
      "epoch: 145  batch: 11  loss: 0.07704180\n",
      "epoch: 145  batch: 12  loss: 0.12263341\n",
      "epoch: 145  batch: 13  loss: 0.08098841\n",
      "epoch: 145  batch: 14  loss: 0.06106290\n",
      "epoch: 145  batch: 15  loss: 0.10366243\n",
      "epoch: 145  batch: 16  loss: 0.06407815\n",
      "epoch: 145  batch: 17  loss: 0.05377930\n",
      "epoch: 145  batch: 18  loss: 0.06146332\n",
      "epoch: 145  batch: 19  loss: 0.08381275\n",
      "epoch: 145  batch: 20  loss: 0.06349392\n",
      "epoch: 145  batch: 21  loss: 0.09272210\n",
      "epoch: 145  batch: 22  loss: 0.08850027\n",
      "epoch: 145  batch: 23  loss: 0.12915464\n",
      "epoch: 145  batch: 24  loss: 0.10163435\n",
      "epoch: 145  batch: 25  loss: 0.08913476\n",
      "epoch: 145  batch: 26  loss: 0.07628264\n",
      "epoch: 145  batch: 27  loss: 0.10035583\n",
      "epoch: 145  batch: 28  loss: 0.08183755\n",
      "epoch: 145  batch: 29  loss: 0.07131461\n",
      "epoch: 145  batch: 30  loss: 0.07609494\n",
      "epoch: 145  batch: 31  loss: 0.07042483\n",
      "epoch: 145  batch: 32  loss: 0.07163631\n",
      "epoch: 145  batch: 33  loss: 0.10487772\n",
      "epoch: 145  batch: 34  loss: 0.06626435\n",
      "epoch: 145  batch: 35  loss: 0.07287952\n",
      "epoch: 145  batch: 36  loss: 0.09434188\n",
      "epoch: 145  batch: 37  loss: 0.07503934\n",
      "epoch: 145  batch: 38  loss: 0.08066974\n",
      "epoch: 145  batch: 39  loss: 0.06854542\n",
      "epoch: 145  batch: 40  loss: 0.06859936\n",
      "epoch: 145  batch: 41  loss: 0.09215242\n",
      "epoch: 145  batch: 42  loss: 0.13214375\n",
      "epoch: 145  batch: 43  loss: 0.07188382\n",
      "epoch: 145  batch: 44  loss: 0.09263263\n",
      "epoch: 145  batch: 45  loss: 0.07982566\n",
      "epoch: 145  batch: 46  loss: 0.06220249\n",
      "epoch: 145  batch: 47  loss: 0.07195740\n",
      "epoch: 145  batch: 48  loss: 0.13580358\n",
      "epoch: 145  batch: 49  loss: 0.05092246\n",
      "epoch: 145  batch: 50  loss: 0.08295216\n",
      "epoch: 145  batch: 51  loss: 0.10492717\n",
      "epoch: 145  batch: 52  loss: 0.09275640\n",
      "epoch: 145  batch: 53  loss: 0.08900082\n",
      "epoch: 145  batch: 54  loss: 0.08884988\n",
      "epoch: 145  batch: 55  loss: 0.12129714\n",
      "epoch: 145  batch: 56  loss: 0.07276612\n",
      "epoch: 145  batch: 57  loss: 0.10580108\n",
      "epoch: 145  batch: 58  loss: 0.07278338\n",
      "epoch: 145  batch: 59  loss: 0.07685660\n",
      "epoch: 145  batch: 60  loss: 0.09620532\n",
      "epoch: 145  batch: 61  loss: 0.11562251\n",
      "epoch: 145  batch: 62  loss: 0.05805470\n",
      "epoch: 145  batch: 63  loss: 0.09267683\n",
      "epoch: 145  batch: 64  loss: 0.05898964\n",
      "epoch: 145  batch: 65  loss: 0.07674628\n",
      "epoch: 145  batch: 66  loss: 0.06403551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 145  batch: 67  loss: 0.06257775\n",
      "epoch: 145  batch: 68  loss: 0.07024419\n",
      "epoch: 145  batch: 69  loss: 0.07391485\n",
      "epoch: 145  batch: 70  loss: 0.06665705\n",
      "epoch: 145  batch: 71  loss: 0.06822864\n",
      "epoch: 145  batch: 72  loss: 0.07515552\n",
      "epoch: 145  batch: 73  loss: 0.11788327\n",
      "epoch: 145  batch: 74  loss: 0.06784781\n",
      "epoch: 145  batch: 75  loss: 0.08785196\n",
      "epoch: 145  batch: 76  loss: 0.05842494\n",
      "epoch: 145  batch: 77  loss: 0.06883287\n",
      "epoch: 145  batch: 78  loss: 0.08747455\n",
      "epoch: 145  batch: 79  loss: 0.06324643\n",
      "epoch: 145  batch: 80  loss: 0.05275986\n",
      "epoch: 145  batch: 81  loss: 0.06602415\n",
      "epoch: 145  batch: 82  loss: 0.10548384\n",
      "epoch: 145  batch: 83  loss: 0.09030909\n",
      "epoch: 145  batch: 84  loss: 0.07537594\n",
      "epoch: 145  batch: 85  loss: 0.07916717\n",
      "epoch: 145  batch: 86  loss: 0.06427213\n",
      "epoch: 145  batch: 87  loss: 0.10945382\n",
      "epoch: 146  batch: 1  loss: 0.09630353\n",
      "epoch: 146  batch: 2  loss: 0.07705808\n",
      "epoch: 146  batch: 3  loss: 0.12103192\n",
      "epoch: 146  batch: 4  loss: 0.06487991\n",
      "epoch: 146  batch: 5  loss: 0.07701205\n",
      "epoch: 146  batch: 6  loss: 0.05862644\n",
      "epoch: 146  batch: 7  loss: 0.12960277\n",
      "epoch: 146  batch: 8  loss: 0.06114878\n",
      "epoch: 146  batch: 9  loss: 0.08419796\n",
      "epoch: 146  batch: 10  loss: 0.07743715\n",
      "epoch: 146  batch: 11  loss: 0.09496555\n",
      "epoch: 146  batch: 12  loss: 0.06780831\n",
      "epoch: 146  batch: 13  loss: 0.07226913\n",
      "epoch: 146  batch: 14  loss: 0.07336159\n",
      "epoch: 146  batch: 15  loss: 0.05645886\n",
      "epoch: 146  batch: 16  loss: 0.07382159\n",
      "epoch: 146  batch: 17  loss: 0.07909650\n",
      "epoch: 146  batch: 18  loss: 0.08914085\n",
      "epoch: 146  batch: 19  loss: 0.09382509\n",
      "epoch: 146  batch: 20  loss: 0.10724335\n",
      "epoch: 146  batch: 21  loss: 0.09645092\n",
      "epoch: 146  batch: 22  loss: 0.05278145\n",
      "epoch: 146  batch: 23  loss: 0.07549887\n",
      "epoch: 146  batch: 24  loss: 0.06337740\n",
      "epoch: 146  batch: 25  loss: 0.06323465\n",
      "epoch: 146  batch: 26  loss: 0.06396137\n",
      "epoch: 146  batch: 27  loss: 0.08068449\n",
      "epoch: 146  batch: 28  loss: 0.07953314\n",
      "epoch: 146  batch: 29  loss: 0.09429356\n",
      "epoch: 146  batch: 30  loss: 0.08039384\n",
      "epoch: 146  batch: 31  loss: 0.08875290\n",
      "epoch: 146  batch: 32  loss: 0.08040659\n",
      "epoch: 146  batch: 33  loss: 0.06580833\n",
      "epoch: 146  batch: 34  loss: 0.07162588\n",
      "epoch: 146  batch: 35  loss: 0.10989843\n",
      "epoch: 146  batch: 36  loss: 0.06717978\n",
      "epoch: 146  batch: 37  loss: 0.07963137\n",
      "epoch: 146  batch: 38  loss: 0.07970195\n",
      "epoch: 146  batch: 39  loss: 0.06150342\n",
      "epoch: 146  batch: 40  loss: 0.06518286\n",
      "epoch: 146  batch: 41  loss: 0.07314761\n",
      "epoch: 146  batch: 42  loss: 0.09656787\n",
      "epoch: 146  batch: 43  loss: 0.09273801\n",
      "epoch: 146  batch: 44  loss: 0.08371155\n",
      "epoch: 146  batch: 45  loss: 0.07792391\n",
      "epoch: 146  batch: 46  loss: 0.11111230\n",
      "epoch: 146  batch: 47  loss: 0.08032311\n",
      "epoch: 146  batch: 48  loss: 0.06314658\n",
      "epoch: 146  batch: 49  loss: 0.07784563\n",
      "epoch: 146  batch: 50  loss: 0.07717887\n",
      "epoch: 146  batch: 51  loss: 0.06981503\n",
      "epoch: 146  batch: 52  loss: 0.07043073\n",
      "epoch: 146  batch: 53  loss: 0.08074410\n",
      "epoch: 146  batch: 54  loss: 0.07804291\n",
      "epoch: 146  batch: 55  loss: 0.06811627\n",
      "epoch: 146  batch: 56  loss: 0.07616519\n",
      "epoch: 146  batch: 57  loss: 0.08773806\n",
      "epoch: 146  batch: 58  loss: 0.09470385\n",
      "epoch: 146  batch: 59  loss: 0.06862807\n",
      "epoch: 146  batch: 60  loss: 0.06616589\n",
      "epoch: 146  batch: 61  loss: 0.08982984\n",
      "epoch: 146  batch: 62  loss: 0.08304439\n",
      "epoch: 146  batch: 63  loss: 0.09587142\n",
      "epoch: 146  batch: 64  loss: 0.07307474\n",
      "epoch: 146  batch: 65  loss: 0.19096549\n",
      "epoch: 146  batch: 66  loss: 0.09571157\n",
      "epoch: 146  batch: 67  loss: 0.09048753\n",
      "epoch: 146  batch: 68  loss: 0.08269165\n",
      "epoch: 146  batch: 69  loss: 0.07898482\n",
      "epoch: 146  batch: 70  loss: 0.06191965\n",
      "epoch: 146  batch: 71  loss: 0.08385245\n",
      "epoch: 146  batch: 72  loss: 0.09332604\n",
      "epoch: 146  batch: 73  loss: 0.12515955\n",
      "epoch: 146  batch: 74  loss: 0.06690664\n",
      "epoch: 146  batch: 75  loss: 0.08787280\n",
      "epoch: 146  batch: 76  loss: 0.06725020\n",
      "epoch: 146  batch: 77  loss: 0.05412110\n",
      "epoch: 146  batch: 78  loss: 0.09796035\n",
      "epoch: 146  batch: 79  loss: 0.07960841\n",
      "epoch: 146  batch: 80  loss: 0.10216921\n",
      "epoch: 146  batch: 81  loss: 0.11352610\n",
      "epoch: 146  batch: 82  loss: 0.08958449\n",
      "epoch: 146  batch: 83  loss: 0.08240729\n",
      "epoch: 146  batch: 84  loss: 0.04971059\n",
      "epoch: 146  batch: 85  loss: 0.07951753\n",
      "epoch: 146  batch: 86  loss: 0.07891463\n",
      "epoch: 146  batch: 87  loss: 0.11900312\n",
      "epoch: 147  batch: 1  loss: 0.07114598\n",
      "epoch: 147  batch: 2  loss: 0.11238054\n",
      "epoch: 147  batch: 3  loss: 0.08502395\n",
      "epoch: 147  batch: 4  loss: 0.08545974\n",
      "epoch: 147  batch: 5  loss: 0.08685450\n",
      "epoch: 147  batch: 6  loss: 0.11372884\n",
      "epoch: 147  batch: 7  loss: 0.06072960\n",
      "epoch: 147  batch: 8  loss: 0.06749744\n",
      "epoch: 147  batch: 9  loss: 0.07744745\n",
      "epoch: 147  batch: 10  loss: 0.08478020\n",
      "epoch: 147  batch: 11  loss: 0.08557734\n",
      "epoch: 147  batch: 12  loss: 0.06457128\n",
      "epoch: 147  batch: 13  loss: 0.07751176\n",
      "epoch: 147  batch: 14  loss: 0.11430433\n",
      "epoch: 147  batch: 15  loss: 0.09164920\n",
      "epoch: 147  batch: 16  loss: 0.08136833\n",
      "epoch: 147  batch: 17  loss: 0.07801753\n",
      "epoch: 147  batch: 18  loss: 0.12732992\n",
      "epoch: 147  batch: 19  loss: 0.11639082\n",
      "epoch: 147  batch: 20  loss: 0.09084525\n",
      "epoch: 147  batch: 21  loss: 0.10172550\n",
      "epoch: 147  batch: 22  loss: 0.10158708\n",
      "epoch: 147  batch: 23  loss: 0.07956443\n",
      "epoch: 147  batch: 24  loss: 0.09635132\n",
      "epoch: 147  batch: 25  loss: 0.07021906\n",
      "epoch: 147  batch: 26  loss: 0.11272345\n",
      "epoch: 147  batch: 27  loss: 0.07173868\n",
      "epoch: 147  batch: 28  loss: 0.07120322\n",
      "epoch: 147  batch: 29  loss: 0.08520431\n",
      "epoch: 147  batch: 30  loss: 0.08466984\n",
      "epoch: 147  batch: 31  loss: 0.07369540\n",
      "epoch: 147  batch: 32  loss: 0.09458946\n",
      "epoch: 147  batch: 33  loss: 0.06416115\n",
      "epoch: 147  batch: 34  loss: 0.10110322\n",
      "epoch: 147  batch: 35  loss: 0.05699390\n",
      "epoch: 147  batch: 36  loss: 0.05922464\n",
      "epoch: 147  batch: 37  loss: 0.09000315\n",
      "epoch: 147  batch: 38  loss: 0.05395031\n",
      "epoch: 147  batch: 39  loss: 0.12042180\n",
      "epoch: 147  batch: 40  loss: 0.06268050\n",
      "epoch: 147  batch: 41  loss: 0.07176765\n",
      "epoch: 147  batch: 42  loss: 0.06909548\n",
      "epoch: 147  batch: 43  loss: 0.09384894\n",
      "epoch: 147  batch: 44  loss: 0.08622396\n",
      "epoch: 147  batch: 45  loss: 0.10552328\n",
      "epoch: 147  batch: 46  loss: 0.08476897\n",
      "epoch: 147  batch: 47  loss: 0.07418625\n",
      "epoch: 147  batch: 48  loss: 0.06361905\n",
      "epoch: 147  batch: 49  loss: 0.08326790\n",
      "epoch: 147  batch: 50  loss: 0.05335486\n",
      "epoch: 147  batch: 51  loss: 0.06008505\n",
      "epoch: 147  batch: 52  loss: 0.09005022\n",
      "epoch: 147  batch: 53  loss: 0.05810636\n",
      "epoch: 147  batch: 54  loss: 0.09843007\n",
      "epoch: 147  batch: 55  loss: 0.08254843\n",
      "epoch: 147  batch: 56  loss: 0.07943456\n",
      "epoch: 147  batch: 57  loss: 0.07339295\n",
      "epoch: 147  batch: 58  loss: 0.07464471\n",
      "epoch: 147  batch: 59  loss: 0.05317475\n",
      "epoch: 147  batch: 60  loss: 0.06264435\n",
      "epoch: 147  batch: 61  loss: 0.07566838\n",
      "epoch: 147  batch: 62  loss: 0.07246380\n",
      "epoch: 147  batch: 63  loss: 0.11118773\n",
      "epoch: 147  batch: 64  loss: 0.09289243\n",
      "epoch: 147  batch: 65  loss: 0.05728399\n",
      "epoch: 147  batch: 66  loss: 0.05181082\n",
      "epoch: 147  batch: 67  loss: 0.09370852\n",
      "epoch: 147  batch: 68  loss: 0.09014299\n",
      "epoch: 147  batch: 69  loss: 0.09161848\n",
      "epoch: 147  batch: 70  loss: 0.10486390\n",
      "epoch: 147  batch: 71  loss: 0.07156315\n",
      "epoch: 147  batch: 72  loss: 0.06099289\n",
      "epoch: 147  batch: 73  loss: 0.10194592\n",
      "epoch: 147  batch: 74  loss: 0.05305602\n",
      "epoch: 147  batch: 75  loss: 0.07643992\n",
      "epoch: 147  batch: 76  loss: 0.08091598\n",
      "epoch: 147  batch: 77  loss: 0.07630045\n",
      "epoch: 147  batch: 78  loss: 0.08010019\n",
      "epoch: 147  batch: 79  loss: 0.09305761\n",
      "epoch: 147  batch: 80  loss: 0.08135941\n",
      "epoch: 147  batch: 81  loss: 0.10499941\n",
      "epoch: 147  batch: 82  loss: 0.06882850\n",
      "epoch: 147  batch: 83  loss: 0.05953654\n",
      "epoch: 147  batch: 84  loss: 0.07102450\n",
      "epoch: 147  batch: 85  loss: 0.07368568\n",
      "epoch: 147  batch: 86  loss: 0.06105228\n",
      "epoch: 147  batch: 87  loss: 0.12281877\n",
      "epoch: 148  batch: 1  loss: 0.07946616\n",
      "epoch: 148  batch: 2  loss: 0.07072561\n",
      "epoch: 148  batch: 3  loss: 0.08740583\n",
      "epoch: 148  batch: 4  loss: 0.06922722\n",
      "epoch: 148  batch: 5  loss: 0.08931436\n",
      "epoch: 148  batch: 6  loss: 0.05793117\n",
      "epoch: 148  batch: 7  loss: 0.08430561\n",
      "epoch: 148  batch: 8  loss: 0.05972361\n",
      "epoch: 148  batch: 9  loss: 0.08824783\n",
      "epoch: 148  batch: 10  loss: 0.07756210\n",
      "epoch: 148  batch: 11  loss: 0.06149900\n",
      "epoch: 148  batch: 12  loss: 0.09649042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 148  batch: 13  loss: 0.07287433\n",
      "epoch: 148  batch: 14  loss: 0.08408292\n",
      "epoch: 148  batch: 15  loss: 0.10003703\n",
      "epoch: 148  batch: 16  loss: 0.06896360\n",
      "epoch: 148  batch: 17  loss: 0.10501038\n",
      "epoch: 148  batch: 18  loss: 0.08812330\n",
      "epoch: 148  batch: 19  loss: 0.07913285\n",
      "epoch: 148  batch: 20  loss: 0.10094626\n",
      "epoch: 148  batch: 21  loss: 0.11441792\n",
      "epoch: 148  batch: 22  loss: 0.09136146\n",
      "epoch: 148  batch: 23  loss: 0.09081877\n",
      "epoch: 148  batch: 24  loss: 0.10550892\n",
      "epoch: 148  batch: 25  loss: 0.07054841\n",
      "epoch: 148  batch: 26  loss: 0.07112507\n",
      "epoch: 148  batch: 27  loss: 0.05797184\n",
      "epoch: 148  batch: 28  loss: 0.08143991\n",
      "epoch: 148  batch: 29  loss: 0.08657521\n",
      "epoch: 148  batch: 30  loss: 0.06910437\n",
      "epoch: 148  batch: 31  loss: 0.08638413\n",
      "epoch: 148  batch: 32  loss: 0.06427108\n",
      "epoch: 148  batch: 33  loss: 0.07560174\n",
      "epoch: 148  batch: 34  loss: 0.07677653\n",
      "epoch: 148  batch: 35  loss: 0.08695296\n",
      "epoch: 148  batch: 36  loss: 0.07469434\n",
      "epoch: 148  batch: 37  loss: 0.09518579\n",
      "epoch: 148  batch: 38  loss: 0.09218525\n",
      "epoch: 148  batch: 39  loss: 0.13981277\n",
      "epoch: 148  batch: 40  loss: 0.09044969\n",
      "epoch: 148  batch: 41  loss: 0.08761431\n",
      "epoch: 148  batch: 42  loss: 0.06386470\n",
      "epoch: 148  batch: 43  loss: 0.07468225\n",
      "epoch: 148  batch: 44  loss: 0.06366157\n",
      "epoch: 148  batch: 45  loss: 0.07492512\n",
      "epoch: 148  batch: 46  loss: 0.12785819\n",
      "epoch: 148  batch: 47  loss: 0.08419530\n",
      "epoch: 148  batch: 48  loss: 0.06238373\n",
      "epoch: 148  batch: 49  loss: 0.09347468\n",
      "epoch: 148  batch: 50  loss: 0.09149096\n",
      "epoch: 148  batch: 51  loss: 0.09677007\n",
      "epoch: 148  batch: 52  loss: 0.07082693\n",
      "epoch: 148  batch: 53  loss: 0.08100297\n",
      "epoch: 148  batch: 54  loss: 0.06416084\n",
      "epoch: 148  batch: 55  loss: 0.09520293\n",
      "epoch: 148  batch: 56  loss: 0.05577805\n",
      "epoch: 148  batch: 57  loss: 0.07400658\n",
      "epoch: 148  batch: 58  loss: 0.06217692\n",
      "epoch: 148  batch: 59  loss: 0.08782306\n",
      "epoch: 148  batch: 60  loss: 0.04511999\n",
      "epoch: 148  batch: 61  loss: 0.05803614\n",
      "epoch: 148  batch: 62  loss: 0.07417583\n",
      "epoch: 148  batch: 63  loss: 0.07456977\n",
      "epoch: 148  batch: 64  loss: 0.06533326\n",
      "epoch: 148  batch: 65  loss: 0.07580458\n",
      "epoch: 148  batch: 66  loss: 0.06110486\n",
      "epoch: 148  batch: 67  loss: 0.07745102\n",
      "epoch: 148  batch: 68  loss: 0.12368201\n",
      "epoch: 148  batch: 69  loss: 0.08985178\n",
      "epoch: 148  batch: 70  loss: 0.09053280\n",
      "epoch: 148  batch: 71  loss: 0.08627198\n",
      "epoch: 148  batch: 72  loss: 0.06691116\n",
      "epoch: 148  batch: 73  loss: 0.05254743\n",
      "epoch: 148  batch: 74  loss: 0.05113558\n",
      "epoch: 148  batch: 75  loss: 0.06336153\n",
      "epoch: 148  batch: 76  loss: 0.06341600\n",
      "epoch: 148  batch: 77  loss: 0.10048246\n",
      "epoch: 148  batch: 78  loss: 0.10142548\n",
      "epoch: 148  batch: 79  loss: 0.06455896\n",
      "epoch: 148  batch: 80  loss: 0.09458706\n",
      "epoch: 148  batch: 81  loss: 0.07487021\n",
      "epoch: 148  batch: 82  loss: 0.05716595\n",
      "epoch: 148  batch: 83  loss: 0.12847990\n",
      "epoch: 148  batch: 84  loss: 0.06072377\n",
      "epoch: 148  batch: 85  loss: 0.07976902\n",
      "epoch: 148  batch: 86  loss: 0.09778319\n",
      "epoch: 148  batch: 87  loss: 0.07466567\n",
      "epoch: 149  batch: 1  loss: 0.07667498\n",
      "epoch: 149  batch: 2  loss: 0.08704212\n",
      "epoch: 149  batch: 3  loss: 0.08483269\n",
      "epoch: 149  batch: 4  loss: 0.06645424\n",
      "epoch: 149  batch: 5  loss: 0.06247031\n",
      "epoch: 149  batch: 6  loss: 0.06263354\n",
      "epoch: 149  batch: 7  loss: 0.07186955\n",
      "epoch: 149  batch: 8  loss: 0.07711627\n",
      "epoch: 149  batch: 9  loss: 0.08711185\n",
      "epoch: 149  batch: 10  loss: 0.06991456\n",
      "epoch: 149  batch: 11  loss: 0.08689127\n",
      "epoch: 149  batch: 12  loss: 0.08641544\n",
      "epoch: 149  batch: 13  loss: 0.09650153\n",
      "epoch: 149  batch: 14  loss: 0.08385760\n",
      "epoch: 149  batch: 15  loss: 0.06985378\n",
      "epoch: 149  batch: 16  loss: 0.07011440\n",
      "epoch: 149  batch: 17  loss: 0.08496925\n",
      "epoch: 149  batch: 18  loss: 0.06748463\n",
      "epoch: 149  batch: 19  loss: 0.07948209\n",
      "epoch: 149  batch: 20  loss: 0.06974956\n",
      "epoch: 149  batch: 21  loss: 0.08028463\n",
      "epoch: 149  batch: 22  loss: 0.06114599\n",
      "epoch: 149  batch: 23  loss: 0.07571734\n",
      "epoch: 149  batch: 24  loss: 0.05977760\n",
      "epoch: 149  batch: 25  loss: 0.06027607\n",
      "epoch: 149  batch: 26  loss: 0.05738408\n",
      "epoch: 149  batch: 27  loss: 0.08020911\n",
      "epoch: 149  batch: 28  loss: 0.09066305\n",
      "epoch: 149  batch: 29  loss: 0.14932483\n",
      "epoch: 149  batch: 30  loss: 0.07970895\n",
      "epoch: 149  batch: 31  loss: 0.06285489\n",
      "epoch: 149  batch: 32  loss: 0.08937814\n",
      "epoch: 149  batch: 33  loss: 0.07164437\n",
      "epoch: 149  batch: 34  loss: 0.11195057\n",
      "epoch: 149  batch: 35  loss: 0.07884098\n",
      "epoch: 149  batch: 36  loss: 0.05995053\n",
      "epoch: 149  batch: 37  loss: 0.11124001\n",
      "epoch: 149  batch: 38  loss: 0.08385647\n",
      "epoch: 149  batch: 39  loss: 0.05761167\n",
      "epoch: 149  batch: 40  loss: 0.08654214\n",
      "epoch: 149  batch: 41  loss: 0.08142902\n",
      "epoch: 149  batch: 42  loss: 0.11053342\n",
      "epoch: 149  batch: 43  loss: 0.07238285\n",
      "epoch: 149  batch: 44  loss: 0.06605687\n",
      "epoch: 149  batch: 45  loss: 0.05206827\n",
      "epoch: 149  batch: 46  loss: 0.15258101\n",
      "epoch: 149  batch: 47  loss: 0.06219684\n",
      "epoch: 149  batch: 48  loss: 0.08399166\n",
      "epoch: 149  batch: 49  loss: 0.06872117\n",
      "epoch: 149  batch: 50  loss: 0.08748339\n",
      "epoch: 149  batch: 51  loss: 0.07513266\n",
      "epoch: 149  batch: 52  loss: 0.07870142\n",
      "epoch: 149  batch: 53  loss: 0.04873788\n",
      "epoch: 149  batch: 54  loss: 0.07554206\n",
      "epoch: 149  batch: 55  loss: 0.05678728\n",
      "epoch: 149  batch: 56  loss: 0.10614570\n",
      "epoch: 149  batch: 57  loss: 0.10638851\n",
      "epoch: 149  batch: 58  loss: 0.06773394\n",
      "epoch: 149  batch: 59  loss: 0.05670326\n",
      "epoch: 149  batch: 60  loss: 0.09268744\n",
      "epoch: 149  batch: 61  loss: 0.06463757\n",
      "epoch: 149  batch: 62  loss: 0.11542714\n",
      "epoch: 149  batch: 63  loss: 0.06762604\n",
      "epoch: 149  batch: 64  loss: 0.14107507\n",
      "epoch: 149  batch: 65  loss: 0.06222789\n",
      "epoch: 149  batch: 66  loss: 0.09880201\n",
      "epoch: 149  batch: 67  loss: 0.06944901\n",
      "epoch: 149  batch: 68  loss: 0.08462851\n",
      "epoch: 149  batch: 69  loss: 0.07221858\n",
      "epoch: 149  batch: 70  loss: 0.08114739\n",
      "epoch: 149  batch: 71  loss: 0.06206885\n",
      "epoch: 149  batch: 72  loss: 0.09030916\n",
      "epoch: 149  batch: 73  loss: 0.08417219\n",
      "epoch: 149  batch: 74  loss: 0.07458801\n",
      "epoch: 149  batch: 75  loss: 0.09260863\n",
      "epoch: 149  batch: 76  loss: 0.12711403\n",
      "epoch: 149  batch: 77  loss: 0.07552306\n",
      "epoch: 149  batch: 78  loss: 0.07667033\n",
      "epoch: 149  batch: 79  loss: 0.06920924\n",
      "epoch: 149  batch: 80  loss: 0.07613534\n",
      "epoch: 149  batch: 81  loss: 0.15067919\n",
      "epoch: 149  batch: 82  loss: 0.06724975\n",
      "epoch: 149  batch: 83  loss: 0.06860007\n",
      "epoch: 149  batch: 84  loss: 0.09180339\n",
      "epoch: 149  batch: 85  loss: 0.06680188\n",
      "epoch: 149  batch: 86  loss: 0.07231618\n",
      "epoch: 149  batch: 87  loss: 0.09590074\n",
      "epoch: 150  batch: 1  loss: 0.10543680\n",
      "epoch: 150  batch: 2  loss: 0.10782095\n",
      "epoch: 150  batch: 3  loss: 0.07398871\n",
      "epoch: 150  batch: 4  loss: 0.07466278\n",
      "epoch: 150  batch: 5  loss: 0.10669499\n",
      "epoch: 150  batch: 6  loss: 0.07600046\n",
      "epoch: 150  batch: 7  loss: 0.04227681\n",
      "epoch: 150  batch: 8  loss: 0.10880712\n",
      "epoch: 150  batch: 9  loss: 0.09108523\n",
      "epoch: 150  batch: 10  loss: 0.08912558\n",
      "epoch: 150  batch: 11  loss: 0.06098180\n",
      "epoch: 150  batch: 12  loss: 0.05480814\n",
      "epoch: 150  batch: 13  loss: 0.04614884\n",
      "epoch: 150  batch: 14  loss: 0.09302721\n",
      "epoch: 150  batch: 15  loss: 0.05126728\n",
      "epoch: 150  batch: 16  loss: 0.06006927\n",
      "epoch: 150  batch: 17  loss: 0.05388029\n",
      "epoch: 150  batch: 18  loss: 0.07575592\n",
      "epoch: 150  batch: 19  loss: 0.06689873\n",
      "epoch: 150  batch: 20  loss: 0.07949701\n",
      "epoch: 150  batch: 21  loss: 0.07195727\n",
      "epoch: 150  batch: 22  loss: 0.12238650\n",
      "epoch: 150  batch: 23  loss: 0.09689201\n",
      "epoch: 150  batch: 24  loss: 0.08001763\n",
      "epoch: 150  batch: 25  loss: 0.09853198\n",
      "epoch: 150  batch: 26  loss: 0.07212803\n",
      "epoch: 150  batch: 27  loss: 0.09194920\n",
      "epoch: 150  batch: 28  loss: 0.09474114\n",
      "epoch: 150  batch: 29  loss: 0.07376750\n",
      "epoch: 150  batch: 30  loss: 0.11705108\n",
      "epoch: 150  batch: 31  loss: 0.07952870\n",
      "epoch: 150  batch: 32  loss: 0.05839485\n",
      "epoch: 150  batch: 33  loss: 0.08168503\n",
      "epoch: 150  batch: 34  loss: 0.09283127\n",
      "epoch: 150  batch: 35  loss: 0.10692742\n",
      "epoch: 150  batch: 36  loss: 0.06524550\n",
      "epoch: 150  batch: 37  loss: 0.05283469\n",
      "epoch: 150  batch: 38  loss: 0.07969110\n",
      "epoch: 150  batch: 39  loss: 0.06664618\n",
      "epoch: 150  batch: 40  loss: 0.07231148\n",
      "epoch: 150  batch: 41  loss: 0.08661444\n",
      "epoch: 150  batch: 42  loss: 0.08361306\n",
      "epoch: 150  batch: 43  loss: 0.07037621\n",
      "epoch: 150  batch: 44  loss: 0.08548532\n",
      "epoch: 150  batch: 45  loss: 0.07510776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 150  batch: 46  loss: 0.10381342\n",
      "epoch: 150  batch: 47  loss: 0.12154610\n",
      "epoch: 150  batch: 48  loss: 0.10438994\n",
      "epoch: 150  batch: 49  loss: 0.08918139\n",
      "epoch: 150  batch: 50  loss: 0.09136030\n",
      "epoch: 150  batch: 51  loss: 0.07922617\n",
      "epoch: 150  batch: 52  loss: 0.12802683\n",
      "epoch: 150  batch: 53  loss: 0.07776258\n",
      "epoch: 150  batch: 54  loss: 0.05146226\n",
      "epoch: 150  batch: 55  loss: 0.06242294\n",
      "epoch: 150  batch: 56  loss: 0.10925395\n",
      "epoch: 150  batch: 57  loss: 0.08605793\n",
      "epoch: 150  batch: 58  loss: 0.09151000\n",
      "epoch: 150  batch: 59  loss: 0.08663954\n",
      "epoch: 150  batch: 60  loss: 0.07728405\n",
      "epoch: 150  batch: 61  loss: 0.06962387\n",
      "epoch: 150  batch: 62  loss: 0.06537957\n",
      "epoch: 150  batch: 63  loss: 0.12861441\n",
      "epoch: 150  batch: 64  loss: 0.07902329\n",
      "epoch: 150  batch: 65  loss: 0.05476759\n",
      "epoch: 150  batch: 66  loss: 0.09198170\n",
      "epoch: 150  batch: 67  loss: 0.09016356\n",
      "epoch: 150  batch: 68  loss: 0.06759703\n",
      "epoch: 150  batch: 69  loss: 0.05327522\n",
      "epoch: 150  batch: 70  loss: 0.10319518\n",
      "epoch: 150  batch: 71  loss: 0.08331952\n",
      "epoch: 150  batch: 72  loss: 0.08489384\n",
      "epoch: 150  batch: 73  loss: 0.07846441\n",
      "epoch: 150  batch: 74  loss: 0.13280450\n",
      "epoch: 150  batch: 75  loss: 0.07496205\n",
      "epoch: 150  batch: 76  loss: 0.06225272\n",
      "epoch: 150  batch: 77  loss: 0.11380543\n",
      "epoch: 150  batch: 78  loss: 0.07771631\n",
      "epoch: 150  batch: 79  loss: 0.06670874\n",
      "epoch: 150  batch: 80  loss: 0.06520137\n",
      "epoch: 150  batch: 81  loss: 0.11255947\n",
      "epoch: 150  batch: 82  loss: 0.09358625\n",
      "epoch: 150  batch: 83  loss: 0.08597872\n",
      "epoch: 150  batch: 84  loss: 0.06167840\n",
      "epoch: 150  batch: 85  loss: 0.05933449\n",
      "epoch: 150  batch: 86  loss: 0.05623191\n",
      "epoch: 150  batch: 87  loss: 0.07463435\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "                \n",
    "        # Apply the model\n",
    "        y_pred = Model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "#         torch.cuda.empty_cache()\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%1 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Run the validationing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "            # Apply the model\n",
    "            \n",
    "            X_validation = X_validation.to(device)\n",
    "            y_validation = y_validation.to(device)\n",
    "            \n",
    "            y_val = Model(X_validation)\n",
    "    loss = criterion(y_val, y_validation)\n",
    "    validation_losses.append(loss.cpu().detach().numpy())\n",
    "#     validation_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7796f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-16T11:01:23.122227Z",
     "start_time": "2023-01-16T11:01:22.933042Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(validation_losses, label='validation loss')\n",
    "plt.legend();\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fce3df",
   "metadata": {},
   "source": [
    "# Cheking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb8d7322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:49.339891Z",
     "start_time": "2023-01-17T17:18:49.335498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(color_im)\n",
    "    depth_raw = o3d.geometry.Image(depth_im)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "#     PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,1,0]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d61af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e456c1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:49.771710Z",
     "start_time": "2023-01-17T17:18:49.769401Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_resize = transforms.Resize(480, interpolation=transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a78878d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:19:10.028431Z",
     "start_time": "2023-01-17T17:19:09.895941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AoRNet(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('Modele/RN-A_L1-150E-.pt'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c474164f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:19:50.394885Z",
     "start_time": "2023-01-17T17:19:49.337730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.23733,     -0.33263,      1.57444], [     0.23759,      0.56475,      1.65292]]\n",
      "REAL:\n",
      "[[    -0.17981,     -0.56752,      1.47500], [    -0.14518,      0.51585,      1.23950]]\n",
      "DIFFERENCE:\n",
      "[[     0.41714,      0.23489,      0.09944], [     0.38278,      0.04889,      0.41342]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.28345,     -0.98640,      2.74670], [    -0.28623,      1.16293,      2.78294]]\n",
      "REAL:\n",
      "[[     0.43280,      0.66123,      1.71077], [     0.42100,     -0.82478,      1.81904]]\n",
      "DIFFERENCE:\n",
      "[[     0.71625,      1.64764,      1.03593], [     0.70723,      1.98772,      0.96390]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.25439,     -0.72423,      2.02772], [    -0.26095,      0.75123,      2.08781]]\n",
      "REAL:\n",
      "[[     0.10236,     -0.81088,      2.10750], [     0.11888,      0.73375,      1.95050]]\n",
      "DIFFERENCE:\n",
      "[[     0.35676,      0.08665,      0.07978], [     0.37983,      0.01749,      0.13731]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.11492,     -0.32005,      1.19719], [     0.11701,      0.31717,      1.27194]]\n",
      "REAL:\n",
      "[[     0.09985,     -0.33658,      1.17800], [     0.10554,      0.18001,      1.30350]]\n",
      "DIFFERENCE:\n",
      "[[     0.01507,      0.01653,      0.01919], [     0.01147,      0.13716,      0.03156]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.03447,     -0.49831,      1.51826], [    -0.02980,      0.54804,      1.54513]]\n",
      "REAL:\n",
      "[[    -0.03908,     -0.54405,      1.41400], [    -0.02759,      0.64029,      1.52450]]\n",
      "DIFFERENCE:\n",
      "[[     0.00461,      0.04573,      0.10426], [     0.00221,      0.09225,      0.02063]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04384,     -0.67887,      2.13194], [    -0.01740,      0.85319,      2.19511]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.01767,      0.01849,      0.01794], [     0.01640,      0.07773,      0.02139]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.14150,     -0.30342,      1.58170], [     0.16198,      0.49123,      1.60039]]\n",
      "REAL:\n",
      "[[    -0.37297,     -0.54713,      1.56650], [    -0.38246,      0.65200,      1.58100]]\n",
      "DIFFERENCE:\n",
      "[[     0.51447,      0.24371,      0.01521], [     0.54444,      0.16077,      0.01939]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.05025,     -0.50471,      1.59767], [    -0.03720,      0.58117,      1.67373]]\n",
      "REAL:\n",
      "[[     0.25915,      0.39362,      1.00380], [     0.38275,     -0.50470,      1.15920]]\n",
      "DIFFERENCE:\n",
      "[[     0.30940,      0.89833,      0.59388], [     0.41995,      1.08587,      0.51453]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.04935,     -0.40008,      1.29500], [     0.03886,      0.44937,      1.35727]]\n",
      "REAL:\n",
      "[[     0.07721,     -0.53259,      1.37400], [     0.10185,      0.46658,      1.15000]]\n",
      "DIFFERENCE:\n",
      "[[     0.02785,      0.13251,      0.07900], [     0.06299,      0.01720,      0.20727]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.09044,     -0.63461,      2.10714], [    -0.06318,      0.91546,      2.13575]]\n",
      "REAL:\n",
      "[[    -0.38443,     -0.42173,      1.08800], [    -0.42214,      0.25520,      1.11650]]\n",
      "DIFFERENCE:\n",
      "[[     0.29399,      0.21288,      1.01914], [     0.35896,      0.66026,      1.01925]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.14471,     -0.29891,      1.19928], [     0.14495,      0.30689,      1.27996]]\n",
      "REAL:\n",
      "[[     0.09985,     -0.33658,      1.17800], [     0.10554,      0.18001,      1.30350]]\n",
      "DIFFERENCE:\n",
      "[[     0.04486,      0.03767,      0.02128], [     0.03942,      0.12688,      0.02354]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.22220,     -0.75862,      2.25581], [    -0.18263,      0.99072,      2.36280]]\n",
      "REAL:\n",
      "[[    -0.25020,     -0.28831,      0.75500], [    -0.27864,      0.29191,      0.77400]]\n",
      "DIFFERENCE:\n",
      "[[     0.02801,      0.47031,      1.50081], [     0.09601,      0.69881,      1.58880]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.17765,     -0.37804,      1.94187], [     0.19751,      0.66583,      1.97107]]\n",
      "REAL:\n",
      "[[     0.18603,      0.20283,      0.52038], [     0.17132,     -0.16519,      0.48510]]\n",
      "DIFFERENCE:\n",
      "[[     0.00839,      0.58087,      1.42149], [     0.02619,      0.83103,      1.48597]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.21583,     -0.31037,      1.22302], [     0.21729,      0.42109,      1.35923]]\n",
      "REAL:\n",
      "[[     0.20611,      0.28295,      0.72403], [     0.16220,     -0.39194,      0.86080]]\n",
      "DIFFERENCE:\n",
      "[[     0.00973,      0.59331,      0.49899], [     0.05509,      0.81303,      0.49842]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.05047,     -0.50498,      1.66249], [    -0.04694,      0.59349,      1.66999]]\n",
      "REAL:\n",
      "[[    -0.44352,     -0.50108,      1.63400], [    -0.41762,      0.61650,      1.49150]]\n",
      "DIFFERENCE:\n",
      "[[     0.39305,      0.00390,      0.02849], [     0.37069,      0.02301,      0.17849]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.40198,     -0.90179,      3.59435], [    -0.10306,      0.91915,      2.88440]]\n",
      "REAL:\n",
      "[[     0.28945,     -0.49499,      1.27700], [     0.28663,      0.46767,      1.13150]]\n",
      "DIFFERENCE:\n",
      "[[     0.69144,      0.40680,      2.31735], [     0.38969,      0.45148,      1.75290]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.03465,     -0.54085,      2.54043], [     0.06725,      1.00708,      2.53630]]\n",
      "REAL:\n",
      "[[    -0.25020,     -0.28831,      0.75500], [    -0.27864,      0.29191,      0.77400]]\n",
      "DIFFERENCE:\n",
      "[[     0.28486,      0.25254,      1.78543], [     0.34589,      0.71518,      1.76230]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.21641,     -0.83257,      2.51874], [    -0.21437,      0.98205,      2.51715]]\n",
      "REAL:\n",
      "[[     0.61301,      0.36330,      1.35973], [     0.57917,     -0.60016,      1.46694]]\n",
      "DIFFERENCE:\n",
      "[[     0.82942,      1.19587,      1.15901], [     0.79354,      1.58222,      1.05020]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14662,     -0.67511,      2.18746], [    -0.14869,      0.79745,      2.21704]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.03563,      0.16111,      0.69246], [     0.02948,      0.91623,      0.69604]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.23112,     -0.73603,      2.07233], [    -0.22957,      0.80373,      2.10422]]\n",
      "REAL:\n",
      "[[     0.24949,     -0.68322,      1.51394], [     0.28472,     -0.13071,      1.23487]]\n",
      "DIFFERENCE:\n",
      "[[     0.48061,      0.05281,      0.55839], [     0.51428,      0.93444,      0.86936]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.25719,     -0.15852,      1.73783], [     0.26641,      0.36488,      1.64106]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.02757,      0.01972,      0.05183], [     0.03474,      0.02886,      0.03006]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.44723,     -1.10924,      3.08707], [    -0.48281,      1.03267,      3.07490]]\n",
      "REAL:\n",
      "[[    -0.31430,     -1.02671,      3.14300], [    -0.30916,      0.74329,      3.27900]]\n",
      "DIFFERENCE:\n",
      "[[     0.13293,      0.08253,      0.05593], [     0.17365,      0.28939,      0.20410]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07094,     -0.80113,      2.35662], [    -0.15689,      0.59888,      2.28311]]\n",
      "REAL:\n",
      "[[    -0.10629,     -0.86348,      2.23850], [    -0.13628,      0.79469,      2.26800]]\n",
      "DIFFERENCE:\n",
      "[[     0.03534,      0.06235,      0.11812], [     0.02061,      0.19581,      0.01511]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.38364,     -0.88599,      3.03863], [    -0.22500,      1.21316,      2.74468]]\n",
      "REAL:\n",
      "[[    -0.30493,     -0.81315,      2.48200], [    -0.30081,      0.95081,      2.42900]]\n",
      "DIFFERENCE:\n",
      "[[     0.07871,      0.07284,      0.55663], [     0.07582,      0.26235,      0.31568]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 3 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.45922,     -1.13357,      3.10745], [    -0.49136,      1.06608,      3.10892]]\n",
      "REAL:\n",
      "[[    -0.31430,     -1.02671,      3.14300], [    -0.30916,      0.74329,      3.27900]]\n",
      "DIFFERENCE:\n",
      "[[     0.14492,      0.10686,      0.03555], [     0.18220,      0.32279,      0.17008]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.10224,     -0.49499,      1.92138], [     0.11533,      0.70988,      2.00765]]\n",
      "REAL:\n",
      "[[     0.30275,     -0.59853,      1.29764], [     0.20282,      0.46640,      1.14813]]\n",
      "DIFFERENCE:\n",
      "[[     0.20050,      0.10354,      0.62375], [     0.08750,      0.24348,      0.85952]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.02341,     -0.44163,      1.65367], [     0.02588,      0.54347,      1.66610]]\n",
      "REAL:\n",
      "[[    -0.44352,     -0.50108,      1.63400], [    -0.41762,      0.61650,      1.49150]]\n",
      "DIFFERENCE:\n",
      "[[     0.46694,      0.05945,      0.01967], [     0.44351,      0.07303,      0.17460]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.08640,     -0.65512,      2.20947], [    -0.06602,      0.84716,      2.22799]]\n",
      "REAL:\n",
      "[[     0.02643,     -0.21876,      1.97950], [     0.02001,      0.13011,      1.75150]]\n",
      "DIFFERENCE:\n",
      "[[     0.11282,      0.43636,      0.22997], [     0.08604,      0.71705,      0.47649]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.05499,     -0.42511,      1.51523], [     0.06089,      0.51628,      1.57698]]\n",
      "REAL:\n",
      "[[     0.25915,      0.39362,      1.00380], [     0.38275,     -0.50470,      1.15920]]\n",
      "DIFFERENCE:\n",
      "[[     0.20415,      0.81873,      0.51143], [     0.32186,      1.02098,      0.41778]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.05383,     -0.43640,      1.72022], [     0.06298,      0.55598,      1.71989]]\n",
      "REAL:\n",
      "[[    -0.44352,     -0.50108,      1.63400], [    -0.41762,      0.61650,      1.49150]]\n",
      "DIFFERENCE:\n",
      "[[     0.49735,      0.06469,      0.08622], [     0.48060,      0.06052,      0.22839]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.07383,     -0.41547,      2.00817], [     0.11882,      0.74405,      1.95722]]\n",
      "REAL:\n",
      "[[     0.15711,      0.19682,      0.52163], [     0.14105,     -0.16195,      0.49663]]\n",
      "DIFFERENCE:\n",
      "[[     0.08327,      0.61229,      1.48655], [     0.02223,      0.90600,      1.46058]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04234,     -0.68007,      2.22731], [    -0.03139,      0.91778,      2.31858]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.01617,      0.01970,      0.11331], [     0.00241,      0.01314,      0.10208]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.09903,     -0.62182,      2.02208], [    -0.07034,      0.86710,      2.05042]]\n",
      "REAL:\n",
      "[[    -0.38443,     -0.42173,      1.08800], [    -0.42214,      0.25520,      1.11650]]\n",
      "DIFFERENCE:\n",
      "[[     0.28540,      0.20009,      0.93408], [     0.35180,      0.61190,      0.93392]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.05336,     -0.70586,      2.32755], [    -0.06119,      0.97033,      2.51648]]\n",
      "REAL:\n",
      "[[    -0.40356,     -0.36136,      0.80818], [    -0.42266,      0.28699,      0.76599]]\n",
      "DIFFERENCE:\n",
      "[[     0.35020,      0.34450,      1.51937], [     0.36147,      0.68335,      1.75049]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.38974,     -0.86305,      2.23783], [    -0.38176,      0.87202,      2.23335]]\n",
      "REAL:\n",
      "[[    -0.29695,     -0.80519,      2.08250], [    -0.27981,      0.84136,      2.06900]]\n",
      "DIFFERENCE:\n",
      "[[     0.09279,      0.05786,      0.15533], [     0.10195,      0.03066,      0.16435]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.27071,     -0.74345,      2.05245], [    -0.25765,      0.81512,      2.07470]]\n",
      "REAL:\n",
      "[[     0.20119,     -0.49865,      1.29600], [     0.19995,      0.39897,      0.96750]]\n",
      "DIFFERENCE:\n",
      "[[     0.47190,      0.24480,      0.75645], [     0.45760,      0.41615,      1.10720]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.30467,     -0.75527,      2.06213], [    -0.28812,      0.82286,      2.05210]]\n",
      "REAL:\n",
      "[[     0.00491,     -0.56350,      1.72000], [     0.01795,      0.00000,      1.45000]]\n",
      "DIFFERENCE:\n",
      "[[     0.30959,      0.19177,      0.34213], [     0.30607,      0.82286,      0.60210]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.07272,     -0.51733,      1.94753], [     0.08730,      0.72690,      2.03337]]\n",
      "REAL:\n",
      "[[     0.30275,     -0.59853,      1.29764], [     0.20282,      0.46640,      1.14813]]\n",
      "DIFFERENCE:\n",
      "[[     0.23003,      0.08120,      0.64990], [     0.11553,      0.26050,      0.88524]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.37157,     -0.88430,      2.28984], [    -0.36215,      0.91145,      2.29022]]\n",
      "REAL:\n",
      "[[    -0.35519,     -0.78803,      2.03800], [    -0.36082,      0.85092,      2.02600]]\n",
      "DIFFERENCE:\n",
      "[[     0.01638,      0.09628,      0.25184], [     0.00133,      0.06053,      0.26422]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.06297,     -0.52850,      1.73554], [    -0.03864,      0.53492,      1.70638]]\n",
      "REAL:\n",
      "[[     0.29214,     -0.81039,      2.10100], [     0.30219,      0.73074,      1.92300]]\n",
      "DIFFERENCE:\n",
      "[[     0.35511,      0.28188,      0.36546], [     0.34083,      0.19582,      0.21662]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.09929,     -0.56435,      1.67082], [    -0.11241,      0.64767,      1.73185]]\n",
      "REAL:\n",
      "[[     0.07721,     -0.53259,      1.37400], [     0.10185,      0.46658,      1.15000]]\n",
      "DIFFERENCE:\n",
      "[[     0.17650,      0.03177,      0.29682], [     0.21426,      0.18109,      0.58185]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.10615,     -0.32073,      1.31560], [     0.09595,      0.40578,      1.39831]]\n",
      "REAL:\n",
      "[[    -0.37297,     -0.54713,      1.56650], [    -0.38246,      0.65200,      1.58100]]\n",
      "DIFFERENCE:\n",
      "[[     0.47912,      0.22640,      0.25090], [     0.47841,      0.24622,      0.18269]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.46379,     -0.93209,      3.07315], [    -0.29171,      1.21901,      2.74487]]\n",
      "REAL:\n",
      "[[    -0.30493,     -0.81315,      2.48200], [    -0.30081,      0.95081,      2.42900]]\n",
      "DIFFERENCE:\n",
      "[[     0.15886,      0.11894,      0.59115], [     0.00911,      0.26819,      0.31587]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.18603,     -0.35728,      1.90478], [     0.21020,      0.68758,      1.95453]]\n",
      "REAL:\n",
      "[[     0.09682,     -0.13258,      0.64750], [     0.09629,      0.27620,      0.66050]]\n",
      "DIFFERENCE:\n",
      "[[     0.08921,      0.22471,      1.25728], [     0.11392,      0.41139,      1.29403]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.07259,     -0.34801,      1.17113], [     0.07439,      0.30057,      1.25401]]\n",
      "REAL:\n",
      "[[     0.09985,     -0.33658,      1.17800], [     0.10554,      0.18001,      1.30350]]\n",
      "DIFFERENCE:\n",
      "[[     0.02726,      0.01143,      0.00687], [     0.03114,      0.12057,      0.04949]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14474,     -0.64788,      2.00633], [    -0.12743,      0.86018,      2.04244]]\n",
      "REAL:\n",
      "[[    -0.38443,     -0.42173,      1.08800], [    -0.42214,      0.25520,      1.11650]]\n",
      "DIFFERENCE:\n",
      "[[     0.23969,      0.22615,      0.91833], [     0.29471,      0.60498,      0.92594]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.43653,     -1.00746,      2.91809], [    -0.41125,      1.23249,      2.82535]]\n",
      "REAL:\n",
      "[[     0.27954,     -0.03693,      1.84600], [     0.28317,      0.33122,      1.80200]]\n",
      "DIFFERENCE:\n",
      "[[     0.71607,      0.97053,      1.07209], [     0.69442,      0.90127,      1.02335]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.19163,     -0.70251,      2.24239], [    -0.17423,      0.84920,      2.26563]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.00938,      0.18852,      0.74739], [     0.00394,      0.96798,      0.74463]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.38702,     -0.14700,      1.81148], [     0.41081,      0.53467,      1.79605]]\n",
      "REAL:\n",
      "[[     0.09682,     -0.13258,      0.64750], [     0.09629,      0.27620,      0.66050]]\n",
      "DIFFERENCE:\n",
      "[[     0.29020,      0.01442,      1.16398], [     0.31452,      0.25847,      1.13555]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.15780,     -0.76206,      2.39974], [    -0.16958,      0.91274,      2.40775]]\n",
      "REAL:\n",
      "[[     0.43280,      0.66123,      1.71077], [     0.42100,     -0.82478,      1.81904]]\n",
      "DIFFERENCE:\n",
      "[[     0.59060,      1.42330,      0.68897], [     0.59058,      1.73752,      0.58871]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 6 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.22764,     -0.34147,      1.92684], [     0.24048,      0.68711,      1.96246]]\n",
      "REAL:\n",
      "[[     0.26129,     -0.15201,      0.58250], [     0.26914,      0.19266,      0.61300]]\n",
      "DIFFERENCE:\n",
      "[[     0.03365,      0.18946,      1.34434], [     0.02866,      0.49446,      1.34946]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.12001,     -0.62041,      2.14077], [    -0.09148,      0.92497,      2.14499]]\n",
      "REAL:\n",
      "[[     0.05654,     -0.47373,      1.85600], [     0.09394,      0.77630,      1.86100]]\n",
      "DIFFERENCE:\n",
      "[[     0.17655,      0.14669,      0.28477], [     0.18542,      0.14867,      0.28399]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.22313,     -0.72012,      1.93018], [    -0.22145,      0.79312,      1.93679]]\n",
      "REAL:\n",
      "[[     0.29214,     -0.81039,      2.10100], [     0.30219,      0.73074,      1.92300]]\n",
      "DIFFERENCE:\n",
      "[[     0.51527,      0.09027,      0.17082], [     0.52363,      0.06238,      0.01379]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.20785,     -0.74622,      2.12265], [    -0.21160,      0.82043,      2.16800]]\n",
      "REAL:\n",
      "[[     0.26868,     -0.12965,      1.23894], [     0.24447,     -0.70894,      1.53277]]\n",
      "DIFFERENCE:\n",
      "[[     0.47653,      0.61657,      0.88371], [     0.45608,      1.52937,      0.63524]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14844,     -0.66734,      1.97126], [    -0.15493,      0.71837,      2.07849]]\n",
      "REAL:\n",
      "[[    -0.54453,     -0.50548,      1.05742], [    -0.55623,      0.36407,      0.92269]]\n",
      "DIFFERENCE:\n",
      "[[     0.39609,      0.16186,      0.91384], [     0.40130,      0.35430,      1.15580]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.20798,     -0.72433,      2.06340], [    -0.21357,      0.77580,      2.16283]]\n",
      "REAL:\n",
      "[[    -0.54453,     -0.50548,      1.05742], [    -0.55623,      0.36407,      0.92269]]\n",
      "DIFFERENCE:\n",
      "[[     0.33655,      0.21885,      1.00598], [     0.34266,      0.41174,      1.24015]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.37408,     -0.86882,      2.27422], [    -0.36702,      0.88259,      2.26946]]\n",
      "REAL:\n",
      "[[    -0.40760,     -0.78803,      2.03800], [    -0.39595,      0.85596,      2.03800]]\n",
      "DIFFERENCE:\n",
      "[[     0.03352,      0.08079,      0.23623], [     0.02893,      0.02663,      0.23146]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.03223,     -0.42298,      1.57462], [     0.04186,      0.49527,      1.57368]]\n",
      "REAL:\n",
      "[[     0.10236,     -0.81088,      2.10750], [     0.11888,      0.73375,      1.95050]]\n",
      "DIFFERENCE:\n",
      "[[     0.07013,      0.38790,      0.53288], [     0.07703,      0.23848,      0.37682]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.15075,     -0.57021,      1.86982], [    -0.12347,      0.79581,      1.85228]]\n",
      "REAL:\n",
      "[[    -0.28236,     -0.60742,      1.95050], [    -0.26528,      0.70156,      1.67800]]\n",
      "DIFFERENCE:\n",
      "[[     0.13161,      0.03721,      0.08068], [     0.14182,      0.09424,      0.17428]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.33737,     -0.92708,      2.63514], [    -0.33360,      1.10162,      2.65498]]\n",
      "REAL:\n",
      "[[     0.43280,      0.66123,      1.71077], [     0.42100,     -0.82478,      1.81904]]\n",
      "DIFFERENCE:\n",
      "[[     0.77018,      1.58831,      0.92437], [     0.75460,      1.92640,      0.83593]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14389,     -0.70454,      2.29705], [    -0.11172,      0.89505,      2.28897]]\n",
      "REAL:\n",
      "[[     0.02643,     -0.21876,      1.97950], [     0.02001,      0.13011,      1.75150]]\n",
      "DIFFERENCE:\n",
      "[[     0.17031,      0.48578,      0.31755], [     0.13173,      0.76494,      0.53747]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.15400,     -0.47277,      1.87063], [     0.16455,      0.69594,      1.96692]]\n",
      "REAL:\n",
      "[[     0.30275,     -0.59853,      1.29764], [     0.20282,      0.46640,      1.14813]]\n",
      "DIFFERENCE:\n",
      "[[     0.14875,      0.12576,      0.57300], [     0.03828,      0.22954,      0.81879]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.06316,     -0.43824,      1.52974], [     0.06881,      0.53860,      1.61222]]\n",
      "REAL:\n",
      "[[     0.36134,      0.43296,      1.08243], [     0.31176,     -0.60058,      1.31251]]\n",
      "DIFFERENCE:\n",
      "[[     0.29817,      0.87120,      0.44731], [     0.24295,      1.13918,      0.29971]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.29788,     -0.21775,      1.31998], [     0.30812,      0.44573,      1.41691]]\n",
      "REAL:\n",
      "[[     0.20611,      0.28295,      0.72403], [     0.16220,     -0.39194,      0.86080]]\n",
      "DIFFERENCE:\n",
      "[[     0.09177,      0.50070,      0.59595], [     0.14592,      0.83766,      0.55611]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.28732,     -0.68832,      1.78568], [    -0.27249,      0.66013,      1.79350]]\n",
      "REAL:\n",
      "[[    -0.41055,     -0.68764,      1.77400], [    -0.35904,      0.71001,      1.69050]]\n",
      "DIFFERENCE:\n",
      "[[     0.12324,      0.00069,      0.01168], [     0.08655,      0.04988,      0.10300]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.31286,     -0.76931,      2.48439], [    -0.23098,      1.07826,      2.42011]]\n",
      "REAL:\n",
      "[[    -0.28505,     -0.79071,      2.05000], [    -0.29546,      0.93014,      2.29800]]\n",
      "DIFFERENCE:\n",
      "[[     0.02781,      0.02141,      0.43439], [     0.06448,      0.14812,      0.12211]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.22945,     -0.32727,      1.44155], [     0.23437,      0.49500,      1.53777]]\n",
      "REAL:\n",
      "[[     0.20611,      0.28295,      0.72403], [     0.16220,     -0.39194,      0.86080]]\n",
      "DIFFERENCE:\n",
      "[[     0.02335,      0.61021,      0.71751], [     0.07217,      0.88693,      0.67697]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.15936,     -0.65917,      2.01230], [    -0.13717,      0.87214,      2.04091]]\n",
      "REAL:\n",
      "[[    -0.38443,     -0.42173,      1.08800], [    -0.42214,      0.25520,      1.11650]]\n",
      "DIFFERENCE:\n",
      "[[     0.22507,      0.23744,      0.92430], [     0.28497,      0.61694,      0.92441]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04102,     -0.49887,      1.58395], [    -0.03049,      0.57657,      1.63408]]\n",
      "REAL:\n",
      "[[     0.25915,      0.39362,      1.00380], [     0.38275,     -0.50470,      1.15920]]\n",
      "DIFFERENCE:\n",
      "[[     0.30017,      0.89249,      0.58016], [     0.41324,      1.08127,      0.47488]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.55342,     -1.02247,      3.20041], [    -0.41136,      1.34180,      2.93923]]\n",
      "REAL:\n",
      "[[     0.27954,     -0.03693,      1.84600], [     0.28317,      0.33122,      1.80200]]\n",
      "DIFFERENCE:\n",
      "[[     0.83296,      0.98554,      1.35441], [     0.69453,      1.01057,      1.13723]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01495,     -0.49937,      1.57743], [    -0.03559,      0.52284,      1.69636]]\n",
      "REAL:\n",
      "[[    -0.37297,     -0.54713,      1.56650], [    -0.38246,      0.65200,      1.58100]]\n",
      "DIFFERENCE:\n",
      "[[     0.35802,      0.04776,      0.01093], [     0.34687,      0.12915,      0.11536]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.20846,     -0.75140,      2.32018], [    -0.20266,      0.89098,      2.35372]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.02621,      0.23741,      0.82518], [     0.02448,      1.00976,      0.83272]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 8 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.11849,     -0.31823,      1.19346], [     0.12003,      0.31323,      1.26767]]\n",
      "REAL:\n",
      "[[     0.09985,     -0.33658,      1.17800], [     0.10554,      0.18001,      1.30350]]\n",
      "DIFFERENCE:\n",
      "[[     0.01864,      0.01834,      0.01546], [     0.01450,      0.13323,      0.03583]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.29115,     -0.80554,      3.64830], [     0.02537,      0.89174,      2.90196]]\n",
      "REAL:\n",
      "[[     0.26565,      0.42141,      1.12947], [     0.26895,     -0.60752,      1.28076]]\n",
      "DIFFERENCE:\n",
      "[[     0.55680,      1.22695,      2.51883], [     0.24358,      1.49925,      1.62120]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.10196,     -0.39453,      1.52896], [     0.11204,      0.52648,      1.59219]]\n",
      "REAL:\n",
      "[[     0.25915,      0.39362,      1.00380], [     0.38275,     -0.50470,      1.15920]]\n",
      "DIFFERENCE:\n",
      "[[     0.15719,      0.78815,      0.52517], [     0.27071,      1.03118,      0.43299]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.28737,     -0.14920,      1.73898], [     0.29054,      0.36887,      1.64397]]\n",
      "REAL:\n",
      "[[     0.23283,     -0.17502,      1.68600], [     0.22651,      0.34130,      1.60700]]\n",
      "DIFFERENCE:\n",
      "[[     0.05454,      0.02583,      0.05298], [     0.06403,      0.02757,      0.03697]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.31815,     -0.95003,      2.64420], [    -0.32250,      1.08892,      2.64513]]\n",
      "REAL:\n",
      "[[     0.61301,      0.36330,      1.35973], [     0.57917,     -0.60016,      1.46694]]\n",
      "DIFFERENCE:\n",
      "[[     0.93116,      1.31333,      1.28447], [     0.90167,      1.68908,      1.17819]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.56914,      0.00619,      1.21831], [     0.57926,      0.26989,      1.30832]]\n",
      "REAL:\n",
      "[[     0.44540,     -0.12920,      1.19000], [     0.44520,      0.35854,      1.24650]]\n",
      "DIFFERENCE:\n",
      "[[     0.12374,      0.13539,      0.02831], [     0.13406,      0.08864,      0.06182]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.30560,     -0.27066,      2.14162], [     0.32425,      0.69373,      2.15014]]\n",
      "REAL:\n",
      "[[     0.18603,      0.20283,      0.52038], [     0.17132,     -0.16519,      0.48510]]\n",
      "DIFFERENCE:\n",
      "[[     0.11957,      0.47349,      1.62124], [     0.15293,      0.85892,      1.66504]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.02512,     -0.38106,      2.96554], [     0.07119,      0.72130,      2.55803]]\n",
      "REAL:\n",
      "[[     0.36197,     -0.66360,      1.71200], [     0.36183,      0.59089,      1.42300]]\n",
      "DIFFERENCE:\n",
      "[[     0.33685,      0.28255,      1.25354], [     0.29064,      0.13041,      1.13503]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.19242,     -0.65242,      1.87111], [    -0.19122,      0.68466,      1.90377]]\n",
      "REAL:\n",
      "[[     0.10236,     -0.81088,      2.10750], [     0.11888,      0.73375,      1.95050]]\n",
      "DIFFERENCE:\n",
      "[[     0.29479,      0.15846,      0.23639], [     0.31010,      0.04908,      0.04673]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.26869,     -0.86401,      2.54056], [    -0.25093,      1.21942,      2.65067]]\n",
      "REAL:\n",
      "[[    -0.23647,     -0.47238,      1.03133], [    -0.21862,      0.29674,      0.99922]]\n",
      "DIFFERENCE:\n",
      "[[     0.03222,      0.39163,      1.50923], [     0.03231,      0.92268,      1.65145]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.36596,     -0.88852,      2.42395], [    -0.34726,      0.95177,      2.40680]]\n",
      "REAL:\n",
      "[[    -0.14792,     -0.80852,      2.18800], [    -0.14852,      0.88116,      2.10750]]\n",
      "DIFFERENCE:\n",
      "[[     0.21804,      0.07999,      0.23595], [     0.19873,      0.07061,      0.29930]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.27796,     -0.29713,      1.55727], [     0.27746,      0.52531,      1.64794]]\n",
      "REAL:\n",
      "[[    -0.17981,     -0.56752,      1.47500], [    -0.14518,      0.51585,      1.23950]]\n",
      "DIFFERENCE:\n",
      "[[     0.45777,      0.27040,      0.08227], [     0.42264,      0.00946,      0.40844]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.03716,     -0.44568,      1.63304], [     0.04382,      0.57067,      1.68758]]\n",
      "REAL:\n",
      "[[     0.20119,     -0.49865,      1.29600], [     0.19995,      0.39897,      0.96750]]\n",
      "DIFFERENCE:\n",
      "[[     0.16403,      0.05297,      0.33704], [     0.15613,      0.17171,      0.72008]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04437,     -0.57810,      2.05972], [    -0.04146,      0.71309,      2.09804]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.13788,      0.06410,      0.56472], [     0.13672,      0.83187,      0.57704]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.39736,     -0.91766,      2.39118], [    -0.39113,      0.95089,      2.37939]]\n",
      "REAL:\n",
      "[[    -0.14792,     -0.80852,      2.18800], [    -0.14852,      0.88116,      2.10750]]\n",
      "DIFFERENCE:\n",
      "[[     0.24944,      0.10914,      0.20318], [     0.24261,      0.06972,      0.27189]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.24501,     -0.17073,      1.74393], [     0.25103,      0.37995,      1.64215]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.01539,      0.00751,      0.05794], [     0.01935,      0.04393,      0.03115]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.25632,     -0.76171,      2.23839], [    -0.22738,      0.87732,      2.29146]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.07407,      0.24772,      0.74339], [     0.04920,      0.99611,      0.77046]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.54754,     -1.05646,      3.88487], [    -0.22561,      1.01980,      3.13777]]\n",
      "REAL:\n",
      "[[     0.34555,     -0.51515,      1.32900], [     0.20370,      0.47972,      1.15000]]\n",
      "DIFFERENCE:\n",
      "[[     0.89309,      0.54131,      2.55587], [     0.42932,      0.54008,      1.98777]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.22043,     -0.73611,      2.27178], [    -0.20648,      0.86212,      2.29588]]\n",
      "REAL:\n",
      "[[    -0.18225,     -0.51400,      1.49500], [    -0.17817,     -0.11878,      1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.03818,      0.22211,      0.77678], [     0.02831,      0.98091,      0.77488]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 10 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.18661,     -0.72442,      2.07576], [    -0.19506,      0.79510,      2.11115]]\n",
      "REAL:\n",
      "[[     0.24949,     -0.68322,      1.51394], [     0.28472,     -0.13071,      1.23487]]\n",
      "DIFFERENCE:\n",
      "[[     0.43610,      0.04120,      0.56182], [     0.47978,      0.92581,      0.87628]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07446,     -0.62475,      2.19358], [    -0.03480,      0.84106,      2.18985]]\n",
      "REAL:\n",
      "[[     0.02643,     -0.21876,      1.97950], [     0.02001,      0.13011,      1.75150]]\n",
      "DIFFERENCE:\n",
      "[[     0.10089,      0.40599,      0.21408], [     0.05481,      0.71095,      0.43835]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.17162,     -0.38229,      1.92674], [     0.20078,      0.68558,      1.92025]]\n",
      "REAL:\n",
      "[[     0.15711,      0.19682,      0.52163], [     0.14105,     -0.16195,      0.49663]]\n",
      "DIFFERENCE:\n",
      "[[     0.01451,      0.57912,      1.40511], [     0.05973,      0.84753,      1.42362]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.35267,     -0.95146,      2.66106], [    -0.35072,      1.06621,      2.68142]]\n",
      "REAL:\n",
      "[[     0.61301,      0.36330,      1.35973], [     0.57917,     -0.60016,      1.46694]]\n",
      "DIFFERENCE:\n",
      "[[     0.96568,      1.31476,      1.30133], [     0.92990,      1.66638,      1.21447]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.34549,     -0.81593,      2.58595], [    -0.26576,      1.11919,      2.52248]]\n",
      "REAL:\n",
      "[[    -0.28505,     -0.79071,      2.05000], [    -0.29546,      0.93014,      2.29800]]\n",
      "DIFFERENCE:\n",
      "[[     0.06045,      0.02521,      0.53595], [     0.02970,      0.18905,      0.22448]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.20533,     -0.72801,      2.22445], [    -0.17565,      0.90484,      2.23945]]\n",
      "REAL:\n",
      "[[     0.02643,     -0.21876,      1.97950], [     0.02001,      0.13011,      1.75150]]\n",
      "DIFFERENCE:\n",
      "[[     0.23175,      0.50925,      0.24495], [     0.19567,      0.77473,      0.48795]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.45469,     -1.10374,      3.04620], [    -0.46817,      1.10287,      3.03327]]\n",
      "REAL:\n",
      "[[    -0.31430,     -1.02671,      3.14300], [    -0.30916,      0.74329,      3.27900]]\n",
      "DIFFERENCE:\n",
      "[[     0.14039,      0.07702,      0.09680], [     0.15901,      0.35958,      0.24573]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.00072,     -0.50673,      1.89211], [    -0.00993,      0.67591,      1.87092]]\n",
      "REAL:\n",
      "[[    -0.09837,      0.46026,      1.15902], [    -0.14276,     -0.63336,      1.34374]]\n",
      "DIFFERENCE:\n",
      "[[     0.09765,      0.96699,      0.73310], [     0.13283,      1.30927,      0.52718]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.31859,     -0.76917,      2.49630], [    -0.21976,      1.10234,      2.38760]]\n",
      "REAL:\n",
      "[[    -0.28505,     -0.79071,      2.05000], [    -0.29546,      0.93014,      2.29800]]\n",
      "DIFFERENCE:\n",
      "[[     0.03355,      0.02155,      0.44630], [     0.07569,      0.17220,      0.08960]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.21509,     -0.33278,      1.79251], [     0.25077,      0.62859,      1.80441]]\n",
      "REAL:\n",
      "[[     0.15711,      0.19682,      0.52163], [     0.14105,     -0.16195,      0.49663]]\n",
      "DIFFERENCE:\n",
      "[[     0.05798,      0.52960,      1.27088], [     0.10972,      0.79054,      1.30778]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.17826,     -0.36574,      1.87065], [     0.19746,      0.67072,      1.93893]]\n",
      "REAL:\n",
      "[[     0.09682,     -0.13258,      0.64750], [     0.09629,      0.27620,      0.66050]]\n",
      "DIFFERENCE:\n",
      "[[     0.08144,      0.23316,      1.22315], [     0.10117,      0.39452,      1.27843]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.16525,     -0.68215,      2.10008], [    -0.12672,      0.87493,      2.19820]]\n",
      "REAL:\n",
      "[[    -0.25020,     -0.28831,      0.75500], [    -0.27864,      0.29191,      0.77400]]\n",
      "DIFFERENCE:\n",
      "[[     0.08495,      0.39384,      1.34508], [     0.15192,      0.58302,      1.42420]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.34048,     -0.80305,      2.19267], [    -0.32331,      0.89144,      2.18457]]\n",
      "REAL:\n",
      "[[     0.00491,     -0.56350,      1.72000], [     0.01795,      0.00000,      1.45000]]\n",
      "DIFFERENCE:\n",
      "[[     0.34539,      0.23954,      0.47267], [     0.34126,      0.89144,      0.73457]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.26473,     -0.79243,      2.46312], [    -0.18242,      0.99409,      2.38535]]\n",
      "REAL:\n",
      "[[     0.02643,     -0.21876,      1.97950], [     0.02001,      0.13011,      1.75150]]\n",
      "DIFFERENCE:\n",
      "[[     0.29115,      0.57366,      0.48362], [     0.20243,      0.86398,      0.63385]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.25911,     -0.30795,      1.57225], [     0.26243,      0.54579,      1.64793]]\n",
      "REAL:\n",
      "[[    -0.17981,     -0.56752,      1.47500], [    -0.14518,      0.51585,      1.23950]]\n",
      "DIFFERENCE:\n",
      "[[     0.43892,      0.25958,      0.09725], [     0.40761,      0.02994,      0.40843]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.30002,     -0.78682,      2.15398], [    -0.28880,      0.88614,      2.17046]]\n",
      "REAL:\n",
      "[[     0.20119,     -0.49865,      1.29600], [     0.19995,      0.39897,      0.96750]]\n",
      "DIFFERENCE:\n",
      "[[     0.50121,      0.28817,      0.85798], [     0.48875,      0.48718,      1.20296]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07096,     -0.59071,      2.16115], [     0.02644,      0.93853,      2.05257]]\n",
      "REAL:\n",
      "[[     0.05654,     -0.47373,      1.85600], [     0.09394,      0.77630,      1.86100]]\n",
      "DIFFERENCE:\n",
      "[[     0.12750,      0.11699,      0.30515], [     0.06749,      0.16222,      0.19157]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.03595,     -0.67840,      2.24864], [    -0.02546,      0.92763,      2.35241]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.00978,      0.01802,      0.13464], [     0.00833,      0.00328,      0.13591]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "diff_X1 = []\n",
    "diff_Y1 = []\n",
    "diff_Z1 = []\n",
    "diff_X2 = []\n",
    "diff_Y2 = []\n",
    "diff_Z2 = []\n",
    "\n",
    "X1 = [] \n",
    "Y1 = [] \n",
    "Z1 = []\n",
    "X2 = []\n",
    "Y2 = []\n",
    "Z2 = [] \n",
    "\n",
    "hX1 = [] \n",
    "hY1 = [] \n",
    "hZ1 = []\n",
    "hX2 = []\n",
    "hY2 = []\n",
    "hZ2 = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "#         Apply the model\n",
    "        \n",
    "        X_validation = X_validation.to(device)\n",
    "        y_validation = y_validation.to(device)\n",
    "        \n",
    "\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = X_invNorm[0].cpu().numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "#             RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "            DEPTH_buff = X_invNorm[1].cpu().numpy()*5500\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_validation[j][0].cpu().numpy(), y_validation[j][1].cpu().numpy(), y_validation[j][2].cpu().numpy()],\n",
    "                    [y_validation[j][3].cpu().numpy(), y_validation[j][4].cpu().numpy(), y_validation[j][5].cpu().numpy()]]\n",
    "#             draw_arrow(PC, REAL, PREDICTED)\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            diff_X1.append(diff[j][0])\n",
    "            diff_Y1.append(diff[j][1])\n",
    "            diff_Z1.append(diff[j][2])\n",
    "            diff_X2.append(diff[j][3])\n",
    "            diff_Y2.append(diff[j][4])\n",
    "            diff_Z2.append(diff[j][5])\n",
    "            \n",
    "            X1.append(y_validation[j][0].cpu().numpy())\n",
    "            Y1.append(y_validation[j][1].cpu().numpy())\n",
    "            Z1.append(y_validation[j][2].cpu().numpy())\n",
    "            X2.append(y_validation[j][3].cpu().numpy())\n",
    "            Y2.append(y_validation[j][4].cpu().numpy())\n",
    "            Z2.append(y_validation[j][5].cpu().numpy())\n",
    "\n",
    "            hX1.append(y_val[j][0].cpu().numpy()) \n",
    "            hY1.append(y_val[j][1].cpu().numpy()) \n",
    "            hZ1.append(y_val[j][2].cpu().numpy())\n",
    "            hX2.append(y_val[j][3].cpu().numpy())\n",
    "            hY2.append(y_val[j][4].cpu().numpy())\n",
    "            hZ2.append(y_val[j][5].cpu().numpy()) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80527311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:19:55.793818Z",
     "start_time": "2023-01-17T17:19:55.791292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(Model.state_dict(), 'Modele/LDat_RN-A_L1-100E-.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d673a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:19:57.055633Z",
     "start_time": "2023-01-17T17:19:56.511876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "fig, axs = plt.subplots(2, 3,figsize=(20,10))\n",
    "axs[0, 0].plot(X1[0:20],'o')\n",
    "axs[0, 0].plot(hX1[0:20],'+r')\n",
    "axs[0, 0].set_title('X_1')\n",
    "axs[0, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[0, 1].plot(Y1[0:20],'o')\n",
    "axs[0, 1].plot(hY1[0:20],'+r')\n",
    "axs[0, 1].set_title('Y_1')\n",
    "\n",
    "axs[0, 2].plot(Z1[0:20],'o')\n",
    "axs[0, 2].plot(hZ1[0:20],'+r')\n",
    "axs[0, 2].set_title('Z_1')\n",
    "\n",
    "axs[1, 0].plot(X2[0:20],'o')\n",
    "axs[1, 0].plot(hX2[0:20],'+r')\n",
    "axs[1, 0].set_title('X_2')\n",
    "axs[1, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[1, 1].plot(Y2[0:20],'o')\n",
    "axs[1, 1].plot(hY2[0:20],'+r')\n",
    "axs[1, 1].set_title('Y_2')\n",
    "\n",
    "axs[1, 2].plot(Z2[0:20],'o')\n",
    "axs[1, 2].plot(hZ2[0:20],'+r')\n",
    "axs[1, 2].set_title('Z_2')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.legend(['Rzeczywista','Estymowana'])  \n",
    "\n",
    "\n",
    "plt.show()\n",
    "SAVE_DIR = '/home/el_zlociako/Documents/Praca_inzynierska/CNN/Ploty_do_inz/'\n",
    "fig.savefig(SAVE_DIR+'REG1_VAL', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db49c8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:20:23.267353Z",
     "start_time": "2023-01-17T17:20:23.263886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24611685, 0.3323248, 0.62759, 0.24611685, 0.5393316, 0.6414924]\n"
     ]
    }
   ],
   "source": [
    "X1_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y1_MEAN_DIFF = np.mean(diff_Y1)\n",
    "Z1_MEAN_DIFF = np.mean(diff_Z1)\n",
    "X2_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y2_MEAN_DIFF = np.mean(diff_Y2)\n",
    "Z2_MEAN_DIFF = np.mean(diff_Z2)\n",
    "\n",
    "MEAN_ERR = [X1_MEAN_DIFF, Y1_MEAN_DIFF, Z1_MEAN_DIFF, X2_MEAN_DIFF, Y2_MEAN_DIFF, Z2_MEAN_DIFF]\n",
    "print(MEAN_ERR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351666d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28057c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b361d4100cabf439e872d27edcfc9e968620b5cc1a2991a8793a2beed62efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
