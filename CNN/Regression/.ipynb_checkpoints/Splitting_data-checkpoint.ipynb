{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1329c18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:39.924679Z",
     "start_time": "2023-01-17T22:42:37.786286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import open3d as o3d\n",
    "\n",
    "from Libraries.dataloader import DataLoader as DL\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6dfab",
   "metadata": {},
   "source": [
    "#  Inicjalizowane danych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e02fc2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:39.929075Z",
     "start_time": "2023-01-17T22:42:39.926876Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68719e44",
   "metadata": {},
   "source": [
    "# Załadowanie danych\n",
    "Ładujemy dane do zmiennych a następnie odpowiednio przekształcamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376f4b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:39.944902Z",
     "start_time": "2023-01-17T22:42:39.930241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, p=0.5, mean=[0.0, 0.5], std=[1.0, 1.0]):\n",
    "        self.p    = p\n",
    "        self.std  = np.random.uniform(std[0],std[1])\n",
    "        self.mean = np.random.uniform(mean[0],mean[1])\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        if random.random() < self.p:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        else:\n",
    "            return tensor \n",
    "\n",
    "\n",
    "DataAug = transforms.Compose([\n",
    "    transforms.ColorJitter(\n",
    "        brightness=[0.5,1.5],\n",
    "        contrast=[0.5, 1.5],\n",
    "        saturation=[0.5, 1.5],\n",
    "        hue=[-0.1,0.1],\n",
    "    ),\n",
    "    transforms.GaussianBlur(\n",
    "        kernel_size=3,\n",
    "        sigma=(0.1, 9.0)\n",
    "    ),\n",
    "#     transforms.RandomErasing(\n",
    "#         p=0.1,\n",
    "#         scale=(0.01, 0.1),\n",
    "#         ratio=(0.01, 3.3),\n",
    "#         value=0,\n",
    "#     ),\n",
    "    GaussianNoise(\n",
    "        p=0.2,\n",
    "        mean=[0.0, 0.1],\n",
    "        std=[0.01, 0.3]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823deffa",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025b1d4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:47.601135Z",
     "start_time": "2023-01-17T22:42:39.946473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "# DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "# dl = DL()\n",
    "\n",
    "# X_trainA, y_trainA = dl.load(DATASET_ROOTDIR, 'files_ArUco/data_TRA.csv', 'R')\n",
    "# X_trainB, y_trainB = dl.load(DATASET_ROOTDIR, 'files/data_TRA.csv', 'R')\n",
    "\n",
    "# X_validationA, y_validationA = dl.load(DATASET_ROOTDIR, 'files_ArUco/data_VAL.csv', 'R')\n",
    "# X_validationB, y_validationB = dl.load(DATASET_ROOTDIR, 'files/data_VAL.csv', 'R')\n",
    "\n",
    "# X_train = torch.cat((X_trainA, X_trainB),axis=0)\n",
    "# y_train = torch.cat((y_trainA, y_trainB),axis=0)\n",
    "\n",
    "# X_validation = torch.cat((X_validationA, X_validationB),axis=0)\n",
    "# y_validation = torch.cat((y_validationA, y_validationB),axis=0)\n",
    "\n",
    "# # X_train, X_validation, y_train, y_validation = train_test_split(RGBD_input, axis_out, test_size=0.2)\n",
    "# print(X_validationA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "493832bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:23:52.120354Z",
     "start_time": "2023-01-17T23:23:49.922940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([132, 3, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "\n",
    "X_train, y_train = dl.load(DATASET_ROOTDIR, 'files/data_TRA.csv', 'R')\n",
    "X_validation, y_validation = dl.load(DATASET_ROOTDIR, 'files/data_VAL.csv', 'R')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d92a",
   "metadata": {},
   "source": [
    "# RGB + D \n",
    "Na wejście do modelu zostanie podany tensor zawieający kombinację RGB + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2280a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T17:18:42.687191Z",
     "start_time": "2023-01-17T17:18:42.615274Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23db3ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:50.434672Z",
     "start_time": "2023-01-17T22:42:47.604858Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_aug = X_train.clone()\n",
    "\n",
    "for i in range(X_train_aug.shape[0]):\n",
    "     X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "y_train = torch.cat((y_train, y_train),axis=0)\n",
    "X_train = torch.cat((X_train, X_train_aug),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb1b812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:24:01.103228Z",
     "start_time": "2023-01-17T23:24:01.093870Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_trainDataset = TensorDataset(X_train, y_train)\n",
    "AoRD_validationDataset = TensorDataset(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:24:01.453002Z",
     "start_time": "2023-01-17T23:24:01.410345Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AoRD_trainDataset, batch_size=15, shuffle=False)\n",
    "validation_loader = DataLoader(AoRD_validationDataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159076ba",
   "metadata": {},
   "source": [
    "# Wyciąganie pojedyńczego elementu z batcha\n",
    "Można zrobić to na kilka sposobów, ale ten jest najszybszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab99ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:50.469335Z",
     "start_time": "2023-01-17T22:42:50.455181Z"
    }
   },
   "outputs": [],
   "source": [
    "# for b, (X_train, y_train) in enumerate(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "# Stworzenie modelu\n",
    "Nazwałem model AoRNet od angielsiego **A**xis **o**f **R**rotation oraz od nazwy modelu matki Res**Net**`u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0db1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:50.485215Z",
     "start_time": "2023-01-17T22:42:50.471631Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=3, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a67d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:51.710588Z",
     "start_time": "2023-01-17T22:42:50.486506Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = AoRNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0f079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T22:42:51.714775Z",
     "start_time": "2023-01-17T22:42:51.711861Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=10, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad777bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:16:08.597224Z",
     "start_time": "2023-01-17T22:42:51.716287Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch: 1  loss: 1.06668711\n",
      "epoch:  1  batch: 2  loss: 9.56523228\n",
      "epoch:  1  batch: 3  loss: 0.73446572\n",
      "epoch:  1  batch: 4  loss: 0.70586127\n",
      "epoch:  1  batch: 5  loss: 0.91964579\n",
      "epoch:  1  batch: 6  loss: 0.53306264\n",
      "epoch:  1  batch: 7  loss: 0.31962752\n",
      "epoch:  1  batch: 8  loss: 0.30398750\n",
      "epoch:  1  batch: 9  loss: 0.50960398\n",
      "epoch:  1  batch: 10  loss: 0.21543100\n",
      "epoch:  1  batch: 11  loss: 0.22010711\n",
      "epoch:  1  batch: 12  loss: 0.52474064\n",
      "epoch:  1  batch: 13  loss: 1.31413782\n",
      "epoch:  1  batch: 14  loss: 0.23248927\n",
      "epoch:  1  batch: 15  loss: 0.41202676\n",
      "epoch:  1  batch: 16  loss: 0.14192414\n",
      "epoch:  1  batch: 17  loss: 0.36996761\n",
      "epoch:  1  batch: 18  loss: 1.62220871\n",
      "epoch:  1  batch: 19  loss: 0.08510237\n",
      "epoch:  1  batch: 20  loss: 0.25750417\n",
      "epoch:  1  batch: 21  loss: 0.37019435\n",
      "epoch:  1  batch: 22  loss: 0.57556850\n",
      "epoch:  1  batch: 23  loss: 0.53939646\n",
      "epoch:  1  batch: 24  loss: 0.57414198\n",
      "epoch:  1  batch: 25  loss: 0.15966067\n",
      "epoch:  1  batch: 26  loss: 0.33803493\n",
      "epoch:  1  batch: 27  loss: 0.61892742\n",
      "epoch:  1  batch: 28  loss: 0.37605152\n",
      "epoch:  1  batch: 29  loss: 0.40329149\n",
      "epoch:  1  batch: 30  loss: 0.31109011\n",
      "epoch:  1  batch: 31  loss: 0.45378771\n",
      "epoch:  1  batch: 32  loss: 0.27072605\n",
      "epoch:  1  batch: 33  loss: 0.22442414\n",
      "epoch:  1  batch: 34  loss: 0.23509997\n",
      "epoch:  1  batch: 35  loss: 0.33210886\n",
      "epoch:  1  batch: 36  loss: 0.53908169\n",
      "epoch:  1  batch: 37  loss: 0.35850263\n",
      "epoch:  1  batch: 38  loss: 0.14961578\n",
      "epoch:  1  batch: 39  loss: 0.40821472\n",
      "epoch:  1  batch: 40  loss: 0.14739887\n",
      "epoch:  1  batch: 41  loss: 0.42090181\n",
      "epoch:  1  batch: 42  loss: 0.31816584\n",
      "epoch:  1  batch: 43  loss: 0.25769174\n",
      "epoch:  1  batch: 44  loss: 0.11110272\n",
      "epoch:  1  batch: 45  loss: 0.07683591\n",
      "epoch:  1  batch: 46  loss: 0.99893379\n",
      "epoch:  1  batch: 47  loss: 1.08751643\n",
      "epoch:  1  batch: 48  loss: 0.45688275\n",
      "epoch:  1  batch: 49  loss: 0.10760469\n",
      "epoch:  1  batch: 50  loss: 0.21926105\n",
      "epoch:  1  batch: 51  loss: 0.33266729\n",
      "epoch:  1  batch: 52  loss: 0.31277847\n",
      "epoch:  1  batch: 53  loss: 0.34555691\n",
      "epoch:  1  batch: 54  loss: 0.96319580\n",
      "epoch:  1  batch: 55  loss: 0.49488023\n",
      "epoch:  1  batch: 56  loss: 0.27356508\n",
      "epoch:  1  batch: 57  loss: 0.25257698\n",
      "epoch:  1  batch: 58  loss: 0.63011473\n",
      "epoch:  1  batch: 59  loss: 0.48473567\n",
      "epoch:  1  batch: 60  loss: 0.89275903\n",
      "epoch:  1  batch: 61  loss: 1.55976188\n",
      "epoch:  1  batch: 62  loss: 0.36531764\n",
      "epoch:  1  batch: 63  loss: 0.49125972\n",
      "epoch:  1  batch: 64  loss: 0.33116278\n",
      "epoch:  1  batch: 65  loss: 0.43592900\n",
      "epoch:  1  batch: 66  loss: 0.40954384\n",
      "epoch:  1  batch: 67  loss: 0.47882950\n",
      "epoch:  1  batch: 68  loss: 0.44275689\n",
      "epoch:  2  batch: 1  loss: 0.49466181\n",
      "epoch:  2  batch: 2  loss: 0.37131816\n",
      "epoch:  2  batch: 3  loss: 0.47028819\n",
      "epoch:  2  batch: 4  loss: 0.21732654\n",
      "epoch:  2  batch: 5  loss: 0.14392827\n",
      "epoch:  2  batch: 6  loss: 0.17698678\n",
      "epoch:  2  batch: 7  loss: 0.34056026\n",
      "epoch:  2  batch: 8  loss: 0.17644572\n",
      "epoch:  2  batch: 9  loss: 0.15859438\n",
      "epoch:  2  batch: 10  loss: 0.10784364\n",
      "epoch:  2  batch: 11  loss: 0.10191020\n",
      "epoch:  2  batch: 12  loss: 0.35215273\n",
      "epoch:  2  batch: 13  loss: 0.72261220\n",
      "epoch:  2  batch: 14  loss: 0.38317287\n",
      "epoch:  2  batch: 15  loss: 0.21863273\n",
      "epoch:  2  batch: 16  loss: 0.36164594\n",
      "epoch:  2  batch: 17  loss: 0.56485331\n",
      "epoch:  2  batch: 18  loss: 0.24854439\n",
      "epoch:  2  batch: 19  loss: 0.30869013\n",
      "epoch:  2  batch: 20  loss: 0.51366830\n",
      "epoch:  2  batch: 21  loss: 0.48269442\n",
      "epoch:  2  batch: 22  loss: 0.22178818\n",
      "epoch:  2  batch: 23  loss: 0.10813168\n",
      "epoch:  2  batch: 24  loss: 0.24032916\n",
      "epoch:  2  batch: 25  loss: 0.26249680\n",
      "epoch:  2  batch: 26  loss: 0.51632553\n",
      "epoch:  2  batch: 27  loss: 0.62409073\n",
      "epoch:  2  batch: 28  loss: 0.31973961\n",
      "epoch:  2  batch: 29  loss: 0.24764451\n",
      "epoch:  2  batch: 30  loss: 0.13485345\n",
      "epoch:  2  batch: 31  loss: 0.11226190\n",
      "epoch:  2  batch: 32  loss: 0.18681963\n",
      "epoch:  2  batch: 33  loss: 0.23905225\n",
      "epoch:  2  batch: 34  loss: 0.22562163\n",
      "epoch:  2  batch: 35  loss: 0.51123017\n",
      "epoch:  2  batch: 36  loss: 0.22833320\n",
      "epoch:  2  batch: 37  loss: 0.19236654\n",
      "epoch:  2  batch: 38  loss: 0.05178356\n",
      "epoch:  2  batch: 39  loss: 0.35019490\n",
      "epoch:  2  batch: 40  loss: 0.10472579\n",
      "epoch:  2  batch: 41  loss: 0.23180449\n",
      "epoch:  2  batch: 42  loss: 0.20894280\n",
      "epoch:  2  batch: 43  loss: 0.13503452\n",
      "epoch:  2  batch: 44  loss: 0.23857813\n",
      "epoch:  2  batch: 45  loss: 0.14075188\n",
      "epoch:  2  batch: 46  loss: 0.47508642\n",
      "epoch:  2  batch: 47  loss: 0.56273448\n",
      "epoch:  2  batch: 48  loss: 0.31981578\n",
      "epoch:  2  batch: 49  loss: 0.21188575\n",
      "epoch:  2  batch: 50  loss: 0.50318784\n",
      "epoch:  2  batch: 51  loss: 0.43978408\n",
      "epoch:  2  batch: 52  loss: 0.12965848\n",
      "epoch:  2  batch: 53  loss: 0.26673457\n",
      "epoch:  2  batch: 54  loss: 0.54511631\n",
      "epoch:  2  batch: 55  loss: 0.37935191\n",
      "epoch:  2  batch: 56  loss: 0.15542918\n",
      "epoch:  2  batch: 57  loss: 0.09898160\n",
      "epoch:  2  batch: 58  loss: 0.81656605\n",
      "epoch:  2  batch: 59  loss: 0.22695795\n",
      "epoch:  2  batch: 60  loss: 0.63352698\n",
      "epoch:  2  batch: 61  loss: 1.02662706\n",
      "epoch:  2  batch: 62  loss: 0.31316054\n",
      "epoch:  2  batch: 63  loss: 0.27501786\n",
      "epoch:  2  batch: 64  loss: 0.20972472\n",
      "epoch:  2  batch: 65  loss: 0.11888101\n",
      "epoch:  2  batch: 66  loss: 0.20061201\n",
      "epoch:  2  batch: 67  loss: 0.17080571\n",
      "epoch:  2  batch: 68  loss: 0.42167529\n",
      "epoch:  3  batch: 1  loss: 0.63179219\n",
      "epoch:  3  batch: 2  loss: 0.07697301\n",
      "epoch:  3  batch: 3  loss: 0.34856004\n",
      "epoch:  3  batch: 4  loss: 0.21945459\n",
      "epoch:  3  batch: 5  loss: 0.41530001\n",
      "epoch:  3  batch: 6  loss: 0.34933287\n",
      "epoch:  3  batch: 7  loss: 0.34435463\n",
      "epoch:  3  batch: 8  loss: 0.12011757\n",
      "epoch:  3  batch: 9  loss: 0.14503078\n",
      "epoch:  3  batch: 10  loss: 0.14034039\n",
      "epoch:  3  batch: 11  loss: 0.09337902\n",
      "epoch:  3  batch: 12  loss: 0.65271753\n",
      "epoch:  3  batch: 13  loss: 1.18888319\n",
      "epoch:  3  batch: 14  loss: 0.44127157\n",
      "epoch:  3  batch: 15  loss: 0.28120524\n",
      "epoch:  3  batch: 16  loss: 0.25888249\n",
      "epoch:  3  batch: 17  loss: 0.69870007\n",
      "epoch:  3  batch: 18  loss: 0.19087340\n",
      "epoch:  3  batch: 19  loss: 0.32062191\n",
      "epoch:  3  batch: 20  loss: 0.88629347\n",
      "epoch:  3  batch: 21  loss: 0.68200177\n",
      "epoch:  3  batch: 22  loss: 0.27753383\n",
      "epoch:  3  batch: 23  loss: 0.28515416\n",
      "epoch:  3  batch: 24  loss: 0.38003665\n",
      "epoch:  3  batch: 25  loss: 0.36214885\n",
      "epoch:  3  batch: 26  loss: 0.66939855\n",
      "epoch:  3  batch: 27  loss: 0.94137120\n",
      "epoch:  3  batch: 28  loss: 0.45706686\n",
      "epoch:  3  batch: 29  loss: 0.33656994\n",
      "epoch:  3  batch: 30  loss: 0.21992184\n",
      "epoch:  3  batch: 31  loss: 0.34032145\n",
      "epoch:  3  batch: 32  loss: 0.30007714\n",
      "epoch:  3  batch: 33  loss: 0.53524178\n",
      "epoch:  3  batch: 34  loss: 0.33711952\n",
      "epoch:  3  batch: 35  loss: 0.65788519\n",
      "epoch:  3  batch: 36  loss: 0.16717178\n",
      "epoch:  3  batch: 37  loss: 0.20160091\n",
      "epoch:  3  batch: 38  loss: 0.23707043\n",
      "epoch:  3  batch: 39  loss: 0.10814147\n",
      "epoch:  3  batch: 40  loss: 0.12308808\n",
      "epoch:  3  batch: 41  loss: 0.21906175\n",
      "epoch:  3  batch: 42  loss: 0.10976485\n",
      "epoch:  3  batch: 43  loss: 0.17807212\n",
      "epoch:  3  batch: 44  loss: 0.15409517\n",
      "epoch:  3  batch: 45  loss: 0.10184862\n",
      "epoch:  3  batch: 46  loss: 0.51934457\n",
      "epoch:  3  batch: 47  loss: 0.60450739\n",
      "epoch:  3  batch: 48  loss: 0.35575074\n",
      "epoch:  3  batch: 49  loss: 0.18488723\n",
      "epoch:  3  batch: 50  loss: 0.38032970\n",
      "epoch:  3  batch: 51  loss: 0.38354349\n",
      "epoch:  3  batch: 52  loss: 0.14414620\n",
      "epoch:  3  batch: 53  loss: 0.19742291\n",
      "epoch:  3  batch: 54  loss: 0.59797561\n",
      "epoch:  3  batch: 55  loss: 0.36137119\n",
      "epoch:  3  batch: 56  loss: 0.18453878\n",
      "epoch:  3  batch: 57  loss: 0.08111423\n",
      "epoch:  3  batch: 58  loss: 0.46568468\n",
      "epoch:  3  batch: 59  loss: 0.38130665\n",
      "epoch:  3  batch: 60  loss: 0.45377034\n",
      "epoch:  3  batch: 61  loss: 0.81747878\n",
      "epoch:  3  batch: 62  loss: 0.22721390\n",
      "epoch:  3  batch: 63  loss: 0.27306843\n",
      "epoch:  3  batch: 64  loss: 0.12874824\n",
      "epoch:  3  batch: 65  loss: 0.24416491\n",
      "epoch:  3  batch: 66  loss: 0.51697361\n",
      "epoch:  3  batch: 67  loss: 0.20416307\n",
      "epoch:  3  batch: 68  loss: 0.49694875\n",
      "epoch:  4  batch: 1  loss: 0.44841161\n",
      "epoch:  4  batch: 2  loss: 0.14732412\n",
      "epoch:  4  batch: 3  loss: 0.11494049\n",
      "epoch:  4  batch: 4  loss: 0.10016324\n",
      "epoch:  4  batch: 5  loss: 0.20288628\n",
      "epoch:  4  batch: 6  loss: 0.15297045\n",
      "epoch:  4  batch: 7  loss: 0.23787066\n",
      "epoch:  4  batch: 8  loss: 0.07875828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4  batch: 9  loss: 0.05999782\n",
      "epoch:  4  batch: 10  loss: 0.07216310\n",
      "epoch:  4  batch: 11  loss: 0.06718153\n",
      "epoch:  4  batch: 12  loss: 0.43939304\n",
      "epoch:  4  batch: 13  loss: 0.84218115\n",
      "epoch:  4  batch: 14  loss: 0.28681472\n",
      "epoch:  4  batch: 15  loss: 0.15543585\n",
      "epoch:  4  batch: 16  loss: 0.27661842\n",
      "epoch:  4  batch: 17  loss: 0.33213997\n",
      "epoch:  4  batch: 18  loss: 0.15067542\n",
      "epoch:  4  batch: 19  loss: 0.14844562\n",
      "epoch:  4  batch: 20  loss: 0.60561073\n",
      "epoch:  4  batch: 21  loss: 0.47889447\n",
      "epoch:  4  batch: 22  loss: 0.13665348\n",
      "epoch:  4  batch: 23  loss: 0.15573990\n",
      "epoch:  4  batch: 24  loss: 0.22916476\n",
      "epoch:  4  batch: 25  loss: 0.15913332\n",
      "epoch:  4  batch: 26  loss: 0.46039471\n",
      "epoch:  4  batch: 27  loss: 0.85527074\n",
      "epoch:  4  batch: 28  loss: 0.42611942\n",
      "epoch:  4  batch: 29  loss: 0.26944241\n",
      "epoch:  4  batch: 30  loss: 0.16729744\n",
      "epoch:  4  batch: 31  loss: 0.11620615\n",
      "epoch:  4  batch: 32  loss: 0.26411849\n",
      "epoch:  4  batch: 33  loss: 0.23738635\n",
      "epoch:  4  batch: 34  loss: 0.23503251\n",
      "epoch:  4  batch: 35  loss: 0.25777948\n",
      "epoch:  4  batch: 36  loss: 0.06376857\n",
      "epoch:  4  batch: 37  loss: 0.04788593\n",
      "epoch:  4  batch: 38  loss: 0.04794438\n",
      "epoch:  4  batch: 39  loss: 0.17024414\n",
      "epoch:  4  batch: 40  loss: 0.07160904\n",
      "epoch:  4  batch: 41  loss: 0.19637206\n",
      "epoch:  4  batch: 42  loss: 0.20835610\n",
      "epoch:  4  batch: 43  loss: 0.19286405\n",
      "epoch:  4  batch: 44  loss: 0.17197345\n",
      "epoch:  4  batch: 45  loss: 0.12750013\n",
      "epoch:  4  batch: 46  loss: 0.42623901\n",
      "epoch:  4  batch: 47  loss: 0.55120319\n",
      "epoch:  4  batch: 48  loss: 0.28375199\n",
      "epoch:  4  batch: 49  loss: 0.20817716\n",
      "epoch:  4  batch: 50  loss: 0.42202064\n",
      "epoch:  4  batch: 51  loss: 0.37830108\n",
      "epoch:  4  batch: 52  loss: 0.12164413\n",
      "epoch:  4  batch: 53  loss: 0.21963751\n",
      "epoch:  4  batch: 54  loss: 0.47424924\n",
      "epoch:  4  batch: 55  loss: 0.35030252\n",
      "epoch:  4  batch: 56  loss: 0.16156340\n",
      "epoch:  4  batch: 57  loss: 0.09000270\n",
      "epoch:  4  batch: 58  loss: 0.26801938\n",
      "epoch:  4  batch: 59  loss: 0.23602882\n",
      "epoch:  4  batch: 60  loss: 0.33890781\n",
      "epoch:  4  batch: 61  loss: 0.70044565\n",
      "epoch:  4  batch: 62  loss: 0.23372835\n",
      "epoch:  4  batch: 63  loss: 0.18597341\n",
      "epoch:  4  batch: 64  loss: 0.14672558\n",
      "epoch:  4  batch: 65  loss: 0.06207997\n",
      "epoch:  4  batch: 66  loss: 0.21489814\n",
      "epoch:  4  batch: 67  loss: 0.27639914\n",
      "epoch:  4  batch: 68  loss: 0.26950616\n",
      "epoch:  5  batch: 1  loss: 0.39227059\n",
      "epoch:  5  batch: 2  loss: 0.05312258\n",
      "epoch:  5  batch: 3  loss: 0.21336946\n",
      "epoch:  5  batch: 4  loss: 0.05975482\n",
      "epoch:  5  batch: 5  loss: 0.23029511\n",
      "epoch:  5  batch: 6  loss: 0.12803529\n",
      "epoch:  5  batch: 7  loss: 0.33345780\n",
      "epoch:  5  batch: 8  loss: 0.06371703\n",
      "epoch:  5  batch: 9  loss: 0.17917189\n",
      "epoch:  5  batch: 10  loss: 0.08286013\n",
      "epoch:  5  batch: 11  loss: 0.08482324\n",
      "epoch:  5  batch: 12  loss: 0.54014748\n",
      "epoch:  5  batch: 13  loss: 0.86253136\n",
      "epoch:  5  batch: 14  loss: 0.37460375\n",
      "epoch:  5  batch: 15  loss: 0.23847856\n",
      "epoch:  5  batch: 16  loss: 0.35965800\n",
      "epoch:  5  batch: 17  loss: 0.60830098\n",
      "epoch:  5  batch: 18  loss: 0.11680655\n",
      "epoch:  5  batch: 19  loss: 0.14021583\n",
      "epoch:  5  batch: 20  loss: 0.50280368\n",
      "epoch:  5  batch: 21  loss: 0.49318197\n",
      "epoch:  5  batch: 22  loss: 0.17486630\n",
      "epoch:  5  batch: 23  loss: 0.12029222\n",
      "epoch:  5  batch: 24  loss: 0.16351816\n",
      "epoch:  5  batch: 25  loss: 0.37361923\n",
      "epoch:  5  batch: 26  loss: 0.36984941\n",
      "epoch:  5  batch: 27  loss: 0.40233833\n",
      "epoch:  5  batch: 28  loss: 0.29837614\n",
      "epoch:  5  batch: 29  loss: 0.17869386\n",
      "epoch:  5  batch: 30  loss: 0.11688288\n",
      "epoch:  5  batch: 31  loss: 0.08991178\n",
      "epoch:  5  batch: 32  loss: 0.06734601\n",
      "epoch:  5  batch: 33  loss: 0.14486715\n",
      "epoch:  5  batch: 34  loss: 0.13402377\n",
      "epoch:  5  batch: 35  loss: 0.25723538\n",
      "epoch:  5  batch: 36  loss: 0.07222526\n",
      "epoch:  5  batch: 37  loss: 0.06508493\n",
      "epoch:  5  batch: 38  loss: 0.03784666\n",
      "epoch:  5  batch: 39  loss: 0.25233391\n",
      "epoch:  5  batch: 40  loss: 0.09221084\n",
      "epoch:  5  batch: 41  loss: 0.28703436\n",
      "epoch:  5  batch: 42  loss: 0.16321710\n",
      "epoch:  5  batch: 43  loss: 0.15934713\n",
      "epoch:  5  batch: 44  loss: 0.22754151\n",
      "epoch:  5  batch: 45  loss: 0.18844563\n",
      "epoch:  5  batch: 46  loss: 0.36907336\n",
      "epoch:  5  batch: 47  loss: 0.48168260\n",
      "epoch:  5  batch: 48  loss: 0.26029080\n",
      "epoch:  5  batch: 49  loss: 0.20963135\n",
      "epoch:  5  batch: 50  loss: 0.39170787\n",
      "epoch:  5  batch: 51  loss: 0.33704314\n",
      "epoch:  5  batch: 52  loss: 0.13056920\n",
      "epoch:  5  batch: 53  loss: 0.17935506\n",
      "epoch:  5  batch: 54  loss: 0.42571497\n",
      "epoch:  5  batch: 55  loss: 0.27988720\n",
      "epoch:  5  batch: 56  loss: 0.12773737\n",
      "epoch:  5  batch: 57  loss: 0.10123054\n",
      "epoch:  5  batch: 58  loss: 0.17520647\n",
      "epoch:  5  batch: 59  loss: 0.13777591\n",
      "epoch:  5  batch: 60  loss: 0.46707433\n",
      "epoch:  5  batch: 61  loss: 0.67436755\n",
      "epoch:  5  batch: 62  loss: 0.20494436\n",
      "epoch:  5  batch: 63  loss: 0.15164125\n",
      "epoch:  5  batch: 64  loss: 0.22070818\n",
      "epoch:  5  batch: 65  loss: 0.06986513\n",
      "epoch:  5  batch: 66  loss: 0.17173599\n",
      "epoch:  5  batch: 67  loss: 0.28211507\n",
      "epoch:  5  batch: 68  loss: 0.38476709\n",
      "epoch:  6  batch: 1  loss: 0.90371960\n",
      "epoch:  6  batch: 2  loss: 0.06690460\n",
      "epoch:  6  batch: 3  loss: 0.12988056\n",
      "epoch:  6  batch: 4  loss: 0.03072532\n",
      "epoch:  6  batch: 5  loss: 0.16483070\n",
      "epoch:  6  batch: 6  loss: 0.10983773\n",
      "epoch:  6  batch: 7  loss: 0.31574458\n",
      "epoch:  6  batch: 8  loss: 0.08408578\n",
      "epoch:  6  batch: 9  loss: 0.13176103\n",
      "epoch:  6  batch: 10  loss: 0.12245083\n",
      "epoch:  6  batch: 11  loss: 0.16468920\n",
      "epoch:  6  batch: 12  loss: 0.16458656\n",
      "epoch:  6  batch: 13  loss: 0.80195940\n",
      "epoch:  6  batch: 14  loss: 0.35534596\n",
      "epoch:  6  batch: 15  loss: 0.27705321\n",
      "epoch:  6  batch: 16  loss: 0.34626248\n",
      "epoch:  6  batch: 17  loss: 0.77369750\n",
      "epoch:  6  batch: 18  loss: 0.24621865\n",
      "epoch:  6  batch: 19  loss: 0.14200339\n",
      "epoch:  6  batch: 20  loss: 0.46010095\n",
      "epoch:  6  batch: 21  loss: 0.51443392\n",
      "epoch:  6  batch: 22  loss: 0.18259554\n",
      "epoch:  6  batch: 23  loss: 0.10415490\n",
      "epoch:  6  batch: 24  loss: 0.16183335\n",
      "epoch:  6  batch: 25  loss: 0.11679883\n",
      "epoch:  6  batch: 26  loss: 0.47028902\n",
      "epoch:  6  batch: 27  loss: 0.66767102\n",
      "epoch:  6  batch: 28  loss: 0.49349672\n",
      "epoch:  6  batch: 29  loss: 0.26942015\n",
      "epoch:  6  batch: 30  loss: 0.16085775\n",
      "epoch:  6  batch: 31  loss: 0.10543453\n",
      "epoch:  6  batch: 32  loss: 0.08106861\n",
      "epoch:  6  batch: 33  loss: 0.14657180\n",
      "epoch:  6  batch: 34  loss: 0.36773688\n",
      "epoch:  6  batch: 35  loss: 0.27978405\n",
      "epoch:  6  batch: 36  loss: 0.11276819\n",
      "epoch:  6  batch: 37  loss: 0.08017574\n",
      "epoch:  6  batch: 38  loss: 0.04557683\n",
      "epoch:  6  batch: 39  loss: 0.18583196\n",
      "epoch:  6  batch: 40  loss: 0.07905156\n",
      "epoch:  6  batch: 41  loss: 0.26400065\n",
      "epoch:  6  batch: 42  loss: 0.18572286\n",
      "epoch:  6  batch: 43  loss: 0.18802221\n",
      "epoch:  6  batch: 44  loss: 0.24233711\n",
      "epoch:  6  batch: 45  loss: 0.18770434\n",
      "epoch:  6  batch: 46  loss: 0.29626876\n",
      "epoch:  6  batch: 47  loss: 0.38977417\n",
      "epoch:  6  batch: 48  loss: 0.21601622\n",
      "epoch:  6  batch: 49  loss: 0.23325263\n",
      "epoch:  6  batch: 50  loss: 0.39535359\n",
      "epoch:  6  batch: 51  loss: 0.27891636\n",
      "epoch:  6  batch: 52  loss: 0.14466961\n",
      "epoch:  6  batch: 53  loss: 0.14613277\n",
      "epoch:  6  batch: 54  loss: 0.37821785\n",
      "epoch:  6  batch: 55  loss: 0.22847138\n",
      "epoch:  6  batch: 56  loss: 0.08501039\n",
      "epoch:  6  batch: 57  loss: 0.08724321\n",
      "epoch:  6  batch: 58  loss: 0.18912828\n",
      "epoch:  6  batch: 59  loss: 0.17815344\n",
      "epoch:  6  batch: 60  loss: 0.49366558\n",
      "epoch:  6  batch: 61  loss: 0.62620741\n",
      "epoch:  6  batch: 62  loss: 0.28727257\n",
      "epoch:  6  batch: 63  loss: 0.21853887\n",
      "epoch:  6  batch: 64  loss: 0.17177150\n",
      "epoch:  6  batch: 65  loss: 0.06784642\n",
      "epoch:  6  batch: 66  loss: 0.11975160\n",
      "epoch:  6  batch: 67  loss: 0.26291665\n",
      "epoch:  6  batch: 68  loss: 0.58479410\n",
      "epoch:  7  batch: 1  loss: 0.77974975\n",
      "epoch:  7  batch: 2  loss: 0.06579866\n",
      "epoch:  7  batch: 3  loss: 0.18807314\n",
      "epoch:  7  batch: 4  loss: 0.05747570\n",
      "epoch:  7  batch: 5  loss: 0.20300853\n",
      "epoch:  7  batch: 6  loss: 0.18829826\n",
      "epoch:  7  batch: 7  loss: 0.32581168\n",
      "epoch:  7  batch: 8  loss: 0.11666936\n",
      "epoch:  7  batch: 9  loss: 0.11281078\n",
      "epoch:  7  batch: 10  loss: 0.18565093\n",
      "epoch:  7  batch: 11  loss: 0.16142543\n",
      "epoch:  7  batch: 12  loss: 0.50063378\n",
      "epoch:  7  batch: 13  loss: 0.83600497\n",
      "epoch:  7  batch: 14  loss: 0.31122276\n",
      "epoch:  7  batch: 15  loss: 0.30128059\n",
      "epoch:  7  batch: 16  loss: 0.46798581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7  batch: 17  loss: 0.73681813\n",
      "epoch:  7  batch: 18  loss: 0.23020957\n",
      "epoch:  7  batch: 19  loss: 0.19736888\n",
      "epoch:  7  batch: 20  loss: 0.39933139\n",
      "epoch:  7  batch: 21  loss: 0.40251186\n",
      "epoch:  7  batch: 22  loss: 0.12810956\n",
      "epoch:  7  batch: 23  loss: 0.07512070\n",
      "epoch:  7  batch: 24  loss: 0.10233276\n",
      "epoch:  7  batch: 25  loss: 0.11058415\n",
      "epoch:  7  batch: 26  loss: 0.56936234\n",
      "epoch:  7  batch: 27  loss: 0.80324954\n",
      "epoch:  7  batch: 28  loss: 0.35701466\n",
      "epoch:  7  batch: 29  loss: 0.12047467\n",
      "epoch:  7  batch: 30  loss: 0.05278700\n",
      "epoch:  7  batch: 31  loss: 0.11895305\n",
      "epoch:  7  batch: 32  loss: 0.13926420\n",
      "epoch:  7  batch: 33  loss: 0.27744827\n",
      "epoch:  7  batch: 34  loss: 0.22407335\n",
      "epoch:  7  batch: 35  loss: 0.26579958\n",
      "epoch:  7  batch: 36  loss: 0.04672844\n",
      "epoch:  7  batch: 37  loss: 0.11092166\n",
      "epoch:  7  batch: 38  loss: 0.05031622\n",
      "epoch:  7  batch: 39  loss: 0.23462702\n",
      "epoch:  7  batch: 40  loss: 0.09746787\n",
      "epoch:  7  batch: 41  loss: 0.22880457\n",
      "epoch:  7  batch: 42  loss: 0.16272815\n",
      "epoch:  7  batch: 43  loss: 0.20582440\n",
      "epoch:  7  batch: 44  loss: 0.16802178\n",
      "epoch:  7  batch: 45  loss: 0.19438185\n",
      "epoch:  7  batch: 46  loss: 0.41805413\n",
      "epoch:  7  batch: 47  loss: 0.49285516\n",
      "epoch:  7  batch: 48  loss: 0.39010927\n",
      "epoch:  7  batch: 49  loss: 0.21531068\n",
      "epoch:  7  batch: 50  loss: 0.41595203\n",
      "epoch:  7  batch: 51  loss: 0.39785615\n",
      "epoch:  7  batch: 52  loss: 0.13464375\n",
      "epoch:  7  batch: 53  loss: 0.30232868\n",
      "epoch:  7  batch: 54  loss: 0.53576660\n",
      "epoch:  7  batch: 55  loss: 0.35219508\n",
      "epoch:  7  batch: 56  loss: 0.16571584\n",
      "epoch:  7  batch: 57  loss: 0.09489011\n",
      "epoch:  7  batch: 58  loss: 0.09821926\n",
      "epoch:  7  batch: 59  loss: 0.20358434\n",
      "epoch:  7  batch: 60  loss: 0.38240975\n",
      "epoch:  7  batch: 61  loss: 0.66496229\n",
      "epoch:  7  batch: 62  loss: 0.16896157\n",
      "epoch:  7  batch: 63  loss: 0.22536568\n",
      "epoch:  7  batch: 64  loss: 0.12997082\n",
      "epoch:  7  batch: 65  loss: 0.08936293\n",
      "epoch:  7  batch: 66  loss: 0.19686513\n",
      "epoch:  7  batch: 67  loss: 0.22792825\n",
      "epoch:  7  batch: 68  loss: 0.36395332\n",
      "epoch:  8  batch: 1  loss: 0.38129035\n",
      "epoch:  8  batch: 2  loss: 0.07570038\n",
      "epoch:  8  batch: 3  loss: 0.05938546\n",
      "epoch:  8  batch: 4  loss: 0.08846525\n",
      "epoch:  8  batch: 5  loss: 0.13854265\n",
      "epoch:  8  batch: 6  loss: 0.21897316\n",
      "epoch:  8  batch: 7  loss: 0.29194054\n",
      "epoch:  8  batch: 8  loss: 0.10956969\n",
      "epoch:  8  batch: 9  loss: 0.12691638\n",
      "epoch:  8  batch: 10  loss: 0.14394040\n",
      "epoch:  8  batch: 11  loss: 0.16565457\n",
      "epoch:  8  batch: 12  loss: 0.37160060\n",
      "epoch:  8  batch: 13  loss: 0.59303617\n",
      "epoch:  8  batch: 14  loss: 0.31405306\n",
      "epoch:  8  batch: 15  loss: 0.29385063\n",
      "epoch:  8  batch: 16  loss: 0.34620211\n",
      "epoch:  8  batch: 17  loss: 0.49715754\n",
      "epoch:  8  batch: 18  loss: 0.21881092\n",
      "epoch:  8  batch: 19  loss: 0.15067837\n",
      "epoch:  8  batch: 20  loss: 0.31042472\n",
      "epoch:  8  batch: 21  loss: 0.35038891\n",
      "epoch:  8  batch: 22  loss: 0.12519540\n",
      "epoch:  8  batch: 23  loss: 0.05681220\n",
      "epoch:  8  batch: 24  loss: 0.18630755\n",
      "epoch:  8  batch: 25  loss: 0.21790208\n",
      "epoch:  8  batch: 26  loss: 0.25001597\n",
      "epoch:  8  batch: 27  loss: 0.60928863\n",
      "epoch:  8  batch: 28  loss: 0.22850311\n",
      "epoch:  8  batch: 29  loss: 0.14012057\n",
      "epoch:  8  batch: 30  loss: 0.11314921\n",
      "epoch:  8  batch: 31  loss: 0.15121619\n",
      "epoch:  8  batch: 32  loss: 0.21473250\n",
      "epoch:  8  batch: 33  loss: 0.38764301\n",
      "epoch:  8  batch: 34  loss: 0.33666903\n",
      "epoch:  8  batch: 35  loss: 0.35952544\n",
      "epoch:  8  batch: 36  loss: 0.06923740\n",
      "epoch:  8  batch: 37  loss: 0.05093639\n",
      "epoch:  8  batch: 38  loss: 0.05393123\n",
      "epoch:  8  batch: 39  loss: 0.15274315\n",
      "epoch:  8  batch: 40  loss: 0.07942687\n",
      "epoch:  8  batch: 41  loss: 0.22758478\n",
      "epoch:  8  batch: 42  loss: 0.09089712\n",
      "epoch:  8  batch: 43  loss: 0.08637127\n",
      "epoch:  8  batch: 44  loss: 0.12184699\n",
      "epoch:  8  batch: 45  loss: 0.10163124\n",
      "epoch:  8  batch: 46  loss: 0.44007647\n",
      "epoch:  8  batch: 47  loss: 0.55313104\n",
      "epoch:  8  batch: 48  loss: 0.31374255\n",
      "epoch:  8  batch: 49  loss: 0.20505568\n",
      "epoch:  8  batch: 50  loss: 0.44784021\n",
      "epoch:  8  batch: 51  loss: 0.37398157\n",
      "epoch:  8  batch: 52  loss: 0.11400522\n",
      "epoch:  8  batch: 53  loss: 0.19639893\n",
      "epoch:  8  batch: 54  loss: 0.42117107\n",
      "epoch:  8  batch: 55  loss: 0.29212028\n",
      "epoch:  8  batch: 56  loss: 0.11834674\n",
      "epoch:  8  batch: 57  loss: 0.09155664\n",
      "epoch:  8  batch: 58  loss: 0.15378837\n",
      "epoch:  8  batch: 59  loss: 0.18680085\n",
      "epoch:  8  batch: 60  loss: 0.27814382\n",
      "epoch:  8  batch: 61  loss: 0.66573215\n",
      "epoch:  8  batch: 62  loss: 0.13663070\n",
      "epoch:  8  batch: 63  loss: 0.25393072\n",
      "epoch:  8  batch: 64  loss: 0.09083194\n",
      "epoch:  8  batch: 65  loss: 0.05790118\n",
      "epoch:  8  batch: 66  loss: 0.21594010\n",
      "epoch:  8  batch: 67  loss: 0.29596350\n",
      "epoch:  8  batch: 68  loss: 0.26661986\n",
      "epoch:  9  batch: 1  loss: 0.34721994\n",
      "epoch:  9  batch: 2  loss: 0.18980086\n",
      "epoch:  9  batch: 3  loss: 0.06960593\n",
      "epoch:  9  batch: 4  loss: 0.03826468\n",
      "epoch:  9  batch: 5  loss: 0.21099332\n",
      "epoch:  9  batch: 6  loss: 0.12010458\n",
      "epoch:  9  batch: 7  loss: 0.22096573\n",
      "epoch:  9  batch: 8  loss: 0.06741922\n",
      "epoch:  9  batch: 9  loss: 0.14760442\n",
      "epoch:  9  batch: 10  loss: 0.16120207\n",
      "epoch:  9  batch: 11  loss: 0.13422751\n",
      "epoch:  9  batch: 12  loss: 0.33264387\n",
      "epoch:  9  batch: 13  loss: 0.64442497\n",
      "epoch:  9  batch: 14  loss: 0.34071857\n",
      "epoch:  9  batch: 15  loss: 0.29539257\n",
      "epoch:  9  batch: 16  loss: 0.39237592\n",
      "epoch:  9  batch: 17  loss: 0.61634898\n",
      "epoch:  9  batch: 18  loss: 0.19320363\n",
      "epoch:  9  batch: 19  loss: 0.16159546\n",
      "epoch:  9  batch: 20  loss: 0.32613185\n",
      "epoch:  9  batch: 21  loss: 0.35850722\n",
      "epoch:  9  batch: 22  loss: 0.09332382\n",
      "epoch:  9  batch: 23  loss: 0.07017732\n",
      "epoch:  9  batch: 24  loss: 0.08476864\n",
      "epoch:  9  batch: 25  loss: 0.17237458\n",
      "epoch:  9  batch: 26  loss: 0.20549022\n",
      "epoch:  9  batch: 27  loss: 0.59526563\n",
      "epoch:  9  batch: 28  loss: 0.19986153\n",
      "epoch:  9  batch: 29  loss: 0.12530443\n",
      "epoch:  9  batch: 30  loss: 0.08010181\n",
      "epoch:  9  batch: 31  loss: 0.11451735\n",
      "epoch:  9  batch: 32  loss: 0.28003141\n",
      "epoch:  9  batch: 33  loss: 0.23977880\n",
      "epoch:  9  batch: 34  loss: 0.12322571\n",
      "epoch:  9  batch: 35  loss: 0.30828968\n",
      "epoch:  9  batch: 36  loss: 0.10622905\n",
      "epoch:  9  batch: 37  loss: 0.11521643\n",
      "epoch:  9  batch: 38  loss: 0.06937488\n",
      "epoch:  9  batch: 39  loss: 0.32525510\n",
      "epoch:  9  batch: 40  loss: 0.09656635\n",
      "epoch:  9  batch: 41  loss: 0.24941210\n",
      "epoch:  9  batch: 42  loss: 0.11842211\n",
      "epoch:  9  batch: 43  loss: 0.10367171\n",
      "epoch:  9  batch: 44  loss: 0.16770943\n",
      "epoch:  9  batch: 45  loss: 0.15386699\n",
      "epoch:  9  batch: 46  loss: 0.40002698\n",
      "epoch:  9  batch: 47  loss: 0.53634262\n",
      "epoch:  9  batch: 48  loss: 0.36918998\n",
      "epoch:  9  batch: 49  loss: 0.22850473\n",
      "epoch:  9  batch: 50  loss: 0.47879174\n",
      "epoch:  9  batch: 51  loss: 0.39196146\n",
      "epoch:  9  batch: 52  loss: 0.19230105\n",
      "epoch:  9  batch: 53  loss: 0.23571604\n",
      "epoch:  9  batch: 54  loss: 0.37134147\n",
      "epoch:  9  batch: 55  loss: 0.24845548\n",
      "epoch:  9  batch: 56  loss: 0.09870283\n",
      "epoch:  9  batch: 57  loss: 0.07854744\n",
      "epoch:  9  batch: 58  loss: 0.10064153\n",
      "epoch:  9  batch: 59  loss: 0.14795567\n",
      "epoch:  9  batch: 60  loss: 0.40921208\n",
      "epoch:  9  batch: 61  loss: 0.74029273\n",
      "epoch:  9  batch: 62  loss: 0.17345834\n",
      "epoch:  9  batch: 63  loss: 0.28085241\n",
      "epoch:  9  batch: 64  loss: 0.09148015\n",
      "epoch:  9  batch: 65  loss: 0.11172166\n",
      "epoch:  9  batch: 66  loss: 0.21461770\n",
      "epoch:  9  batch: 67  loss: 0.25579634\n",
      "epoch:  9  batch: 68  loss: 0.37513393\n",
      "epoch: 10  batch: 1  loss: 0.31564230\n",
      "epoch: 10  batch: 2  loss: 0.19305092\n",
      "epoch: 10  batch: 3  loss: 0.13260041\n",
      "epoch: 10  batch: 4  loss: 0.05698233\n",
      "epoch: 10  batch: 5  loss: 0.19542974\n",
      "epoch: 10  batch: 6  loss: 0.13912214\n",
      "epoch: 10  batch: 7  loss: 0.31437862\n",
      "epoch: 10  batch: 8  loss: 0.08390700\n",
      "epoch: 10  batch: 9  loss: 0.14463590\n",
      "epoch: 10  batch: 10  loss: 0.12406122\n",
      "epoch: 10  batch: 11  loss: 0.12050179\n",
      "epoch: 10  batch: 12  loss: 0.28452489\n",
      "epoch: 10  batch: 13  loss: 0.66827071\n",
      "epoch: 10  batch: 14  loss: 0.41170561\n",
      "epoch: 10  batch: 15  loss: 0.18080987\n",
      "epoch: 10  batch: 16  loss: 0.44357219\n",
      "epoch: 10  batch: 17  loss: 0.61713159\n",
      "epoch: 10  batch: 18  loss: 0.20357087\n",
      "epoch: 10  batch: 19  loss: 0.20063956\n",
      "epoch: 10  batch: 20  loss: 0.38222605\n",
      "epoch: 10  batch: 21  loss: 0.43081132\n",
      "epoch: 10  batch: 22  loss: 0.10211336\n",
      "epoch: 10  batch: 23  loss: 0.07626511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10  batch: 24  loss: 0.05373032\n",
      "epoch: 10  batch: 25  loss: 0.11455397\n",
      "epoch: 10  batch: 26  loss: 0.25851691\n",
      "epoch: 10  batch: 27  loss: 0.81448102\n",
      "epoch: 10  batch: 28  loss: 0.26181433\n",
      "epoch: 10  batch: 29  loss: 0.21030720\n",
      "epoch: 10  batch: 30  loss: 0.12950009\n",
      "epoch: 10  batch: 31  loss: 0.07002777\n",
      "epoch: 10  batch: 32  loss: 0.18805432\n",
      "epoch: 10  batch: 33  loss: 0.25237793\n",
      "epoch: 10  batch: 34  loss: 0.20595628\n",
      "epoch: 10  batch: 35  loss: 0.39444453\n",
      "epoch: 10  batch: 36  loss: 0.09282320\n",
      "epoch: 10  batch: 37  loss: 0.10343486\n",
      "epoch: 10  batch: 38  loss: 0.18261181\n",
      "epoch: 10  batch: 39  loss: 0.27340695\n",
      "epoch: 10  batch: 40  loss: 0.13586743\n",
      "epoch: 10  batch: 41  loss: 0.26689366\n",
      "epoch: 10  batch: 42  loss: 0.25269276\n",
      "epoch: 10  batch: 43  loss: 0.18461604\n",
      "epoch: 10  batch: 44  loss: 0.21001142\n",
      "epoch: 10  batch: 45  loss: 0.23847723\n",
      "epoch: 10  batch: 46  loss: 0.28099933\n",
      "epoch: 10  batch: 47  loss: 0.37562740\n",
      "epoch: 10  batch: 48  loss: 0.26668465\n",
      "epoch: 10  batch: 49  loss: 0.19576433\n",
      "epoch: 10  batch: 50  loss: 0.38757342\n",
      "epoch: 10  batch: 51  loss: 0.34136030\n",
      "epoch: 10  batch: 52  loss: 0.19991536\n",
      "epoch: 10  batch: 53  loss: 0.28483984\n",
      "epoch: 10  batch: 54  loss: 0.44172809\n",
      "epoch: 10  batch: 55  loss: 0.25218895\n",
      "epoch: 10  batch: 56  loss: 0.10613060\n",
      "epoch: 10  batch: 57  loss: 0.10393647\n",
      "epoch: 10  batch: 58  loss: 0.11255695\n",
      "epoch: 10  batch: 59  loss: 0.13533033\n",
      "epoch: 10  batch: 60  loss: 0.37025651\n",
      "epoch: 10  batch: 61  loss: 0.78632593\n",
      "epoch: 10  batch: 62  loss: 0.20482977\n",
      "epoch: 10  batch: 63  loss: 0.28542596\n",
      "epoch: 10  batch: 64  loss: 0.11743785\n",
      "epoch: 10  batch: 65  loss: 0.05581502\n",
      "epoch: 10  batch: 66  loss: 0.32132378\n",
      "epoch: 10  batch: 67  loss: 0.38791454\n",
      "epoch: 10  batch: 68  loss: 0.42240825\n",
      "epoch: 11  batch: 1  loss: 0.27548155\n",
      "epoch: 11  batch: 2  loss: 0.07934873\n",
      "epoch: 11  batch: 3  loss: 0.08403097\n",
      "epoch: 11  batch: 4  loss: 0.03498290\n",
      "epoch: 11  batch: 5  loss: 0.11942592\n",
      "epoch: 11  batch: 6  loss: 0.10172918\n",
      "epoch: 11  batch: 7  loss: 0.26154697\n",
      "epoch: 11  batch: 8  loss: 0.07337928\n",
      "epoch: 11  batch: 9  loss: 0.09711232\n",
      "epoch: 11  batch: 10  loss: 0.11164763\n",
      "epoch: 11  batch: 11  loss: 0.14838792\n",
      "epoch: 11  batch: 12  loss: 0.32911533\n",
      "epoch: 11  batch: 13  loss: 0.72814858\n",
      "epoch: 11  batch: 14  loss: 0.31970054\n",
      "epoch: 11  batch: 15  loss: 0.17625432\n",
      "epoch: 11  batch: 16  loss: 0.30207729\n",
      "epoch: 11  batch: 17  loss: 0.41461399\n",
      "epoch: 11  batch: 18  loss: 0.08261149\n",
      "epoch: 11  batch: 19  loss: 0.07826302\n",
      "epoch: 11  batch: 20  loss: 0.39851278\n",
      "epoch: 11  batch: 21  loss: 0.46418077\n",
      "epoch: 11  batch: 22  loss: 0.15587555\n",
      "epoch: 11  batch: 23  loss: 0.08961619\n",
      "epoch: 11  batch: 24  loss: 0.13180241\n",
      "epoch: 11  batch: 25  loss: 0.20999832\n",
      "epoch: 11  batch: 26  loss: 0.12588531\n",
      "epoch: 11  batch: 27  loss: 0.34124961\n",
      "epoch: 11  batch: 28  loss: 0.19418415\n",
      "epoch: 11  batch: 29  loss: 0.11577615\n",
      "epoch: 11  batch: 30  loss: 0.06540248\n",
      "epoch: 11  batch: 31  loss: 0.05316858\n",
      "epoch: 11  batch: 32  loss: 0.12258549\n",
      "epoch: 11  batch: 33  loss: 0.16521543\n",
      "epoch: 11  batch: 34  loss: 0.19100128\n",
      "epoch: 11  batch: 35  loss: 0.29928836\n",
      "epoch: 11  batch: 36  loss: 0.10869249\n",
      "epoch: 11  batch: 37  loss: 0.12653458\n",
      "epoch: 11  batch: 38  loss: 0.04938554\n",
      "epoch: 11  batch: 39  loss: 0.24404284\n",
      "epoch: 11  batch: 40  loss: 0.08453690\n",
      "epoch: 11  batch: 41  loss: 0.27523294\n",
      "epoch: 11  batch: 42  loss: 0.13162506\n",
      "epoch: 11  batch: 43  loss: 0.12958489\n",
      "epoch: 11  batch: 44  loss: 0.14078158\n",
      "epoch: 11  batch: 45  loss: 0.06663677\n",
      "epoch: 11  batch: 46  loss: 0.42758346\n",
      "epoch: 11  batch: 47  loss: 0.53658170\n",
      "epoch: 11  batch: 48  loss: 0.42716214\n",
      "epoch: 11  batch: 49  loss: 0.17906906\n",
      "epoch: 11  batch: 50  loss: 0.33324251\n",
      "epoch: 11  batch: 51  loss: 0.22961451\n",
      "epoch: 11  batch: 52  loss: 0.09030668\n",
      "epoch: 11  batch: 53  loss: 0.08052681\n",
      "epoch: 11  batch: 54  loss: 0.34223291\n",
      "epoch: 11  batch: 55  loss: 0.23389448\n",
      "epoch: 11  batch: 56  loss: 0.13819815\n",
      "epoch: 11  batch: 57  loss: 0.05903046\n",
      "epoch: 11  batch: 58  loss: 0.28034276\n",
      "epoch: 11  batch: 59  loss: 0.22106074\n",
      "epoch: 11  batch: 60  loss: 0.30576846\n",
      "epoch: 11  batch: 61  loss: 0.66635215\n",
      "epoch: 11  batch: 62  loss: 0.14318089\n",
      "epoch: 11  batch: 63  loss: 0.19645412\n",
      "epoch: 11  batch: 64  loss: 0.07051209\n",
      "epoch: 11  batch: 65  loss: 0.12554450\n",
      "epoch: 11  batch: 66  loss: 0.25434300\n",
      "epoch: 11  batch: 67  loss: 0.31243634\n",
      "epoch: 11  batch: 68  loss: 0.35967621\n",
      "epoch: 12  batch: 1  loss: 0.43653363\n",
      "epoch: 12  batch: 2  loss: 0.09075902\n",
      "epoch: 12  batch: 3  loss: 0.14197604\n",
      "epoch: 12  batch: 4  loss: 0.05475849\n",
      "epoch: 12  batch: 5  loss: 0.14744502\n",
      "epoch: 12  batch: 6  loss: 0.09077528\n",
      "epoch: 12  batch: 7  loss: 0.26987132\n",
      "epoch: 12  batch: 8  loss: 0.07483611\n",
      "epoch: 12  batch: 9  loss: 0.11716542\n",
      "epoch: 12  batch: 10  loss: 0.10628147\n",
      "epoch: 12  batch: 11  loss: 0.10949131\n",
      "epoch: 12  batch: 12  loss: 0.44294235\n",
      "epoch: 12  batch: 13  loss: 0.82427132\n",
      "epoch: 12  batch: 14  loss: 0.49467358\n",
      "epoch: 12  batch: 15  loss: 0.32479560\n",
      "epoch: 12  batch: 16  loss: 0.33653048\n",
      "epoch: 12  batch: 17  loss: 0.51181686\n",
      "epoch: 12  batch: 18  loss: 0.13808045\n",
      "epoch: 12  batch: 19  loss: 0.16971630\n",
      "epoch: 12  batch: 20  loss: 0.39426038\n",
      "epoch: 12  batch: 21  loss: 0.50581503\n",
      "epoch: 12  batch: 22  loss: 0.14309447\n",
      "epoch: 12  batch: 23  loss: 0.07665204\n",
      "epoch: 12  batch: 24  loss: 0.08165675\n",
      "epoch: 12  batch: 25  loss: 0.17013940\n",
      "epoch: 12  batch: 26  loss: 0.14150299\n",
      "epoch: 12  batch: 27  loss: 0.46491483\n",
      "epoch: 12  batch: 28  loss: 0.17544441\n",
      "epoch: 12  batch: 29  loss: 0.11057188\n",
      "epoch: 12  batch: 30  loss: 0.06331546\n",
      "epoch: 12  batch: 31  loss: 0.10784427\n",
      "epoch: 12  batch: 32  loss: 0.19495150\n",
      "epoch: 12  batch: 33  loss: 0.30014068\n",
      "epoch: 12  batch: 34  loss: 0.21623389\n",
      "epoch: 12  batch: 35  loss: 0.36669651\n",
      "epoch: 12  batch: 36  loss: 0.14867081\n",
      "epoch: 12  batch: 37  loss: 0.11302426\n",
      "epoch: 12  batch: 38  loss: 0.03699931\n",
      "epoch: 12  batch: 39  loss: 0.24794909\n",
      "epoch: 12  batch: 40  loss: 0.06962758\n",
      "epoch: 12  batch: 41  loss: 0.23318304\n",
      "epoch: 12  batch: 42  loss: 0.16010317\n",
      "epoch: 12  batch: 43  loss: 0.10933221\n",
      "epoch: 12  batch: 44  loss: 0.14252353\n",
      "epoch: 12  batch: 45  loss: 0.06209785\n",
      "epoch: 12  batch: 46  loss: 0.43555939\n",
      "epoch: 12  batch: 47  loss: 0.98610961\n",
      "epoch: 12  batch: 48  loss: 0.30405116\n",
      "epoch: 12  batch: 49  loss: 0.20217192\n",
      "epoch: 12  batch: 50  loss: 0.41334069\n",
      "epoch: 12  batch: 51  loss: 0.34560165\n",
      "epoch: 12  batch: 52  loss: 0.12535979\n",
      "epoch: 12  batch: 53  loss: 0.15813647\n",
      "epoch: 12  batch: 54  loss: 0.35774991\n",
      "epoch: 12  batch: 55  loss: 0.22963110\n",
      "epoch: 12  batch: 56  loss: 0.10497491\n",
      "epoch: 12  batch: 57  loss: 0.04362996\n",
      "epoch: 12  batch: 58  loss: 0.19655423\n",
      "epoch: 12  batch: 59  loss: 0.23325586\n",
      "epoch: 12  batch: 60  loss: 0.29416123\n",
      "epoch: 12  batch: 61  loss: 0.64444619\n",
      "epoch: 12  batch: 62  loss: 0.13572305\n",
      "epoch: 12  batch: 63  loss: 0.16595332\n",
      "epoch: 12  batch: 64  loss: 0.05140151\n",
      "epoch: 12  batch: 65  loss: 0.20949544\n",
      "epoch: 12  batch: 66  loss: 0.26811990\n",
      "epoch: 12  batch: 67  loss: 0.32303119\n",
      "epoch: 12  batch: 68  loss: 0.41834995\n",
      "epoch: 13  batch: 1  loss: 0.44528377\n",
      "epoch: 13  batch: 2  loss: 0.10970508\n",
      "epoch: 13  batch: 3  loss: 0.08494701\n",
      "epoch: 13  batch: 4  loss: 0.06332868\n",
      "epoch: 13  batch: 5  loss: 0.09845224\n",
      "epoch: 13  batch: 6  loss: 0.11006212\n",
      "epoch: 13  batch: 7  loss: 0.23204337\n",
      "epoch: 13  batch: 8  loss: 0.05147294\n",
      "epoch: 13  batch: 9  loss: 0.07270534\n",
      "epoch: 13  batch: 10  loss: 0.08184081\n",
      "epoch: 13  batch: 11  loss: 0.07281704\n",
      "epoch: 13  batch: 12  loss: 0.50008285\n",
      "epoch: 13  batch: 13  loss: 1.01243818\n",
      "epoch: 13  batch: 14  loss: 0.36945745\n",
      "epoch: 13  batch: 15  loss: 0.20458788\n",
      "epoch: 13  batch: 16  loss: 0.25100261\n",
      "epoch: 13  batch: 17  loss: 0.43236205\n",
      "epoch: 13  batch: 18  loss: 0.12231011\n",
      "epoch: 13  batch: 19  loss: 0.10202152\n",
      "epoch: 13  batch: 20  loss: 0.45011470\n",
      "epoch: 13  batch: 21  loss: 0.41762000\n",
      "epoch: 13  batch: 22  loss: 0.16359834\n",
      "epoch: 13  batch: 23  loss: 0.08450355\n",
      "epoch: 13  batch: 24  loss: 0.11270033\n",
      "epoch: 13  batch: 25  loss: 0.17451042\n",
      "epoch: 13  batch: 26  loss: 0.24236542\n",
      "epoch: 13  batch: 27  loss: 0.42568856\n",
      "epoch: 13  batch: 28  loss: 0.23027815\n",
      "epoch: 13  batch: 29  loss: 0.22231679\n",
      "epoch: 13  batch: 30  loss: 0.17711122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13  batch: 31  loss: 0.06652821\n",
      "epoch: 13  batch: 32  loss: 0.10619435\n",
      "epoch: 13  batch: 33  loss: 0.23642881\n",
      "epoch: 13  batch: 34  loss: 0.13923372\n",
      "epoch: 13  batch: 35  loss: 0.24617209\n",
      "epoch: 13  batch: 36  loss: 0.16529161\n",
      "epoch: 13  batch: 37  loss: 0.11511940\n",
      "epoch: 13  batch: 38  loss: 0.08073137\n",
      "epoch: 13  batch: 39  loss: 0.27112982\n",
      "epoch: 13  batch: 40  loss: 0.08261190\n",
      "epoch: 13  batch: 41  loss: 0.27754965\n",
      "epoch: 13  batch: 42  loss: 0.18154030\n",
      "epoch: 13  batch: 43  loss: 0.25645754\n",
      "epoch: 13  batch: 44  loss: 0.23695382\n",
      "epoch: 13  batch: 45  loss: 0.19972906\n",
      "epoch: 13  batch: 46  loss: 0.30111408\n",
      "epoch: 13  batch: 47  loss: 0.51918364\n",
      "epoch: 13  batch: 48  loss: 0.29043666\n",
      "epoch: 13  batch: 49  loss: 0.20829612\n",
      "epoch: 13  batch: 50  loss: 0.52751768\n",
      "epoch: 13  batch: 51  loss: 0.51480991\n",
      "epoch: 13  batch: 52  loss: 0.25505877\n",
      "epoch: 13  batch: 53  loss: 0.30769765\n",
      "epoch: 13  batch: 54  loss: 0.42540035\n",
      "epoch: 13  batch: 55  loss: 0.27953506\n",
      "epoch: 13  batch: 56  loss: 0.13643974\n",
      "epoch: 13  batch: 57  loss: 0.11502235\n",
      "epoch: 13  batch: 58  loss: 0.08243728\n",
      "epoch: 13  batch: 59  loss: 0.13218895\n",
      "epoch: 13  batch: 60  loss: 0.47306931\n",
      "epoch: 13  batch: 61  loss: 0.80827522\n",
      "epoch: 13  batch: 62  loss: 0.26455936\n",
      "epoch: 13  batch: 63  loss: 0.39432323\n",
      "epoch: 13  batch: 64  loss: 0.23838435\n",
      "epoch: 13  batch: 65  loss: 0.05648015\n",
      "epoch: 13  batch: 66  loss: 0.09742936\n",
      "epoch: 13  batch: 67  loss: 0.24754247\n",
      "epoch: 13  batch: 68  loss: 0.28771776\n",
      "epoch: 14  batch: 1  loss: 0.34031674\n",
      "epoch: 14  batch: 2  loss: 0.17454161\n",
      "epoch: 14  batch: 3  loss: 0.12094153\n",
      "epoch: 14  batch: 4  loss: 0.11883569\n",
      "epoch: 14  batch: 5  loss: 0.36097708\n",
      "epoch: 14  batch: 6  loss: 0.18297461\n",
      "epoch: 14  batch: 7  loss: 0.38331047\n",
      "epoch: 14  batch: 8  loss: 0.13362870\n",
      "epoch: 14  batch: 9  loss: 0.21978603\n",
      "epoch: 14  batch: 10  loss: 0.20653597\n",
      "epoch: 14  batch: 11  loss: 0.21904799\n",
      "epoch: 14  batch: 12  loss: 0.25763854\n",
      "epoch: 14  batch: 13  loss: 0.61541325\n",
      "epoch: 14  batch: 14  loss: 0.32124627\n",
      "epoch: 14  batch: 15  loss: 0.20584674\n",
      "epoch: 14  batch: 16  loss: 0.37650740\n",
      "epoch: 14  batch: 17  loss: 0.55484813\n",
      "epoch: 14  batch: 18  loss: 0.21397159\n",
      "epoch: 14  batch: 19  loss: 0.27515846\n",
      "epoch: 14  batch: 20  loss: 0.34898537\n",
      "epoch: 14  batch: 21  loss: 0.38818568\n",
      "epoch: 14  batch: 22  loss: 0.10316447\n",
      "epoch: 14  batch: 23  loss: 0.10855725\n",
      "epoch: 14  batch: 24  loss: 0.06100259\n",
      "epoch: 14  batch: 25  loss: 0.08938535\n",
      "epoch: 14  batch: 26  loss: 0.30662185\n",
      "epoch: 14  batch: 27  loss: 0.61732084\n",
      "epoch: 14  batch: 28  loss: 0.27662525\n",
      "epoch: 14  batch: 29  loss: 0.21432696\n",
      "epoch: 14  batch: 30  loss: 0.11717733\n",
      "epoch: 14  batch: 31  loss: 0.06186829\n",
      "epoch: 14  batch: 32  loss: 0.17592674\n",
      "epoch: 14  batch: 33  loss: 0.36656284\n",
      "epoch: 14  batch: 34  loss: 0.13211796\n",
      "epoch: 14  batch: 35  loss: 0.25010207\n",
      "epoch: 14  batch: 36  loss: 0.07480236\n",
      "epoch: 14  batch: 37  loss: 0.04197823\n",
      "epoch: 14  batch: 38  loss: 0.06389533\n",
      "epoch: 14  batch: 39  loss: 0.29998586\n",
      "epoch: 14  batch: 40  loss: 0.08398660\n",
      "epoch: 14  batch: 41  loss: 0.35206738\n",
      "epoch: 14  batch: 42  loss: 0.27237517\n",
      "epoch: 14  batch: 43  loss: 0.32821259\n",
      "epoch: 14  batch: 44  loss: 0.36712310\n",
      "epoch: 14  batch: 45  loss: 0.24826339\n",
      "epoch: 14  batch: 46  loss: 0.20800668\n",
      "epoch: 14  batch: 47  loss: 0.29696161\n",
      "epoch: 14  batch: 48  loss: 0.21938445\n",
      "epoch: 14  batch: 49  loss: 0.17920206\n",
      "epoch: 14  batch: 50  loss: 0.30584812\n",
      "epoch: 14  batch: 51  loss: 0.27863759\n",
      "epoch: 14  batch: 52  loss: 0.13818783\n",
      "epoch: 14  batch: 53  loss: 0.28039798\n",
      "epoch: 14  batch: 54  loss: 0.36220416\n",
      "epoch: 14  batch: 55  loss: 0.24448194\n",
      "epoch: 14  batch: 56  loss: 0.09623640\n",
      "epoch: 14  batch: 57  loss: 0.12882209\n",
      "epoch: 14  batch: 58  loss: 0.12641187\n",
      "epoch: 14  batch: 59  loss: 0.12465687\n",
      "epoch: 14  batch: 60  loss: 0.46600005\n",
      "epoch: 14  batch: 61  loss: 0.98631495\n",
      "epoch: 14  batch: 62  loss: 0.22828072\n",
      "epoch: 14  batch: 63  loss: 0.45799395\n",
      "epoch: 14  batch: 64  loss: 0.14041328\n",
      "epoch: 14  batch: 65  loss: 0.05789018\n",
      "epoch: 14  batch: 66  loss: 0.07148374\n",
      "epoch: 14  batch: 67  loss: 0.17534496\n",
      "epoch: 14  batch: 68  loss: 0.33199278\n",
      "epoch: 15  batch: 1  loss: 0.29910541\n",
      "epoch: 15  batch: 2  loss: 0.11153092\n",
      "epoch: 15  batch: 3  loss: 0.10365769\n",
      "epoch: 15  batch: 4  loss: 0.15579580\n",
      "epoch: 15  batch: 5  loss: 0.18872672\n",
      "epoch: 15  batch: 6  loss: 0.12828122\n",
      "epoch: 15  batch: 7  loss: 0.31984594\n",
      "epoch: 15  batch: 8  loss: 0.06392523\n",
      "epoch: 15  batch: 9  loss: 0.18166128\n",
      "epoch: 15  batch: 10  loss: 0.18436556\n",
      "epoch: 15  batch: 11  loss: 0.16965193\n",
      "epoch: 15  batch: 12  loss: 0.26921439\n",
      "epoch: 15  batch: 13  loss: 0.91031820\n",
      "epoch: 15  batch: 14  loss: 0.25738159\n",
      "epoch: 15  batch: 15  loss: 0.18521143\n",
      "epoch: 15  batch: 16  loss: 0.25519359\n",
      "epoch: 15  batch: 17  loss: 0.53795016\n",
      "epoch: 15  batch: 18  loss: 0.13689645\n",
      "epoch: 15  batch: 19  loss: 0.13317738\n",
      "epoch: 15  batch: 20  loss: 0.30927673\n",
      "epoch: 15  batch: 21  loss: 0.38399145\n",
      "epoch: 15  batch: 22  loss: 0.08445391\n",
      "epoch: 15  batch: 23  loss: 0.06128719\n",
      "epoch: 15  batch: 24  loss: 0.05981738\n",
      "epoch: 15  batch: 25  loss: 0.14613268\n",
      "epoch: 15  batch: 26  loss: 0.22610196\n",
      "epoch: 15  batch: 27  loss: 0.62193352\n",
      "epoch: 15  batch: 28  loss: 0.26282743\n",
      "epoch: 15  batch: 29  loss: 0.16944312\n",
      "epoch: 15  batch: 30  loss: 0.10780145\n",
      "epoch: 15  batch: 31  loss: 0.05736722\n",
      "epoch: 15  batch: 32  loss: 0.16111408\n",
      "epoch: 15  batch: 33  loss: 0.18791917\n",
      "epoch: 15  batch: 34  loss: 0.28842360\n",
      "epoch: 15  batch: 35  loss: 0.38744509\n",
      "epoch: 15  batch: 36  loss: 0.11802083\n",
      "epoch: 15  batch: 37  loss: 0.11916491\n",
      "epoch: 15  batch: 38  loss: 0.06460070\n",
      "epoch: 15  batch: 39  loss: 0.34238902\n",
      "epoch: 15  batch: 40  loss: 0.10881549\n",
      "epoch: 15  batch: 41  loss: 0.27212521\n",
      "epoch: 15  batch: 42  loss: 0.17918676\n",
      "epoch: 15  batch: 43  loss: 0.21194747\n",
      "epoch: 15  batch: 44  loss: 0.28299612\n",
      "epoch: 15  batch: 45  loss: 0.23850504\n",
      "epoch: 15  batch: 46  loss: 0.26906151\n",
      "epoch: 15  batch: 47  loss: 0.41678375\n",
      "epoch: 15  batch: 48  loss: 0.30481014\n",
      "epoch: 15  batch: 49  loss: 0.25715366\n",
      "epoch: 15  batch: 50  loss: 0.44029644\n",
      "epoch: 15  batch: 51  loss: 0.40283620\n",
      "epoch: 15  batch: 52  loss: 0.17851779\n",
      "epoch: 15  batch: 53  loss: 0.24602136\n",
      "epoch: 15  batch: 54  loss: 0.39621785\n",
      "epoch: 15  batch: 55  loss: 0.25852650\n",
      "epoch: 15  batch: 56  loss: 0.12763536\n",
      "epoch: 15  batch: 57  loss: 0.09897082\n",
      "epoch: 15  batch: 58  loss: 0.08992574\n",
      "epoch: 15  batch: 59  loss: 0.11664303\n",
      "epoch: 15  batch: 60  loss: 0.42768836\n",
      "epoch: 15  batch: 61  loss: 0.86619437\n",
      "epoch: 15  batch: 62  loss: 0.19458899\n",
      "epoch: 15  batch: 63  loss: 0.31515598\n",
      "epoch: 15  batch: 64  loss: 0.20400207\n",
      "epoch: 15  batch: 65  loss: 0.07226536\n",
      "epoch: 15  batch: 66  loss: 0.10197345\n",
      "epoch: 15  batch: 67  loss: 0.16745016\n",
      "epoch: 15  batch: 68  loss: 0.19937693\n",
      "epoch: 16  batch: 1  loss: 0.27136689\n",
      "epoch: 16  batch: 2  loss: 0.13526401\n",
      "epoch: 16  batch: 3  loss: 0.12723136\n",
      "epoch: 16  batch: 4  loss: 0.09190638\n",
      "epoch: 16  batch: 5  loss: 0.21809585\n",
      "epoch: 16  batch: 6  loss: 0.21077091\n",
      "epoch: 16  batch: 7  loss: 0.42664006\n",
      "epoch: 16  batch: 8  loss: 0.18119478\n",
      "epoch: 16  batch: 9  loss: 0.29535601\n",
      "epoch: 16  batch: 10  loss: 0.20920567\n",
      "epoch: 16  batch: 11  loss: 0.33715269\n",
      "epoch: 16  batch: 12  loss: 0.20627865\n",
      "epoch: 16  batch: 13  loss: 0.32413426\n",
      "epoch: 16  batch: 14  loss: 0.22871347\n",
      "epoch: 16  batch: 15  loss: 0.18081382\n",
      "epoch: 16  batch: 16  loss: 0.23832695\n",
      "epoch: 16  batch: 17  loss: 0.44594452\n",
      "epoch: 16  batch: 18  loss: 0.23809205\n",
      "epoch: 16  batch: 19  loss: 0.21172567\n",
      "epoch: 16  batch: 20  loss: 0.33636519\n",
      "epoch: 16  batch: 21  loss: 0.42445198\n",
      "epoch: 16  batch: 22  loss: 0.08973726\n",
      "epoch: 16  batch: 23  loss: 0.10152264\n",
      "epoch: 16  batch: 24  loss: 0.08018734\n",
      "epoch: 16  batch: 25  loss: 0.05969323\n",
      "epoch: 16  batch: 26  loss: 0.37724024\n",
      "epoch: 16  batch: 27  loss: 0.84513575\n",
      "epoch: 16  batch: 28  loss: 0.38406307\n",
      "epoch: 16  batch: 29  loss: 0.30284730\n",
      "epoch: 16  batch: 30  loss: 0.18259297\n",
      "epoch: 16  batch: 31  loss: 0.06899438\n",
      "epoch: 16  batch: 32  loss: 0.06331297\n",
      "epoch: 16  batch: 33  loss: 0.11079411\n",
      "epoch: 16  batch: 34  loss: 0.12457789\n",
      "epoch: 16  batch: 35  loss: 0.26983351\n",
      "epoch: 16  batch: 36  loss: 0.09233189\n",
      "epoch: 16  batch: 37  loss: 0.06508400\n",
      "epoch: 16  batch: 38  loss: 0.07076669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16  batch: 39  loss: 0.30427712\n",
      "epoch: 16  batch: 40  loss: 0.11738151\n",
      "epoch: 16  batch: 41  loss: 0.34234557\n",
      "epoch: 16  batch: 42  loss: 0.50379634\n",
      "epoch: 16  batch: 43  loss: 0.25734320\n",
      "epoch: 16  batch: 44  loss: 0.44342738\n",
      "epoch: 16  batch: 45  loss: 0.50308722\n",
      "epoch: 16  batch: 46  loss: 0.20521440\n",
      "epoch: 16  batch: 47  loss: 0.22384559\n",
      "epoch: 16  batch: 48  loss: 0.21525659\n",
      "epoch: 16  batch: 49  loss: 0.15863903\n",
      "epoch: 16  batch: 50  loss: 0.27364841\n",
      "epoch: 16  batch: 51  loss: 0.33623403\n",
      "epoch: 16  batch: 52  loss: 0.15560102\n",
      "epoch: 16  batch: 53  loss: 0.21549967\n",
      "epoch: 16  batch: 54  loss: 0.40870643\n",
      "epoch: 16  batch: 55  loss: 0.33366311\n",
      "epoch: 16  batch: 56  loss: 0.11634155\n",
      "epoch: 16  batch: 57  loss: 0.11965173\n",
      "epoch: 16  batch: 58  loss: 0.06370918\n",
      "epoch: 16  batch: 59  loss: 0.12708396\n",
      "epoch: 16  batch: 60  loss: 0.37290931\n",
      "epoch: 16  batch: 61  loss: 1.44356179\n",
      "epoch: 16  batch: 62  loss: 0.22252053\n",
      "epoch: 16  batch: 63  loss: 0.30967551\n",
      "epoch: 16  batch: 64  loss: 0.20687766\n",
      "epoch: 16  batch: 65  loss: 0.06370218\n",
      "epoch: 16  batch: 66  loss: 0.13549012\n",
      "epoch: 16  batch: 67  loss: 0.21781890\n",
      "epoch: 16  batch: 68  loss: 0.31534576\n",
      "epoch: 17  batch: 1  loss: 0.34325561\n",
      "epoch: 17  batch: 2  loss: 0.42115945\n",
      "epoch: 17  batch: 3  loss: 0.24086656\n",
      "epoch: 17  batch: 4  loss: 0.25970832\n",
      "epoch: 17  batch: 5  loss: 0.47876659\n",
      "epoch: 17  batch: 6  loss: 0.79818946\n",
      "epoch: 17  batch: 7  loss: 0.50667518\n",
      "epoch: 17  batch: 8  loss: 0.27802473\n",
      "epoch: 17  batch: 9  loss: 0.45177680\n",
      "epoch: 17  batch: 10  loss: 0.16599348\n",
      "epoch: 17  batch: 11  loss: 0.35505140\n",
      "epoch: 17  batch: 12  loss: 0.24288845\n",
      "epoch: 17  batch: 13  loss: 0.43622062\n",
      "epoch: 17  batch: 14  loss: 0.25409365\n",
      "epoch: 17  batch: 15  loss: 0.24519074\n",
      "epoch: 17  batch: 16  loss: 0.34003574\n",
      "epoch: 17  batch: 17  loss: 0.65679663\n",
      "epoch: 17  batch: 18  loss: 0.26696455\n",
      "epoch: 17  batch: 19  loss: 0.29059526\n",
      "epoch: 17  batch: 20  loss: 0.33608013\n",
      "epoch: 17  batch: 21  loss: 0.42247298\n",
      "epoch: 17  batch: 22  loss: 0.14805754\n",
      "epoch: 17  batch: 23  loss: 0.16033711\n",
      "epoch: 17  batch: 24  loss: 0.12354902\n",
      "epoch: 17  batch: 25  loss: 0.11974759\n",
      "epoch: 17  batch: 26  loss: 0.51043177\n",
      "epoch: 17  batch: 27  loss: 0.98248005\n",
      "epoch: 17  batch: 28  loss: 0.47054750\n",
      "epoch: 17  batch: 29  loss: 0.34984592\n",
      "epoch: 17  batch: 30  loss: 0.22535229\n",
      "epoch: 17  batch: 31  loss: 0.07672407\n",
      "epoch: 17  batch: 32  loss: 0.08341616\n",
      "epoch: 17  batch: 33  loss: 0.12539297\n",
      "epoch: 17  batch: 34  loss: 0.14993113\n",
      "epoch: 17  batch: 35  loss: 0.30819660\n",
      "epoch: 17  batch: 36  loss: 0.14118415\n",
      "epoch: 17  batch: 37  loss: 0.10995045\n",
      "epoch: 17  batch: 38  loss: 0.16988499\n",
      "epoch: 17  batch: 39  loss: 0.39407849\n",
      "epoch: 17  batch: 40  loss: 0.12334173\n",
      "epoch: 17  batch: 41  loss: 0.46776074\n",
      "epoch: 17  batch: 42  loss: 0.30535737\n",
      "epoch: 17  batch: 43  loss: 0.33736968\n",
      "epoch: 17  batch: 44  loss: 0.29019371\n",
      "epoch: 17  batch: 45  loss: 0.25447023\n",
      "epoch: 17  batch: 46  loss: 0.23639764\n",
      "epoch: 17  batch: 47  loss: 0.35319772\n",
      "epoch: 17  batch: 48  loss: 0.21228494\n",
      "epoch: 17  batch: 49  loss: 0.18245380\n",
      "epoch: 17  batch: 50  loss: 0.28613511\n",
      "epoch: 17  batch: 51  loss: 0.29893038\n",
      "epoch: 17  batch: 52  loss: 0.13375135\n",
      "epoch: 17  batch: 53  loss: 0.26610863\n",
      "epoch: 17  batch: 54  loss: 0.45717344\n",
      "epoch: 17  batch: 55  loss: 0.30426502\n",
      "epoch: 17  batch: 56  loss: 0.12145910\n",
      "epoch: 17  batch: 57  loss: 0.15461835\n",
      "epoch: 17  batch: 58  loss: 0.07209007\n",
      "epoch: 17  batch: 59  loss: 0.12873207\n",
      "epoch: 17  batch: 60  loss: 0.45973486\n",
      "epoch: 17  batch: 61  loss: 0.93172175\n",
      "epoch: 17  batch: 62  loss: 0.24206331\n",
      "epoch: 17  batch: 63  loss: 0.46472105\n",
      "epoch: 17  batch: 64  loss: 0.16902086\n",
      "epoch: 17  batch: 65  loss: 0.05319115\n",
      "epoch: 17  batch: 66  loss: 0.06077569\n",
      "epoch: 17  batch: 67  loss: 0.11264636\n",
      "epoch: 17  batch: 68  loss: 0.23520684\n",
      "epoch: 18  batch: 1  loss: 0.36219212\n",
      "epoch: 18  batch: 2  loss: 0.07902075\n",
      "epoch: 18  batch: 3  loss: 0.12747663\n",
      "epoch: 18  batch: 4  loss: 0.14299227\n",
      "epoch: 18  batch: 5  loss: 0.30301559\n",
      "epoch: 18  batch: 6  loss: 0.20545860\n",
      "epoch: 18  batch: 7  loss: 0.36175254\n",
      "epoch: 18  batch: 8  loss: 0.16139948\n",
      "epoch: 18  batch: 9  loss: 0.26693365\n",
      "epoch: 18  batch: 10  loss: 0.26006830\n",
      "epoch: 18  batch: 11  loss: 0.25177363\n",
      "epoch: 18  batch: 12  loss: 0.17855325\n",
      "epoch: 18  batch: 13  loss: 0.65612298\n",
      "epoch: 18  batch: 14  loss: 0.34807366\n",
      "epoch: 18  batch: 15  loss: 0.15936589\n",
      "epoch: 18  batch: 16  loss: 0.33701304\n",
      "epoch: 18  batch: 17  loss: 0.60831374\n",
      "epoch: 18  batch: 18  loss: 0.23577848\n",
      "epoch: 18  batch: 19  loss: 0.25368381\n",
      "epoch: 18  batch: 20  loss: 0.33988678\n",
      "epoch: 18  batch: 21  loss: 0.40202734\n",
      "epoch: 18  batch: 22  loss: 0.08657404\n",
      "epoch: 18  batch: 23  loss: 0.08471134\n",
      "epoch: 18  batch: 24  loss: 0.05712259\n",
      "epoch: 18  batch: 25  loss: 0.10611098\n",
      "epoch: 18  batch: 26  loss: 0.26612639\n",
      "epoch: 18  batch: 27  loss: 0.58063620\n",
      "epoch: 18  batch: 28  loss: 0.26733026\n",
      "epoch: 18  batch: 29  loss: 0.19635673\n",
      "epoch: 18  batch: 30  loss: 0.12432790\n",
      "epoch: 18  batch: 31  loss: 0.07509380\n",
      "epoch: 18  batch: 32  loss: 0.10234119\n",
      "epoch: 18  batch: 33  loss: 0.17613910\n",
      "epoch: 18  batch: 34  loss: 0.17783241\n",
      "epoch: 18  batch: 35  loss: 0.29951423\n",
      "epoch: 18  batch: 36  loss: 0.08115222\n",
      "epoch: 18  batch: 37  loss: 0.10999612\n",
      "epoch: 18  batch: 38  loss: 0.06704963\n",
      "epoch: 18  batch: 39  loss: 0.28069341\n",
      "epoch: 18  batch: 40  loss: 0.15593946\n",
      "epoch: 18  batch: 41  loss: 0.32631314\n",
      "epoch: 18  batch: 42  loss: 0.29717872\n",
      "epoch: 18  batch: 43  loss: 0.31356418\n",
      "epoch: 18  batch: 44  loss: 0.33095339\n",
      "epoch: 18  batch: 45  loss: 0.32582039\n",
      "epoch: 18  batch: 46  loss: 0.20997472\n",
      "epoch: 18  batch: 47  loss: 0.25173756\n",
      "epoch: 18  batch: 48  loss: 0.17624131\n",
      "epoch: 18  batch: 49  loss: 0.15235418\n",
      "epoch: 18  batch: 50  loss: 0.26696828\n",
      "epoch: 18  batch: 51  loss: 0.18983629\n",
      "epoch: 18  batch: 52  loss: 0.11843643\n",
      "epoch: 18  batch: 53  loss: 0.21708918\n",
      "epoch: 18  batch: 54  loss: 0.38681099\n",
      "epoch: 18  batch: 55  loss: 0.28371176\n",
      "epoch: 18  batch: 56  loss: 0.10035800\n",
      "epoch: 18  batch: 57  loss: 0.08668558\n",
      "epoch: 18  batch: 58  loss: 0.07588872\n",
      "epoch: 18  batch: 59  loss: 0.12942199\n",
      "epoch: 18  batch: 60  loss: 0.36888340\n",
      "epoch: 18  batch: 61  loss: 0.64299756\n",
      "epoch: 18  batch: 62  loss: 0.28261924\n",
      "epoch: 18  batch: 63  loss: 0.38491425\n",
      "epoch: 18  batch: 64  loss: 0.08488882\n",
      "epoch: 18  batch: 65  loss: 0.04989460\n",
      "epoch: 18  batch: 66  loss: 0.09578627\n",
      "epoch: 18  batch: 67  loss: 0.21826702\n",
      "epoch: 18  batch: 68  loss: 0.27446705\n",
      "epoch: 19  batch: 1  loss: 0.41052693\n",
      "epoch: 19  batch: 2  loss: 0.06252931\n",
      "epoch: 19  batch: 3  loss: 0.18215761\n",
      "epoch: 19  batch: 4  loss: 0.10664999\n",
      "epoch: 19  batch: 5  loss: 0.19028641\n",
      "epoch: 19  batch: 6  loss: 0.24163485\n",
      "epoch: 19  batch: 7  loss: 0.36856166\n",
      "epoch: 19  batch: 8  loss: 0.14978945\n",
      "epoch: 19  batch: 9  loss: 0.27842343\n",
      "epoch: 19  batch: 10  loss: 0.24211481\n",
      "epoch: 19  batch: 11  loss: 0.25066388\n",
      "epoch: 19  batch: 12  loss: 0.25199485\n",
      "epoch: 19  batch: 13  loss: 0.45155555\n",
      "epoch: 19  batch: 14  loss: 0.27557138\n",
      "epoch: 19  batch: 15  loss: 0.19034515\n",
      "epoch: 19  batch: 16  loss: 0.30541474\n",
      "epoch: 19  batch: 17  loss: 0.50459003\n",
      "epoch: 19  batch: 18  loss: 0.20720677\n",
      "epoch: 19  batch: 19  loss: 0.24287169\n",
      "epoch: 19  batch: 20  loss: 0.39453143\n",
      "epoch: 19  batch: 21  loss: 0.42250136\n",
      "epoch: 19  batch: 22  loss: 0.10397968\n",
      "epoch: 19  batch: 23  loss: 0.10433269\n",
      "epoch: 19  batch: 24  loss: 0.06233984\n",
      "epoch: 19  batch: 25  loss: 0.06688219\n",
      "epoch: 19  batch: 26  loss: 0.48345575\n",
      "epoch: 19  batch: 27  loss: 0.83646053\n",
      "epoch: 19  batch: 28  loss: 0.44050255\n",
      "epoch: 19  batch: 29  loss: 0.26490107\n",
      "epoch: 19  batch: 30  loss: 0.18767570\n",
      "epoch: 19  batch: 31  loss: 0.08375499\n",
      "epoch: 19  batch: 32  loss: 0.08463819\n",
      "epoch: 19  batch: 33  loss: 0.12242354\n",
      "epoch: 19  batch: 34  loss: 0.11356732\n",
      "epoch: 19  batch: 35  loss: 0.19125400\n",
      "epoch: 19  batch: 36  loss: 0.13869981\n",
      "epoch: 19  batch: 37  loss: 0.10933848\n",
      "epoch: 19  batch: 38  loss: 0.08639685\n",
      "epoch: 19  batch: 39  loss: 0.21059360\n",
      "epoch: 19  batch: 40  loss: 0.11726092\n",
      "epoch: 19  batch: 41  loss: 0.33573541\n",
      "epoch: 19  batch: 42  loss: 0.16366650\n",
      "epoch: 19  batch: 43  loss: 0.35817167\n",
      "epoch: 19  batch: 44  loss: 0.27336350\n",
      "epoch: 19  batch: 45  loss: 0.43937680\n",
      "epoch: 19  batch: 46  loss: 0.25124982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19  batch: 47  loss: 0.30624399\n",
      "epoch: 19  batch: 48  loss: 0.17975052\n",
      "epoch: 19  batch: 49  loss: 0.16520770\n",
      "epoch: 19  batch: 50  loss: 0.31230173\n",
      "epoch: 19  batch: 51  loss: 0.31416726\n",
      "epoch: 19  batch: 52  loss: 0.12005120\n",
      "epoch: 19  batch: 53  loss: 0.19971313\n",
      "epoch: 19  batch: 54  loss: 0.39936668\n",
      "epoch: 19  batch: 55  loss: 0.25926062\n",
      "epoch: 19  batch: 56  loss: 0.10433189\n",
      "epoch: 19  batch: 57  loss: 0.07646573\n",
      "epoch: 19  batch: 58  loss: 0.08471859\n",
      "epoch: 19  batch: 59  loss: 0.13124053\n",
      "epoch: 19  batch: 60  loss: 0.37339276\n",
      "epoch: 19  batch: 61  loss: 0.78800899\n",
      "epoch: 19  batch: 62  loss: 0.23985767\n",
      "epoch: 19  batch: 63  loss: 0.29969686\n",
      "epoch: 19  batch: 64  loss: 0.10079484\n",
      "epoch: 19  batch: 65  loss: 0.07988234\n",
      "epoch: 19  batch: 66  loss: 0.06536432\n",
      "epoch: 19  batch: 67  loss: 0.08260339\n",
      "epoch: 19  batch: 68  loss: 0.22953652\n",
      "epoch: 20  batch: 1  loss: 0.30259666\n",
      "epoch: 20  batch: 2  loss: 0.15617813\n",
      "epoch: 20  batch: 3  loss: 0.12481334\n",
      "epoch: 20  batch: 4  loss: 0.10448059\n",
      "epoch: 20  batch: 5  loss: 0.28106144\n",
      "epoch: 20  batch: 6  loss: 0.17010652\n",
      "epoch: 20  batch: 7  loss: 0.30732557\n",
      "epoch: 20  batch: 8  loss: 0.14756005\n",
      "epoch: 20  batch: 9  loss: 0.30541232\n",
      "epoch: 20  batch: 10  loss: 0.27277675\n",
      "epoch: 20  batch: 11  loss: 0.33494613\n",
      "epoch: 20  batch: 12  loss: 0.20489733\n",
      "epoch: 20  batch: 13  loss: 0.36802351\n",
      "epoch: 20  batch: 14  loss: 0.23798761\n",
      "epoch: 20  batch: 15  loss: 0.18080501\n",
      "epoch: 20  batch: 16  loss: 0.23098192\n",
      "epoch: 20  batch: 17  loss: 0.57070452\n",
      "epoch: 20  batch: 18  loss: 0.23535882\n",
      "epoch: 20  batch: 19  loss: 0.16909045\n",
      "epoch: 20  batch: 20  loss: 0.34830174\n",
      "epoch: 20  batch: 21  loss: 0.41279909\n",
      "epoch: 20  batch: 22  loss: 0.08382866\n",
      "epoch: 20  batch: 23  loss: 0.08169776\n",
      "epoch: 20  batch: 24  loss: 0.05534194\n",
      "epoch: 20  batch: 25  loss: 0.04365871\n",
      "epoch: 20  batch: 26  loss: 0.43576890\n",
      "epoch: 20  batch: 27  loss: 0.70319307\n",
      "epoch: 20  batch: 28  loss: 0.25734487\n",
      "epoch: 20  batch: 29  loss: 0.22362617\n",
      "epoch: 20  batch: 30  loss: 0.15337430\n",
      "epoch: 20  batch: 31  loss: 0.07263105\n",
      "epoch: 20  batch: 32  loss: 0.06707138\n",
      "epoch: 20  batch: 33  loss: 0.18229976\n",
      "epoch: 20  batch: 34  loss: 0.12500973\n",
      "epoch: 20  batch: 35  loss: 0.25805292\n",
      "epoch: 20  batch: 36  loss: 0.18756121\n",
      "epoch: 20  batch: 37  loss: 0.10311337\n",
      "epoch: 20  batch: 38  loss: 0.16577916\n",
      "epoch: 20  batch: 39  loss: 0.28698063\n",
      "epoch: 20  batch: 40  loss: 0.09186962\n",
      "epoch: 20  batch: 41  loss: 0.34907117\n",
      "epoch: 20  batch: 42  loss: 0.22297958\n",
      "epoch: 20  batch: 43  loss: 0.26582116\n",
      "epoch: 20  batch: 44  loss: 0.37588918\n",
      "epoch: 20  batch: 45  loss: 0.25452647\n",
      "epoch: 20  batch: 46  loss: 0.22027969\n",
      "epoch: 20  batch: 47  loss: 0.23247698\n",
      "epoch: 20  batch: 48  loss: 0.19272190\n",
      "epoch: 20  batch: 49  loss: 0.17424850\n",
      "epoch: 20  batch: 50  loss: 0.30345622\n",
      "epoch: 20  batch: 51  loss: 0.39740881\n",
      "epoch: 20  batch: 52  loss: 0.13205168\n",
      "epoch: 20  batch: 53  loss: 0.15718573\n",
      "epoch: 20  batch: 54  loss: 0.42463881\n",
      "epoch: 20  batch: 55  loss: 0.23101260\n",
      "epoch: 20  batch: 56  loss: 0.08727819\n",
      "epoch: 20  batch: 57  loss: 0.06301406\n",
      "epoch: 20  batch: 58  loss: 0.11056627\n",
      "epoch: 20  batch: 59  loss: 0.13123864\n",
      "epoch: 20  batch: 60  loss: 0.34197152\n",
      "epoch: 20  batch: 61  loss: 0.76582760\n",
      "epoch: 20  batch: 62  loss: 0.17583688\n",
      "epoch: 20  batch: 63  loss: 0.26062480\n",
      "epoch: 20  batch: 64  loss: 0.10071488\n",
      "epoch: 20  batch: 65  loss: 0.05130984\n",
      "epoch: 20  batch: 66  loss: 0.10022703\n",
      "epoch: 20  batch: 67  loss: 0.17084470\n",
      "epoch: 20  batch: 68  loss: 0.26541537\n",
      "epoch: 21  batch: 1  loss: 0.33273616\n",
      "epoch: 21  batch: 2  loss: 0.16150284\n",
      "epoch: 21  batch: 3  loss: 0.11776948\n",
      "epoch: 21  batch: 4  loss: 0.07314257\n",
      "epoch: 21  batch: 5  loss: 0.21889590\n",
      "epoch: 21  batch: 6  loss: 0.16472456\n",
      "epoch: 21  batch: 7  loss: 0.35119936\n",
      "epoch: 21  batch: 8  loss: 0.14971338\n",
      "epoch: 21  batch: 9  loss: 0.27863523\n",
      "epoch: 21  batch: 10  loss: 0.28705415\n",
      "epoch: 21  batch: 11  loss: 0.23817660\n",
      "epoch: 21  batch: 12  loss: 0.17577489\n",
      "epoch: 21  batch: 13  loss: 0.39369941\n",
      "epoch: 21  batch: 14  loss: 0.40478042\n",
      "epoch: 21  batch: 15  loss: 0.19968735\n",
      "epoch: 21  batch: 16  loss: 0.34570578\n",
      "epoch: 21  batch: 17  loss: 0.52106613\n",
      "epoch: 21  batch: 18  loss: 0.19333537\n",
      "epoch: 21  batch: 19  loss: 0.24112244\n",
      "epoch: 21  batch: 20  loss: 0.36725727\n",
      "epoch: 21  batch: 21  loss: 0.41431031\n",
      "epoch: 21  batch: 22  loss: 0.09660672\n",
      "epoch: 21  batch: 23  loss: 0.10024512\n",
      "epoch: 21  batch: 24  loss: 0.06360684\n",
      "epoch: 21  batch: 25  loss: 0.06946431\n",
      "epoch: 21  batch: 26  loss: 0.38026801\n",
      "epoch: 21  batch: 27  loss: 0.75865698\n",
      "epoch: 21  batch: 28  loss: 0.33652997\n",
      "epoch: 21  batch: 29  loss: 0.29763660\n",
      "epoch: 21  batch: 30  loss: 0.17137054\n",
      "epoch: 21  batch: 31  loss: 0.06087110\n",
      "epoch: 21  batch: 32  loss: 0.06409181\n",
      "epoch: 21  batch: 33  loss: 0.12659431\n",
      "epoch: 21  batch: 34  loss: 0.17103451\n",
      "epoch: 21  batch: 35  loss: 0.28060326\n",
      "epoch: 21  batch: 36  loss: 0.09465887\n",
      "epoch: 21  batch: 37  loss: 0.14705229\n",
      "epoch: 21  batch: 38  loss: 0.17021574\n",
      "epoch: 21  batch: 39  loss: 0.34190086\n",
      "epoch: 21  batch: 40  loss: 0.17523310\n",
      "epoch: 21  batch: 41  loss: 0.26221734\n",
      "epoch: 21  batch: 42  loss: 0.26908037\n",
      "epoch: 21  batch: 43  loss: 0.20080481\n",
      "epoch: 21  batch: 44  loss: 0.31510222\n",
      "epoch: 21  batch: 45  loss: 0.23587470\n",
      "epoch: 21  batch: 46  loss: 0.25128663\n",
      "epoch: 21  batch: 47  loss: 0.28798935\n",
      "epoch: 21  batch: 48  loss: 0.20803778\n",
      "epoch: 21  batch: 49  loss: 0.15926233\n",
      "epoch: 21  batch: 50  loss: 0.28750199\n",
      "epoch: 21  batch: 51  loss: 0.26870558\n",
      "epoch: 21  batch: 52  loss: 0.14390768\n",
      "epoch: 21  batch: 53  loss: 0.16245051\n",
      "epoch: 21  batch: 54  loss: 0.36894736\n",
      "epoch: 21  batch: 55  loss: 0.22788459\n",
      "epoch: 21  batch: 56  loss: 0.09722445\n",
      "epoch: 21  batch: 57  loss: 0.09341940\n",
      "epoch: 21  batch: 58  loss: 0.08688129\n",
      "epoch: 21  batch: 59  loss: 0.14360659\n",
      "epoch: 21  batch: 60  loss: 0.45735428\n",
      "epoch: 21  batch: 61  loss: 0.92612666\n",
      "epoch: 21  batch: 62  loss: 0.20885326\n",
      "epoch: 21  batch: 63  loss: 0.38003340\n",
      "epoch: 21  batch: 64  loss: 0.18484123\n",
      "epoch: 21  batch: 65  loss: 0.04814579\n",
      "epoch: 21  batch: 66  loss: 0.06671898\n",
      "epoch: 21  batch: 67  loss: 0.08434382\n",
      "epoch: 21  batch: 68  loss: 0.20975655\n",
      "epoch: 22  batch: 1  loss: 0.29087168\n",
      "epoch: 22  batch: 2  loss: 0.06166691\n",
      "epoch: 22  batch: 3  loss: 0.10405865\n",
      "epoch: 22  batch: 4  loss: 0.09105591\n",
      "epoch: 22  batch: 5  loss: 0.15536700\n",
      "epoch: 22  batch: 6  loss: 0.09221563\n",
      "epoch: 22  batch: 7  loss: 0.28526178\n",
      "epoch: 22  batch: 8  loss: 0.05488423\n",
      "epoch: 22  batch: 9  loss: 0.04279799\n",
      "epoch: 22  batch: 10  loss: 0.04260811\n",
      "epoch: 22  batch: 11  loss: 0.00866628\n",
      "epoch: 22  batch: 12  loss: 0.69952881\n",
      "epoch: 22  batch: 13  loss: 1.10062885\n",
      "epoch: 22  batch: 14  loss: 0.25647053\n",
      "epoch: 22  batch: 15  loss: 0.23581383\n",
      "epoch: 22  batch: 16  loss: 0.09442434\n",
      "epoch: 22  batch: 17  loss: 0.16033480\n",
      "epoch: 22  batch: 18  loss: 0.28622565\n",
      "epoch: 22  batch: 19  loss: 0.20155740\n",
      "epoch: 22  batch: 20  loss: 1.00525808\n",
      "epoch: 22  batch: 21  loss: 0.80162221\n",
      "epoch: 22  batch: 22  loss: 0.34290403\n",
      "epoch: 22  batch: 23  loss: 0.11088982\n",
      "epoch: 22  batch: 24  loss: 0.15260519\n",
      "epoch: 22  batch: 25  loss: 0.17679973\n",
      "epoch: 22  batch: 26  loss: 0.28625193\n",
      "epoch: 22  batch: 27  loss: 0.61273611\n",
      "epoch: 22  batch: 28  loss: 0.33540294\n",
      "epoch: 22  batch: 29  loss: 0.30949974\n",
      "epoch: 22  batch: 30  loss: 0.20032120\n",
      "epoch: 22  batch: 31  loss: 0.09316591\n",
      "epoch: 22  batch: 32  loss: 0.05485765\n",
      "epoch: 22  batch: 33  loss: 0.09840149\n",
      "epoch: 22  batch: 34  loss: 0.09396715\n",
      "epoch: 22  batch: 35  loss: 0.16844183\n",
      "epoch: 22  batch: 36  loss: 0.07559248\n",
      "epoch: 22  batch: 37  loss: 0.06928836\n",
      "epoch: 22  batch: 38  loss: 0.04902776\n",
      "epoch: 22  batch: 39  loss: 0.19857487\n",
      "epoch: 22  batch: 40  loss: 0.09109093\n",
      "epoch: 22  batch: 41  loss: 0.20938270\n",
      "epoch: 22  batch: 42  loss: 0.14871766\n",
      "epoch: 22  batch: 43  loss: 0.20214261\n",
      "epoch: 22  batch: 44  loss: 0.22019938\n",
      "epoch: 22  batch: 45  loss: 0.27394482\n",
      "epoch: 22  batch: 46  loss: 0.26325974\n",
      "epoch: 22  batch: 47  loss: 0.31952453\n",
      "epoch: 22  batch: 48  loss: 0.20656158\n",
      "epoch: 22  batch: 49  loss: 0.16569583\n",
      "epoch: 22  batch: 50  loss: 0.33746564\n",
      "epoch: 22  batch: 51  loss: 0.29463005\n",
      "epoch: 22  batch: 52  loss: 0.13479723\n",
      "epoch: 22  batch: 53  loss: 0.17573985\n",
      "epoch: 22  batch: 54  loss: 0.43031627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22  batch: 55  loss: 0.26029351\n",
      "epoch: 22  batch: 56  loss: 0.10048678\n",
      "epoch: 22  batch: 57  loss: 0.14949799\n",
      "epoch: 22  batch: 58  loss: 0.07584812\n",
      "epoch: 22  batch: 59  loss: 0.10866776\n",
      "epoch: 22  batch: 60  loss: 0.37229955\n",
      "epoch: 22  batch: 61  loss: 0.93916529\n",
      "epoch: 22  batch: 62  loss: 0.20875703\n",
      "epoch: 22  batch: 63  loss: 0.39839962\n",
      "epoch: 22  batch: 64  loss: 0.14506966\n",
      "epoch: 22  batch: 65  loss: 0.06056049\n",
      "epoch: 22  batch: 66  loss: 0.06889306\n",
      "epoch: 22  batch: 67  loss: 0.07925083\n",
      "epoch: 22  batch: 68  loss: 0.21727757\n",
      "epoch: 23  batch: 1  loss: 0.27013126\n",
      "epoch: 23  batch: 2  loss: 0.13110144\n",
      "epoch: 23  batch: 3  loss: 0.09926037\n",
      "epoch: 23  batch: 4  loss: 0.10346186\n",
      "epoch: 23  batch: 5  loss: 0.22669157\n",
      "epoch: 23  batch: 6  loss: 0.15462619\n",
      "epoch: 23  batch: 7  loss: 0.30102977\n",
      "epoch: 23  batch: 8  loss: 0.13267314\n",
      "epoch: 23  batch: 9  loss: 0.26597854\n",
      "epoch: 23  batch: 10  loss: 0.28299782\n",
      "epoch: 23  batch: 11  loss: 0.30768457\n",
      "epoch: 23  batch: 12  loss: 0.22169887\n",
      "epoch: 23  batch: 13  loss: 0.35997111\n",
      "epoch: 23  batch: 14  loss: 0.23862481\n",
      "epoch: 23  batch: 15  loss: 0.20759150\n",
      "epoch: 23  batch: 16  loss: 0.21809626\n",
      "epoch: 23  batch: 17  loss: 0.44064608\n",
      "epoch: 23  batch: 18  loss: 0.17196666\n",
      "epoch: 23  batch: 19  loss: 0.18313898\n",
      "epoch: 23  batch: 20  loss: 0.35306790\n",
      "epoch: 23  batch: 21  loss: 0.41821662\n",
      "epoch: 23  batch: 22  loss: 0.08077469\n",
      "epoch: 23  batch: 23  loss: 0.08408774\n",
      "epoch: 23  batch: 24  loss: 0.06118528\n",
      "epoch: 23  batch: 25  loss: 0.07210168\n",
      "epoch: 23  batch: 26  loss: 0.40030348\n",
      "epoch: 23  batch: 27  loss: 0.74484652\n",
      "epoch: 23  batch: 28  loss: 0.34841251\n",
      "epoch: 23  batch: 29  loss: 0.26998761\n",
      "epoch: 23  batch: 30  loss: 0.18277414\n",
      "epoch: 23  batch: 31  loss: 0.10317322\n",
      "epoch: 23  batch: 32  loss: 0.05911497\n",
      "epoch: 23  batch: 33  loss: 0.11511515\n",
      "epoch: 23  batch: 34  loss: 0.14732832\n",
      "epoch: 23  batch: 35  loss: 0.25952208\n",
      "epoch: 23  batch: 36  loss: 0.05298857\n",
      "epoch: 23  batch: 37  loss: 0.06372642\n",
      "epoch: 23  batch: 38  loss: 0.07630827\n",
      "epoch: 23  batch: 39  loss: 0.38695291\n",
      "epoch: 23  batch: 40  loss: 0.21340854\n",
      "epoch: 23  batch: 41  loss: 0.32711262\n",
      "epoch: 23  batch: 42  loss: 0.22832830\n",
      "epoch: 23  batch: 43  loss: 0.43376732\n",
      "epoch: 23  batch: 44  loss: 0.39218116\n",
      "epoch: 23  batch: 45  loss: 0.35971487\n",
      "epoch: 23  batch: 46  loss: 0.21352793\n",
      "epoch: 23  batch: 47  loss: 0.22417203\n",
      "epoch: 23  batch: 48  loss: 0.17026636\n",
      "epoch: 23  batch: 49  loss: 0.15844318\n",
      "epoch: 23  batch: 50  loss: 0.28925905\n",
      "epoch: 23  batch: 51  loss: 0.23377162\n",
      "epoch: 23  batch: 52  loss: 0.12431598\n",
      "epoch: 23  batch: 53  loss: 0.12265218\n",
      "epoch: 23  batch: 54  loss: 0.35961914\n",
      "epoch: 23  batch: 55  loss: 0.23339957\n",
      "epoch: 23  batch: 56  loss: 0.08080997\n",
      "epoch: 23  batch: 57  loss: 0.11438876\n",
      "epoch: 23  batch: 58  loss: 0.09498020\n",
      "epoch: 23  batch: 59  loss: 0.13260557\n",
      "epoch: 23  batch: 60  loss: 0.35847652\n",
      "epoch: 23  batch: 61  loss: 0.83156878\n",
      "epoch: 23  batch: 62  loss: 0.23010077\n",
      "epoch: 23  batch: 63  loss: 0.39031389\n",
      "epoch: 23  batch: 64  loss: 0.25397825\n",
      "epoch: 23  batch: 65  loss: 0.03194048\n",
      "epoch: 23  batch: 66  loss: 0.03368428\n",
      "epoch: 23  batch: 67  loss: 0.06990820\n",
      "epoch: 23  batch: 68  loss: 0.12424106\n",
      "epoch: 24  batch: 1  loss: 0.22508837\n",
      "epoch: 24  batch: 2  loss: 0.07333311\n",
      "epoch: 24  batch: 3  loss: 0.12501225\n",
      "epoch: 24  batch: 4  loss: 0.10081823\n",
      "epoch: 24  batch: 5  loss: 0.26223224\n",
      "epoch: 24  batch: 6  loss: 0.21049415\n",
      "epoch: 24  batch: 7  loss: 0.30470636\n",
      "epoch: 24  batch: 8  loss: 0.19920905\n",
      "epoch: 24  batch: 9  loss: 0.32360825\n",
      "epoch: 24  batch: 10  loss: 0.29639831\n",
      "epoch: 24  batch: 11  loss: 0.37352833\n",
      "epoch: 24  batch: 12  loss: 0.19440295\n",
      "epoch: 24  batch: 13  loss: 0.21705972\n",
      "epoch: 24  batch: 14  loss: 0.20459586\n",
      "epoch: 24  batch: 15  loss: 0.17878558\n",
      "epoch: 24  batch: 16  loss: 0.16354994\n",
      "epoch: 24  batch: 17  loss: 0.31490496\n",
      "epoch: 24  batch: 18  loss: 0.11791341\n",
      "epoch: 24  batch: 19  loss: 0.17214888\n",
      "epoch: 24  batch: 20  loss: 0.31157181\n",
      "epoch: 24  batch: 21  loss: 0.39568961\n",
      "epoch: 24  batch: 22  loss: 0.09319405\n",
      "epoch: 24  batch: 23  loss: 0.11410394\n",
      "epoch: 24  batch: 24  loss: 0.07823921\n",
      "epoch: 24  batch: 25  loss: 0.05443776\n",
      "epoch: 24  batch: 26  loss: 0.38576213\n",
      "epoch: 24  batch: 27  loss: 0.82015127\n",
      "epoch: 24  batch: 28  loss: 0.33934474\n",
      "epoch: 24  batch: 29  loss: 0.28842530\n",
      "epoch: 24  batch: 30  loss: 0.19307826\n",
      "epoch: 24  batch: 31  loss: 0.06854376\n",
      "epoch: 24  batch: 32  loss: 0.02812374\n",
      "epoch: 24  batch: 33  loss: 0.04088452\n",
      "epoch: 24  batch: 34  loss: 0.11294921\n",
      "epoch: 24  batch: 35  loss: 0.22174568\n",
      "epoch: 24  batch: 36  loss: 0.05920627\n",
      "epoch: 24  batch: 37  loss: 0.07376935\n",
      "epoch: 24  batch: 38  loss: 0.10775308\n",
      "epoch: 24  batch: 39  loss: 0.32497111\n",
      "epoch: 24  batch: 40  loss: 0.08971938\n",
      "epoch: 24  batch: 41  loss: 0.31972590\n",
      "epoch: 24  batch: 42  loss: 0.17413978\n",
      "epoch: 24  batch: 43  loss: 0.24501750\n",
      "epoch: 24  batch: 44  loss: 0.30649391\n",
      "epoch: 24  batch: 45  loss: 0.28637412\n",
      "epoch: 24  batch: 46  loss: 0.18616976\n",
      "epoch: 24  batch: 47  loss: 0.22110777\n",
      "epoch: 24  batch: 48  loss: 0.18356730\n",
      "epoch: 24  batch: 49  loss: 0.14044334\n",
      "epoch: 24  batch: 50  loss: 0.24862072\n",
      "epoch: 24  batch: 51  loss: 0.19317098\n",
      "epoch: 24  batch: 52  loss: 0.08541633\n",
      "epoch: 24  batch: 53  loss: 0.12249673\n",
      "epoch: 24  batch: 54  loss: 0.36605412\n",
      "epoch: 24  batch: 55  loss: 0.23047924\n",
      "epoch: 24  batch: 56  loss: 0.08620279\n",
      "epoch: 24  batch: 57  loss: 0.05419598\n",
      "epoch: 24  batch: 58  loss: 0.09516281\n",
      "epoch: 24  batch: 59  loss: 0.11147252\n",
      "epoch: 24  batch: 60  loss: 0.35433522\n",
      "epoch: 24  batch: 61  loss: 0.80635571\n",
      "epoch: 24  batch: 62  loss: 0.17363337\n",
      "epoch: 24  batch: 63  loss: 0.35117254\n",
      "epoch: 24  batch: 64  loss: 0.18201362\n",
      "epoch: 24  batch: 65  loss: 0.03529919\n",
      "epoch: 24  batch: 66  loss: 0.04335989\n",
      "epoch: 24  batch: 67  loss: 0.07796293\n",
      "epoch: 24  batch: 68  loss: 0.15795657\n",
      "epoch: 25  batch: 1  loss: 0.22980975\n",
      "epoch: 25  batch: 2  loss: 0.09175002\n",
      "epoch: 25  batch: 3  loss: 0.09470158\n",
      "epoch: 25  batch: 4  loss: 0.07299791\n",
      "epoch: 25  batch: 5  loss: 0.24272798\n",
      "epoch: 25  batch: 6  loss: 0.15667319\n",
      "epoch: 25  batch: 7  loss: 0.28122702\n",
      "epoch: 25  batch: 8  loss: 0.16218887\n",
      "epoch: 25  batch: 9  loss: 0.21232846\n",
      "epoch: 25  batch: 10  loss: 0.27361959\n",
      "epoch: 25  batch: 11  loss: 0.39137948\n",
      "epoch: 25  batch: 12  loss: 0.19969228\n",
      "epoch: 25  batch: 13  loss: 0.19370143\n",
      "epoch: 25  batch: 14  loss: 0.18540482\n",
      "epoch: 25  batch: 15  loss: 0.18677270\n",
      "epoch: 25  batch: 16  loss: 0.16221066\n",
      "epoch: 25  batch: 17  loss: 0.28205857\n",
      "epoch: 25  batch: 18  loss: 0.09662359\n",
      "epoch: 25  batch: 19  loss: 0.13538319\n",
      "epoch: 25  batch: 20  loss: 0.29709455\n",
      "epoch: 25  batch: 21  loss: 0.38968930\n",
      "epoch: 25  batch: 22  loss: 0.08373651\n",
      "epoch: 25  batch: 23  loss: 0.08142190\n",
      "epoch: 25  batch: 24  loss: 0.07200592\n",
      "epoch: 25  batch: 25  loss: 0.09652812\n",
      "epoch: 25  batch: 26  loss: 0.31228253\n",
      "epoch: 25  batch: 27  loss: 0.75072795\n",
      "epoch: 25  batch: 28  loss: 0.33278328\n",
      "epoch: 25  batch: 29  loss: 0.33659720\n",
      "epoch: 25  batch: 30  loss: 0.21075791\n",
      "epoch: 25  batch: 31  loss: 0.07617656\n",
      "epoch: 25  batch: 32  loss: 0.02708442\n",
      "epoch: 25  batch: 33  loss: 0.06014910\n",
      "epoch: 25  batch: 34  loss: 0.10817700\n",
      "epoch: 25  batch: 35  loss: 0.26990640\n",
      "epoch: 25  batch: 36  loss: 0.05871850\n",
      "epoch: 25  batch: 37  loss: 0.10158101\n",
      "epoch: 25  batch: 38  loss: 0.09645172\n",
      "epoch: 25  batch: 39  loss: 0.27982092\n",
      "epoch: 25  batch: 40  loss: 0.08164553\n",
      "epoch: 25  batch: 41  loss: 0.28040692\n",
      "epoch: 25  batch: 42  loss: 0.19276175\n",
      "epoch: 25  batch: 43  loss: 0.20442551\n",
      "epoch: 25  batch: 44  loss: 0.26456839\n",
      "epoch: 25  batch: 45  loss: 0.24312639\n",
      "epoch: 25  batch: 46  loss: 0.19924648\n",
      "epoch: 25  batch: 47  loss: 0.22423902\n",
      "epoch: 25  batch: 48  loss: 0.16512063\n",
      "epoch: 25  batch: 49  loss: 0.14225657\n",
      "epoch: 25  batch: 50  loss: 0.23321682\n",
      "epoch: 25  batch: 51  loss: 0.14085720\n",
      "epoch: 25  batch: 52  loss: 0.10410409\n",
      "epoch: 25  batch: 53  loss: 0.10853879\n",
      "epoch: 25  batch: 54  loss: 0.36004463\n",
      "epoch: 25  batch: 55  loss: 0.22956175\n",
      "epoch: 25  batch: 56  loss: 0.08912399\n",
      "epoch: 25  batch: 57  loss: 0.06476396\n",
      "epoch: 25  batch: 58  loss: 0.11535194\n",
      "epoch: 25  batch: 59  loss: 0.10863851\n",
      "epoch: 25  batch: 60  loss: 0.38631636\n",
      "epoch: 25  batch: 61  loss: 0.69848686\n",
      "epoch: 25  batch: 62  loss: 0.17359871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25  batch: 63  loss: 0.30099347\n",
      "epoch: 25  batch: 64  loss: 0.21455060\n",
      "epoch: 25  batch: 65  loss: 0.04123782\n",
      "epoch: 25  batch: 66  loss: 0.06813993\n",
      "epoch: 25  batch: 67  loss: 0.11653282\n",
      "epoch: 25  batch: 68  loss: 0.14123440\n",
      "epoch: 26  batch: 1  loss: 0.22953017\n",
      "epoch: 26  batch: 2  loss: 0.11614947\n",
      "epoch: 26  batch: 3  loss: 0.10995580\n",
      "epoch: 26  batch: 4  loss: 0.11289438\n",
      "epoch: 26  batch: 5  loss: 0.20857345\n",
      "epoch: 26  batch: 6  loss: 0.18803868\n",
      "epoch: 26  batch: 7  loss: 0.28543237\n",
      "epoch: 26  batch: 8  loss: 0.19747221\n",
      "epoch: 26  batch: 9  loss: 0.32288146\n",
      "epoch: 26  batch: 10  loss: 0.29291460\n",
      "epoch: 26  batch: 11  loss: 0.32573560\n",
      "epoch: 26  batch: 12  loss: 0.19386275\n",
      "epoch: 26  batch: 13  loss: 0.28030893\n",
      "epoch: 26  batch: 14  loss: 0.17308702\n",
      "epoch: 26  batch: 15  loss: 0.15078640\n",
      "epoch: 26  batch: 16  loss: 0.17808050\n",
      "epoch: 26  batch: 17  loss: 0.31548637\n",
      "epoch: 26  batch: 18  loss: 0.10185727\n",
      "epoch: 26  batch: 19  loss: 0.14499260\n",
      "epoch: 26  batch: 20  loss: 0.29211608\n",
      "epoch: 26  batch: 21  loss: 0.36734757\n",
      "epoch: 26  batch: 22  loss: 0.06739574\n",
      "epoch: 26  batch: 23  loss: 0.07856908\n",
      "epoch: 26  batch: 24  loss: 0.07551876\n",
      "epoch: 26  batch: 25  loss: 0.07661788\n",
      "epoch: 26  batch: 26  loss: 0.38236412\n",
      "epoch: 26  batch: 27  loss: 0.72237647\n",
      "epoch: 26  batch: 28  loss: 0.34637639\n",
      "epoch: 26  batch: 29  loss: 0.27670395\n",
      "epoch: 26  batch: 30  loss: 0.17767374\n",
      "epoch: 26  batch: 31  loss: 0.04876650\n",
      "epoch: 26  batch: 32  loss: 0.02914907\n",
      "epoch: 26  batch: 33  loss: 0.06629143\n",
      "epoch: 26  batch: 34  loss: 0.11249909\n",
      "epoch: 26  batch: 35  loss: 0.21677777\n",
      "epoch: 26  batch: 36  loss: 0.08534050\n",
      "epoch: 26  batch: 37  loss: 0.08389640\n",
      "epoch: 26  batch: 38  loss: 0.07711899\n",
      "epoch: 26  batch: 39  loss: 0.32906598\n",
      "epoch: 26  batch: 40  loss: 0.09719105\n",
      "epoch: 26  batch: 41  loss: 0.39761940\n",
      "epoch: 26  batch: 42  loss: 0.25754669\n",
      "epoch: 26  batch: 43  loss: 0.18601473\n",
      "epoch: 26  batch: 44  loss: 0.26403323\n",
      "epoch: 26  batch: 45  loss: 0.29877844\n",
      "epoch: 26  batch: 46  loss: 0.18750472\n",
      "epoch: 26  batch: 47  loss: 0.20773987\n",
      "epoch: 26  batch: 48  loss: 0.14974403\n",
      "epoch: 26  batch: 49  loss: 0.13276911\n",
      "epoch: 26  batch: 50  loss: 0.20946622\n",
      "epoch: 26  batch: 51  loss: 0.13012789\n",
      "epoch: 26  batch: 52  loss: 0.09735237\n",
      "epoch: 26  batch: 53  loss: 0.12966144\n",
      "epoch: 26  batch: 54  loss: 0.36131373\n",
      "epoch: 26  batch: 55  loss: 0.24122904\n",
      "epoch: 26  batch: 56  loss: 0.08296279\n",
      "epoch: 26  batch: 57  loss: 0.07866523\n",
      "epoch: 26  batch: 58  loss: 0.09683844\n",
      "epoch: 26  batch: 59  loss: 0.11305838\n",
      "epoch: 26  batch: 60  loss: 0.35373271\n",
      "epoch: 26  batch: 61  loss: 0.65149540\n",
      "epoch: 26  batch: 62  loss: 0.15934291\n",
      "epoch: 26  batch: 63  loss: 0.28216413\n",
      "epoch: 26  batch: 64  loss: 0.24294090\n",
      "epoch: 26  batch: 65  loss: 0.05740907\n",
      "epoch: 26  batch: 66  loss: 0.05450365\n",
      "epoch: 26  batch: 67  loss: 0.06339151\n",
      "epoch: 26  batch: 68  loss: 0.13379237\n",
      "epoch: 27  batch: 1  loss: 0.19544305\n",
      "epoch: 27  batch: 2  loss: 0.08758137\n",
      "epoch: 27  batch: 3  loss: 0.13442640\n",
      "epoch: 27  batch: 4  loss: 0.08402204\n",
      "epoch: 27  batch: 5  loss: 0.19894539\n",
      "epoch: 27  batch: 6  loss: 0.22838886\n",
      "epoch: 27  batch: 7  loss: 0.27997780\n",
      "epoch: 27  batch: 8  loss: 0.23884825\n",
      "epoch: 27  batch: 9  loss: 0.26902917\n",
      "epoch: 27  batch: 10  loss: 0.33503759\n",
      "epoch: 27  batch: 11  loss: 0.30691379\n",
      "epoch: 27  batch: 12  loss: 0.20993280\n",
      "epoch: 27  batch: 13  loss: 0.23418683\n",
      "epoch: 27  batch: 14  loss: 0.16791204\n",
      "epoch: 27  batch: 15  loss: 0.15076053\n",
      "epoch: 27  batch: 16  loss: 0.17173885\n",
      "epoch: 27  batch: 17  loss: 0.26439133\n",
      "epoch: 27  batch: 18  loss: 0.13074751\n",
      "epoch: 27  batch: 19  loss: 0.11759423\n",
      "epoch: 27  batch: 20  loss: 0.29302320\n",
      "epoch: 27  batch: 21  loss: 0.36465520\n",
      "epoch: 27  batch: 22  loss: 0.07727586\n",
      "epoch: 27  batch: 23  loss: 0.06981049\n",
      "epoch: 27  batch: 24  loss: 0.07563717\n",
      "epoch: 27  batch: 25  loss: 0.06856409\n",
      "epoch: 27  batch: 26  loss: 0.33713248\n",
      "epoch: 27  batch: 27  loss: 0.77660000\n",
      "epoch: 27  batch: 28  loss: 0.31545061\n",
      "epoch: 27  batch: 29  loss: 0.27148777\n",
      "epoch: 27  batch: 30  loss: 0.17763241\n",
      "epoch: 27  batch: 31  loss: 0.05476902\n",
      "epoch: 27  batch: 32  loss: 0.02760281\n",
      "epoch: 27  batch: 33  loss: 0.05124396\n",
      "epoch: 27  batch: 34  loss: 0.10473625\n",
      "epoch: 27  batch: 35  loss: 0.19944356\n",
      "epoch: 27  batch: 36  loss: 0.06929944\n",
      "epoch: 27  batch: 37  loss: 0.07369166\n",
      "epoch: 27  batch: 38  loss: 0.08296783\n",
      "epoch: 27  batch: 39  loss: 0.33218211\n",
      "epoch: 27  batch: 40  loss: 0.09467059\n",
      "epoch: 27  batch: 41  loss: 0.26910228\n",
      "epoch: 27  batch: 42  loss: 0.23185697\n",
      "epoch: 27  batch: 43  loss: 0.17629401\n",
      "epoch: 27  batch: 44  loss: 0.23766422\n",
      "epoch: 27  batch: 45  loss: 0.30337441\n",
      "epoch: 27  batch: 46  loss: 0.23363166\n",
      "epoch: 27  batch: 47  loss: 0.17371358\n",
      "epoch: 27  batch: 48  loss: 0.16011615\n",
      "epoch: 27  batch: 49  loss: 0.13177735\n",
      "epoch: 27  batch: 50  loss: 0.20482169\n",
      "epoch: 27  batch: 51  loss: 0.18237555\n",
      "epoch: 27  batch: 52  loss: 0.14249615\n",
      "epoch: 27  batch: 53  loss: 0.16161691\n",
      "epoch: 27  batch: 54  loss: 0.37287241\n",
      "epoch: 27  batch: 55  loss: 0.24034886\n",
      "epoch: 27  batch: 56  loss: 0.08688562\n",
      "epoch: 27  batch: 57  loss: 0.10237008\n",
      "epoch: 27  batch: 58  loss: 0.07939190\n",
      "epoch: 27  batch: 59  loss: 0.10812481\n",
      "epoch: 27  batch: 60  loss: 0.30273649\n",
      "epoch: 27  batch: 61  loss: 0.82217205\n",
      "epoch: 27  batch: 62  loss: 0.20835161\n",
      "epoch: 27  batch: 63  loss: 0.30022049\n",
      "epoch: 27  batch: 64  loss: 0.23259002\n",
      "epoch: 27  batch: 65  loss: 0.05804123\n",
      "epoch: 27  batch: 66  loss: 0.05181160\n",
      "epoch: 27  batch: 67  loss: 0.05450907\n",
      "epoch: 27  batch: 68  loss: 0.12718606\n",
      "epoch: 28  batch: 1  loss: 0.23365636\n",
      "epoch: 28  batch: 2  loss: 0.08518362\n",
      "epoch: 28  batch: 3  loss: 0.12157464\n",
      "epoch: 28  batch: 4  loss: 0.10900072\n",
      "epoch: 28  batch: 5  loss: 0.22672370\n",
      "epoch: 28  batch: 6  loss: 0.20930609\n",
      "epoch: 28  batch: 7  loss: 0.32267225\n",
      "epoch: 28  batch: 8  loss: 0.20732889\n",
      "epoch: 28  batch: 9  loss: 0.30937871\n",
      "epoch: 28  batch: 10  loss: 0.30638209\n",
      "epoch: 28  batch: 11  loss: 0.37201479\n",
      "epoch: 28  batch: 12  loss: 0.20106870\n",
      "epoch: 28  batch: 13  loss: 0.17049965\n",
      "epoch: 28  batch: 14  loss: 0.16950615\n",
      "epoch: 28  batch: 15  loss: 0.16180748\n",
      "epoch: 28  batch: 16  loss: 0.17108817\n",
      "epoch: 28  batch: 17  loss: 0.26504245\n",
      "epoch: 28  batch: 18  loss: 0.09417682\n",
      "epoch: 28  batch: 19  loss: 0.10742857\n",
      "epoch: 28  batch: 20  loss: 0.28258312\n",
      "epoch: 28  batch: 21  loss: 0.34668261\n",
      "epoch: 28  batch: 22  loss: 0.07598010\n",
      "epoch: 28  batch: 23  loss: 0.07565892\n",
      "epoch: 28  batch: 24  loss: 0.07520470\n",
      "epoch: 28  batch: 25  loss: 0.11699390\n",
      "epoch: 28  batch: 26  loss: 0.29335177\n",
      "epoch: 28  batch: 27  loss: 0.69595814\n",
      "epoch: 28  batch: 28  loss: 0.34488937\n",
      "epoch: 28  batch: 29  loss: 0.32865465\n",
      "epoch: 28  batch: 30  loss: 0.15471216\n",
      "epoch: 28  batch: 31  loss: 0.06080220\n",
      "epoch: 28  batch: 32  loss: 0.03950270\n",
      "epoch: 28  batch: 33  loss: 0.06748784\n",
      "epoch: 28  batch: 34  loss: 0.10569765\n",
      "epoch: 28  batch: 35  loss: 0.18612589\n",
      "epoch: 28  batch: 36  loss: 0.04398980\n",
      "epoch: 28  batch: 37  loss: 0.06194620\n",
      "epoch: 28  batch: 38  loss: 0.10530423\n",
      "epoch: 28  batch: 39  loss: 0.28181744\n",
      "epoch: 28  batch: 40  loss: 0.11832032\n",
      "epoch: 28  batch: 41  loss: 0.26368102\n",
      "epoch: 28  batch: 42  loss: 0.16134845\n",
      "epoch: 28  batch: 43  loss: 0.17018098\n",
      "epoch: 28  batch: 44  loss: 0.31992358\n",
      "epoch: 28  batch: 45  loss: 0.25662598\n",
      "epoch: 28  batch: 46  loss: 0.19516945\n",
      "epoch: 28  batch: 47  loss: 0.21908544\n",
      "epoch: 28  batch: 48  loss: 0.15911384\n",
      "epoch: 28  batch: 49  loss: 0.16418926\n",
      "epoch: 28  batch: 50  loss: 0.24649327\n",
      "epoch: 28  batch: 51  loss: 0.19293603\n",
      "epoch: 28  batch: 52  loss: 0.10130418\n",
      "epoch: 28  batch: 53  loss: 0.10172518\n",
      "epoch: 28  batch: 54  loss: 0.36423814\n",
      "epoch: 28  batch: 55  loss: 0.23478445\n",
      "epoch: 28  batch: 56  loss: 0.08158753\n",
      "epoch: 28  batch: 57  loss: 0.07661106\n",
      "epoch: 28  batch: 58  loss: 0.09420480\n",
      "epoch: 28  batch: 59  loss: 0.12466721\n",
      "epoch: 28  batch: 60  loss: 0.30871481\n",
      "epoch: 28  batch: 61  loss: 0.83588189\n",
      "epoch: 28  batch: 62  loss: 0.18087541\n",
      "epoch: 28  batch: 63  loss: 0.26199594\n",
      "epoch: 28  batch: 64  loss: 0.14597018\n",
      "epoch: 28  batch: 65  loss: 0.07289901\n",
      "epoch: 28  batch: 66  loss: 0.04455207\n",
      "epoch: 28  batch: 67  loss: 0.07087837\n",
      "epoch: 28  batch: 68  loss: 0.11229540\n",
      "epoch: 29  batch: 1  loss: 0.21805146\n",
      "epoch: 29  batch: 2  loss: 0.09168176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29  batch: 3  loss: 0.09527376\n",
      "epoch: 29  batch: 4  loss: 0.10306327\n",
      "epoch: 29  batch: 5  loss: 0.20939152\n",
      "epoch: 29  batch: 6  loss: 0.20336419\n",
      "epoch: 29  batch: 7  loss: 0.28445300\n",
      "epoch: 29  batch: 8  loss: 0.12219511\n",
      "epoch: 29  batch: 9  loss: 0.34369364\n",
      "epoch: 29  batch: 10  loss: 0.45733637\n",
      "epoch: 29  batch: 11  loss: 0.43496507\n",
      "epoch: 29  batch: 12  loss: 0.19598389\n",
      "epoch: 29  batch: 13  loss: 0.17010224\n",
      "epoch: 29  batch: 14  loss: 0.16246779\n",
      "epoch: 29  batch: 15  loss: 0.14339797\n",
      "epoch: 29  batch: 16  loss: 0.17536922\n",
      "epoch: 29  batch: 17  loss: 0.26435804\n",
      "epoch: 29  batch: 18  loss: 0.08842672\n",
      "epoch: 29  batch: 19  loss: 0.09509337\n",
      "epoch: 29  batch: 20  loss: 0.27835470\n",
      "epoch: 29  batch: 21  loss: 0.39532337\n",
      "epoch: 29  batch: 22  loss: 0.07341673\n",
      "epoch: 29  batch: 23  loss: 0.06591205\n",
      "epoch: 29  batch: 24  loss: 0.07531210\n",
      "epoch: 29  batch: 25  loss: 0.11413448\n",
      "epoch: 29  batch: 26  loss: 0.29012138\n",
      "epoch: 29  batch: 27  loss: 0.78815812\n",
      "epoch: 29  batch: 28  loss: 0.41768965\n",
      "epoch: 29  batch: 29  loss: 0.25503042\n",
      "epoch: 29  batch: 30  loss: 0.17242503\n",
      "epoch: 29  batch: 31  loss: 0.08315589\n",
      "epoch: 29  batch: 32  loss: 0.02737905\n",
      "epoch: 29  batch: 33  loss: 0.03714116\n",
      "epoch: 29  batch: 34  loss: 0.10801440\n",
      "epoch: 29  batch: 35  loss: 0.23112984\n",
      "epoch: 29  batch: 36  loss: 0.04135353\n",
      "epoch: 29  batch: 37  loss: 0.05796238\n",
      "epoch: 29  batch: 38  loss: 0.07351860\n",
      "epoch: 29  batch: 39  loss: 0.27290741\n",
      "epoch: 29  batch: 40  loss: 0.11229989\n",
      "epoch: 29  batch: 41  loss: 0.27750835\n",
      "epoch: 29  batch: 42  loss: 0.26994342\n",
      "epoch: 29  batch: 43  loss: 0.19307870\n",
      "epoch: 29  batch: 44  loss: 0.32131645\n",
      "epoch: 29  batch: 45  loss: 0.26699603\n",
      "epoch: 29  batch: 46  loss: 0.20157857\n",
      "epoch: 29  batch: 47  loss: 0.24181491\n",
      "epoch: 29  batch: 48  loss: 0.16174591\n",
      "epoch: 29  batch: 49  loss: 0.16458789\n",
      "epoch: 29  batch: 50  loss: 0.25765637\n",
      "epoch: 29  batch: 51  loss: 0.20493625\n",
      "epoch: 29  batch: 52  loss: 0.09682819\n",
      "epoch: 29  batch: 53  loss: 0.11392964\n",
      "epoch: 29  batch: 54  loss: 0.36285827\n",
      "epoch: 29  batch: 55  loss: 0.23706721\n",
      "epoch: 29  batch: 56  loss: 0.08208919\n",
      "epoch: 29  batch: 57  loss: 0.11510718\n",
      "epoch: 29  batch: 58  loss: 0.09766144\n",
      "epoch: 29  batch: 59  loss: 0.12013780\n",
      "epoch: 29  batch: 60  loss: 0.27446011\n",
      "epoch: 29  batch: 61  loss: 0.89565378\n",
      "epoch: 29  batch: 62  loss: 0.20467494\n",
      "epoch: 29  batch: 63  loss: 0.35676610\n",
      "epoch: 29  batch: 64  loss: 0.14638464\n",
      "epoch: 29  batch: 65  loss: 0.03686280\n",
      "epoch: 29  batch: 66  loss: 0.04789737\n",
      "epoch: 29  batch: 67  loss: 0.08328176\n",
      "epoch: 29  batch: 68  loss: 0.12075634\n",
      "epoch: 30  batch: 1  loss: 0.23890528\n",
      "epoch: 30  batch: 2  loss: 0.08281435\n",
      "epoch: 30  batch: 3  loss: 0.12653415\n",
      "epoch: 30  batch: 4  loss: 0.08448374\n",
      "epoch: 30  batch: 5  loss: 0.24402784\n",
      "epoch: 30  batch: 6  loss: 0.18688114\n",
      "epoch: 30  batch: 7  loss: 0.29177609\n",
      "epoch: 30  batch: 8  loss: 0.18743469\n",
      "epoch: 30  batch: 9  loss: 0.37446710\n",
      "epoch: 30  batch: 10  loss: 0.30691162\n",
      "epoch: 30  batch: 11  loss: 0.28487542\n",
      "epoch: 30  batch: 12  loss: 0.19619052\n",
      "epoch: 30  batch: 13  loss: 0.19809932\n",
      "epoch: 30  batch: 14  loss: 0.17051019\n",
      "epoch: 30  batch: 15  loss: 0.14310752\n",
      "epoch: 30  batch: 16  loss: 0.17690703\n",
      "epoch: 30  batch: 17  loss: 0.27505982\n",
      "epoch: 30  batch: 18  loss: 0.10388555\n",
      "epoch: 30  batch: 19  loss: 0.10334352\n",
      "epoch: 30  batch: 20  loss: 0.26722583\n",
      "epoch: 30  batch: 21  loss: 0.32668984\n",
      "epoch: 30  batch: 22  loss: 0.07715718\n",
      "epoch: 30  batch: 23  loss: 0.08942787\n",
      "epoch: 30  batch: 24  loss: 0.07607877\n",
      "epoch: 30  batch: 25  loss: 0.11261530\n",
      "epoch: 30  batch: 26  loss: 0.34537554\n",
      "epoch: 30  batch: 27  loss: 0.69025230\n",
      "epoch: 30  batch: 28  loss: 0.33053845\n",
      "epoch: 30  batch: 29  loss: 0.33214545\n",
      "epoch: 30  batch: 30  loss: 0.16021509\n",
      "epoch: 30  batch: 31  loss: 0.07471341\n",
      "epoch: 30  batch: 32  loss: 0.05269502\n",
      "epoch: 30  batch: 33  loss: 0.09797622\n",
      "epoch: 30  batch: 34  loss: 0.13957496\n",
      "epoch: 30  batch: 35  loss: 0.29950413\n",
      "epoch: 30  batch: 36  loss: 0.04045145\n",
      "epoch: 30  batch: 37  loss: 0.04166209\n",
      "epoch: 30  batch: 38  loss: 0.05429287\n",
      "epoch: 30  batch: 39  loss: 0.25684571\n",
      "epoch: 30  batch: 40  loss: 0.10699794\n",
      "epoch: 30  batch: 41  loss: 0.24828051\n",
      "epoch: 30  batch: 42  loss: 0.12371127\n",
      "epoch: 30  batch: 43  loss: 0.15297651\n",
      "epoch: 30  batch: 44  loss: 0.35925674\n",
      "epoch: 30  batch: 45  loss: 0.26601329\n",
      "epoch: 30  batch: 46  loss: 0.19416663\n",
      "epoch: 30  batch: 47  loss: 0.22624563\n",
      "epoch: 30  batch: 48  loss: 0.18397234\n",
      "epoch: 30  batch: 49  loss: 0.14626062\n",
      "epoch: 30  batch: 50  loss: 0.24974464\n",
      "epoch: 30  batch: 51  loss: 0.22435740\n",
      "epoch: 30  batch: 52  loss: 0.09015590\n",
      "epoch: 30  batch: 53  loss: 0.10217813\n",
      "epoch: 30  batch: 54  loss: 0.37988120\n",
      "epoch: 30  batch: 55  loss: 0.22999497\n",
      "epoch: 30  batch: 56  loss: 0.08656808\n",
      "epoch: 30  batch: 57  loss: 0.09210827\n",
      "epoch: 30  batch: 58  loss: 0.10413566\n",
      "epoch: 30  batch: 59  loss: 0.10309385\n",
      "epoch: 30  batch: 60  loss: 0.32950607\n",
      "epoch: 30  batch: 61  loss: 0.71785212\n",
      "epoch: 30  batch: 62  loss: 0.15188049\n",
      "epoch: 30  batch: 63  loss: 0.28895628\n",
      "epoch: 30  batch: 64  loss: 0.22772230\n",
      "epoch: 30  batch: 65  loss: 0.05453182\n",
      "epoch: 30  batch: 66  loss: 0.06280905\n",
      "epoch: 30  batch: 67  loss: 0.10563997\n",
      "epoch: 30  batch: 68  loss: 0.16969870\n",
      "epoch: 31  batch: 1  loss: 0.22397742\n",
      "epoch: 31  batch: 2  loss: 0.13806702\n",
      "epoch: 31  batch: 3  loss: 0.08992184\n",
      "epoch: 31  batch: 4  loss: 0.07522254\n",
      "epoch: 31  batch: 5  loss: 0.25863814\n",
      "epoch: 31  batch: 6  loss: 0.10977908\n",
      "epoch: 31  batch: 7  loss: 0.35211885\n",
      "epoch: 31  batch: 8  loss: 0.15239207\n",
      "epoch: 31  batch: 9  loss: 0.29164028\n",
      "epoch: 31  batch: 10  loss: 0.30315495\n",
      "epoch: 31  batch: 11  loss: 0.24583204\n",
      "epoch: 31  batch: 12  loss: 0.18652865\n",
      "epoch: 31  batch: 13  loss: 0.42096186\n",
      "epoch: 31  batch: 14  loss: 0.18362501\n",
      "epoch: 31  batch: 15  loss: 0.17161885\n",
      "epoch: 31  batch: 16  loss: 0.44879398\n",
      "epoch: 31  batch: 17  loss: 0.41117013\n",
      "epoch: 31  batch: 18  loss: 0.12800483\n",
      "epoch: 31  batch: 19  loss: 0.30474418\n",
      "epoch: 31  batch: 20  loss: 0.37993041\n",
      "epoch: 31  batch: 21  loss: 0.40269998\n",
      "epoch: 31  batch: 22  loss: 0.08996182\n",
      "epoch: 31  batch: 23  loss: 0.07751250\n",
      "epoch: 31  batch: 24  loss: 0.05134365\n",
      "epoch: 31  batch: 25  loss: 0.09846172\n",
      "epoch: 31  batch: 26  loss: 0.24494214\n",
      "epoch: 31  batch: 27  loss: 0.57333511\n",
      "epoch: 31  batch: 28  loss: 0.26322827\n",
      "epoch: 31  batch: 29  loss: 0.20301989\n",
      "epoch: 31  batch: 30  loss: 0.13455504\n",
      "epoch: 31  batch: 31  loss: 0.05236500\n",
      "epoch: 31  batch: 32  loss: 0.08082990\n",
      "epoch: 31  batch: 33  loss: 0.14935596\n",
      "epoch: 31  batch: 34  loss: 0.22945623\n",
      "epoch: 31  batch: 35  loss: 0.29037672\n",
      "epoch: 31  batch: 36  loss: 0.11466113\n",
      "epoch: 31  batch: 37  loss: 0.10058912\n",
      "epoch: 31  batch: 38  loss: 0.07304705\n",
      "epoch: 31  batch: 39  loss: 0.25441769\n",
      "epoch: 31  batch: 40  loss: 0.11029064\n",
      "epoch: 31  batch: 41  loss: 0.27374339\n",
      "epoch: 31  batch: 42  loss: 0.17554867\n",
      "epoch: 31  batch: 43  loss: 0.15957054\n",
      "epoch: 31  batch: 44  loss: 0.30771393\n",
      "epoch: 31  batch: 45  loss: 0.29572034\n",
      "epoch: 31  batch: 46  loss: 0.24206051\n",
      "epoch: 31  batch: 47  loss: 0.25062463\n",
      "epoch: 31  batch: 48  loss: 0.17459762\n",
      "epoch: 31  batch: 49  loss: 0.14646332\n",
      "epoch: 31  batch: 50  loss: 0.28654858\n",
      "epoch: 31  batch: 51  loss: 0.27965397\n",
      "epoch: 31  batch: 52  loss: 0.11211942\n",
      "epoch: 31  batch: 53  loss: 0.14675495\n",
      "epoch: 31  batch: 54  loss: 0.36988559\n",
      "epoch: 31  batch: 55  loss: 0.25483924\n",
      "epoch: 31  batch: 56  loss: 0.08313496\n",
      "epoch: 31  batch: 57  loss: 0.10884292\n",
      "epoch: 31  batch: 58  loss: 0.07815541\n",
      "epoch: 31  batch: 59  loss: 0.11506172\n",
      "epoch: 31  batch: 60  loss: 0.38865316\n",
      "epoch: 31  batch: 61  loss: 0.88099229\n",
      "epoch: 31  batch: 62  loss: 0.17644316\n",
      "epoch: 31  batch: 63  loss: 0.29546759\n",
      "epoch: 31  batch: 64  loss: 0.13710737\n",
      "epoch: 31  batch: 65  loss: 0.04218141\n",
      "epoch: 31  batch: 66  loss: 0.06287406\n",
      "epoch: 31  batch: 67  loss: 0.11356527\n",
      "epoch: 31  batch: 68  loss: 0.20697689\n",
      "epoch: 32  batch: 1  loss: 0.27307868\n",
      "epoch: 32  batch: 2  loss: 0.07911815\n",
      "epoch: 32  batch: 3  loss: 0.09673426\n",
      "epoch: 32  batch: 4  loss: 0.09720857\n",
      "epoch: 32  batch: 5  loss: 0.23822114\n",
      "epoch: 32  batch: 6  loss: 0.17907178\n",
      "epoch: 32  batch: 7  loss: 0.36213940\n",
      "epoch: 32  batch: 8  loss: 0.11496186\n",
      "epoch: 32  batch: 9  loss: 0.28683928\n",
      "epoch: 32  batch: 10  loss: 0.33281803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32  batch: 11  loss: 0.32448804\n",
      "epoch: 32  batch: 12  loss: 0.14502357\n",
      "epoch: 32  batch: 13  loss: 0.31468025\n",
      "epoch: 32  batch: 14  loss: 0.22680613\n",
      "epoch: 32  batch: 15  loss: 0.13868226\n",
      "epoch: 32  batch: 16  loss: 0.19486625\n",
      "epoch: 32  batch: 17  loss: 0.39876643\n",
      "epoch: 32  batch: 18  loss: 0.15011306\n",
      "epoch: 32  batch: 19  loss: 0.30886143\n",
      "epoch: 32  batch: 20  loss: 0.32333201\n",
      "epoch: 32  batch: 21  loss: 0.37123609\n",
      "epoch: 32  batch: 22  loss: 0.08786591\n",
      "epoch: 32  batch: 23  loss: 0.13049176\n",
      "epoch: 32  batch: 24  loss: 0.06870028\n",
      "epoch: 32  batch: 25  loss: 0.07572117\n",
      "epoch: 32  batch: 26  loss: 0.33518696\n",
      "epoch: 32  batch: 27  loss: 0.71467018\n",
      "epoch: 32  batch: 28  loss: 0.34534374\n",
      "epoch: 32  batch: 29  loss: 0.25904566\n",
      "epoch: 32  batch: 30  loss: 0.17893673\n",
      "epoch: 32  batch: 31  loss: 0.07266349\n",
      "epoch: 32  batch: 32  loss: 0.03942631\n",
      "epoch: 32  batch: 33  loss: 0.03075984\n",
      "epoch: 32  batch: 34  loss: 0.11536162\n",
      "epoch: 32  batch: 35  loss: 0.20754687\n",
      "epoch: 32  batch: 36  loss: 0.05293949\n",
      "epoch: 32  batch: 37  loss: 0.10180232\n",
      "epoch: 32  batch: 38  loss: 0.06097153\n",
      "epoch: 32  batch: 39  loss: 0.28267902\n",
      "epoch: 32  batch: 40  loss: 0.16548763\n",
      "epoch: 32  batch: 41  loss: 0.38035330\n",
      "epoch: 32  batch: 42  loss: 0.25759119\n",
      "epoch: 32  batch: 43  loss: 0.33003783\n",
      "epoch: 32  batch: 44  loss: 0.32973024\n",
      "epoch: 32  batch: 45  loss: 0.48472792\n",
      "epoch: 32  batch: 46  loss: 0.22691350\n",
      "epoch: 32  batch: 47  loss: 0.20183025\n",
      "epoch: 32  batch: 48  loss: 0.15266898\n",
      "epoch: 32  batch: 49  loss: 0.14830685\n",
      "epoch: 32  batch: 50  loss: 0.25675875\n",
      "epoch: 32  batch: 51  loss: 0.22635253\n",
      "epoch: 32  batch: 52  loss: 0.09534768\n",
      "epoch: 32  batch: 53  loss: 0.10163882\n",
      "epoch: 32  batch: 54  loss: 0.42097953\n",
      "epoch: 32  batch: 55  loss: 0.24454823\n",
      "epoch: 32  batch: 56  loss: 0.09735117\n",
      "epoch: 32  batch: 57  loss: 0.08164522\n",
      "epoch: 32  batch: 58  loss: 0.10598069\n",
      "epoch: 32  batch: 59  loss: 0.10898507\n",
      "epoch: 32  batch: 60  loss: 0.39746070\n",
      "epoch: 32  batch: 61  loss: 0.80128956\n",
      "epoch: 32  batch: 62  loss: 0.20817912\n",
      "epoch: 32  batch: 63  loss: 0.32642934\n",
      "epoch: 32  batch: 64  loss: 0.19709602\n",
      "epoch: 32  batch: 65  loss: 0.04751040\n",
      "epoch: 32  batch: 66  loss: 0.03651999\n",
      "epoch: 32  batch: 67  loss: 0.08515363\n",
      "epoch: 32  batch: 68  loss: 0.16798912\n",
      "epoch: 33  batch: 1  loss: 0.25306746\n",
      "epoch: 33  batch: 2  loss: 0.07168042\n",
      "epoch: 33  batch: 3  loss: 0.02914820\n",
      "epoch: 33  batch: 4  loss: 0.03672605\n",
      "epoch: 33  batch: 5  loss: 0.17547090\n",
      "epoch: 33  batch: 6  loss: 0.13483855\n",
      "epoch: 33  batch: 7  loss: 0.29690668\n",
      "epoch: 33  batch: 8  loss: 0.19049141\n",
      "epoch: 33  batch: 9  loss: 0.28295389\n",
      "epoch: 33  batch: 10  loss: 0.40879437\n",
      "epoch: 33  batch: 11  loss: 0.38944346\n",
      "epoch: 33  batch: 12  loss: 0.21452561\n",
      "epoch: 33  batch: 13  loss: 0.18197301\n",
      "epoch: 33  batch: 14  loss: 0.24834451\n",
      "epoch: 33  batch: 15  loss: 0.19584619\n",
      "epoch: 33  batch: 16  loss: 0.14205717\n",
      "epoch: 33  batch: 17  loss: 0.25987175\n",
      "epoch: 33  batch: 18  loss: 0.12541099\n",
      "epoch: 33  batch: 19  loss: 0.14152336\n",
      "epoch: 33  batch: 20  loss: 0.31986865\n",
      "epoch: 33  batch: 21  loss: 0.39088780\n",
      "epoch: 33  batch: 22  loss: 0.08341285\n",
      "epoch: 33  batch: 23  loss: 0.06061860\n",
      "epoch: 33  batch: 24  loss: 0.09327438\n",
      "epoch: 33  batch: 25  loss: 0.08706053\n",
      "epoch: 33  batch: 26  loss: 0.32321399\n",
      "epoch: 33  batch: 27  loss: 0.65636063\n",
      "epoch: 33  batch: 28  loss: 0.36321765\n",
      "epoch: 33  batch: 29  loss: 0.31983897\n",
      "epoch: 33  batch: 30  loss: 0.22447324\n",
      "epoch: 33  batch: 31  loss: 0.08071093\n",
      "epoch: 33  batch: 32  loss: 0.03213928\n",
      "epoch: 33  batch: 33  loss: 0.07117328\n",
      "epoch: 33  batch: 34  loss: 0.12112227\n",
      "epoch: 33  batch: 35  loss: 0.20334996\n",
      "epoch: 33  batch: 36  loss: 0.04774540\n",
      "epoch: 33  batch: 37  loss: 0.05203364\n",
      "epoch: 33  batch: 38  loss: 0.11487673\n",
      "epoch: 33  batch: 39  loss: 0.26609680\n",
      "epoch: 33  batch: 40  loss: 0.10243042\n",
      "epoch: 33  batch: 41  loss: 0.28375763\n",
      "epoch: 33  batch: 42  loss: 0.20824772\n",
      "epoch: 33  batch: 43  loss: 0.25608429\n",
      "epoch: 33  batch: 44  loss: 0.47880709\n",
      "epoch: 33  batch: 45  loss: 0.45068589\n",
      "epoch: 33  batch: 46  loss: 0.26118833\n",
      "epoch: 33  batch: 47  loss: 0.18175542\n",
      "epoch: 33  batch: 48  loss: 0.16149245\n",
      "epoch: 33  batch: 49  loss: 0.15218124\n",
      "epoch: 33  batch: 50  loss: 0.29568669\n",
      "epoch: 33  batch: 51  loss: 0.21405429\n",
      "epoch: 33  batch: 52  loss: 0.09571010\n",
      "epoch: 33  batch: 53  loss: 0.13876347\n",
      "epoch: 33  batch: 54  loss: 0.36994764\n",
      "epoch: 33  batch: 55  loss: 0.23762982\n",
      "epoch: 33  batch: 56  loss: 0.08563959\n",
      "epoch: 33  batch: 57  loss: 0.05739342\n",
      "epoch: 33  batch: 58  loss: 0.13573624\n",
      "epoch: 33  batch: 59  loss: 0.11521801\n",
      "epoch: 33  batch: 60  loss: 0.37674141\n",
      "epoch: 33  batch: 61  loss: 0.91665244\n",
      "epoch: 33  batch: 62  loss: 0.22249845\n",
      "epoch: 33  batch: 63  loss: 0.35943288\n",
      "epoch: 33  batch: 64  loss: 0.15773359\n",
      "epoch: 33  batch: 65  loss: 0.08031584\n",
      "epoch: 33  batch: 66  loss: 0.06657746\n",
      "epoch: 33  batch: 67  loss: 0.08064226\n",
      "epoch: 33  batch: 68  loss: 0.17032066\n",
      "epoch: 34  batch: 1  loss: 0.23276553\n",
      "epoch: 34  batch: 2  loss: 0.11303256\n",
      "epoch: 34  batch: 3  loss: 0.10553839\n",
      "epoch: 34  batch: 4  loss: 0.08564875\n",
      "epoch: 34  batch: 5  loss: 0.21977332\n",
      "epoch: 34  batch: 6  loss: 0.17543969\n",
      "epoch: 34  batch: 7  loss: 0.34524983\n",
      "epoch: 34  batch: 8  loss: 0.18407032\n",
      "epoch: 34  batch: 9  loss: 0.17080896\n",
      "epoch: 34  batch: 10  loss: 0.38761783\n",
      "epoch: 34  batch: 11  loss: 0.34686327\n",
      "epoch: 34  batch: 12  loss: 0.20204397\n",
      "epoch: 34  batch: 13  loss: 0.32931587\n",
      "epoch: 34  batch: 14  loss: 0.23688056\n",
      "epoch: 34  batch: 15  loss: 0.17752437\n",
      "epoch: 34  batch: 16  loss: 0.17386062\n",
      "epoch: 34  batch: 17  loss: 0.37498519\n",
      "epoch: 34  batch: 18  loss: 0.16328359\n",
      "epoch: 34  batch: 19  loss: 0.14355160\n",
      "epoch: 34  batch: 20  loss: 0.32633701\n",
      "epoch: 34  batch: 21  loss: 0.39431801\n",
      "epoch: 34  batch: 22  loss: 0.10011603\n",
      "epoch: 34  batch: 23  loss: 0.09969360\n",
      "epoch: 34  batch: 24  loss: 0.08147377\n",
      "epoch: 34  batch: 25  loss: 0.06295831\n",
      "epoch: 34  batch: 26  loss: 0.33711505\n",
      "epoch: 34  batch: 27  loss: 0.75686294\n",
      "epoch: 34  batch: 28  loss: 0.42870456\n",
      "epoch: 34  batch: 29  loss: 0.32719773\n",
      "epoch: 34  batch: 30  loss: 0.23885399\n",
      "epoch: 34  batch: 31  loss: 0.11403773\n",
      "epoch: 34  batch: 32  loss: 0.05082987\n",
      "epoch: 34  batch: 33  loss: 0.03904167\n",
      "epoch: 34  batch: 34  loss: 0.11478528\n",
      "epoch: 34  batch: 35  loss: 0.22520477\n",
      "epoch: 34  batch: 36  loss: 0.05364120\n",
      "epoch: 34  batch: 37  loss: 0.08817618\n",
      "epoch: 34  batch: 38  loss: 0.06402154\n",
      "epoch: 34  batch: 39  loss: 0.25848043\n",
      "epoch: 34  batch: 40  loss: 0.14855556\n",
      "epoch: 34  batch: 41  loss: 0.34455204\n",
      "epoch: 34  batch: 42  loss: 0.22209927\n",
      "epoch: 34  batch: 43  loss: 0.25926772\n",
      "epoch: 34  batch: 44  loss: 0.35727471\n",
      "epoch: 34  batch: 45  loss: 0.30958381\n",
      "epoch: 34  batch: 46  loss: 0.21614504\n",
      "epoch: 34  batch: 47  loss: 0.22839630\n",
      "epoch: 34  batch: 48  loss: 0.15980732\n",
      "epoch: 34  batch: 49  loss: 0.15059926\n",
      "epoch: 34  batch: 50  loss: 0.23702063\n",
      "epoch: 34  batch: 51  loss: 0.22404402\n",
      "epoch: 34  batch: 52  loss: 0.08513098\n",
      "epoch: 34  batch: 53  loss: 0.13694513\n",
      "epoch: 34  batch: 54  loss: 0.35134840\n",
      "epoch: 34  batch: 55  loss: 0.24005422\n",
      "epoch: 34  batch: 56  loss: 0.08403602\n",
      "epoch: 34  batch: 57  loss: 0.06817603\n",
      "epoch: 34  batch: 58  loss: 0.11959023\n",
      "epoch: 34  batch: 59  loss: 0.11675983\n",
      "epoch: 34  batch: 60  loss: 0.34981090\n",
      "epoch: 34  batch: 61  loss: 0.68600219\n",
      "epoch: 34  batch: 62  loss: 0.19339104\n",
      "epoch: 34  batch: 63  loss: 0.37795547\n",
      "epoch: 34  batch: 64  loss: 0.19255315\n",
      "epoch: 34  batch: 65  loss: 0.03374951\n",
      "epoch: 34  batch: 66  loss: 0.03776217\n",
      "epoch: 34  batch: 67  loss: 0.07984462\n",
      "epoch: 34  batch: 68  loss: 0.12026400\n",
      "epoch: 35  batch: 1  loss: 0.21396896\n",
      "epoch: 35  batch: 2  loss: 0.07398455\n",
      "epoch: 35  batch: 3  loss: 0.09488130\n",
      "epoch: 35  batch: 4  loss: 0.11542320\n",
      "epoch: 35  batch: 5  loss: 0.17902121\n",
      "epoch: 35  batch: 6  loss: 0.20430303\n",
      "epoch: 35  batch: 7  loss: 0.34930086\n",
      "epoch: 35  batch: 8  loss: 0.19825333\n",
      "epoch: 35  batch: 9  loss: 0.21310639\n",
      "epoch: 35  batch: 10  loss: 0.34132215\n",
      "epoch: 35  batch: 11  loss: 0.32815772\n",
      "epoch: 35  batch: 12  loss: 0.18330795\n",
      "epoch: 35  batch: 13  loss: 0.18367268\n",
      "epoch: 35  batch: 14  loss: 0.16021816\n",
      "epoch: 35  batch: 15  loss: 0.16299257\n",
      "epoch: 35  batch: 16  loss: 0.15900342\n",
      "epoch: 35  batch: 17  loss: 0.28052330\n",
      "epoch: 35  batch: 18  loss: 0.12121928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35  batch: 19  loss: 0.11559682\n",
      "epoch: 35  batch: 20  loss: 0.29358134\n",
      "epoch: 35  batch: 21  loss: 0.35575962\n",
      "epoch: 35  batch: 22  loss: 0.07397801\n",
      "epoch: 35  batch: 23  loss: 0.07092743\n",
      "epoch: 35  batch: 24  loss: 0.07276905\n",
      "epoch: 35  batch: 25  loss: 0.09581505\n",
      "epoch: 35  batch: 26  loss: 0.31488118\n",
      "epoch: 35  batch: 27  loss: 0.66231871\n",
      "epoch: 35  batch: 28  loss: 0.31866008\n",
      "epoch: 35  batch: 29  loss: 0.27289850\n",
      "epoch: 35  batch: 30  loss: 0.19028041\n",
      "epoch: 35  batch: 31  loss: 0.06616038\n",
      "epoch: 35  batch: 32  loss: 0.02828376\n",
      "epoch: 35  batch: 33  loss: 0.06784026\n",
      "epoch: 35  batch: 34  loss: 0.10676818\n",
      "epoch: 35  batch: 35  loss: 0.23713697\n",
      "epoch: 35  batch: 36  loss: 0.05411850\n",
      "epoch: 35  batch: 37  loss: 0.09337313\n",
      "epoch: 35  batch: 38  loss: 0.06741320\n",
      "epoch: 35  batch: 39  loss: 0.25679365\n",
      "epoch: 35  batch: 40  loss: 0.12058335\n",
      "epoch: 35  batch: 41  loss: 0.31259367\n",
      "epoch: 35  batch: 42  loss: 0.17487349\n",
      "epoch: 35  batch: 43  loss: 0.26052150\n",
      "epoch: 35  batch: 44  loss: 0.28673533\n",
      "epoch: 35  batch: 45  loss: 0.26546395\n",
      "epoch: 35  batch: 46  loss: 0.20963055\n",
      "epoch: 35  batch: 47  loss: 0.21824163\n",
      "epoch: 35  batch: 48  loss: 0.15629007\n",
      "epoch: 35  batch: 49  loss: 0.13372524\n",
      "epoch: 35  batch: 50  loss: 0.21650293\n",
      "epoch: 35  batch: 51  loss: 0.18045616\n",
      "epoch: 35  batch: 52  loss: 0.09855962\n",
      "epoch: 35  batch: 53  loss: 0.10365039\n",
      "epoch: 35  batch: 54  loss: 0.36312199\n",
      "epoch: 35  batch: 55  loss: 0.23435475\n",
      "epoch: 35  batch: 56  loss: 0.08178211\n",
      "epoch: 35  batch: 57  loss: 0.06301678\n",
      "epoch: 35  batch: 58  loss: 0.14789198\n",
      "epoch: 35  batch: 59  loss: 0.10774162\n",
      "epoch: 35  batch: 60  loss: 0.40604788\n",
      "epoch: 35  batch: 61  loss: 0.84214139\n",
      "epoch: 35  batch: 62  loss: 0.16778299\n",
      "epoch: 35  batch: 63  loss: 0.39727250\n",
      "epoch: 35  batch: 64  loss: 0.17028791\n",
      "epoch: 35  batch: 65  loss: 0.09163095\n",
      "epoch: 35  batch: 66  loss: 0.03641087\n",
      "epoch: 35  batch: 67  loss: 0.07906603\n",
      "epoch: 35  batch: 68  loss: 0.16660200\n",
      "epoch: 36  batch: 1  loss: 0.24105398\n",
      "epoch: 36  batch: 2  loss: 0.04836377\n",
      "epoch: 36  batch: 3  loss: 0.05797521\n",
      "epoch: 36  batch: 4  loss: 0.07949523\n",
      "epoch: 36  batch: 5  loss: 0.21975161\n",
      "epoch: 36  batch: 6  loss: 0.16422531\n",
      "epoch: 36  batch: 7  loss: 0.35054198\n",
      "epoch: 36  batch: 8  loss: 0.10597860\n",
      "epoch: 36  batch: 9  loss: 0.30864215\n",
      "epoch: 36  batch: 10  loss: 0.35820600\n",
      "epoch: 36  batch: 11  loss: 0.41658571\n",
      "epoch: 36  batch: 12  loss: 0.19768268\n",
      "epoch: 36  batch: 13  loss: 0.24505961\n",
      "epoch: 36  batch: 14  loss: 0.24419653\n",
      "epoch: 36  batch: 15  loss: 0.14305642\n",
      "epoch: 36  batch: 16  loss: 0.17314023\n",
      "epoch: 36  batch: 17  loss: 0.31008977\n",
      "epoch: 36  batch: 18  loss: 0.16849516\n",
      "epoch: 36  batch: 19  loss: 0.18926528\n",
      "epoch: 36  batch: 20  loss: 0.31830493\n",
      "epoch: 36  batch: 21  loss: 0.37024131\n",
      "epoch: 36  batch: 22  loss: 0.08735778\n",
      "epoch: 36  batch: 23  loss: 0.07977103\n",
      "epoch: 36  batch: 24  loss: 0.20731573\n",
      "epoch: 36  batch: 25  loss: 0.07452850\n",
      "epoch: 36  batch: 26  loss: 0.28223622\n",
      "epoch: 36  batch: 27  loss: 0.70162380\n",
      "epoch: 36  batch: 28  loss: 0.28999776\n",
      "epoch: 36  batch: 29  loss: 0.26911139\n",
      "epoch: 36  batch: 30  loss: 0.18253887\n",
      "epoch: 36  batch: 31  loss: 0.05267417\n",
      "epoch: 36  batch: 32  loss: 0.05141345\n",
      "epoch: 36  batch: 33  loss: 0.12229771\n",
      "epoch: 36  batch: 34  loss: 0.11894974\n",
      "epoch: 36  batch: 35  loss: 0.27982229\n",
      "epoch: 36  batch: 36  loss: 0.09077967\n",
      "epoch: 36  batch: 37  loss: 0.06055893\n",
      "epoch: 36  batch: 38  loss: 0.05904065\n",
      "epoch: 36  batch: 39  loss: 0.26419201\n",
      "epoch: 36  batch: 40  loss: 0.11592884\n",
      "epoch: 36  batch: 41  loss: 0.29108077\n",
      "epoch: 36  batch: 42  loss: 0.25661620\n",
      "epoch: 36  batch: 43  loss: 0.23203844\n",
      "epoch: 36  batch: 44  loss: 0.47310859\n",
      "epoch: 36  batch: 45  loss: 0.38007075\n",
      "epoch: 36  batch: 46  loss: 0.20491214\n",
      "epoch: 36  batch: 47  loss: 0.19594155\n",
      "epoch: 36  batch: 48  loss: 0.15179452\n",
      "epoch: 36  batch: 49  loss: 0.15424646\n",
      "epoch: 36  batch: 50  loss: 0.19576187\n",
      "epoch: 36  batch: 51  loss: 0.12812622\n",
      "epoch: 36  batch: 52  loss: 0.08242442\n",
      "epoch: 36  batch: 53  loss: 0.15001363\n",
      "epoch: 36  batch: 54  loss: 0.37313029\n",
      "epoch: 36  batch: 55  loss: 0.23145977\n",
      "epoch: 36  batch: 56  loss: 0.08359797\n",
      "epoch: 36  batch: 57  loss: 0.05395234\n",
      "epoch: 36  batch: 58  loss: 0.10470207\n",
      "epoch: 36  batch: 59  loss: 0.11685999\n",
      "epoch: 36  batch: 60  loss: 0.43046349\n",
      "epoch: 36  batch: 61  loss: 0.90307695\n",
      "epoch: 36  batch: 62  loss: 0.21640007\n",
      "epoch: 36  batch: 63  loss: 0.39272276\n",
      "epoch: 36  batch: 64  loss: 0.14167583\n",
      "epoch: 36  batch: 65  loss: 0.04494001\n",
      "epoch: 36  batch: 66  loss: 0.03579310\n",
      "epoch: 36  batch: 67  loss: 0.06158020\n",
      "epoch: 36  batch: 68  loss: 0.17953700\n",
      "epoch: 37  batch: 1  loss: 0.26066250\n",
      "epoch: 37  batch: 2  loss: 0.13194905\n",
      "epoch: 37  batch: 3  loss: 0.04887927\n",
      "epoch: 37  batch: 4  loss: 0.06718654\n",
      "epoch: 37  batch: 5  loss: 0.19288874\n",
      "epoch: 37  batch: 6  loss: 0.16552010\n",
      "epoch: 37  batch: 7  loss: 0.29750735\n",
      "epoch: 37  batch: 8  loss: 0.16982077\n",
      "epoch: 37  batch: 9  loss: 0.28228319\n",
      "epoch: 37  batch: 10  loss: 0.29654080\n",
      "epoch: 37  batch: 11  loss: 0.32529962\n",
      "epoch: 37  batch: 12  loss: 0.21552220\n",
      "epoch: 37  batch: 13  loss: 0.22204272\n",
      "epoch: 37  batch: 14  loss: 0.16590351\n",
      "epoch: 37  batch: 15  loss: 0.16880861\n",
      "epoch: 37  batch: 16  loss: 0.16097189\n",
      "epoch: 37  batch: 17  loss: 0.33893803\n",
      "epoch: 37  batch: 18  loss: 0.09802531\n",
      "epoch: 37  batch: 19  loss: 0.12903671\n",
      "epoch: 37  batch: 20  loss: 0.26996887\n",
      "epoch: 37  batch: 21  loss: 0.35435757\n",
      "epoch: 37  batch: 22  loss: 0.06865618\n",
      "epoch: 37  batch: 23  loss: 0.06033824\n",
      "epoch: 37  batch: 24  loss: 0.06076524\n",
      "epoch: 37  batch: 25  loss: 0.12527150\n",
      "epoch: 37  batch: 26  loss: 0.35764974\n",
      "epoch: 37  batch: 27  loss: 0.70153701\n",
      "epoch: 37  batch: 28  loss: 0.36174080\n",
      "epoch: 37  batch: 29  loss: 0.30023751\n",
      "epoch: 37  batch: 30  loss: 0.22679073\n",
      "epoch: 37  batch: 31  loss: 0.04836558\n",
      "epoch: 37  batch: 32  loss: 0.03655670\n",
      "epoch: 37  batch: 33  loss: 0.07779621\n",
      "epoch: 37  batch: 34  loss: 0.12031836\n",
      "epoch: 37  batch: 35  loss: 0.24276510\n",
      "epoch: 37  batch: 36  loss: 0.08748021\n",
      "epoch: 37  batch: 37  loss: 0.07872403\n",
      "epoch: 37  batch: 38  loss: 0.08101650\n",
      "epoch: 37  batch: 39  loss: 0.26585123\n",
      "epoch: 37  batch: 40  loss: 0.09548807\n",
      "epoch: 37  batch: 41  loss: 0.30201721\n",
      "epoch: 37  batch: 42  loss: 0.19040537\n",
      "epoch: 37  batch: 43  loss: 0.21284252\n",
      "epoch: 37  batch: 44  loss: 0.36482355\n",
      "epoch: 37  batch: 45  loss: 0.29091167\n",
      "epoch: 37  batch: 46  loss: 0.22307871\n",
      "epoch: 37  batch: 47  loss: 0.27346402\n",
      "epoch: 37  batch: 48  loss: 0.15786129\n",
      "epoch: 37  batch: 49  loss: 0.15865664\n",
      "epoch: 37  batch: 50  loss: 0.27470055\n",
      "epoch: 37  batch: 51  loss: 0.24776170\n",
      "epoch: 37  batch: 52  loss: 0.08199730\n",
      "epoch: 37  batch: 53  loss: 0.15089175\n",
      "epoch: 37  batch: 54  loss: 0.33974668\n",
      "epoch: 37  batch: 55  loss: 0.24834552\n",
      "epoch: 37  batch: 56  loss: 0.08131059\n",
      "epoch: 37  batch: 57  loss: 0.08725422\n",
      "epoch: 37  batch: 58  loss: 0.13609554\n",
      "epoch: 37  batch: 59  loss: 0.12364919\n",
      "epoch: 37  batch: 60  loss: 0.39446837\n",
      "epoch: 37  batch: 61  loss: 0.90385592\n",
      "epoch: 37  batch: 62  loss: 0.25527292\n",
      "epoch: 37  batch: 63  loss: 0.45878789\n",
      "epoch: 37  batch: 64  loss: 0.19228227\n",
      "epoch: 37  batch: 65  loss: 0.05068000\n",
      "epoch: 37  batch: 66  loss: 0.03871472\n",
      "epoch: 37  batch: 67  loss: 0.07530552\n",
      "epoch: 37  batch: 68  loss: 0.13382648\n",
      "epoch: 38  batch: 1  loss: 0.25076994\n",
      "epoch: 38  batch: 2  loss: 0.07382195\n",
      "epoch: 38  batch: 3  loss: 0.09323034\n",
      "epoch: 38  batch: 4  loss: 0.13426611\n",
      "epoch: 38  batch: 5  loss: 0.28034645\n",
      "epoch: 38  batch: 6  loss: 0.15733247\n",
      "epoch: 38  batch: 7  loss: 0.33880556\n",
      "epoch: 38  batch: 8  loss: 0.18040763\n",
      "epoch: 38  batch: 9  loss: 0.19896080\n",
      "epoch: 38  batch: 10  loss: 0.31114355\n",
      "epoch: 38  batch: 11  loss: 0.36310893\n",
      "epoch: 38  batch: 12  loss: 0.21899407\n",
      "epoch: 38  batch: 13  loss: 0.29431257\n",
      "epoch: 38  batch: 14  loss: 0.55693626\n",
      "epoch: 38  batch: 15  loss: 0.19220056\n",
      "epoch: 38  batch: 16  loss: 0.17259219\n",
      "epoch: 38  batch: 17  loss: 0.34485957\n",
      "epoch: 38  batch: 18  loss: 0.10793065\n",
      "epoch: 38  batch: 19  loss: 0.11670193\n",
      "epoch: 38  batch: 20  loss: 0.31844211\n",
      "epoch: 38  batch: 21  loss: 0.40587863\n",
      "epoch: 38  batch: 22  loss: 0.09247338\n",
      "epoch: 38  batch: 23  loss: 0.06954072\n",
      "epoch: 38  batch: 24  loss: 0.07915055\n",
      "epoch: 38  batch: 25  loss: 0.07360530\n",
      "epoch: 38  batch: 26  loss: 0.28711060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38  batch: 27  loss: 0.66551119\n",
      "epoch: 38  batch: 28  loss: 0.33840802\n",
      "epoch: 38  batch: 29  loss: 0.24358538\n",
      "epoch: 38  batch: 30  loss: 0.15927316\n",
      "epoch: 38  batch: 31  loss: 0.08102530\n",
      "epoch: 38  batch: 32  loss: 0.04729318\n",
      "epoch: 38  batch: 33  loss: 0.07590102\n",
      "epoch: 38  batch: 34  loss: 0.14237644\n",
      "epoch: 38  batch: 35  loss: 0.27232996\n",
      "epoch: 38  batch: 36  loss: 0.08059932\n",
      "epoch: 38  batch: 37  loss: 0.09966983\n",
      "epoch: 38  batch: 38  loss: 0.08386330\n",
      "epoch: 38  batch: 39  loss: 0.32484153\n",
      "epoch: 38  batch: 40  loss: 0.14961763\n",
      "epoch: 38  batch: 41  loss: 0.29597896\n",
      "epoch: 38  batch: 42  loss: 0.23164970\n",
      "epoch: 38  batch: 43  loss: 0.31277949\n",
      "epoch: 38  batch: 44  loss: 0.33053556\n",
      "epoch: 38  batch: 45  loss: 0.38515350\n",
      "epoch: 38  batch: 46  loss: 0.25550663\n",
      "epoch: 38  batch: 47  loss: 0.25308374\n",
      "epoch: 38  batch: 48  loss: 0.21156265\n",
      "epoch: 38  batch: 49  loss: 0.19702755\n",
      "epoch: 38  batch: 50  loss: 0.31147453\n",
      "epoch: 38  batch: 51  loss: 0.25709823\n",
      "epoch: 38  batch: 52  loss: 0.10523077\n",
      "epoch: 38  batch: 53  loss: 0.17013448\n",
      "epoch: 38  batch: 54  loss: 0.39828497\n",
      "epoch: 38  batch: 55  loss: 0.25772151\n",
      "epoch: 38  batch: 56  loss: 0.09795077\n",
      "epoch: 38  batch: 57  loss: 0.07272599\n",
      "epoch: 38  batch: 58  loss: 0.08596402\n",
      "epoch: 38  batch: 59  loss: 0.11553229\n",
      "epoch: 38  batch: 60  loss: 0.38488173\n",
      "epoch: 38  batch: 61  loss: 0.86504036\n",
      "epoch: 38  batch: 62  loss: 0.23347282\n",
      "epoch: 38  batch: 63  loss: 0.33797985\n",
      "epoch: 38  batch: 64  loss: 0.17919478\n",
      "epoch: 38  batch: 65  loss: 0.08700339\n",
      "epoch: 38  batch: 66  loss: 0.06113599\n",
      "epoch: 38  batch: 67  loss: 0.10180784\n",
      "epoch: 38  batch: 68  loss: 0.15956585\n",
      "epoch: 39  batch: 1  loss: 0.23025005\n",
      "epoch: 39  batch: 2  loss: 0.07719550\n",
      "epoch: 39  batch: 3  loss: 0.04196462\n",
      "epoch: 39  batch: 4  loss: 0.06070829\n",
      "epoch: 39  batch: 5  loss: 0.18741706\n",
      "epoch: 39  batch: 6  loss: 0.11799559\n",
      "epoch: 39  batch: 7  loss: 0.30472112\n",
      "epoch: 39  batch: 8  loss: 0.16150162\n",
      "epoch: 39  batch: 9  loss: 0.29993603\n",
      "epoch: 39  batch: 10  loss: 0.30663395\n",
      "epoch: 39  batch: 11  loss: 0.40300679\n",
      "epoch: 39  batch: 12  loss: 0.21752211\n",
      "epoch: 39  batch: 13  loss: 0.29002884\n",
      "epoch: 39  batch: 14  loss: 0.20330901\n",
      "epoch: 39  batch: 15  loss: 0.16420679\n",
      "epoch: 39  batch: 16  loss: 0.16842058\n",
      "epoch: 39  batch: 17  loss: 0.31020200\n",
      "epoch: 39  batch: 18  loss: 0.23004462\n",
      "epoch: 39  batch: 19  loss: 0.23516853\n",
      "epoch: 39  batch: 20  loss: 0.31740871\n",
      "epoch: 39  batch: 21  loss: 0.35982150\n",
      "epoch: 39  batch: 22  loss: 0.07412807\n",
      "epoch: 39  batch: 23  loss: 0.06041662\n",
      "epoch: 39  batch: 24  loss: 0.07275033\n",
      "epoch: 39  batch: 25  loss: 0.10465529\n",
      "epoch: 39  batch: 26  loss: 0.30748305\n",
      "epoch: 39  batch: 27  loss: 0.66355658\n",
      "epoch: 39  batch: 28  loss: 0.29315361\n",
      "epoch: 39  batch: 29  loss: 0.23698273\n",
      "epoch: 39  batch: 30  loss: 0.14685427\n",
      "epoch: 39  batch: 31  loss: 0.06468679\n",
      "epoch: 39  batch: 32  loss: 0.04664391\n",
      "epoch: 39  batch: 33  loss: 0.11469295\n",
      "epoch: 39  batch: 34  loss: 0.11624313\n",
      "epoch: 39  batch: 35  loss: 0.22510245\n",
      "epoch: 39  batch: 36  loss: 0.08218971\n",
      "epoch: 39  batch: 37  loss: 0.10950638\n",
      "epoch: 39  batch: 38  loss: 0.10309141\n",
      "epoch: 39  batch: 39  loss: 0.32393071\n",
      "epoch: 39  batch: 40  loss: 0.12601966\n",
      "epoch: 39  batch: 41  loss: 0.23800516\n",
      "epoch: 39  batch: 42  loss: 0.19364277\n",
      "epoch: 39  batch: 43  loss: 0.23536129\n",
      "epoch: 39  batch: 44  loss: 0.27322102\n",
      "epoch: 39  batch: 45  loss: 0.49028853\n",
      "epoch: 39  batch: 46  loss: 0.22140528\n",
      "epoch: 39  batch: 47  loss: 0.21498579\n",
      "epoch: 39  batch: 48  loss: 0.18026641\n",
      "epoch: 39  batch: 49  loss: 0.15159629\n",
      "epoch: 39  batch: 50  loss: 0.25776559\n",
      "epoch: 39  batch: 51  loss: 0.16608347\n",
      "epoch: 39  batch: 52  loss: 0.08261380\n",
      "epoch: 39  batch: 53  loss: 0.12869665\n",
      "epoch: 39  batch: 54  loss: 0.37506154\n",
      "epoch: 39  batch: 55  loss: 0.24498320\n",
      "epoch: 39  batch: 56  loss: 0.08666771\n",
      "epoch: 39  batch: 57  loss: 0.07218075\n",
      "epoch: 39  batch: 58  loss: 0.11776831\n",
      "epoch: 39  batch: 59  loss: 0.12355462\n",
      "epoch: 39  batch: 60  loss: 0.33982417\n",
      "epoch: 39  batch: 61  loss: 0.80987740\n",
      "epoch: 39  batch: 62  loss: 0.28785762\n",
      "epoch: 39  batch: 63  loss: 0.31483203\n",
      "epoch: 39  batch: 64  loss: 0.21429910\n",
      "epoch: 39  batch: 65  loss: 0.06487077\n",
      "epoch: 39  batch: 66  loss: 0.03645296\n",
      "epoch: 39  batch: 67  loss: 0.05964828\n",
      "epoch: 39  batch: 68  loss: 0.12139258\n",
      "epoch: 40  batch: 1  loss: 0.21833806\n",
      "epoch: 40  batch: 2  loss: 0.06458630\n",
      "epoch: 40  batch: 3  loss: 0.03793391\n",
      "epoch: 40  batch: 4  loss: 0.04364462\n",
      "epoch: 40  batch: 5  loss: 0.15774350\n",
      "epoch: 40  batch: 6  loss: 0.18501964\n",
      "epoch: 40  batch: 7  loss: 0.27507803\n",
      "epoch: 40  batch: 8  loss: 0.19625315\n",
      "epoch: 40  batch: 9  loss: 0.32907501\n",
      "epoch: 40  batch: 10  loss: 0.42215425\n",
      "epoch: 40  batch: 11  loss: 0.40638047\n",
      "epoch: 40  batch: 12  loss: 0.24494766\n",
      "epoch: 40  batch: 13  loss: 0.12839535\n",
      "epoch: 40  batch: 14  loss: 0.15260255\n",
      "epoch: 40  batch: 15  loss: 0.14552146\n",
      "epoch: 40  batch: 16  loss: 0.07691385\n",
      "epoch: 40  batch: 17  loss: 0.21493308\n",
      "epoch: 40  batch: 18  loss: 0.05765510\n",
      "epoch: 40  batch: 19  loss: 0.04294283\n",
      "epoch: 40  batch: 20  loss: 0.30536678\n",
      "epoch: 40  batch: 21  loss: 0.36922118\n",
      "epoch: 40  batch: 22  loss: 0.10341886\n",
      "epoch: 40  batch: 23  loss: 0.05799415\n",
      "epoch: 40  batch: 24  loss: 0.07354582\n",
      "epoch: 40  batch: 25  loss: 0.12085526\n",
      "epoch: 40  batch: 26  loss: 0.20532678\n",
      "epoch: 40  batch: 27  loss: 0.46713111\n",
      "epoch: 40  batch: 28  loss: 0.25525433\n",
      "epoch: 40  batch: 29  loss: 0.16096015\n",
      "epoch: 40  batch: 30  loss: 0.10638072\n",
      "epoch: 40  batch: 31  loss: 0.07027531\n",
      "epoch: 40  batch: 32  loss: 0.02745446\n",
      "epoch: 40  batch: 33  loss: 0.10118479\n",
      "epoch: 40  batch: 34  loss: 0.09195516\n",
      "epoch: 40  batch: 35  loss: 0.18864913\n",
      "epoch: 40  batch: 36  loss: 0.03573773\n",
      "epoch: 40  batch: 37  loss: 0.02681234\n",
      "epoch: 40  batch: 38  loss: 0.07846069\n",
      "epoch: 40  batch: 39  loss: 0.19724093\n",
      "epoch: 40  batch: 40  loss: 0.11837258\n",
      "epoch: 40  batch: 41  loss: 0.23891261\n",
      "epoch: 40  batch: 42  loss: 0.17760214\n",
      "epoch: 40  batch: 43  loss: 0.21772207\n",
      "epoch: 40  batch: 44  loss: 0.36780784\n",
      "epoch: 40  batch: 45  loss: 0.46880326\n",
      "epoch: 40  batch: 46  loss: 0.20627557\n",
      "epoch: 40  batch: 47  loss: 0.17563117\n",
      "epoch: 40  batch: 48  loss: 0.12784484\n",
      "epoch: 40  batch: 49  loss: 0.14665888\n",
      "epoch: 40  batch: 50  loss: 0.13788736\n",
      "epoch: 40  batch: 51  loss: 0.12667033\n",
      "epoch: 40  batch: 52  loss: 0.05769006\n",
      "epoch: 40  batch: 53  loss: 0.06141496\n",
      "epoch: 40  batch: 54  loss: 0.39220878\n",
      "epoch: 40  batch: 55  loss: 0.25143826\n",
      "epoch: 40  batch: 56  loss: 0.08485509\n",
      "epoch: 40  batch: 57  loss: 0.04015516\n",
      "epoch: 40  batch: 58  loss: 0.15528592\n",
      "epoch: 40  batch: 59  loss: 0.10074997\n",
      "epoch: 40  batch: 60  loss: 0.28986397\n",
      "epoch: 40  batch: 61  loss: 0.52655971\n",
      "epoch: 40  batch: 62  loss: 0.18889610\n",
      "epoch: 40  batch: 63  loss: 0.20895886\n",
      "epoch: 40  batch: 64  loss: 0.15310085\n",
      "epoch: 40  batch: 65  loss: 0.05657953\n",
      "epoch: 40  batch: 66  loss: 0.03189956\n",
      "epoch: 40  batch: 67  loss: 0.04434805\n",
      "epoch: 40  batch: 68  loss: 0.09540664\n",
      "epoch: 41  batch: 1  loss: 0.18661924\n",
      "epoch: 41  batch: 2  loss: 0.04560666\n",
      "epoch: 41  batch: 3  loss: 0.03110596\n",
      "epoch: 41  batch: 4  loss: 0.03109649\n",
      "epoch: 41  batch: 5  loss: 0.13006608\n",
      "epoch: 41  batch: 6  loss: 0.12574792\n",
      "epoch: 41  batch: 7  loss: 0.24801649\n",
      "epoch: 41  batch: 8  loss: 0.14709370\n",
      "epoch: 41  batch: 9  loss: 0.26533258\n",
      "epoch: 41  batch: 10  loss: 0.36248928\n",
      "epoch: 41  batch: 11  loss: 0.34506115\n",
      "epoch: 41  batch: 12  loss: 0.22190268\n",
      "epoch: 41  batch: 13  loss: 0.15225342\n",
      "epoch: 41  batch: 14  loss: 0.15582851\n",
      "epoch: 41  batch: 15  loss: 0.13966653\n",
      "epoch: 41  batch: 16  loss: 0.08877914\n",
      "epoch: 41  batch: 17  loss: 0.22253446\n",
      "epoch: 41  batch: 18  loss: 0.06017293\n",
      "epoch: 41  batch: 19  loss: 0.04376264\n",
      "epoch: 41  batch: 20  loss: 0.28879464\n",
      "epoch: 41  batch: 21  loss: 0.35673261\n",
      "epoch: 41  batch: 22  loss: 0.08736233\n",
      "epoch: 41  batch: 23  loss: 0.06151797\n",
      "epoch: 41  batch: 24  loss: 0.06355341\n",
      "epoch: 41  batch: 25  loss: 0.10324860\n",
      "epoch: 41  batch: 26  loss: 0.19711979\n",
      "epoch: 41  batch: 27  loss: 0.52131987\n",
      "epoch: 41  batch: 28  loss: 0.25282082\n",
      "epoch: 41  batch: 29  loss: 0.18497251\n",
      "epoch: 41  batch: 30  loss: 0.12751308\n",
      "epoch: 41  batch: 31  loss: 0.07597105\n",
      "epoch: 41  batch: 32  loss: 0.02418616\n",
      "epoch: 41  batch: 33  loss: 0.07627682\n",
      "epoch: 41  batch: 34  loss: 0.08725672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41  batch: 35  loss: 0.17322123\n",
      "epoch: 41  batch: 36  loss: 0.03213803\n",
      "epoch: 41  batch: 37  loss: 0.02668798\n",
      "epoch: 41  batch: 38  loss: 0.06161433\n",
      "epoch: 41  batch: 39  loss: 0.18069153\n",
      "epoch: 41  batch: 40  loss: 0.10292138\n",
      "epoch: 41  batch: 41  loss: 0.22202289\n",
      "epoch: 41  batch: 42  loss: 0.15355748\n",
      "epoch: 41  batch: 43  loss: 0.19476654\n",
      "epoch: 41  batch: 44  loss: 0.31946036\n",
      "epoch: 41  batch: 45  loss: 0.41516411\n",
      "epoch: 41  batch: 46  loss: 0.21340324\n",
      "epoch: 41  batch: 47  loss: 0.18493034\n",
      "epoch: 41  batch: 48  loss: 0.13145781\n",
      "epoch: 41  batch: 49  loss: 0.13051149\n",
      "epoch: 41  batch: 50  loss: 0.15152986\n",
      "epoch: 41  batch: 51  loss: 0.13485828\n",
      "epoch: 41  batch: 52  loss: 0.05897051\n",
      "epoch: 41  batch: 53  loss: 0.06080020\n",
      "epoch: 41  batch: 54  loss: 0.38082519\n",
      "epoch: 41  batch: 55  loss: 0.24565913\n",
      "epoch: 41  batch: 56  loss: 0.08255657\n",
      "epoch: 41  batch: 57  loss: 0.04377205\n",
      "epoch: 41  batch: 58  loss: 0.14357087\n",
      "epoch: 41  batch: 59  loss: 0.09658942\n",
      "epoch: 41  batch: 60  loss: 0.29940200\n",
      "epoch: 41  batch: 61  loss: 0.55318445\n",
      "epoch: 41  batch: 62  loss: 0.19513220\n",
      "epoch: 41  batch: 63  loss: 0.23669367\n",
      "epoch: 41  batch: 64  loss: 0.15566041\n",
      "epoch: 41  batch: 65  loss: 0.06057322\n",
      "epoch: 41  batch: 66  loss: 0.02870491\n",
      "epoch: 41  batch: 67  loss: 0.04105280\n",
      "epoch: 41  batch: 68  loss: 0.08779842\n",
      "epoch: 42  batch: 1  loss: 0.17872700\n",
      "epoch: 42  batch: 2  loss: 0.04499874\n",
      "epoch: 42  batch: 3  loss: 0.03083159\n",
      "epoch: 42  batch: 4  loss: 0.02891616\n",
      "epoch: 42  batch: 5  loss: 0.12297577\n",
      "epoch: 42  batch: 6  loss: 0.10429018\n",
      "epoch: 42  batch: 7  loss: 0.23624247\n",
      "epoch: 42  batch: 8  loss: 0.13567483\n",
      "epoch: 42  batch: 9  loss: 0.24992153\n",
      "epoch: 42  batch: 10  loss: 0.32830548\n",
      "epoch: 42  batch: 11  loss: 0.30759305\n",
      "epoch: 42  batch: 12  loss: 0.21523227\n",
      "epoch: 42  batch: 13  loss: 0.15808003\n",
      "epoch: 42  batch: 14  loss: 0.15841417\n",
      "epoch: 42  batch: 15  loss: 0.13819422\n",
      "epoch: 42  batch: 16  loss: 0.09118549\n",
      "epoch: 42  batch: 17  loss: 0.22536452\n",
      "epoch: 42  batch: 18  loss: 0.06194055\n",
      "epoch: 42  batch: 19  loss: 0.04639611\n",
      "epoch: 42  batch: 20  loss: 0.28685227\n",
      "epoch: 42  batch: 21  loss: 0.35411745\n",
      "epoch: 42  batch: 22  loss: 0.09113391\n",
      "epoch: 42  batch: 23  loss: 0.05651771\n",
      "epoch: 42  batch: 24  loss: 0.06091804\n",
      "epoch: 42  batch: 25  loss: 0.08441190\n",
      "epoch: 42  batch: 26  loss: 0.22450662\n",
      "epoch: 42  batch: 27  loss: 0.53229815\n",
      "epoch: 42  batch: 28  loss: 0.23881751\n",
      "epoch: 42  batch: 29  loss: 0.18256599\n",
      "epoch: 42  batch: 30  loss: 0.12660185\n",
      "epoch: 42  batch: 31  loss: 0.07927524\n",
      "epoch: 42  batch: 32  loss: 0.02096197\n",
      "epoch: 42  batch: 33  loss: 0.07124242\n",
      "epoch: 42  batch: 34  loss: 0.08601843\n",
      "epoch: 42  batch: 35  loss: 0.17144579\n",
      "epoch: 42  batch: 36  loss: 0.03280318\n",
      "epoch: 42  batch: 37  loss: 0.02704270\n",
      "epoch: 42  batch: 38  loss: 0.05315336\n",
      "epoch: 42  batch: 39  loss: 0.17871240\n",
      "epoch: 42  batch: 40  loss: 0.09112996\n",
      "epoch: 42  batch: 41  loss: 0.21726806\n",
      "epoch: 42  batch: 42  loss: 0.14720368\n",
      "epoch: 42  batch: 43  loss: 0.18687211\n",
      "epoch: 42  batch: 44  loss: 0.29262763\n",
      "epoch: 42  batch: 45  loss: 0.40823972\n",
      "epoch: 42  batch: 46  loss: 0.21225533\n",
      "epoch: 42  batch: 47  loss: 0.20449184\n",
      "epoch: 42  batch: 48  loss: 0.13237758\n",
      "epoch: 42  batch: 49  loss: 0.13035969\n",
      "epoch: 42  batch: 50  loss: 0.16508615\n",
      "epoch: 42  batch: 51  loss: 0.13754484\n",
      "epoch: 42  batch: 52  loss: 0.05949321\n",
      "epoch: 42  batch: 53  loss: 0.06480831\n",
      "epoch: 42  batch: 54  loss: 0.37994596\n",
      "epoch: 42  batch: 55  loss: 0.24562213\n",
      "epoch: 42  batch: 56  loss: 0.08256587\n",
      "epoch: 42  batch: 57  loss: 0.04706182\n",
      "epoch: 42  batch: 58  loss: 0.13627397\n",
      "epoch: 42  batch: 59  loss: 0.09402841\n",
      "epoch: 42  batch: 60  loss: 0.29198396\n",
      "epoch: 42  batch: 61  loss: 0.56268823\n",
      "epoch: 42  batch: 62  loss: 0.18923272\n",
      "epoch: 42  batch: 63  loss: 0.22515789\n",
      "epoch: 42  batch: 64  loss: 0.16768624\n",
      "epoch: 42  batch: 65  loss: 0.06341412\n",
      "epoch: 42  batch: 66  loss: 0.02876114\n",
      "epoch: 42  batch: 67  loss: 0.03828640\n",
      "epoch: 42  batch: 68  loss: 0.08636939\n",
      "epoch: 43  batch: 1  loss: 0.17855307\n",
      "epoch: 43  batch: 2  loss: 0.04502216\n",
      "epoch: 43  batch: 3  loss: 0.03049788\n",
      "epoch: 43  batch: 4  loss: 0.02825405\n",
      "epoch: 43  batch: 5  loss: 0.12124183\n",
      "epoch: 43  batch: 6  loss: 0.12609756\n",
      "epoch: 43  batch: 7  loss: 0.22673918\n",
      "epoch: 43  batch: 8  loss: 0.13716516\n",
      "epoch: 43  batch: 9  loss: 0.25655842\n",
      "epoch: 43  batch: 10  loss: 0.32538557\n",
      "epoch: 43  batch: 11  loss: 0.30380061\n",
      "epoch: 43  batch: 12  loss: 0.20444001\n",
      "epoch: 43  batch: 13  loss: 0.15533556\n",
      "epoch: 43  batch: 14  loss: 0.15867659\n",
      "epoch: 43  batch: 15  loss: 0.13477956\n",
      "epoch: 43  batch: 16  loss: 0.09304578\n",
      "epoch: 43  batch: 17  loss: 0.22389472\n",
      "epoch: 43  batch: 18  loss: 0.06146964\n",
      "epoch: 43  batch: 19  loss: 0.04432975\n",
      "epoch: 43  batch: 20  loss: 0.28444031\n",
      "epoch: 43  batch: 21  loss: 0.35258850\n",
      "epoch: 43  batch: 22  loss: 0.08631763\n",
      "epoch: 43  batch: 23  loss: 0.05356682\n",
      "epoch: 43  batch: 24  loss: 0.06017238\n",
      "epoch: 43  batch: 25  loss: 0.08113743\n",
      "epoch: 43  batch: 26  loss: 0.22201101\n",
      "epoch: 43  batch: 27  loss: 0.53640324\n",
      "epoch: 43  batch: 28  loss: 0.23585998\n",
      "epoch: 43  batch: 29  loss: 0.17829281\n",
      "epoch: 43  batch: 30  loss: 0.12760291\n",
      "epoch: 43  batch: 31  loss: 0.08014414\n",
      "epoch: 43  batch: 32  loss: 0.01860871\n",
      "epoch: 43  batch: 33  loss: 0.06755659\n",
      "epoch: 43  batch: 34  loss: 0.08564645\n",
      "epoch: 43  batch: 35  loss: 0.17045289\n",
      "epoch: 43  batch: 36  loss: 0.03315537\n",
      "epoch: 43  batch: 37  loss: 0.02788592\n",
      "epoch: 43  batch: 38  loss: 0.05127775\n",
      "epoch: 43  batch: 39  loss: 0.17776798\n",
      "epoch: 43  batch: 40  loss: 0.09103845\n",
      "epoch: 43  batch: 41  loss: 0.21423455\n",
      "epoch: 43  batch: 42  loss: 0.14175740\n",
      "epoch: 43  batch: 43  loss: 0.18401960\n",
      "epoch: 43  batch: 44  loss: 0.28510427\n",
      "epoch: 43  batch: 45  loss: 0.40213659\n",
      "epoch: 43  batch: 46  loss: 0.21163717\n",
      "epoch: 43  batch: 47  loss: 0.20137061\n",
      "epoch: 43  batch: 48  loss: 0.13249236\n",
      "epoch: 43  batch: 49  loss: 0.12801006\n",
      "epoch: 43  batch: 50  loss: 0.16484620\n",
      "epoch: 43  batch: 51  loss: 0.14149144\n",
      "epoch: 43  batch: 52  loss: 0.06030804\n",
      "epoch: 43  batch: 53  loss: 0.06327152\n",
      "epoch: 43  batch: 54  loss: 0.37777093\n",
      "epoch: 43  batch: 55  loss: 0.24410240\n",
      "epoch: 43  batch: 56  loss: 0.08277433\n",
      "epoch: 43  batch: 57  loss: 0.04718644\n",
      "epoch: 43  batch: 58  loss: 0.13480844\n",
      "epoch: 43  batch: 59  loss: 0.09173743\n",
      "epoch: 43  batch: 60  loss: 0.30541304\n",
      "epoch: 43  batch: 61  loss: 0.56369585\n",
      "epoch: 43  batch: 62  loss: 0.18889053\n",
      "epoch: 43  batch: 63  loss: 0.22999892\n",
      "epoch: 43  batch: 64  loss: 0.15868908\n",
      "epoch: 43  batch: 65  loss: 0.06155949\n",
      "epoch: 43  batch: 66  loss: 0.02913127\n",
      "epoch: 43  batch: 67  loss: 0.03765852\n",
      "epoch: 43  batch: 68  loss: 0.08534028\n",
      "epoch: 44  batch: 1  loss: 0.17598842\n",
      "epoch: 44  batch: 2  loss: 0.04537824\n",
      "epoch: 44  batch: 3  loss: 0.03021380\n",
      "epoch: 44  batch: 4  loss: 0.02799656\n",
      "epoch: 44  batch: 5  loss: 0.12034082\n",
      "epoch: 44  batch: 6  loss: 0.13000998\n",
      "epoch: 44  batch: 7  loss: 0.22900952\n",
      "epoch: 44  batch: 8  loss: 0.13752154\n",
      "epoch: 44  batch: 9  loss: 0.24313377\n",
      "epoch: 44  batch: 10  loss: 0.32076547\n",
      "epoch: 44  batch: 11  loss: 0.28507712\n",
      "epoch: 44  batch: 12  loss: 0.20182478\n",
      "epoch: 44  batch: 13  loss: 0.15392703\n",
      "epoch: 44  batch: 14  loss: 0.15586655\n",
      "epoch: 44  batch: 15  loss: 0.13453951\n",
      "epoch: 44  batch: 16  loss: 0.09374405\n",
      "epoch: 44  batch: 17  loss: 0.22115912\n",
      "epoch: 44  batch: 18  loss: 0.06488921\n",
      "epoch: 44  batch: 19  loss: 0.04543937\n",
      "epoch: 44  batch: 20  loss: 0.28450248\n",
      "epoch: 44  batch: 21  loss: 0.35079220\n",
      "epoch: 44  batch: 22  loss: 0.08821576\n",
      "epoch: 44  batch: 23  loss: 0.05277927\n",
      "epoch: 44  batch: 24  loss: 0.05885056\n",
      "epoch: 44  batch: 25  loss: 0.08312376\n",
      "epoch: 44  batch: 26  loss: 0.23379526\n",
      "epoch: 44  batch: 27  loss: 0.52786690\n",
      "epoch: 44  batch: 28  loss: 0.23583163\n",
      "epoch: 44  batch: 29  loss: 0.20322005\n",
      "epoch: 44  batch: 30  loss: 0.14895849\n",
      "epoch: 44  batch: 31  loss: 0.07880071\n",
      "epoch: 44  batch: 32  loss: 0.01929478\n",
      "epoch: 44  batch: 33  loss: 0.06357880\n",
      "epoch: 44  batch: 34  loss: 0.08448555\n",
      "epoch: 44  batch: 35  loss: 0.16937444\n",
      "epoch: 44  batch: 36  loss: 0.03366721\n",
      "epoch: 44  batch: 37  loss: 0.02857923\n",
      "epoch: 44  batch: 38  loss: 0.04740576\n",
      "epoch: 44  batch: 39  loss: 0.17474939\n",
      "epoch: 44  batch: 40  loss: 0.10164320\n",
      "epoch: 44  batch: 41  loss: 0.20594455\n",
      "epoch: 44  batch: 42  loss: 0.15426037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44  batch: 43  loss: 0.17742023\n",
      "epoch: 44  batch: 44  loss: 0.25888801\n",
      "epoch: 44  batch: 45  loss: 0.40159565\n",
      "epoch: 44  batch: 46  loss: 0.21236482\n",
      "epoch: 44  batch: 47  loss: 0.17921533\n",
      "epoch: 44  batch: 48  loss: 0.13255896\n",
      "epoch: 44  batch: 49  loss: 0.13665296\n",
      "epoch: 44  batch: 50  loss: 0.16383551\n",
      "epoch: 44  batch: 51  loss: 0.13139966\n",
      "epoch: 44  batch: 52  loss: 0.06305641\n",
      "epoch: 44  batch: 53  loss: 0.06476449\n",
      "epoch: 44  batch: 54  loss: 0.37709472\n",
      "epoch: 44  batch: 55  loss: 0.24410619\n",
      "epoch: 44  batch: 56  loss: 0.08477236\n",
      "epoch: 44  batch: 57  loss: 0.04827214\n",
      "epoch: 44  batch: 58  loss: 0.12783754\n",
      "epoch: 44  batch: 59  loss: 0.10241791\n",
      "epoch: 44  batch: 60  loss: 0.30277309\n",
      "epoch: 44  batch: 61  loss: 0.56673729\n",
      "epoch: 44  batch: 62  loss: 0.19322722\n",
      "epoch: 44  batch: 63  loss: 0.24511355\n",
      "epoch: 44  batch: 64  loss: 0.17404544\n",
      "epoch: 44  batch: 65  loss: 0.05979588\n",
      "epoch: 44  batch: 66  loss: 0.02996559\n",
      "epoch: 44  batch: 67  loss: 0.04035788\n",
      "epoch: 44  batch: 68  loss: 0.08572609\n",
      "epoch: 45  batch: 1  loss: 0.17884083\n",
      "epoch: 45  batch: 2  loss: 0.04387559\n",
      "epoch: 45  batch: 3  loss: 0.03001759\n",
      "epoch: 45  batch: 4  loss: 0.02807035\n",
      "epoch: 45  batch: 5  loss: 0.11962549\n",
      "epoch: 45  batch: 6  loss: 0.12301002\n",
      "epoch: 45  batch: 7  loss: 0.22083576\n",
      "epoch: 45  batch: 8  loss: 0.13226156\n",
      "epoch: 45  batch: 9  loss: 0.26127595\n",
      "epoch: 45  batch: 10  loss: 0.31270796\n",
      "epoch: 45  batch: 11  loss: 0.28448194\n",
      "epoch: 45  batch: 12  loss: 0.19938010\n",
      "epoch: 45  batch: 13  loss: 0.15581094\n",
      "epoch: 45  batch: 14  loss: 0.15447612\n",
      "epoch: 45  batch: 15  loss: 0.12943071\n",
      "epoch: 45  batch: 16  loss: 0.09350213\n",
      "epoch: 45  batch: 17  loss: 0.20979445\n",
      "epoch: 45  batch: 18  loss: 0.06402140\n",
      "epoch: 45  batch: 19  loss: 0.04680452\n",
      "epoch: 45  batch: 20  loss: 0.28282288\n",
      "epoch: 45  batch: 21  loss: 0.35039082\n",
      "epoch: 45  batch: 22  loss: 0.08792864\n",
      "epoch: 45  batch: 23  loss: 0.05412823\n",
      "epoch: 45  batch: 24  loss: 0.05696834\n",
      "epoch: 45  batch: 25  loss: 0.08899857\n",
      "epoch: 45  batch: 26  loss: 0.21119331\n",
      "epoch: 45  batch: 27  loss: 0.51755053\n",
      "epoch: 45  batch: 28  loss: 0.20304324\n",
      "epoch: 45  batch: 29  loss: 0.19342476\n",
      "epoch: 45  batch: 30  loss: 0.11836603\n",
      "epoch: 45  batch: 31  loss: 0.07450164\n",
      "epoch: 45  batch: 32  loss: 0.01779910\n",
      "epoch: 45  batch: 33  loss: 0.06092315\n",
      "epoch: 45  batch: 34  loss: 0.08559254\n",
      "epoch: 45  batch: 35  loss: 0.16906536\n",
      "epoch: 45  batch: 36  loss: 0.03389372\n",
      "epoch: 45  batch: 37  loss: 0.02998095\n",
      "epoch: 45  batch: 38  loss: 0.05233300\n",
      "epoch: 45  batch: 39  loss: 0.17651445\n",
      "epoch: 45  batch: 40  loss: 0.10809128\n",
      "epoch: 45  batch: 41  loss: 0.21067272\n",
      "epoch: 45  batch: 42  loss: 0.13960314\n",
      "epoch: 45  batch: 43  loss: 0.17507641\n",
      "epoch: 45  batch: 44  loss: 0.25760648\n",
      "epoch: 45  batch: 45  loss: 0.39142898\n",
      "epoch: 45  batch: 46  loss: 0.21112317\n",
      "epoch: 45  batch: 47  loss: 0.19014347\n",
      "epoch: 45  batch: 48  loss: 0.13194238\n",
      "epoch: 45  batch: 49  loss: 0.12610714\n",
      "epoch: 45  batch: 50  loss: 0.15791871\n",
      "epoch: 45  batch: 51  loss: 0.13986492\n",
      "epoch: 45  batch: 52  loss: 0.06140617\n",
      "epoch: 45  batch: 53  loss: 0.06414453\n",
      "epoch: 45  batch: 54  loss: 0.38014531\n",
      "epoch: 45  batch: 55  loss: 0.24441813\n",
      "epoch: 45  batch: 56  loss: 0.08486822\n",
      "epoch: 45  batch: 57  loss: 0.04921650\n",
      "epoch: 45  batch: 58  loss: 0.12959631\n",
      "epoch: 45  batch: 59  loss: 0.08749537\n",
      "epoch: 45  batch: 60  loss: 0.30344427\n",
      "epoch: 45  batch: 61  loss: 0.55934948\n",
      "epoch: 45  batch: 62  loss: 0.19184354\n",
      "epoch: 45  batch: 63  loss: 0.24454272\n",
      "epoch: 45  batch: 64  loss: 0.16585214\n",
      "epoch: 45  batch: 65  loss: 0.05633562\n",
      "epoch: 45  batch: 66  loss: 0.03079164\n",
      "epoch: 45  batch: 67  loss: 0.04093515\n",
      "epoch: 45  batch: 68  loss: 0.08564939\n",
      "epoch: 46  batch: 1  loss: 0.17951722\n",
      "epoch: 46  batch: 2  loss: 0.04528695\n",
      "epoch: 46  batch: 3  loss: 0.03037576\n",
      "epoch: 46  batch: 4  loss: 0.02843646\n",
      "epoch: 46  batch: 5  loss: 0.11727034\n",
      "epoch: 46  batch: 6  loss: 0.09535798\n",
      "epoch: 46  batch: 7  loss: 0.31331125\n",
      "epoch: 46  batch: 8  loss: 0.12514549\n",
      "epoch: 46  batch: 9  loss: 0.22440843\n",
      "epoch: 46  batch: 10  loss: 0.31757504\n",
      "epoch: 46  batch: 11  loss: 0.28149322\n",
      "epoch: 46  batch: 12  loss: 0.19880921\n",
      "epoch: 46  batch: 13  loss: 0.14982687\n",
      "epoch: 46  batch: 14  loss: 0.15313166\n",
      "epoch: 46  batch: 15  loss: 0.13673005\n",
      "epoch: 46  batch: 16  loss: 0.09324574\n",
      "epoch: 46  batch: 17  loss: 0.20947762\n",
      "epoch: 46  batch: 18  loss: 0.06356665\n",
      "epoch: 46  batch: 19  loss: 0.04978598\n",
      "epoch: 46  batch: 20  loss: 0.28260222\n",
      "epoch: 46  batch: 21  loss: 0.34959400\n",
      "epoch: 46  batch: 22  loss: 0.09082451\n",
      "epoch: 46  batch: 23  loss: 0.05510729\n",
      "epoch: 46  batch: 24  loss: 0.05549089\n",
      "epoch: 46  batch: 25  loss: 0.08015909\n",
      "epoch: 46  batch: 26  loss: 0.20224185\n",
      "epoch: 46  batch: 27  loss: 0.52826810\n",
      "epoch: 46  batch: 28  loss: 0.22139458\n",
      "epoch: 46  batch: 29  loss: 0.19493052\n",
      "epoch: 46  batch: 30  loss: 0.11386866\n",
      "epoch: 46  batch: 31  loss: 0.07835685\n",
      "epoch: 46  batch: 32  loss: 0.01706458\n",
      "epoch: 46  batch: 33  loss: 0.06160077\n",
      "epoch: 46  batch: 34  loss: 0.08651561\n",
      "epoch: 46  batch: 35  loss: 0.16855444\n",
      "epoch: 46  batch: 36  loss: 0.03459245\n",
      "epoch: 46  batch: 37  loss: 0.03018527\n",
      "epoch: 46  batch: 38  loss: 0.04965806\n",
      "epoch: 46  batch: 39  loss: 0.17468239\n",
      "epoch: 46  batch: 40  loss: 0.09805049\n",
      "epoch: 46  batch: 41  loss: 0.21722287\n",
      "epoch: 46  batch: 42  loss: 0.13960868\n",
      "epoch: 46  batch: 43  loss: 0.16889367\n",
      "epoch: 46  batch: 44  loss: 0.24946402\n",
      "epoch: 46  batch: 45  loss: 0.37218353\n",
      "epoch: 46  batch: 46  loss: 0.20552382\n",
      "epoch: 46  batch: 47  loss: 0.19765604\n",
      "epoch: 46  batch: 48  loss: 0.13095281\n",
      "epoch: 46  batch: 49  loss: 0.12640359\n",
      "epoch: 46  batch: 50  loss: 0.16491492\n",
      "epoch: 46  batch: 51  loss: 0.13574985\n",
      "epoch: 46  batch: 52  loss: 0.06230751\n",
      "epoch: 46  batch: 53  loss: 0.06409254\n",
      "epoch: 46  batch: 54  loss: 0.38060176\n",
      "epoch: 46  batch: 55  loss: 0.24336442\n",
      "epoch: 46  batch: 56  loss: 0.08481155\n",
      "epoch: 46  batch: 57  loss: 0.05050363\n",
      "epoch: 46  batch: 58  loss: 0.12557602\n",
      "epoch: 46  batch: 59  loss: 0.08760975\n",
      "epoch: 46  batch: 60  loss: 0.29201820\n",
      "epoch: 46  batch: 61  loss: 0.56492156\n",
      "epoch: 46  batch: 62  loss: 0.19120854\n",
      "epoch: 46  batch: 63  loss: 0.22298822\n",
      "epoch: 46  batch: 64  loss: 0.16325855\n",
      "epoch: 46  batch: 65  loss: 0.06304729\n",
      "epoch: 46  batch: 66  loss: 0.03126818\n",
      "epoch: 46  batch: 67  loss: 0.04100383\n",
      "epoch: 46  batch: 68  loss: 0.08516969\n",
      "epoch: 47  batch: 1  loss: 0.17301886\n",
      "epoch: 47  batch: 2  loss: 0.04348351\n",
      "epoch: 47  batch: 3  loss: 0.03081625\n",
      "epoch: 47  batch: 4  loss: 0.02772188\n",
      "epoch: 47  batch: 5  loss: 0.11724681\n",
      "epoch: 47  batch: 6  loss: 0.09550735\n",
      "epoch: 47  batch: 7  loss: 0.27389583\n",
      "epoch: 47  batch: 8  loss: 0.12457106\n",
      "epoch: 47  batch: 9  loss: 0.24853575\n",
      "epoch: 47  batch: 10  loss: 0.29261741\n",
      "epoch: 47  batch: 11  loss: 0.27797985\n",
      "epoch: 47  batch: 12  loss: 0.19535811\n",
      "epoch: 47  batch: 13  loss: 0.13595067\n",
      "epoch: 47  batch: 14  loss: 0.15565388\n",
      "epoch: 47  batch: 15  loss: 0.12838183\n",
      "epoch: 47  batch: 16  loss: 0.09400668\n",
      "epoch: 47  batch: 17  loss: 0.19793469\n",
      "epoch: 47  batch: 18  loss: 0.06142438\n",
      "epoch: 47  batch: 19  loss: 0.04785253\n",
      "epoch: 47  batch: 20  loss: 0.28177527\n",
      "epoch: 47  batch: 21  loss: 0.34727734\n",
      "epoch: 47  batch: 22  loss: 0.09176560\n",
      "epoch: 47  batch: 23  loss: 0.05183246\n",
      "epoch: 47  batch: 24  loss: 0.05612743\n",
      "epoch: 47  batch: 25  loss: 0.07959431\n",
      "epoch: 47  batch: 26  loss: 0.21923311\n",
      "epoch: 47  batch: 27  loss: 0.51670837\n",
      "epoch: 47  batch: 28  loss: 0.20768209\n",
      "epoch: 47  batch: 29  loss: 0.20068957\n",
      "epoch: 47  batch: 30  loss: 0.15286499\n",
      "epoch: 47  batch: 31  loss: 0.07269309\n",
      "epoch: 47  batch: 32  loss: 0.01649430\n",
      "epoch: 47  batch: 33  loss: 0.05680478\n",
      "epoch: 47  batch: 34  loss: 0.08651135\n",
      "epoch: 47  batch: 35  loss: 0.16973990\n",
      "epoch: 47  batch: 36  loss: 0.03570515\n",
      "epoch: 47  batch: 37  loss: 0.03067013\n",
      "epoch: 47  batch: 38  loss: 0.04771354\n",
      "epoch: 47  batch: 39  loss: 0.17387238\n",
      "epoch: 47  batch: 40  loss: 0.10970921\n",
      "epoch: 47  batch: 41  loss: 0.20290644\n",
      "epoch: 47  batch: 42  loss: 0.14550863\n",
      "epoch: 47  batch: 43  loss: 0.17004466\n",
      "epoch: 47  batch: 44  loss: 0.23546222\n",
      "epoch: 47  batch: 45  loss: 0.36303076\n",
      "epoch: 47  batch: 46  loss: 0.20832185\n",
      "epoch: 47  batch: 47  loss: 0.18921104\n",
      "epoch: 47  batch: 48  loss: 0.13208959\n",
      "epoch: 47  batch: 49  loss: 0.12803674\n",
      "epoch: 47  batch: 50  loss: 0.16323552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47  batch: 51  loss: 0.13206874\n",
      "epoch: 47  batch: 52  loss: 0.06266937\n",
      "epoch: 47  batch: 53  loss: 0.06523903\n",
      "epoch: 47  batch: 54  loss: 0.38175845\n",
      "epoch: 47  batch: 55  loss: 0.24250881\n",
      "epoch: 47  batch: 56  loss: 0.08554003\n",
      "epoch: 47  batch: 57  loss: 0.05017555\n",
      "epoch: 47  batch: 58  loss: 0.12778349\n",
      "epoch: 47  batch: 59  loss: 0.08756828\n",
      "epoch: 47  batch: 60  loss: 0.30110389\n",
      "epoch: 47  batch: 61  loss: 0.55337805\n",
      "epoch: 47  batch: 62  loss: 0.17841005\n",
      "epoch: 47  batch: 63  loss: 0.22550528\n",
      "epoch: 47  batch: 64  loss: 0.17632715\n",
      "epoch: 47  batch: 65  loss: 0.05362870\n",
      "epoch: 47  batch: 66  loss: 0.03215944\n",
      "epoch: 47  batch: 67  loss: 0.04004962\n",
      "epoch: 47  batch: 68  loss: 0.08645894\n",
      "epoch: 48  batch: 1  loss: 0.17702228\n",
      "epoch: 48  batch: 2  loss: 0.04413509\n",
      "epoch: 48  batch: 3  loss: 0.03090690\n",
      "epoch: 48  batch: 4  loss: 0.02899460\n",
      "epoch: 48  batch: 5  loss: 0.11952091\n",
      "epoch: 48  batch: 6  loss: 0.09547281\n",
      "epoch: 48  batch: 7  loss: 0.26252586\n",
      "epoch: 48  batch: 8  loss: 0.13102967\n",
      "epoch: 48  batch: 9  loss: 0.22373353\n",
      "epoch: 48  batch: 10  loss: 0.32931644\n",
      "epoch: 48  batch: 11  loss: 0.27998990\n",
      "epoch: 48  batch: 12  loss: 0.18853985\n",
      "epoch: 48  batch: 13  loss: 0.13465585\n",
      "epoch: 48  batch: 14  loss: 0.15096530\n",
      "epoch: 48  batch: 15  loss: 0.13220669\n",
      "epoch: 48  batch: 16  loss: 0.09399868\n",
      "epoch: 48  batch: 17  loss: 0.20373052\n",
      "epoch: 48  batch: 18  loss: 0.05990768\n",
      "epoch: 48  batch: 19  loss: 0.04989015\n",
      "epoch: 48  batch: 20  loss: 0.28103298\n",
      "epoch: 48  batch: 21  loss: 0.34671593\n",
      "epoch: 48  batch: 22  loss: 0.08935015\n",
      "epoch: 48  batch: 23  loss: 0.05226703\n",
      "epoch: 48  batch: 24  loss: 0.05696530\n",
      "epoch: 48  batch: 25  loss: 0.07888637\n",
      "epoch: 48  batch: 26  loss: 0.20080656\n",
      "epoch: 48  batch: 27  loss: 0.52653760\n",
      "epoch: 48  batch: 28  loss: 0.17328818\n",
      "epoch: 48  batch: 29  loss: 0.18903188\n",
      "epoch: 48  batch: 30  loss: 0.11007823\n",
      "epoch: 48  batch: 31  loss: 0.07389916\n",
      "epoch: 48  batch: 32  loss: 0.01631899\n",
      "epoch: 48  batch: 33  loss: 0.05663695\n",
      "epoch: 48  batch: 34  loss: 0.08717344\n",
      "epoch: 48  batch: 35  loss: 0.16995998\n",
      "epoch: 48  batch: 36  loss: 0.03596439\n",
      "epoch: 48  batch: 37  loss: 0.03076200\n",
      "epoch: 48  batch: 38  loss: 0.04561117\n",
      "epoch: 48  batch: 39  loss: 0.17395785\n",
      "epoch: 48  batch: 40  loss: 0.11529626\n",
      "epoch: 48  batch: 41  loss: 0.20184284\n",
      "epoch: 48  batch: 42  loss: 0.14714321\n",
      "epoch: 48  batch: 43  loss: 0.16964404\n",
      "epoch: 48  batch: 44  loss: 0.23832330\n",
      "epoch: 48  batch: 45  loss: 0.36319461\n",
      "epoch: 48  batch: 46  loss: 0.20482965\n",
      "epoch: 48  batch: 47  loss: 0.18675683\n",
      "epoch: 48  batch: 48  loss: 0.12945731\n",
      "epoch: 48  batch: 49  loss: 0.13053493\n",
      "epoch: 48  batch: 50  loss: 0.15698247\n",
      "epoch: 48  batch: 51  loss: 0.13174739\n",
      "epoch: 48  batch: 52  loss: 0.06515609\n",
      "epoch: 48  batch: 53  loss: 0.06996657\n",
      "epoch: 48  batch: 54  loss: 0.38243163\n",
      "epoch: 48  batch: 55  loss: 0.24263500\n",
      "epoch: 48  batch: 56  loss: 0.08608885\n",
      "epoch: 48  batch: 57  loss: 0.04963608\n",
      "epoch: 48  batch: 58  loss: 0.12328541\n",
      "epoch: 48  batch: 59  loss: 0.09176090\n",
      "epoch: 48  batch: 60  loss: 0.29642397\n",
      "epoch: 48  batch: 61  loss: 0.55980694\n",
      "epoch: 48  batch: 62  loss: 0.17023945\n",
      "epoch: 48  batch: 63  loss: 0.20708381\n",
      "epoch: 48  batch: 64  loss: 0.17729829\n",
      "epoch: 48  batch: 65  loss: 0.05260242\n",
      "epoch: 48  batch: 66  loss: 0.03234521\n",
      "epoch: 48  batch: 67  loss: 0.04183535\n",
      "epoch: 48  batch: 68  loss: 0.08528664\n",
      "epoch: 49  batch: 1  loss: 0.16870935\n",
      "epoch: 49  batch: 2  loss: 0.04361644\n",
      "epoch: 49  batch: 3  loss: 0.03027368\n",
      "epoch: 49  batch: 4  loss: 0.02805907\n",
      "epoch: 49  batch: 5  loss: 0.11551448\n",
      "epoch: 49  batch: 6  loss: 0.09454316\n",
      "epoch: 49  batch: 7  loss: 0.23767751\n",
      "epoch: 49  batch: 8  loss: 0.12100624\n",
      "epoch: 49  batch: 9  loss: 0.23145591\n",
      "epoch: 49  batch: 10  loss: 0.28622472\n",
      "epoch: 49  batch: 11  loss: 0.27332804\n",
      "epoch: 49  batch: 12  loss: 0.17899410\n",
      "epoch: 49  batch: 13  loss: 0.11954703\n",
      "epoch: 49  batch: 14  loss: 0.15248348\n",
      "epoch: 49  batch: 15  loss: 0.12482153\n",
      "epoch: 49  batch: 16  loss: 0.09384662\n",
      "epoch: 49  batch: 17  loss: 0.18104659\n",
      "epoch: 49  batch: 18  loss: 0.05651939\n",
      "epoch: 49  batch: 19  loss: 0.04215785\n",
      "epoch: 49  batch: 20  loss: 0.28241372\n",
      "epoch: 49  batch: 21  loss: 0.34714830\n",
      "epoch: 49  batch: 22  loss: 0.08728158\n",
      "epoch: 49  batch: 23  loss: 0.05449486\n",
      "epoch: 49  batch: 24  loss: 0.05508807\n",
      "epoch: 49  batch: 25  loss: 0.08302670\n",
      "epoch: 49  batch: 26  loss: 0.17360245\n",
      "epoch: 49  batch: 27  loss: 0.51966274\n",
      "epoch: 49  batch: 28  loss: 0.16052929\n",
      "epoch: 49  batch: 29  loss: 0.18156879\n",
      "epoch: 49  batch: 30  loss: 0.12621066\n",
      "epoch: 49  batch: 31  loss: 0.07200161\n",
      "epoch: 49  batch: 32  loss: 0.01387654\n",
      "epoch: 49  batch: 33  loss: 0.07032820\n",
      "epoch: 49  batch: 34  loss: 0.08717524\n",
      "epoch: 49  batch: 35  loss: 0.16974895\n",
      "epoch: 49  batch: 36  loss: 0.03618073\n",
      "epoch: 49  batch: 37  loss: 0.03108507\n",
      "epoch: 49  batch: 38  loss: 0.04649347\n",
      "epoch: 49  batch: 39  loss: 0.17305329\n",
      "epoch: 49  batch: 40  loss: 0.11303472\n",
      "epoch: 49  batch: 41  loss: 0.20385078\n",
      "epoch: 49  batch: 42  loss: 0.13857657\n",
      "epoch: 49  batch: 43  loss: 0.16520394\n",
      "epoch: 49  batch: 44  loss: 0.23420809\n",
      "epoch: 49  batch: 45  loss: 0.35925993\n",
      "epoch: 49  batch: 46  loss: 0.20271195\n",
      "epoch: 49  batch: 47  loss: 0.19023499\n",
      "epoch: 49  batch: 48  loss: 0.12884974\n",
      "epoch: 49  batch: 49  loss: 0.12851284\n",
      "epoch: 49  batch: 50  loss: 0.15772383\n",
      "epoch: 49  batch: 51  loss: 0.13456395\n",
      "epoch: 49  batch: 52  loss: 0.06447115\n",
      "epoch: 49  batch: 53  loss: 0.06469646\n",
      "epoch: 49  batch: 54  loss: 0.38277984\n",
      "epoch: 49  batch: 55  loss: 0.24235177\n",
      "epoch: 49  batch: 56  loss: 0.08607365\n",
      "epoch: 49  batch: 57  loss: 0.05103680\n",
      "epoch: 49  batch: 58  loss: 0.12361028\n",
      "epoch: 49  batch: 59  loss: 0.08871407\n",
      "epoch: 49  batch: 60  loss: 0.27010241\n",
      "epoch: 49  batch: 61  loss: 0.55083787\n",
      "epoch: 49  batch: 62  loss: 0.16535714\n",
      "epoch: 49  batch: 63  loss: 0.19380327\n",
      "epoch: 49  batch: 64  loss: 0.16670418\n",
      "epoch: 49  batch: 65  loss: 0.05523532\n",
      "epoch: 49  batch: 66  loss: 0.03326818\n",
      "epoch: 49  batch: 67  loss: 0.04014071\n",
      "epoch: 49  batch: 68  loss: 0.08567056\n",
      "epoch: 50  batch: 1  loss: 0.16966878\n",
      "epoch: 50  batch: 2  loss: 0.04346054\n",
      "epoch: 50  batch: 3  loss: 0.03014167\n",
      "epoch: 50  batch: 4  loss: 0.02811426\n",
      "epoch: 50  batch: 5  loss: 0.11596557\n",
      "epoch: 50  batch: 6  loss: 0.10841361\n",
      "epoch: 50  batch: 7  loss: 0.24092752\n",
      "epoch: 50  batch: 8  loss: 0.12184353\n",
      "epoch: 50  batch: 9  loss: 0.21887276\n",
      "epoch: 50  batch: 10  loss: 0.27844501\n",
      "epoch: 50  batch: 11  loss: 0.27164090\n",
      "epoch: 50  batch: 12  loss: 0.17813878\n",
      "epoch: 50  batch: 13  loss: 0.11494035\n",
      "epoch: 50  batch: 14  loss: 0.14864886\n",
      "epoch: 50  batch: 15  loss: 0.12342385\n",
      "epoch: 50  batch: 16  loss: 0.09368747\n",
      "epoch: 50  batch: 17  loss: 0.16412020\n",
      "epoch: 50  batch: 18  loss: 0.05717534\n",
      "epoch: 50  batch: 19  loss: 0.04202418\n",
      "epoch: 50  batch: 20  loss: 0.28327477\n",
      "epoch: 50  batch: 21  loss: 0.34713811\n",
      "epoch: 50  batch: 22  loss: 0.08714225\n",
      "epoch: 50  batch: 23  loss: 0.05510473\n",
      "epoch: 50  batch: 24  loss: 0.05521793\n",
      "epoch: 50  batch: 25  loss: 0.08216006\n",
      "epoch: 50  batch: 26  loss: 0.16794646\n",
      "epoch: 50  batch: 27  loss: 0.51743859\n",
      "epoch: 50  batch: 28  loss: 0.15658139\n",
      "epoch: 50  batch: 29  loss: 0.17620322\n",
      "epoch: 50  batch: 30  loss: 0.11016780\n",
      "epoch: 50  batch: 31  loss: 0.07066544\n",
      "epoch: 50  batch: 32  loss: 0.01397930\n",
      "epoch: 50  batch: 33  loss: 0.06605455\n",
      "epoch: 50  batch: 34  loss: 0.08678100\n",
      "epoch: 50  batch: 35  loss: 0.16919887\n",
      "epoch: 50  batch: 36  loss: 0.03629450\n",
      "epoch: 50  batch: 37  loss: 0.03167170\n",
      "epoch: 50  batch: 38  loss: 0.04782735\n",
      "epoch: 50  batch: 39  loss: 0.17277266\n",
      "epoch: 50  batch: 40  loss: 0.11836220\n",
      "epoch: 50  batch: 41  loss: 0.20718057\n",
      "epoch: 50  batch: 42  loss: 0.13224080\n",
      "epoch: 50  batch: 43  loss: 0.16157049\n",
      "epoch: 50  batch: 44  loss: 0.23232126\n",
      "epoch: 50  batch: 45  loss: 0.35766909\n",
      "epoch: 50  batch: 46  loss: 0.20448469\n",
      "epoch: 50  batch: 47  loss: 0.18702760\n",
      "epoch: 50  batch: 48  loss: 0.12872149\n",
      "epoch: 50  batch: 49  loss: 0.12588888\n",
      "epoch: 50  batch: 50  loss: 0.15461551\n",
      "epoch: 50  batch: 51  loss: 0.13841663\n",
      "epoch: 50  batch: 52  loss: 0.06518999\n",
      "epoch: 50  batch: 53  loss: 0.06467432\n",
      "epoch: 50  batch: 54  loss: 0.38452759\n",
      "epoch: 50  batch: 55  loss: 0.24188507\n",
      "epoch: 50  batch: 56  loss: 0.08640473\n",
      "epoch: 50  batch: 57  loss: 0.05156748\n",
      "epoch: 50  batch: 58  loss: 0.12700099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50  batch: 59  loss: 0.08820120\n",
      "epoch: 50  batch: 60  loss: 0.28496704\n",
      "epoch: 50  batch: 61  loss: 0.54962683\n",
      "epoch: 50  batch: 62  loss: 0.15784942\n",
      "epoch: 50  batch: 63  loss: 0.19886085\n",
      "epoch: 50  batch: 64  loss: 0.18929747\n",
      "epoch: 50  batch: 65  loss: 0.04667930\n",
      "epoch: 50  batch: 66  loss: 0.03416573\n",
      "epoch: 50  batch: 67  loss: 0.04229149\n",
      "epoch: 50  batch: 68  loss: 0.08577015\n",
      "epoch: 51  batch: 1  loss: 0.17035249\n",
      "epoch: 51  batch: 2  loss: 0.04391793\n",
      "epoch: 51  batch: 3  loss: 0.03064666\n",
      "epoch: 51  batch: 4  loss: 0.02933981\n",
      "epoch: 51  batch: 5  loss: 0.11509368\n",
      "epoch: 51  batch: 6  loss: 0.09255350\n",
      "epoch: 51  batch: 7  loss: 0.24102670\n",
      "epoch: 51  batch: 8  loss: 0.12326655\n",
      "epoch: 51  batch: 9  loss: 0.21563098\n",
      "epoch: 51  batch: 10  loss: 0.32926437\n",
      "epoch: 51  batch: 11  loss: 0.27938107\n",
      "epoch: 51  batch: 12  loss: 0.18345660\n",
      "epoch: 51  batch: 13  loss: 0.11358527\n",
      "epoch: 51  batch: 14  loss: 0.14627966\n",
      "epoch: 51  batch: 15  loss: 0.12698796\n",
      "epoch: 51  batch: 16  loss: 0.09309181\n",
      "epoch: 51  batch: 17  loss: 0.17289110\n",
      "epoch: 51  batch: 18  loss: 0.06203688\n",
      "epoch: 51  batch: 19  loss: 0.04533525\n",
      "epoch: 51  batch: 20  loss: 0.28376630\n",
      "epoch: 51  batch: 21  loss: 0.34678537\n",
      "epoch: 51  batch: 22  loss: 0.09126263\n",
      "epoch: 51  batch: 23  loss: 0.05185865\n",
      "epoch: 51  batch: 24  loss: 0.05595079\n",
      "epoch: 51  batch: 25  loss: 0.07967815\n",
      "epoch: 51  batch: 26  loss: 0.22511029\n",
      "epoch: 51  batch: 27  loss: 0.50402594\n",
      "epoch: 51  batch: 28  loss: 0.17718227\n",
      "epoch: 51  batch: 29  loss: 0.18183477\n",
      "epoch: 51  batch: 30  loss: 0.14829601\n",
      "epoch: 51  batch: 31  loss: 0.06758339\n",
      "epoch: 51  batch: 32  loss: 0.01518294\n",
      "epoch: 51  batch: 33  loss: 0.05319706\n",
      "epoch: 51  batch: 34  loss: 0.08691002\n",
      "epoch: 51  batch: 35  loss: 0.17007868\n",
      "epoch: 51  batch: 36  loss: 0.03642099\n",
      "epoch: 51  batch: 37  loss: 0.03113278\n",
      "epoch: 51  batch: 38  loss: 0.04474933\n",
      "epoch: 51  batch: 39  loss: 0.17201589\n",
      "epoch: 51  batch: 40  loss: 0.11687610\n",
      "epoch: 51  batch: 41  loss: 0.19808546\n",
      "epoch: 51  batch: 42  loss: 0.16281749\n",
      "epoch: 51  batch: 43  loss: 0.16914478\n",
      "epoch: 51  batch: 44  loss: 0.22990204\n",
      "epoch: 51  batch: 45  loss: 0.36832553\n",
      "epoch: 51  batch: 46  loss: 0.19453579\n",
      "epoch: 51  batch: 47  loss: 0.18040000\n",
      "epoch: 51  batch: 48  loss: 0.12905392\n",
      "epoch: 51  batch: 49  loss: 0.13095172\n",
      "epoch: 51  batch: 50  loss: 0.15550743\n",
      "epoch: 51  batch: 51  loss: 0.12966740\n",
      "epoch: 51  batch: 52  loss: 0.06753545\n",
      "epoch: 51  batch: 53  loss: 0.06612234\n",
      "epoch: 51  batch: 54  loss: 0.38467503\n",
      "epoch: 51  batch: 55  loss: 0.24108081\n",
      "epoch: 51  batch: 56  loss: 0.08644684\n",
      "epoch: 51  batch: 57  loss: 0.05037654\n",
      "epoch: 51  batch: 58  loss: 0.12582034\n",
      "epoch: 51  batch: 59  loss: 0.08966987\n",
      "epoch: 51  batch: 60  loss: 0.28760189\n",
      "epoch: 51  batch: 61  loss: 0.54753065\n",
      "epoch: 51  batch: 62  loss: 0.15950789\n",
      "epoch: 51  batch: 63  loss: 0.20362046\n",
      "epoch: 51  batch: 64  loss: 0.17144468\n",
      "epoch: 51  batch: 65  loss: 0.05551367\n",
      "epoch: 51  batch: 66  loss: 0.03388187\n",
      "epoch: 51  batch: 67  loss: 0.04364983\n",
      "epoch: 51  batch: 68  loss: 0.08524888\n",
      "epoch: 52  batch: 1  loss: 0.16658807\n",
      "epoch: 52  batch: 2  loss: 0.04426119\n",
      "epoch: 52  batch: 3  loss: 0.03088720\n",
      "epoch: 52  batch: 4  loss: 0.02840548\n",
      "epoch: 52  batch: 5  loss: 0.11387403\n",
      "epoch: 52  batch: 6  loss: 0.09222396\n",
      "epoch: 52  batch: 7  loss: 0.22344483\n",
      "epoch: 52  batch: 8  loss: 0.11924678\n",
      "epoch: 52  batch: 9  loss: 0.22110115\n",
      "epoch: 52  batch: 10  loss: 0.29877377\n",
      "epoch: 52  batch: 11  loss: 0.28031605\n",
      "epoch: 52  batch: 12  loss: 0.18254273\n",
      "epoch: 52  batch: 13  loss: 0.11087893\n",
      "epoch: 52  batch: 14  loss: 0.14875147\n",
      "epoch: 52  batch: 15  loss: 0.12191696\n",
      "epoch: 52  batch: 16  loss: 0.09354752\n",
      "epoch: 52  batch: 17  loss: 0.15410158\n",
      "epoch: 52  batch: 18  loss: 0.05565507\n",
      "epoch: 52  batch: 19  loss: 0.04104558\n",
      "epoch: 52  batch: 20  loss: 0.28556648\n",
      "epoch: 52  batch: 21  loss: 0.34619883\n",
      "epoch: 52  batch: 22  loss: 0.08886582\n",
      "epoch: 52  batch: 23  loss: 0.05404867\n",
      "epoch: 52  batch: 24  loss: 0.05379997\n",
      "epoch: 52  batch: 25  loss: 0.08804666\n",
      "epoch: 52  batch: 26  loss: 0.15773953\n",
      "epoch: 52  batch: 27  loss: 0.49532604\n",
      "epoch: 52  batch: 28  loss: 0.14657626\n",
      "epoch: 52  batch: 29  loss: 0.18449195\n",
      "epoch: 52  batch: 30  loss: 0.10774277\n",
      "epoch: 52  batch: 31  loss: 0.06954774\n",
      "epoch: 52  batch: 32  loss: 0.01378849\n",
      "epoch: 52  batch: 33  loss: 0.06616082\n",
      "epoch: 52  batch: 34  loss: 0.08652197\n",
      "epoch: 52  batch: 35  loss: 0.16801277\n",
      "epoch: 52  batch: 36  loss: 0.03686183\n",
      "epoch: 52  batch: 37  loss: 0.03220102\n",
      "epoch: 52  batch: 38  loss: 0.04679526\n",
      "epoch: 52  batch: 39  loss: 0.16910471\n",
      "epoch: 52  batch: 40  loss: 0.11728878\n",
      "epoch: 52  batch: 41  loss: 0.20812009\n",
      "epoch: 52  batch: 42  loss: 0.13698779\n",
      "epoch: 52  batch: 43  loss: 0.15918067\n",
      "epoch: 52  batch: 44  loss: 0.24149628\n",
      "epoch: 52  batch: 45  loss: 0.35456347\n",
      "epoch: 52  batch: 46  loss: 0.19741388\n",
      "epoch: 52  batch: 47  loss: 0.18806708\n",
      "epoch: 52  batch: 48  loss: 0.12796390\n",
      "epoch: 52  batch: 49  loss: 0.12416457\n",
      "epoch: 52  batch: 50  loss: 0.14455065\n",
      "epoch: 52  batch: 51  loss: 0.13926636\n",
      "epoch: 52  batch: 52  loss: 0.06505179\n",
      "epoch: 52  batch: 53  loss: 0.06550673\n",
      "epoch: 52  batch: 54  loss: 0.38653651\n",
      "epoch: 52  batch: 55  loss: 0.24173479\n",
      "epoch: 52  batch: 56  loss: 0.08563703\n",
      "epoch: 52  batch: 57  loss: 0.04900671\n",
      "epoch: 52  batch: 58  loss: 0.12963313\n",
      "epoch: 52  batch: 59  loss: 0.08974732\n",
      "epoch: 52  batch: 60  loss: 0.31387758\n",
      "epoch: 52  batch: 61  loss: 0.57222706\n",
      "epoch: 52  batch: 62  loss: 0.16319215\n",
      "epoch: 52  batch: 63  loss: 0.21113153\n",
      "epoch: 52  batch: 64  loss: 0.15835530\n",
      "epoch: 52  batch: 65  loss: 0.06170927\n",
      "epoch: 52  batch: 66  loss: 0.03544530\n",
      "epoch: 52  batch: 67  loss: 0.04126218\n",
      "epoch: 52  batch: 68  loss: 0.08561569\n",
      "epoch: 53  batch: 1  loss: 0.16366763\n",
      "epoch: 53  batch: 2  loss: 0.04763355\n",
      "epoch: 53  batch: 3  loss: 0.03073038\n",
      "epoch: 53  batch: 4  loss: 0.02842828\n",
      "epoch: 53  batch: 5  loss: 0.11379956\n",
      "epoch: 53  batch: 6  loss: 0.09861047\n",
      "epoch: 53  batch: 7  loss: 0.25558531\n",
      "epoch: 53  batch: 8  loss: 0.11393581\n",
      "epoch: 53  batch: 9  loss: 0.20479228\n",
      "epoch: 53  batch: 10  loss: 0.27406773\n",
      "epoch: 53  batch: 11  loss: 0.29219016\n",
      "epoch: 53  batch: 12  loss: 0.17591938\n",
      "epoch: 53  batch: 13  loss: 0.12136163\n",
      "epoch: 53  batch: 14  loss: 0.13384300\n",
      "epoch: 53  batch: 15  loss: 0.12785348\n",
      "epoch: 53  batch: 16  loss: 0.09249194\n",
      "epoch: 53  batch: 17  loss: 0.15417169\n",
      "epoch: 53  batch: 18  loss: 0.06924523\n",
      "epoch: 53  batch: 19  loss: 0.05982370\n",
      "epoch: 53  batch: 20  loss: 0.28544030\n",
      "epoch: 53  batch: 21  loss: 0.34468889\n",
      "epoch: 53  batch: 22  loss: 0.09963731\n",
      "epoch: 53  batch: 23  loss: 0.05364667\n",
      "epoch: 53  batch: 24  loss: 0.06111667\n",
      "epoch: 53  batch: 25  loss: 0.07649346\n",
      "epoch: 53  batch: 26  loss: 0.19455302\n",
      "epoch: 53  batch: 27  loss: 0.48110861\n",
      "epoch: 53  batch: 28  loss: 0.24179561\n",
      "epoch: 53  batch: 29  loss: 0.21036141\n",
      "epoch: 53  batch: 30  loss: 0.11080876\n",
      "epoch: 53  batch: 31  loss: 0.05890035\n",
      "epoch: 53  batch: 32  loss: 0.01836227\n",
      "epoch: 53  batch: 33  loss: 0.03086196\n",
      "epoch: 53  batch: 34  loss: 0.08296479\n",
      "epoch: 53  batch: 35  loss: 0.16756698\n",
      "epoch: 53  batch: 36  loss: 0.03829346\n",
      "epoch: 53  batch: 37  loss: 0.03264089\n",
      "epoch: 53  batch: 38  loss: 0.05261288\n",
      "epoch: 53  batch: 39  loss: 0.18149085\n",
      "epoch: 53  batch: 40  loss: 0.10647728\n",
      "epoch: 53  batch: 41  loss: 0.19813105\n",
      "epoch: 53  batch: 42  loss: 0.15409945\n",
      "epoch: 53  batch: 43  loss: 0.17489518\n",
      "epoch: 53  batch: 44  loss: 0.24398118\n",
      "epoch: 53  batch: 45  loss: 0.36982003\n",
      "epoch: 53  batch: 46  loss: 0.19100952\n",
      "epoch: 53  batch: 47  loss: 0.19853354\n",
      "epoch: 53  batch: 48  loss: 0.12926073\n",
      "epoch: 53  batch: 49  loss: 0.16725539\n",
      "epoch: 53  batch: 50  loss: 0.15709157\n",
      "epoch: 53  batch: 51  loss: 0.12032916\n",
      "epoch: 53  batch: 52  loss: 0.06546041\n",
      "epoch: 53  batch: 53  loss: 0.06384270\n",
      "epoch: 53  batch: 54  loss: 0.38134810\n",
      "epoch: 53  batch: 55  loss: 0.24029109\n",
      "epoch: 53  batch: 56  loss: 0.10856174\n",
      "epoch: 53  batch: 57  loss: 0.04946241\n",
      "epoch: 53  batch: 58  loss: 0.14408940\n",
      "epoch: 53  batch: 59  loss: 0.09395893\n",
      "epoch: 53  batch: 60  loss: 0.27042979\n",
      "epoch: 53  batch: 61  loss: 0.54568034\n",
      "epoch: 53  batch: 62  loss: 0.16750634\n",
      "epoch: 53  batch: 63  loss: 0.30666542\n",
      "epoch: 53  batch: 64  loss: 0.16589843\n",
      "epoch: 53  batch: 65  loss: 0.06329449\n",
      "epoch: 53  batch: 66  loss: 0.03565761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53  batch: 67  loss: 0.04383086\n",
      "epoch: 53  batch: 68  loss: 0.08605681\n",
      "epoch: 54  batch: 1  loss: 0.16612683\n",
      "epoch: 54  batch: 2  loss: 0.04949744\n",
      "epoch: 54  batch: 3  loss: 0.03661246\n",
      "epoch: 54  batch: 4  loss: 0.02825259\n",
      "epoch: 54  batch: 5  loss: 0.13310248\n",
      "epoch: 54  batch: 6  loss: 0.14500532\n",
      "epoch: 54  batch: 7  loss: 0.23844019\n",
      "epoch: 54  batch: 8  loss: 0.11365090\n",
      "epoch: 54  batch: 9  loss: 0.23330215\n",
      "epoch: 54  batch: 10  loss: 0.31189638\n",
      "epoch: 54  batch: 11  loss: 0.34041059\n",
      "epoch: 54  batch: 12  loss: 0.17197980\n",
      "epoch: 54  batch: 13  loss: 0.13749844\n",
      "epoch: 54  batch: 14  loss: 0.13092323\n",
      "epoch: 54  batch: 15  loss: 0.12717672\n",
      "epoch: 54  batch: 16  loss: 0.09297145\n",
      "epoch: 54  batch: 17  loss: 0.14443843\n",
      "epoch: 54  batch: 18  loss: 0.06770362\n",
      "epoch: 54  batch: 19  loss: 0.06835410\n",
      "epoch: 54  batch: 20  loss: 0.28362390\n",
      "epoch: 54  batch: 21  loss: 0.34547222\n",
      "epoch: 54  batch: 22  loss: 0.09872657\n",
      "epoch: 54  batch: 23  loss: 0.05306572\n",
      "epoch: 54  batch: 24  loss: 0.05885649\n",
      "epoch: 54  batch: 25  loss: 0.07251252\n",
      "epoch: 54  batch: 26  loss: 0.18018465\n",
      "epoch: 54  batch: 27  loss: 0.49015045\n",
      "epoch: 54  batch: 28  loss: 0.18355061\n",
      "epoch: 54  batch: 29  loss: 0.20849353\n",
      "epoch: 54  batch: 30  loss: 0.11122695\n",
      "epoch: 54  batch: 31  loss: 0.05697019\n",
      "epoch: 54  batch: 32  loss: 0.01745812\n",
      "epoch: 54  batch: 33  loss: 0.02311861\n",
      "epoch: 54  batch: 34  loss: 0.08456017\n",
      "epoch: 54  batch: 35  loss: 0.16908188\n",
      "epoch: 54  batch: 36  loss: 0.03653570\n",
      "epoch: 54  batch: 37  loss: 0.03165380\n",
      "epoch: 54  batch: 38  loss: 0.04510085\n",
      "epoch: 54  batch: 39  loss: 0.17649549\n",
      "epoch: 54  batch: 40  loss: 0.09894622\n",
      "epoch: 54  batch: 41  loss: 0.19805837\n",
      "epoch: 54  batch: 42  loss: 0.14163952\n",
      "epoch: 54  batch: 43  loss: 0.17953515\n",
      "epoch: 54  batch: 44  loss: 0.23088072\n",
      "epoch: 54  batch: 45  loss: 0.36175141\n",
      "epoch: 54  batch: 46  loss: 0.18637685\n",
      "epoch: 54  batch: 47  loss: 0.20301060\n",
      "epoch: 54  batch: 48  loss: 0.13049346\n",
      "epoch: 54  batch: 49  loss: 0.16211836\n",
      "epoch: 54  batch: 50  loss: 0.16055407\n",
      "epoch: 54  batch: 51  loss: 0.12452222\n",
      "epoch: 54  batch: 52  loss: 0.06240464\n",
      "epoch: 54  batch: 53  loss: 0.06681655\n",
      "epoch: 54  batch: 54  loss: 0.38076240\n",
      "epoch: 54  batch: 55  loss: 0.24152723\n",
      "epoch: 54  batch: 56  loss: 0.09995894\n",
      "epoch: 54  batch: 57  loss: 0.05322421\n",
      "epoch: 54  batch: 58  loss: 0.12664160\n",
      "epoch: 54  batch: 59  loss: 0.09153908\n",
      "epoch: 54  batch: 60  loss: 0.23914219\n",
      "epoch: 54  batch: 61  loss: 0.56471014\n",
      "epoch: 54  batch: 62  loss: 0.14427464\n",
      "epoch: 54  batch: 63  loss: 0.29985324\n",
      "epoch: 54  batch: 64  loss: 0.15577123\n",
      "epoch: 54  batch: 65  loss: 0.06642620\n",
      "epoch: 54  batch: 66  loss: 0.03527071\n",
      "epoch: 54  batch: 67  loss: 0.04459681\n",
      "epoch: 54  batch: 68  loss: 0.08430474\n",
      "epoch: 55  batch: 1  loss: 0.16356556\n",
      "epoch: 55  batch: 2  loss: 0.05040239\n",
      "epoch: 55  batch: 3  loss: 0.04086163\n",
      "epoch: 55  batch: 4  loss: 0.02778341\n",
      "epoch: 55  batch: 5  loss: 0.12189742\n",
      "epoch: 55  batch: 6  loss: 0.12225853\n",
      "epoch: 55  batch: 7  loss: 0.23075157\n",
      "epoch: 55  batch: 8  loss: 0.11004485\n",
      "epoch: 55  batch: 9  loss: 0.19720030\n",
      "epoch: 55  batch: 10  loss: 0.20454475\n",
      "epoch: 55  batch: 11  loss: 0.33025455\n",
      "epoch: 55  batch: 12  loss: 0.16884975\n",
      "epoch: 55  batch: 13  loss: 0.13437235\n",
      "epoch: 55  batch: 14  loss: 0.13133904\n",
      "epoch: 55  batch: 15  loss: 0.11444425\n",
      "epoch: 55  batch: 16  loss: 0.09262890\n",
      "epoch: 55  batch: 17  loss: 0.14613973\n",
      "epoch: 55  batch: 18  loss: 0.05928014\n",
      "epoch: 55  batch: 19  loss: 0.06060008\n",
      "epoch: 55  batch: 20  loss: 0.28589475\n",
      "epoch: 55  batch: 21  loss: 0.34727865\n",
      "epoch: 55  batch: 22  loss: 0.10409314\n",
      "epoch: 55  batch: 23  loss: 0.05589928\n",
      "epoch: 55  batch: 24  loss: 0.05600883\n",
      "epoch: 55  batch: 25  loss: 0.06894461\n",
      "epoch: 55  batch: 26  loss: 0.14523405\n",
      "epoch: 55  batch: 27  loss: 0.49082831\n",
      "epoch: 55  batch: 28  loss: 0.21821146\n",
      "epoch: 55  batch: 29  loss: 0.18505290\n",
      "epoch: 55  batch: 30  loss: 0.10289807\n",
      "epoch: 55  batch: 31  loss: 0.05526019\n",
      "epoch: 55  batch: 32  loss: 0.01786197\n",
      "epoch: 55  batch: 33  loss: 0.02923180\n",
      "epoch: 55  batch: 34  loss: 0.08314195\n",
      "epoch: 55  batch: 35  loss: 0.16543789\n",
      "epoch: 55  batch: 36  loss: 0.03719548\n",
      "epoch: 55  batch: 37  loss: 0.03308575\n",
      "epoch: 55  batch: 38  loss: 0.04383298\n",
      "epoch: 55  batch: 39  loss: 0.17522617\n",
      "epoch: 55  batch: 40  loss: 0.08736484\n",
      "epoch: 55  batch: 41  loss: 0.20047837\n",
      "epoch: 55  batch: 42  loss: 0.17546381\n",
      "epoch: 55  batch: 43  loss: 0.15445390\n",
      "epoch: 55  batch: 44  loss: 0.24255463\n",
      "epoch: 55  batch: 45  loss: 0.34854180\n",
      "epoch: 55  batch: 46  loss: 0.17804842\n",
      "epoch: 55  batch: 47  loss: 0.18952730\n",
      "epoch: 55  batch: 48  loss: 0.12763485\n",
      "epoch: 55  batch: 49  loss: 0.15680663\n",
      "epoch: 55  batch: 50  loss: 0.15942238\n",
      "epoch: 55  batch: 51  loss: 0.12646826\n",
      "epoch: 55  batch: 52  loss: 0.06262229\n",
      "epoch: 55  batch: 53  loss: 0.06444702\n",
      "epoch: 55  batch: 54  loss: 0.38382065\n",
      "epoch: 55  batch: 55  loss: 0.24044466\n",
      "epoch: 55  batch: 56  loss: 0.10076862\n",
      "epoch: 55  batch: 57  loss: 0.05158362\n",
      "epoch: 55  batch: 58  loss: 0.12314580\n",
      "epoch: 55  batch: 59  loss: 0.09069803\n",
      "epoch: 55  batch: 60  loss: 0.21491420\n",
      "epoch: 55  batch: 61  loss: 0.55330569\n",
      "epoch: 55  batch: 62  loss: 0.15958576\n",
      "epoch: 55  batch: 63  loss: 0.29439279\n",
      "epoch: 55  batch: 64  loss: 0.15148708\n",
      "epoch: 55  batch: 65  loss: 0.06873845\n",
      "epoch: 55  batch: 66  loss: 0.03699339\n",
      "epoch: 55  batch: 67  loss: 0.04708548\n",
      "epoch: 55  batch: 68  loss: 0.08654733\n",
      "epoch: 56  batch: 1  loss: 0.16418651\n",
      "epoch: 56  batch: 2  loss: 0.05001596\n",
      "epoch: 56  batch: 3  loss: 0.04122253\n",
      "epoch: 56  batch: 4  loss: 0.02788498\n",
      "epoch: 56  batch: 5  loss: 0.12399811\n",
      "epoch: 56  batch: 6  loss: 0.11197348\n",
      "epoch: 56  batch: 7  loss: 0.23125698\n",
      "epoch: 56  batch: 8  loss: 0.11633744\n",
      "epoch: 56  batch: 9  loss: 0.19019733\n",
      "epoch: 56  batch: 10  loss: 0.21091025\n",
      "epoch: 56  batch: 11  loss: 0.33654359\n",
      "epoch: 56  batch: 12  loss: 0.17306347\n",
      "epoch: 56  batch: 13  loss: 0.11070879\n",
      "epoch: 56  batch: 14  loss: 0.13024449\n",
      "epoch: 56  batch: 15  loss: 0.11730281\n",
      "epoch: 56  batch: 16  loss: 0.09120253\n",
      "epoch: 56  batch: 17  loss: 0.12928960\n",
      "epoch: 56  batch: 18  loss: 0.06038627\n",
      "epoch: 56  batch: 19  loss: 0.06024817\n",
      "epoch: 56  batch: 20  loss: 0.28609017\n",
      "epoch: 56  batch: 21  loss: 0.34536010\n",
      "epoch: 56  batch: 22  loss: 0.10034945\n",
      "epoch: 56  batch: 23  loss: 0.05175322\n",
      "epoch: 56  batch: 24  loss: 0.05536573\n",
      "epoch: 56  batch: 25  loss: 0.06876677\n",
      "epoch: 56  batch: 26  loss: 0.15267953\n",
      "epoch: 56  batch: 27  loss: 0.46918666\n",
      "epoch: 56  batch: 28  loss: 0.13941585\n",
      "epoch: 56  batch: 29  loss: 0.18793161\n",
      "epoch: 56  batch: 30  loss: 0.12792435\n",
      "epoch: 56  batch: 31  loss: 0.05202690\n",
      "epoch: 56  batch: 32  loss: 0.01753162\n",
      "epoch: 56  batch: 33  loss: 0.03296718\n",
      "epoch: 56  batch: 34  loss: 0.08310985\n",
      "epoch: 56  batch: 35  loss: 0.16492751\n",
      "epoch: 56  batch: 36  loss: 0.03729516\n",
      "epoch: 56  batch: 37  loss: 0.03302053\n",
      "epoch: 56  batch: 38  loss: 0.04404687\n",
      "epoch: 56  batch: 39  loss: 0.17229933\n",
      "epoch: 56  batch: 40  loss: 0.08993635\n",
      "epoch: 56  batch: 41  loss: 0.19906971\n",
      "epoch: 56  batch: 42  loss: 0.16739927\n",
      "epoch: 56  batch: 43  loss: 0.14666530\n",
      "epoch: 56  batch: 44  loss: 0.22870588\n",
      "epoch: 56  batch: 45  loss: 0.34032816\n",
      "epoch: 56  batch: 46  loss: 0.17822927\n",
      "epoch: 56  batch: 47  loss: 0.17103475\n",
      "epoch: 56  batch: 48  loss: 0.12686391\n",
      "epoch: 56  batch: 49  loss: 0.13542256\n",
      "epoch: 56  batch: 50  loss: 0.16230711\n",
      "epoch: 56  batch: 51  loss: 0.13283840\n",
      "epoch: 56  batch: 52  loss: 0.06814412\n",
      "epoch: 56  batch: 53  loss: 0.07493597\n",
      "epoch: 56  batch: 54  loss: 0.38726199\n",
      "epoch: 56  batch: 55  loss: 0.23973487\n",
      "epoch: 56  batch: 56  loss: 0.09869344\n",
      "epoch: 56  batch: 57  loss: 0.05005132\n",
      "epoch: 56  batch: 58  loss: 0.13603806\n",
      "epoch: 56  batch: 59  loss: 0.08952090\n",
      "epoch: 56  batch: 60  loss: 0.24783827\n",
      "epoch: 56  batch: 61  loss: 0.58853471\n",
      "epoch: 56  batch: 62  loss: 0.15577477\n",
      "epoch: 56  batch: 63  loss: 0.25882965\n",
      "epoch: 56  batch: 64  loss: 0.20130958\n",
      "epoch: 56  batch: 65  loss: 0.06434532\n",
      "epoch: 56  batch: 66  loss: 0.03742914\n",
      "epoch: 56  batch: 67  loss: 0.05453726\n",
      "epoch: 56  batch: 68  loss: 0.08570043\n",
      "epoch: 57  batch: 1  loss: 0.16255099\n",
      "epoch: 57  batch: 2  loss: 0.04737401\n",
      "epoch: 57  batch: 3  loss: 0.03476370\n",
      "epoch: 57  batch: 4  loss: 0.02811254\n",
      "epoch: 57  batch: 5  loss: 0.12767757\n",
      "epoch: 57  batch: 6  loss: 0.11056962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 57  batch: 7  loss: 0.22738534\n",
      "epoch: 57  batch: 8  loss: 0.11551113\n",
      "epoch: 57  batch: 9  loss: 0.19678207\n",
      "epoch: 57  batch: 10  loss: 0.22867402\n",
      "epoch: 57  batch: 11  loss: 0.32473236\n",
      "epoch: 57  batch: 12  loss: 0.17002687\n",
      "epoch: 57  batch: 13  loss: 0.11353704\n",
      "epoch: 57  batch: 14  loss: 0.13206932\n",
      "epoch: 57  batch: 15  loss: 0.11600323\n",
      "epoch: 57  batch: 16  loss: 0.08907874\n",
      "epoch: 57  batch: 17  loss: 0.13324906\n",
      "epoch: 57  batch: 18  loss: 0.05541839\n",
      "epoch: 57  batch: 19  loss: 0.07048003\n",
      "epoch: 57  batch: 20  loss: 0.28520715\n",
      "epoch: 57  batch: 21  loss: 0.34435424\n",
      "epoch: 57  batch: 22  loss: 0.11736147\n",
      "epoch: 57  batch: 23  loss: 0.05416487\n",
      "epoch: 57  batch: 24  loss: 0.06115513\n",
      "epoch: 57  batch: 25  loss: 0.06629146\n",
      "epoch: 57  batch: 26  loss: 0.15417489\n",
      "epoch: 57  batch: 27  loss: 0.44922626\n",
      "epoch: 57  batch: 28  loss: 0.14807965\n",
      "epoch: 57  batch: 29  loss: 0.15911084\n",
      "epoch: 57  batch: 30  loss: 0.10536675\n",
      "epoch: 57  batch: 31  loss: 0.05233342\n",
      "epoch: 57  batch: 32  loss: 0.01915387\n",
      "epoch: 57  batch: 33  loss: 0.03842378\n",
      "epoch: 57  batch: 34  loss: 0.08350562\n",
      "epoch: 57  batch: 35  loss: 0.17288344\n",
      "epoch: 57  batch: 36  loss: 0.03820239\n",
      "epoch: 57  batch: 37  loss: 0.03845531\n",
      "epoch: 57  batch: 38  loss: 0.04091299\n",
      "epoch: 57  batch: 39  loss: 0.17872708\n",
      "epoch: 57  batch: 40  loss: 0.07399201\n",
      "epoch: 57  batch: 41  loss: 0.20212984\n",
      "epoch: 57  batch: 42  loss: 0.15444474\n",
      "epoch: 57  batch: 43  loss: 0.15373190\n",
      "epoch: 57  batch: 44  loss: 0.25661916\n",
      "epoch: 57  batch: 45  loss: 0.33655876\n",
      "epoch: 57  batch: 46  loss: 0.17642134\n",
      "epoch: 57  batch: 47  loss: 0.19801609\n",
      "epoch: 57  batch: 48  loss: 0.12628768\n",
      "epoch: 57  batch: 49  loss: 0.12951453\n",
      "epoch: 57  batch: 50  loss: 0.16750976\n",
      "epoch: 57  batch: 51  loss: 0.11554195\n",
      "epoch: 57  batch: 52  loss: 0.06347957\n",
      "epoch: 57  batch: 53  loss: 0.08496241\n",
      "epoch: 57  batch: 54  loss: 0.38486820\n",
      "epoch: 57  batch: 55  loss: 0.24020742\n",
      "epoch: 57  batch: 56  loss: 0.08845450\n",
      "epoch: 57  batch: 57  loss: 0.04507947\n",
      "epoch: 57  batch: 58  loss: 0.13105270\n",
      "epoch: 57  batch: 59  loss: 0.08884113\n",
      "epoch: 57  batch: 60  loss: 0.22038552\n",
      "epoch: 57  batch: 61  loss: 0.61615688\n",
      "epoch: 57  batch: 62  loss: 0.15279850\n",
      "epoch: 57  batch: 63  loss: 0.20403519\n",
      "epoch: 57  batch: 64  loss: 0.11505920\n",
      "epoch: 57  batch: 65  loss: 0.04051337\n",
      "epoch: 57  batch: 66  loss: 0.03879127\n",
      "epoch: 57  batch: 67  loss: 0.05735254\n",
      "epoch: 57  batch: 68  loss: 0.08761750\n",
      "epoch: 58  batch: 1  loss: 0.16232757\n",
      "epoch: 58  batch: 2  loss: 0.04259796\n",
      "epoch: 58  batch: 3  loss: 0.03803753\n",
      "epoch: 58  batch: 4  loss: 0.02947753\n",
      "epoch: 58  batch: 5  loss: 0.13197884\n",
      "epoch: 58  batch: 6  loss: 0.12266742\n",
      "epoch: 58  batch: 7  loss: 0.22251940\n",
      "epoch: 58  batch: 8  loss: 0.13187148\n",
      "epoch: 58  batch: 9  loss: 0.26452819\n",
      "epoch: 58  batch: 10  loss: 0.22234841\n",
      "epoch: 58  batch: 11  loss: 0.41334373\n",
      "epoch: 58  batch: 12  loss: 0.17859730\n",
      "epoch: 58  batch: 13  loss: 0.09767426\n",
      "epoch: 58  batch: 14  loss: 0.13506599\n",
      "epoch: 58  batch: 15  loss: 0.11600433\n",
      "epoch: 58  batch: 16  loss: 0.08869103\n",
      "epoch: 58  batch: 17  loss: 0.13104713\n",
      "epoch: 58  batch: 18  loss: 0.05034732\n",
      "epoch: 58  batch: 19  loss: 0.05014926\n",
      "epoch: 58  batch: 20  loss: 0.29095760\n",
      "epoch: 58  batch: 21  loss: 0.34306479\n",
      "epoch: 58  batch: 22  loss: 0.11962819\n",
      "epoch: 58  batch: 23  loss: 0.04997212\n",
      "epoch: 58  batch: 24  loss: 0.05643775\n",
      "epoch: 58  batch: 25  loss: 0.06544328\n",
      "epoch: 58  batch: 26  loss: 0.13773671\n",
      "epoch: 58  batch: 27  loss: 0.46459004\n",
      "epoch: 58  batch: 28  loss: 0.14069043\n",
      "epoch: 58  batch: 29  loss: 0.17802091\n",
      "epoch: 58  batch: 30  loss: 0.12855680\n",
      "epoch: 58  batch: 31  loss: 0.05563789\n",
      "epoch: 58  batch: 32  loss: 0.01653538\n",
      "epoch: 58  batch: 33  loss: 0.04225759\n",
      "epoch: 58  batch: 34  loss: 0.08374920\n",
      "epoch: 58  batch: 35  loss: 0.16195089\n",
      "epoch: 58  batch: 36  loss: 0.03810944\n",
      "epoch: 58  batch: 37  loss: 0.03440069\n",
      "epoch: 58  batch: 38  loss: 0.03982628\n",
      "epoch: 58  batch: 39  loss: 0.17466110\n",
      "epoch: 58  batch: 40  loss: 0.07416262\n",
      "epoch: 58  batch: 41  loss: 0.19562769\n",
      "epoch: 58  batch: 42  loss: 0.14163706\n",
      "epoch: 58  batch: 43  loss: 0.14616111\n",
      "epoch: 58  batch: 44  loss: 0.20863125\n",
      "epoch: 58  batch: 45  loss: 0.32986024\n",
      "epoch: 58  batch: 46  loss: 0.18154368\n",
      "epoch: 58  batch: 47  loss: 0.16852745\n",
      "epoch: 58  batch: 48  loss: 0.12444706\n",
      "epoch: 58  batch: 49  loss: 0.13654839\n",
      "epoch: 58  batch: 50  loss: 0.17229494\n",
      "epoch: 58  batch: 51  loss: 0.11856677\n",
      "epoch: 58  batch: 52  loss: 0.06290820\n",
      "epoch: 58  batch: 53  loss: 0.06883327\n",
      "epoch: 58  batch: 54  loss: 0.38214251\n",
      "epoch: 58  batch: 55  loss: 0.23771191\n",
      "epoch: 58  batch: 56  loss: 0.10675164\n",
      "epoch: 58  batch: 57  loss: 0.04337690\n",
      "epoch: 58  batch: 58  loss: 0.11866120\n",
      "epoch: 58  batch: 59  loss: 0.09104325\n",
      "epoch: 58  batch: 60  loss: 0.21406820\n",
      "epoch: 58  batch: 61  loss: 0.54272425\n",
      "epoch: 58  batch: 62  loss: 0.14511901\n",
      "epoch: 58  batch: 63  loss: 0.18459210\n",
      "epoch: 58  batch: 64  loss: 0.13840620\n",
      "epoch: 58  batch: 65  loss: 0.05197078\n",
      "epoch: 58  batch: 66  loss: 0.03908930\n",
      "epoch: 58  batch: 67  loss: 0.04870861\n",
      "epoch: 58  batch: 68  loss: 0.09017512\n",
      "epoch: 59  batch: 1  loss: 0.16172244\n",
      "epoch: 59  batch: 2  loss: 0.04347714\n",
      "epoch: 59  batch: 3  loss: 0.04041627\n",
      "epoch: 59  batch: 4  loss: 0.02960188\n",
      "epoch: 59  batch: 5  loss: 0.13920081\n",
      "epoch: 59  batch: 6  loss: 0.11477663\n",
      "epoch: 59  batch: 7  loss: 0.22319984\n",
      "epoch: 59  batch: 8  loss: 0.13607135\n",
      "epoch: 59  batch: 9  loss: 0.25123799\n",
      "epoch: 59  batch: 10  loss: 0.21758239\n",
      "epoch: 59  batch: 11  loss: 0.39520690\n",
      "epoch: 59  batch: 12  loss: 0.16893668\n",
      "epoch: 59  batch: 13  loss: 0.09728012\n",
      "epoch: 59  batch: 14  loss: 0.13076745\n",
      "epoch: 59  batch: 15  loss: 0.11509708\n",
      "epoch: 59  batch: 16  loss: 0.08818860\n",
      "epoch: 59  batch: 17  loss: 0.13583130\n",
      "epoch: 59  batch: 18  loss: 0.05222249\n",
      "epoch: 59  batch: 19  loss: 0.05808325\n",
      "epoch: 59  batch: 20  loss: 0.28946722\n",
      "epoch: 59  batch: 21  loss: 0.34816793\n",
      "epoch: 59  batch: 22  loss: 0.09979586\n",
      "epoch: 59  batch: 23  loss: 0.05352706\n",
      "epoch: 59  batch: 24  loss: 0.05511932\n",
      "epoch: 59  batch: 25  loss: 0.06153006\n",
      "epoch: 59  batch: 26  loss: 0.12476890\n",
      "epoch: 59  batch: 27  loss: 0.47805342\n",
      "epoch: 59  batch: 28  loss: 0.18846372\n",
      "epoch: 59  batch: 29  loss: 0.17218605\n",
      "epoch: 59  batch: 30  loss: 0.11996271\n",
      "epoch: 59  batch: 31  loss: 0.05322217\n",
      "epoch: 59  batch: 32  loss: 0.01737473\n",
      "epoch: 59  batch: 33  loss: 0.03568078\n",
      "epoch: 59  batch: 34  loss: 0.08394022\n",
      "epoch: 59  batch: 35  loss: 0.16019869\n",
      "epoch: 59  batch: 36  loss: 0.03988484\n",
      "epoch: 59  batch: 37  loss: 0.03731022\n",
      "epoch: 59  batch: 38  loss: 0.04177230\n",
      "epoch: 59  batch: 39  loss: 0.16915627\n",
      "epoch: 59  batch: 40  loss: 0.07298902\n",
      "epoch: 59  batch: 41  loss: 0.19839033\n",
      "epoch: 59  batch: 42  loss: 0.14962888\n",
      "epoch: 59  batch: 43  loss: 0.15353037\n",
      "epoch: 59  batch: 44  loss: 0.20743202\n",
      "epoch: 59  batch: 45  loss: 0.32909197\n",
      "epoch: 59  batch: 46  loss: 0.16940454\n",
      "epoch: 59  batch: 47  loss: 0.18127191\n",
      "epoch: 59  batch: 48  loss: 0.12647854\n",
      "epoch: 59  batch: 49  loss: 0.12762298\n",
      "epoch: 59  batch: 50  loss: 0.16730396\n",
      "epoch: 59  batch: 51  loss: 0.11765575\n",
      "epoch: 59  batch: 52  loss: 0.06272520\n",
      "epoch: 59  batch: 53  loss: 0.06970309\n",
      "epoch: 59  batch: 54  loss: 0.38260528\n",
      "epoch: 59  batch: 55  loss: 0.23723887\n",
      "epoch: 59  batch: 56  loss: 0.10760829\n",
      "epoch: 59  batch: 57  loss: 0.04341764\n",
      "epoch: 59  batch: 58  loss: 0.11715544\n",
      "epoch: 59  batch: 59  loss: 0.09166607\n",
      "epoch: 59  batch: 60  loss: 0.20825379\n",
      "epoch: 59  batch: 61  loss: 0.53346074\n",
      "epoch: 59  batch: 62  loss: 0.13318288\n",
      "epoch: 59  batch: 63  loss: 0.21248712\n",
      "epoch: 59  batch: 64  loss: 0.12524110\n",
      "epoch: 59  batch: 65  loss: 0.04870725\n",
      "epoch: 59  batch: 66  loss: 0.04037260\n",
      "epoch: 59  batch: 67  loss: 0.04813811\n",
      "epoch: 59  batch: 68  loss: 0.08707163\n",
      "epoch: 60  batch: 1  loss: 0.16083315\n",
      "epoch: 60  batch: 2  loss: 0.04565241\n",
      "epoch: 60  batch: 3  loss: 0.03958860\n",
      "epoch: 60  batch: 4  loss: 0.02806426\n",
      "epoch: 60  batch: 5  loss: 0.13848753\n",
      "epoch: 60  batch: 6  loss: 0.10841583\n",
      "epoch: 60  batch: 7  loss: 0.22132577\n",
      "epoch: 60  batch: 8  loss: 0.13421366\n",
      "epoch: 60  batch: 9  loss: 0.24322690\n",
      "epoch: 60  batch: 10  loss: 0.21839939\n",
      "epoch: 60  batch: 11  loss: 0.41169283\n",
      "epoch: 60  batch: 12  loss: 0.16289246\n",
      "epoch: 60  batch: 13  loss: 0.09117355\n",
      "epoch: 60  batch: 14  loss: 0.13351086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60  batch: 15  loss: 0.11293702\n",
      "epoch: 60  batch: 16  loss: 0.08379826\n",
      "epoch: 60  batch: 17  loss: 0.13142604\n",
      "epoch: 60  batch: 18  loss: 0.05211737\n",
      "epoch: 60  batch: 19  loss: 0.07325823\n",
      "epoch: 60  batch: 20  loss: 0.28873363\n",
      "epoch: 60  batch: 21  loss: 0.34479839\n",
      "epoch: 60  batch: 22  loss: 0.12454271\n",
      "epoch: 60  batch: 23  loss: 0.05057454\n",
      "epoch: 60  batch: 24  loss: 0.05905658\n",
      "epoch: 60  batch: 25  loss: 0.06100250\n",
      "epoch: 60  batch: 26  loss: 0.15792765\n",
      "epoch: 60  batch: 27  loss: 0.43082666\n",
      "epoch: 60  batch: 28  loss: 0.16654225\n",
      "epoch: 60  batch: 29  loss: 0.16490415\n",
      "epoch: 60  batch: 30  loss: 0.12312919\n",
      "epoch: 60  batch: 31  loss: 0.05153004\n",
      "epoch: 60  batch: 32  loss: 0.01619896\n",
      "epoch: 60  batch: 33  loss: 0.03710027\n",
      "epoch: 60  batch: 34  loss: 0.08174568\n",
      "epoch: 60  batch: 35  loss: 0.15973575\n",
      "epoch: 60  batch: 36  loss: 0.04018617\n",
      "epoch: 60  batch: 37  loss: 0.03675773\n",
      "epoch: 60  batch: 38  loss: 0.04450500\n",
      "epoch: 60  batch: 39  loss: 0.17957340\n",
      "epoch: 60  batch: 40  loss: 0.08014370\n",
      "epoch: 60  batch: 41  loss: 0.19370376\n",
      "epoch: 60  batch: 42  loss: 0.13304268\n",
      "epoch: 60  batch: 43  loss: 0.13759851\n",
      "epoch: 60  batch: 44  loss: 0.20897707\n",
      "epoch: 60  batch: 45  loss: 0.32095727\n",
      "epoch: 60  batch: 46  loss: 0.17714731\n",
      "epoch: 60  batch: 47  loss: 0.16799664\n",
      "epoch: 60  batch: 48  loss: 0.13008203\n",
      "epoch: 60  batch: 49  loss: 0.12209606\n",
      "epoch: 60  batch: 50  loss: 0.15800993\n",
      "epoch: 60  batch: 51  loss: 0.11911394\n",
      "epoch: 60  batch: 52  loss: 0.06097500\n",
      "epoch: 60  batch: 53  loss: 0.07246841\n",
      "epoch: 60  batch: 54  loss: 0.38786787\n",
      "epoch: 60  batch: 55  loss: 0.23694442\n",
      "epoch: 60  batch: 56  loss: 0.10479952\n",
      "epoch: 60  batch: 57  loss: 0.04123187\n",
      "epoch: 60  batch: 58  loss: 0.11926161\n",
      "epoch: 60  batch: 59  loss: 0.09215245\n",
      "epoch: 60  batch: 60  loss: 0.21277320\n",
      "epoch: 60  batch: 61  loss: 0.57531369\n",
      "epoch: 60  batch: 62  loss: 0.12746467\n",
      "epoch: 60  batch: 63  loss: 0.21350765\n",
      "epoch: 60  batch: 64  loss: 0.14168100\n",
      "epoch: 60  batch: 65  loss: 0.03869468\n",
      "epoch: 60  batch: 66  loss: 0.04030537\n",
      "epoch: 60  batch: 67  loss: 0.04881038\n",
      "epoch: 60  batch: 68  loss: 0.09486889\n",
      "epoch: 61  batch: 1  loss: 0.16123505\n",
      "epoch: 61  batch: 2  loss: 0.04711020\n",
      "epoch: 61  batch: 3  loss: 0.04813240\n",
      "epoch: 61  batch: 4  loss: 0.02770008\n",
      "epoch: 61  batch: 5  loss: 0.13428439\n",
      "epoch: 61  batch: 6  loss: 0.11268492\n",
      "epoch: 61  batch: 7  loss: 0.22582814\n",
      "epoch: 61  batch: 8  loss: 0.15692270\n",
      "epoch: 61  batch: 9  loss: 0.18646739\n",
      "epoch: 61  batch: 10  loss: 0.24610613\n",
      "epoch: 61  batch: 11  loss: 0.42416421\n",
      "epoch: 61  batch: 12  loss: 0.18327174\n",
      "epoch: 61  batch: 13  loss: 0.10197341\n",
      "epoch: 61  batch: 14  loss: 0.13286608\n",
      "epoch: 61  batch: 15  loss: 0.12171379\n",
      "epoch: 61  batch: 16  loss: 0.07989188\n",
      "epoch: 61  batch: 17  loss: 0.14304006\n",
      "epoch: 61  batch: 18  loss: 0.05914498\n",
      "epoch: 61  batch: 19  loss: 0.07678303\n",
      "epoch: 61  batch: 20  loss: 0.28896424\n",
      "epoch: 61  batch: 21  loss: 0.34243041\n",
      "epoch: 61  batch: 22  loss: 0.11176807\n",
      "epoch: 61  batch: 23  loss: 0.05117632\n",
      "epoch: 61  batch: 24  loss: 0.06952552\n",
      "epoch: 61  batch: 25  loss: 0.05982759\n",
      "epoch: 61  batch: 26  loss: 0.14532785\n",
      "epoch: 61  batch: 27  loss: 0.40540078\n",
      "epoch: 61  batch: 28  loss: 0.13184373\n",
      "epoch: 61  batch: 29  loss: 0.15739235\n",
      "epoch: 61  batch: 30  loss: 0.12456973\n",
      "epoch: 61  batch: 31  loss: 0.04807898\n",
      "epoch: 61  batch: 32  loss: 0.01698963\n",
      "epoch: 61  batch: 33  loss: 0.02654666\n",
      "epoch: 61  batch: 34  loss: 0.09455700\n",
      "epoch: 61  batch: 35  loss: 0.15859830\n",
      "epoch: 61  batch: 36  loss: 0.03974357\n",
      "epoch: 61  batch: 37  loss: 0.03597452\n",
      "epoch: 61  batch: 38  loss: 0.04265351\n",
      "epoch: 61  batch: 39  loss: 0.17403659\n",
      "epoch: 61  batch: 40  loss: 0.07607520\n",
      "epoch: 61  batch: 41  loss: 0.19233187\n",
      "epoch: 61  batch: 42  loss: 0.14120413\n",
      "epoch: 61  batch: 43  loss: 0.13763438\n",
      "epoch: 61  batch: 44  loss: 0.20106612\n",
      "epoch: 61  batch: 45  loss: 0.31664625\n",
      "epoch: 61  batch: 46  loss: 0.16928893\n",
      "epoch: 61  batch: 47  loss: 0.17823623\n",
      "epoch: 61  batch: 48  loss: 0.12599938\n",
      "epoch: 61  batch: 49  loss: 0.11783471\n",
      "epoch: 61  batch: 50  loss: 0.16290469\n",
      "epoch: 61  batch: 51  loss: 0.11791994\n",
      "epoch: 61  batch: 52  loss: 0.06210041\n",
      "epoch: 61  batch: 53  loss: 0.06812196\n",
      "epoch: 61  batch: 54  loss: 0.38607281\n",
      "epoch: 61  batch: 55  loss: 0.23612086\n",
      "epoch: 61  batch: 56  loss: 0.11232343\n",
      "epoch: 61  batch: 57  loss: 0.04164007\n",
      "epoch: 61  batch: 58  loss: 0.11715675\n",
      "epoch: 61  batch: 59  loss: 0.09312080\n",
      "epoch: 61  batch: 60  loss: 0.18899645\n",
      "epoch: 61  batch: 61  loss: 0.50739926\n",
      "epoch: 61  batch: 62  loss: 0.12619174\n",
      "epoch: 61  batch: 63  loss: 0.19837329\n",
      "epoch: 61  batch: 64  loss: 0.10249561\n",
      "epoch: 61  batch: 65  loss: 0.04668402\n",
      "epoch: 61  batch: 66  loss: 0.04131817\n",
      "epoch: 61  batch: 67  loss: 0.05300505\n",
      "epoch: 61  batch: 68  loss: 0.08557548\n",
      "epoch: 62  batch: 1  loss: 0.16048467\n",
      "epoch: 62  batch: 2  loss: 0.04706316\n",
      "epoch: 62  batch: 3  loss: 0.03740476\n",
      "epoch: 62  batch: 4  loss: 0.02747212\n",
      "epoch: 62  batch: 5  loss: 0.12395316\n",
      "epoch: 62  batch: 6  loss: 0.10800143\n",
      "epoch: 62  batch: 7  loss: 0.22523478\n",
      "epoch: 62  batch: 8  loss: 0.11292221\n",
      "epoch: 62  batch: 9  loss: 0.27835912\n",
      "epoch: 62  batch: 10  loss: 0.21315138\n",
      "epoch: 62  batch: 11  loss: 0.38985533\n",
      "epoch: 62  batch: 12  loss: 0.16704880\n",
      "epoch: 62  batch: 13  loss: 0.09749699\n",
      "epoch: 62  batch: 14  loss: 0.13840334\n",
      "epoch: 62  batch: 15  loss: 0.12600943\n",
      "epoch: 62  batch: 16  loss: 0.07842898\n",
      "epoch: 62  batch: 17  loss: 0.11983193\n",
      "epoch: 62  batch: 18  loss: 0.05447546\n",
      "epoch: 62  batch: 19  loss: 0.06501579\n",
      "epoch: 62  batch: 20  loss: 0.30599269\n",
      "epoch: 62  batch: 21  loss: 0.34512833\n",
      "epoch: 62  batch: 22  loss: 0.11635712\n",
      "epoch: 62  batch: 23  loss: 0.05101967\n",
      "epoch: 62  batch: 24  loss: 0.06729913\n",
      "epoch: 62  batch: 25  loss: 0.05980521\n",
      "epoch: 62  batch: 26  loss: 0.16789159\n",
      "epoch: 62  batch: 27  loss: 0.43584850\n",
      "epoch: 62  batch: 28  loss: 0.15660222\n",
      "epoch: 62  batch: 29  loss: 0.15579094\n",
      "epoch: 62  batch: 30  loss: 0.09025967\n",
      "epoch: 62  batch: 31  loss: 0.04535641\n",
      "epoch: 62  batch: 32  loss: 0.01853969\n",
      "epoch: 62  batch: 33  loss: 0.03311836\n",
      "epoch: 62  batch: 34  loss: 0.07937527\n",
      "epoch: 62  batch: 35  loss: 0.15857926\n",
      "epoch: 62  batch: 36  loss: 0.04034223\n",
      "epoch: 62  batch: 37  loss: 0.03646253\n",
      "epoch: 62  batch: 38  loss: 0.04625008\n",
      "epoch: 62  batch: 39  loss: 0.16027781\n",
      "epoch: 62  batch: 40  loss: 0.10088493\n",
      "epoch: 62  batch: 41  loss: 0.18962830\n",
      "epoch: 62  batch: 42  loss: 0.12877148\n",
      "epoch: 62  batch: 43  loss: 0.12627657\n",
      "epoch: 62  batch: 44  loss: 0.22269920\n",
      "epoch: 62  batch: 45  loss: 0.31768459\n",
      "epoch: 62  batch: 46  loss: 0.17064701\n",
      "epoch: 62  batch: 47  loss: 0.13680895\n",
      "epoch: 62  batch: 48  loss: 0.12190562\n",
      "epoch: 62  batch: 49  loss: 0.11878780\n",
      "epoch: 62  batch: 50  loss: 0.15701056\n",
      "epoch: 62  batch: 51  loss: 0.11656306\n",
      "epoch: 62  batch: 52  loss: 0.06364328\n",
      "epoch: 62  batch: 53  loss: 0.06995240\n",
      "epoch: 62  batch: 54  loss: 0.39563912\n",
      "epoch: 62  batch: 55  loss: 0.23559450\n",
      "epoch: 62  batch: 56  loss: 0.09085700\n",
      "epoch: 62  batch: 57  loss: 0.04369999\n",
      "epoch: 62  batch: 58  loss: 0.11196657\n",
      "epoch: 62  batch: 59  loss: 0.09391456\n",
      "epoch: 62  batch: 60  loss: 0.19053397\n",
      "epoch: 62  batch: 61  loss: 0.51261735\n",
      "epoch: 62  batch: 62  loss: 0.12686838\n",
      "epoch: 62  batch: 63  loss: 0.19703463\n",
      "epoch: 62  batch: 64  loss: 0.10553496\n",
      "epoch: 62  batch: 65  loss: 0.05221393\n",
      "epoch: 62  batch: 66  loss: 0.04241526\n",
      "epoch: 62  batch: 67  loss: 0.05277279\n",
      "epoch: 62  batch: 68  loss: 0.08678770\n",
      "epoch: 63  batch: 1  loss: 0.16751771\n",
      "epoch: 63  batch: 2  loss: 0.04688997\n",
      "epoch: 63  batch: 3  loss: 0.03846515\n",
      "epoch: 63  batch: 4  loss: 0.02742002\n",
      "epoch: 63  batch: 5  loss: 0.12452804\n",
      "epoch: 63  batch: 6  loss: 0.09901924\n",
      "epoch: 63  batch: 7  loss: 0.22147493\n",
      "epoch: 63  batch: 8  loss: 0.12064622\n",
      "epoch: 63  batch: 9  loss: 0.20729388\n",
      "epoch: 63  batch: 10  loss: 0.21524344\n",
      "epoch: 63  batch: 11  loss: 0.40546358\n",
      "epoch: 63  batch: 12  loss: 0.18095182\n",
      "epoch: 63  batch: 13  loss: 0.07704619\n",
      "epoch: 63  batch: 14  loss: 0.13229097\n",
      "epoch: 63  batch: 15  loss: 0.11100756\n",
      "epoch: 63  batch: 16  loss: 0.07354932\n",
      "epoch: 63  batch: 17  loss: 0.11454406\n",
      "epoch: 63  batch: 18  loss: 0.05203053\n",
      "epoch: 63  batch: 19  loss: 0.06224930\n",
      "epoch: 63  batch: 20  loss: 0.29498440\n",
      "epoch: 63  batch: 21  loss: 0.34631068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 63  batch: 22  loss: 0.11582721\n",
      "epoch: 63  batch: 23  loss: 0.05090778\n",
      "epoch: 63  batch: 24  loss: 0.06546129\n",
      "epoch: 63  batch: 25  loss: 0.05992648\n",
      "epoch: 63  batch: 26  loss: 0.09517952\n",
      "epoch: 63  batch: 27  loss: 0.40888113\n",
      "epoch: 63  batch: 28  loss: 0.16364568\n",
      "epoch: 63  batch: 29  loss: 0.10928595\n",
      "epoch: 63  batch: 30  loss: 0.08998436\n",
      "epoch: 63  batch: 31  loss: 0.04592913\n",
      "epoch: 63  batch: 32  loss: 0.01846929\n",
      "epoch: 63  batch: 33  loss: 0.03285476\n",
      "epoch: 63  batch: 34  loss: 0.09405931\n",
      "epoch: 63  batch: 35  loss: 0.15621169\n",
      "epoch: 63  batch: 36  loss: 0.03897976\n",
      "epoch: 63  batch: 37  loss: 0.03496760\n",
      "epoch: 63  batch: 38  loss: 0.04402227\n",
      "epoch: 63  batch: 39  loss: 0.17646740\n",
      "epoch: 63  batch: 40  loss: 0.07188139\n",
      "epoch: 63  batch: 41  loss: 0.18640541\n",
      "epoch: 63  batch: 42  loss: 0.13174434\n",
      "epoch: 63  batch: 43  loss: 0.12949868\n",
      "epoch: 63  batch: 44  loss: 0.20069654\n",
      "epoch: 63  batch: 45  loss: 0.31163242\n",
      "epoch: 63  batch: 46  loss: 0.15120126\n",
      "epoch: 63  batch: 47  loss: 0.15237775\n",
      "epoch: 63  batch: 48  loss: 0.12417579\n",
      "epoch: 63  batch: 49  loss: 0.11706582\n",
      "epoch: 63  batch: 50  loss: 0.17599387\n",
      "epoch: 63  batch: 51  loss: 0.12135157\n",
      "epoch: 63  batch: 52  loss: 0.06606334\n",
      "epoch: 63  batch: 53  loss: 0.07086451\n",
      "epoch: 63  batch: 54  loss: 0.38410011\n",
      "epoch: 63  batch: 55  loss: 0.23593526\n",
      "epoch: 63  batch: 56  loss: 0.11450047\n",
      "epoch: 63  batch: 57  loss: 0.04152115\n",
      "epoch: 63  batch: 58  loss: 0.11382599\n",
      "epoch: 63  batch: 59  loss: 0.09681509\n",
      "epoch: 63  batch: 60  loss: 0.18054716\n",
      "epoch: 63  batch: 61  loss: 0.50036091\n",
      "epoch: 63  batch: 62  loss: 0.12234882\n",
      "epoch: 63  batch: 63  loss: 0.25937423\n",
      "epoch: 63  batch: 64  loss: 0.11562312\n",
      "epoch: 63  batch: 65  loss: 0.04365485\n",
      "epoch: 63  batch: 66  loss: 0.04293014\n",
      "epoch: 63  batch: 67  loss: 0.05252381\n",
      "epoch: 63  batch: 68  loss: 0.08372821\n",
      "epoch: 64  batch: 1  loss: 0.16087210\n",
      "epoch: 64  batch: 2  loss: 0.05731796\n",
      "epoch: 64  batch: 3  loss: 0.04021573\n",
      "epoch: 64  batch: 4  loss: 0.03000236\n",
      "epoch: 64  batch: 5  loss: 0.15443657\n",
      "epoch: 64  batch: 6  loss: 0.12525538\n",
      "epoch: 64  batch: 7  loss: 0.21035822\n",
      "epoch: 64  batch: 8  loss: 0.11614455\n",
      "epoch: 64  batch: 9  loss: 0.24918243\n",
      "epoch: 64  batch: 10  loss: 0.20635970\n",
      "epoch: 64  batch: 11  loss: 0.40315950\n",
      "epoch: 64  batch: 12  loss: 0.17085823\n",
      "epoch: 64  batch: 13  loss: 0.07147238\n",
      "epoch: 64  batch: 14  loss: 0.13421848\n",
      "epoch: 64  batch: 15  loss: 0.11287180\n",
      "epoch: 64  batch: 16  loss: 0.06277561\n",
      "epoch: 64  batch: 17  loss: 0.10944214\n",
      "epoch: 64  batch: 18  loss: 0.05902122\n",
      "epoch: 64  batch: 19  loss: 0.06684041\n",
      "epoch: 64  batch: 20  loss: 0.29139563\n",
      "epoch: 64  batch: 21  loss: 0.33664718\n",
      "epoch: 64  batch: 22  loss: 0.10853142\n",
      "epoch: 64  batch: 23  loss: 0.05095264\n",
      "epoch: 64  batch: 24  loss: 0.06789035\n",
      "epoch: 64  batch: 25  loss: 0.05896635\n",
      "epoch: 64  batch: 26  loss: 0.08546020\n",
      "epoch: 64  batch: 27  loss: 0.34979740\n",
      "epoch: 64  batch: 28  loss: 0.14940022\n",
      "epoch: 64  batch: 29  loss: 0.12765050\n",
      "epoch: 64  batch: 30  loss: 0.06886014\n",
      "epoch: 64  batch: 31  loss: 0.04368285\n",
      "epoch: 64  batch: 32  loss: 0.02046224\n",
      "epoch: 64  batch: 33  loss: 0.02496682\n",
      "epoch: 64  batch: 34  loss: 0.09571479\n",
      "epoch: 64  batch: 35  loss: 0.15427691\n",
      "epoch: 64  batch: 36  loss: 0.04094665\n",
      "epoch: 64  batch: 37  loss: 0.03688916\n",
      "epoch: 64  batch: 38  loss: 0.04477550\n",
      "epoch: 64  batch: 39  loss: 0.15699510\n",
      "epoch: 64  batch: 40  loss: 0.07169956\n",
      "epoch: 64  batch: 41  loss: 0.18498260\n",
      "epoch: 64  batch: 42  loss: 0.12233245\n",
      "epoch: 64  batch: 43  loss: 0.11982500\n",
      "epoch: 64  batch: 44  loss: 0.21621472\n",
      "epoch: 64  batch: 45  loss: 0.30436873\n",
      "epoch: 64  batch: 46  loss: 0.15681252\n",
      "epoch: 64  batch: 47  loss: 0.15542926\n",
      "epoch: 64  batch: 48  loss: 0.11885603\n",
      "epoch: 64  batch: 49  loss: 0.11787979\n",
      "epoch: 64  batch: 50  loss: 0.17876811\n",
      "epoch: 64  batch: 51  loss: 0.11596166\n",
      "epoch: 64  batch: 52  loss: 0.06431324\n",
      "epoch: 64  batch: 53  loss: 0.07664166\n",
      "epoch: 64  batch: 54  loss: 0.38668031\n",
      "epoch: 64  batch: 55  loss: 0.23497650\n",
      "epoch: 64  batch: 56  loss: 0.11773852\n",
      "epoch: 64  batch: 57  loss: 0.04162280\n",
      "epoch: 64  batch: 58  loss: 0.10674267\n",
      "epoch: 64  batch: 59  loss: 0.09956377\n",
      "epoch: 64  batch: 60  loss: 0.15472052\n",
      "epoch: 64  batch: 61  loss: 0.44553110\n",
      "epoch: 64  batch: 62  loss: 0.10346235\n",
      "epoch: 64  batch: 63  loss: 0.18123321\n",
      "epoch: 64  batch: 64  loss: 0.07616394\n",
      "epoch: 64  batch: 65  loss: 0.05937480\n",
      "epoch: 64  batch: 66  loss: 0.04562315\n",
      "epoch: 64  batch: 67  loss: 0.04863353\n",
      "epoch: 64  batch: 68  loss: 0.08302190\n",
      "epoch: 65  batch: 1  loss: 0.16016622\n",
      "epoch: 65  batch: 2  loss: 0.05965208\n",
      "epoch: 65  batch: 3  loss: 0.03168660\n",
      "epoch: 65  batch: 4  loss: 0.02819157\n",
      "epoch: 65  batch: 5  loss: 0.15372176\n",
      "epoch: 65  batch: 6  loss: 0.09052370\n",
      "epoch: 65  batch: 7  loss: 0.21134748\n",
      "epoch: 65  batch: 8  loss: 0.13680165\n",
      "epoch: 65  batch: 9  loss: 0.24687958\n",
      "epoch: 65  batch: 10  loss: 0.26952603\n",
      "epoch: 65  batch: 11  loss: 0.34286335\n",
      "epoch: 65  batch: 12  loss: 0.17097466\n",
      "epoch: 65  batch: 13  loss: 0.06216056\n",
      "epoch: 65  batch: 14  loss: 0.14800303\n",
      "epoch: 65  batch: 15  loss: 0.17850538\n",
      "epoch: 65  batch: 16  loss: 0.07081994\n",
      "epoch: 65  batch: 17  loss: 0.12496307\n",
      "epoch: 65  batch: 18  loss: 0.05306669\n",
      "epoch: 65  batch: 19  loss: 0.08115341\n",
      "epoch: 65  batch: 20  loss: 0.32650858\n",
      "epoch: 65  batch: 21  loss: 0.34395638\n",
      "epoch: 65  batch: 22  loss: 0.08973004\n",
      "epoch: 65  batch: 23  loss: 0.04940708\n",
      "epoch: 65  batch: 24  loss: 0.06931809\n",
      "epoch: 65  batch: 25  loss: 0.05732708\n",
      "epoch: 65  batch: 26  loss: 0.12136918\n",
      "epoch: 65  batch: 27  loss: 0.36985695\n",
      "epoch: 65  batch: 28  loss: 0.11729892\n",
      "epoch: 65  batch: 29  loss: 0.14334764\n",
      "epoch: 65  batch: 30  loss: 0.11226478\n",
      "epoch: 65  batch: 31  loss: 0.04101209\n",
      "epoch: 65  batch: 32  loss: 0.01654718\n",
      "epoch: 65  batch: 33  loss: 0.02437259\n",
      "epoch: 65  batch: 34  loss: 0.07798229\n",
      "epoch: 65  batch: 35  loss: 0.15319827\n",
      "epoch: 65  batch: 36  loss: 0.04176613\n",
      "epoch: 65  batch: 37  loss: 0.03568249\n",
      "epoch: 65  batch: 38  loss: 0.04536134\n",
      "epoch: 65  batch: 39  loss: 0.14920649\n",
      "epoch: 65  batch: 40  loss: 0.11924801\n",
      "epoch: 65  batch: 41  loss: 0.18110979\n",
      "epoch: 65  batch: 42  loss: 0.11809441\n",
      "epoch: 65  batch: 43  loss: 0.11212640\n",
      "epoch: 65  batch: 44  loss: 0.19614455\n",
      "epoch: 65  batch: 45  loss: 0.28749421\n",
      "epoch: 65  batch: 46  loss: 0.15206221\n",
      "epoch: 65  batch: 47  loss: 0.17299215\n",
      "epoch: 65  batch: 48  loss: 0.13603026\n",
      "epoch: 65  batch: 49  loss: 0.13827085\n",
      "epoch: 65  batch: 50  loss: 0.15341143\n",
      "epoch: 65  batch: 51  loss: 0.12540409\n",
      "epoch: 65  batch: 52  loss: 0.06622266\n",
      "epoch: 65  batch: 53  loss: 0.07604779\n",
      "epoch: 65  batch: 54  loss: 0.40594441\n",
      "epoch: 65  batch: 55  loss: 0.23153704\n",
      "epoch: 65  batch: 56  loss: 0.08239563\n",
      "epoch: 65  batch: 57  loss: 0.05517421\n",
      "epoch: 65  batch: 58  loss: 0.10365716\n",
      "epoch: 65  batch: 59  loss: 0.09498294\n",
      "epoch: 65  batch: 60  loss: 0.15892944\n",
      "epoch: 65  batch: 61  loss: 0.46811923\n",
      "epoch: 65  batch: 62  loss: 0.15083082\n",
      "epoch: 65  batch: 63  loss: 0.24361463\n",
      "epoch: 65  batch: 64  loss: 0.09636530\n",
      "epoch: 65  batch: 65  loss: 0.04487183\n",
      "epoch: 65  batch: 66  loss: 0.04222349\n",
      "epoch: 65  batch: 67  loss: 0.05361071\n",
      "epoch: 65  batch: 68  loss: 0.08796774\n",
      "epoch: 66  batch: 1  loss: 0.15634340\n",
      "epoch: 66  batch: 2  loss: 0.05077673\n",
      "epoch: 66  batch: 3  loss: 0.03423709\n",
      "epoch: 66  batch: 4  loss: 0.02830093\n",
      "epoch: 66  batch: 5  loss: 0.12493565\n",
      "epoch: 66  batch: 6  loss: 0.14470005\n",
      "epoch: 66  batch: 7  loss: 0.23153344\n",
      "epoch: 66  batch: 8  loss: 0.17104118\n",
      "epoch: 66  batch: 9  loss: 0.15984832\n",
      "epoch: 66  batch: 10  loss: 0.48069841\n",
      "epoch: 66  batch: 11  loss: 0.40782195\n",
      "epoch: 66  batch: 12  loss: 0.19807613\n",
      "epoch: 66  batch: 13  loss: 0.08296288\n",
      "epoch: 66  batch: 14  loss: 0.13970514\n",
      "epoch: 66  batch: 15  loss: 0.11813857\n",
      "epoch: 66  batch: 16  loss: 0.05651375\n",
      "epoch: 66  batch: 17  loss: 0.11634233\n",
      "epoch: 66  batch: 18  loss: 0.06559144\n",
      "epoch: 66  batch: 19  loss: 0.08494278\n",
      "epoch: 66  batch: 20  loss: 0.28044039\n",
      "epoch: 66  batch: 21  loss: 0.32991698\n",
      "epoch: 66  batch: 22  loss: 0.08986922\n",
      "epoch: 66  batch: 23  loss: 0.05927019\n",
      "epoch: 66  batch: 24  loss: 0.07400911\n",
      "epoch: 66  batch: 25  loss: 0.06211603\n",
      "epoch: 66  batch: 26  loss: 0.12909687\n",
      "epoch: 66  batch: 27  loss: 0.40440425\n",
      "epoch: 66  batch: 28  loss: 0.19094270\n",
      "epoch: 66  batch: 29  loss: 0.17805997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 66  batch: 30  loss: 0.04580212\n",
      "epoch: 66  batch: 31  loss: 0.04082143\n",
      "epoch: 66  batch: 32  loss: 0.02251836\n",
      "epoch: 66  batch: 33  loss: 0.03084210\n",
      "epoch: 66  batch: 34  loss: 0.07520740\n",
      "epoch: 66  batch: 35  loss: 0.16298091\n",
      "epoch: 66  batch: 36  loss: 0.03860517\n",
      "epoch: 66  batch: 37  loss: 0.04349544\n",
      "epoch: 66  batch: 38  loss: 0.03976844\n",
      "epoch: 66  batch: 39  loss: 0.15904675\n",
      "epoch: 66  batch: 40  loss: 0.06816587\n",
      "epoch: 66  batch: 41  loss: 0.17813575\n",
      "epoch: 66  batch: 42  loss: 0.09893590\n",
      "epoch: 66  batch: 43  loss: 0.12617302\n",
      "epoch: 66  batch: 44  loss: 0.21964788\n",
      "epoch: 66  batch: 45  loss: 0.28783247\n",
      "epoch: 66  batch: 46  loss: 0.15970446\n",
      "epoch: 66  batch: 47  loss: 0.11342371\n",
      "epoch: 66  batch: 48  loss: 0.13399492\n",
      "epoch: 66  batch: 49  loss: 0.13601685\n",
      "epoch: 66  batch: 50  loss: 0.14188576\n",
      "epoch: 66  batch: 51  loss: 0.17850846\n",
      "epoch: 66  batch: 52  loss: 0.08620381\n",
      "epoch: 66  batch: 53  loss: 0.08678737\n",
      "epoch: 66  batch: 54  loss: 0.39833570\n",
      "epoch: 66  batch: 55  loss: 0.23140599\n",
      "epoch: 66  batch: 56  loss: 0.10313174\n",
      "epoch: 66  batch: 57  loss: 0.04202642\n",
      "epoch: 66  batch: 58  loss: 0.10940985\n",
      "epoch: 66  batch: 59  loss: 0.09609014\n",
      "epoch: 66  batch: 60  loss: 0.15611726\n",
      "epoch: 66  batch: 61  loss: 0.58273953\n",
      "epoch: 66  batch: 62  loss: 0.12391716\n",
      "epoch: 66  batch: 63  loss: 0.17957029\n",
      "epoch: 66  batch: 64  loss: 0.08313555\n",
      "epoch: 66  batch: 65  loss: 0.05668953\n",
      "epoch: 66  batch: 66  loss: 0.03750584\n",
      "epoch: 66  batch: 67  loss: 0.06149741\n",
      "epoch: 66  batch: 68  loss: 0.08960544\n",
      "epoch: 67  batch: 1  loss: 0.15204515\n",
      "epoch: 67  batch: 2  loss: 0.04836904\n",
      "epoch: 67  batch: 3  loss: 0.03945573\n",
      "epoch: 67  batch: 4  loss: 0.02809138\n",
      "epoch: 67  batch: 5  loss: 0.11232411\n",
      "epoch: 67  batch: 6  loss: 0.08816455\n",
      "epoch: 67  batch: 7  loss: 0.21919391\n",
      "epoch: 67  batch: 8  loss: 0.14294699\n",
      "epoch: 67  batch: 9  loss: 0.21457179\n",
      "epoch: 67  batch: 10  loss: 0.38191825\n",
      "epoch: 67  batch: 11  loss: 0.26279637\n",
      "epoch: 67  batch: 12  loss: 0.16037180\n",
      "epoch: 67  batch: 13  loss: 0.06360295\n",
      "epoch: 67  batch: 14  loss: 0.14370294\n",
      "epoch: 67  batch: 15  loss: 0.12609179\n",
      "epoch: 67  batch: 16  loss: 0.05382847\n",
      "epoch: 67  batch: 17  loss: 0.13938227\n",
      "epoch: 67  batch: 18  loss: 0.05894144\n",
      "epoch: 67  batch: 19  loss: 0.05564709\n",
      "epoch: 67  batch: 20  loss: 0.38184717\n",
      "epoch: 67  batch: 21  loss: 0.32881567\n",
      "epoch: 67  batch: 22  loss: 0.14249495\n",
      "epoch: 67  batch: 23  loss: 0.05217637\n",
      "epoch: 67  batch: 24  loss: 0.06260100\n",
      "epoch: 67  batch: 25  loss: 0.06166447\n",
      "epoch: 67  batch: 26  loss: 0.16742113\n",
      "epoch: 67  batch: 27  loss: 0.42416763\n",
      "epoch: 67  batch: 28  loss: 0.29119021\n",
      "epoch: 67  batch: 29  loss: 0.16749635\n",
      "epoch: 67  batch: 30  loss: 0.18959627\n",
      "epoch: 67  batch: 31  loss: 0.05633640\n",
      "epoch: 67  batch: 32  loss: 0.04295374\n",
      "epoch: 67  batch: 33  loss: 0.04118455\n",
      "epoch: 67  batch: 34  loss: 0.07764282\n",
      "epoch: 67  batch: 35  loss: 0.15391375\n",
      "epoch: 67  batch: 36  loss: 0.03976398\n",
      "epoch: 67  batch: 37  loss: 0.04334919\n",
      "epoch: 67  batch: 38  loss: 0.04912908\n",
      "epoch: 67  batch: 39  loss: 0.15320359\n",
      "epoch: 67  batch: 40  loss: 0.07688555\n",
      "epoch: 67  batch: 41  loss: 0.17550346\n",
      "epoch: 67  batch: 42  loss: 0.10514558\n",
      "epoch: 67  batch: 43  loss: 0.11860070\n",
      "epoch: 67  batch: 44  loss: 0.19263986\n",
      "epoch: 67  batch: 45  loss: 0.28453436\n",
      "epoch: 67  batch: 46  loss: 0.15133327\n",
      "epoch: 67  batch: 47  loss: 0.20833576\n",
      "epoch: 67  batch: 48  loss: 0.14148664\n",
      "epoch: 67  batch: 49  loss: 0.12663755\n",
      "epoch: 67  batch: 50  loss: 0.11728866\n",
      "epoch: 67  batch: 51  loss: 0.13604333\n",
      "epoch: 67  batch: 52  loss: 0.08495804\n",
      "epoch: 67  batch: 53  loss: 0.07463834\n",
      "epoch: 67  batch: 54  loss: 0.39617917\n",
      "epoch: 67  batch: 55  loss: 0.22752886\n",
      "epoch: 67  batch: 56  loss: 0.07570591\n",
      "epoch: 67  batch: 57  loss: 0.03940997\n",
      "epoch: 67  batch: 58  loss: 0.14165811\n",
      "epoch: 67  batch: 59  loss: 0.09613888\n",
      "epoch: 67  batch: 60  loss: 0.13722903\n",
      "epoch: 67  batch: 61  loss: 0.53515923\n",
      "epoch: 67  batch: 62  loss: 0.16219902\n",
      "epoch: 67  batch: 63  loss: 0.28162196\n",
      "epoch: 67  batch: 64  loss: 0.07537543\n",
      "epoch: 67  batch: 65  loss: 0.04554187\n",
      "epoch: 67  batch: 66  loss: 0.03949520\n",
      "epoch: 67  batch: 67  loss: 0.03691883\n",
      "epoch: 67  batch: 68  loss: 0.06584145\n",
      "epoch: 68  batch: 1  loss: 0.15403329\n",
      "epoch: 68  batch: 2  loss: 0.04625878\n",
      "epoch: 68  batch: 3  loss: 0.03681437\n",
      "epoch: 68  batch: 4  loss: 0.02936715\n",
      "epoch: 68  batch: 5  loss: 0.10861512\n",
      "epoch: 68  batch: 6  loss: 0.09086864\n",
      "epoch: 68  batch: 7  loss: 0.25811061\n",
      "epoch: 68  batch: 8  loss: 0.18084823\n",
      "epoch: 68  batch: 9  loss: 0.21301669\n",
      "epoch: 68  batch: 10  loss: 0.37268466\n",
      "epoch: 68  batch: 11  loss: 0.24090649\n",
      "epoch: 68  batch: 12  loss: 0.16090627\n",
      "epoch: 68  batch: 13  loss: 0.07994577\n",
      "epoch: 68  batch: 14  loss: 0.14005272\n",
      "epoch: 68  batch: 15  loss: 0.12954000\n",
      "epoch: 68  batch: 16  loss: 0.05712251\n",
      "epoch: 68  batch: 17  loss: 0.10127526\n",
      "epoch: 68  batch: 18  loss: 0.06813867\n",
      "epoch: 68  batch: 19  loss: 0.05325893\n",
      "epoch: 68  batch: 20  loss: 0.36959282\n",
      "epoch: 68  batch: 21  loss: 0.32242590\n",
      "epoch: 68  batch: 22  loss: 0.13215090\n",
      "epoch: 68  batch: 23  loss: 0.05115317\n",
      "epoch: 68  batch: 24  loss: 0.06341889\n",
      "epoch: 68  batch: 25  loss: 0.06301210\n",
      "epoch: 68  batch: 26  loss: 0.11412038\n",
      "epoch: 68  batch: 27  loss: 0.39275709\n",
      "epoch: 68  batch: 28  loss: 0.16391692\n",
      "epoch: 68  batch: 29  loss: 0.14979225\n",
      "epoch: 68  batch: 30  loss: 0.06877153\n",
      "epoch: 68  batch: 31  loss: 0.03500868\n",
      "epoch: 68  batch: 32  loss: 0.05881446\n",
      "epoch: 68  batch: 33  loss: 0.04194316\n",
      "epoch: 68  batch: 34  loss: 0.07343027\n",
      "epoch: 68  batch: 35  loss: 0.15010884\n",
      "epoch: 68  batch: 36  loss: 0.04182991\n",
      "epoch: 68  batch: 37  loss: 0.03653384\n",
      "epoch: 68  batch: 38  loss: 0.05844554\n",
      "epoch: 68  batch: 39  loss: 0.14703982\n",
      "epoch: 68  batch: 40  loss: 0.06939210\n",
      "epoch: 68  batch: 41  loss: 0.17725001\n",
      "epoch: 68  batch: 42  loss: 0.13516404\n",
      "epoch: 68  batch: 43  loss: 0.11714997\n",
      "epoch: 68  batch: 44  loss: 0.18665247\n",
      "epoch: 68  batch: 45  loss: 0.27758929\n",
      "epoch: 68  batch: 46  loss: 0.14532371\n",
      "epoch: 68  batch: 47  loss: 0.14697573\n",
      "epoch: 68  batch: 48  loss: 0.13584937\n",
      "epoch: 68  batch: 49  loss: 0.12658827\n",
      "epoch: 68  batch: 50  loss: 0.12292483\n",
      "epoch: 68  batch: 51  loss: 0.09455957\n",
      "epoch: 68  batch: 52  loss: 0.07829730\n",
      "epoch: 68  batch: 53  loss: 0.07456647\n",
      "epoch: 68  batch: 54  loss: 0.45888710\n",
      "epoch: 68  batch: 55  loss: 0.22561936\n",
      "epoch: 68  batch: 56  loss: 0.07531635\n",
      "epoch: 68  batch: 57  loss: 0.04056774\n",
      "epoch: 68  batch: 58  loss: 0.14066257\n",
      "epoch: 68  batch: 59  loss: 0.09902196\n",
      "epoch: 68  batch: 60  loss: 0.12233285\n",
      "epoch: 68  batch: 61  loss: 0.49401271\n",
      "epoch: 68  batch: 62  loss: 0.11247642\n",
      "epoch: 68  batch: 63  loss: 0.16332074\n",
      "epoch: 68  batch: 64  loss: 0.08204831\n",
      "epoch: 68  batch: 65  loss: 0.03597988\n",
      "epoch: 68  batch: 66  loss: 0.03968698\n",
      "epoch: 68  batch: 67  loss: 0.07460497\n",
      "epoch: 68  batch: 68  loss: 0.08259487\n",
      "epoch: 69  batch: 1  loss: 0.15385601\n",
      "epoch: 69  batch: 2  loss: 0.06067405\n",
      "epoch: 69  batch: 3  loss: 0.03750467\n",
      "epoch: 69  batch: 4  loss: 0.02912509\n",
      "epoch: 69  batch: 5  loss: 0.10960132\n",
      "epoch: 69  batch: 6  loss: 0.10359030\n",
      "epoch: 69  batch: 7  loss: 0.21163478\n",
      "epoch: 69  batch: 8  loss: 0.09844580\n",
      "epoch: 69  batch: 9  loss: 0.22624436\n",
      "epoch: 69  batch: 10  loss: 0.33539689\n",
      "epoch: 69  batch: 11  loss: 0.27522093\n",
      "epoch: 69  batch: 12  loss: 0.18891098\n",
      "epoch: 69  batch: 13  loss: 0.04901814\n",
      "epoch: 69  batch: 14  loss: 0.14728068\n",
      "epoch: 69  batch: 15  loss: 0.13137773\n",
      "epoch: 69  batch: 16  loss: 0.05687419\n",
      "epoch: 69  batch: 17  loss: 0.10279251\n",
      "epoch: 69  batch: 18  loss: 0.07538479\n",
      "epoch: 69  batch: 19  loss: 0.07355368\n",
      "epoch: 69  batch: 20  loss: 0.32027471\n",
      "epoch: 69  batch: 21  loss: 0.32061332\n",
      "epoch: 69  batch: 22  loss: 0.10948014\n",
      "epoch: 69  batch: 23  loss: 0.04952203\n",
      "epoch: 69  batch: 24  loss: 0.07270037\n",
      "epoch: 69  batch: 25  loss: 0.06095292\n",
      "epoch: 69  batch: 26  loss: 0.06760900\n",
      "epoch: 69  batch: 27  loss: 0.28218657\n",
      "epoch: 69  batch: 28  loss: 0.10763367\n",
      "epoch: 69  batch: 29  loss: 0.13044226\n",
      "epoch: 69  batch: 30  loss: 0.05095734\n",
      "epoch: 69  batch: 31  loss: 0.02984085\n",
      "epoch: 69  batch: 32  loss: 0.02470414\n",
      "epoch: 69  batch: 33  loss: 0.02103302\n",
      "epoch: 69  batch: 34  loss: 0.09802788\n",
      "epoch: 69  batch: 35  loss: 0.14717436\n",
      "epoch: 69  batch: 36  loss: 0.04195790\n",
      "epoch: 69  batch: 37  loss: 0.03964424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69  batch: 38  loss: 0.03982551\n",
      "epoch: 69  batch: 39  loss: 0.14218093\n",
      "epoch: 69  batch: 40  loss: 0.15977243\n",
      "epoch: 69  batch: 41  loss: 0.17310619\n",
      "epoch: 69  batch: 42  loss: 0.10819174\n",
      "epoch: 69  batch: 43  loss: 0.14285366\n",
      "epoch: 69  batch: 44  loss: 0.18777187\n",
      "epoch: 69  batch: 45  loss: 0.56718194\n",
      "epoch: 69  batch: 46  loss: 0.21143113\n",
      "epoch: 69  batch: 47  loss: 0.20102629\n",
      "epoch: 69  batch: 48  loss: 0.13408858\n",
      "epoch: 69  batch: 49  loss: 0.13653193\n",
      "epoch: 69  batch: 50  loss: 0.09835241\n",
      "epoch: 69  batch: 51  loss: 0.10003433\n",
      "epoch: 69  batch: 52  loss: 0.06533120\n",
      "epoch: 69  batch: 53  loss: 0.07013458\n",
      "epoch: 69  batch: 54  loss: 0.34792086\n",
      "epoch: 69  batch: 55  loss: 0.22533093\n",
      "epoch: 69  batch: 56  loss: 0.12464350\n",
      "epoch: 69  batch: 57  loss: 0.05445012\n",
      "epoch: 69  batch: 58  loss: 0.11036495\n",
      "epoch: 69  batch: 59  loss: 0.10633201\n",
      "epoch: 69  batch: 60  loss: 0.16541605\n",
      "epoch: 69  batch: 61  loss: 0.72489369\n",
      "epoch: 69  batch: 62  loss: 0.23477401\n",
      "epoch: 69  batch: 63  loss: 0.22804290\n",
      "epoch: 69  batch: 64  loss: 0.24571534\n",
      "epoch: 69  batch: 65  loss: 0.11048396\n",
      "epoch: 69  batch: 66  loss: 0.03629911\n",
      "epoch: 69  batch: 67  loss: 0.05877280\n",
      "epoch: 69  batch: 68  loss: 0.08783782\n",
      "epoch: 70  batch: 1  loss: 0.15633687\n",
      "epoch: 70  batch: 2  loss: 0.04658949\n",
      "epoch: 70  batch: 3  loss: 0.04784213\n",
      "epoch: 70  batch: 4  loss: 0.02973864\n",
      "epoch: 70  batch: 5  loss: 0.10601133\n",
      "epoch: 70  batch: 6  loss: 0.18915488\n",
      "epoch: 70  batch: 7  loss: 0.20019616\n",
      "epoch: 70  batch: 8  loss: 0.13615702\n",
      "epoch: 70  batch: 9  loss: 0.21337813\n",
      "epoch: 70  batch: 10  loss: 0.17922316\n",
      "epoch: 70  batch: 11  loss: 0.31067446\n",
      "epoch: 70  batch: 12  loss: 0.16019981\n",
      "epoch: 70  batch: 13  loss: 0.07106472\n",
      "epoch: 70  batch: 14  loss: 0.16518304\n",
      "epoch: 70  batch: 15  loss: 0.14067806\n",
      "epoch: 70  batch: 16  loss: 0.07692638\n",
      "epoch: 70  batch: 17  loss: 0.20489281\n",
      "epoch: 70  batch: 18  loss: 0.07689676\n",
      "epoch: 70  batch: 19  loss: 0.06625790\n",
      "epoch: 70  batch: 20  loss: 0.28417307\n",
      "epoch: 70  batch: 21  loss: 0.48692602\n",
      "epoch: 70  batch: 22  loss: 0.12043586\n",
      "epoch: 70  batch: 23  loss: 0.04572863\n",
      "epoch: 70  batch: 24  loss: 0.06708142\n",
      "epoch: 70  batch: 25  loss: 0.05874028\n",
      "epoch: 70  batch: 26  loss: 0.09237999\n",
      "epoch: 70  batch: 27  loss: 0.36848027\n",
      "epoch: 70  batch: 28  loss: 0.10991440\n",
      "epoch: 70  batch: 29  loss: 0.30750811\n",
      "epoch: 70  batch: 30  loss: 0.12050845\n",
      "epoch: 70  batch: 31  loss: 0.03764239\n",
      "epoch: 70  batch: 32  loss: 0.01538589\n",
      "epoch: 70  batch: 33  loss: 0.02239518\n",
      "epoch: 70  batch: 34  loss: 0.07607273\n",
      "epoch: 70  batch: 35  loss: 0.15163282\n",
      "epoch: 70  batch: 36  loss: 0.04248195\n",
      "epoch: 70  batch: 37  loss: 0.03738934\n",
      "epoch: 70  batch: 38  loss: 0.04033019\n",
      "epoch: 70  batch: 39  loss: 0.20867823\n",
      "epoch: 70  batch: 40  loss: 0.06819072\n",
      "epoch: 70  batch: 41  loss: 0.17515457\n",
      "epoch: 70  batch: 42  loss: 0.12485062\n",
      "epoch: 70  batch: 43  loss: 0.12473281\n",
      "epoch: 70  batch: 44  loss: 0.18787573\n",
      "epoch: 70  batch: 45  loss: 0.28824592\n",
      "epoch: 70  batch: 46  loss: 0.16057403\n",
      "epoch: 70  batch: 47  loss: 0.21089593\n",
      "epoch: 70  batch: 48  loss: 0.13958347\n",
      "epoch: 70  batch: 49  loss: 0.14717509\n",
      "epoch: 70  batch: 50  loss: 0.20307508\n",
      "epoch: 70  batch: 51  loss: 0.13353707\n",
      "epoch: 70  batch: 52  loss: 0.05795258\n",
      "epoch: 70  batch: 53  loss: 0.07488327\n",
      "epoch: 70  batch: 54  loss: 0.35260472\n",
      "epoch: 70  batch: 55  loss: 0.22452435\n",
      "epoch: 70  batch: 56  loss: 0.07991488\n",
      "epoch: 70  batch: 57  loss: 0.04682235\n",
      "epoch: 70  batch: 58  loss: 0.11588425\n",
      "epoch: 70  batch: 59  loss: 0.09517134\n",
      "epoch: 70  batch: 60  loss: 0.17504846\n",
      "epoch: 70  batch: 61  loss: 0.29814315\n",
      "epoch: 70  batch: 62  loss: 0.21444410\n",
      "epoch: 70  batch: 63  loss: 0.31496489\n",
      "epoch: 70  batch: 64  loss: 0.18375389\n",
      "epoch: 70  batch: 65  loss: 0.04367914\n",
      "epoch: 70  batch: 66  loss: 0.04050303\n",
      "epoch: 70  batch: 67  loss: 0.03756743\n",
      "epoch: 70  batch: 68  loss: 0.08941214\n",
      "epoch: 71  batch: 1  loss: 0.14757596\n",
      "epoch: 71  batch: 2  loss: 0.04954464\n",
      "epoch: 71  batch: 3  loss: 0.03403621\n",
      "epoch: 71  batch: 4  loss: 0.03332295\n",
      "epoch: 71  batch: 5  loss: 0.09858864\n",
      "epoch: 71  batch: 6  loss: 0.31403938\n",
      "epoch: 71  batch: 7  loss: 0.37720045\n",
      "epoch: 71  batch: 8  loss: 0.14773466\n",
      "epoch: 71  batch: 9  loss: 0.20926332\n",
      "epoch: 71  batch: 10  loss: 0.16027349\n",
      "epoch: 71  batch: 11  loss: 0.23992722\n",
      "epoch: 71  batch: 12  loss: 0.15154131\n",
      "epoch: 71  batch: 13  loss: 0.04321662\n",
      "epoch: 71  batch: 14  loss: 0.16014142\n",
      "epoch: 71  batch: 15  loss: 0.14001366\n",
      "epoch: 71  batch: 16  loss: 0.09174693\n",
      "epoch: 71  batch: 17  loss: 0.09616309\n",
      "epoch: 71  batch: 18  loss: 0.05599459\n",
      "epoch: 71  batch: 19  loss: 0.06079174\n",
      "epoch: 71  batch: 20  loss: 0.29293132\n",
      "epoch: 71  batch: 21  loss: 0.33162349\n",
      "epoch: 71  batch: 22  loss: 0.10153563\n",
      "epoch: 71  batch: 23  loss: 0.04579052\n",
      "epoch: 71  batch: 24  loss: 0.07491753\n",
      "epoch: 71  batch: 25  loss: 0.06825253\n",
      "epoch: 71  batch: 26  loss: 0.09028916\n",
      "epoch: 71  batch: 27  loss: 0.52106833\n",
      "epoch: 71  batch: 28  loss: 0.10251772\n",
      "epoch: 71  batch: 29  loss: 0.25461394\n",
      "epoch: 71  batch: 30  loss: 0.21540968\n",
      "epoch: 71  batch: 31  loss: 0.04532668\n",
      "epoch: 71  batch: 32  loss: 0.01854855\n",
      "epoch: 71  batch: 33  loss: 0.01295352\n",
      "epoch: 71  batch: 34  loss: 0.09285367\n",
      "epoch: 71  batch: 35  loss: 0.15176074\n",
      "epoch: 71  batch: 36  loss: 0.04217082\n",
      "epoch: 71  batch: 37  loss: 0.03605719\n",
      "epoch: 71  batch: 38  loss: 0.03723627\n",
      "epoch: 71  batch: 39  loss: 0.15281296\n",
      "epoch: 71  batch: 40  loss: 0.08325696\n",
      "epoch: 71  batch: 41  loss: 0.17557468\n",
      "epoch: 71  batch: 42  loss: 0.11569496\n",
      "epoch: 71  batch: 43  loss: 0.13009706\n",
      "epoch: 71  batch: 44  loss: 0.16565292\n",
      "epoch: 71  batch: 45  loss: 0.25843665\n",
      "epoch: 71  batch: 46  loss: 0.15702541\n",
      "epoch: 71  batch: 47  loss: 0.16109280\n",
      "epoch: 71  batch: 48  loss: 0.13307044\n",
      "epoch: 71  batch: 49  loss: 0.12098967\n",
      "epoch: 71  batch: 50  loss: 0.17831381\n",
      "epoch: 71  batch: 51  loss: 0.12996402\n",
      "epoch: 71  batch: 52  loss: 0.06049965\n",
      "epoch: 71  batch: 53  loss: 0.08449948\n",
      "epoch: 71  batch: 54  loss: 0.35112923\n",
      "epoch: 71  batch: 55  loss: 0.22754818\n",
      "epoch: 71  batch: 56  loss: 0.08063134\n",
      "epoch: 71  batch: 57  loss: 0.05102532\n",
      "epoch: 71  batch: 58  loss: 0.11532371\n",
      "epoch: 71  batch: 59  loss: 0.09070083\n",
      "epoch: 71  batch: 60  loss: 0.15130304\n",
      "epoch: 71  batch: 61  loss: 0.42713907\n",
      "epoch: 71  batch: 62  loss: 0.21729158\n",
      "epoch: 71  batch: 63  loss: 0.31115991\n",
      "epoch: 71  batch: 64  loss: 0.21152005\n",
      "epoch: 71  batch: 65  loss: 0.08329733\n",
      "epoch: 71  batch: 66  loss: 0.03976211\n",
      "epoch: 71  batch: 67  loss: 0.08737157\n",
      "epoch: 71  batch: 68  loss: 0.07900008\n",
      "epoch: 72  batch: 1  loss: 0.14733046\n",
      "epoch: 72  batch: 2  loss: 0.04855109\n",
      "epoch: 72  batch: 3  loss: 0.04859320\n",
      "epoch: 72  batch: 4  loss: 0.06084228\n",
      "epoch: 72  batch: 5  loss: 0.10434772\n",
      "epoch: 72  batch: 6  loss: 0.40847024\n",
      "epoch: 72  batch: 7  loss: 0.28564110\n",
      "epoch: 72  batch: 8  loss: 0.10378985\n",
      "epoch: 72  batch: 9  loss: 0.18257616\n",
      "epoch: 72  batch: 10  loss: 0.24543564\n",
      "epoch: 72  batch: 11  loss: 0.29908231\n",
      "epoch: 72  batch: 12  loss: 0.14871027\n",
      "epoch: 72  batch: 13  loss: 0.04278928\n",
      "epoch: 72  batch: 14  loss: 0.15614966\n",
      "epoch: 72  batch: 15  loss: 0.12853000\n",
      "epoch: 72  batch: 16  loss: 0.06615105\n",
      "epoch: 72  batch: 17  loss: 0.08541166\n",
      "epoch: 72  batch: 18  loss: 0.10314939\n",
      "epoch: 72  batch: 19  loss: 0.04966648\n",
      "epoch: 72  batch: 20  loss: 0.28014290\n",
      "epoch: 72  batch: 21  loss: 0.32550499\n",
      "epoch: 72  batch: 22  loss: 0.15229024\n",
      "epoch: 72  batch: 23  loss: 0.04532450\n",
      "epoch: 72  batch: 24  loss: 0.06446541\n",
      "epoch: 72  batch: 25  loss: 0.07676263\n",
      "epoch: 72  batch: 26  loss: 0.05920445\n",
      "epoch: 72  batch: 27  loss: 0.35760269\n",
      "epoch: 72  batch: 28  loss: 0.14520876\n",
      "epoch: 72  batch: 29  loss: 0.33971617\n",
      "epoch: 72  batch: 30  loss: 0.12869012\n",
      "epoch: 72  batch: 31  loss: 0.05714794\n",
      "epoch: 72  batch: 32  loss: 0.04911056\n",
      "epoch: 72  batch: 33  loss: 0.13429289\n",
      "epoch: 72  batch: 34  loss: 0.08238126\n",
      "epoch: 72  batch: 35  loss: 0.15462981\n",
      "epoch: 72  batch: 36  loss: 0.04530642\n",
      "epoch: 72  batch: 37  loss: 0.03354070\n",
      "epoch: 72  batch: 38  loss: 0.03975722\n",
      "epoch: 72  batch: 39  loss: 0.14620078\n",
      "epoch: 72  batch: 40  loss: 0.12426636\n",
      "epoch: 72  batch: 41  loss: 0.18142127\n",
      "epoch: 72  batch: 42  loss: 0.09656068\n",
      "epoch: 72  batch: 43  loss: 0.15365888\n",
      "epoch: 72  batch: 44  loss: 0.19389978\n",
      "epoch: 72  batch: 45  loss: 0.28285480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 72  batch: 46  loss: 0.16949649\n",
      "epoch: 72  batch: 47  loss: 0.17476963\n",
      "epoch: 72  batch: 48  loss: 0.13582408\n",
      "epoch: 72  batch: 49  loss: 0.12325945\n",
      "epoch: 72  batch: 50  loss: 0.12668774\n",
      "epoch: 72  batch: 51  loss: 0.10804630\n",
      "epoch: 72  batch: 52  loss: 0.05732927\n",
      "epoch: 72  batch: 53  loss: 0.07077196\n",
      "epoch: 72  batch: 54  loss: 0.41229239\n",
      "epoch: 72  batch: 55  loss: 0.22303104\n",
      "epoch: 72  batch: 56  loss: 0.10728344\n",
      "epoch: 72  batch: 57  loss: 0.04909407\n",
      "epoch: 72  batch: 58  loss: 0.12808177\n",
      "epoch: 72  batch: 59  loss: 0.10146260\n",
      "epoch: 72  batch: 60  loss: 0.12559931\n",
      "epoch: 72  batch: 61  loss: 0.43937463\n",
      "epoch: 72  batch: 62  loss: 0.21211353\n",
      "epoch: 72  batch: 63  loss: 0.26651511\n",
      "epoch: 72  batch: 64  loss: 0.13139664\n",
      "epoch: 72  batch: 65  loss: 0.04119802\n",
      "epoch: 72  batch: 66  loss: 0.03819292\n",
      "epoch: 72  batch: 67  loss: 0.03291210\n",
      "epoch: 72  batch: 68  loss: 0.06710463\n",
      "epoch: 73  batch: 1  loss: 0.21102682\n",
      "epoch: 73  batch: 2  loss: 0.04743122\n",
      "epoch: 73  batch: 3  loss: 0.05096971\n",
      "epoch: 73  batch: 4  loss: 0.03114475\n",
      "epoch: 73  batch: 5  loss: 0.09678717\n",
      "epoch: 73  batch: 6  loss: 0.10893756\n",
      "epoch: 73  batch: 7  loss: 0.31314504\n",
      "epoch: 73  batch: 8  loss: 0.09510911\n",
      "epoch: 73  batch: 9  loss: 0.17554966\n",
      "epoch: 73  batch: 10  loss: 0.19440433\n",
      "epoch: 73  batch: 11  loss: 0.27429077\n",
      "epoch: 73  batch: 12  loss: 0.17481934\n",
      "epoch: 73  batch: 13  loss: 0.05429496\n",
      "epoch: 73  batch: 14  loss: 0.15064086\n",
      "epoch: 73  batch: 15  loss: 0.12160087\n",
      "epoch: 73  batch: 16  loss: 0.06108389\n",
      "epoch: 73  batch: 17  loss: 0.08948843\n",
      "epoch: 73  batch: 18  loss: 0.05850621\n",
      "epoch: 73  batch: 19  loss: 0.09813663\n",
      "epoch: 73  batch: 20  loss: 0.27565283\n",
      "epoch: 73  batch: 21  loss: 0.32014546\n",
      "epoch: 73  batch: 22  loss: 0.10339718\n",
      "epoch: 73  batch: 23  loss: 0.04595119\n",
      "epoch: 73  batch: 24  loss: 0.11612480\n",
      "epoch: 73  batch: 25  loss: 0.06505833\n",
      "epoch: 73  batch: 26  loss: 0.06042874\n",
      "epoch: 73  batch: 27  loss: 0.30301565\n",
      "epoch: 73  batch: 28  loss: 0.12360118\n",
      "epoch: 73  batch: 29  loss: 0.12057839\n",
      "epoch: 73  batch: 30  loss: 0.15498005\n",
      "epoch: 73  batch: 31  loss: 0.04012553\n",
      "epoch: 73  batch: 32  loss: 0.01389465\n",
      "epoch: 73  batch: 33  loss: 0.01856346\n",
      "epoch: 73  batch: 34  loss: 0.08652698\n",
      "epoch: 73  batch: 35  loss: 0.15316395\n",
      "epoch: 73  batch: 36  loss: 0.04803440\n",
      "epoch: 73  batch: 37  loss: 0.04457849\n",
      "epoch: 73  batch: 38  loss: 0.04265057\n",
      "epoch: 73  batch: 39  loss: 0.14659265\n",
      "epoch: 73  batch: 40  loss: 0.12635842\n",
      "epoch: 73  batch: 41  loss: 0.17473041\n",
      "epoch: 73  batch: 42  loss: 0.10785438\n",
      "epoch: 73  batch: 43  loss: 0.11870918\n",
      "epoch: 73  batch: 44  loss: 0.19526376\n",
      "epoch: 73  batch: 45  loss: 0.40840033\n",
      "epoch: 73  batch: 46  loss: 0.17661703\n",
      "epoch: 73  batch: 47  loss: 0.11891104\n",
      "epoch: 73  batch: 48  loss: 0.13998011\n",
      "epoch: 73  batch: 49  loss: 0.14287774\n",
      "epoch: 73  batch: 50  loss: 0.10345586\n",
      "epoch: 73  batch: 51  loss: 0.11269240\n",
      "epoch: 73  batch: 52  loss: 0.08783052\n",
      "epoch: 73  batch: 53  loss: 0.12334240\n",
      "epoch: 73  batch: 54  loss: 0.34909895\n",
      "epoch: 73  batch: 55  loss: 0.22239693\n",
      "epoch: 73  batch: 56  loss: 0.08416162\n",
      "epoch: 73  batch: 57  loss: 0.05182057\n",
      "epoch: 73  batch: 58  loss: 0.09882247\n",
      "epoch: 73  batch: 59  loss: 0.11134282\n",
      "epoch: 73  batch: 60  loss: 0.12449598\n",
      "epoch: 73  batch: 61  loss: 0.74310261\n",
      "epoch: 73  batch: 62  loss: 0.19811575\n",
      "epoch: 73  batch: 63  loss: 0.21275052\n",
      "epoch: 73  batch: 64  loss: 0.29484624\n",
      "epoch: 73  batch: 65  loss: 0.06298321\n",
      "epoch: 73  batch: 66  loss: 0.03531654\n",
      "epoch: 73  batch: 67  loss: 0.03887596\n",
      "epoch: 73  batch: 68  loss: 0.06353298\n",
      "epoch: 74  batch: 1  loss: 0.15037777\n",
      "epoch: 74  batch: 2  loss: 0.04781630\n",
      "epoch: 74  batch: 3  loss: 0.03882650\n",
      "epoch: 74  batch: 4  loss: 0.03091265\n",
      "epoch: 74  batch: 5  loss: 0.09492937\n",
      "epoch: 74  batch: 6  loss: 0.32701433\n",
      "epoch: 74  batch: 7  loss: 0.21860303\n",
      "epoch: 74  batch: 8  loss: 0.14246614\n",
      "epoch: 74  batch: 9  loss: 0.17182197\n",
      "epoch: 74  batch: 10  loss: 0.22180375\n",
      "epoch: 74  batch: 11  loss: 0.25969666\n",
      "epoch: 74  batch: 12  loss: 0.14916468\n",
      "epoch: 74  batch: 13  loss: 0.04855693\n",
      "epoch: 74  batch: 14  loss: 0.15396103\n",
      "epoch: 74  batch: 15  loss: 0.13130260\n",
      "epoch: 74  batch: 16  loss: 0.06530850\n",
      "epoch: 74  batch: 17  loss: 0.07651947\n",
      "epoch: 74  batch: 18  loss: 0.06921934\n",
      "epoch: 74  batch: 19  loss: 0.05829308\n",
      "epoch: 74  batch: 20  loss: 0.31200600\n",
      "epoch: 74  batch: 21  loss: 0.31674516\n",
      "epoch: 74  batch: 22  loss: 0.14733194\n",
      "epoch: 74  batch: 23  loss: 0.04757056\n",
      "epoch: 74  batch: 24  loss: 0.06466496\n",
      "epoch: 74  batch: 25  loss: 0.07295655\n",
      "epoch: 74  batch: 26  loss: 0.05932639\n",
      "epoch: 74  batch: 27  loss: 0.35516727\n",
      "epoch: 74  batch: 28  loss: 0.11407706\n",
      "epoch: 74  batch: 29  loss: 0.24956968\n",
      "epoch: 74  batch: 30  loss: 0.09488074\n",
      "epoch: 74  batch: 31  loss: 0.03544999\n",
      "epoch: 74  batch: 32  loss: 0.02736394\n",
      "epoch: 74  batch: 33  loss: 0.01676461\n",
      "epoch: 74  batch: 34  loss: 0.07639470\n",
      "epoch: 74  batch: 35  loss: 0.15399456\n",
      "epoch: 74  batch: 36  loss: 0.04673645\n",
      "epoch: 74  batch: 37  loss: 0.04036336\n",
      "epoch: 74  batch: 38  loss: 0.03810955\n",
      "epoch: 74  batch: 39  loss: 0.14973746\n",
      "epoch: 74  batch: 40  loss: 0.07982041\n",
      "epoch: 74  batch: 41  loss: 0.17257051\n",
      "epoch: 74  batch: 42  loss: 0.10492033\n",
      "epoch: 74  batch: 43  loss: 0.16168217\n",
      "epoch: 74  batch: 44  loss: 0.16939393\n",
      "epoch: 74  batch: 45  loss: 0.27441815\n",
      "epoch: 74  batch: 46  loss: 0.15422294\n",
      "epoch: 74  batch: 47  loss: 0.13543385\n",
      "epoch: 74  batch: 48  loss: 0.14335717\n",
      "epoch: 74  batch: 49  loss: 0.12992473\n",
      "epoch: 74  batch: 50  loss: 0.10490545\n",
      "epoch: 74  batch: 51  loss: 0.09759884\n",
      "epoch: 74  batch: 52  loss: 0.10843457\n",
      "epoch: 74  batch: 53  loss: 0.07330935\n",
      "epoch: 74  batch: 54  loss: 0.34268168\n",
      "epoch: 74  batch: 55  loss: 0.22042495\n",
      "epoch: 74  batch: 56  loss: 0.11041610\n",
      "epoch: 74  batch: 57  loss: 0.04334811\n",
      "epoch: 74  batch: 58  loss: 0.12827457\n",
      "epoch: 74  batch: 59  loss: 0.10050318\n",
      "epoch: 74  batch: 60  loss: 0.06967080\n",
      "epoch: 74  batch: 61  loss: 0.29470804\n",
      "epoch: 74  batch: 62  loss: 0.21496998\n",
      "epoch: 74  batch: 63  loss: 0.25571582\n",
      "epoch: 74  batch: 64  loss: 0.09227762\n",
      "epoch: 74  batch: 65  loss: 0.03708911\n",
      "epoch: 74  batch: 66  loss: 0.03577062\n",
      "epoch: 74  batch: 67  loss: 0.02999025\n",
      "epoch: 74  batch: 68  loss: 0.07133722\n",
      "epoch: 75  batch: 1  loss: 0.19054757\n",
      "epoch: 75  batch: 2  loss: 0.04710944\n",
      "epoch: 75  batch: 3  loss: 0.04381089\n",
      "epoch: 75  batch: 4  loss: 0.03034790\n",
      "epoch: 75  batch: 5  loss: 0.09641980\n",
      "epoch: 75  batch: 6  loss: 0.18671677\n",
      "epoch: 75  batch: 7  loss: 0.28315020\n",
      "epoch: 75  batch: 8  loss: 0.13481440\n",
      "epoch: 75  batch: 9  loss: 0.23549087\n",
      "epoch: 75  batch: 10  loss: 0.15360314\n",
      "epoch: 75  batch: 11  loss: 0.22900032\n",
      "epoch: 75  batch: 12  loss: 0.16167456\n",
      "epoch: 75  batch: 13  loss: 0.03881321\n",
      "epoch: 75  batch: 14  loss: 0.15899061\n",
      "epoch: 75  batch: 15  loss: 0.12417231\n",
      "epoch: 75  batch: 16  loss: 0.07933167\n",
      "epoch: 75  batch: 17  loss: 0.09708883\n",
      "epoch: 75  batch: 18  loss: 0.05582050\n",
      "epoch: 75  batch: 19  loss: 0.04659961\n",
      "epoch: 75  batch: 20  loss: 0.27706239\n",
      "epoch: 75  batch: 21  loss: 0.31769055\n",
      "epoch: 75  batch: 22  loss: 0.10068033\n",
      "epoch: 75  batch: 23  loss: 0.04966791\n",
      "epoch: 75  batch: 24  loss: 0.06511424\n",
      "epoch: 75  batch: 25  loss: 0.06424025\n",
      "epoch: 75  batch: 26  loss: 0.03452435\n",
      "epoch: 75  batch: 27  loss: 0.30601326\n",
      "epoch: 75  batch: 28  loss: 0.19393171\n",
      "epoch: 75  batch: 29  loss: 0.13779669\n",
      "epoch: 75  batch: 30  loss: 0.10406971\n",
      "epoch: 75  batch: 31  loss: 0.05642568\n",
      "epoch: 75  batch: 32  loss: 0.01449820\n",
      "epoch: 75  batch: 33  loss: 0.06021313\n",
      "epoch: 75  batch: 34  loss: 0.09246720\n",
      "epoch: 75  batch: 35  loss: 0.15083364\n",
      "epoch: 75  batch: 36  loss: 0.05259713\n",
      "epoch: 75  batch: 37  loss: 0.04126170\n",
      "epoch: 75  batch: 38  loss: 0.04698835\n",
      "epoch: 75  batch: 39  loss: 0.14842342\n",
      "epoch: 75  batch: 40  loss: 0.06974229\n",
      "epoch: 75  batch: 41  loss: 0.16899510\n",
      "epoch: 75  batch: 42  loss: 0.11383565\n",
      "epoch: 75  batch: 43  loss: 0.11484010\n",
      "epoch: 75  batch: 44  loss: 0.15292683\n",
      "epoch: 75  batch: 45  loss: 0.23215392\n",
      "epoch: 75  batch: 46  loss: 0.11215433\n",
      "epoch: 75  batch: 47  loss: 0.10809140\n",
      "epoch: 75  batch: 48  loss: 0.14412674\n",
      "epoch: 75  batch: 49  loss: 0.12876584\n",
      "epoch: 75  batch: 50  loss: 0.07999741\n",
      "epoch: 75  batch: 51  loss: 0.11495098\n",
      "epoch: 75  batch: 52  loss: 0.09484764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 75  batch: 53  loss: 0.08950429\n",
      "epoch: 75  batch: 54  loss: 0.35710442\n",
      "epoch: 75  batch: 55  loss: 0.21897936\n",
      "epoch: 75  batch: 56  loss: 0.07787557\n",
      "epoch: 75  batch: 57  loss: 0.04289823\n",
      "epoch: 75  batch: 58  loss: 0.10445017\n",
      "epoch: 75  batch: 59  loss: 0.09928131\n",
      "epoch: 75  batch: 60  loss: 0.05007618\n",
      "epoch: 75  batch: 61  loss: 0.24417850\n",
      "epoch: 75  batch: 62  loss: 0.21359652\n",
      "epoch: 75  batch: 63  loss: 0.20949359\n",
      "epoch: 75  batch: 64  loss: 0.25034109\n",
      "epoch: 75  batch: 65  loss: 0.04864652\n",
      "epoch: 75  batch: 66  loss: 0.03984641\n",
      "epoch: 75  batch: 67  loss: 0.04137602\n",
      "epoch: 75  batch: 68  loss: 0.06810505\n",
      "epoch: 76  batch: 1  loss: 0.15769282\n",
      "epoch: 76  batch: 2  loss: 0.04842997\n",
      "epoch: 76  batch: 3  loss: 0.03818843\n",
      "epoch: 76  batch: 4  loss: 0.03045953\n",
      "epoch: 76  batch: 5  loss: 0.10375477\n",
      "epoch: 76  batch: 6  loss: 0.07910710\n",
      "epoch: 76  batch: 7  loss: 0.23539159\n",
      "epoch: 76  batch: 8  loss: 0.09286576\n",
      "epoch: 76  batch: 9  loss: 0.13867466\n",
      "epoch: 76  batch: 10  loss: 0.19236374\n",
      "epoch: 76  batch: 11  loss: 0.25540864\n",
      "epoch: 76  batch: 12  loss: 0.20283242\n",
      "epoch: 76  batch: 13  loss: 0.04271621\n",
      "epoch: 76  batch: 14  loss: 0.14864047\n",
      "epoch: 76  batch: 15  loss: 0.13508943\n",
      "epoch: 76  batch: 16  loss: 0.06821451\n",
      "epoch: 76  batch: 17  loss: 0.13635132\n",
      "epoch: 76  batch: 18  loss: 0.09071126\n",
      "epoch: 76  batch: 19  loss: 0.05674475\n",
      "epoch: 76  batch: 20  loss: 0.28642160\n",
      "epoch: 76  batch: 21  loss: 0.38575712\n",
      "epoch: 76  batch: 22  loss: 0.12474552\n",
      "epoch: 76  batch: 23  loss: 0.04756201\n",
      "epoch: 76  batch: 24  loss: 0.07028984\n",
      "epoch: 76  batch: 25  loss: 0.05872283\n",
      "epoch: 76  batch: 26  loss: 0.05193948\n",
      "epoch: 76  batch: 27  loss: 0.24089973\n",
      "epoch: 76  batch: 28  loss: 0.04508047\n",
      "epoch: 76  batch: 29  loss: 0.13922557\n",
      "epoch: 76  batch: 30  loss: 0.03328083\n",
      "epoch: 76  batch: 31  loss: 0.03004940\n",
      "epoch: 76  batch: 32  loss: 0.01292533\n",
      "epoch: 76  batch: 33  loss: 0.01203887\n",
      "epoch: 76  batch: 34  loss: 0.09058955\n",
      "epoch: 76  batch: 35  loss: 0.14953484\n",
      "epoch: 76  batch: 36  loss: 0.05180470\n",
      "epoch: 76  batch: 37  loss: 0.03576997\n",
      "epoch: 76  batch: 38  loss: 0.04197681\n",
      "epoch: 76  batch: 39  loss: 0.14912257\n",
      "epoch: 76  batch: 40  loss: 0.06804911\n",
      "epoch: 76  batch: 41  loss: 0.16625489\n",
      "epoch: 76  batch: 42  loss: 0.12665240\n",
      "epoch: 76  batch: 43  loss: 0.11665847\n",
      "epoch: 76  batch: 44  loss: 0.16346219\n",
      "epoch: 76  batch: 45  loss: 0.19799316\n",
      "epoch: 76  batch: 46  loss: 0.14296375\n",
      "epoch: 76  batch: 47  loss: 0.21723381\n",
      "epoch: 76  batch: 48  loss: 0.15863454\n",
      "epoch: 76  batch: 49  loss: 0.12508242\n",
      "epoch: 76  batch: 50  loss: 0.11343750\n",
      "epoch: 76  batch: 51  loss: 0.09263488\n",
      "epoch: 76  batch: 52  loss: 0.12529653\n",
      "epoch: 76  batch: 53  loss: 0.07232159\n",
      "epoch: 76  batch: 54  loss: 0.33860686\n",
      "epoch: 76  batch: 55  loss: 0.21451648\n",
      "epoch: 76  batch: 56  loss: 0.07869895\n",
      "epoch: 76  batch: 57  loss: 0.04803550\n",
      "epoch: 76  batch: 58  loss: 0.09229980\n",
      "epoch: 76  batch: 59  loss: 0.10197900\n",
      "epoch: 76  batch: 60  loss: 0.04500860\n",
      "epoch: 76  batch: 61  loss: 0.15996423\n",
      "epoch: 76  batch: 62  loss: 0.19959122\n",
      "epoch: 76  batch: 63  loss: 0.09458705\n",
      "epoch: 76  batch: 64  loss: 0.24524403\n",
      "epoch: 76  batch: 65  loss: 0.04243011\n",
      "epoch: 76  batch: 66  loss: 0.03685480\n",
      "epoch: 76  batch: 67  loss: 0.02959098\n",
      "epoch: 76  batch: 68  loss: 0.06181946\n",
      "epoch: 77  batch: 1  loss: 0.14124410\n",
      "epoch: 77  batch: 2  loss: 0.05005525\n",
      "epoch: 77  batch: 3  loss: 0.04088522\n",
      "epoch: 77  batch: 4  loss: 0.03267782\n",
      "epoch: 77  batch: 5  loss: 0.09306832\n",
      "epoch: 77  batch: 6  loss: 0.07932768\n",
      "epoch: 77  batch: 7  loss: 0.19789319\n",
      "epoch: 77  batch: 8  loss: 0.08750411\n",
      "epoch: 77  batch: 9  loss: 0.13261934\n",
      "epoch: 77  batch: 10  loss: 0.13191958\n",
      "epoch: 77  batch: 11  loss: 0.21515563\n",
      "epoch: 77  batch: 12  loss: 0.15703918\n",
      "epoch: 77  batch: 13  loss: 0.07771308\n",
      "epoch: 77  batch: 14  loss: 0.14909111\n",
      "epoch: 77  batch: 15  loss: 0.14148565\n",
      "epoch: 77  batch: 16  loss: 0.08045039\n",
      "epoch: 77  batch: 17  loss: 0.08188523\n",
      "epoch: 77  batch: 18  loss: 0.08198600\n",
      "epoch: 77  batch: 19  loss: 0.07673705\n",
      "epoch: 77  batch: 20  loss: 0.26443389\n",
      "epoch: 77  batch: 21  loss: 0.30287710\n",
      "epoch: 77  batch: 22  loss: 0.08334237\n",
      "epoch: 77  batch: 23  loss: 0.04462979\n",
      "epoch: 77  batch: 24  loss: 0.06657552\n",
      "epoch: 77  batch: 25  loss: 0.06140432\n",
      "epoch: 77  batch: 26  loss: 0.04475965\n",
      "epoch: 77  batch: 27  loss: 0.17261666\n",
      "epoch: 77  batch: 28  loss: 0.02581894\n",
      "epoch: 77  batch: 29  loss: 0.12277818\n",
      "epoch: 77  batch: 30  loss: 0.13661996\n",
      "epoch: 77  batch: 31  loss: 0.02841383\n",
      "epoch: 77  batch: 32  loss: 0.01132704\n",
      "epoch: 77  batch: 33  loss: 0.00893143\n",
      "epoch: 77  batch: 34  loss: 0.08861890\n",
      "epoch: 77  batch: 35  loss: 0.15179197\n",
      "epoch: 77  batch: 36  loss: 0.05573270\n",
      "epoch: 77  batch: 37  loss: 0.04215429\n",
      "epoch: 77  batch: 38  loss: 0.03975358\n",
      "epoch: 77  batch: 39  loss: 0.13262147\n",
      "epoch: 77  batch: 40  loss: 0.06847128\n",
      "epoch: 77  batch: 41  loss: 0.16292796\n",
      "epoch: 77  batch: 42  loss: 0.11078059\n",
      "epoch: 77  batch: 43  loss: 0.08586694\n",
      "epoch: 77  batch: 44  loss: 0.17129929\n",
      "epoch: 77  batch: 45  loss: 0.19067426\n",
      "epoch: 77  batch: 46  loss: 0.13385794\n",
      "epoch: 77  batch: 47  loss: 0.30078170\n",
      "epoch: 77  batch: 48  loss: 0.16806899\n",
      "epoch: 77  batch: 49  loss: 0.12731391\n",
      "epoch: 77  batch: 50  loss: 0.21595702\n",
      "epoch: 77  batch: 51  loss: 0.12770467\n",
      "epoch: 77  batch: 52  loss: 0.05918867\n",
      "epoch: 77  batch: 53  loss: 0.11510514\n",
      "epoch: 77  batch: 54  loss: 0.33556664\n",
      "epoch: 77  batch: 55  loss: 0.21552260\n",
      "epoch: 77  batch: 56  loss: 0.08262458\n",
      "epoch: 77  batch: 57  loss: 0.06086692\n",
      "epoch: 77  batch: 58  loss: 0.10669959\n",
      "epoch: 77  batch: 59  loss: 0.10186377\n",
      "epoch: 77  batch: 60  loss: 0.22096387\n",
      "epoch: 77  batch: 61  loss: 0.34019178\n",
      "epoch: 77  batch: 62  loss: 0.26177126\n",
      "epoch: 77  batch: 63  loss: 0.07671049\n",
      "epoch: 77  batch: 64  loss: 0.13448228\n",
      "epoch: 77  batch: 65  loss: 0.08726250\n",
      "epoch: 77  batch: 66  loss: 0.04603301\n",
      "epoch: 77  batch: 67  loss: 0.03309136\n",
      "epoch: 77  batch: 68  loss: 0.06052285\n",
      "epoch: 78  batch: 1  loss: 0.13822997\n",
      "epoch: 78  batch: 2  loss: 0.04905062\n",
      "epoch: 78  batch: 3  loss: 0.03606532\n",
      "epoch: 78  batch: 4  loss: 0.03105560\n",
      "epoch: 78  batch: 5  loss: 0.09258521\n",
      "epoch: 78  batch: 6  loss: 0.07864370\n",
      "epoch: 78  batch: 7  loss: 0.26372421\n",
      "epoch: 78  batch: 8  loss: 0.21014866\n",
      "epoch: 78  batch: 9  loss: 0.16221045\n",
      "epoch: 78  batch: 10  loss: 0.17550723\n",
      "epoch: 78  batch: 11  loss: 0.19121560\n",
      "epoch: 78  batch: 12  loss: 0.13606919\n",
      "epoch: 78  batch: 13  loss: 0.07200748\n",
      "epoch: 78  batch: 14  loss: 0.15384626\n",
      "epoch: 78  batch: 15  loss: 0.14654270\n",
      "epoch: 78  batch: 16  loss: 0.06371793\n",
      "epoch: 78  batch: 17  loss: 0.06156154\n",
      "epoch: 78  batch: 18  loss: 0.07986634\n",
      "epoch: 78  batch: 19  loss: 0.04927004\n",
      "epoch: 78  batch: 20  loss: 0.26666877\n",
      "epoch: 78  batch: 21  loss: 0.30781898\n",
      "epoch: 78  batch: 22  loss: 0.07306994\n",
      "epoch: 78  batch: 23  loss: 0.04359729\n",
      "epoch: 78  batch: 24  loss: 0.06814077\n",
      "epoch: 78  batch: 25  loss: 0.07075490\n",
      "epoch: 78  batch: 26  loss: 0.03396610\n",
      "epoch: 78  batch: 27  loss: 0.15982527\n",
      "epoch: 78  batch: 28  loss: 0.02114982\n",
      "epoch: 78  batch: 29  loss: 0.07115217\n",
      "epoch: 78  batch: 30  loss: 0.14051297\n",
      "epoch: 78  batch: 31  loss: 0.05981469\n",
      "epoch: 78  batch: 32  loss: 0.01364432\n",
      "epoch: 78  batch: 33  loss: 0.00859722\n",
      "epoch: 78  batch: 34  loss: 0.09604918\n",
      "epoch: 78  batch: 35  loss: 0.17079544\n",
      "epoch: 78  batch: 36  loss: 0.05601104\n",
      "epoch: 78  batch: 37  loss: 0.03748693\n",
      "epoch: 78  batch: 38  loss: 0.24060357\n",
      "epoch: 78  batch: 39  loss: 0.13737968\n",
      "epoch: 78  batch: 40  loss: 0.08167293\n",
      "epoch: 78  batch: 41  loss: 0.16488472\n",
      "epoch: 78  batch: 42  loss: 0.08919515\n",
      "epoch: 78  batch: 43  loss: 0.08706769\n",
      "epoch: 78  batch: 44  loss: 0.14452247\n",
      "epoch: 78  batch: 45  loss: 0.21161817\n",
      "epoch: 78  batch: 46  loss: 0.18213975\n",
      "epoch: 78  batch: 47  loss: 0.25929838\n",
      "epoch: 78  batch: 48  loss: 0.16096327\n",
      "epoch: 78  batch: 49  loss: 0.12702058\n",
      "epoch: 78  batch: 50  loss: 0.10828437\n",
      "epoch: 78  batch: 51  loss: 0.10026415\n",
      "epoch: 78  batch: 52  loss: 0.09908421\n",
      "epoch: 78  batch: 53  loss: 0.11668601\n",
      "epoch: 78  batch: 54  loss: 0.32694861\n",
      "epoch: 78  batch: 55  loss: 0.21421196\n",
      "epoch: 78  batch: 56  loss: 0.08400614\n",
      "epoch: 78  batch: 57  loss: 0.06220955\n",
      "epoch: 78  batch: 58  loss: 0.10075918\n",
      "epoch: 78  batch: 59  loss: 0.11636072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 78  batch: 60  loss: 0.05535252\n",
      "epoch: 78  batch: 61  loss: 0.27219772\n",
      "epoch: 78  batch: 62  loss: 0.21064208\n",
      "epoch: 78  batch: 63  loss: 0.20789160\n",
      "epoch: 78  batch: 64  loss: 0.11172543\n",
      "epoch: 78  batch: 65  loss: 0.08413241\n",
      "epoch: 78  batch: 66  loss: 0.03856070\n",
      "epoch: 78  batch: 67  loss: 0.02774915\n",
      "epoch: 78  batch: 68  loss: 0.06714522\n",
      "epoch: 79  batch: 1  loss: 0.16871062\n",
      "epoch: 79  batch: 2  loss: 0.05183396\n",
      "epoch: 79  batch: 3  loss: 0.04994156\n",
      "epoch: 79  batch: 4  loss: 0.03431249\n",
      "epoch: 79  batch: 5  loss: 0.09177549\n",
      "epoch: 79  batch: 6  loss: 0.07863769\n",
      "epoch: 79  batch: 7  loss: 0.18232746\n",
      "epoch: 79  batch: 8  loss: 0.10379753\n",
      "epoch: 79  batch: 9  loss: 0.14269884\n",
      "epoch: 79  batch: 10  loss: 0.19129565\n",
      "epoch: 79  batch: 11  loss: 0.19891898\n",
      "epoch: 79  batch: 12  loss: 0.14536986\n",
      "epoch: 79  batch: 13  loss: 0.03915523\n",
      "epoch: 79  batch: 14  loss: 0.15293264\n",
      "epoch: 79  batch: 15  loss: 0.12519984\n",
      "epoch: 79  batch: 16  loss: 0.06180554\n",
      "epoch: 79  batch: 17  loss: 0.06644266\n",
      "epoch: 79  batch: 18  loss: 0.05155233\n",
      "epoch: 79  batch: 19  loss: 0.05565581\n",
      "epoch: 79  batch: 20  loss: 0.34616426\n",
      "epoch: 79  batch: 21  loss: 0.30592960\n",
      "epoch: 79  batch: 22  loss: 0.15786257\n",
      "epoch: 79  batch: 23  loss: 0.05675833\n",
      "epoch: 79  batch: 24  loss: 0.07383792\n",
      "epoch: 79  batch: 25  loss: 0.05768618\n",
      "epoch: 79  batch: 26  loss: 0.03468401\n",
      "epoch: 79  batch: 27  loss: 0.12317105\n",
      "epoch: 79  batch: 28  loss: 0.02927474\n",
      "epoch: 79  batch: 29  loss: 0.16048920\n",
      "epoch: 79  batch: 30  loss: 0.02957374\n",
      "epoch: 79  batch: 31  loss: 0.02589088\n",
      "epoch: 79  batch: 32  loss: 0.01489821\n",
      "epoch: 79  batch: 33  loss: 0.01067938\n",
      "epoch: 79  batch: 34  loss: 0.08205672\n",
      "epoch: 79  batch: 35  loss: 0.15098585\n",
      "epoch: 79  batch: 36  loss: 0.05032861\n",
      "epoch: 79  batch: 37  loss: 0.05133193\n",
      "epoch: 79  batch: 38  loss: 0.03884398\n",
      "epoch: 79  batch: 39  loss: 0.13411963\n",
      "epoch: 79  batch: 40  loss: 0.06821962\n",
      "epoch: 79  batch: 41  loss: 0.16255574\n",
      "epoch: 79  batch: 42  loss: 0.09573012\n",
      "epoch: 79  batch: 43  loss: 0.11962988\n",
      "epoch: 79  batch: 44  loss: 0.14960177\n",
      "epoch: 79  batch: 45  loss: 0.26558009\n",
      "epoch: 79  batch: 46  loss: 0.13840976\n",
      "epoch: 79  batch: 47  loss: 0.16850385\n",
      "epoch: 79  batch: 48  loss: 0.16368400\n",
      "epoch: 79  batch: 49  loss: 0.12532090\n",
      "epoch: 79  batch: 50  loss: 0.15548834\n",
      "epoch: 79  batch: 51  loss: 0.10950025\n",
      "epoch: 79  batch: 52  loss: 0.06398650\n",
      "epoch: 79  batch: 53  loss: 0.10701048\n",
      "epoch: 79  batch: 54  loss: 0.34017533\n",
      "epoch: 79  batch: 55  loss: 0.21563028\n",
      "epoch: 79  batch: 56  loss: 0.07653760\n",
      "epoch: 79  batch: 57  loss: 0.06278870\n",
      "epoch: 79  batch: 58  loss: 0.09213851\n",
      "epoch: 79  batch: 59  loss: 0.11578745\n",
      "epoch: 79  batch: 60  loss: 0.04596266\n",
      "epoch: 79  batch: 61  loss: 0.54164267\n",
      "epoch: 79  batch: 62  loss: 0.28610051\n",
      "epoch: 79  batch: 63  loss: 0.12447396\n",
      "epoch: 79  batch: 64  loss: 0.26575428\n",
      "epoch: 79  batch: 65  loss: 0.05965046\n",
      "epoch: 79  batch: 66  loss: 0.07510296\n",
      "epoch: 79  batch: 67  loss: 0.31338638\n",
      "epoch: 79  batch: 68  loss: 0.13796872\n",
      "epoch: 80  batch: 1  loss: 0.29480332\n",
      "epoch: 80  batch: 2  loss: 0.06196491\n",
      "epoch: 80  batch: 3  loss: 0.05412035\n",
      "epoch: 80  batch: 4  loss: 0.03451501\n",
      "epoch: 80  batch: 5  loss: 0.09006538\n",
      "epoch: 80  batch: 6  loss: 0.07585567\n",
      "epoch: 80  batch: 7  loss: 0.47325230\n",
      "epoch: 80  batch: 8  loss: 0.07073548\n",
      "epoch: 80  batch: 9  loss: 0.10553409\n",
      "epoch: 80  batch: 10  loss: 0.84408891\n",
      "epoch: 80  batch: 11  loss: 0.28578433\n",
      "epoch: 80  batch: 12  loss: 0.15706719\n",
      "epoch: 80  batch: 13  loss: 0.20954536\n",
      "epoch: 80  batch: 14  loss: 0.16333674\n",
      "epoch: 80  batch: 15  loss: 0.12889358\n",
      "epoch: 80  batch: 16  loss: 0.09523348\n",
      "epoch: 80  batch: 17  loss: 0.30494109\n",
      "epoch: 80  batch: 18  loss: 0.13056237\n",
      "epoch: 80  batch: 19  loss: 0.04875429\n",
      "epoch: 80  batch: 20  loss: 0.24837884\n",
      "epoch: 80  batch: 21  loss: 0.31058124\n",
      "epoch: 80  batch: 22  loss: 0.07092503\n",
      "epoch: 80  batch: 23  loss: 0.05263309\n",
      "epoch: 80  batch: 24  loss: 0.07266369\n",
      "epoch: 80  batch: 25  loss: 0.06575245\n",
      "epoch: 80  batch: 26  loss: 0.31740335\n",
      "epoch: 80  batch: 27  loss: 0.65548074\n",
      "epoch: 80  batch: 28  loss: 0.20561841\n",
      "epoch: 80  batch: 29  loss: 0.16126771\n",
      "epoch: 80  batch: 30  loss: 0.25467750\n",
      "epoch: 80  batch: 31  loss: 0.06393615\n",
      "epoch: 80  batch: 32  loss: 0.01721243\n",
      "epoch: 80  batch: 33  loss: 0.02205803\n",
      "epoch: 80  batch: 34  loss: 0.11234504\n",
      "epoch: 80  batch: 35  loss: 0.14824469\n",
      "epoch: 80  batch: 36  loss: 0.05169990\n",
      "epoch: 80  batch: 37  loss: 0.04486191\n",
      "epoch: 80  batch: 38  loss: 0.04477377\n",
      "epoch: 80  batch: 39  loss: 0.18080536\n",
      "epoch: 80  batch: 40  loss: 0.07250836\n",
      "epoch: 80  batch: 41  loss: 0.17421727\n",
      "epoch: 80  batch: 42  loss: 0.09956387\n",
      "epoch: 80  batch: 43  loss: 0.14245403\n",
      "epoch: 80  batch: 44  loss: 0.27512592\n",
      "epoch: 80  batch: 45  loss: 0.23527299\n",
      "epoch: 80  batch: 46  loss: 0.16053268\n",
      "epoch: 80  batch: 47  loss: 0.13142912\n",
      "epoch: 80  batch: 48  loss: 0.16968605\n",
      "epoch: 80  batch: 49  loss: 0.13293813\n",
      "epoch: 80  batch: 50  loss: 0.16818373\n",
      "epoch: 80  batch: 51  loss: 0.08565885\n",
      "epoch: 80  batch: 52  loss: 0.06145143\n",
      "epoch: 80  batch: 53  loss: 0.09281857\n",
      "epoch: 80  batch: 54  loss: 0.33586001\n",
      "epoch: 80  batch: 55  loss: 0.21418652\n",
      "epoch: 80  batch: 56  loss: 0.07800432\n",
      "epoch: 80  batch: 57  loss: 0.05873888\n",
      "epoch: 80  batch: 58  loss: 0.10329008\n",
      "epoch: 80  batch: 59  loss: 0.09838697\n",
      "epoch: 80  batch: 60  loss: 0.18650903\n",
      "epoch: 80  batch: 61  loss: 0.39797491\n",
      "epoch: 80  batch: 62  loss: 0.23898940\n",
      "epoch: 80  batch: 63  loss: 0.21454866\n",
      "epoch: 80  batch: 64  loss: 0.19344866\n",
      "epoch: 80  batch: 65  loss: 0.04084735\n",
      "epoch: 80  batch: 66  loss: 0.04199576\n",
      "epoch: 80  batch: 67  loss: 0.02962664\n",
      "epoch: 80  batch: 68  loss: 0.06610012\n",
      "epoch: 81  batch: 1  loss: 0.14183180\n",
      "epoch: 81  batch: 2  loss: 0.05022467\n",
      "epoch: 81  batch: 3  loss: 0.04913079\n",
      "epoch: 81  batch: 4  loss: 0.03570048\n",
      "epoch: 81  batch: 5  loss: 0.09711995\n",
      "epoch: 81  batch: 6  loss: 0.08757204\n",
      "epoch: 81  batch: 7  loss: 0.18921424\n",
      "epoch: 81  batch: 8  loss: 0.08985851\n",
      "epoch: 81  batch: 9  loss: 0.12556466\n",
      "epoch: 81  batch: 10  loss: 0.70774943\n",
      "epoch: 81  batch: 11  loss: 0.55140215\n",
      "epoch: 81  batch: 12  loss: 0.13736524\n",
      "epoch: 81  batch: 13  loss: 0.05238754\n",
      "epoch: 81  batch: 14  loss: 0.14710286\n",
      "epoch: 81  batch: 15  loss: 0.11929916\n",
      "epoch: 81  batch: 16  loss: 0.06717090\n",
      "epoch: 81  batch: 17  loss: 0.19892301\n",
      "epoch: 81  batch: 18  loss: 0.10567127\n",
      "epoch: 81  batch: 19  loss: 0.04283946\n",
      "epoch: 81  batch: 20  loss: 0.26435733\n",
      "epoch: 81  batch: 21  loss: 0.38705650\n",
      "epoch: 81  batch: 22  loss: 0.06866451\n",
      "epoch: 81  batch: 23  loss: 0.05642983\n",
      "epoch: 81  batch: 24  loss: 0.06804737\n",
      "epoch: 81  batch: 25  loss: 0.05253137\n",
      "epoch: 81  batch: 26  loss: 0.20372052\n",
      "epoch: 81  batch: 27  loss: 0.27472246\n",
      "epoch: 81  batch: 28  loss: 0.07244437\n",
      "epoch: 81  batch: 29  loss: 0.05048250\n",
      "epoch: 81  batch: 30  loss: 0.10781382\n",
      "epoch: 81  batch: 31  loss: 0.02988536\n",
      "epoch: 81  batch: 32  loss: 0.02589870\n",
      "epoch: 81  batch: 33  loss: 0.01184350\n",
      "epoch: 81  batch: 34  loss: 0.07360373\n",
      "epoch: 81  batch: 35  loss: 0.15071277\n",
      "epoch: 81  batch: 36  loss: 0.04414028\n",
      "epoch: 81  batch: 37  loss: 0.04803386\n",
      "epoch: 81  batch: 38  loss: 0.04409771\n",
      "epoch: 81  batch: 39  loss: 0.16865997\n",
      "epoch: 81  batch: 40  loss: 0.08274885\n",
      "epoch: 81  batch: 41  loss: 0.17004545\n",
      "epoch: 81  batch: 42  loss: 0.11970696\n",
      "epoch: 81  batch: 43  loss: 0.11313967\n",
      "epoch: 81  batch: 44  loss: 0.15748318\n",
      "epoch: 81  batch: 45  loss: 0.22104433\n",
      "epoch: 81  batch: 46  loss: 0.18887854\n",
      "epoch: 81  batch: 47  loss: 0.11656693\n",
      "epoch: 81  batch: 48  loss: 0.15757920\n",
      "epoch: 81  batch: 49  loss: 0.12974727\n",
      "epoch: 81  batch: 50  loss: 0.22541057\n",
      "epoch: 81  batch: 51  loss: 0.07982802\n",
      "epoch: 81  batch: 52  loss: 0.06714594\n",
      "epoch: 81  batch: 53  loss: 0.09188067\n",
      "epoch: 81  batch: 54  loss: 0.39072579\n",
      "epoch: 81  batch: 55  loss: 0.25229657\n",
      "epoch: 81  batch: 56  loss: 0.07889486\n",
      "epoch: 81  batch: 57  loss: 0.05063609\n",
      "epoch: 81  batch: 58  loss: 0.08977337\n",
      "epoch: 81  batch: 59  loss: 0.10171367\n",
      "epoch: 81  batch: 60  loss: 0.13833925\n",
      "epoch: 81  batch: 61  loss: 0.30959138\n",
      "epoch: 81  batch: 62  loss: 0.19493695\n",
      "epoch: 81  batch: 63  loss: 0.25908414\n",
      "epoch: 81  batch: 64  loss: 0.25752208\n",
      "epoch: 81  batch: 65  loss: 0.04932870\n",
      "epoch: 81  batch: 66  loss: 0.04048198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 81  batch: 67  loss: 0.02874660\n",
      "epoch: 81  batch: 68  loss: 0.06145630\n",
      "epoch: 82  batch: 1  loss: 0.15012902\n",
      "epoch: 82  batch: 2  loss: 0.04835812\n",
      "epoch: 82  batch: 3  loss: 0.03882504\n",
      "epoch: 82  batch: 4  loss: 0.03212027\n",
      "epoch: 82  batch: 5  loss: 0.09579392\n",
      "epoch: 82  batch: 6  loss: 0.07758556\n",
      "epoch: 82  batch: 7  loss: 0.19049670\n",
      "epoch: 82  batch: 8  loss: 0.07886288\n",
      "epoch: 82  batch: 9  loss: 0.15162693\n",
      "epoch: 82  batch: 10  loss: 0.40745911\n",
      "epoch: 82  batch: 11  loss: 0.26682037\n",
      "epoch: 82  batch: 12  loss: 0.13836026\n",
      "epoch: 82  batch: 13  loss: 0.03868630\n",
      "epoch: 82  batch: 14  loss: 0.14656870\n",
      "epoch: 82  batch: 15  loss: 0.11723915\n",
      "epoch: 82  batch: 16  loss: 0.07104494\n",
      "epoch: 82  batch: 17  loss: 0.13744043\n",
      "epoch: 82  batch: 18  loss: 0.09057812\n",
      "epoch: 82  batch: 19  loss: 0.04874758\n",
      "epoch: 82  batch: 20  loss: 0.27596691\n",
      "epoch: 82  batch: 21  loss: 0.41832021\n",
      "epoch: 82  batch: 22  loss: 0.07710996\n",
      "epoch: 82  batch: 23  loss: 0.05278356\n",
      "epoch: 82  batch: 24  loss: 0.06265204\n",
      "epoch: 82  batch: 25  loss: 0.05860116\n",
      "epoch: 82  batch: 26  loss: 0.04921015\n",
      "epoch: 82  batch: 27  loss: 0.18502168\n",
      "epoch: 82  batch: 28  loss: 0.04963247\n",
      "epoch: 82  batch: 29  loss: 0.02456308\n",
      "epoch: 82  batch: 30  loss: 0.03439052\n",
      "epoch: 82  batch: 31  loss: 0.05579919\n",
      "epoch: 82  batch: 32  loss: 0.03356704\n",
      "epoch: 82  batch: 33  loss: 0.01581591\n",
      "epoch: 82  batch: 34  loss: 0.07793193\n",
      "epoch: 82  batch: 35  loss: 0.15029083\n",
      "epoch: 82  batch: 36  loss: 0.04740506\n",
      "epoch: 82  batch: 37  loss: 0.03796109\n",
      "epoch: 82  batch: 38  loss: 0.04317707\n",
      "epoch: 82  batch: 39  loss: 0.16308486\n",
      "epoch: 82  batch: 40  loss: 0.07830510\n",
      "epoch: 82  batch: 41  loss: 0.17671317\n",
      "epoch: 82  batch: 42  loss: 0.09735313\n",
      "epoch: 82  batch: 43  loss: 0.10824828\n",
      "epoch: 82  batch: 44  loss: 0.15380834\n",
      "epoch: 82  batch: 45  loss: 0.23419495\n",
      "epoch: 82  batch: 46  loss: 0.11637767\n",
      "epoch: 82  batch: 47  loss: 0.10102773\n",
      "epoch: 82  batch: 48  loss: 0.15840359\n",
      "epoch: 82  batch: 49  loss: 0.12559485\n",
      "epoch: 82  batch: 50  loss: 0.10653640\n",
      "epoch: 82  batch: 51  loss: 0.07942130\n",
      "epoch: 82  batch: 52  loss: 0.06481590\n",
      "epoch: 82  batch: 53  loss: 0.07824226\n",
      "epoch: 82  batch: 54  loss: 0.33779326\n",
      "epoch: 82  batch: 55  loss: 0.21763614\n",
      "epoch: 82  batch: 56  loss: 0.07846847\n",
      "epoch: 82  batch: 57  loss: 0.05415202\n",
      "epoch: 82  batch: 58  loss: 0.10866804\n",
      "epoch: 82  batch: 59  loss: 0.10050176\n",
      "epoch: 82  batch: 60  loss: 0.05411059\n",
      "epoch: 82  batch: 61  loss: 0.17157650\n",
      "epoch: 82  batch: 62  loss: 0.20358692\n",
      "epoch: 82  batch: 63  loss: 0.06833826\n",
      "epoch: 82  batch: 64  loss: 0.20892535\n",
      "epoch: 82  batch: 65  loss: 0.03755747\n",
      "epoch: 82  batch: 66  loss: 0.03643097\n",
      "epoch: 82  batch: 67  loss: 0.02969366\n",
      "epoch: 82  batch: 68  loss: 0.06073271\n",
      "epoch: 83  batch: 1  loss: 0.13437076\n",
      "epoch: 83  batch: 2  loss: 0.05002676\n",
      "epoch: 83  batch: 3  loss: 0.04036367\n",
      "epoch: 83  batch: 4  loss: 0.03427375\n",
      "epoch: 83  batch: 5  loss: 0.09216744\n",
      "epoch: 83  batch: 6  loss: 0.07507032\n",
      "epoch: 83  batch: 7  loss: 0.19178461\n",
      "epoch: 83  batch: 8  loss: 0.07635014\n",
      "epoch: 83  batch: 9  loss: 0.13121703\n",
      "epoch: 83  batch: 10  loss: 0.27264372\n",
      "epoch: 83  batch: 11  loss: 0.21035396\n",
      "epoch: 83  batch: 12  loss: 0.12688039\n",
      "epoch: 83  batch: 13  loss: 0.04513421\n",
      "epoch: 83  batch: 14  loss: 0.14519069\n",
      "epoch: 83  batch: 15  loss: 0.12530315\n",
      "epoch: 83  batch: 16  loss: 0.06956978\n",
      "epoch: 83  batch: 17  loss: 0.08302822\n",
      "epoch: 83  batch: 18  loss: 0.08181756\n",
      "epoch: 83  batch: 19  loss: 0.05467964\n",
      "epoch: 83  batch: 20  loss: 0.25515467\n",
      "epoch: 83  batch: 21  loss: 0.34841597\n",
      "epoch: 83  batch: 22  loss: 0.06782100\n",
      "epoch: 83  batch: 23  loss: 0.04321966\n",
      "epoch: 83  batch: 24  loss: 0.06129003\n",
      "epoch: 83  batch: 25  loss: 0.06080030\n",
      "epoch: 83  batch: 26  loss: 0.02540810\n",
      "epoch: 83  batch: 27  loss: 0.13311465\n",
      "epoch: 83  batch: 28  loss: 0.03768237\n",
      "epoch: 83  batch: 29  loss: 0.02594601\n",
      "epoch: 83  batch: 30  loss: 0.03160504\n",
      "epoch: 83  batch: 31  loss: 0.08642057\n",
      "epoch: 83  batch: 32  loss: 0.01906224\n",
      "epoch: 83  batch: 33  loss: 0.01265512\n",
      "epoch: 83  batch: 34  loss: 0.08052419\n",
      "epoch: 83  batch: 35  loss: 0.14824452\n",
      "epoch: 83  batch: 36  loss: 0.05048665\n",
      "epoch: 83  batch: 37  loss: 0.04501532\n",
      "epoch: 83  batch: 38  loss: 0.03789850\n",
      "epoch: 83  batch: 39  loss: 0.14336486\n",
      "epoch: 83  batch: 40  loss: 0.06885567\n",
      "epoch: 83  batch: 41  loss: 0.16374004\n",
      "epoch: 83  batch: 42  loss: 0.09527560\n",
      "epoch: 83  batch: 43  loss: 0.09062625\n",
      "epoch: 83  batch: 44  loss: 0.13201782\n",
      "epoch: 83  batch: 45  loss: 0.20384204\n",
      "epoch: 83  batch: 46  loss: 0.11490570\n",
      "epoch: 83  batch: 47  loss: 0.10394223\n",
      "epoch: 83  batch: 48  loss: 0.16975313\n",
      "epoch: 83  batch: 49  loss: 0.13014561\n",
      "epoch: 83  batch: 50  loss: 0.09206543\n",
      "epoch: 83  batch: 51  loss: 0.11762207\n",
      "epoch: 83  batch: 52  loss: 0.06308229\n",
      "epoch: 83  batch: 53  loss: 0.07614753\n",
      "epoch: 83  batch: 54  loss: 0.32915455\n",
      "epoch: 83  batch: 55  loss: 0.21231413\n",
      "epoch: 83  batch: 56  loss: 0.07481865\n",
      "epoch: 83  batch: 57  loss: 0.06011993\n",
      "epoch: 83  batch: 58  loss: 0.10297955\n",
      "epoch: 83  batch: 59  loss: 0.10324843\n",
      "epoch: 83  batch: 60  loss: 0.05618326\n",
      "epoch: 83  batch: 61  loss: 0.14959221\n",
      "epoch: 83  batch: 62  loss: 0.20258974\n",
      "epoch: 83  batch: 63  loss: 0.04879197\n",
      "epoch: 83  batch: 64  loss: 0.21886753\n",
      "epoch: 83  batch: 65  loss: 0.03889692\n",
      "epoch: 83  batch: 66  loss: 0.04016713\n",
      "epoch: 83  batch: 67  loss: 0.03117444\n",
      "epoch: 83  batch: 68  loss: 0.05712327\n",
      "epoch: 84  batch: 1  loss: 0.13190061\n",
      "epoch: 84  batch: 2  loss: 0.05121456\n",
      "epoch: 84  batch: 3  loss: 0.04274390\n",
      "epoch: 84  batch: 4  loss: 0.03474587\n",
      "epoch: 84  batch: 5  loss: 0.08875117\n",
      "epoch: 84  batch: 6  loss: 0.07117187\n",
      "epoch: 84  batch: 7  loss: 0.20345256\n",
      "epoch: 84  batch: 8  loss: 0.07092959\n",
      "epoch: 84  batch: 9  loss: 0.12587933\n",
      "epoch: 84  batch: 10  loss: 0.19278647\n",
      "epoch: 84  batch: 11  loss: 0.18341494\n",
      "epoch: 84  batch: 12  loss: 0.11961884\n",
      "epoch: 84  batch: 13  loss: 0.05690969\n",
      "epoch: 84  batch: 14  loss: 0.14723778\n",
      "epoch: 84  batch: 15  loss: 0.11376338\n",
      "epoch: 84  batch: 16  loss: 0.06396669\n",
      "epoch: 84  batch: 17  loss: 0.06232914\n",
      "epoch: 84  batch: 18  loss: 0.08749432\n",
      "epoch: 84  batch: 19  loss: 0.06707667\n",
      "epoch: 84  batch: 20  loss: 0.25191823\n",
      "epoch: 84  batch: 21  loss: 0.36095387\n",
      "epoch: 84  batch: 22  loss: 0.06511629\n",
      "epoch: 84  batch: 23  loss: 0.05430963\n",
      "epoch: 84  batch: 24  loss: 0.06269420\n",
      "epoch: 84  batch: 25  loss: 0.06580466\n",
      "epoch: 84  batch: 26  loss: 0.02993018\n",
      "epoch: 84  batch: 27  loss: 0.12610334\n",
      "epoch: 84  batch: 28  loss: 0.02155079\n",
      "epoch: 84  batch: 29  loss: 0.03142773\n",
      "epoch: 84  batch: 30  loss: 0.02526145\n",
      "epoch: 84  batch: 31  loss: 0.02883465\n",
      "epoch: 84  batch: 32  loss: 0.01118397\n",
      "epoch: 84  batch: 33  loss: 0.01025015\n",
      "epoch: 84  batch: 34  loss: 0.08712638\n",
      "epoch: 84  batch: 35  loss: 0.14993443\n",
      "epoch: 84  batch: 36  loss: 0.05318927\n",
      "epoch: 84  batch: 37  loss: 0.04600428\n",
      "epoch: 84  batch: 38  loss: 0.04159159\n",
      "epoch: 84  batch: 39  loss: 0.13836102\n",
      "epoch: 84  batch: 40  loss: 0.06682102\n",
      "epoch: 84  batch: 41  loss: 0.16022725\n",
      "epoch: 84  batch: 42  loss: 0.08891962\n",
      "epoch: 84  batch: 43  loss: 0.08300768\n",
      "epoch: 84  batch: 44  loss: 0.13660592\n",
      "epoch: 84  batch: 45  loss: 0.20743765\n",
      "epoch: 84  batch: 46  loss: 0.10889819\n",
      "epoch: 84  batch: 47  loss: 0.17347889\n",
      "epoch: 84  batch: 48  loss: 0.17090714\n",
      "epoch: 84  batch: 49  loss: 0.12889403\n",
      "epoch: 84  batch: 50  loss: 0.08608466\n",
      "epoch: 84  batch: 51  loss: 0.08656579\n",
      "epoch: 84  batch: 52  loss: 0.05821374\n",
      "epoch: 84  batch: 53  loss: 0.06528984\n",
      "epoch: 84  batch: 54  loss: 0.32483602\n",
      "epoch: 84  batch: 55  loss: 0.21165891\n",
      "epoch: 84  batch: 56  loss: 0.07901188\n",
      "epoch: 84  batch: 57  loss: 0.06288130\n",
      "epoch: 84  batch: 58  loss: 0.10863387\n",
      "epoch: 84  batch: 59  loss: 0.10175730\n",
      "epoch: 84  batch: 60  loss: 0.04647481\n",
      "epoch: 84  batch: 61  loss: 0.11686777\n",
      "epoch: 84  batch: 62  loss: 0.22971971\n",
      "epoch: 84  batch: 63  loss: 0.04396339\n",
      "epoch: 84  batch: 64  loss: 0.19433238\n",
      "epoch: 84  batch: 65  loss: 0.03895377\n",
      "epoch: 84  batch: 66  loss: 0.04360121\n",
      "epoch: 84  batch: 67  loss: 0.03260519\n",
      "epoch: 84  batch: 68  loss: 0.05601712\n",
      "epoch: 85  batch: 1  loss: 0.13061224\n",
      "epoch: 85  batch: 2  loss: 0.05248320\n",
      "epoch: 85  batch: 3  loss: 0.04739064\n",
      "epoch: 85  batch: 4  loss: 0.03700390\n",
      "epoch: 85  batch: 5  loss: 0.08763428\n",
      "epoch: 85  batch: 6  loss: 0.07050799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85  batch: 7  loss: 0.18192163\n",
      "epoch: 85  batch: 8  loss: 0.06617297\n",
      "epoch: 85  batch: 9  loss: 0.10796922\n",
      "epoch: 85  batch: 10  loss: 0.17637937\n",
      "epoch: 85  batch: 11  loss: 0.16371255\n",
      "epoch: 85  batch: 12  loss: 0.11461599\n",
      "epoch: 85  batch: 13  loss: 0.04380787\n",
      "epoch: 85  batch: 14  loss: 0.15100975\n",
      "epoch: 85  batch: 15  loss: 0.11675180\n",
      "epoch: 85  batch: 16  loss: 0.07311164\n",
      "epoch: 85  batch: 17  loss: 0.05691805\n",
      "epoch: 85  batch: 18  loss: 0.08468134\n",
      "epoch: 85  batch: 19  loss: 0.04491648\n",
      "epoch: 85  batch: 20  loss: 0.24623613\n",
      "epoch: 85  batch: 21  loss: 0.32331032\n",
      "epoch: 85  batch: 22  loss: 0.07027336\n",
      "epoch: 85  batch: 23  loss: 0.04727508\n",
      "epoch: 85  batch: 24  loss: 0.06526554\n",
      "epoch: 85  batch: 25  loss: 0.06918125\n",
      "epoch: 85  batch: 26  loss: 0.02978152\n",
      "epoch: 85  batch: 27  loss: 0.06872306\n",
      "epoch: 85  batch: 28  loss: 0.05928544\n",
      "epoch: 85  batch: 29  loss: 0.02882847\n",
      "epoch: 85  batch: 30  loss: 0.01771137\n",
      "epoch: 85  batch: 31  loss: 0.02818127\n",
      "epoch: 85  batch: 32  loss: 0.02337644\n",
      "epoch: 85  batch: 33  loss: 0.00995484\n",
      "epoch: 85  batch: 34  loss: 0.08024850\n",
      "epoch: 85  batch: 35  loss: 0.14916670\n",
      "epoch: 85  batch: 36  loss: 0.05444352\n",
      "epoch: 85  batch: 37  loss: 0.04957795\n",
      "epoch: 85  batch: 38  loss: 0.04178966\n",
      "epoch: 85  batch: 39  loss: 0.12783426\n",
      "epoch: 85  batch: 40  loss: 0.07375120\n",
      "epoch: 85  batch: 41  loss: 0.16044664\n",
      "epoch: 85  batch: 42  loss: 0.07588077\n",
      "epoch: 85  batch: 43  loss: 0.08773930\n",
      "epoch: 85  batch: 44  loss: 0.12373066\n",
      "epoch: 85  batch: 45  loss: 0.19386548\n",
      "epoch: 85  batch: 46  loss: 0.13413751\n",
      "epoch: 85  batch: 47  loss: 0.11425221\n",
      "epoch: 85  batch: 48  loss: 0.17129426\n",
      "epoch: 85  batch: 49  loss: 0.13386090\n",
      "epoch: 85  batch: 50  loss: 0.07956789\n",
      "epoch: 85  batch: 51  loss: 0.07377420\n",
      "epoch: 85  batch: 52  loss: 0.05775026\n",
      "epoch: 85  batch: 53  loss: 0.06341986\n",
      "epoch: 85  batch: 54  loss: 0.31998977\n",
      "epoch: 85  batch: 55  loss: 0.21013023\n",
      "epoch: 85  batch: 56  loss: 0.08110595\n",
      "epoch: 85  batch: 57  loss: 0.06220463\n",
      "epoch: 85  batch: 58  loss: 0.10141972\n",
      "epoch: 85  batch: 59  loss: 0.10610034\n",
      "epoch: 85  batch: 60  loss: 0.04146769\n",
      "epoch: 85  batch: 61  loss: 0.12594886\n",
      "epoch: 85  batch: 62  loss: 0.17033231\n",
      "epoch: 85  batch: 63  loss: 0.03505547\n",
      "epoch: 85  batch: 64  loss: 0.19225876\n",
      "epoch: 85  batch: 65  loss: 0.03898715\n",
      "epoch: 85  batch: 66  loss: 0.03809581\n",
      "epoch: 85  batch: 67  loss: 0.03325129\n",
      "epoch: 85  batch: 68  loss: 0.05477009\n",
      "epoch: 86  batch: 1  loss: 0.12724940\n",
      "epoch: 86  batch: 2  loss: 0.05543205\n",
      "epoch: 86  batch: 3  loss: 0.04916724\n",
      "epoch: 86  batch: 4  loss: 0.03710059\n",
      "epoch: 86  batch: 5  loss: 0.08660428\n",
      "epoch: 86  batch: 6  loss: 0.06907736\n",
      "epoch: 86  batch: 7  loss: 0.19977808\n",
      "epoch: 86  batch: 8  loss: 0.06199411\n",
      "epoch: 86  batch: 9  loss: 0.10369173\n",
      "epoch: 86  batch: 10  loss: 0.17014237\n",
      "epoch: 86  batch: 11  loss: 0.14993688\n",
      "epoch: 86  batch: 12  loss: 0.11709596\n",
      "epoch: 86  batch: 13  loss: 0.04422472\n",
      "epoch: 86  batch: 14  loss: 0.15200616\n",
      "epoch: 86  batch: 15  loss: 0.11692618\n",
      "epoch: 86  batch: 16  loss: 0.06397580\n",
      "epoch: 86  batch: 17  loss: 0.07268813\n",
      "epoch: 86  batch: 18  loss: 0.08443446\n",
      "epoch: 86  batch: 19  loss: 0.04235010\n",
      "epoch: 86  batch: 20  loss: 0.24534607\n",
      "epoch: 86  batch: 21  loss: 0.30534548\n",
      "epoch: 86  batch: 22  loss: 0.07088214\n",
      "epoch: 86  batch: 23  loss: 0.04308187\n",
      "epoch: 86  batch: 24  loss: 0.06507481\n",
      "epoch: 86  batch: 25  loss: 0.05484219\n",
      "epoch: 86  batch: 26  loss: 0.02913681\n",
      "epoch: 86  batch: 27  loss: 0.06627310\n",
      "epoch: 86  batch: 28  loss: 0.02793363\n",
      "epoch: 86  batch: 29  loss: 0.03693895\n",
      "epoch: 86  batch: 30  loss: 0.01928991\n",
      "epoch: 86  batch: 31  loss: 0.03688258\n",
      "epoch: 86  batch: 32  loss: 0.01868916\n",
      "epoch: 86  batch: 33  loss: 0.00945760\n",
      "epoch: 86  batch: 34  loss: 0.08445784\n",
      "epoch: 86  batch: 35  loss: 0.14230451\n",
      "epoch: 86  batch: 36  loss: 0.05732064\n",
      "epoch: 86  batch: 37  loss: 0.04799086\n",
      "epoch: 86  batch: 38  loss: 0.04490589\n",
      "epoch: 86  batch: 39  loss: 0.12956613\n",
      "epoch: 86  batch: 40  loss: 0.06795075\n",
      "epoch: 86  batch: 41  loss: 0.15713067\n",
      "epoch: 86  batch: 42  loss: 0.07695517\n",
      "epoch: 86  batch: 43  loss: 0.08187659\n",
      "epoch: 86  batch: 44  loss: 0.12501901\n",
      "epoch: 86  batch: 45  loss: 0.19195732\n",
      "epoch: 86  batch: 46  loss: 0.09928027\n",
      "epoch: 86  batch: 47  loss: 0.11680047\n",
      "epoch: 86  batch: 48  loss: 0.17673801\n",
      "epoch: 86  batch: 49  loss: 0.13137974\n",
      "epoch: 86  batch: 50  loss: 0.07763504\n",
      "epoch: 86  batch: 51  loss: 0.07883497\n",
      "epoch: 86  batch: 52  loss: 0.06825035\n",
      "epoch: 86  batch: 53  loss: 0.06229038\n",
      "epoch: 86  batch: 54  loss: 0.31750441\n",
      "epoch: 86  batch: 55  loss: 0.20534866\n",
      "epoch: 86  batch: 56  loss: 0.07571926\n",
      "epoch: 86  batch: 57  loss: 0.06336737\n",
      "epoch: 86  batch: 58  loss: 0.10496382\n",
      "epoch: 86  batch: 59  loss: 0.11168654\n",
      "epoch: 86  batch: 60  loss: 0.03503994\n",
      "epoch: 86  batch: 61  loss: 0.11356842\n",
      "epoch: 86  batch: 62  loss: 0.22156911\n",
      "epoch: 86  batch: 63  loss: 0.05558788\n",
      "epoch: 86  batch: 64  loss: 0.16212872\n",
      "epoch: 86  batch: 65  loss: 0.03679515\n",
      "epoch: 86  batch: 66  loss: 0.03958725\n",
      "epoch: 86  batch: 67  loss: 0.03378511\n",
      "epoch: 86  batch: 68  loss: 0.05485974\n",
      "epoch: 87  batch: 1  loss: 0.12360516\n",
      "epoch: 87  batch: 2  loss: 0.05771393\n",
      "epoch: 87  batch: 3  loss: 0.05065406\n",
      "epoch: 87  batch: 4  loss: 0.03700285\n",
      "epoch: 87  batch: 5  loss: 0.08642165\n",
      "epoch: 87  batch: 6  loss: 0.06830415\n",
      "epoch: 87  batch: 7  loss: 0.17716250\n",
      "epoch: 87  batch: 8  loss: 0.06225979\n",
      "epoch: 87  batch: 9  loss: 0.10262000\n",
      "epoch: 87  batch: 10  loss: 0.16458018\n",
      "epoch: 87  batch: 11  loss: 0.16097963\n",
      "epoch: 87  batch: 12  loss: 0.10998201\n",
      "epoch: 87  batch: 13  loss: 0.05269273\n",
      "epoch: 87  batch: 14  loss: 0.15292536\n",
      "epoch: 87  batch: 15  loss: 0.11593512\n",
      "epoch: 87  batch: 16  loss: 0.07093200\n",
      "epoch: 87  batch: 17  loss: 0.05825367\n",
      "epoch: 87  batch: 18  loss: 0.09859066\n",
      "epoch: 87  batch: 19  loss: 0.08992150\n",
      "epoch: 87  batch: 20  loss: 0.24496515\n",
      "epoch: 87  batch: 21  loss: 0.30263489\n",
      "epoch: 87  batch: 22  loss: 0.06057839\n",
      "epoch: 87  batch: 23  loss: 0.05112819\n",
      "epoch: 87  batch: 24  loss: 0.06779089\n",
      "epoch: 87  batch: 25  loss: 0.06617136\n",
      "epoch: 87  batch: 26  loss: 0.04243645\n",
      "epoch: 87  batch: 27  loss: 0.08196753\n",
      "epoch: 87  batch: 28  loss: 0.05965279\n",
      "epoch: 87  batch: 29  loss: 0.03680210\n",
      "epoch: 87  batch: 30  loss: 0.02076527\n",
      "epoch: 87  batch: 31  loss: 0.06429380\n",
      "epoch: 87  batch: 32  loss: 0.01480024\n",
      "epoch: 87  batch: 33  loss: 0.00888409\n",
      "epoch: 87  batch: 34  loss: 0.08178950\n",
      "epoch: 87  batch: 35  loss: 0.14001288\n",
      "epoch: 87  batch: 36  loss: 0.05898283\n",
      "epoch: 87  batch: 37  loss: 0.04573822\n",
      "epoch: 87  batch: 38  loss: 0.04338368\n",
      "epoch: 87  batch: 39  loss: 0.13032824\n",
      "epoch: 87  batch: 40  loss: 0.08092286\n",
      "epoch: 87  batch: 41  loss: 0.16083775\n",
      "epoch: 87  batch: 42  loss: 0.07382668\n",
      "epoch: 87  batch: 43  loss: 0.08494101\n",
      "epoch: 87  batch: 44  loss: 0.12732098\n",
      "epoch: 87  batch: 45  loss: 0.18996739\n",
      "epoch: 87  batch: 46  loss: 0.11581896\n",
      "epoch: 87  batch: 47  loss: 0.12763184\n",
      "epoch: 87  batch: 48  loss: 0.17194487\n",
      "epoch: 87  batch: 49  loss: 0.13850424\n",
      "epoch: 87  batch: 50  loss: 0.08326419\n",
      "epoch: 87  batch: 51  loss: 0.07797943\n",
      "epoch: 87  batch: 52  loss: 0.05956858\n",
      "epoch: 87  batch: 53  loss: 0.07107189\n",
      "epoch: 87  batch: 54  loss: 0.32130122\n",
      "epoch: 87  batch: 55  loss: 0.20812957\n",
      "epoch: 87  batch: 56  loss: 0.08101095\n",
      "epoch: 87  batch: 57  loss: 0.06207403\n",
      "epoch: 87  batch: 58  loss: 0.10542443\n",
      "epoch: 87  batch: 59  loss: 0.10872142\n",
      "epoch: 87  batch: 60  loss: 0.03155351\n",
      "epoch: 87  batch: 61  loss: 0.12752160\n",
      "epoch: 87  batch: 62  loss: 0.24859357\n",
      "epoch: 87  batch: 63  loss: 0.04718005\n",
      "epoch: 87  batch: 64  loss: 0.12891299\n",
      "epoch: 87  batch: 65  loss: 0.03863382\n",
      "epoch: 87  batch: 66  loss: 0.05136556\n",
      "epoch: 87  batch: 67  loss: 0.03606450\n",
      "epoch: 87  batch: 68  loss: 0.07197533\n",
      "epoch: 88  batch: 1  loss: 0.12279917\n",
      "epoch: 88  batch: 2  loss: 0.05513544\n",
      "epoch: 88  batch: 3  loss: 0.05356462\n",
      "epoch: 88  batch: 4  loss: 0.03468283\n",
      "epoch: 88  batch: 5  loss: 0.08884947\n",
      "epoch: 88  batch: 6  loss: 0.07072910\n",
      "epoch: 88  batch: 7  loss: 0.29380697\n",
      "epoch: 88  batch: 8  loss: 0.06265330\n",
      "epoch: 88  batch: 9  loss: 0.10907239\n",
      "epoch: 88  batch: 10  loss: 0.15027839\n",
      "epoch: 88  batch: 11  loss: 0.13015442\n",
      "epoch: 88  batch: 12  loss: 0.13156345\n",
      "epoch: 88  batch: 13  loss: 0.07027532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 88  batch: 14  loss: 0.15714249\n",
      "epoch: 88  batch: 15  loss: 0.17061414\n",
      "epoch: 88  batch: 16  loss: 0.06653446\n",
      "epoch: 88  batch: 17  loss: 0.13066608\n",
      "epoch: 88  batch: 18  loss: 0.05267137\n",
      "epoch: 88  batch: 19  loss: 0.05386209\n",
      "epoch: 88  batch: 20  loss: 0.29953355\n",
      "epoch: 88  batch: 21  loss: 0.44955912\n",
      "epoch: 88  batch: 22  loss: 0.06209067\n",
      "epoch: 88  batch: 23  loss: 0.08433113\n",
      "epoch: 88  batch: 24  loss: 0.06893042\n",
      "epoch: 88  batch: 25  loss: 0.07770650\n",
      "epoch: 88  batch: 26  loss: 0.05086076\n",
      "epoch: 88  batch: 27  loss: 0.08442138\n",
      "epoch: 88  batch: 28  loss: 0.02111785\n",
      "epoch: 88  batch: 29  loss: 0.21756959\n",
      "epoch: 88  batch: 30  loss: 0.23597637\n",
      "epoch: 88  batch: 31  loss: 0.14091605\n",
      "epoch: 88  batch: 32  loss: 0.01529259\n",
      "epoch: 88  batch: 33  loss: 0.05275897\n",
      "epoch: 88  batch: 34  loss: 0.11302508\n",
      "epoch: 88  batch: 35  loss: 0.14611423\n",
      "epoch: 88  batch: 36  loss: 0.05315137\n",
      "epoch: 88  batch: 37  loss: 0.05956217\n",
      "epoch: 88  batch: 38  loss: 0.04181461\n",
      "epoch: 88  batch: 39  loss: 0.14353582\n",
      "epoch: 88  batch: 40  loss: 0.07046442\n",
      "epoch: 88  batch: 41  loss: 0.18312509\n",
      "epoch: 88  batch: 42  loss: 0.07573088\n",
      "epoch: 88  batch: 43  loss: 0.13613404\n",
      "epoch: 88  batch: 44  loss: 0.12982449\n",
      "epoch: 88  batch: 45  loss: 0.19715068\n",
      "epoch: 88  batch: 46  loss: 0.20252173\n",
      "epoch: 88  batch: 47  loss: 0.27879104\n",
      "epoch: 88  batch: 48  loss: 0.17048374\n",
      "epoch: 88  batch: 49  loss: 0.13163018\n",
      "epoch: 88  batch: 50  loss: 0.15914433\n",
      "epoch: 88  batch: 51  loss: 0.07916216\n",
      "epoch: 88  batch: 52  loss: 0.06063476\n",
      "epoch: 88  batch: 53  loss: 0.12677522\n",
      "epoch: 88  batch: 54  loss: 0.38821691\n",
      "epoch: 88  batch: 55  loss: 0.21187440\n",
      "epoch: 88  batch: 56  loss: 0.07727730\n",
      "epoch: 88  batch: 57  loss: 0.07610255\n",
      "epoch: 88  batch: 58  loss: 0.12421322\n",
      "epoch: 88  batch: 59  loss: 0.11365641\n",
      "epoch: 88  batch: 60  loss: 0.09260976\n",
      "epoch: 88  batch: 61  loss: 0.53360307\n",
      "epoch: 88  batch: 62  loss: 0.08212086\n",
      "epoch: 88  batch: 63  loss: 0.54128259\n",
      "epoch: 88  batch: 64  loss: 0.15488201\n",
      "epoch: 88  batch: 65  loss: 0.06389610\n",
      "epoch: 88  batch: 66  loss: 0.04829092\n",
      "epoch: 88  batch: 67  loss: 0.03161442\n",
      "epoch: 88  batch: 68  loss: 0.06034035\n",
      "epoch: 89  batch: 1  loss: 0.45564952\n",
      "epoch: 89  batch: 2  loss: 0.05381635\n",
      "epoch: 89  batch: 3  loss: 0.04541043\n",
      "epoch: 89  batch: 4  loss: 0.04507419\n",
      "epoch: 89  batch: 5  loss: 0.10082725\n",
      "epoch: 89  batch: 6  loss: 0.07279609\n",
      "epoch: 89  batch: 7  loss: 0.35624292\n",
      "epoch: 89  batch: 8  loss: 0.10577238\n",
      "epoch: 89  batch: 9  loss: 0.17941584\n",
      "epoch: 89  batch: 10  loss: 0.19864422\n",
      "epoch: 89  batch: 11  loss: 0.15182312\n",
      "epoch: 89  batch: 12  loss: 0.13523568\n",
      "epoch: 89  batch: 13  loss: 0.04688092\n",
      "epoch: 89  batch: 14  loss: 0.15372469\n",
      "epoch: 89  batch: 15  loss: 0.15887050\n",
      "epoch: 89  batch: 16  loss: 0.08833928\n",
      "epoch: 89  batch: 17  loss: 0.10792904\n",
      "epoch: 89  batch: 18  loss: 0.04683353\n",
      "epoch: 89  batch: 19  loss: 0.07043330\n",
      "epoch: 89  batch: 20  loss: 0.24536332\n",
      "epoch: 89  batch: 21  loss: 0.30136564\n",
      "epoch: 89  batch: 22  loss: 0.09780364\n",
      "epoch: 89  batch: 23  loss: 0.07354230\n",
      "epoch: 89  batch: 24  loss: 0.07708121\n",
      "epoch: 89  batch: 25  loss: 0.07688460\n",
      "epoch: 89  batch: 26  loss: 0.04260680\n",
      "epoch: 89  batch: 27  loss: 0.12899427\n",
      "epoch: 89  batch: 28  loss: 0.05882328\n",
      "epoch: 89  batch: 29  loss: 0.02719215\n",
      "epoch: 89  batch: 30  loss: 0.05820327\n",
      "epoch: 89  batch: 31  loss: 0.11836701\n",
      "epoch: 89  batch: 32  loss: 0.01360409\n",
      "epoch: 89  batch: 33  loss: 0.03877511\n",
      "epoch: 89  batch: 34  loss: 0.11102106\n",
      "epoch: 89  batch: 35  loss: 0.14824554\n",
      "epoch: 89  batch: 36  loss: 0.04693199\n",
      "epoch: 89  batch: 37  loss: 0.05676996\n",
      "epoch: 89  batch: 38  loss: 0.03834718\n",
      "epoch: 89  batch: 39  loss: 0.13920948\n",
      "epoch: 89  batch: 40  loss: 0.07084201\n",
      "epoch: 89  batch: 41  loss: 0.17845455\n",
      "epoch: 89  batch: 42  loss: 0.07319018\n",
      "epoch: 89  batch: 43  loss: 0.14407387\n",
      "epoch: 89  batch: 44  loss: 0.19334698\n",
      "epoch: 89  batch: 45  loss: 0.20941187\n",
      "epoch: 89  batch: 46  loss: 0.16749239\n",
      "epoch: 89  batch: 47  loss: 0.26673043\n",
      "epoch: 89  batch: 48  loss: 0.15568368\n",
      "epoch: 89  batch: 49  loss: 0.12788209\n",
      "epoch: 89  batch: 50  loss: 0.22012669\n",
      "epoch: 89  batch: 51  loss: 0.09881905\n",
      "epoch: 89  batch: 52  loss: 0.06414730\n",
      "epoch: 89  batch: 53  loss: 0.10707599\n",
      "epoch: 89  batch: 54  loss: 0.41023988\n",
      "epoch: 89  batch: 55  loss: 0.21857402\n",
      "epoch: 89  batch: 56  loss: 0.07975768\n",
      "epoch: 89  batch: 57  loss: 0.06060494\n",
      "epoch: 89  batch: 58  loss: 0.11558414\n",
      "epoch: 89  batch: 59  loss: 0.10322446\n",
      "epoch: 89  batch: 60  loss: 0.06251999\n",
      "epoch: 89  batch: 61  loss: 0.32413289\n",
      "epoch: 89  batch: 62  loss: 0.10219250\n",
      "epoch: 89  batch: 63  loss: 0.45461199\n",
      "epoch: 89  batch: 64  loss: 0.12649386\n",
      "epoch: 89  batch: 65  loss: 0.05108662\n",
      "epoch: 89  batch: 66  loss: 0.05031799\n",
      "epoch: 89  batch: 67  loss: 0.03636204\n",
      "epoch: 89  batch: 68  loss: 0.18429890\n",
      "epoch: 90  batch: 1  loss: 0.14719599\n",
      "epoch: 90  batch: 2  loss: 0.05220503\n",
      "epoch: 90  batch: 3  loss: 0.05086590\n",
      "epoch: 90  batch: 4  loss: 0.03714023\n",
      "epoch: 90  batch: 5  loss: 0.08933043\n",
      "epoch: 90  batch: 6  loss: 0.07455745\n",
      "epoch: 90  batch: 7  loss: 0.20794128\n",
      "epoch: 90  batch: 8  loss: 0.13400497\n",
      "epoch: 90  batch: 9  loss: 0.15838480\n",
      "epoch: 90  batch: 10  loss: 0.17317207\n",
      "epoch: 90  batch: 11  loss: 0.15912807\n",
      "epoch: 90  batch: 12  loss: 0.11902604\n",
      "epoch: 90  batch: 13  loss: 0.03699017\n",
      "epoch: 90  batch: 14  loss: 0.15370607\n",
      "epoch: 90  batch: 15  loss: 0.14703508\n",
      "epoch: 90  batch: 16  loss: 0.07848307\n",
      "epoch: 90  batch: 17  loss: 0.07647171\n",
      "epoch: 90  batch: 18  loss: 0.04557286\n",
      "epoch: 90  batch: 19  loss: 0.07278314\n",
      "epoch: 90  batch: 20  loss: 0.24647336\n",
      "epoch: 90  batch: 21  loss: 0.30006078\n",
      "epoch: 90  batch: 22  loss: 0.07016768\n",
      "epoch: 90  batch: 23  loss: 0.06745274\n",
      "epoch: 90  batch: 24  loss: 0.07514611\n",
      "epoch: 90  batch: 25  loss: 0.08037063\n",
      "epoch: 90  batch: 26  loss: 0.03827620\n",
      "epoch: 90  batch: 27  loss: 0.06923110\n",
      "epoch: 90  batch: 28  loss: 0.08898692\n",
      "epoch: 90  batch: 29  loss: 0.06359982\n",
      "epoch: 90  batch: 30  loss: 0.08030666\n",
      "epoch: 90  batch: 31  loss: 0.12903473\n",
      "epoch: 90  batch: 32  loss: 0.03304852\n",
      "epoch: 90  batch: 33  loss: 0.02774649\n",
      "epoch: 90  batch: 34  loss: 0.10819452\n",
      "epoch: 90  batch: 35  loss: 0.14978191\n",
      "epoch: 90  batch: 36  loss: 0.07486343\n",
      "epoch: 90  batch: 37  loss: 0.05085331\n",
      "epoch: 90  batch: 38  loss: 0.16609147\n",
      "epoch: 90  batch: 39  loss: 0.14236732\n",
      "epoch: 90  batch: 40  loss: 0.06806566\n",
      "epoch: 90  batch: 41  loss: 0.17593841\n",
      "epoch: 90  batch: 42  loss: 0.07564297\n",
      "epoch: 90  batch: 43  loss: 0.12312328\n",
      "epoch: 90  batch: 44  loss: 0.15631711\n",
      "epoch: 90  batch: 45  loss: 0.18197078\n",
      "epoch: 90  batch: 46  loss: 0.18569168\n",
      "epoch: 90  batch: 47  loss: 0.27210402\n",
      "epoch: 90  batch: 48  loss: 0.15723670\n",
      "epoch: 90  batch: 49  loss: 0.12647170\n",
      "epoch: 90  batch: 50  loss: 0.19103254\n",
      "epoch: 90  batch: 51  loss: 0.08069914\n",
      "epoch: 90  batch: 52  loss: 0.06871384\n",
      "epoch: 90  batch: 53  loss: 0.11006472\n",
      "epoch: 90  batch: 54  loss: 0.33202940\n",
      "epoch: 90  batch: 55  loss: 0.23485535\n",
      "epoch: 90  batch: 56  loss: 0.07354809\n",
      "epoch: 90  batch: 57  loss: 0.05819287\n",
      "epoch: 90  batch: 58  loss: 0.10784175\n",
      "epoch: 90  batch: 59  loss: 0.10490008\n",
      "epoch: 90  batch: 60  loss: 0.10672036\n",
      "epoch: 90  batch: 61  loss: 0.40275720\n",
      "epoch: 90  batch: 62  loss: 0.09076959\n",
      "epoch: 90  batch: 63  loss: 0.44613010\n",
      "epoch: 90  batch: 64  loss: 0.08192118\n",
      "epoch: 90  batch: 65  loss: 0.03887467\n",
      "epoch: 90  batch: 66  loss: 0.04732476\n",
      "epoch: 90  batch: 67  loss: 0.03552489\n",
      "epoch: 90  batch: 68  loss: 0.06115430\n",
      "epoch: 91  batch: 1  loss: 0.22055541\n",
      "epoch: 91  batch: 2  loss: 0.05406008\n",
      "epoch: 91  batch: 3  loss: 0.05537448\n",
      "epoch: 91  batch: 4  loss: 0.05493352\n",
      "epoch: 91  batch: 5  loss: 1.06907892\n",
      "epoch: 91  batch: 6  loss: 0.07285444\n",
      "epoch: 91  batch: 7  loss: 0.19219622\n",
      "epoch: 91  batch: 8  loss: 0.09725241\n",
      "epoch: 91  batch: 9  loss: 0.11291480\n",
      "epoch: 91  batch: 10  loss: 0.16605531\n",
      "epoch: 91  batch: 11  loss: 0.18988046\n",
      "epoch: 91  batch: 12  loss: 0.39855289\n",
      "epoch: 91  batch: 13  loss: 0.08378368\n",
      "epoch: 91  batch: 14  loss: 0.18332486\n",
      "epoch: 91  batch: 15  loss: 0.16436811\n",
      "epoch: 91  batch: 16  loss: 0.06887063\n",
      "epoch: 91  batch: 17  loss: 0.09496529\n",
      "epoch: 91  batch: 18  loss: 0.06469686\n",
      "epoch: 91  batch: 19  loss: 0.07640958\n",
      "epoch: 91  batch: 20  loss: 0.33372781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91  batch: 21  loss: 0.29201683\n",
      "epoch: 91  batch: 22  loss: 0.10002948\n",
      "epoch: 91  batch: 23  loss: 0.05090638\n",
      "epoch: 91  batch: 24  loss: 0.13820559\n",
      "epoch: 91  batch: 25  loss: 0.09258972\n",
      "epoch: 91  batch: 26  loss: 0.26174903\n",
      "epoch: 91  batch: 27  loss: 0.39732608\n",
      "epoch: 91  batch: 28  loss: 0.31311616\n",
      "epoch: 91  batch: 29  loss: 0.23782896\n",
      "epoch: 91  batch: 30  loss: 0.12803529\n",
      "epoch: 91  batch: 31  loss: 0.04571598\n",
      "epoch: 91  batch: 32  loss: 0.01590512\n",
      "epoch: 91  batch: 33  loss: 0.04533750\n",
      "epoch: 91  batch: 34  loss: 0.10081524\n",
      "epoch: 91  batch: 35  loss: 0.13995054\n",
      "epoch: 91  batch: 36  loss: 0.07703622\n",
      "epoch: 91  batch: 37  loss: 0.04902412\n",
      "epoch: 91  batch: 38  loss: 0.04820677\n",
      "epoch: 91  batch: 39  loss: 0.15359591\n",
      "epoch: 91  batch: 40  loss: 0.07409877\n",
      "epoch: 91  batch: 41  loss: 0.16934995\n",
      "epoch: 91  batch: 42  loss: 0.09601994\n",
      "epoch: 91  batch: 43  loss: 0.30794403\n",
      "epoch: 91  batch: 44  loss: 0.19851933\n",
      "epoch: 91  batch: 45  loss: 0.31557560\n",
      "epoch: 91  batch: 46  loss: 0.20677596\n",
      "epoch: 91  batch: 47  loss: 0.17250478\n",
      "epoch: 91  batch: 48  loss: 0.12783006\n",
      "epoch: 91  batch: 49  loss: 0.15089838\n",
      "epoch: 91  batch: 50  loss: 0.28085744\n",
      "epoch: 91  batch: 51  loss: 0.14592090\n",
      "epoch: 91  batch: 52  loss: 0.08925574\n",
      "epoch: 91  batch: 53  loss: 0.10443062\n",
      "epoch: 91  batch: 54  loss: 0.34872577\n",
      "epoch: 91  batch: 55  loss: 0.22212008\n",
      "epoch: 91  batch: 56  loss: 0.07585762\n",
      "epoch: 91  batch: 57  loss: 0.06744823\n",
      "epoch: 91  batch: 58  loss: 0.10708609\n",
      "epoch: 91  batch: 59  loss: 0.10271293\n",
      "epoch: 91  batch: 60  loss: 0.45089450\n",
      "epoch: 91  batch: 61  loss: 0.99039257\n",
      "epoch: 91  batch: 62  loss: 0.29447404\n",
      "epoch: 91  batch: 63  loss: 0.11957397\n",
      "epoch: 91  batch: 64  loss: 0.15959278\n",
      "epoch: 91  batch: 65  loss: 0.04161135\n",
      "epoch: 91  batch: 66  loss: 0.04467337\n",
      "epoch: 91  batch: 67  loss: 0.02754899\n",
      "epoch: 91  batch: 68  loss: 0.06008483\n",
      "epoch: 92  batch: 1  loss: 0.23317169\n",
      "epoch: 92  batch: 2  loss: 0.09385423\n",
      "epoch: 92  batch: 3  loss: 0.04776630\n",
      "epoch: 92  batch: 4  loss: 0.03283204\n",
      "epoch: 92  batch: 5  loss: 0.13275973\n",
      "epoch: 92  batch: 6  loss: 0.22929756\n",
      "epoch: 92  batch: 7  loss: 0.20615628\n",
      "epoch: 92  batch: 8  loss: 0.10655073\n",
      "epoch: 92  batch: 9  loss: 0.19502454\n",
      "epoch: 92  batch: 10  loss: 0.57870698\n",
      "epoch: 92  batch: 11  loss: 0.51684099\n",
      "epoch: 92  batch: 12  loss: 0.15628769\n",
      "epoch: 92  batch: 13  loss: 0.27754641\n",
      "epoch: 92  batch: 14  loss: 0.18978603\n",
      "epoch: 92  batch: 15  loss: 0.12269797\n",
      "epoch: 92  batch: 16  loss: 0.07611242\n",
      "epoch: 92  batch: 17  loss: 0.16127466\n",
      "epoch: 92  batch: 18  loss: 0.05025001\n",
      "epoch: 92  batch: 19  loss: 0.05431730\n",
      "epoch: 92  batch: 20  loss: 0.26081944\n",
      "epoch: 92  batch: 21  loss: 0.30223480\n",
      "epoch: 92  batch: 22  loss: 0.06183636\n",
      "epoch: 92  batch: 23  loss: 0.04768629\n",
      "epoch: 92  batch: 24  loss: 0.08961608\n",
      "epoch: 92  batch: 25  loss: 0.08429182\n",
      "epoch: 92  batch: 26  loss: 0.18814747\n",
      "epoch: 92  batch: 27  loss: 0.47093761\n",
      "epoch: 92  batch: 28  loss: 0.29554725\n",
      "epoch: 92  batch: 29  loss: 0.18017676\n",
      "epoch: 92  batch: 30  loss: 0.11397114\n",
      "epoch: 92  batch: 31  loss: 0.05696652\n",
      "epoch: 92  batch: 32  loss: 0.01951179\n",
      "epoch: 92  batch: 33  loss: 0.03532736\n",
      "epoch: 92  batch: 34  loss: 0.09725641\n",
      "epoch: 92  batch: 35  loss: 0.14307393\n",
      "epoch: 92  batch: 36  loss: 0.06237907\n",
      "epoch: 92  batch: 37  loss: 0.04820733\n",
      "epoch: 92  batch: 38  loss: 0.04955453\n",
      "epoch: 92  batch: 39  loss: 0.15220426\n",
      "epoch: 92  batch: 40  loss: 0.07927562\n",
      "epoch: 92  batch: 41  loss: 0.18195297\n",
      "epoch: 92  batch: 42  loss: 0.09332207\n",
      "epoch: 92  batch: 43  loss: 0.21052614\n",
      "epoch: 92  batch: 44  loss: 0.22045837\n",
      "epoch: 92  batch: 45  loss: 0.29672465\n",
      "epoch: 92  batch: 46  loss: 0.16376840\n",
      "epoch: 92  batch: 47  loss: 0.14376566\n",
      "epoch: 92  batch: 48  loss: 0.14617527\n",
      "epoch: 92  batch: 49  loss: 0.14183982\n",
      "epoch: 92  batch: 50  loss: 0.24650247\n",
      "epoch: 92  batch: 51  loss: 0.10388739\n",
      "epoch: 92  batch: 52  loss: 0.06865607\n",
      "epoch: 92  batch: 53  loss: 0.06733157\n",
      "epoch: 92  batch: 54  loss: 0.34833488\n",
      "epoch: 92  batch: 55  loss: 0.22681987\n",
      "epoch: 92  batch: 56  loss: 0.07724515\n",
      "epoch: 92  batch: 57  loss: 0.05715404\n",
      "epoch: 92  batch: 58  loss: 0.11606978\n",
      "epoch: 92  batch: 59  loss: 0.09594668\n",
      "epoch: 92  batch: 60  loss: 0.36789528\n",
      "epoch: 92  batch: 61  loss: 0.92349941\n",
      "epoch: 92  batch: 62  loss: 0.25968742\n",
      "epoch: 92  batch: 63  loss: 0.14446850\n",
      "epoch: 92  batch: 64  loss: 0.12290627\n",
      "epoch: 92  batch: 65  loss: 0.04624069\n",
      "epoch: 92  batch: 66  loss: 0.04375694\n",
      "epoch: 92  batch: 67  loss: 0.03855759\n",
      "epoch: 92  batch: 68  loss: 0.06055943\n",
      "epoch: 93  batch: 1  loss: 0.17796314\n",
      "epoch: 93  batch: 2  loss: 0.07217459\n",
      "epoch: 93  batch: 3  loss: 0.04606050\n",
      "epoch: 93  batch: 4  loss: 0.03267535\n",
      "epoch: 93  batch: 5  loss: 0.13106367\n",
      "epoch: 93  batch: 6  loss: 0.21003936\n",
      "epoch: 93  batch: 7  loss: 0.22634897\n",
      "epoch: 93  batch: 8  loss: 0.10809767\n",
      "epoch: 93  batch: 9  loss: 0.12665986\n",
      "epoch: 93  batch: 10  loss: 0.58385772\n",
      "epoch: 93  batch: 11  loss: 0.42547557\n",
      "epoch: 93  batch: 12  loss: 0.14166656\n",
      "epoch: 93  batch: 13  loss: 0.23478365\n",
      "epoch: 93  batch: 14  loss: 0.17760500\n",
      "epoch: 93  batch: 15  loss: 0.11650705\n",
      "epoch: 93  batch: 16  loss: 0.06303069\n",
      "epoch: 93  batch: 17  loss: 0.11035859\n",
      "epoch: 93  batch: 18  loss: 0.05626737\n",
      "epoch: 93  batch: 19  loss: 0.04806582\n",
      "epoch: 93  batch: 20  loss: 0.29574123\n",
      "epoch: 93  batch: 21  loss: 0.30239868\n",
      "epoch: 93  batch: 22  loss: 0.07132326\n",
      "epoch: 93  batch: 23  loss: 0.04703865\n",
      "epoch: 93  batch: 24  loss: 0.08013168\n",
      "epoch: 93  batch: 25  loss: 0.07826659\n",
      "epoch: 93  batch: 26  loss: 0.13560601\n",
      "epoch: 93  batch: 27  loss: 0.40509784\n",
      "epoch: 93  batch: 28  loss: 0.21915339\n",
      "epoch: 93  batch: 29  loss: 0.14486769\n",
      "epoch: 93  batch: 30  loss: 0.11180288\n",
      "epoch: 93  batch: 31  loss: 0.04348296\n",
      "epoch: 93  batch: 32  loss: 0.02705421\n",
      "epoch: 93  batch: 33  loss: 0.03910148\n",
      "epoch: 93  batch: 34  loss: 0.10126485\n",
      "epoch: 93  batch: 35  loss: 0.14324695\n",
      "epoch: 93  batch: 36  loss: 0.05906300\n",
      "epoch: 93  batch: 37  loss: 0.04528907\n",
      "epoch: 93  batch: 38  loss: 0.05152272\n",
      "epoch: 93  batch: 39  loss: 0.15047714\n",
      "epoch: 93  batch: 40  loss: 0.07546359\n",
      "epoch: 93  batch: 41  loss: 0.18215129\n",
      "epoch: 93  batch: 42  loss: 0.08967026\n",
      "epoch: 93  batch: 43  loss: 0.18874927\n",
      "epoch: 93  batch: 44  loss: 0.22189294\n",
      "epoch: 93  batch: 45  loss: 0.26642627\n",
      "epoch: 93  batch: 46  loss: 0.15153183\n",
      "epoch: 93  batch: 47  loss: 0.12317845\n",
      "epoch: 93  batch: 48  loss: 0.13715795\n",
      "epoch: 93  batch: 49  loss: 0.13702899\n",
      "epoch: 93  batch: 50  loss: 0.23554540\n",
      "epoch: 93  batch: 51  loss: 0.09336759\n",
      "epoch: 93  batch: 52  loss: 0.07879546\n",
      "epoch: 93  batch: 53  loss: 0.07528166\n",
      "epoch: 93  batch: 54  loss: 0.34461182\n",
      "epoch: 93  batch: 55  loss: 0.22466321\n",
      "epoch: 93  batch: 56  loss: 0.07969207\n",
      "epoch: 93  batch: 57  loss: 0.05731000\n",
      "epoch: 93  batch: 58  loss: 0.11730246\n",
      "epoch: 93  batch: 59  loss: 0.09817736\n",
      "epoch: 93  batch: 60  loss: 0.34715793\n",
      "epoch: 93  batch: 61  loss: 0.89110017\n",
      "epoch: 93  batch: 62  loss: 0.24376738\n",
      "epoch: 93  batch: 63  loss: 0.15548086\n",
      "epoch: 93  batch: 64  loss: 0.12525086\n",
      "epoch: 93  batch: 65  loss: 0.04532520\n",
      "epoch: 93  batch: 66  loss: 0.04579243\n",
      "epoch: 93  batch: 67  loss: 0.04099854\n",
      "epoch: 93  batch: 68  loss: 0.06144373\n",
      "epoch: 94  batch: 1  loss: 0.17736717\n",
      "epoch: 94  batch: 2  loss: 0.07060680\n",
      "epoch: 94  batch: 3  loss: 0.04348686\n",
      "epoch: 94  batch: 4  loss: 0.03308839\n",
      "epoch: 94  batch: 5  loss: 0.12592702\n",
      "epoch: 94  batch: 6  loss: 0.22479452\n",
      "epoch: 94  batch: 7  loss: 0.20986596\n",
      "epoch: 94  batch: 8  loss: 0.12460665\n",
      "epoch: 94  batch: 9  loss: 0.11894660\n",
      "epoch: 94  batch: 10  loss: 0.58334422\n",
      "epoch: 94  batch: 11  loss: 0.37427345\n",
      "epoch: 94  batch: 12  loss: 0.11710271\n",
      "epoch: 94  batch: 13  loss: 0.22249189\n",
      "epoch: 94  batch: 14  loss: 0.17530040\n",
      "epoch: 94  batch: 15  loss: 0.11257171\n",
      "epoch: 94  batch: 16  loss: 0.05213880\n",
      "epoch: 94  batch: 17  loss: 0.10306277\n",
      "epoch: 94  batch: 18  loss: 0.05365294\n",
      "epoch: 94  batch: 19  loss: 0.04853711\n",
      "epoch: 94  batch: 20  loss: 0.29721427\n",
      "epoch: 94  batch: 21  loss: 0.30274823\n",
      "epoch: 94  batch: 22  loss: 0.06666761\n",
      "epoch: 94  batch: 23  loss: 0.04528153\n",
      "epoch: 94  batch: 24  loss: 0.07674712\n",
      "epoch: 94  batch: 25  loss: 0.08234067\n",
      "epoch: 94  batch: 26  loss: 0.11624991\n",
      "epoch: 94  batch: 27  loss: 0.39940348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 94  batch: 28  loss: 0.12894931\n",
      "epoch: 94  batch: 29  loss: 0.12473334\n",
      "epoch: 94  batch: 30  loss: 0.10670904\n",
      "epoch: 94  batch: 31  loss: 0.04334054\n",
      "epoch: 94  batch: 32  loss: 0.01541668\n",
      "epoch: 94  batch: 33  loss: 0.03424915\n",
      "epoch: 94  batch: 34  loss: 0.10418780\n",
      "epoch: 94  batch: 35  loss: 0.14448856\n",
      "epoch: 94  batch: 36  loss: 0.05776402\n",
      "epoch: 94  batch: 37  loss: 0.04215105\n",
      "epoch: 94  batch: 38  loss: 0.04286781\n",
      "epoch: 94  batch: 39  loss: 0.16144562\n",
      "epoch: 94  batch: 40  loss: 0.07421748\n",
      "epoch: 94  batch: 41  loss: 0.18086968\n",
      "epoch: 94  batch: 42  loss: 0.09067889\n",
      "epoch: 94  batch: 43  loss: 0.18282010\n",
      "epoch: 94  batch: 44  loss: 0.23362811\n",
      "epoch: 94  batch: 45  loss: 0.27080637\n",
      "epoch: 94  batch: 46  loss: 0.13345498\n",
      "epoch: 94  batch: 47  loss: 0.11403018\n",
      "epoch: 94  batch: 48  loss: 0.13058959\n",
      "epoch: 94  batch: 49  loss: 0.13453503\n",
      "epoch: 94  batch: 50  loss: 0.23442031\n",
      "epoch: 94  batch: 51  loss: 0.10003953\n",
      "epoch: 94  batch: 52  loss: 0.07994918\n",
      "epoch: 94  batch: 53  loss: 0.07044891\n",
      "epoch: 94  batch: 54  loss: 0.35371155\n",
      "epoch: 94  batch: 55  loss: 0.22512782\n",
      "epoch: 94  batch: 56  loss: 0.07707409\n",
      "epoch: 94  batch: 57  loss: 0.05919313\n",
      "epoch: 94  batch: 58  loss: 0.10817201\n",
      "epoch: 94  batch: 59  loss: 0.09800328\n",
      "epoch: 94  batch: 60  loss: 0.35617024\n",
      "epoch: 94  batch: 61  loss: 0.88903117\n",
      "epoch: 94  batch: 62  loss: 0.24334607\n",
      "epoch: 94  batch: 63  loss: 0.08637762\n",
      "epoch: 94  batch: 64  loss: 0.07227708\n",
      "epoch: 94  batch: 65  loss: 0.04636731\n",
      "epoch: 94  batch: 66  loss: 0.04648920\n",
      "epoch: 94  batch: 67  loss: 0.04419054\n",
      "epoch: 94  batch: 68  loss: 0.06072520\n",
      "epoch: 95  batch: 1  loss: 0.16279793\n",
      "epoch: 95  batch: 2  loss: 0.04887158\n",
      "epoch: 95  batch: 3  loss: 0.04196443\n",
      "epoch: 95  batch: 4  loss: 0.03112466\n",
      "epoch: 95  batch: 5  loss: 0.11640555\n",
      "epoch: 95  batch: 6  loss: 0.20499656\n",
      "epoch: 95  batch: 7  loss: 0.21469994\n",
      "epoch: 95  batch: 8  loss: 0.11181993\n",
      "epoch: 95  batch: 9  loss: 0.11536223\n",
      "epoch: 95  batch: 10  loss: 0.52377641\n",
      "epoch: 95  batch: 11  loss: 0.33029643\n",
      "epoch: 95  batch: 12  loss: 0.10583869\n",
      "epoch: 95  batch: 13  loss: 0.20815116\n",
      "epoch: 95  batch: 14  loss: 0.16731416\n",
      "epoch: 95  batch: 15  loss: 0.11251853\n",
      "epoch: 95  batch: 16  loss: 0.04517908\n",
      "epoch: 95  batch: 17  loss: 0.09821217\n",
      "epoch: 95  batch: 18  loss: 0.05024366\n",
      "epoch: 95  batch: 19  loss: 0.04937759\n",
      "epoch: 95  batch: 20  loss: 0.31500906\n",
      "epoch: 95  batch: 21  loss: 0.30355510\n",
      "epoch: 95  batch: 22  loss: 0.06158065\n",
      "epoch: 95  batch: 23  loss: 0.04886066\n",
      "epoch: 95  batch: 24  loss: 0.07213065\n",
      "epoch: 95  batch: 25  loss: 0.07779299\n",
      "epoch: 95  batch: 26  loss: 0.07719870\n",
      "epoch: 95  batch: 27  loss: 0.32864821\n",
      "epoch: 95  batch: 28  loss: 0.09273757\n",
      "epoch: 95  batch: 29  loss: 0.11455806\n",
      "epoch: 95  batch: 30  loss: 0.07810497\n",
      "epoch: 95  batch: 31  loss: 0.03444259\n",
      "epoch: 95  batch: 32  loss: 0.01675866\n",
      "epoch: 95  batch: 33  loss: 0.04452383\n",
      "epoch: 95  batch: 34  loss: 0.10314933\n",
      "epoch: 95  batch: 35  loss: 0.14422034\n",
      "epoch: 95  batch: 36  loss: 0.05729953\n",
      "epoch: 95  batch: 37  loss: 0.04085556\n",
      "epoch: 95  batch: 38  loss: 0.04718595\n",
      "epoch: 95  batch: 39  loss: 0.15168329\n",
      "epoch: 95  batch: 40  loss: 0.07115143\n",
      "epoch: 95  batch: 41  loss: 0.17863405\n",
      "epoch: 95  batch: 42  loss: 0.08694723\n",
      "epoch: 95  batch: 43  loss: 0.16537948\n",
      "epoch: 95  batch: 44  loss: 0.22719797\n",
      "epoch: 95  batch: 45  loss: 0.27147359\n",
      "epoch: 95  batch: 46  loss: 0.12400396\n",
      "epoch: 95  batch: 47  loss: 0.12102520\n",
      "epoch: 95  batch: 48  loss: 0.13684025\n",
      "epoch: 95  batch: 49  loss: 0.12879412\n",
      "epoch: 95  batch: 50  loss: 0.23282836\n",
      "epoch: 95  batch: 51  loss: 0.08411536\n",
      "epoch: 95  batch: 52  loss: 0.08095589\n",
      "epoch: 95  batch: 53  loss: 0.06385836\n",
      "epoch: 95  batch: 54  loss: 0.34852475\n",
      "epoch: 95  batch: 55  loss: 0.22231880\n",
      "epoch: 95  batch: 56  loss: 0.07832793\n",
      "epoch: 95  batch: 57  loss: 0.05332530\n",
      "epoch: 95  batch: 58  loss: 0.10981037\n",
      "epoch: 95  batch: 59  loss: 0.09329095\n",
      "epoch: 95  batch: 60  loss: 0.31911764\n",
      "epoch: 95  batch: 61  loss: 0.87195200\n",
      "epoch: 95  batch: 62  loss: 0.23399727\n",
      "epoch: 95  batch: 63  loss: 0.06865378\n",
      "epoch: 95  batch: 64  loss: 0.04702806\n",
      "epoch: 95  batch: 65  loss: 0.04453317\n",
      "epoch: 95  batch: 66  loss: 0.04717164\n",
      "epoch: 95  batch: 67  loss: 0.06112606\n",
      "epoch: 95  batch: 68  loss: 0.05946925\n",
      "epoch: 96  batch: 1  loss: 0.16529462\n",
      "epoch: 96  batch: 2  loss: 0.05153408\n",
      "epoch: 96  batch: 3  loss: 0.04265181\n",
      "epoch: 96  batch: 4  loss: 0.03310851\n",
      "epoch: 96  batch: 5  loss: 0.10986943\n",
      "epoch: 96  batch: 6  loss: 0.20067978\n",
      "epoch: 96  batch: 7  loss: 0.21627070\n",
      "epoch: 96  batch: 8  loss: 0.10148946\n",
      "epoch: 96  batch: 9  loss: 0.11300839\n",
      "epoch: 96  batch: 10  loss: 0.35021439\n",
      "epoch: 96  batch: 11  loss: 0.31369832\n",
      "epoch: 96  batch: 12  loss: 0.10011243\n",
      "epoch: 96  batch: 13  loss: 0.18790203\n",
      "epoch: 96  batch: 14  loss: 0.17468709\n",
      "epoch: 96  batch: 15  loss: 0.12138331\n",
      "epoch: 96  batch: 16  loss: 0.05040743\n",
      "epoch: 96  batch: 17  loss: 0.07115098\n",
      "epoch: 96  batch: 18  loss: 0.04856142\n",
      "epoch: 96  batch: 19  loss: 0.05070210\n",
      "epoch: 96  batch: 20  loss: 0.31766415\n",
      "epoch: 96  batch: 21  loss: 0.30143797\n",
      "epoch: 96  batch: 22  loss: 0.05944412\n",
      "epoch: 96  batch: 23  loss: 0.04478869\n",
      "epoch: 96  batch: 24  loss: 0.06812651\n",
      "epoch: 96  batch: 25  loss: 0.07679007\n",
      "epoch: 96  batch: 26  loss: 0.05278186\n",
      "epoch: 96  batch: 27  loss: 0.25096005\n",
      "epoch: 96  batch: 28  loss: 0.04509433\n",
      "epoch: 96  batch: 29  loss: 0.07950526\n",
      "epoch: 96  batch: 30  loss: 0.12223684\n",
      "epoch: 96  batch: 31  loss: 0.03266364\n",
      "epoch: 96  batch: 32  loss: 0.01942601\n",
      "epoch: 96  batch: 33  loss: 0.05070242\n",
      "epoch: 96  batch: 34  loss: 0.10386835\n",
      "epoch: 96  batch: 35  loss: 0.14481011\n",
      "epoch: 96  batch: 36  loss: 0.06025869\n",
      "epoch: 96  batch: 37  loss: 0.04207147\n",
      "epoch: 96  batch: 38  loss: 0.06059629\n",
      "epoch: 96  batch: 39  loss: 0.14300731\n",
      "epoch: 96  batch: 40  loss: 0.06796246\n",
      "epoch: 96  batch: 41  loss: 0.17520556\n",
      "epoch: 96  batch: 42  loss: 0.08068059\n",
      "epoch: 96  batch: 43  loss: 0.13820714\n",
      "epoch: 96  batch: 44  loss: 0.22900014\n",
      "epoch: 96  batch: 45  loss: 0.25652936\n",
      "epoch: 96  batch: 46  loss: 0.13259502\n",
      "epoch: 96  batch: 47  loss: 0.10783988\n",
      "epoch: 96  batch: 48  loss: 0.13912199\n",
      "epoch: 96  batch: 49  loss: 0.12871028\n",
      "epoch: 96  batch: 50  loss: 0.24827759\n",
      "epoch: 96  batch: 51  loss: 0.08483399\n",
      "epoch: 96  batch: 52  loss: 0.09254049\n",
      "epoch: 96  batch: 53  loss: 0.07658828\n",
      "epoch: 96  batch: 54  loss: 0.33971924\n",
      "epoch: 96  batch: 55  loss: 0.21921737\n",
      "epoch: 96  batch: 56  loss: 0.08132513\n",
      "epoch: 96  batch: 57  loss: 0.04656065\n",
      "epoch: 96  batch: 58  loss: 0.10724591\n",
      "epoch: 96  batch: 59  loss: 0.09766068\n",
      "epoch: 96  batch: 60  loss: 0.26891577\n",
      "epoch: 96  batch: 61  loss: 0.86775362\n",
      "epoch: 96  batch: 62  loss: 0.22698697\n",
      "epoch: 96  batch: 63  loss: 0.06273523\n",
      "epoch: 96  batch: 64  loss: 0.04167166\n",
      "epoch: 96  batch: 65  loss: 0.04037865\n",
      "epoch: 96  batch: 66  loss: 0.04561247\n",
      "epoch: 96  batch: 67  loss: 0.05429519\n",
      "epoch: 96  batch: 68  loss: 0.05706826\n",
      "epoch: 97  batch: 1  loss: 0.14267702\n",
      "epoch: 97  batch: 2  loss: 0.04472081\n",
      "epoch: 97  batch: 3  loss: 0.04132297\n",
      "epoch: 97  batch: 4  loss: 0.03391404\n",
      "epoch: 97  batch: 5  loss: 0.10464447\n",
      "epoch: 97  batch: 6  loss: 0.14514214\n",
      "epoch: 97  batch: 7  loss: 0.20819516\n",
      "epoch: 97  batch: 8  loss: 0.10406650\n",
      "epoch: 97  batch: 9  loss: 0.10870088\n",
      "epoch: 97  batch: 10  loss: 0.27575806\n",
      "epoch: 97  batch: 11  loss: 0.30229950\n",
      "epoch: 97  batch: 12  loss: 0.10983688\n",
      "epoch: 97  batch: 13  loss: 0.15064168\n",
      "epoch: 97  batch: 14  loss: 0.17748664\n",
      "epoch: 97  batch: 15  loss: 0.10581163\n",
      "epoch: 97  batch: 16  loss: 0.09024258\n",
      "epoch: 97  batch: 17  loss: 0.05088667\n",
      "epoch: 97  batch: 18  loss: 0.10096887\n",
      "epoch: 97  batch: 19  loss: 0.06599279\n",
      "epoch: 97  batch: 20  loss: 0.34764481\n",
      "epoch: 97  batch: 21  loss: 0.31244975\n",
      "epoch: 97  batch: 22  loss: 0.08687020\n",
      "epoch: 97  batch: 23  loss: 0.05776187\n",
      "epoch: 97  batch: 24  loss: 0.10870025\n",
      "epoch: 97  batch: 25  loss: 0.09859459\n",
      "epoch: 97  batch: 26  loss: 0.02410218\n",
      "epoch: 97  batch: 27  loss: 0.08182260\n",
      "epoch: 97  batch: 28  loss: 0.01668886\n",
      "epoch: 97  batch: 29  loss: 0.03795927\n",
      "epoch: 97  batch: 30  loss: 0.08988756\n",
      "epoch: 97  batch: 31  loss: 0.02725373\n",
      "epoch: 97  batch: 32  loss: 0.01238983\n",
      "epoch: 97  batch: 33  loss: 0.07295100\n",
      "epoch: 97  batch: 34  loss: 0.09338386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 97  batch: 35  loss: 0.14284937\n",
      "epoch: 97  batch: 36  loss: 0.05814733\n",
      "epoch: 97  batch: 37  loss: 0.04149022\n",
      "epoch: 97  batch: 38  loss: 0.05561291\n",
      "epoch: 97  batch: 39  loss: 0.14139362\n",
      "epoch: 97  batch: 40  loss: 0.06669624\n",
      "epoch: 97  batch: 41  loss: 0.17189962\n",
      "epoch: 97  batch: 42  loss: 0.08411119\n",
      "epoch: 97  batch: 43  loss: 0.14264072\n",
      "epoch: 97  batch: 44  loss: 0.22030434\n",
      "epoch: 97  batch: 45  loss: 0.24018075\n",
      "epoch: 97  batch: 46  loss: 0.11178445\n",
      "epoch: 97  batch: 47  loss: 0.09124061\n",
      "epoch: 97  batch: 48  loss: 0.13019007\n",
      "epoch: 97  batch: 49  loss: 0.12640822\n",
      "epoch: 97  batch: 50  loss: 0.21712787\n",
      "epoch: 97  batch: 51  loss: 0.07647598\n",
      "epoch: 97  batch: 52  loss: 0.08875839\n",
      "epoch: 97  batch: 53  loss: 0.05546645\n",
      "epoch: 97  batch: 54  loss: 0.33476579\n",
      "epoch: 97  batch: 55  loss: 0.21620277\n",
      "epoch: 97  batch: 56  loss: 0.07564012\n",
      "epoch: 97  batch: 57  loss: 0.04143448\n",
      "epoch: 97  batch: 58  loss: 0.11895084\n",
      "epoch: 97  batch: 59  loss: 0.08618413\n",
      "epoch: 97  batch: 60  loss: 0.16316263\n",
      "epoch: 97  batch: 61  loss: 0.78083515\n",
      "epoch: 97  batch: 62  loss: 0.18388553\n",
      "epoch: 97  batch: 63  loss: 0.04053570\n",
      "epoch: 97  batch: 64  loss: 0.03118253\n",
      "epoch: 97  batch: 65  loss: 0.03928129\n",
      "epoch: 97  batch: 66  loss: 0.04325512\n",
      "epoch: 97  batch: 67  loss: 0.03798833\n",
      "epoch: 97  batch: 68  loss: 0.05496849\n",
      "epoch: 98  batch: 1  loss: 0.13442478\n",
      "epoch: 98  batch: 2  loss: 0.04351822\n",
      "epoch: 98  batch: 3  loss: 0.04118995\n",
      "epoch: 98  batch: 4  loss: 0.03405929\n",
      "epoch: 98  batch: 5  loss: 0.09820272\n",
      "epoch: 98  batch: 6  loss: 0.10008562\n",
      "epoch: 98  batch: 7  loss: 0.20051545\n",
      "epoch: 98  batch: 8  loss: 0.09216916\n",
      "epoch: 98  batch: 9  loss: 0.10144946\n",
      "epoch: 98  batch: 10  loss: 0.24713755\n",
      "epoch: 98  batch: 11  loss: 0.28039047\n",
      "epoch: 98  batch: 12  loss: 0.09052382\n",
      "epoch: 98  batch: 13  loss: 0.16895205\n",
      "epoch: 98  batch: 14  loss: 0.16490434\n",
      "epoch: 98  batch: 15  loss: 0.10631955\n",
      "epoch: 98  batch: 16  loss: 0.07093773\n",
      "epoch: 98  batch: 17  loss: 0.05248259\n",
      "epoch: 98  batch: 18  loss: 0.07231937\n",
      "epoch: 98  batch: 19  loss: 0.05096469\n",
      "epoch: 98  batch: 20  loss: 0.31300235\n",
      "epoch: 98  batch: 21  loss: 0.30003896\n",
      "epoch: 98  batch: 22  loss: 0.07110972\n",
      "epoch: 98  batch: 23  loss: 0.04834135\n",
      "epoch: 98  batch: 24  loss: 0.09206929\n",
      "epoch: 98  batch: 25  loss: 0.09027634\n",
      "epoch: 98  batch: 26  loss: 0.02091407\n",
      "epoch: 98  batch: 27  loss: 0.09455858\n",
      "epoch: 98  batch: 28  loss: 0.01589800\n",
      "epoch: 98  batch: 29  loss: 0.03905401\n",
      "epoch: 98  batch: 30  loss: 0.05998521\n",
      "epoch: 98  batch: 31  loss: 0.02783011\n",
      "epoch: 98  batch: 32  loss: 0.01228332\n",
      "epoch: 98  batch: 33  loss: 0.05546336\n",
      "epoch: 98  batch: 34  loss: 0.09423271\n",
      "epoch: 98  batch: 35  loss: 0.14230555\n",
      "epoch: 98  batch: 36  loss: 0.05901749\n",
      "epoch: 98  batch: 37  loss: 0.04020517\n",
      "epoch: 98  batch: 38  loss: 0.04677712\n",
      "epoch: 98  batch: 39  loss: 0.13913989\n",
      "epoch: 98  batch: 40  loss: 0.06491446\n",
      "epoch: 98  batch: 41  loss: 0.17034751\n",
      "epoch: 98  batch: 42  loss: 0.08118182\n",
      "epoch: 98  batch: 43  loss: 0.13656750\n",
      "epoch: 98  batch: 44  loss: 0.20869204\n",
      "epoch: 98  batch: 45  loss: 0.22918628\n",
      "epoch: 98  batch: 46  loss: 0.11171958\n",
      "epoch: 98  batch: 47  loss: 0.09020983\n",
      "epoch: 98  batch: 48  loss: 0.13287303\n",
      "epoch: 98  batch: 49  loss: 0.12625839\n",
      "epoch: 98  batch: 50  loss: 0.22144707\n",
      "epoch: 98  batch: 51  loss: 0.07542136\n",
      "epoch: 98  batch: 52  loss: 0.08310042\n",
      "epoch: 98  batch: 53  loss: 0.05585427\n",
      "epoch: 98  batch: 54  loss: 0.33524814\n",
      "epoch: 98  batch: 55  loss: 0.21622711\n",
      "epoch: 98  batch: 56  loss: 0.07691390\n",
      "epoch: 98  batch: 57  loss: 0.04172160\n",
      "epoch: 98  batch: 58  loss: 0.11573987\n",
      "epoch: 98  batch: 59  loss: 0.08578275\n",
      "epoch: 98  batch: 60  loss: 0.16180250\n",
      "epoch: 98  batch: 61  loss: 0.79005605\n",
      "epoch: 98  batch: 62  loss: 0.19089256\n",
      "epoch: 98  batch: 63  loss: 0.04427896\n",
      "epoch: 98  batch: 64  loss: 0.03248779\n",
      "epoch: 98  batch: 65  loss: 0.03956284\n",
      "epoch: 98  batch: 66  loss: 0.04238166\n",
      "epoch: 98  batch: 67  loss: 0.03508029\n",
      "epoch: 98  batch: 68  loss: 0.05396475\n",
      "epoch: 99  batch: 1  loss: 0.13285844\n",
      "epoch: 99  batch: 2  loss: 0.04338914\n",
      "epoch: 99  batch: 3  loss: 0.04042269\n",
      "epoch: 99  batch: 4  loss: 0.03373025\n",
      "epoch: 99  batch: 5  loss: 0.09601853\n",
      "epoch: 99  batch: 6  loss: 0.09068903\n",
      "epoch: 99  batch: 7  loss: 0.19801521\n",
      "epoch: 99  batch: 8  loss: 0.08677904\n",
      "epoch: 99  batch: 9  loss: 0.09869234\n",
      "epoch: 99  batch: 10  loss: 0.23411369\n",
      "epoch: 99  batch: 11  loss: 0.27157754\n",
      "epoch: 99  batch: 12  loss: 0.08674762\n",
      "epoch: 99  batch: 13  loss: 0.17088172\n",
      "epoch: 99  batch: 14  loss: 0.16243842\n",
      "epoch: 99  batch: 15  loss: 0.10653041\n",
      "epoch: 99  batch: 16  loss: 0.06595536\n",
      "epoch: 99  batch: 17  loss: 0.05234432\n",
      "epoch: 99  batch: 18  loss: 0.06176670\n",
      "epoch: 99  batch: 19  loss: 0.04797760\n",
      "epoch: 99  batch: 20  loss: 0.30398640\n",
      "epoch: 99  batch: 21  loss: 0.29764241\n",
      "epoch: 99  batch: 22  loss: 0.06678284\n",
      "epoch: 99  batch: 23  loss: 0.04626067\n",
      "epoch: 99  batch: 24  loss: 0.08757257\n",
      "epoch: 99  batch: 25  loss: 0.08622153\n",
      "epoch: 99  batch: 26  loss: 0.02005955\n",
      "epoch: 99  batch: 27  loss: 0.09533335\n",
      "epoch: 99  batch: 28  loss: 0.01615380\n",
      "epoch: 99  batch: 29  loss: 0.03496979\n",
      "epoch: 99  batch: 30  loss: 0.04053118\n",
      "epoch: 99  batch: 31  loss: 0.02770786\n",
      "epoch: 99  batch: 32  loss: 0.01230177\n",
      "epoch: 99  batch: 33  loss: 0.05031038\n",
      "epoch: 99  batch: 34  loss: 0.09433483\n",
      "epoch: 99  batch: 35  loss: 0.14219390\n",
      "epoch: 99  batch: 36  loss: 0.05926407\n",
      "epoch: 99  batch: 37  loss: 0.03991832\n",
      "epoch: 99  batch: 38  loss: 0.04361759\n",
      "epoch: 99  batch: 39  loss: 0.13883623\n",
      "epoch: 99  batch: 40  loss: 0.06434350\n",
      "epoch: 99  batch: 41  loss: 0.17015904\n",
      "epoch: 99  batch: 42  loss: 0.08008893\n",
      "epoch: 99  batch: 43  loss: 0.13473091\n",
      "epoch: 99  batch: 44  loss: 0.20538023\n",
      "epoch: 99  batch: 45  loss: 0.22438346\n",
      "epoch: 99  batch: 46  loss: 0.10997345\n",
      "epoch: 99  batch: 47  loss: 0.08897234\n",
      "epoch: 99  batch: 48  loss: 0.13409486\n",
      "epoch: 99  batch: 49  loss: 0.12660609\n",
      "epoch: 99  batch: 50  loss: 0.22196101\n",
      "epoch: 99  batch: 51  loss: 0.07566356\n",
      "epoch: 99  batch: 52  loss: 0.08203354\n",
      "epoch: 99  batch: 53  loss: 0.05602306\n",
      "epoch: 99  batch: 54  loss: 0.33557430\n",
      "epoch: 99  batch: 55  loss: 0.21615121\n",
      "epoch: 99  batch: 56  loss: 0.07743856\n",
      "epoch: 99  batch: 57  loss: 0.04194085\n",
      "epoch: 99  batch: 58  loss: 0.11488794\n",
      "epoch: 99  batch: 59  loss: 0.08564451\n",
      "epoch: 99  batch: 60  loss: 0.15521869\n",
      "epoch: 99  batch: 61  loss: 0.78969175\n",
      "epoch: 99  batch: 62  loss: 0.19265871\n",
      "epoch: 99  batch: 63  loss: 0.04414798\n",
      "epoch: 99  batch: 64  loss: 0.03215574\n",
      "epoch: 99  batch: 65  loss: 0.03992845\n",
      "epoch: 99  batch: 66  loss: 0.04207481\n",
      "epoch: 99  batch: 67  loss: 0.03425610\n",
      "epoch: 99  batch: 68  loss: 0.05348788\n",
      "epoch: 100  batch: 1  loss: 0.13222942\n",
      "epoch: 100  batch: 2  loss: 0.04343583\n",
      "epoch: 100  batch: 3  loss: 0.03982864\n",
      "epoch: 100  batch: 4  loss: 0.03362959\n",
      "epoch: 100  batch: 5  loss: 0.09496619\n",
      "epoch: 100  batch: 6  loss: 0.08904605\n",
      "epoch: 100  batch: 7  loss: 0.19714187\n",
      "epoch: 100  batch: 8  loss: 0.08375243\n",
      "epoch: 100  batch: 9  loss: 0.09697863\n",
      "epoch: 100  batch: 10  loss: 0.22793874\n",
      "epoch: 100  batch: 11  loss: 0.26764733\n",
      "epoch: 100  batch: 12  loss: 0.08478189\n",
      "epoch: 100  batch: 13  loss: 0.16826263\n",
      "epoch: 100  batch: 14  loss: 0.16126557\n",
      "epoch: 100  batch: 15  loss: 0.10664538\n",
      "epoch: 100  batch: 16  loss: 0.06417961\n",
      "epoch: 100  batch: 17  loss: 0.05212328\n",
      "epoch: 100  batch: 18  loss: 0.05612933\n",
      "epoch: 100  batch: 19  loss: 0.04722644\n",
      "epoch: 100  batch: 20  loss: 0.30150372\n",
      "epoch: 100  batch: 21  loss: 0.29668665\n",
      "epoch: 100  batch: 22  loss: 0.06480286\n",
      "epoch: 100  batch: 23  loss: 0.04534676\n",
      "epoch: 100  batch: 24  loss: 0.08519346\n",
      "epoch: 100  batch: 25  loss: 0.08381731\n",
      "epoch: 100  batch: 26  loss: 0.01944195\n",
      "epoch: 100  batch: 27  loss: 0.09367962\n",
      "epoch: 100  batch: 28  loss: 0.01641358\n",
      "epoch: 100  batch: 29  loss: 0.03069035\n",
      "epoch: 100  batch: 30  loss: 0.03166560\n",
      "epoch: 100  batch: 31  loss: 0.02748370\n",
      "epoch: 100  batch: 32  loss: 0.01226281\n",
      "epoch: 100  batch: 33  loss: 0.04856354\n",
      "epoch: 100  batch: 34  loss: 0.09436680\n",
      "epoch: 100  batch: 35  loss: 0.14214112\n",
      "epoch: 100  batch: 36  loss: 0.05941632\n",
      "epoch: 100  batch: 37  loss: 0.03974930\n",
      "epoch: 100  batch: 38  loss: 0.04201173\n",
      "epoch: 100  batch: 39  loss: 0.13852453\n",
      "epoch: 100  batch: 40  loss: 0.06406189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100  batch: 41  loss: 0.17005658\n",
      "epoch: 100  batch: 42  loss: 0.07939699\n",
      "epoch: 100  batch: 43  loss: 0.13372637\n",
      "epoch: 100  batch: 44  loss: 0.20412980\n",
      "epoch: 100  batch: 45  loss: 0.22109894\n",
      "epoch: 100  batch: 46  loss: 0.10821671\n",
      "epoch: 100  batch: 47  loss: 0.08783097\n",
      "epoch: 100  batch: 48  loss: 0.13494737\n",
      "epoch: 100  batch: 49  loss: 0.12695356\n",
      "epoch: 100  batch: 50  loss: 0.22140965\n",
      "epoch: 100  batch: 51  loss: 0.07602966\n",
      "epoch: 100  batch: 52  loss: 0.08208172\n",
      "epoch: 100  batch: 53  loss: 0.05615015\n",
      "epoch: 100  batch: 54  loss: 0.33559445\n",
      "epoch: 100  batch: 55  loss: 0.21592306\n",
      "epoch: 100  batch: 56  loss: 0.07776849\n",
      "epoch: 100  batch: 57  loss: 0.04199324\n",
      "epoch: 100  batch: 58  loss: 0.11466309\n",
      "epoch: 100  batch: 59  loss: 0.08568795\n",
      "epoch: 100  batch: 60  loss: 0.14781746\n",
      "epoch: 100  batch: 61  loss: 0.78612554\n",
      "epoch: 100  batch: 62  loss: 0.19237180\n",
      "epoch: 100  batch: 63  loss: 0.04330532\n",
      "epoch: 100  batch: 64  loss: 0.03140552\n",
      "epoch: 100  batch: 65  loss: 0.04020394\n",
      "epoch: 100  batch: 66  loss: 0.04191232\n",
      "epoch: 100  batch: 67  loss: 0.03393060\n",
      "epoch: 100  batch: 68  loss: 0.05312161\n",
      "epoch: 101  batch: 1  loss: 0.13182086\n",
      "epoch: 101  batch: 2  loss: 0.04349433\n",
      "epoch: 101  batch: 3  loss: 0.03931346\n",
      "epoch: 101  batch: 4  loss: 0.03357670\n",
      "epoch: 101  batch: 5  loss: 0.09419893\n",
      "epoch: 101  batch: 6  loss: 0.08785579\n",
      "epoch: 101  batch: 7  loss: 0.19655180\n",
      "epoch: 101  batch: 8  loss: 0.08164428\n",
      "epoch: 101  batch: 9  loss: 0.09558228\n",
      "epoch: 101  batch: 10  loss: 0.22342293\n",
      "epoch: 101  batch: 11  loss: 0.26492250\n",
      "epoch: 101  batch: 12  loss: 0.08344263\n",
      "epoch: 101  batch: 13  loss: 0.16401085\n",
      "epoch: 101  batch: 14  loss: 0.16051470\n",
      "epoch: 101  batch: 15  loss: 0.10681102\n",
      "epoch: 101  batch: 16  loss: 0.06340283\n",
      "epoch: 101  batch: 17  loss: 0.05173538\n",
      "epoch: 101  batch: 18  loss: 0.05232490\n",
      "epoch: 101  batch: 19  loss: 0.04698021\n",
      "epoch: 101  batch: 20  loss: 0.30063349\n",
      "epoch: 101  batch: 21  loss: 0.29592299\n",
      "epoch: 101  batch: 22  loss: 0.06347146\n",
      "epoch: 101  batch: 23  loss: 0.04477143\n",
      "epoch: 101  batch: 24  loss: 0.08343632\n",
      "epoch: 101  batch: 25  loss: 0.08221789\n",
      "epoch: 101  batch: 26  loss: 0.01900213\n",
      "epoch: 101  batch: 27  loss: 0.09153290\n",
      "epoch: 101  batch: 28  loss: 0.01655566\n",
      "epoch: 101  batch: 29  loss: 0.02681135\n",
      "epoch: 101  batch: 30  loss: 0.02671589\n",
      "epoch: 101  batch: 31  loss: 0.02729752\n",
      "epoch: 101  batch: 32  loss: 0.01221749\n",
      "epoch: 101  batch: 33  loss: 0.04737485\n",
      "epoch: 101  batch: 34  loss: 0.09440730\n",
      "epoch: 101  batch: 35  loss: 0.14205401\n",
      "epoch: 101  batch: 36  loss: 0.05960094\n",
      "epoch: 101  batch: 37  loss: 0.03961802\n",
      "epoch: 101  batch: 38  loss: 0.04107396\n",
      "epoch: 101  batch: 39  loss: 0.13806133\n",
      "epoch: 101  batch: 40  loss: 0.06388913\n",
      "epoch: 101  batch: 41  loss: 0.16989622\n",
      "epoch: 101  batch: 42  loss: 0.07882850\n",
      "epoch: 101  batch: 43  loss: 0.13291728\n",
      "epoch: 101  batch: 44  loss: 0.20342661\n",
      "epoch: 101  batch: 45  loss: 0.21812715\n",
      "epoch: 101  batch: 46  loss: 0.10666218\n",
      "epoch: 101  batch: 47  loss: 0.08678012\n",
      "epoch: 101  batch: 48  loss: 0.13573056\n",
      "epoch: 101  batch: 49  loss: 0.12721860\n",
      "epoch: 101  batch: 50  loss: 0.22012092\n",
      "epoch: 101  batch: 51  loss: 0.07626702\n",
      "epoch: 101  batch: 52  loss: 0.08247732\n",
      "epoch: 101  batch: 53  loss: 0.05628720\n",
      "epoch: 101  batch: 54  loss: 0.33542973\n",
      "epoch: 101  batch: 55  loss: 0.21551618\n",
      "epoch: 101  batch: 56  loss: 0.07799229\n",
      "epoch: 101  batch: 57  loss: 0.04192032\n",
      "epoch: 101  batch: 58  loss: 0.11458357\n",
      "epoch: 101  batch: 59  loss: 0.08583028\n",
      "epoch: 101  batch: 60  loss: 0.14036644\n",
      "epoch: 101  batch: 61  loss: 0.78092730\n",
      "epoch: 101  batch: 62  loss: 0.19088131\n",
      "epoch: 101  batch: 63  loss: 0.04211070\n",
      "epoch: 101  batch: 64  loss: 0.03053144\n",
      "epoch: 101  batch: 65  loss: 0.04036096\n",
      "epoch: 101  batch: 66  loss: 0.04178324\n",
      "epoch: 101  batch: 67  loss: 0.03378025\n",
      "epoch: 101  batch: 68  loss: 0.05282253\n",
      "epoch: 102  batch: 1  loss: 0.13151808\n",
      "epoch: 102  batch: 2  loss: 0.04351655\n",
      "epoch: 102  batch: 3  loss: 0.03887281\n",
      "epoch: 102  batch: 4  loss: 0.03355423\n",
      "epoch: 102  batch: 5  loss: 0.09356641\n",
      "epoch: 102  batch: 6  loss: 0.08680325\n",
      "epoch: 102  batch: 7  loss: 0.19603187\n",
      "epoch: 102  batch: 8  loss: 0.07999048\n",
      "epoch: 102  batch: 9  loss: 0.09434478\n",
      "epoch: 102  batch: 10  loss: 0.21959820\n",
      "epoch: 102  batch: 11  loss: 0.26265767\n",
      "epoch: 102  batch: 12  loss: 0.08243100\n",
      "epoch: 102  batch: 13  loss: 0.15897457\n",
      "epoch: 102  batch: 14  loss: 0.15984701\n",
      "epoch: 102  batch: 15  loss: 0.10704842\n",
      "epoch: 102  batch: 16  loss: 0.06294382\n",
      "epoch: 102  batch: 17  loss: 0.05137433\n",
      "epoch: 102  batch: 18  loss: 0.04962632\n",
      "epoch: 102  batch: 19  loss: 0.04688669\n",
      "epoch: 102  batch: 20  loss: 0.29983488\n",
      "epoch: 102  batch: 21  loss: 0.29520613\n",
      "epoch: 102  batch: 22  loss: 0.06240911\n",
      "epoch: 102  batch: 23  loss: 0.04436890\n",
      "epoch: 102  batch: 24  loss: 0.08212540\n",
      "epoch: 102  batch: 25  loss: 0.08104184\n",
      "epoch: 102  batch: 26  loss: 0.01868576\n",
      "epoch: 102  batch: 27  loss: 0.08928365\n",
      "epoch: 102  batch: 28  loss: 0.01658392\n",
      "epoch: 102  batch: 29  loss: 0.02355526\n",
      "epoch: 102  batch: 30  loss: 0.02372237\n",
      "epoch: 102  batch: 31  loss: 0.02714363\n",
      "epoch: 102  batch: 32  loss: 0.01215174\n",
      "epoch: 102  batch: 33  loss: 0.04633675\n",
      "epoch: 102  batch: 34  loss: 0.09439384\n",
      "epoch: 102  batch: 35  loss: 0.14195730\n",
      "epoch: 102  batch: 36  loss: 0.05981459\n",
      "epoch: 102  batch: 37  loss: 0.03950170\n",
      "epoch: 102  batch: 38  loss: 0.04044458\n",
      "epoch: 102  batch: 39  loss: 0.13754445\n",
      "epoch: 102  batch: 40  loss: 0.06374720\n",
      "epoch: 102  batch: 41  loss: 0.16967270\n",
      "epoch: 102  batch: 42  loss: 0.07827596\n",
      "epoch: 102  batch: 43  loss: 0.13217197\n",
      "epoch: 102  batch: 44  loss: 0.20277062\n",
      "epoch: 102  batch: 45  loss: 0.21545535\n",
      "epoch: 102  batch: 46  loss: 0.10528273\n",
      "epoch: 102  batch: 47  loss: 0.08590645\n",
      "epoch: 102  batch: 48  loss: 0.13625325\n",
      "epoch: 102  batch: 49  loss: 0.12740606\n",
      "epoch: 102  batch: 50  loss: 0.21808705\n",
      "epoch: 102  batch: 51  loss: 0.07640297\n",
      "epoch: 102  batch: 52  loss: 0.08298338\n",
      "epoch: 102  batch: 53  loss: 0.05641664\n",
      "epoch: 102  batch: 54  loss: 0.33511624\n",
      "epoch: 102  batch: 55  loss: 0.21494196\n",
      "epoch: 102  batch: 56  loss: 0.07819270\n",
      "epoch: 102  batch: 57  loss: 0.04177774\n",
      "epoch: 102  batch: 58  loss: 0.11458901\n",
      "epoch: 102  batch: 59  loss: 0.08605625\n",
      "epoch: 102  batch: 60  loss: 0.13273326\n",
      "epoch: 102  batch: 61  loss: 0.77392697\n",
      "epoch: 102  batch: 62  loss: 0.18854108\n",
      "epoch: 102  batch: 63  loss: 0.04059957\n",
      "epoch: 102  batch: 64  loss: 0.02960934\n",
      "epoch: 102  batch: 65  loss: 0.04049101\n",
      "epoch: 102  batch: 66  loss: 0.04164889\n",
      "epoch: 102  batch: 67  loss: 0.03369261\n",
      "epoch: 102  batch: 68  loss: 0.05258260\n",
      "epoch: 103  batch: 1  loss: 0.13129921\n",
      "epoch: 103  batch: 2  loss: 0.04353878\n",
      "epoch: 103  batch: 3  loss: 0.03846181\n",
      "epoch: 103  batch: 4  loss: 0.03356751\n",
      "epoch: 103  batch: 5  loss: 0.09302811\n",
      "epoch: 103  batch: 6  loss: 0.08585273\n",
      "epoch: 103  batch: 7  loss: 0.19558950\n",
      "epoch: 103  batch: 8  loss: 0.07862525\n",
      "epoch: 103  batch: 9  loss: 0.09321065\n",
      "epoch: 103  batch: 10  loss: 0.21633504\n",
      "epoch: 103  batch: 11  loss: 0.26046070\n",
      "epoch: 103  batch: 12  loss: 0.08159022\n",
      "epoch: 103  batch: 13  loss: 0.15343674\n",
      "epoch: 103  batch: 14  loss: 0.15933344\n",
      "epoch: 103  batch: 15  loss: 0.10729570\n",
      "epoch: 103  batch: 16  loss: 0.06272069\n",
      "epoch: 103  batch: 17  loss: 0.05109320\n",
      "epoch: 103  batch: 18  loss: 0.04776946\n",
      "epoch: 103  batch: 19  loss: 0.04692267\n",
      "epoch: 103  batch: 20  loss: 0.29901519\n",
      "epoch: 103  batch: 21  loss: 0.29443279\n",
      "epoch: 103  batch: 22  loss: 0.06151524\n",
      "epoch: 103  batch: 23  loss: 0.04401100\n",
      "epoch: 103  batch: 24  loss: 0.08103503\n",
      "epoch: 103  batch: 25  loss: 0.08021394\n",
      "epoch: 103  batch: 26  loss: 0.01844268\n",
      "epoch: 103  batch: 27  loss: 0.08701345\n",
      "epoch: 103  batch: 28  loss: 0.01653117\n",
      "epoch: 103  batch: 29  loss: 0.02081014\n",
      "epoch: 103  batch: 30  loss: 0.02185206\n",
      "epoch: 103  batch: 31  loss: 0.02704697\n",
      "epoch: 103  batch: 32  loss: 0.01210609\n",
      "epoch: 103  batch: 33  loss: 0.04543065\n",
      "epoch: 103  batch: 34  loss: 0.09433179\n",
      "epoch: 103  batch: 35  loss: 0.14181048\n",
      "epoch: 103  batch: 36  loss: 0.06005769\n",
      "epoch: 103  batch: 37  loss: 0.03939526\n",
      "epoch: 103  batch: 38  loss: 0.03999430\n",
      "epoch: 103  batch: 39  loss: 0.13693292\n",
      "epoch: 103  batch: 40  loss: 0.06364770\n",
      "epoch: 103  batch: 41  loss: 0.16940236\n",
      "epoch: 103  batch: 42  loss: 0.07774613\n",
      "epoch: 103  batch: 43  loss: 0.13135771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 103  batch: 44  loss: 0.20215617\n",
      "epoch: 103  batch: 45  loss: 0.21283644\n",
      "epoch: 103  batch: 46  loss: 0.10394673\n",
      "epoch: 103  batch: 47  loss: 0.08517512\n",
      "epoch: 103  batch: 48  loss: 0.13662182\n",
      "epoch: 103  batch: 49  loss: 0.12760715\n",
      "epoch: 103  batch: 50  loss: 0.21544309\n",
      "epoch: 103  batch: 51  loss: 0.07648292\n",
      "epoch: 103  batch: 52  loss: 0.08351441\n",
      "epoch: 103  batch: 53  loss: 0.05651116\n",
      "epoch: 103  batch: 54  loss: 0.33474392\n",
      "epoch: 103  batch: 55  loss: 0.21424091\n",
      "epoch: 103  batch: 56  loss: 0.07837763\n",
      "epoch: 103  batch: 57  loss: 0.04159398\n",
      "epoch: 103  batch: 58  loss: 0.11451334\n",
      "epoch: 103  batch: 59  loss: 0.08631906\n",
      "epoch: 103  batch: 60  loss: 0.12553057\n",
      "epoch: 103  batch: 61  loss: 0.76509064\n",
      "epoch: 103  batch: 62  loss: 0.18537560\n",
      "epoch: 103  batch: 63  loss: 0.03914941\n",
      "epoch: 103  batch: 64  loss: 0.02864865\n",
      "epoch: 103  batch: 65  loss: 0.04057686\n",
      "epoch: 103  batch: 66  loss: 0.04151873\n",
      "epoch: 103  batch: 67  loss: 0.03368253\n",
      "epoch: 103  batch: 68  loss: 0.05237056\n",
      "epoch: 104  batch: 1  loss: 0.13114345\n",
      "epoch: 104  batch: 2  loss: 0.04355885\n",
      "epoch: 104  batch: 3  loss: 0.03806849\n",
      "epoch: 104  batch: 4  loss: 0.03356903\n",
      "epoch: 104  batch: 5  loss: 0.09253298\n",
      "epoch: 104  batch: 6  loss: 0.08500344\n",
      "epoch: 104  batch: 7  loss: 0.19521421\n",
      "epoch: 104  batch: 8  loss: 0.07749969\n",
      "epoch: 104  batch: 9  loss: 0.09216250\n",
      "epoch: 104  batch: 10  loss: 0.21344084\n",
      "epoch: 104  batch: 11  loss: 0.25839639\n",
      "epoch: 104  batch: 12  loss: 0.08086621\n",
      "epoch: 104  batch: 13  loss: 0.14737836\n",
      "epoch: 104  batch: 14  loss: 0.15873888\n",
      "epoch: 104  batch: 15  loss: 0.10756258\n",
      "epoch: 104  batch: 16  loss: 0.06265666\n",
      "epoch: 104  batch: 17  loss: 0.05091198\n",
      "epoch: 104  batch: 18  loss: 0.04658851\n",
      "epoch: 104  batch: 19  loss: 0.04711834\n",
      "epoch: 104  batch: 20  loss: 0.29830384\n",
      "epoch: 104  batch: 21  loss: 0.29370719\n",
      "epoch: 104  batch: 22  loss: 0.06072418\n",
      "epoch: 104  batch: 23  loss: 0.04373763\n",
      "epoch: 104  batch: 24  loss: 0.08016144\n",
      "epoch: 104  batch: 25  loss: 0.07958087\n",
      "epoch: 104  batch: 26  loss: 0.01825496\n",
      "epoch: 104  batch: 27  loss: 0.08470603\n",
      "epoch: 104  batch: 28  loss: 0.01639416\n",
      "epoch: 104  batch: 29  loss: 0.01870324\n",
      "epoch: 104  batch: 30  loss: 0.02080211\n",
      "epoch: 104  batch: 31  loss: 0.02696904\n",
      "epoch: 104  batch: 32  loss: 0.01208836\n",
      "epoch: 104  batch: 33  loss: 0.04467328\n",
      "epoch: 104  batch: 34  loss: 0.09421895\n",
      "epoch: 104  batch: 35  loss: 0.14169134\n",
      "epoch: 104  batch: 36  loss: 0.06034485\n",
      "epoch: 104  batch: 37  loss: 0.03928058\n",
      "epoch: 104  batch: 38  loss: 0.03968116\n",
      "epoch: 104  batch: 39  loss: 0.13630681\n",
      "epoch: 104  batch: 40  loss: 0.06354547\n",
      "epoch: 104  batch: 41  loss: 0.16908465\n",
      "epoch: 104  batch: 42  loss: 0.07718927\n",
      "epoch: 104  batch: 43  loss: 0.13062115\n",
      "epoch: 104  batch: 44  loss: 0.20113310\n",
      "epoch: 104  batch: 45  loss: 0.21032710\n",
      "epoch: 104  batch: 46  loss: 0.10273249\n",
      "epoch: 104  batch: 47  loss: 0.08463475\n",
      "epoch: 104  batch: 48  loss: 0.13679096\n",
      "epoch: 104  batch: 49  loss: 0.12783617\n",
      "epoch: 104  batch: 50  loss: 0.21223454\n",
      "epoch: 104  batch: 51  loss: 0.07654250\n",
      "epoch: 104  batch: 52  loss: 0.08410314\n",
      "epoch: 104  batch: 53  loss: 0.05659597\n",
      "epoch: 104  batch: 54  loss: 0.33428913\n",
      "epoch: 104  batch: 55  loss: 0.21338651\n",
      "epoch: 104  batch: 56  loss: 0.07852887\n",
      "epoch: 104  batch: 57  loss: 0.04136995\n",
      "epoch: 104  batch: 58  loss: 0.11458073\n",
      "epoch: 104  batch: 59  loss: 0.08658346\n",
      "epoch: 104  batch: 60  loss: 0.11831542\n",
      "epoch: 104  batch: 61  loss: 0.75292683\n",
      "epoch: 104  batch: 62  loss: 0.18123047\n",
      "epoch: 104  batch: 63  loss: 0.03772674\n",
      "epoch: 104  batch: 64  loss: 0.02774139\n",
      "epoch: 104  batch: 65  loss: 0.04066207\n",
      "epoch: 104  batch: 66  loss: 0.04137623\n",
      "epoch: 104  batch: 67  loss: 0.03373030\n",
      "epoch: 104  batch: 68  loss: 0.05216338\n",
      "epoch: 105  batch: 1  loss: 0.13109235\n",
      "epoch: 105  batch: 2  loss: 0.04358509\n",
      "epoch: 105  batch: 3  loss: 0.03771533\n",
      "epoch: 105  batch: 4  loss: 0.03352726\n",
      "epoch: 105  batch: 5  loss: 0.09211584\n",
      "epoch: 105  batch: 6  loss: 0.08425499\n",
      "epoch: 105  batch: 7  loss: 0.19495049\n",
      "epoch: 105  batch: 8  loss: 0.07655486\n",
      "epoch: 105  batch: 9  loss: 0.09112354\n",
      "epoch: 105  batch: 10  loss: 0.21090652\n",
      "epoch: 105  batch: 11  loss: 0.25665569\n",
      "epoch: 105  batch: 12  loss: 0.08021414\n",
      "epoch: 105  batch: 13  loss: 0.14069194\n",
      "epoch: 105  batch: 14  loss: 0.15800054\n",
      "epoch: 105  batch: 15  loss: 0.10786436\n",
      "epoch: 105  batch: 16  loss: 0.06273538\n",
      "epoch: 105  batch: 17  loss: 0.05079481\n",
      "epoch: 105  batch: 18  loss: 0.04592077\n",
      "epoch: 105  batch: 19  loss: 0.04750870\n",
      "epoch: 105  batch: 20  loss: 0.29734999\n",
      "epoch: 105  batch: 21  loss: 0.29302728\n",
      "epoch: 105  batch: 22  loss: 0.06000505\n",
      "epoch: 105  batch: 23  loss: 0.04351656\n",
      "epoch: 105  batch: 24  loss: 0.07933845\n",
      "epoch: 105  batch: 25  loss: 0.07915177\n",
      "epoch: 105  batch: 26  loss: 0.01810410\n",
      "epoch: 105  batch: 27  loss: 0.08263186\n",
      "epoch: 105  batch: 28  loss: 0.01620187\n",
      "epoch: 105  batch: 29  loss: 0.01714673\n",
      "epoch: 105  batch: 30  loss: 0.02023309\n",
      "epoch: 105  batch: 31  loss: 0.02693632\n",
      "epoch: 105  batch: 32  loss: 0.01210269\n",
      "epoch: 105  batch: 33  loss: 0.04411882\n",
      "epoch: 105  batch: 34  loss: 0.09404384\n",
      "epoch: 105  batch: 35  loss: 0.14153765\n",
      "epoch: 105  batch: 36  loss: 0.06069604\n",
      "epoch: 105  batch: 37  loss: 0.03918521\n",
      "epoch: 105  batch: 38  loss: 0.03959592\n",
      "epoch: 105  batch: 39  loss: 0.13555904\n",
      "epoch: 105  batch: 40  loss: 0.06347273\n",
      "epoch: 105  batch: 41  loss: 0.16873696\n",
      "epoch: 105  batch: 42  loss: 0.07663856\n",
      "epoch: 105  batch: 43  loss: 0.13000961\n",
      "epoch: 105  batch: 44  loss: 0.20010816\n",
      "epoch: 105  batch: 45  loss: 0.20780423\n",
      "epoch: 105  batch: 46  loss: 0.10153389\n",
      "epoch: 105  batch: 47  loss: 0.08415534\n",
      "epoch: 105  batch: 48  loss: 0.13695344\n",
      "epoch: 105  batch: 49  loss: 0.12813982\n",
      "epoch: 105  batch: 50  loss: 0.20814170\n",
      "epoch: 105  batch: 51  loss: 0.07663851\n",
      "epoch: 105  batch: 52  loss: 0.08472697\n",
      "epoch: 105  batch: 53  loss: 0.05667594\n",
      "epoch: 105  batch: 54  loss: 0.33380529\n",
      "epoch: 105  batch: 55  loss: 0.21234174\n",
      "epoch: 105  batch: 56  loss: 0.07867400\n",
      "epoch: 105  batch: 57  loss: 0.04116349\n",
      "epoch: 105  batch: 58  loss: 0.11464944\n",
      "epoch: 105  batch: 59  loss: 0.08683004\n",
      "epoch: 105  batch: 60  loss: 0.11118019\n",
      "epoch: 105  batch: 61  loss: 0.73417944\n",
      "epoch: 105  batch: 62  loss: 0.17598423\n",
      "epoch: 105  batch: 63  loss: 0.03663834\n",
      "epoch: 105  batch: 64  loss: 0.02684148\n",
      "epoch: 105  batch: 65  loss: 0.04073052\n",
      "epoch: 105  batch: 66  loss: 0.04126041\n",
      "epoch: 105  batch: 67  loss: 0.03382128\n",
      "epoch: 105  batch: 68  loss: 0.05198255\n",
      "epoch: 106  batch: 1  loss: 0.13121240\n",
      "epoch: 106  batch: 2  loss: 0.04361304\n",
      "epoch: 106  batch: 3  loss: 0.03751440\n",
      "epoch: 106  batch: 4  loss: 0.03328842\n",
      "epoch: 106  batch: 5  loss: 0.09179467\n",
      "epoch: 106  batch: 6  loss: 0.08348899\n",
      "epoch: 106  batch: 7  loss: 0.19473301\n",
      "epoch: 106  batch: 8  loss: 0.07590927\n",
      "epoch: 106  batch: 9  loss: 0.09007789\n",
      "epoch: 106  batch: 10  loss: 0.20924732\n",
      "epoch: 106  batch: 11  loss: 0.25580865\n",
      "epoch: 106  batch: 12  loss: 0.07980499\n",
      "epoch: 106  batch: 13  loss: 0.13312431\n",
      "epoch: 106  batch: 14  loss: 0.15685353\n",
      "epoch: 106  batch: 15  loss: 0.10817159\n",
      "epoch: 106  batch: 16  loss: 0.06308446\n",
      "epoch: 106  batch: 17  loss: 0.05072322\n",
      "epoch: 106  batch: 18  loss: 0.04564672\n",
      "epoch: 106  batch: 19  loss: 0.04861564\n",
      "epoch: 106  batch: 20  loss: 0.29648447\n",
      "epoch: 106  batch: 21  loss: 0.29237041\n",
      "epoch: 106  batch: 22  loss: 0.05919415\n",
      "epoch: 106  batch: 23  loss: 0.04332299\n",
      "epoch: 106  batch: 24  loss: 0.07853246\n",
      "epoch: 106  batch: 25  loss: 0.07901617\n",
      "epoch: 106  batch: 26  loss: 0.01795534\n",
      "epoch: 106  batch: 27  loss: 0.08131330\n",
      "epoch: 106  batch: 28  loss: 0.01608775\n",
      "epoch: 106  batch: 29  loss: 0.01596507\n",
      "epoch: 106  batch: 30  loss: 0.02026962\n",
      "epoch: 106  batch: 31  loss: 0.02692988\n",
      "epoch: 106  batch: 32  loss: 0.01213821\n",
      "epoch: 106  batch: 33  loss: 0.04416934\n",
      "epoch: 106  batch: 34  loss: 0.09377953\n",
      "epoch: 106  batch: 35  loss: 0.14140251\n",
      "epoch: 106  batch: 36  loss: 0.06107809\n",
      "epoch: 106  batch: 37  loss: 0.03908289\n",
      "epoch: 106  batch: 38  loss: 0.03983560\n",
      "epoch: 106  batch: 39  loss: 0.13476938\n",
      "epoch: 106  batch: 40  loss: 0.06341045\n",
      "epoch: 106  batch: 41  loss: 0.16838029\n",
      "epoch: 106  batch: 42  loss: 0.07607120\n",
      "epoch: 106  batch: 43  loss: 0.12972240\n",
      "epoch: 106  batch: 44  loss: 0.19887204\n",
      "epoch: 106  batch: 45  loss: 0.20512915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106  batch: 46  loss: 0.10032615\n",
      "epoch: 106  batch: 47  loss: 0.08367211\n",
      "epoch: 106  batch: 48  loss: 0.13759665\n",
      "epoch: 106  batch: 49  loss: 0.12851869\n",
      "epoch: 106  batch: 50  loss: 0.20282444\n",
      "epoch: 106  batch: 51  loss: 0.07686535\n",
      "epoch: 106  batch: 52  loss: 0.08548107\n",
      "epoch: 106  batch: 53  loss: 0.05704508\n",
      "epoch: 106  batch: 54  loss: 0.33322453\n",
      "epoch: 106  batch: 55  loss: 0.21078154\n",
      "epoch: 106  batch: 56  loss: 0.07889898\n",
      "epoch: 106  batch: 57  loss: 0.04101130\n",
      "epoch: 106  batch: 58  loss: 0.11530845\n",
      "epoch: 106  batch: 59  loss: 0.08704455\n",
      "epoch: 106  batch: 60  loss: 0.10351656\n",
      "epoch: 106  batch: 61  loss: 0.69680959\n",
      "epoch: 106  batch: 62  loss: 0.16945791\n",
      "epoch: 106  batch: 63  loss: 0.03601244\n",
      "epoch: 106  batch: 64  loss: 0.02594399\n",
      "epoch: 106  batch: 65  loss: 0.04076420\n",
      "epoch: 106  batch: 66  loss: 0.04107495\n",
      "epoch: 106  batch: 67  loss: 0.03394675\n",
      "epoch: 106  batch: 68  loss: 0.05181530\n",
      "epoch: 107  batch: 1  loss: 0.13164765\n",
      "epoch: 107  batch: 2  loss: 0.04364013\n",
      "epoch: 107  batch: 3  loss: 0.03721890\n",
      "epoch: 107  batch: 4  loss: 0.03283234\n",
      "epoch: 107  batch: 5  loss: 0.09160271\n",
      "epoch: 107  batch: 6  loss: 0.08279742\n",
      "epoch: 107  batch: 7  loss: 0.19453886\n",
      "epoch: 107  batch: 8  loss: 0.07539475\n",
      "epoch: 107  batch: 9  loss: 0.08896975\n",
      "epoch: 107  batch: 10  loss: 0.20814352\n",
      "epoch: 107  batch: 11  loss: 0.25636765\n",
      "epoch: 107  batch: 12  loss: 0.07960271\n",
      "epoch: 107  batch: 13  loss: 0.12505993\n",
      "epoch: 107  batch: 14  loss: 0.15533766\n",
      "epoch: 107  batch: 15  loss: 0.10851574\n",
      "epoch: 107  batch: 16  loss: 0.06333452\n",
      "epoch: 107  batch: 17  loss: 0.05078580\n",
      "epoch: 107  batch: 18  loss: 0.04590241\n",
      "epoch: 107  batch: 19  loss: 0.05023917\n",
      "epoch: 107  batch: 20  loss: 0.29490757\n",
      "epoch: 107  batch: 21  loss: 0.29174379\n",
      "epoch: 107  batch: 22  loss: 0.05837684\n",
      "epoch: 107  batch: 23  loss: 0.04312827\n",
      "epoch: 107  batch: 24  loss: 0.07748955\n",
      "epoch: 107  batch: 25  loss: 0.07887049\n",
      "epoch: 107  batch: 26  loss: 0.01780372\n",
      "epoch: 107  batch: 27  loss: 0.08058976\n",
      "epoch: 107  batch: 28  loss: 0.01599538\n",
      "epoch: 107  batch: 29  loss: 0.01544003\n",
      "epoch: 107  batch: 30  loss: 0.02084404\n",
      "epoch: 107  batch: 31  loss: 0.02692711\n",
      "epoch: 107  batch: 32  loss: 0.01219709\n",
      "epoch: 107  batch: 33  loss: 0.04446636\n",
      "epoch: 107  batch: 34  loss: 0.09353080\n",
      "epoch: 107  batch: 35  loss: 0.14124455\n",
      "epoch: 107  batch: 36  loss: 0.06156623\n",
      "epoch: 107  batch: 37  loss: 0.03900879\n",
      "epoch: 107  batch: 38  loss: 0.04014628\n",
      "epoch: 107  batch: 39  loss: 0.13396433\n",
      "epoch: 107  batch: 40  loss: 0.06338525\n",
      "epoch: 107  batch: 41  loss: 0.16798072\n",
      "epoch: 107  batch: 42  loss: 0.07547892\n",
      "epoch: 107  batch: 43  loss: 0.12962006\n",
      "epoch: 107  batch: 44  loss: 0.19777328\n",
      "epoch: 107  batch: 45  loss: 0.20246553\n",
      "epoch: 107  batch: 46  loss: 0.09918866\n",
      "epoch: 107  batch: 47  loss: 0.08315501\n",
      "epoch: 107  batch: 48  loss: 0.13836226\n",
      "epoch: 107  batch: 49  loss: 0.12901244\n",
      "epoch: 107  batch: 50  loss: 0.19698524\n",
      "epoch: 107  batch: 51  loss: 0.07719690\n",
      "epoch: 107  batch: 52  loss: 0.08630474\n",
      "epoch: 107  batch: 53  loss: 0.05842974\n",
      "epoch: 107  batch: 54  loss: 0.33263332\n",
      "epoch: 107  batch: 55  loss: 0.20912074\n",
      "epoch: 107  batch: 56  loss: 0.07913488\n",
      "epoch: 107  batch: 57  loss: 0.04107101\n",
      "epoch: 107  batch: 58  loss: 0.11576556\n",
      "epoch: 107  batch: 59  loss: 0.08731874\n",
      "epoch: 107  batch: 60  loss: 0.09544978\n",
      "epoch: 107  batch: 61  loss: 0.64316553\n",
      "epoch: 107  batch: 62  loss: 0.16247553\n",
      "epoch: 107  batch: 63  loss: 0.03563882\n",
      "epoch: 107  batch: 64  loss: 0.02513580\n",
      "epoch: 107  batch: 65  loss: 0.04075975\n",
      "epoch: 107  batch: 66  loss: 0.04083278\n",
      "epoch: 107  batch: 67  loss: 0.03399439\n",
      "epoch: 107  batch: 68  loss: 0.05163796\n",
      "epoch: 108  batch: 1  loss: 0.13195516\n",
      "epoch: 108  batch: 2  loss: 0.04363327\n",
      "epoch: 108  batch: 3  loss: 0.03676492\n",
      "epoch: 108  batch: 4  loss: 0.03248146\n",
      "epoch: 108  batch: 5  loss: 0.09129154\n",
      "epoch: 108  batch: 6  loss: 0.08236841\n",
      "epoch: 108  batch: 7  loss: 0.19418323\n",
      "epoch: 108  batch: 8  loss: 0.07447853\n",
      "epoch: 108  batch: 9  loss: 0.08782671\n",
      "epoch: 108  batch: 10  loss: 0.20568866\n",
      "epoch: 108  batch: 11  loss: 0.25447968\n",
      "epoch: 108  batch: 12  loss: 0.07935577\n",
      "epoch: 108  batch: 13  loss: 0.11836012\n",
      "epoch: 108  batch: 14  loss: 0.15414028\n",
      "epoch: 108  batch: 15  loss: 0.10898658\n",
      "epoch: 108  batch: 16  loss: 0.06278238\n",
      "epoch: 108  batch: 17  loss: 0.05100471\n",
      "epoch: 108  batch: 18  loss: 0.04631054\n",
      "epoch: 108  batch: 19  loss: 0.05110070\n",
      "epoch: 108  batch: 20  loss: 0.29308346\n",
      "epoch: 108  batch: 21  loss: 0.29120934\n",
      "epoch: 108  batch: 22  loss: 0.05774588\n",
      "epoch: 108  batch: 23  loss: 0.04303956\n",
      "epoch: 108  batch: 24  loss: 0.07617514\n",
      "epoch: 108  batch: 25  loss: 0.07830792\n",
      "epoch: 108  batch: 26  loss: 0.01764761\n",
      "epoch: 108  batch: 27  loss: 0.07944060\n",
      "epoch: 108  batch: 28  loss: 0.01581828\n",
      "epoch: 108  batch: 29  loss: 0.01538869\n",
      "epoch: 108  batch: 30  loss: 0.02126411\n",
      "epoch: 108  batch: 31  loss: 0.02692569\n",
      "epoch: 108  batch: 32  loss: 0.01225967\n",
      "epoch: 108  batch: 33  loss: 0.04417952\n",
      "epoch: 108  batch: 34  loss: 0.09345086\n",
      "epoch: 108  batch: 35  loss: 0.14098801\n",
      "epoch: 108  batch: 36  loss: 0.06225865\n",
      "epoch: 108  batch: 37  loss: 0.03898840\n",
      "epoch: 108  batch: 38  loss: 0.04013230\n",
      "epoch: 108  batch: 39  loss: 0.13307537\n",
      "epoch: 108  batch: 40  loss: 0.06344674\n",
      "epoch: 108  batch: 41  loss: 0.16745628\n",
      "epoch: 108  batch: 42  loss: 0.07485260\n",
      "epoch: 108  batch: 43  loss: 0.12879033\n",
      "epoch: 108  batch: 44  loss: 0.19615224\n",
      "epoch: 108  batch: 45  loss: 0.19966692\n",
      "epoch: 108  batch: 46  loss: 0.09815977\n",
      "epoch: 108  batch: 47  loss: 0.08279253\n",
      "epoch: 108  batch: 48  loss: 0.13851811\n",
      "epoch: 108  batch: 49  loss: 0.12958051\n",
      "epoch: 108  batch: 50  loss: 0.19149077\n",
      "epoch: 108  batch: 51  loss: 0.07746904\n",
      "epoch: 108  batch: 52  loss: 0.08707210\n",
      "epoch: 108  batch: 53  loss: 0.05954236\n",
      "epoch: 108  batch: 54  loss: 0.33211273\n",
      "epoch: 108  batch: 55  loss: 0.20818463\n",
      "epoch: 108  batch: 56  loss: 0.07935036\n",
      "epoch: 108  batch: 57  loss: 0.04128618\n",
      "epoch: 108  batch: 58  loss: 0.11549989\n",
      "epoch: 108  batch: 59  loss: 0.08765177\n",
      "epoch: 108  batch: 60  loss: 0.08788697\n",
      "epoch: 108  batch: 61  loss: 0.59303945\n",
      "epoch: 108  batch: 62  loss: 0.15563869\n",
      "epoch: 108  batch: 63  loss: 0.03511100\n",
      "epoch: 108  batch: 64  loss: 0.02437835\n",
      "epoch: 108  batch: 65  loss: 0.04072151\n",
      "epoch: 108  batch: 66  loss: 0.04065818\n",
      "epoch: 108  batch: 67  loss: 0.03402400\n",
      "epoch: 108  batch: 68  loss: 0.05141725\n",
      "epoch: 109  batch: 1  loss: 0.13224176\n",
      "epoch: 109  batch: 2  loss: 0.04362115\n",
      "epoch: 109  batch: 3  loss: 0.03626392\n",
      "epoch: 109  batch: 4  loss: 0.03218647\n",
      "epoch: 109  batch: 5  loss: 0.09088296\n",
      "epoch: 109  batch: 6  loss: 0.08196669\n",
      "epoch: 109  batch: 7  loss: 0.19370456\n",
      "epoch: 109  batch: 8  loss: 0.07326975\n",
      "epoch: 109  batch: 9  loss: 0.08666550\n",
      "epoch: 109  batch: 10  loss: 0.20249571\n",
      "epoch: 109  batch: 11  loss: 0.25076661\n",
      "epoch: 109  batch: 12  loss: 0.07917071\n",
      "epoch: 109  batch: 13  loss: 0.11269923\n",
      "epoch: 109  batch: 14  loss: 0.15298605\n",
      "epoch: 109  batch: 15  loss: 0.10954843\n",
      "epoch: 109  batch: 16  loss: 0.06183783\n",
      "epoch: 109  batch: 17  loss: 0.05127132\n",
      "epoch: 109  batch: 18  loss: 0.04667733\n",
      "epoch: 109  batch: 19  loss: 0.05156945\n",
      "epoch: 109  batch: 20  loss: 0.29052681\n",
      "epoch: 109  batch: 21  loss: 0.29065824\n",
      "epoch: 109  batch: 22  loss: 0.05721529\n",
      "epoch: 109  batch: 23  loss: 0.04303214\n",
      "epoch: 109  batch: 24  loss: 0.07477000\n",
      "epoch: 109  batch: 25  loss: 0.07771888\n",
      "epoch: 109  batch: 26  loss: 0.01751431\n",
      "epoch: 109  batch: 27  loss: 0.07788778\n",
      "epoch: 109  batch: 28  loss: 0.01562949\n",
      "epoch: 109  batch: 29  loss: 0.01549532\n",
      "epoch: 109  batch: 30  loss: 0.02155737\n",
      "epoch: 109  batch: 31  loss: 0.02692343\n",
      "epoch: 109  batch: 32  loss: 0.01232121\n",
      "epoch: 109  batch: 33  loss: 0.04364781\n",
      "epoch: 109  batch: 34  loss: 0.09342635\n",
      "epoch: 109  batch: 35  loss: 0.14065312\n",
      "epoch: 109  batch: 36  loss: 0.06304250\n",
      "epoch: 109  batch: 37  loss: 0.03900092\n",
      "epoch: 109  batch: 38  loss: 0.03988244\n",
      "epoch: 109  batch: 39  loss: 0.13213782\n",
      "epoch: 109  batch: 40  loss: 0.06357675\n",
      "epoch: 109  batch: 41  loss: 0.16683084\n",
      "epoch: 109  batch: 42  loss: 0.07419372\n",
      "epoch: 109  batch: 43  loss: 0.12759270\n",
      "epoch: 109  batch: 44  loss: 0.19406858\n",
      "epoch: 109  batch: 45  loss: 0.19673662\n",
      "epoch: 109  batch: 46  loss: 0.09704655\n",
      "epoch: 109  batch: 47  loss: 0.08235551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 109  batch: 48  loss: 0.13842833\n",
      "epoch: 109  batch: 49  loss: 0.13017327\n",
      "epoch: 109  batch: 50  loss: 0.18580903\n",
      "epoch: 109  batch: 51  loss: 0.07771125\n",
      "epoch: 109  batch: 52  loss: 0.08779737\n",
      "epoch: 109  batch: 53  loss: 0.05993729\n",
      "epoch: 109  batch: 54  loss: 0.33158630\n",
      "epoch: 109  batch: 55  loss: 0.20771968\n",
      "epoch: 109  batch: 56  loss: 0.07951459\n",
      "epoch: 109  batch: 57  loss: 0.04156177\n",
      "epoch: 109  batch: 58  loss: 0.11493376\n",
      "epoch: 109  batch: 59  loss: 0.08798406\n",
      "epoch: 109  batch: 60  loss: 0.08044536\n",
      "epoch: 109  batch: 61  loss: 0.54743975\n",
      "epoch: 109  batch: 62  loss: 0.14866613\n",
      "epoch: 109  batch: 63  loss: 0.03463047\n",
      "epoch: 109  batch: 64  loss: 0.02366411\n",
      "epoch: 109  batch: 65  loss: 0.04064374\n",
      "epoch: 109  batch: 66  loss: 0.04048917\n",
      "epoch: 109  batch: 67  loss: 0.03404225\n",
      "epoch: 109  batch: 68  loss: 0.05118121\n",
      "epoch: 110  batch: 1  loss: 0.13247691\n",
      "epoch: 110  batch: 2  loss: 0.04360734\n",
      "epoch: 110  batch: 3  loss: 0.03576597\n",
      "epoch: 110  batch: 4  loss: 0.03191231\n",
      "epoch: 110  batch: 5  loss: 0.09045671\n",
      "epoch: 110  batch: 6  loss: 0.08150951\n",
      "epoch: 110  batch: 7  loss: 0.19313826\n",
      "epoch: 110  batch: 8  loss: 0.07189221\n",
      "epoch: 110  batch: 9  loss: 0.08544960\n",
      "epoch: 110  batch: 10  loss: 0.19893430\n",
      "epoch: 110  batch: 11  loss: 0.24695240\n",
      "epoch: 110  batch: 12  loss: 0.07890180\n",
      "epoch: 110  batch: 13  loss: 0.10749029\n",
      "epoch: 110  batch: 14  loss: 0.15179858\n",
      "epoch: 110  batch: 15  loss: 0.11016539\n",
      "epoch: 110  batch: 16  loss: 0.06080469\n",
      "epoch: 110  batch: 17  loss: 0.05147514\n",
      "epoch: 110  batch: 18  loss: 0.04708266\n",
      "epoch: 110  batch: 19  loss: 0.05178766\n",
      "epoch: 110  batch: 20  loss: 0.28738469\n",
      "epoch: 110  batch: 21  loss: 0.29019180\n",
      "epoch: 110  batch: 22  loss: 0.05670759\n",
      "epoch: 110  batch: 23  loss: 0.04303367\n",
      "epoch: 110  batch: 24  loss: 0.07335465\n",
      "epoch: 110  batch: 25  loss: 0.07712514\n",
      "epoch: 110  batch: 26  loss: 0.01742865\n",
      "epoch: 110  batch: 27  loss: 0.07594529\n",
      "epoch: 110  batch: 28  loss: 0.01545488\n",
      "epoch: 110  batch: 29  loss: 0.01562010\n",
      "epoch: 110  batch: 30  loss: 0.02175074\n",
      "epoch: 110  batch: 31  loss: 0.02691332\n",
      "epoch: 110  batch: 32  loss: 0.01236671\n",
      "epoch: 110  batch: 33  loss: 0.04294572\n",
      "epoch: 110  batch: 34  loss: 0.09338839\n",
      "epoch: 110  batch: 35  loss: 0.14028780\n",
      "epoch: 110  batch: 36  loss: 0.06387638\n",
      "epoch: 110  batch: 37  loss: 0.03902607\n",
      "epoch: 110  batch: 38  loss: 0.03935555\n",
      "epoch: 110  batch: 39  loss: 0.13126116\n",
      "epoch: 110  batch: 40  loss: 0.06375065\n",
      "epoch: 110  batch: 41  loss: 0.16614428\n",
      "epoch: 110  batch: 42  loss: 0.07351102\n",
      "epoch: 110  batch: 43  loss: 0.12610818\n",
      "epoch: 110  batch: 44  loss: 0.19151099\n",
      "epoch: 110  batch: 45  loss: 0.19376698\n",
      "epoch: 110  batch: 46  loss: 0.09574362\n",
      "epoch: 110  batch: 47  loss: 0.08201652\n",
      "epoch: 110  batch: 48  loss: 0.13801979\n",
      "epoch: 110  batch: 49  loss: 0.13084708\n",
      "epoch: 110  batch: 50  loss: 0.17963377\n",
      "epoch: 110  batch: 51  loss: 0.07790693\n",
      "epoch: 110  batch: 52  loss: 0.08843785\n",
      "epoch: 110  batch: 53  loss: 0.05982850\n",
      "epoch: 110  batch: 54  loss: 0.33105826\n",
      "epoch: 110  batch: 55  loss: 0.20784679\n",
      "epoch: 110  batch: 56  loss: 0.07962296\n",
      "epoch: 110  batch: 57  loss: 0.04180103\n",
      "epoch: 110  batch: 58  loss: 0.11399710\n",
      "epoch: 110  batch: 59  loss: 0.08825917\n",
      "epoch: 110  batch: 60  loss: 0.07300199\n",
      "epoch: 110  batch: 61  loss: 0.50756425\n",
      "epoch: 110  batch: 62  loss: 0.14189227\n",
      "epoch: 110  batch: 63  loss: 0.03413935\n",
      "epoch: 110  batch: 64  loss: 0.02297652\n",
      "epoch: 110  batch: 65  loss: 0.04058336\n",
      "epoch: 110  batch: 66  loss: 0.04039029\n",
      "epoch: 110  batch: 67  loss: 0.03408997\n",
      "epoch: 110  batch: 68  loss: 0.05092521\n",
      "epoch: 111  batch: 1  loss: 0.13253996\n",
      "epoch: 111  batch: 2  loss: 0.04356858\n",
      "epoch: 111  batch: 3  loss: 0.03526119\n",
      "epoch: 111  batch: 4  loss: 0.03168361\n",
      "epoch: 111  batch: 5  loss: 0.08995157\n",
      "epoch: 111  batch: 6  loss: 0.08105545\n",
      "epoch: 111  batch: 7  loss: 0.19248579\n",
      "epoch: 111  batch: 8  loss: 0.07039334\n",
      "epoch: 111  batch: 9  loss: 0.08423163\n",
      "epoch: 111  batch: 10  loss: 0.19513892\n",
      "epoch: 111  batch: 11  loss: 0.24282518\n",
      "epoch: 111  batch: 12  loss: 0.07856433\n",
      "epoch: 111  batch: 13  loss: 0.10291194\n",
      "epoch: 111  batch: 14  loss: 0.15091418\n",
      "epoch: 111  batch: 15  loss: 0.11081214\n",
      "epoch: 111  batch: 16  loss: 0.05966463\n",
      "epoch: 111  batch: 17  loss: 0.05163672\n",
      "epoch: 111  batch: 18  loss: 0.04737862\n",
      "epoch: 111  batch: 19  loss: 0.05175469\n",
      "epoch: 111  batch: 20  loss: 0.28394002\n",
      "epoch: 111  batch: 21  loss: 0.28958195\n",
      "epoch: 111  batch: 22  loss: 0.05627392\n",
      "epoch: 111  batch: 23  loss: 0.04304812\n",
      "epoch: 111  batch: 24  loss: 0.07215620\n",
      "epoch: 111  batch: 25  loss: 0.07646716\n",
      "epoch: 111  batch: 26  loss: 0.01741520\n",
      "epoch: 111  batch: 27  loss: 0.07366562\n",
      "epoch: 111  batch: 28  loss: 0.01531645\n",
      "epoch: 111  batch: 29  loss: 0.01568852\n",
      "epoch: 111  batch: 30  loss: 0.02126587\n",
      "epoch: 111  batch: 31  loss: 0.02688402\n",
      "epoch: 111  batch: 32  loss: 0.01239025\n",
      "epoch: 111  batch: 33  loss: 0.04217093\n",
      "epoch: 111  batch: 34  loss: 0.09336793\n",
      "epoch: 111  batch: 35  loss: 0.13991827\n",
      "epoch: 111  batch: 36  loss: 0.06476220\n",
      "epoch: 111  batch: 37  loss: 0.03906266\n",
      "epoch: 111  batch: 38  loss: 0.03868743\n",
      "epoch: 111  batch: 39  loss: 0.13052133\n",
      "epoch: 111  batch: 40  loss: 0.06399016\n",
      "epoch: 111  batch: 41  loss: 0.16541918\n",
      "epoch: 111  batch: 42  loss: 0.07283466\n",
      "epoch: 111  batch: 43  loss: 0.12443165\n",
      "epoch: 111  batch: 44  loss: 0.18836704\n",
      "epoch: 111  batch: 45  loss: 0.19077376\n",
      "epoch: 111  batch: 46  loss: 0.09440494\n",
      "epoch: 111  batch: 47  loss: 0.08156202\n",
      "epoch: 111  batch: 48  loss: 0.13723479\n",
      "epoch: 111  batch: 49  loss: 0.13158326\n",
      "epoch: 111  batch: 50  loss: 0.17383474\n",
      "epoch: 111  batch: 51  loss: 0.07807089\n",
      "epoch: 111  batch: 52  loss: 0.08898234\n",
      "epoch: 111  batch: 53  loss: 0.05947127\n",
      "epoch: 111  batch: 54  loss: 0.33053848\n",
      "epoch: 111  batch: 55  loss: 0.20800875\n",
      "epoch: 111  batch: 56  loss: 0.07974385\n",
      "epoch: 111  batch: 57  loss: 0.04195773\n",
      "epoch: 111  batch: 58  loss: 0.11272001\n",
      "epoch: 111  batch: 59  loss: 0.08848862\n",
      "epoch: 111  batch: 60  loss: 0.06575749\n",
      "epoch: 111  batch: 61  loss: 0.47284794\n",
      "epoch: 111  batch: 62  loss: 0.13505670\n",
      "epoch: 111  batch: 63  loss: 0.03372352\n",
      "epoch: 111  batch: 64  loss: 0.02241079\n",
      "epoch: 111  batch: 65  loss: 0.04049204\n",
      "epoch: 111  batch: 66  loss: 0.04032767\n",
      "epoch: 111  batch: 67  loss: 0.03411244\n",
      "epoch: 111  batch: 68  loss: 0.05068099\n",
      "epoch: 112  batch: 1  loss: 0.13222151\n",
      "epoch: 112  batch: 2  loss: 0.04361631\n",
      "epoch: 112  batch: 3  loss: 0.03484435\n",
      "epoch: 112  batch: 4  loss: 0.03155772\n",
      "epoch: 112  batch: 5  loss: 0.08942907\n",
      "epoch: 112  batch: 6  loss: 0.08049247\n",
      "epoch: 112  batch: 7  loss: 0.19182524\n",
      "epoch: 112  batch: 8  loss: 0.06901935\n",
      "epoch: 112  batch: 9  loss: 0.08299191\n",
      "epoch: 112  batch: 10  loss: 0.19157423\n",
      "epoch: 112  batch: 11  loss: 0.23926108\n",
      "epoch: 112  batch: 12  loss: 0.07811570\n",
      "epoch: 112  batch: 13  loss: 0.09853902\n",
      "epoch: 112  batch: 14  loss: 0.15002961\n",
      "epoch: 112  batch: 15  loss: 0.11150214\n",
      "epoch: 112  batch: 16  loss: 0.05871518\n",
      "epoch: 112  batch: 17  loss: 0.05168829\n",
      "epoch: 112  batch: 18  loss: 0.04770609\n",
      "epoch: 112  batch: 19  loss: 0.05168718\n",
      "epoch: 112  batch: 20  loss: 0.28027672\n",
      "epoch: 112  batch: 21  loss: 0.28882080\n",
      "epoch: 112  batch: 22  loss: 0.05584895\n",
      "epoch: 112  batch: 23  loss: 0.04304384\n",
      "epoch: 112  batch: 24  loss: 0.07119221\n",
      "epoch: 112  batch: 25  loss: 0.07592082\n",
      "epoch: 112  batch: 26  loss: 0.01746506\n",
      "epoch: 112  batch: 27  loss: 0.07131682\n",
      "epoch: 112  batch: 28  loss: 0.01526628\n",
      "epoch: 112  batch: 29  loss: 0.01579912\n",
      "epoch: 112  batch: 30  loss: 0.02073643\n",
      "epoch: 112  batch: 31  loss: 0.02682018\n",
      "epoch: 112  batch: 32  loss: 0.01237247\n",
      "epoch: 112  batch: 33  loss: 0.04126133\n",
      "epoch: 112  batch: 34  loss: 0.09338938\n",
      "epoch: 112  batch: 35  loss: 0.13953982\n",
      "epoch: 112  batch: 36  loss: 0.06570643\n",
      "epoch: 112  batch: 37  loss: 0.03908459\n",
      "epoch: 112  batch: 38  loss: 0.03791604\n",
      "epoch: 112  batch: 39  loss: 0.12970968\n",
      "epoch: 112  batch: 40  loss: 0.06428934\n",
      "epoch: 112  batch: 41  loss: 0.16466570\n",
      "epoch: 112  batch: 42  loss: 0.07218842\n",
      "epoch: 112  batch: 43  loss: 0.12267355\n",
      "epoch: 112  batch: 44  loss: 0.18502806\n",
      "epoch: 112  batch: 45  loss: 0.18754567\n",
      "epoch: 112  batch: 46  loss: 0.09322660\n",
      "epoch: 112  batch: 47  loss: 0.08105824\n",
      "epoch: 112  batch: 48  loss: 0.13639867\n",
      "epoch: 112  batch: 49  loss: 0.13227347\n",
      "epoch: 112  batch: 50  loss: 0.16809824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112  batch: 51  loss: 0.07812683\n",
      "epoch: 112  batch: 52  loss: 0.08943482\n",
      "epoch: 112  batch: 53  loss: 0.05886140\n",
      "epoch: 112  batch: 54  loss: 0.33003142\n",
      "epoch: 112  batch: 55  loss: 0.20812027\n",
      "epoch: 112  batch: 56  loss: 0.07983533\n",
      "epoch: 112  batch: 57  loss: 0.04215518\n",
      "epoch: 112  batch: 58  loss: 0.11140310\n",
      "epoch: 112  batch: 59  loss: 0.08851849\n",
      "epoch: 112  batch: 60  loss: 0.05900661\n",
      "epoch: 112  batch: 61  loss: 0.44121602\n",
      "epoch: 112  batch: 62  loss: 0.12794322\n",
      "epoch: 112  batch: 63  loss: 0.03331224\n",
      "epoch: 112  batch: 64  loss: 0.02193506\n",
      "epoch: 112  batch: 65  loss: 0.04041338\n",
      "epoch: 112  batch: 66  loss: 0.04033937\n",
      "epoch: 112  batch: 67  loss: 0.03421323\n",
      "epoch: 112  batch: 68  loss: 0.05042664\n",
      "epoch: 113  batch: 1  loss: 0.13183659\n",
      "epoch: 113  batch: 2  loss: 0.04372888\n",
      "epoch: 113  batch: 3  loss: 0.03452039\n",
      "epoch: 113  batch: 4  loss: 0.03140817\n",
      "epoch: 113  batch: 5  loss: 0.08886854\n",
      "epoch: 113  batch: 6  loss: 0.07974692\n",
      "epoch: 113  batch: 7  loss: 0.19107968\n",
      "epoch: 113  batch: 8  loss: 0.06770512\n",
      "epoch: 113  batch: 9  loss: 0.08179677\n",
      "epoch: 113  batch: 10  loss: 0.18785280\n",
      "epoch: 113  batch: 11  loss: 0.23594497\n",
      "epoch: 113  batch: 12  loss: 0.07773523\n",
      "epoch: 113  batch: 13  loss: 0.09434143\n",
      "epoch: 113  batch: 14  loss: 0.14874370\n",
      "epoch: 113  batch: 15  loss: 0.11220394\n",
      "epoch: 113  batch: 16  loss: 0.05764814\n",
      "epoch: 113  batch: 17  loss: 0.05165482\n",
      "epoch: 113  batch: 18  loss: 0.04804679\n",
      "epoch: 113  batch: 19  loss: 0.05181830\n",
      "epoch: 113  batch: 20  loss: 0.27629870\n",
      "epoch: 113  batch: 21  loss: 0.28800941\n",
      "epoch: 113  batch: 22  loss: 0.05545368\n",
      "epoch: 113  batch: 23  loss: 0.04306016\n",
      "epoch: 113  batch: 24  loss: 0.07055922\n",
      "epoch: 113  batch: 25  loss: 0.07535172\n",
      "epoch: 113  batch: 26  loss: 0.01757823\n",
      "epoch: 113  batch: 27  loss: 0.06895892\n",
      "epoch: 113  batch: 28  loss: 0.01528053\n",
      "epoch: 113  batch: 29  loss: 0.01594640\n",
      "epoch: 113  batch: 30  loss: 0.02014356\n",
      "epoch: 113  batch: 31  loss: 0.02675682\n",
      "epoch: 113  batch: 32  loss: 0.01233753\n",
      "epoch: 113  batch: 33  loss: 0.04018550\n",
      "epoch: 113  batch: 34  loss: 0.09354869\n",
      "epoch: 113  batch: 35  loss: 0.13913561\n",
      "epoch: 113  batch: 36  loss: 0.06667763\n",
      "epoch: 113  batch: 37  loss: 0.03910537\n",
      "epoch: 113  batch: 38  loss: 0.03718689\n",
      "epoch: 113  batch: 39  loss: 0.12885262\n",
      "epoch: 113  batch: 40  loss: 0.06466363\n",
      "epoch: 113  batch: 41  loss: 0.16389139\n",
      "epoch: 113  batch: 42  loss: 0.07159726\n",
      "epoch: 113  batch: 43  loss: 0.12081464\n",
      "epoch: 113  batch: 44  loss: 0.18196924\n",
      "epoch: 113  batch: 45  loss: 0.18434982\n",
      "epoch: 113  batch: 46  loss: 0.09217733\n",
      "epoch: 113  batch: 47  loss: 0.08044079\n",
      "epoch: 113  batch: 48  loss: 0.13519239\n",
      "epoch: 113  batch: 49  loss: 0.13289496\n",
      "epoch: 113  batch: 50  loss: 0.16281748\n",
      "epoch: 113  batch: 51  loss: 0.07811705\n",
      "epoch: 113  batch: 52  loss: 0.08979957\n",
      "epoch: 113  batch: 53  loss: 0.05841938\n",
      "epoch: 113  batch: 54  loss: 0.32950851\n",
      "epoch: 113  batch: 55  loss: 0.20826243\n",
      "epoch: 113  batch: 56  loss: 0.07994418\n",
      "epoch: 113  batch: 57  loss: 0.04233615\n",
      "epoch: 113  batch: 58  loss: 0.10987721\n",
      "epoch: 113  batch: 59  loss: 0.08839380\n",
      "epoch: 113  batch: 60  loss: 0.05342775\n",
      "epoch: 113  batch: 61  loss: 0.41297796\n",
      "epoch: 113  batch: 62  loss: 0.12069549\n",
      "epoch: 113  batch: 63  loss: 0.03264898\n",
      "epoch: 113  batch: 64  loss: 0.02154197\n",
      "epoch: 113  batch: 65  loss: 0.04037777\n",
      "epoch: 113  batch: 66  loss: 0.04031237\n",
      "epoch: 113  batch: 67  loss: 0.03423566\n",
      "epoch: 113  batch: 68  loss: 0.05020250\n",
      "epoch: 114  batch: 1  loss: 0.13116162\n",
      "epoch: 114  batch: 2  loss: 0.04385974\n",
      "epoch: 114  batch: 3  loss: 0.03424684\n",
      "epoch: 114  batch: 4  loss: 0.03127184\n",
      "epoch: 114  batch: 5  loss: 0.08828643\n",
      "epoch: 114  batch: 6  loss: 0.07906693\n",
      "epoch: 114  batch: 7  loss: 0.19026510\n",
      "epoch: 114  batch: 8  loss: 0.06644996\n",
      "epoch: 114  batch: 9  loss: 0.08067734\n",
      "epoch: 114  batch: 10  loss: 0.18404688\n",
      "epoch: 114  batch: 11  loss: 0.23244897\n",
      "epoch: 114  batch: 12  loss: 0.07733361\n",
      "epoch: 114  batch: 13  loss: 0.09030607\n",
      "epoch: 114  batch: 14  loss: 0.14764316\n",
      "epoch: 114  batch: 15  loss: 0.11288457\n",
      "epoch: 114  batch: 16  loss: 0.05652530\n",
      "epoch: 114  batch: 17  loss: 0.05155691\n",
      "epoch: 114  batch: 18  loss: 0.04832584\n",
      "epoch: 114  batch: 19  loss: 0.05194842\n",
      "epoch: 114  batch: 20  loss: 0.27221525\n",
      "epoch: 114  batch: 21  loss: 0.28698933\n",
      "epoch: 114  batch: 22  loss: 0.05509467\n",
      "epoch: 114  batch: 23  loss: 0.04304841\n",
      "epoch: 114  batch: 24  loss: 0.07012490\n",
      "epoch: 114  batch: 25  loss: 0.07481690\n",
      "epoch: 114  batch: 26  loss: 0.01774186\n",
      "epoch: 114  batch: 27  loss: 0.06645689\n",
      "epoch: 114  batch: 28  loss: 0.01531161\n",
      "epoch: 114  batch: 29  loss: 0.01605837\n",
      "epoch: 114  batch: 30  loss: 0.01947710\n",
      "epoch: 114  batch: 31  loss: 0.02670819\n",
      "epoch: 114  batch: 32  loss: 0.01228644\n",
      "epoch: 114  batch: 33  loss: 0.03913740\n",
      "epoch: 114  batch: 34  loss: 0.09376594\n",
      "epoch: 114  batch: 35  loss: 0.13874298\n",
      "epoch: 114  batch: 36  loss: 0.06764598\n",
      "epoch: 114  batch: 37  loss: 0.03907511\n",
      "epoch: 114  batch: 38  loss: 0.03647478\n",
      "epoch: 114  batch: 39  loss: 0.12803683\n",
      "epoch: 114  batch: 40  loss: 0.06509423\n",
      "epoch: 114  batch: 41  loss: 0.16312391\n",
      "epoch: 114  batch: 42  loss: 0.07103962\n",
      "epoch: 114  batch: 43  loss: 0.11889456\n",
      "epoch: 114  batch: 44  loss: 0.17914955\n",
      "epoch: 114  batch: 45  loss: 0.18118766\n",
      "epoch: 114  batch: 46  loss: 0.09102238\n",
      "epoch: 114  batch: 47  loss: 0.07983187\n",
      "epoch: 114  batch: 48  loss: 0.13380693\n",
      "epoch: 114  batch: 49  loss: 0.13353613\n",
      "epoch: 114  batch: 50  loss: 0.15744378\n",
      "epoch: 114  batch: 51  loss: 0.07810846\n",
      "epoch: 114  batch: 52  loss: 0.08987274\n",
      "epoch: 114  batch: 53  loss: 0.05826708\n",
      "epoch: 114  batch: 54  loss: 0.32898051\n",
      "epoch: 114  batch: 55  loss: 0.20833185\n",
      "epoch: 114  batch: 56  loss: 0.08005090\n",
      "epoch: 114  batch: 57  loss: 0.04251473\n",
      "epoch: 114  batch: 58  loss: 0.10835599\n",
      "epoch: 114  batch: 59  loss: 0.08784544\n",
      "epoch: 114  batch: 60  loss: 0.04871612\n",
      "epoch: 114  batch: 61  loss: 0.38756597\n",
      "epoch: 114  batch: 62  loss: 0.11347195\n",
      "epoch: 114  batch: 63  loss: 0.03167204\n",
      "epoch: 114  batch: 64  loss: 0.02123276\n",
      "epoch: 114  batch: 65  loss: 0.04044216\n",
      "epoch: 114  batch: 66  loss: 0.04028281\n",
      "epoch: 114  batch: 67  loss: 0.03417122\n",
      "epoch: 114  batch: 68  loss: 0.05001011\n",
      "epoch: 115  batch: 1  loss: 0.13036478\n",
      "epoch: 115  batch: 2  loss: 0.04402637\n",
      "epoch: 115  batch: 3  loss: 0.03401742\n",
      "epoch: 115  batch: 4  loss: 0.03119245\n",
      "epoch: 115  batch: 5  loss: 0.08773667\n",
      "epoch: 115  batch: 6  loss: 0.07838411\n",
      "epoch: 115  batch: 7  loss: 0.18946823\n",
      "epoch: 115  batch: 8  loss: 0.06518413\n",
      "epoch: 115  batch: 9  loss: 0.07954103\n",
      "epoch: 115  batch: 10  loss: 0.18031114\n",
      "epoch: 115  batch: 11  loss: 0.22904581\n",
      "epoch: 115  batch: 12  loss: 0.07681923\n",
      "epoch: 115  batch: 13  loss: 0.08642665\n",
      "epoch: 115  batch: 14  loss: 0.14649880\n",
      "epoch: 115  batch: 15  loss: 0.11360130\n",
      "epoch: 115  batch: 16  loss: 0.05535630\n",
      "epoch: 115  batch: 17  loss: 0.05139406\n",
      "epoch: 115  batch: 18  loss: 0.04868279\n",
      "epoch: 115  batch: 19  loss: 0.05205400\n",
      "epoch: 115  batch: 20  loss: 0.26795754\n",
      "epoch: 115  batch: 21  loss: 0.28596291\n",
      "epoch: 115  batch: 22  loss: 0.05473889\n",
      "epoch: 115  batch: 23  loss: 0.04303721\n",
      "epoch: 115  batch: 24  loss: 0.06986094\n",
      "epoch: 115  batch: 25  loss: 0.07431432\n",
      "epoch: 115  batch: 26  loss: 0.01793460\n",
      "epoch: 115  batch: 27  loss: 0.06401073\n",
      "epoch: 115  batch: 28  loss: 0.01538774\n",
      "epoch: 115  batch: 29  loss: 0.01616449\n",
      "epoch: 115  batch: 30  loss: 0.01882849\n",
      "epoch: 115  batch: 31  loss: 0.02662855\n",
      "epoch: 115  batch: 32  loss: 0.01224682\n",
      "epoch: 115  batch: 33  loss: 0.03780888\n",
      "epoch: 115  batch: 34  loss: 0.09401165\n",
      "epoch: 115  batch: 35  loss: 0.13829507\n",
      "epoch: 115  batch: 36  loss: 0.06862964\n",
      "epoch: 115  batch: 37  loss: 0.03901369\n",
      "epoch: 115  batch: 38  loss: 0.03578598\n",
      "epoch: 115  batch: 39  loss: 0.12721156\n",
      "epoch: 115  batch: 40  loss: 0.06557487\n",
      "epoch: 115  batch: 41  loss: 0.16234843\n",
      "epoch: 115  batch: 42  loss: 0.07053197\n",
      "epoch: 115  batch: 43  loss: 0.11694171\n",
      "epoch: 115  batch: 44  loss: 0.17649813\n",
      "epoch: 115  batch: 45  loss: 0.17793232\n",
      "epoch: 115  batch: 46  loss: 0.08989088\n",
      "epoch: 115  batch: 47  loss: 0.07917660\n",
      "epoch: 115  batch: 48  loss: 0.13245580\n",
      "epoch: 115  batch: 49  loss: 0.13420340\n",
      "epoch: 115  batch: 50  loss: 0.15238273\n",
      "epoch: 115  batch: 51  loss: 0.07807538\n",
      "epoch: 115  batch: 52  loss: 0.08975245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 115  batch: 53  loss: 0.05806317\n",
      "epoch: 115  batch: 54  loss: 0.32853064\n",
      "epoch: 115  batch: 55  loss: 0.20846063\n",
      "epoch: 115  batch: 56  loss: 0.08011009\n",
      "epoch: 115  batch: 57  loss: 0.04266443\n",
      "epoch: 115  batch: 58  loss: 0.10680591\n",
      "epoch: 115  batch: 59  loss: 0.08573350\n",
      "epoch: 115  batch: 60  loss: 0.04478041\n",
      "epoch: 115  batch: 61  loss: 0.36374953\n",
      "epoch: 115  batch: 62  loss: 0.10597354\n",
      "epoch: 115  batch: 63  loss: 0.03052790\n",
      "epoch: 115  batch: 64  loss: 0.02099548\n",
      "epoch: 115  batch: 65  loss: 0.04054766\n",
      "epoch: 115  batch: 66  loss: 0.04035118\n",
      "epoch: 115  batch: 67  loss: 0.03415383\n",
      "epoch: 115  batch: 68  loss: 0.04983664\n",
      "epoch: 116  batch: 1  loss: 0.12969944\n",
      "epoch: 116  batch: 2  loss: 0.04418296\n",
      "epoch: 116  batch: 3  loss: 0.03381820\n",
      "epoch: 116  batch: 4  loss: 0.03116591\n",
      "epoch: 116  batch: 5  loss: 0.08723924\n",
      "epoch: 116  batch: 6  loss: 0.07753861\n",
      "epoch: 116  batch: 7  loss: 0.18891686\n",
      "epoch: 116  batch: 8  loss: 0.06410947\n",
      "epoch: 116  batch: 9  loss: 0.07833046\n",
      "epoch: 116  batch: 10  loss: 0.17667304\n",
      "epoch: 116  batch: 11  loss: 0.22568537\n",
      "epoch: 116  batch: 12  loss: 0.07620735\n",
      "epoch: 116  batch: 13  loss: 0.08285841\n",
      "epoch: 116  batch: 14  loss: 0.14505954\n",
      "epoch: 116  batch: 15  loss: 0.11435327\n",
      "epoch: 116  batch: 16  loss: 0.05416856\n",
      "epoch: 116  batch: 17  loss: 0.05122332\n",
      "epoch: 116  batch: 18  loss: 0.04921486\n",
      "epoch: 116  batch: 19  loss: 0.05226166\n",
      "epoch: 116  batch: 20  loss: 0.26343331\n",
      "epoch: 116  batch: 21  loss: 0.28481323\n",
      "epoch: 116  batch: 22  loss: 0.05440915\n",
      "epoch: 116  batch: 23  loss: 0.04291365\n",
      "epoch: 116  batch: 24  loss: 0.06981550\n",
      "epoch: 116  batch: 25  loss: 0.07400230\n",
      "epoch: 116  batch: 26  loss: 0.01808158\n",
      "epoch: 116  batch: 27  loss: 0.06179399\n",
      "epoch: 116  batch: 28  loss: 0.01539985\n",
      "epoch: 116  batch: 29  loss: 0.01617398\n",
      "epoch: 116  batch: 30  loss: 0.01874290\n",
      "epoch: 116  batch: 31  loss: 0.02650455\n",
      "epoch: 116  batch: 32  loss: 0.01221412\n",
      "epoch: 116  batch: 33  loss: 0.03649442\n",
      "epoch: 116  batch: 34  loss: 0.09415156\n",
      "epoch: 116  batch: 35  loss: 0.13788417\n",
      "epoch: 116  batch: 36  loss: 0.06969810\n",
      "epoch: 116  batch: 37  loss: 0.03890587\n",
      "epoch: 116  batch: 38  loss: 0.03509826\n",
      "epoch: 116  batch: 39  loss: 0.12641707\n",
      "epoch: 116  batch: 40  loss: 0.06606658\n",
      "epoch: 116  batch: 41  loss: 0.16158602\n",
      "epoch: 116  batch: 42  loss: 0.07003336\n",
      "epoch: 116  batch: 43  loss: 0.11509584\n",
      "epoch: 116  batch: 44  loss: 0.17350259\n",
      "epoch: 116  batch: 45  loss: 0.17478882\n",
      "epoch: 116  batch: 46  loss: 0.08870856\n",
      "epoch: 116  batch: 47  loss: 0.07849437\n",
      "epoch: 116  batch: 48  loss: 0.13089469\n",
      "epoch: 116  batch: 49  loss: 0.13487765\n",
      "epoch: 116  batch: 50  loss: 0.14720494\n",
      "epoch: 116  batch: 51  loss: 0.07824064\n",
      "epoch: 116  batch: 52  loss: 0.08974419\n",
      "epoch: 116  batch: 53  loss: 0.05791156\n",
      "epoch: 116  batch: 54  loss: 0.32824475\n",
      "epoch: 116  batch: 55  loss: 0.20823814\n",
      "epoch: 116  batch: 56  loss: 0.08012857\n",
      "epoch: 116  batch: 57  loss: 0.04269065\n",
      "epoch: 116  batch: 58  loss: 0.10508429\n",
      "epoch: 116  batch: 59  loss: 0.08124089\n",
      "epoch: 116  batch: 60  loss: 0.04138903\n",
      "epoch: 116  batch: 61  loss: 0.34166878\n",
      "epoch: 116  batch: 62  loss: 0.09815192\n",
      "epoch: 116  batch: 63  loss: 0.02950546\n",
      "epoch: 116  batch: 64  loss: 0.02075770\n",
      "epoch: 116  batch: 65  loss: 0.04070481\n",
      "epoch: 116  batch: 66  loss: 0.04034269\n",
      "epoch: 116  batch: 67  loss: 0.03372602\n",
      "epoch: 116  batch: 68  loss: 0.04970013\n",
      "epoch: 117  batch: 1  loss: 0.12897807\n",
      "epoch: 117  batch: 2  loss: 0.04457323\n",
      "epoch: 117  batch: 3  loss: 0.03357752\n",
      "epoch: 117  batch: 4  loss: 0.03114742\n",
      "epoch: 117  batch: 5  loss: 0.08674666\n",
      "epoch: 117  batch: 6  loss: 0.07688564\n",
      "epoch: 117  batch: 7  loss: 0.18792748\n",
      "epoch: 117  batch: 8  loss: 0.06308354\n",
      "epoch: 117  batch: 9  loss: 0.07718926\n",
      "epoch: 117  batch: 10  loss: 0.17311712\n",
      "epoch: 117  batch: 11  loss: 0.22219713\n",
      "epoch: 117  batch: 12  loss: 0.07568438\n",
      "epoch: 117  batch: 13  loss: 0.07932554\n",
      "epoch: 117  batch: 14  loss: 0.14379175\n",
      "epoch: 117  batch: 15  loss: 0.11511034\n",
      "epoch: 117  batch: 16  loss: 0.05272947\n",
      "epoch: 117  batch: 17  loss: 0.05114264\n",
      "epoch: 117  batch: 18  loss: 0.04946074\n",
      "epoch: 117  batch: 19  loss: 0.05225362\n",
      "epoch: 117  batch: 20  loss: 0.25895578\n",
      "epoch: 117  batch: 21  loss: 0.28352582\n",
      "epoch: 117  batch: 22  loss: 0.05408809\n",
      "epoch: 117  batch: 23  loss: 0.04313703\n",
      "epoch: 117  batch: 24  loss: 0.06973975\n",
      "epoch: 117  batch: 25  loss: 0.07318331\n",
      "epoch: 117  batch: 26  loss: 0.01826260\n",
      "epoch: 117  batch: 27  loss: 0.05954983\n",
      "epoch: 117  batch: 28  loss: 0.01547100\n",
      "epoch: 117  batch: 29  loss: 0.01650400\n",
      "epoch: 117  batch: 30  loss: 0.01796931\n",
      "epoch: 117  batch: 31  loss: 0.02637823\n",
      "epoch: 117  batch: 32  loss: 0.01223486\n",
      "epoch: 117  batch: 33  loss: 0.03442535\n",
      "epoch: 117  batch: 34  loss: 0.09471618\n",
      "epoch: 117  batch: 35  loss: 0.13736872\n",
      "epoch: 117  batch: 36  loss: 0.07082990\n",
      "epoch: 117  batch: 37  loss: 0.03880488\n",
      "epoch: 117  batch: 38  loss: 0.03450887\n",
      "epoch: 117  batch: 39  loss: 0.12548809\n",
      "epoch: 117  batch: 40  loss: 0.06672522\n",
      "epoch: 117  batch: 41  loss: 0.16078982\n",
      "epoch: 117  batch: 42  loss: 0.06957361\n",
      "epoch: 117  batch: 43  loss: 0.11314671\n",
      "epoch: 117  batch: 44  loss: 0.17087655\n",
      "epoch: 117  batch: 45  loss: 0.17142776\n",
      "epoch: 117  batch: 46  loss: 0.08797526\n",
      "epoch: 117  batch: 47  loss: 0.07755561\n",
      "epoch: 117  batch: 48  loss: 0.12939051\n",
      "epoch: 117  batch: 49  loss: 0.13541789\n",
      "epoch: 117  batch: 50  loss: 0.14307658\n",
      "epoch: 117  batch: 51  loss: 0.07834438\n",
      "epoch: 117  batch: 52  loss: 0.08937559\n",
      "epoch: 117  batch: 53  loss: 0.05784703\n",
      "epoch: 117  batch: 54  loss: 0.32765168\n",
      "epoch: 117  batch: 55  loss: 0.20850743\n",
      "epoch: 117  batch: 56  loss: 0.08032691\n",
      "epoch: 117  batch: 57  loss: 0.04285421\n",
      "epoch: 117  batch: 58  loss: 0.10319835\n",
      "epoch: 117  batch: 59  loss: 0.08052812\n",
      "epoch: 117  batch: 60  loss: 0.03846120\n",
      "epoch: 117  batch: 61  loss: 0.32194826\n",
      "epoch: 117  batch: 62  loss: 0.09050615\n",
      "epoch: 117  batch: 63  loss: 0.02864755\n",
      "epoch: 117  batch: 64  loss: 0.02066758\n",
      "epoch: 117  batch: 65  loss: 0.04065214\n",
      "epoch: 117  batch: 66  loss: 0.04017177\n",
      "epoch: 117  batch: 67  loss: 0.03306343\n",
      "epoch: 117  batch: 68  loss: 0.04952591\n",
      "epoch: 118  batch: 1  loss: 0.12822855\n",
      "epoch: 118  batch: 2  loss: 0.04515789\n",
      "epoch: 118  batch: 3  loss: 0.03328818\n",
      "epoch: 118  batch: 4  loss: 0.03106822\n",
      "epoch: 118  batch: 5  loss: 0.08621769\n",
      "epoch: 118  batch: 6  loss: 0.07624426\n",
      "epoch: 118  batch: 7  loss: 0.18666558\n",
      "epoch: 118  batch: 8  loss: 0.06205834\n",
      "epoch: 118  batch: 9  loss: 0.07616129\n",
      "epoch: 118  batch: 10  loss: 0.16968545\n",
      "epoch: 118  batch: 11  loss: 0.21900928\n",
      "epoch: 118  batch: 12  loss: 0.07523529\n",
      "epoch: 118  batch: 13  loss: 0.07580531\n",
      "epoch: 118  batch: 14  loss: 0.14295557\n",
      "epoch: 118  batch: 15  loss: 0.11586093\n",
      "epoch: 118  batch: 16  loss: 0.05145929\n",
      "epoch: 118  batch: 17  loss: 0.05153622\n",
      "epoch: 118  batch: 18  loss: 0.04943978\n",
      "epoch: 118  batch: 19  loss: 0.05217961\n",
      "epoch: 118  batch: 20  loss: 0.25501952\n",
      "epoch: 118  batch: 21  loss: 0.28230980\n",
      "epoch: 118  batch: 22  loss: 0.05375452\n",
      "epoch: 118  batch: 23  loss: 0.04299097\n",
      "epoch: 118  batch: 24  loss: 0.06985375\n",
      "epoch: 118  batch: 25  loss: 0.07222722\n",
      "epoch: 118  batch: 26  loss: 0.01854221\n",
      "epoch: 118  batch: 27  loss: 0.05749180\n",
      "epoch: 118  batch: 28  loss: 0.01543439\n",
      "epoch: 118  batch: 29  loss: 0.01592711\n",
      "epoch: 118  batch: 30  loss: 0.01732833\n",
      "epoch: 118  batch: 31  loss: 0.02632000\n",
      "epoch: 118  batch: 32  loss: 0.01214161\n",
      "epoch: 118  batch: 33  loss: 0.03432669\n",
      "epoch: 118  batch: 34  loss: 0.09518744\n",
      "epoch: 118  batch: 35  loss: 0.13729873\n",
      "epoch: 118  batch: 36  loss: 0.07191601\n",
      "epoch: 118  batch: 37  loss: 0.03844535\n",
      "epoch: 118  batch: 38  loss: 0.03387815\n",
      "epoch: 118  batch: 39  loss: 0.12509389\n",
      "epoch: 118  batch: 40  loss: 0.06742363\n",
      "epoch: 118  batch: 41  loss: 0.15996742\n",
      "epoch: 118  batch: 42  loss: 0.06903496\n",
      "epoch: 118  batch: 43  loss: 0.11111195\n",
      "epoch: 118  batch: 44  loss: 0.16705498\n",
      "epoch: 118  batch: 45  loss: 0.16930504\n",
      "epoch: 118  batch: 46  loss: 0.08730920\n",
      "epoch: 118  batch: 47  loss: 0.07743744\n",
      "epoch: 118  batch: 48  loss: 0.12618175\n",
      "epoch: 118  batch: 49  loss: 0.13623449\n",
      "epoch: 118  batch: 50  loss: 0.13728222\n",
      "epoch: 118  batch: 51  loss: 0.07846238\n",
      "epoch: 118  batch: 52  loss: 0.08874545\n",
      "epoch: 118  batch: 53  loss: 0.05758762\n",
      "epoch: 118  batch: 54  loss: 0.32668102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 118  batch: 55  loss: 0.20768510\n",
      "epoch: 118  batch: 56  loss: 0.08049925\n",
      "epoch: 118  batch: 57  loss: 0.04292401\n",
      "epoch: 118  batch: 58  loss: 0.10186175\n",
      "epoch: 118  batch: 59  loss: 0.08089497\n",
      "epoch: 118  batch: 60  loss: 0.03651116\n",
      "epoch: 118  batch: 61  loss: 0.30228752\n",
      "epoch: 118  batch: 62  loss: 0.08165490\n",
      "epoch: 118  batch: 63  loss: 0.02761540\n",
      "epoch: 118  batch: 64  loss: 0.02066438\n",
      "epoch: 118  batch: 65  loss: 0.04083997\n",
      "epoch: 118  batch: 66  loss: 0.04038896\n",
      "epoch: 118  batch: 67  loss: 0.03349531\n",
      "epoch: 118  batch: 68  loss: 0.04932909\n",
      "epoch: 119  batch: 1  loss: 0.12787069\n",
      "epoch: 119  batch: 2  loss: 0.04544005\n",
      "epoch: 119  batch: 3  loss: 0.03315436\n",
      "epoch: 119  batch: 4  loss: 0.03081630\n",
      "epoch: 119  batch: 5  loss: 0.08576554\n",
      "epoch: 119  batch: 6  loss: 0.07507990\n",
      "epoch: 119  batch: 7  loss: 0.18610294\n",
      "epoch: 119  batch: 8  loss: 0.06118700\n",
      "epoch: 119  batch: 9  loss: 0.07496638\n",
      "epoch: 119  batch: 10  loss: 0.16621891\n",
      "epoch: 119  batch: 11  loss: 0.21598952\n",
      "epoch: 119  batch: 12  loss: 0.07462958\n",
      "epoch: 119  batch: 13  loss: 0.07246573\n",
      "epoch: 119  batch: 14  loss: 0.14137433\n",
      "epoch: 119  batch: 15  loss: 0.11672343\n",
      "epoch: 119  batch: 16  loss: 0.05084661\n",
      "epoch: 119  batch: 17  loss: 0.05070963\n",
      "epoch: 119  batch: 18  loss: 0.05001078\n",
      "epoch: 119  batch: 19  loss: 0.05197132\n",
      "epoch: 119  batch: 20  loss: 0.25103796\n",
      "epoch: 119  batch: 21  loss: 0.28088456\n",
      "epoch: 119  batch: 22  loss: 0.05356497\n",
      "epoch: 119  batch: 23  loss: 0.04279274\n",
      "epoch: 119  batch: 24  loss: 0.07001308\n",
      "epoch: 119  batch: 25  loss: 0.07235438\n",
      "epoch: 119  batch: 26  loss: 0.01877846\n",
      "epoch: 119  batch: 27  loss: 0.05516968\n",
      "epoch: 119  batch: 28  loss: 0.01525548\n",
      "epoch: 119  batch: 29  loss: 0.01670389\n",
      "epoch: 119  batch: 30  loss: 0.01723737\n",
      "epoch: 119  batch: 31  loss: 0.02591283\n",
      "epoch: 119  batch: 32  loss: 0.01218474\n",
      "epoch: 119  batch: 33  loss: 0.03128267\n",
      "epoch: 119  batch: 34  loss: 0.09519182\n",
      "epoch: 119  batch: 35  loss: 0.13644834\n",
      "epoch: 119  batch: 36  loss: 0.07301084\n",
      "epoch: 119  batch: 37  loss: 0.03861655\n",
      "epoch: 119  batch: 38  loss: 0.03359082\n",
      "epoch: 119  batch: 39  loss: 0.12377548\n",
      "epoch: 119  batch: 40  loss: 0.06794053\n",
      "epoch: 119  batch: 41  loss: 0.15925018\n",
      "epoch: 119  batch: 42  loss: 0.06871665\n",
      "epoch: 119  batch: 43  loss: 0.10955177\n",
      "epoch: 119  batch: 44  loss: 0.16472760\n",
      "epoch: 119  batch: 45  loss: 0.16514921\n",
      "epoch: 119  batch: 46  loss: 0.08599117\n",
      "epoch: 119  batch: 47  loss: 0.07621453\n",
      "epoch: 119  batch: 48  loss: 0.12573861\n",
      "epoch: 119  batch: 49  loss: 0.13679986\n",
      "epoch: 119  batch: 50  loss: 0.13395512\n",
      "epoch: 119  batch: 51  loss: 0.07857062\n",
      "epoch: 119  batch: 52  loss: 0.08872715\n",
      "epoch: 119  batch: 53  loss: 0.05687850\n",
      "epoch: 119  batch: 54  loss: 0.32648554\n",
      "epoch: 119  batch: 55  loss: 0.20762579\n",
      "epoch: 119  batch: 56  loss: 0.08040398\n",
      "epoch: 119  batch: 57  loss: 0.04282596\n",
      "epoch: 119  batch: 58  loss: 0.10001481\n",
      "epoch: 119  batch: 59  loss: 0.08504277\n",
      "epoch: 119  batch: 60  loss: 0.03397224\n",
      "epoch: 119  batch: 61  loss: 0.28508660\n",
      "epoch: 119  batch: 62  loss: 0.07564007\n",
      "epoch: 119  batch: 63  loss: 0.02712806\n",
      "epoch: 119  batch: 64  loss: 0.02034793\n",
      "epoch: 119  batch: 65  loss: 0.04059711\n",
      "epoch: 119  batch: 66  loss: 0.03953268\n",
      "epoch: 119  batch: 67  loss: 0.03164559\n",
      "epoch: 119  batch: 68  loss: 0.04927798\n",
      "epoch: 120  batch: 1  loss: 0.12692763\n",
      "epoch: 120  batch: 2  loss: 0.04730581\n",
      "epoch: 120  batch: 3  loss: 0.03290224\n",
      "epoch: 120  batch: 4  loss: 0.03216643\n",
      "epoch: 120  batch: 5  loss: 0.08529396\n",
      "epoch: 120  batch: 6  loss: 0.07551929\n",
      "epoch: 120  batch: 7  loss: 0.18377173\n",
      "epoch: 120  batch: 8  loss: 0.06045740\n",
      "epoch: 120  batch: 9  loss: 0.07449104\n",
      "epoch: 120  batch: 10  loss: 0.16413189\n",
      "epoch: 120  batch: 11  loss: 0.21273020\n",
      "epoch: 120  batch: 12  loss: 0.07463564\n",
      "epoch: 120  batch: 13  loss: 0.06867465\n",
      "epoch: 120  batch: 14  loss: 0.14177713\n",
      "epoch: 120  batch: 15  loss: 0.11727150\n",
      "epoch: 120  batch: 16  loss: 0.04884989\n",
      "epoch: 120  batch: 17  loss: 0.05132733\n",
      "epoch: 120  batch: 18  loss: 0.04858409\n",
      "epoch: 120  batch: 19  loss: 0.05137547\n",
      "epoch: 120  batch: 20  loss: 0.24829026\n",
      "epoch: 120  batch: 21  loss: 0.27930182\n",
      "epoch: 120  batch: 22  loss: 0.05324925\n",
      "epoch: 120  batch: 23  loss: 0.04383181\n",
      "epoch: 120  batch: 24  loss: 0.07010598\n",
      "epoch: 120  batch: 25  loss: 0.07015463\n",
      "epoch: 120  batch: 26  loss: 0.01947233\n",
      "epoch: 120  batch: 27  loss: 0.05322894\n",
      "epoch: 120  batch: 28  loss: 0.01483816\n",
      "epoch: 120  batch: 29  loss: 0.01714864\n",
      "epoch: 120  batch: 30  loss: 0.01654806\n",
      "epoch: 120  batch: 31  loss: 0.02609489\n",
      "epoch: 120  batch: 32  loss: 0.01218175\n",
      "epoch: 120  batch: 33  loss: 0.03087675\n",
      "epoch: 120  batch: 34  loss: 0.09729739\n",
      "epoch: 120  batch: 35  loss: 0.13616008\n",
      "epoch: 120  batch: 36  loss: 0.07399309\n",
      "epoch: 120  batch: 37  loss: 0.03819461\n",
      "epoch: 120  batch: 38  loss: 0.03311418\n",
      "epoch: 120  batch: 39  loss: 0.12366863\n",
      "epoch: 120  batch: 40  loss: 0.06913829\n",
      "epoch: 120  batch: 41  loss: 0.15839441\n",
      "epoch: 120  batch: 42  loss: 0.06827100\n",
      "epoch: 120  batch: 43  loss: 0.10722648\n",
      "epoch: 120  batch: 44  loss: 0.16323514\n",
      "epoch: 120  batch: 45  loss: 0.16365814\n",
      "epoch: 120  batch: 46  loss: 0.08705924\n",
      "epoch: 120  batch: 47  loss: 0.07597503\n",
      "epoch: 120  batch: 48  loss: 0.12149365\n",
      "epoch: 120  batch: 49  loss: 0.13744879\n",
      "epoch: 120  batch: 50  loss: 0.13087970\n",
      "epoch: 120  batch: 51  loss: 0.07864092\n",
      "epoch: 120  batch: 52  loss: 0.08612740\n",
      "epoch: 120  batch: 53  loss: 0.05758812\n",
      "epoch: 120  batch: 54  loss: 0.32365188\n",
      "epoch: 120  batch: 55  loss: 0.20811866\n",
      "epoch: 120  batch: 56  loss: 0.08121366\n",
      "epoch: 120  batch: 57  loss: 0.04341053\n",
      "epoch: 120  batch: 58  loss: 0.09888625\n",
      "epoch: 120  batch: 59  loss: 0.09514445\n",
      "epoch: 120  batch: 60  loss: 0.03369350\n",
      "epoch: 120  batch: 61  loss: 0.27043980\n",
      "epoch: 120  batch: 62  loss: 0.06815948\n",
      "epoch: 120  batch: 63  loss: 0.02651670\n",
      "epoch: 120  batch: 64  loss: 0.02049769\n",
      "epoch: 120  batch: 65  loss: 0.04040885\n",
      "epoch: 120  batch: 66  loss: 0.03956472\n",
      "epoch: 120  batch: 67  loss: 0.03215655\n",
      "epoch: 120  batch: 68  loss: 0.04912191\n",
      "epoch: 121  batch: 1  loss: 0.12664874\n",
      "epoch: 121  batch: 2  loss: 0.04738629\n",
      "epoch: 121  batch: 3  loss: 0.03267352\n",
      "epoch: 121  batch: 4  loss: 0.03132418\n",
      "epoch: 121  batch: 5  loss: 0.08479238\n",
      "epoch: 121  batch: 6  loss: 0.07416958\n",
      "epoch: 121  batch: 7  loss: 0.18316354\n",
      "epoch: 121  batch: 8  loss: 0.05969503\n",
      "epoch: 121  batch: 9  loss: 0.07336376\n",
      "epoch: 121  batch: 10  loss: 0.16066082\n",
      "epoch: 121  batch: 11  loss: 0.21070762\n",
      "epoch: 121  batch: 12  loss: 0.07412963\n",
      "epoch: 121  batch: 13  loss: 0.06581160\n",
      "epoch: 121  batch: 14  loss: 0.14120005\n",
      "epoch: 121  batch: 15  loss: 0.11814877\n",
      "epoch: 121  batch: 16  loss: 0.04951366\n",
      "epoch: 121  batch: 17  loss: 0.04997809\n",
      "epoch: 121  batch: 18  loss: 0.04886758\n",
      "epoch: 121  batch: 19  loss: 0.05059187\n",
      "epoch: 121  batch: 20  loss: 0.24650255\n",
      "epoch: 121  batch: 21  loss: 0.27755404\n",
      "epoch: 121  batch: 22  loss: 0.05317405\n",
      "epoch: 121  batch: 23  loss: 0.04210133\n",
      "epoch: 121  batch: 24  loss: 0.07052004\n",
      "epoch: 121  batch: 25  loss: 0.07076877\n",
      "epoch: 121  batch: 26  loss: 0.01995881\n",
      "epoch: 121  batch: 27  loss: 0.05026008\n",
      "epoch: 121  batch: 28  loss: 0.01473799\n",
      "epoch: 121  batch: 29  loss: 0.01763485\n",
      "epoch: 121  batch: 30  loss: 0.01617901\n",
      "epoch: 121  batch: 31  loss: 0.02564573\n",
      "epoch: 121  batch: 32  loss: 0.01207485\n",
      "epoch: 121  batch: 33  loss: 0.02814131\n",
      "epoch: 121  batch: 34  loss: 0.09647470\n",
      "epoch: 121  batch: 35  loss: 0.13531308\n",
      "epoch: 121  batch: 36  loss: 0.07473917\n",
      "epoch: 121  batch: 37  loss: 0.03846316\n",
      "epoch: 121  batch: 38  loss: 0.03310632\n",
      "epoch: 121  batch: 39  loss: 0.12219881\n",
      "epoch: 121  batch: 40  loss: 0.06937898\n",
      "epoch: 121  batch: 41  loss: 0.15762845\n",
      "epoch: 121  batch: 42  loss: 0.06800430\n",
      "epoch: 121  batch: 43  loss: 0.10584208\n",
      "epoch: 121  batch: 44  loss: 0.15979275\n",
      "epoch: 121  batch: 45  loss: 0.15961908\n",
      "epoch: 121  batch: 46  loss: 0.08437646\n",
      "epoch: 121  batch: 47  loss: 0.07533025\n",
      "epoch: 121  batch: 48  loss: 0.12186373\n",
      "epoch: 121  batch: 49  loss: 0.13823128\n",
      "epoch: 121  batch: 50  loss: 0.12666407\n",
      "epoch: 121  batch: 51  loss: 0.07839607\n",
      "epoch: 121  batch: 52  loss: 0.08599930\n",
      "epoch: 121  batch: 53  loss: 0.05614146\n",
      "epoch: 121  batch: 54  loss: 0.32365870\n",
      "epoch: 121  batch: 55  loss: 0.20604935\n",
      "epoch: 121  batch: 56  loss: 0.08074114\n",
      "epoch: 121  batch: 57  loss: 0.04240083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121  batch: 58  loss: 0.09753058\n",
      "epoch: 121  batch: 59  loss: 0.09145959\n",
      "epoch: 121  batch: 60  loss: 0.03177845\n",
      "epoch: 121  batch: 61  loss: 0.25655928\n",
      "epoch: 121  batch: 62  loss: 0.06004220\n",
      "epoch: 121  batch: 63  loss: 0.02561545\n",
      "epoch: 121  batch: 64  loss: 0.02019162\n",
      "epoch: 121  batch: 65  loss: 0.03969243\n",
      "epoch: 121  batch: 66  loss: 0.04015757\n",
      "epoch: 121  batch: 67  loss: 0.03258846\n",
      "epoch: 121  batch: 68  loss: 0.04888561\n",
      "epoch: 122  batch: 1  loss: 0.12638466\n",
      "epoch: 122  batch: 2  loss: 0.04703120\n",
      "epoch: 122  batch: 3  loss: 0.03276037\n",
      "epoch: 122  batch: 4  loss: 0.03080643\n",
      "epoch: 122  batch: 5  loss: 0.08471830\n",
      "epoch: 122  batch: 6  loss: 0.07302156\n",
      "epoch: 122  batch: 7  loss: 0.18289287\n",
      "epoch: 122  batch: 8  loss: 0.05920415\n",
      "epoch: 122  batch: 9  loss: 0.07226298\n",
      "epoch: 122  batch: 10  loss: 0.15810236\n",
      "epoch: 122  batch: 11  loss: 0.20768276\n",
      "epoch: 122  batch: 12  loss: 0.07336094\n",
      "epoch: 122  batch: 13  loss: 0.06296389\n",
      "epoch: 122  batch: 14  loss: 0.13977094\n",
      "epoch: 122  batch: 15  loss: 0.11877631\n",
      "epoch: 122  batch: 16  loss: 0.04917801\n",
      "epoch: 122  batch: 17  loss: 0.05111154\n",
      "epoch: 122  batch: 18  loss: 0.04948561\n",
      "epoch: 122  batch: 19  loss: 0.05092524\n",
      "epoch: 122  batch: 20  loss: 0.24335964\n",
      "epoch: 122  batch: 21  loss: 0.27632460\n",
      "epoch: 122  batch: 22  loss: 0.05297524\n",
      "epoch: 122  batch: 23  loss: 0.04104552\n",
      "epoch: 122  batch: 24  loss: 0.07089831\n",
      "epoch: 122  batch: 25  loss: 0.07107452\n",
      "epoch: 122  batch: 26  loss: 0.02002656\n",
      "epoch: 122  batch: 27  loss: 0.04895116\n",
      "epoch: 122  batch: 28  loss: 0.01448063\n",
      "epoch: 122  batch: 29  loss: 0.01601208\n",
      "epoch: 122  batch: 30  loss: 0.01635946\n",
      "epoch: 122  batch: 31  loss: 0.02542772\n",
      "epoch: 122  batch: 32  loss: 0.01190598\n",
      "epoch: 122  batch: 33  loss: 0.02925850\n",
      "epoch: 122  batch: 34  loss: 0.09572639\n",
      "epoch: 122  batch: 35  loss: 0.13565257\n",
      "epoch: 122  batch: 36  loss: 0.07572216\n",
      "epoch: 122  batch: 37  loss: 0.03790081\n",
      "epoch: 122  batch: 38  loss: 0.03286205\n",
      "epoch: 122  batch: 39  loss: 0.12222513\n",
      "epoch: 122  batch: 40  loss: 0.06974243\n",
      "epoch: 122  batch: 41  loss: 0.15715796\n",
      "epoch: 122  batch: 42  loss: 0.06754160\n",
      "epoch: 122  batch: 43  loss: 0.10462326\n",
      "epoch: 122  batch: 44  loss: 0.15557989\n",
      "epoch: 122  batch: 45  loss: 0.15849885\n",
      "epoch: 122  batch: 46  loss: 0.08346871\n",
      "epoch: 122  batch: 47  loss: 0.07622633\n",
      "epoch: 122  batch: 48  loss: 0.11772713\n",
      "epoch: 122  batch: 49  loss: 0.13894854\n",
      "epoch: 122  batch: 50  loss: 0.11861878\n",
      "epoch: 122  batch: 51  loss: 0.07926058\n",
      "epoch: 122  batch: 52  loss: 0.08587261\n",
      "epoch: 122  batch: 53  loss: 0.05567155\n",
      "epoch: 122  batch: 54  loss: 0.32338649\n",
      "epoch: 122  batch: 55  loss: 0.20588376\n",
      "epoch: 122  batch: 56  loss: 0.08030068\n",
      "epoch: 122  batch: 57  loss: 0.04219929\n",
      "epoch: 122  batch: 58  loss: 0.09680038\n",
      "epoch: 122  batch: 59  loss: 0.08486845\n",
      "epoch: 122  batch: 60  loss: 0.03130430\n",
      "epoch: 122  batch: 61  loss: 0.24128199\n",
      "epoch: 122  batch: 62  loss: 0.05089149\n",
      "epoch: 122  batch: 63  loss: 0.02412064\n",
      "epoch: 122  batch: 64  loss: 0.02043524\n",
      "epoch: 122  batch: 65  loss: 0.04000738\n",
      "epoch: 122  batch: 66  loss: 0.04069380\n",
      "epoch: 122  batch: 67  loss: 0.03330754\n",
      "epoch: 122  batch: 68  loss: 0.04880450\n",
      "epoch: 123  batch: 1  loss: 0.12609655\n",
      "epoch: 123  batch: 2  loss: 0.04677640\n",
      "epoch: 123  batch: 3  loss: 0.03263849\n",
      "epoch: 123  batch: 4  loss: 0.03067785\n",
      "epoch: 123  batch: 5  loss: 0.08440486\n",
      "epoch: 123  batch: 6  loss: 0.07249349\n",
      "epoch: 123  batch: 7  loss: 0.18259139\n",
      "epoch: 123  batch: 8  loss: 0.05868925\n",
      "epoch: 123  batch: 9  loss: 0.07106494\n",
      "epoch: 123  batch: 10  loss: 0.15457031\n",
      "epoch: 123  batch: 11  loss: 0.20439498\n",
      "epoch: 123  batch: 12  loss: 0.07221109\n",
      "epoch: 123  batch: 13  loss: 0.06148777\n",
      "epoch: 123  batch: 14  loss: 0.13878274\n",
      "epoch: 123  batch: 15  loss: 0.11960755\n",
      "epoch: 123  batch: 16  loss: 0.04776626\n",
      "epoch: 123  batch: 17  loss: 0.04897652\n",
      "epoch: 123  batch: 18  loss: 0.04953993\n",
      "epoch: 123  batch: 19  loss: 0.05057961\n",
      "epoch: 123  batch: 20  loss: 0.24212515\n",
      "epoch: 123  batch: 21  loss: 0.27485415\n",
      "epoch: 123  batch: 22  loss: 0.05295156\n",
      "epoch: 123  batch: 23  loss: 0.04118189\n",
      "epoch: 123  batch: 24  loss: 0.07090644\n",
      "epoch: 123  batch: 25  loss: 0.07089704\n",
      "epoch: 123  batch: 26  loss: 0.01967366\n",
      "epoch: 123  batch: 27  loss: 0.04756333\n",
      "epoch: 123  batch: 28  loss: 0.01428317\n",
      "epoch: 123  batch: 29  loss: 0.01698357\n",
      "epoch: 123  batch: 30  loss: 0.01627810\n",
      "epoch: 123  batch: 31  loss: 0.02479310\n",
      "epoch: 123  batch: 32  loss: 0.01202409\n",
      "epoch: 123  batch: 33  loss: 0.02473751\n",
      "epoch: 123  batch: 34  loss: 0.09597655\n",
      "epoch: 123  batch: 35  loss: 0.13466698\n",
      "epoch: 123  batch: 36  loss: 0.07711376\n",
      "epoch: 123  batch: 37  loss: 0.03804088\n",
      "epoch: 123  batch: 38  loss: 0.03266493\n",
      "epoch: 123  batch: 39  loss: 0.12044063\n",
      "epoch: 123  batch: 40  loss: 0.07034186\n",
      "epoch: 123  batch: 41  loss: 0.15643644\n",
      "epoch: 123  batch: 42  loss: 0.06730888\n",
      "epoch: 123  batch: 43  loss: 0.10275467\n",
      "epoch: 123  batch: 44  loss: 0.15210623\n",
      "epoch: 123  batch: 45  loss: 0.15438175\n",
      "epoch: 123  batch: 46  loss: 0.08289085\n",
      "epoch: 123  batch: 47  loss: 0.07466435\n",
      "epoch: 123  batch: 48  loss: 0.11732966\n",
      "epoch: 123  batch: 49  loss: 0.13927427\n",
      "epoch: 123  batch: 50  loss: 0.11760698\n",
      "epoch: 123  batch: 51  loss: 0.07936902\n",
      "epoch: 123  batch: 52  loss: 0.08514747\n",
      "epoch: 123  batch: 53  loss: 0.05548532\n",
      "epoch: 123  batch: 54  loss: 0.32360688\n",
      "epoch: 123  batch: 55  loss: 0.20481373\n",
      "epoch: 123  batch: 56  loss: 0.08010264\n",
      "epoch: 123  batch: 57  loss: 0.04181568\n",
      "epoch: 123  batch: 58  loss: 0.09514332\n",
      "epoch: 123  batch: 59  loss: 0.08280213\n",
      "epoch: 123  batch: 60  loss: 0.02940838\n",
      "epoch: 123  batch: 61  loss: 0.22852449\n",
      "epoch: 123  batch: 62  loss: 0.04436349\n",
      "epoch: 123  batch: 63  loss: 0.02373587\n",
      "epoch: 123  batch: 64  loss: 0.01988724\n",
      "epoch: 123  batch: 65  loss: 0.03996178\n",
      "epoch: 123  batch: 66  loss: 0.03967766\n",
      "epoch: 123  batch: 67  loss: 0.03089964\n",
      "epoch: 123  batch: 68  loss: 0.04880489\n",
      "epoch: 124  batch: 1  loss: 0.12531967\n",
      "epoch: 124  batch: 2  loss: 0.04883713\n",
      "epoch: 124  batch: 3  loss: 0.03252786\n",
      "epoch: 124  batch: 4  loss: 0.03261019\n",
      "epoch: 124  batch: 5  loss: 0.08408717\n",
      "epoch: 124  batch: 6  loss: 0.07283602\n",
      "epoch: 124  batch: 7  loss: 0.18024278\n",
      "epoch: 124  batch: 8  loss: 0.05834265\n",
      "epoch: 124  batch: 9  loss: 0.07065888\n",
      "epoch: 124  batch: 10  loss: 0.15322736\n",
      "epoch: 124  batch: 11  loss: 0.20094715\n",
      "epoch: 124  batch: 12  loss: 0.07163086\n",
      "epoch: 124  batch: 13  loss: 0.05844085\n",
      "epoch: 124  batch: 14  loss: 0.13843220\n",
      "epoch: 124  batch: 15  loss: 0.12005069\n",
      "epoch: 124  batch: 16  loss: 0.04582991\n",
      "epoch: 124  batch: 17  loss: 0.04950582\n",
      "epoch: 124  batch: 18  loss: 0.04805787\n",
      "epoch: 124  batch: 19  loss: 0.05023916\n",
      "epoch: 124  batch: 20  loss: 0.24081063\n",
      "epoch: 124  batch: 21  loss: 0.27347225\n",
      "epoch: 124  batch: 22  loss: 0.05275016\n",
      "epoch: 124  batch: 23  loss: 0.04220296\n",
      "epoch: 124  batch: 24  loss: 0.07091991\n",
      "epoch: 124  batch: 25  loss: 0.06913957\n",
      "epoch: 124  batch: 26  loss: 0.02045163\n",
      "epoch: 124  batch: 27  loss: 0.04617995\n",
      "epoch: 124  batch: 28  loss: 0.01383312\n",
      "epoch: 124  batch: 29  loss: 0.01681376\n",
      "epoch: 124  batch: 30  loss: 0.01619287\n",
      "epoch: 124  batch: 31  loss: 0.02493373\n",
      "epoch: 124  batch: 32  loss: 0.01200857\n",
      "epoch: 124  batch: 33  loss: 0.02401809\n",
      "epoch: 124  batch: 34  loss: 0.09816312\n",
      "epoch: 124  batch: 35  loss: 0.13536581\n",
      "epoch: 124  batch: 36  loss: 0.07818767\n",
      "epoch: 124  batch: 37  loss: 0.03738502\n",
      "epoch: 124  batch: 38  loss: 0.03268375\n",
      "epoch: 124  batch: 39  loss: 0.12033627\n",
      "epoch: 124  batch: 40  loss: 0.07167131\n",
      "epoch: 124  batch: 41  loss: 0.15566321\n",
      "epoch: 124  batch: 42  loss: 0.06691529\n",
      "epoch: 124  batch: 43  loss: 0.10006680\n",
      "epoch: 124  batch: 44  loss: 0.15006213\n",
      "epoch: 124  batch: 45  loss: 0.15319879\n",
      "epoch: 124  batch: 46  loss: 0.08356643\n",
      "epoch: 124  batch: 47  loss: 0.07436913\n",
      "epoch: 124  batch: 48  loss: 0.11398678\n",
      "epoch: 124  batch: 49  loss: 0.13970555\n",
      "epoch: 124  batch: 50  loss: 0.11389747\n",
      "epoch: 124  batch: 51  loss: 0.07894426\n",
      "epoch: 124  batch: 52  loss: 0.08212308\n",
      "epoch: 124  batch: 53  loss: 0.05619717\n",
      "epoch: 124  batch: 54  loss: 0.32091674\n",
      "epoch: 124  batch: 55  loss: 0.20644811\n",
      "epoch: 124  batch: 56  loss: 0.08111565\n",
      "epoch: 124  batch: 57  loss: 0.04243418\n",
      "epoch: 124  batch: 58  loss: 0.09391566\n",
      "epoch: 124  batch: 59  loss: 0.09417909\n",
      "epoch: 124  batch: 60  loss: 0.02957831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 124  batch: 61  loss: 0.21887042\n",
      "epoch: 124  batch: 62  loss: 0.03990813\n",
      "epoch: 124  batch: 63  loss: 0.02339012\n",
      "epoch: 124  batch: 64  loss: 0.02026834\n",
      "epoch: 124  batch: 65  loss: 0.03937712\n",
      "epoch: 124  batch: 66  loss: 0.03982591\n",
      "epoch: 124  batch: 67  loss: 0.03131703\n",
      "epoch: 124  batch: 68  loss: 0.04870238\n",
      "epoch: 125  batch: 1  loss: 0.12502448\n",
      "epoch: 125  batch: 2  loss: 0.04832089\n",
      "epoch: 125  batch: 3  loss: 0.03228236\n",
      "epoch: 125  batch: 4  loss: 0.03113125\n",
      "epoch: 125  batch: 5  loss: 0.08355881\n",
      "epoch: 125  batch: 6  loss: 0.07162406\n",
      "epoch: 125  batch: 7  loss: 0.17967464\n",
      "epoch: 125  batch: 8  loss: 0.05775662\n",
      "epoch: 125  batch: 9  loss: 0.06947049\n",
      "epoch: 125  batch: 10  loss: 0.14888375\n",
      "epoch: 125  batch: 11  loss: 0.19903594\n",
      "epoch: 125  batch: 12  loss: 0.07049269\n",
      "epoch: 125  batch: 13  loss: 0.05677329\n",
      "epoch: 125  batch: 14  loss: 0.13829155\n",
      "epoch: 125  batch: 15  loss: 0.12097751\n",
      "epoch: 125  batch: 16  loss: 0.04645356\n",
      "epoch: 125  batch: 17  loss: 0.04793724\n",
      "epoch: 125  batch: 18  loss: 0.04826292\n",
      "epoch: 125  batch: 19  loss: 0.04945776\n",
      "epoch: 125  batch: 20  loss: 0.23949917\n",
      "epoch: 125  batch: 21  loss: 0.27183083\n",
      "epoch: 125  batch: 22  loss: 0.05261315\n",
      "epoch: 125  batch: 23  loss: 0.04014315\n",
      "epoch: 125  batch: 24  loss: 0.07124889\n",
      "epoch: 125  batch: 25  loss: 0.06996800\n",
      "epoch: 125  batch: 26  loss: 0.02054674\n",
      "epoch: 125  batch: 27  loss: 0.04410349\n",
      "epoch: 125  batch: 28  loss: 0.01452792\n",
      "epoch: 125  batch: 29  loss: 0.01643163\n",
      "epoch: 125  batch: 30  loss: 0.01589496\n",
      "epoch: 125  batch: 31  loss: 0.02460331\n",
      "epoch: 125  batch: 32  loss: 0.01185850\n",
      "epoch: 125  batch: 33  loss: 0.02288239\n",
      "epoch: 125  batch: 34  loss: 0.09711992\n",
      "epoch: 125  batch: 35  loss: 0.13444428\n",
      "epoch: 125  batch: 36  loss: 0.07904830\n",
      "epoch: 125  batch: 37  loss: 0.03739563\n",
      "epoch: 125  batch: 38  loss: 0.03265790\n",
      "epoch: 125  batch: 39  loss: 0.11946328\n",
      "epoch: 125  batch: 40  loss: 0.07176808\n",
      "epoch: 125  batch: 41  loss: 0.15487695\n",
      "epoch: 125  batch: 42  loss: 0.06660892\n",
      "epoch: 125  batch: 43  loss: 0.09857316\n",
      "epoch: 125  batch: 44  loss: 0.14531878\n",
      "epoch: 125  batch: 45  loss: 0.15082183\n",
      "epoch: 125  batch: 46  loss: 0.08156249\n",
      "epoch: 125  batch: 47  loss: 0.07452506\n",
      "epoch: 125  batch: 48  loss: 0.11324418\n",
      "epoch: 125  batch: 49  loss: 0.14038169\n",
      "epoch: 125  batch: 50  loss: 0.11085501\n",
      "epoch: 125  batch: 51  loss: 0.07929228\n",
      "epoch: 125  batch: 52  loss: 0.08104447\n",
      "epoch: 125  batch: 53  loss: 0.05509979\n",
      "epoch: 125  batch: 54  loss: 0.32100263\n",
      "epoch: 125  batch: 55  loss: 0.20317031\n",
      "epoch: 125  batch: 56  loss: 0.08067932\n",
      "epoch: 125  batch: 57  loss: 0.04109032\n",
      "epoch: 125  batch: 58  loss: 0.09325510\n",
      "epoch: 125  batch: 59  loss: 0.08542468\n",
      "epoch: 125  batch: 60  loss: 0.02890472\n",
      "epoch: 125  batch: 61  loss: 0.20825128\n",
      "epoch: 125  batch: 62  loss: 0.03686377\n",
      "epoch: 125  batch: 63  loss: 0.02230979\n",
      "epoch: 125  batch: 64  loss: 0.02016463\n",
      "epoch: 125  batch: 65  loss: 0.03908069\n",
      "epoch: 125  batch: 66  loss: 0.04049378\n",
      "epoch: 125  batch: 67  loss: 0.03191863\n",
      "epoch: 125  batch: 68  loss: 0.04847063\n",
      "epoch: 126  batch: 1  loss: 0.12492320\n",
      "epoch: 126  batch: 2  loss: 0.04777633\n",
      "epoch: 126  batch: 3  loss: 0.03224422\n",
      "epoch: 126  batch: 4  loss: 0.03059083\n",
      "epoch: 126  batch: 5  loss: 0.08343317\n",
      "epoch: 126  batch: 6  loss: 0.07098489\n",
      "epoch: 126  batch: 7  loss: 0.17939304\n",
      "epoch: 126  batch: 8  loss: 0.05735265\n",
      "epoch: 126  batch: 9  loss: 0.06838517\n",
      "epoch: 126  batch: 10  loss: 0.14655922\n",
      "epoch: 126  batch: 11  loss: 0.19588047\n",
      "epoch: 126  batch: 12  loss: 0.06935192\n",
      "epoch: 126  batch: 13  loss: 0.05461396\n",
      "epoch: 126  batch: 14  loss: 0.13688424\n",
      "epoch: 126  batch: 15  loss: 0.12165432\n",
      "epoch: 126  batch: 16  loss: 0.04564958\n",
      "epoch: 126  batch: 17  loss: 0.04752388\n",
      "epoch: 126  batch: 18  loss: 0.04867747\n",
      "epoch: 126  batch: 19  loss: 0.04937685\n",
      "epoch: 126  batch: 20  loss: 0.23795377\n",
      "epoch: 126  batch: 21  loss: 0.27064341\n",
      "epoch: 126  batch: 22  loss: 0.05253292\n",
      "epoch: 126  batch: 23  loss: 0.03979357\n",
      "epoch: 126  batch: 24  loss: 0.07125553\n",
      "epoch: 126  batch: 25  loss: 0.07020563\n",
      "epoch: 126  batch: 26  loss: 0.02019617\n",
      "epoch: 126  batch: 27  loss: 0.04316724\n",
      "epoch: 126  batch: 28  loss: 0.01386765\n",
      "epoch: 126  batch: 29  loss: 0.01616313\n",
      "epoch: 126  batch: 30  loss: 0.01586253\n",
      "epoch: 126  batch: 31  loss: 0.02423040\n",
      "epoch: 126  batch: 32  loss: 0.01186179\n",
      "epoch: 126  batch: 33  loss: 0.02149946\n",
      "epoch: 126  batch: 34  loss: 0.09657145\n",
      "epoch: 126  batch: 35  loss: 0.13424283\n",
      "epoch: 126  batch: 36  loss: 0.08021105\n",
      "epoch: 126  batch: 37  loss: 0.03727932\n",
      "epoch: 126  batch: 38  loss: 0.03268299\n",
      "epoch: 126  batch: 39  loss: 0.11872190\n",
      "epoch: 126  batch: 40  loss: 0.07209400\n",
      "epoch: 126  batch: 41  loss: 0.15444490\n",
      "epoch: 126  batch: 42  loss: 0.06626049\n",
      "epoch: 126  batch: 43  loss: 0.09740934\n",
      "epoch: 126  batch: 44  loss: 0.14208405\n",
      "epoch: 126  batch: 45  loss: 0.14841951\n",
      "epoch: 126  batch: 46  loss: 0.08083500\n",
      "epoch: 126  batch: 47  loss: 0.07407738\n",
      "epoch: 126  batch: 48  loss: 0.11139590\n",
      "epoch: 126  batch: 49  loss: 0.14086778\n",
      "epoch: 126  batch: 50  loss: 0.10645017\n",
      "epoch: 126  batch: 51  loss: 0.07984587\n",
      "epoch: 126  batch: 52  loss: 0.08042832\n",
      "epoch: 126  batch: 53  loss: 0.05501646\n",
      "epoch: 126  batch: 54  loss: 0.32094723\n",
      "epoch: 126  batch: 55  loss: 0.20273122\n",
      "epoch: 126  batch: 56  loss: 0.08043073\n",
      "epoch: 126  batch: 57  loss: 0.04106870\n",
      "epoch: 126  batch: 58  loss: 0.09266424\n",
      "epoch: 126  batch: 59  loss: 0.07809525\n",
      "epoch: 126  batch: 60  loss: 0.02811673\n",
      "epoch: 126  batch: 61  loss: 0.19671716\n",
      "epoch: 126  batch: 62  loss: 0.03550243\n",
      "epoch: 126  batch: 63  loss: 0.02160070\n",
      "epoch: 126  batch: 64  loss: 0.01993911\n",
      "epoch: 126  batch: 65  loss: 0.03914488\n",
      "epoch: 126  batch: 66  loss: 0.03989855\n",
      "epoch: 126  batch: 67  loss: 0.03076809\n",
      "epoch: 126  batch: 68  loss: 0.04841235\n",
      "epoch: 127  batch: 1  loss: 0.12446114\n",
      "epoch: 127  batch: 2  loss: 0.04846256\n",
      "epoch: 127  batch: 3  loss: 0.03207967\n",
      "epoch: 127  batch: 4  loss: 0.03122629\n",
      "epoch: 127  batch: 5  loss: 0.08317143\n",
      "epoch: 127  batch: 6  loss: 0.07087506\n",
      "epoch: 127  batch: 7  loss: 0.17779522\n",
      "epoch: 127  batch: 8  loss: 0.05696749\n",
      "epoch: 127  batch: 9  loss: 0.06769644\n",
      "epoch: 127  batch: 10  loss: 0.14424445\n",
      "epoch: 127  batch: 11  loss: 0.19231509\n",
      "epoch: 127  batch: 12  loss: 0.06823844\n",
      "epoch: 127  batch: 13  loss: 0.05298154\n",
      "epoch: 127  batch: 14  loss: 0.13612691\n",
      "epoch: 127  batch: 15  loss: 0.12227332\n",
      "epoch: 127  batch: 16  loss: 0.04381386\n",
      "epoch: 127  batch: 17  loss: 0.04746573\n",
      "epoch: 127  batch: 18  loss: 0.04796172\n",
      "epoch: 127  batch: 19  loss: 0.04880085\n",
      "epoch: 127  batch: 20  loss: 0.23700036\n",
      "epoch: 127  batch: 21  loss: 0.26938707\n",
      "epoch: 127  batch: 22  loss: 0.05252257\n",
      "epoch: 127  batch: 23  loss: 0.04048679\n",
      "epoch: 127  batch: 24  loss: 0.07103109\n",
      "epoch: 127  batch: 25  loss: 0.06935666\n",
      "epoch: 127  batch: 26  loss: 0.02042891\n",
      "epoch: 127  batch: 27  loss: 0.04205215\n",
      "epoch: 127  batch: 28  loss: 0.01321485\n",
      "epoch: 127  batch: 29  loss: 0.01693767\n",
      "epoch: 127  batch: 30  loss: 0.01610649\n",
      "epoch: 127  batch: 31  loss: 0.02406488\n",
      "epoch: 127  batch: 32  loss: 0.01195454\n",
      "epoch: 127  batch: 33  loss: 0.01791326\n",
      "epoch: 127  batch: 34  loss: 0.09782645\n",
      "epoch: 127  batch: 35  loss: 0.13345142\n",
      "epoch: 127  batch: 36  loss: 0.08139774\n",
      "epoch: 127  batch: 37  loss: 0.03722629\n",
      "epoch: 127  batch: 38  loss: 0.03258919\n",
      "epoch: 127  batch: 39  loss: 0.11750741\n",
      "epoch: 127  batch: 40  loss: 0.07305839\n",
      "epoch: 127  batch: 41  loss: 0.15375346\n",
      "epoch: 127  batch: 42  loss: 0.06605242\n",
      "epoch: 127  batch: 43  loss: 0.09548076\n",
      "epoch: 127  batch: 44  loss: 0.14044192\n",
      "epoch: 127  batch: 45  loss: 0.14528348\n",
      "epoch: 127  batch: 46  loss: 0.08053147\n",
      "epoch: 127  batch: 47  loss: 0.07227372\n",
      "epoch: 127  batch: 48  loss: 0.11073887\n",
      "epoch: 127  batch: 49  loss: 0.14124788\n",
      "epoch: 127  batch: 50  loss: 0.10486904\n",
      "epoch: 127  batch: 51  loss: 0.07935446\n",
      "epoch: 127  batch: 52  loss: 0.07859466\n",
      "epoch: 127  batch: 53  loss: 0.05491193\n",
      "epoch: 127  batch: 54  loss: 0.31959072\n",
      "epoch: 127  batch: 55  loss: 0.20253882\n",
      "epoch: 127  batch: 56  loss: 0.08077225\n",
      "epoch: 127  batch: 57  loss: 0.04128285\n",
      "epoch: 127  batch: 58  loss: 0.09158247\n",
      "epoch: 127  batch: 59  loss: 0.08043331\n",
      "epoch: 127  batch: 60  loss: 0.02732097\n",
      "epoch: 127  batch: 61  loss: 0.18809283\n",
      "epoch: 127  batch: 62  loss: 0.03486573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 127  batch: 63  loss: 0.02111409\n",
      "epoch: 127  batch: 64  loss: 0.02024124\n",
      "epoch: 127  batch: 65  loss: 0.03878601\n",
      "epoch: 127  batch: 66  loss: 0.03977873\n",
      "epoch: 127  batch: 67  loss: 0.03109488\n",
      "epoch: 127  batch: 68  loss: 0.04830945\n",
      "epoch: 128  batch: 1  loss: 0.12428359\n",
      "epoch: 128  batch: 2  loss: 0.04733136\n",
      "epoch: 128  batch: 3  loss: 0.03179231\n",
      "epoch: 128  batch: 4  loss: 0.03047528\n",
      "epoch: 128  batch: 5  loss: 0.08288064\n",
      "epoch: 128  batch: 6  loss: 0.07033142\n",
      "epoch: 128  batch: 7  loss: 0.17727363\n",
      "epoch: 128  batch: 8  loss: 0.05660463\n",
      "epoch: 128  batch: 9  loss: 0.06686623\n",
      "epoch: 128  batch: 10  loss: 0.14096142\n",
      "epoch: 128  batch: 11  loss: 0.19058523\n",
      "epoch: 128  batch: 12  loss: 0.06778154\n",
      "epoch: 128  batch: 13  loss: 0.05147646\n",
      "epoch: 128  batch: 14  loss: 0.13619667\n",
      "epoch: 128  batch: 15  loss: 0.12291493\n",
      "epoch: 128  batch: 16  loss: 0.04372749\n",
      "epoch: 128  batch: 17  loss: 0.04899520\n",
      "epoch: 128  batch: 18  loss: 0.04779191\n",
      "epoch: 128  batch: 19  loss: 0.04888945\n",
      "epoch: 128  batch: 20  loss: 0.23591074\n",
      "epoch: 128  batch: 21  loss: 0.26805192\n",
      "epoch: 128  batch: 22  loss: 0.05242598\n",
      "epoch: 128  batch: 23  loss: 0.03893212\n",
      "epoch: 128  batch: 24  loss: 0.07124374\n",
      "epoch: 128  batch: 25  loss: 0.06980684\n",
      "epoch: 128  batch: 26  loss: 0.02030450\n",
      "epoch: 128  batch: 27  loss: 0.04093345\n",
      "epoch: 128  batch: 28  loss: 0.01318359\n",
      "epoch: 128  batch: 29  loss: 0.01532928\n",
      "epoch: 128  batch: 30  loss: 0.01567888\n",
      "epoch: 128  batch: 31  loss: 0.02400632\n",
      "epoch: 128  batch: 32  loss: 0.01164162\n",
      "epoch: 128  batch: 33  loss: 0.02021259\n",
      "epoch: 128  batch: 34  loss: 0.09650872\n",
      "epoch: 128  batch: 35  loss: 0.13474318\n",
      "epoch: 128  batch: 36  loss: 0.08244619\n",
      "epoch: 128  batch: 37  loss: 0.03678028\n",
      "epoch: 128  batch: 38  loss: 0.03301445\n",
      "epoch: 128  batch: 39  loss: 0.11802883\n",
      "epoch: 128  batch: 40  loss: 0.07308064\n",
      "epoch: 128  batch: 41  loss: 0.15324588\n",
      "epoch: 128  batch: 42  loss: 0.06567809\n",
      "epoch: 128  batch: 43  loss: 0.09474473\n",
      "epoch: 128  batch: 44  loss: 0.13560060\n",
      "epoch: 128  batch: 45  loss: 0.14525028\n",
      "epoch: 128  batch: 46  loss: 0.07930925\n",
      "epoch: 128  batch: 47  loss: 0.07394900\n",
      "epoch: 128  batch: 48  loss: 0.10802291\n",
      "epoch: 128  batch: 49  loss: 0.14205858\n",
      "epoch: 128  batch: 50  loss: 0.09980295\n",
      "epoch: 128  batch: 51  loss: 0.08084439\n",
      "epoch: 128  batch: 52  loss: 0.07673085\n",
      "epoch: 128  batch: 53  loss: 0.05501350\n",
      "epoch: 128  batch: 54  loss: 0.31933343\n",
      "epoch: 128  batch: 55  loss: 0.20074672\n",
      "epoch: 128  batch: 56  loss: 0.08051023\n",
      "epoch: 128  batch: 57  loss: 0.04063058\n",
      "epoch: 128  batch: 58  loss: 0.09131502\n",
      "epoch: 128  batch: 59  loss: 0.08766192\n",
      "epoch: 128  batch: 60  loss: 0.02757178\n",
      "epoch: 128  batch: 61  loss: 0.18060032\n",
      "epoch: 128  batch: 62  loss: 0.03446740\n",
      "epoch: 128  batch: 63  loss: 0.02063999\n",
      "epoch: 128  batch: 64  loss: 0.01911288\n",
      "epoch: 128  batch: 65  loss: 0.03911027\n",
      "epoch: 128  batch: 66  loss: 0.03846965\n",
      "epoch: 128  batch: 67  loss: 0.02973216\n",
      "epoch: 128  batch: 68  loss: 0.04843821\n",
      "epoch: 129  batch: 1  loss: 0.12343378\n",
      "epoch: 129  batch: 2  loss: 0.05171708\n",
      "epoch: 129  batch: 3  loss: 0.03170723\n",
      "epoch: 129  batch: 4  loss: 0.03472389\n",
      "epoch: 129  batch: 5  loss: 0.08258277\n",
      "epoch: 129  batch: 6  loss: 0.07090112\n",
      "epoch: 129  batch: 7  loss: 0.17536713\n",
      "epoch: 129  batch: 8  loss: 0.05662007\n",
      "epoch: 129  batch: 9  loss: 0.06653291\n",
      "epoch: 129  batch: 10  loss: 0.14061485\n",
      "epoch: 129  batch: 11  loss: 0.18651444\n",
      "epoch: 129  batch: 12  loss: 0.06745747\n",
      "epoch: 129  batch: 13  loss: 0.04959752\n",
      "epoch: 129  batch: 14  loss: 0.13603038\n",
      "epoch: 129  batch: 15  loss: 0.12390885\n",
      "epoch: 129  batch: 16  loss: 0.04175598\n",
      "epoch: 129  batch: 17  loss: 0.05075916\n",
      "epoch: 129  batch: 18  loss: 0.04682925\n",
      "epoch: 129  batch: 19  loss: 0.04755905\n",
      "epoch: 129  batch: 20  loss: 0.23488647\n",
      "epoch: 129  batch: 21  loss: 0.26678693\n",
      "epoch: 129  batch: 22  loss: 0.05242028\n",
      "epoch: 129  batch: 23  loss: 0.04159231\n",
      "epoch: 129  batch: 24  loss: 0.07098512\n",
      "epoch: 129  batch: 25  loss: 0.06838354\n",
      "epoch: 129  batch: 26  loss: 0.02116462\n",
      "epoch: 129  batch: 27  loss: 0.04027399\n",
      "epoch: 129  batch: 28  loss: 0.01274176\n",
      "epoch: 129  batch: 29  loss: 0.01648020\n",
      "epoch: 129  batch: 30  loss: 0.01957481\n",
      "epoch: 129  batch: 31  loss: 0.02384163\n",
      "epoch: 129  batch: 32  loss: 0.01195231\n",
      "epoch: 129  batch: 33  loss: 0.01448186\n",
      "epoch: 129  batch: 34  loss: 0.10067980\n",
      "epoch: 129  batch: 35  loss: 0.13710803\n",
      "epoch: 129  batch: 36  loss: 0.08325192\n",
      "epoch: 129  batch: 37  loss: 0.03729461\n",
      "epoch: 129  batch: 38  loss: 0.03309332\n",
      "epoch: 129  batch: 39  loss: 0.11559602\n",
      "epoch: 129  batch: 40  loss: 0.07464643\n",
      "epoch: 129  batch: 41  loss: 0.15226653\n",
      "epoch: 129  batch: 42  loss: 0.06560739\n",
      "epoch: 129  batch: 43  loss: 0.09191311\n",
      "epoch: 129  batch: 44  loss: 0.13650006\n",
      "epoch: 129  batch: 45  loss: 0.13990918\n",
      "epoch: 129  batch: 46  loss: 0.08073684\n",
      "epoch: 129  batch: 47  loss: 0.07108516\n",
      "epoch: 129  batch: 48  loss: 0.11089904\n",
      "epoch: 129  batch: 49  loss: 0.14239989\n",
      "epoch: 129  batch: 50  loss: 0.10424122\n",
      "epoch: 129  batch: 51  loss: 0.07918195\n",
      "epoch: 129  batch: 52  loss: 0.07606796\n",
      "epoch: 129  batch: 53  loss: 0.05582773\n",
      "epoch: 129  batch: 54  loss: 0.31637540\n",
      "epoch: 129  batch: 55  loss: 0.20361288\n",
      "epoch: 129  batch: 56  loss: 0.08273281\n",
      "epoch: 129  batch: 57  loss: 0.04163543\n",
      "epoch: 129  batch: 58  loss: 0.08952086\n",
      "epoch: 129  batch: 59  loss: 0.10051297\n",
      "epoch: 129  batch: 60  loss: 0.02686682\n",
      "epoch: 129  batch: 61  loss: 0.17554300\n",
      "epoch: 129  batch: 62  loss: 0.03448505\n",
      "epoch: 129  batch: 63  loss: 0.02192656\n",
      "epoch: 129  batch: 64  loss: 0.01939756\n",
      "epoch: 129  batch: 65  loss: 0.03712059\n",
      "epoch: 129  batch: 66  loss: 0.03836686\n",
      "epoch: 129  batch: 67  loss: 0.03013950\n",
      "epoch: 129  batch: 68  loss: 0.04833471\n",
      "epoch: 130  batch: 1  loss: 0.12337650\n",
      "epoch: 130  batch: 2  loss: 0.04889397\n",
      "epoch: 130  batch: 3  loss: 0.03160426\n",
      "epoch: 130  batch: 4  loss: 0.03065563\n",
      "epoch: 130  batch: 5  loss: 0.08212922\n",
      "epoch: 130  batch: 6  loss: 0.06950707\n",
      "epoch: 130  batch: 7  loss: 0.17479584\n",
      "epoch: 130  batch: 8  loss: 0.05629317\n",
      "epoch: 130  batch: 9  loss: 0.06572623\n",
      "epoch: 130  batch: 10  loss: 0.13597612\n",
      "epoch: 130  batch: 11  loss: 0.18630211\n",
      "epoch: 130  batch: 12  loss: 0.06685051\n",
      "epoch: 130  batch: 13  loss: 0.04805709\n",
      "epoch: 130  batch: 14  loss: 0.13644888\n",
      "epoch: 130  batch: 15  loss: 0.12399657\n",
      "epoch: 130  batch: 16  loss: 0.04420697\n",
      "epoch: 130  batch: 17  loss: 0.04884472\n",
      "epoch: 130  batch: 18  loss: 0.04633275\n",
      "epoch: 130  batch: 19  loss: 0.04702903\n",
      "epoch: 130  batch: 20  loss: 0.23339647\n",
      "epoch: 130  batch: 21  loss: 0.26469430\n",
      "epoch: 130  batch: 22  loss: 0.05220062\n",
      "epoch: 130  batch: 23  loss: 0.03827306\n",
      "epoch: 130  batch: 24  loss: 0.07143884\n",
      "epoch: 130  batch: 25  loss: 0.06965514\n",
      "epoch: 130  batch: 26  loss: 0.02212796\n",
      "epoch: 130  batch: 27  loss: 0.03760785\n",
      "epoch: 130  batch: 28  loss: 0.01584250\n",
      "epoch: 130  batch: 29  loss: 0.01591477\n",
      "epoch: 130  batch: 30  loss: 0.01575551\n",
      "epoch: 130  batch: 31  loss: 0.02381334\n",
      "epoch: 130  batch: 32  loss: 0.01151783\n",
      "epoch: 130  batch: 33  loss: 0.01822276\n",
      "epoch: 130  batch: 34  loss: 0.09779338\n",
      "epoch: 130  batch: 35  loss: 0.13290139\n",
      "epoch: 130  batch: 36  loss: 0.08382849\n",
      "epoch: 130  batch: 37  loss: 0.03652116\n",
      "epoch: 130  batch: 38  loss: 0.03318156\n",
      "epoch: 130  batch: 39  loss: 0.11689143\n",
      "epoch: 130  batch: 40  loss: 0.07393325\n",
      "epoch: 130  batch: 41  loss: 0.15187331\n",
      "epoch: 130  batch: 42  loss: 0.06518473\n",
      "epoch: 130  batch: 43  loss: 0.09163391\n",
      "epoch: 130  batch: 44  loss: 0.13156568\n",
      "epoch: 130  batch: 45  loss: 0.14226113\n",
      "epoch: 130  batch: 46  loss: 0.07756934\n",
      "epoch: 130  batch: 47  loss: 0.07306697\n",
      "epoch: 130  batch: 48  loss: 0.10658963\n",
      "epoch: 130  batch: 49  loss: 0.14308108\n",
      "epoch: 130  batch: 50  loss: 0.09582467\n",
      "epoch: 130  batch: 51  loss: 0.08066392\n",
      "epoch: 130  batch: 52  loss: 0.07305025\n",
      "epoch: 130  batch: 53  loss: 0.05469735\n",
      "epoch: 130  batch: 54  loss: 0.31607249\n",
      "epoch: 130  batch: 55  loss: 0.19881681\n",
      "epoch: 130  batch: 56  loss: 0.08135434\n",
      "epoch: 130  batch: 57  loss: 0.03992315\n",
      "epoch: 130  batch: 58  loss: 0.08955891\n",
      "epoch: 130  batch: 59  loss: 0.09243925\n",
      "epoch: 130  batch: 60  loss: 0.02757953\n",
      "epoch: 130  batch: 61  loss: 0.17027590\n",
      "epoch: 130  batch: 62  loss: 0.03393399\n",
      "epoch: 130  batch: 63  loss: 0.02005336\n",
      "epoch: 130  batch: 64  loss: 0.01944214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 130  batch: 65  loss: 0.03765304\n",
      "epoch: 130  batch: 66  loss: 0.03968696\n",
      "epoch: 130  batch: 67  loss: 0.03100343\n",
      "epoch: 130  batch: 68  loss: 0.04810396\n",
      "epoch: 131  batch: 1  loss: 0.12357721\n",
      "epoch: 131  batch: 2  loss: 0.04773357\n",
      "epoch: 131  batch: 3  loss: 0.03153795\n",
      "epoch: 131  batch: 4  loss: 0.03006226\n",
      "epoch: 131  batch: 5  loss: 0.08198546\n",
      "epoch: 131  batch: 6  loss: 0.06896067\n",
      "epoch: 131  batch: 7  loss: 0.17447428\n",
      "epoch: 131  batch: 8  loss: 0.05597231\n",
      "epoch: 131  batch: 9  loss: 0.06464912\n",
      "epoch: 131  batch: 10  loss: 0.13428135\n",
      "epoch: 131  batch: 11  loss: 0.18295097\n",
      "epoch: 131  batch: 12  loss: 0.06605373\n",
      "epoch: 131  batch: 13  loss: 0.04746618\n",
      "epoch: 131  batch: 14  loss: 0.13426977\n",
      "epoch: 131  batch: 15  loss: 0.12458258\n",
      "epoch: 131  batch: 16  loss: 0.04259781\n",
      "epoch: 131  batch: 17  loss: 0.04456546\n",
      "epoch: 131  batch: 18  loss: 0.04695519\n",
      "epoch: 131  batch: 19  loss: 0.04712707\n",
      "epoch: 131  batch: 20  loss: 0.23242059\n",
      "epoch: 131  batch: 21  loss: 0.26388884\n",
      "epoch: 131  batch: 22  loss: 0.05231921\n",
      "epoch: 131  batch: 23  loss: 0.03848679\n",
      "epoch: 131  batch: 24  loss: 0.07099807\n",
      "epoch: 131  batch: 25  loss: 0.06953162\n",
      "epoch: 131  batch: 26  loss: 0.02106750\n",
      "epoch: 131  batch: 27  loss: 0.03669539\n",
      "epoch: 131  batch: 28  loss: 0.01300236\n",
      "epoch: 131  batch: 29  loss: 0.01653061\n",
      "epoch: 131  batch: 30  loss: 0.01550542\n",
      "epoch: 131  batch: 31  loss: 0.02350728\n",
      "epoch: 131  batch: 32  loss: 0.01176844\n",
      "epoch: 131  batch: 33  loss: 0.01439263\n",
      "epoch: 131  batch: 34  loss: 0.09750414\n",
      "epoch: 131  batch: 35  loss: 0.13142948\n",
      "epoch: 131  batch: 36  loss: 0.08490298\n",
      "epoch: 131  batch: 37  loss: 0.03712741\n",
      "epoch: 131  batch: 38  loss: 0.03242353\n",
      "epoch: 131  batch: 39  loss: 0.11460341\n",
      "epoch: 131  batch: 40  loss: 0.07426021\n",
      "epoch: 131  batch: 41  loss: 0.15147913\n",
      "epoch: 131  batch: 42  loss: 0.06496617\n",
      "epoch: 131  batch: 43  loss: 0.09045771\n",
      "epoch: 131  batch: 44  loss: 0.12993242\n",
      "epoch: 131  batch: 45  loss: 0.13704315\n",
      "epoch: 131  batch: 46  loss: 0.07716918\n",
      "epoch: 131  batch: 47  loss: 0.07106572\n",
      "epoch: 131  batch: 48  loss: 0.10647073\n",
      "epoch: 131  batch: 49  loss: 0.14327905\n",
      "epoch: 131  batch: 50  loss: 0.09293264\n",
      "epoch: 131  batch: 51  loss: 0.08061590\n",
      "epoch: 131  batch: 52  loss: 0.07433835\n",
      "epoch: 131  batch: 53  loss: 0.05438722\n",
      "epoch: 131  batch: 54  loss: 0.31611973\n",
      "epoch: 131  batch: 55  loss: 0.19760768\n",
      "epoch: 131  batch: 56  loss: 0.08093375\n",
      "epoch: 131  batch: 57  loss: 0.04046387\n",
      "epoch: 131  batch: 58  loss: 0.08880462\n",
      "epoch: 131  batch: 59  loss: 0.07803680\n",
      "epoch: 131  batch: 60  loss: 0.02618907\n",
      "epoch: 131  batch: 61  loss: 0.15801965\n",
      "epoch: 131  batch: 62  loss: 0.03396356\n",
      "epoch: 131  batch: 63  loss: 0.01952562\n",
      "epoch: 131  batch: 64  loss: 0.01932947\n",
      "epoch: 131  batch: 65  loss: 0.03722955\n",
      "epoch: 131  batch: 66  loss: 0.03896564\n",
      "epoch: 131  batch: 67  loss: 0.03044303\n",
      "epoch: 131  batch: 68  loss: 0.04797284\n",
      "epoch: 132  batch: 1  loss: 0.12322629\n",
      "epoch: 132  batch: 2  loss: 0.04678698\n",
      "epoch: 132  batch: 3  loss: 0.03135073\n",
      "epoch: 132  batch: 4  loss: 0.03032032\n",
      "epoch: 132  batch: 5  loss: 0.08187107\n",
      "epoch: 132  batch: 6  loss: 0.06896211\n",
      "epoch: 132  batch: 7  loss: 0.17375439\n",
      "epoch: 132  batch: 8  loss: 0.05557391\n",
      "epoch: 132  batch: 9  loss: 0.06394087\n",
      "epoch: 132  batch: 10  loss: 0.13198680\n",
      "epoch: 132  batch: 11  loss: 0.18005539\n",
      "epoch: 132  batch: 12  loss: 0.06431022\n",
      "epoch: 132  batch: 13  loss: 0.04613408\n",
      "epoch: 132  batch: 14  loss: 0.13329872\n",
      "epoch: 132  batch: 15  loss: 0.12525433\n",
      "epoch: 132  batch: 16  loss: 0.04175001\n",
      "epoch: 132  batch: 17  loss: 0.04589518\n",
      "epoch: 132  batch: 18  loss: 0.04687920\n",
      "epoch: 132  batch: 19  loss: 0.04719739\n",
      "epoch: 132  batch: 20  loss: 0.23143992\n",
      "epoch: 132  batch: 21  loss: 0.26277670\n",
      "epoch: 132  batch: 22  loss: 0.05226749\n",
      "epoch: 132  batch: 23  loss: 0.03791303\n",
      "epoch: 132  batch: 24  loss: 0.07055575\n",
      "epoch: 132  batch: 25  loss: 0.06960485\n",
      "epoch: 132  batch: 26  loss: 0.02046170\n",
      "epoch: 132  batch: 27  loss: 0.03628517\n",
      "epoch: 132  batch: 28  loss: 0.01274451\n",
      "epoch: 132  batch: 29  loss: 0.01543937\n",
      "epoch: 132  batch: 30  loss: 0.01547483\n",
      "epoch: 132  batch: 31  loss: 0.02346170\n",
      "epoch: 132  batch: 32  loss: 0.01158899\n",
      "epoch: 132  batch: 33  loss: 0.01586556\n",
      "epoch: 132  batch: 34  loss: 0.09662912\n",
      "epoch: 132  batch: 35  loss: 0.13225228\n",
      "epoch: 132  batch: 36  loss: 0.08582238\n",
      "epoch: 132  batch: 37  loss: 0.03654867\n",
      "epoch: 132  batch: 38  loss: 0.03285190\n",
      "epoch: 132  batch: 39  loss: 0.11496396\n",
      "epoch: 132  batch: 40  loss: 0.07428422\n",
      "epoch: 132  batch: 41  loss: 0.15132633\n",
      "epoch: 132  batch: 42  loss: 0.06457726\n",
      "epoch: 132  batch: 43  loss: 0.08996832\n",
      "epoch: 132  batch: 44  loss: 0.12701070\n",
      "epoch: 132  batch: 45  loss: 0.13658230\n",
      "epoch: 132  batch: 46  loss: 0.07599021\n",
      "epoch: 132  batch: 47  loss: 0.07118271\n",
      "epoch: 132  batch: 48  loss: 0.10413387\n",
      "epoch: 132  batch: 49  loss: 0.14391501\n",
      "epoch: 132  batch: 50  loss: 0.08810341\n",
      "epoch: 132  batch: 51  loss: 0.08119906\n",
      "epoch: 132  batch: 52  loss: 0.07316740\n",
      "epoch: 132  batch: 53  loss: 0.05456119\n",
      "epoch: 132  batch: 54  loss: 0.31549713\n",
      "epoch: 132  batch: 55  loss: 0.19626902\n",
      "epoch: 132  batch: 56  loss: 0.08071628\n",
      "epoch: 132  batch: 57  loss: 0.04027671\n",
      "epoch: 132  batch: 58  loss: 0.08842909\n",
      "epoch: 132  batch: 59  loss: 0.07685941\n",
      "epoch: 132  batch: 60  loss: 0.02623694\n",
      "epoch: 132  batch: 61  loss: 0.15291353\n",
      "epoch: 132  batch: 62  loss: 0.03311309\n",
      "epoch: 132  batch: 63  loss: 0.01869738\n",
      "epoch: 132  batch: 64  loss: 0.01858463\n",
      "epoch: 132  batch: 65  loss: 0.03778050\n",
      "epoch: 132  batch: 66  loss: 0.03831998\n",
      "epoch: 132  batch: 67  loss: 0.02964383\n",
      "epoch: 132  batch: 68  loss: 0.04809513\n",
      "epoch: 133  batch: 1  loss: 0.12263485\n",
      "epoch: 133  batch: 2  loss: 0.04786062\n",
      "epoch: 133  batch: 3  loss: 0.03112413\n",
      "epoch: 133  batch: 4  loss: 0.03157508\n",
      "epoch: 133  batch: 5  loss: 0.08166154\n",
      "epoch: 133  batch: 6  loss: 0.06886130\n",
      "epoch: 133  batch: 7  loss: 0.17238185\n",
      "epoch: 133  batch: 8  loss: 0.05545332\n",
      "epoch: 133  batch: 9  loss: 0.06336113\n",
      "epoch: 133  batch: 10  loss: 0.12989148\n",
      "epoch: 133  batch: 11  loss: 0.17632437\n",
      "epoch: 133  batch: 12  loss: 0.06401484\n",
      "epoch: 133  batch: 13  loss: 0.04595640\n",
      "epoch: 133  batch: 14  loss: 0.13203424\n",
      "epoch: 133  batch: 15  loss: 0.12583210\n",
      "epoch: 133  batch: 16  loss: 0.03990722\n",
      "epoch: 133  batch: 17  loss: 0.04583379\n",
      "epoch: 133  batch: 18  loss: 0.04653048\n",
      "epoch: 133  batch: 19  loss: 0.04674280\n",
      "epoch: 133  batch: 20  loss: 0.23055972\n",
      "epoch: 133  batch: 21  loss: 0.26166141\n",
      "epoch: 133  batch: 22  loss: 0.05234119\n",
      "epoch: 133  batch: 23  loss: 0.03892796\n",
      "epoch: 133  batch: 24  loss: 0.06997881\n",
      "epoch: 133  batch: 25  loss: 0.06899737\n",
      "epoch: 133  batch: 26  loss: 0.02106243\n",
      "epoch: 133  batch: 27  loss: 0.03539286\n",
      "epoch: 133  batch: 28  loss: 0.01223857\n",
      "epoch: 133  batch: 29  loss: 0.01685855\n",
      "epoch: 133  batch: 30  loss: 0.01713093\n",
      "epoch: 133  batch: 31  loss: 0.02335481\n",
      "epoch: 133  batch: 32  loss: 0.01171666\n",
      "epoch: 133  batch: 33  loss: 0.01217116\n",
      "epoch: 133  batch: 34  loss: 0.09867395\n",
      "epoch: 133  batch: 35  loss: 0.13029940\n",
      "epoch: 133  batch: 36  loss: 0.08685498\n",
      "epoch: 133  batch: 37  loss: 0.03676606\n",
      "epoch: 133  batch: 38  loss: 0.03236136\n",
      "epoch: 133  batch: 39  loss: 0.11299057\n",
      "epoch: 133  batch: 40  loss: 0.07517365\n",
      "epoch: 133  batch: 41  loss: 0.15051706\n",
      "epoch: 133  batch: 42  loss: 0.06452448\n",
      "epoch: 133  batch: 43  loss: 0.08760443\n",
      "epoch: 133  batch: 44  loss: 0.12633322\n",
      "epoch: 133  batch: 45  loss: 0.13227330\n",
      "epoch: 133  batch: 46  loss: 0.07595365\n",
      "epoch: 133  batch: 47  loss: 0.06902217\n",
      "epoch: 133  batch: 48  loss: 0.10493930\n",
      "epoch: 133  batch: 49  loss: 0.14431435\n",
      "epoch: 133  batch: 50  loss: 0.08824627\n",
      "epoch: 133  batch: 51  loss: 0.08025427\n",
      "epoch: 133  batch: 52  loss: 0.07313583\n",
      "epoch: 133  batch: 53  loss: 0.05387774\n",
      "epoch: 133  batch: 54  loss: 0.31404150\n",
      "epoch: 133  batch: 55  loss: 0.19494237\n",
      "epoch: 133  batch: 56  loss: 0.08097036\n",
      "epoch: 133  batch: 57  loss: 0.04098285\n",
      "epoch: 133  batch: 58  loss: 0.08741485\n",
      "epoch: 133  batch: 59  loss: 0.08324194\n",
      "epoch: 133  batch: 60  loss: 0.02550035\n",
      "epoch: 133  batch: 61  loss: 0.14574206\n",
      "epoch: 133  batch: 62  loss: 0.03339737\n",
      "epoch: 133  batch: 63  loss: 0.01883697\n",
      "epoch: 133  batch: 64  loss: 0.01920837\n",
      "epoch: 133  batch: 65  loss: 0.03687466\n",
      "epoch: 133  batch: 66  loss: 0.03774502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 133  batch: 67  loss: 0.03025844\n",
      "epoch: 133  batch: 68  loss: 0.04792300\n",
      "epoch: 134  batch: 1  loss: 0.12277495\n",
      "epoch: 134  batch: 2  loss: 0.04567878\n",
      "epoch: 134  batch: 3  loss: 0.03107320\n",
      "epoch: 134  batch: 4  loss: 0.02990613\n",
      "epoch: 134  batch: 5  loss: 0.08130255\n",
      "epoch: 134  batch: 6  loss: 0.06827292\n",
      "epoch: 134  batch: 7  loss: 0.17194206\n",
      "epoch: 134  batch: 8  loss: 0.05511532\n",
      "epoch: 134  batch: 9  loss: 0.06256910\n",
      "epoch: 134  batch: 10  loss: 0.12720917\n",
      "epoch: 134  batch: 11  loss: 0.17547765\n",
      "epoch: 134  batch: 12  loss: 0.06319783\n",
      "epoch: 134  batch: 13  loss: 0.04435477\n",
      "epoch: 134  batch: 14  loss: 0.13234489\n",
      "epoch: 134  batch: 15  loss: 0.12651023\n",
      "epoch: 134  batch: 16  loss: 0.04099200\n",
      "epoch: 134  batch: 17  loss: 0.04593458\n",
      "epoch: 134  batch: 18  loss: 0.04650705\n",
      "epoch: 134  batch: 19  loss: 0.04661342\n",
      "epoch: 134  batch: 20  loss: 0.22945710\n",
      "epoch: 134  batch: 21  loss: 0.25996524\n",
      "epoch: 134  batch: 22  loss: 0.05213962\n",
      "epoch: 134  batch: 23  loss: 0.03723381\n",
      "epoch: 134  batch: 24  loss: 0.06990892\n",
      "epoch: 134  batch: 25  loss: 0.06959101\n",
      "epoch: 134  batch: 26  loss: 0.02025371\n",
      "epoch: 134  batch: 27  loss: 0.03433812\n",
      "epoch: 134  batch: 28  loss: 0.01263951\n",
      "epoch: 134  batch: 29  loss: 0.01516531\n",
      "epoch: 134  batch: 30  loss: 0.01537009\n",
      "epoch: 134  batch: 31  loss: 0.02315725\n",
      "epoch: 134  batch: 32  loss: 0.01148160\n",
      "epoch: 134  batch: 33  loss: 0.01458070\n",
      "epoch: 134  batch: 34  loss: 0.09652928\n",
      "epoch: 134  batch: 35  loss: 0.13189758\n",
      "epoch: 134  batch: 36  loss: 0.08771853\n",
      "epoch: 134  batch: 37  loss: 0.03634853\n",
      "epoch: 134  batch: 38  loss: 0.03291743\n",
      "epoch: 134  batch: 39  loss: 0.11373092\n",
      "epoch: 134  batch: 40  loss: 0.07482086\n",
      "epoch: 134  batch: 41  loss: 0.15034224\n",
      "epoch: 134  batch: 42  loss: 0.06408242\n",
      "epoch: 134  batch: 43  loss: 0.08752390\n",
      "epoch: 134  batch: 44  loss: 0.12216435\n",
      "epoch: 134  batch: 45  loss: 0.13292368\n",
      "epoch: 134  batch: 46  loss: 0.07406811\n",
      "epoch: 134  batch: 47  loss: 0.07005513\n",
      "epoch: 134  batch: 48  loss: 0.10277420\n",
      "epoch: 134  batch: 49  loss: 0.14494576\n",
      "epoch: 134  batch: 50  loss: 0.08435575\n",
      "epoch: 134  batch: 51  loss: 0.08116598\n",
      "epoch: 134  batch: 52  loss: 0.07042922\n",
      "epoch: 134  batch: 53  loss: 0.05463572\n",
      "epoch: 134  batch: 54  loss: 0.31374803\n",
      "epoch: 134  batch: 55  loss: 0.19321595\n",
      "epoch: 134  batch: 56  loss: 0.08055466\n",
      "epoch: 134  batch: 57  loss: 0.04003807\n",
      "epoch: 134  batch: 58  loss: 0.08733377\n",
      "epoch: 134  batch: 59  loss: 0.07931318\n",
      "epoch: 134  batch: 60  loss: 0.02575914\n",
      "epoch: 134  batch: 61  loss: 0.14239779\n",
      "epoch: 134  batch: 62  loss: 0.03265824\n",
      "epoch: 134  batch: 63  loss: 0.01826239\n",
      "epoch: 134  batch: 64  loss: 0.01813017\n",
      "epoch: 134  batch: 65  loss: 0.03698356\n",
      "epoch: 134  batch: 66  loss: 0.03743371\n",
      "epoch: 134  batch: 67  loss: 0.02948556\n",
      "epoch: 134  batch: 68  loss: 0.04802320\n",
      "epoch: 135  batch: 1  loss: 0.12178315\n",
      "epoch: 135  batch: 2  loss: 0.04792696\n",
      "epoch: 135  batch: 3  loss: 0.03089602\n",
      "epoch: 135  batch: 4  loss: 0.03222289\n",
      "epoch: 135  batch: 5  loss: 0.08112249\n",
      "epoch: 135  batch: 6  loss: 0.06836294\n",
      "epoch: 135  batch: 7  loss: 0.17064303\n",
      "epoch: 135  batch: 8  loss: 0.05506106\n",
      "epoch: 135  batch: 9  loss: 0.06192930\n",
      "epoch: 135  batch: 10  loss: 0.12554830\n",
      "epoch: 135  batch: 11  loss: 0.17102180\n",
      "epoch: 135  batch: 12  loss: 0.06253222\n",
      "epoch: 135  batch: 13  loss: 0.04420094\n",
      "epoch: 135  batch: 14  loss: 0.13062982\n",
      "epoch: 135  batch: 15  loss: 0.12703562\n",
      "epoch: 135  batch: 16  loss: 0.03877484\n",
      "epoch: 135  batch: 17  loss: 0.04487503\n",
      "epoch: 135  batch: 18  loss: 0.04606172\n",
      "epoch: 135  batch: 19  loss: 0.04610812\n",
      "epoch: 135  batch: 20  loss: 0.22838652\n",
      "epoch: 135  batch: 21  loss: 0.25901252\n",
      "epoch: 135  batch: 22  loss: 0.05224911\n",
      "epoch: 135  batch: 23  loss: 0.03859814\n",
      "epoch: 135  batch: 24  loss: 0.06932950\n",
      "epoch: 135  batch: 25  loss: 0.06923977\n",
      "epoch: 135  batch: 26  loss: 0.02160658\n",
      "epoch: 135  batch: 27  loss: 0.03355746\n",
      "epoch: 135  batch: 28  loss: 0.01212816\n",
      "epoch: 135  batch: 29  loss: 0.01658971\n",
      "epoch: 135  batch: 30  loss: 0.01780316\n",
      "epoch: 135  batch: 31  loss: 0.02296600\n",
      "epoch: 135  batch: 32  loss: 0.01161817\n",
      "epoch: 135  batch: 33  loss: 0.01126894\n",
      "epoch: 135  batch: 34  loss: 0.09930297\n",
      "epoch: 135  batch: 35  loss: 0.12903841\n",
      "epoch: 135  batch: 36  loss: 0.08858579\n",
      "epoch: 135  batch: 37  loss: 0.03641966\n",
      "epoch: 135  batch: 38  loss: 0.03249713\n",
      "epoch: 135  batch: 39  loss: 0.11160318\n",
      "epoch: 135  batch: 40  loss: 0.07578949\n",
      "epoch: 135  batch: 41  loss: 0.14944132\n",
      "epoch: 135  batch: 42  loss: 0.06405278\n",
      "epoch: 135  batch: 43  loss: 0.08515650\n",
      "epoch: 135  batch: 44  loss: 0.12301062\n",
      "epoch: 135  batch: 45  loss: 0.12836230\n",
      "epoch: 135  batch: 46  loss: 0.07473676\n",
      "epoch: 135  batch: 47  loss: 0.06760201\n",
      "epoch: 135  batch: 48  loss: 0.10342206\n",
      "epoch: 135  batch: 49  loss: 0.14549816\n",
      "epoch: 135  batch: 50  loss: 0.08401053\n",
      "epoch: 135  batch: 51  loss: 0.08049244\n",
      "epoch: 135  batch: 52  loss: 0.07171114\n",
      "epoch: 135  batch: 53  loss: 0.05372069\n",
      "epoch: 135  batch: 54  loss: 0.31210023\n",
      "epoch: 135  batch: 55  loss: 0.19193527\n",
      "epoch: 135  batch: 56  loss: 0.08068488\n",
      "epoch: 135  batch: 57  loss: 0.04101473\n",
      "epoch: 135  batch: 58  loss: 0.08638745\n",
      "epoch: 135  batch: 59  loss: 0.09433988\n",
      "epoch: 135  batch: 60  loss: 0.02511191\n",
      "epoch: 135  batch: 61  loss: 0.13586976\n",
      "epoch: 135  batch: 62  loss: 0.03292006\n",
      "epoch: 135  batch: 63  loss: 0.01829266\n",
      "epoch: 135  batch: 64  loss: 0.01894150\n",
      "epoch: 135  batch: 65  loss: 0.03599074\n",
      "epoch: 135  batch: 66  loss: 0.03656051\n",
      "epoch: 135  batch: 67  loss: 0.03020489\n",
      "epoch: 135  batch: 68  loss: 0.04782807\n",
      "epoch: 136  batch: 1  loss: 0.12198134\n",
      "epoch: 136  batch: 2  loss: 0.04496194\n",
      "epoch: 136  batch: 3  loss: 0.03094756\n",
      "epoch: 136  batch: 4  loss: 0.02971328\n",
      "epoch: 136  batch: 5  loss: 0.08073550\n",
      "epoch: 136  batch: 6  loss: 0.06786181\n",
      "epoch: 136  batch: 7  loss: 0.17006959\n",
      "epoch: 136  batch: 8  loss: 0.05470501\n",
      "epoch: 136  batch: 9  loss: 0.06141348\n",
      "epoch: 136  batch: 10  loss: 0.12269194\n",
      "epoch: 136  batch: 11  loss: 0.17098133\n",
      "epoch: 136  batch: 12  loss: 0.06219787\n",
      "epoch: 136  batch: 13  loss: 0.04289328\n",
      "epoch: 136  batch: 14  loss: 0.13168681\n",
      "epoch: 136  batch: 15  loss: 0.12763071\n",
      "epoch: 136  batch: 16  loss: 0.03997709\n",
      "epoch: 136  batch: 17  loss: 0.04452325\n",
      "epoch: 136  batch: 18  loss: 0.04565809\n",
      "epoch: 136  batch: 19  loss: 0.04559853\n",
      "epoch: 136  batch: 20  loss: 0.22708912\n",
      "epoch: 136  batch: 21  loss: 0.25676543\n",
      "epoch: 136  batch: 22  loss: 0.05200703\n",
      "epoch: 136  batch: 23  loss: 0.03676407\n",
      "epoch: 136  batch: 24  loss: 0.06925245\n",
      "epoch: 136  batch: 25  loss: 0.06966618\n",
      "epoch: 136  batch: 26  loss: 0.02073843\n",
      "epoch: 136  batch: 27  loss: 0.03221692\n",
      "epoch: 136  batch: 28  loss: 0.01235776\n",
      "epoch: 136  batch: 29  loss: 0.01509803\n",
      "epoch: 136  batch: 30  loss: 0.01542562\n",
      "epoch: 136  batch: 31  loss: 0.02271739\n",
      "epoch: 136  batch: 32  loss: 0.01140303\n",
      "epoch: 136  batch: 33  loss: 0.01345223\n",
      "epoch: 136  batch: 34  loss: 0.09659226\n",
      "epoch: 136  batch: 35  loss: 0.13072328\n",
      "epoch: 136  batch: 36  loss: 0.08931263\n",
      "epoch: 136  batch: 37  loss: 0.03597148\n",
      "epoch: 136  batch: 38  loss: 0.03290400\n",
      "epoch: 136  batch: 39  loss: 0.11241576\n",
      "epoch: 136  batch: 40  loss: 0.07543181\n",
      "epoch: 136  batch: 41  loss: 0.14918965\n",
      "epoch: 136  batch: 42  loss: 0.06363469\n",
      "epoch: 136  batch: 43  loss: 0.08530362\n",
      "epoch: 136  batch: 44  loss: 0.11820469\n",
      "epoch: 136  batch: 45  loss: 0.12918819\n",
      "epoch: 136  batch: 46  loss: 0.07233299\n",
      "epoch: 136  batch: 47  loss: 0.06880805\n",
      "epoch: 136  batch: 48  loss: 0.10158382\n",
      "epoch: 136  batch: 49  loss: 0.14599310\n",
      "epoch: 136  batch: 50  loss: 0.08100832\n",
      "epoch: 136  batch: 51  loss: 0.08108744\n",
      "epoch: 136  batch: 52  loss: 0.06810325\n",
      "epoch: 136  batch: 53  loss: 0.05451089\n",
      "epoch: 136  batch: 54  loss: 0.31148651\n",
      "epoch: 136  batch: 55  loss: 0.19101363\n",
      "epoch: 136  batch: 56  loss: 0.08025671\n",
      "epoch: 136  batch: 57  loss: 0.03983463\n",
      "epoch: 136  batch: 58  loss: 0.08627319\n",
      "epoch: 136  batch: 59  loss: 0.07185486\n",
      "epoch: 136  batch: 60  loss: 0.02521681\n",
      "epoch: 136  batch: 61  loss: 0.13208044\n",
      "epoch: 136  batch: 62  loss: 0.03266666\n",
      "epoch: 136  batch: 63  loss: 0.01799425\n",
      "epoch: 136  batch: 64  loss: 0.01826928\n",
      "epoch: 136  batch: 65  loss: 0.03598206\n",
      "epoch: 136  batch: 66  loss: 0.03783431\n",
      "epoch: 136  batch: 67  loss: 0.03001661\n",
      "epoch: 136  batch: 68  loss: 0.04764880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 137  batch: 1  loss: 0.12164875\n",
      "epoch: 137  batch: 2  loss: 0.04583190\n",
      "epoch: 137  batch: 3  loss: 0.03086751\n",
      "epoch: 137  batch: 4  loss: 0.03010011\n",
      "epoch: 137  batch: 5  loss: 0.08040907\n",
      "epoch: 137  batch: 6  loss: 0.06730210\n",
      "epoch: 137  batch: 7  loss: 0.16932802\n",
      "epoch: 137  batch: 8  loss: 0.05454880\n",
      "epoch: 137  batch: 9  loss: 0.06014627\n",
      "epoch: 137  batch: 10  loss: 0.12070760\n",
      "epoch: 137  batch: 11  loss: 0.16631778\n",
      "epoch: 137  batch: 12  loss: 0.06084723\n",
      "epoch: 137  batch: 13  loss: 0.04307285\n",
      "epoch: 137  batch: 14  loss: 0.12889726\n",
      "epoch: 137  batch: 15  loss: 0.12839910\n",
      "epoch: 137  batch: 16  loss: 0.03874778\n",
      "epoch: 137  batch: 17  loss: 0.04135580\n",
      "epoch: 137  batch: 18  loss: 0.04610553\n",
      "epoch: 137  batch: 19  loss: 0.04585661\n",
      "epoch: 137  batch: 20  loss: 0.22632305\n",
      "epoch: 137  batch: 21  loss: 0.25587404\n",
      "epoch: 137  batch: 22  loss: 0.05217495\n",
      "epoch: 137  batch: 23  loss: 0.03690727\n",
      "epoch: 137  batch: 24  loss: 0.06865338\n",
      "epoch: 137  batch: 25  loss: 0.06949762\n",
      "epoch: 137  batch: 26  loss: 0.02062172\n",
      "epoch: 137  batch: 27  loss: 0.03146232\n",
      "epoch: 137  batch: 28  loss: 0.01232510\n",
      "epoch: 137  batch: 29  loss: 0.01602701\n",
      "epoch: 137  batch: 30  loss: 0.01564836\n",
      "epoch: 137  batch: 31  loss: 0.02267526\n",
      "epoch: 137  batch: 32  loss: 0.01154979\n",
      "epoch: 137  batch: 33  loss: 0.01092268\n",
      "epoch: 137  batch: 34  loss: 0.09713043\n",
      "epoch: 137  batch: 35  loss: 0.12846941\n",
      "epoch: 137  batch: 36  loss: 0.09041575\n",
      "epoch: 137  batch: 37  loss: 0.03627530\n",
      "epoch: 137  batch: 38  loss: 0.03221776\n",
      "epoch: 137  batch: 39  loss: 0.11038581\n",
      "epoch: 137  batch: 40  loss: 0.07570402\n",
      "epoch: 137  batch: 41  loss: 0.14869520\n",
      "epoch: 137  batch: 42  loss: 0.06347729\n",
      "epoch: 137  batch: 43  loss: 0.08365312\n",
      "epoch: 137  batch: 44  loss: 0.11668581\n",
      "epoch: 137  batch: 45  loss: 0.12477663\n",
      "epoch: 137  batch: 46  loss: 0.07189672\n",
      "epoch: 137  batch: 47  loss: 0.06649958\n",
      "epoch: 137  batch: 48  loss: 0.10121942\n",
      "epoch: 137  batch: 49  loss: 0.14642771\n",
      "epoch: 137  batch: 50  loss: 0.07808615\n",
      "epoch: 137  batch: 51  loss: 0.08106770\n",
      "epoch: 137  batch: 52  loss: 0.06901328\n",
      "epoch: 137  batch: 53  loss: 0.05354152\n",
      "epoch: 137  batch: 54  loss: 0.31088218\n",
      "epoch: 137  batch: 55  loss: 0.18865372\n",
      "epoch: 137  batch: 56  loss: 0.07956933\n",
      "epoch: 137  batch: 57  loss: 0.04040266\n",
      "epoch: 137  batch: 58  loss: 0.08555779\n",
      "epoch: 137  batch: 59  loss: 0.07066897\n",
      "epoch: 137  batch: 60  loss: 0.02447083\n",
      "epoch: 137  batch: 61  loss: 0.12536912\n",
      "epoch: 137  batch: 62  loss: 0.03205873\n",
      "epoch: 137  batch: 63  loss: 0.01763247\n",
      "epoch: 137  batch: 64  loss: 0.01796376\n",
      "epoch: 137  batch: 65  loss: 0.03565559\n",
      "epoch: 137  batch: 66  loss: 0.03629513\n",
      "epoch: 137  batch: 67  loss: 0.02936960\n",
      "epoch: 137  batch: 68  loss: 0.04767840\n",
      "epoch: 138  batch: 1  loss: 0.12084541\n",
      "epoch: 138  batch: 2  loss: 0.04491760\n",
      "epoch: 138  batch: 3  loss: 0.03050680\n",
      "epoch: 138  batch: 4  loss: 0.03068788\n",
      "epoch: 138  batch: 5  loss: 0.08028998\n",
      "epoch: 138  batch: 6  loss: 0.06736038\n",
      "epoch: 138  batch: 7  loss: 0.16830468\n",
      "epoch: 138  batch: 8  loss: 0.05434070\n",
      "epoch: 138  batch: 9  loss: 0.05997188\n",
      "epoch: 138  batch: 10  loss: 0.11862539\n",
      "epoch: 138  batch: 11  loss: 0.16418196\n",
      "epoch: 138  batch: 12  loss: 0.06037947\n",
      "epoch: 138  batch: 13  loss: 0.04219571\n",
      "epoch: 138  batch: 14  loss: 0.12890464\n",
      "epoch: 138  batch: 15  loss: 0.12885574\n",
      "epoch: 138  batch: 16  loss: 0.03790086\n",
      "epoch: 138  batch: 17  loss: 0.04109974\n",
      "epoch: 138  batch: 18  loss: 0.04537268\n",
      "epoch: 138  batch: 19  loss: 0.04552743\n",
      "epoch: 138  batch: 20  loss: 0.22513203\n",
      "epoch: 138  batch: 21  loss: 0.25435734\n",
      "epoch: 138  batch: 22  loss: 0.05211265\n",
      "epoch: 138  batch: 23  loss: 0.03666978\n",
      "epoch: 138  batch: 24  loss: 0.06778481\n",
      "epoch: 138  batch: 25  loss: 0.06974390\n",
      "epoch: 138  batch: 26  loss: 0.02066266\n",
      "epoch: 138  batch: 27  loss: 0.03081265\n",
      "epoch: 138  batch: 28  loss: 0.01189456\n",
      "epoch: 138  batch: 29  loss: 0.01511087\n",
      "epoch: 138  batch: 30  loss: 0.01589161\n",
      "epoch: 138  batch: 31  loss: 0.02226256\n",
      "epoch: 138  batch: 32  loss: 0.01142921\n",
      "epoch: 138  batch: 33  loss: 0.01189180\n",
      "epoch: 138  batch: 34  loss: 0.09715574\n",
      "epoch: 138  batch: 35  loss: 0.12857644\n",
      "epoch: 138  batch: 36  loss: 0.09131215\n",
      "epoch: 138  batch: 37  loss: 0.03533504\n",
      "epoch: 138  batch: 38  loss: 0.03263586\n",
      "epoch: 138  batch: 39  loss: 0.11051829\n",
      "epoch: 138  batch: 40  loss: 0.07603709\n",
      "epoch: 138  batch: 41  loss: 0.14827169\n",
      "epoch: 138  batch: 42  loss: 0.06317303\n",
      "epoch: 138  batch: 43  loss: 0.08271509\n",
      "epoch: 138  batch: 44  loss: 0.11472724\n",
      "epoch: 138  batch: 45  loss: 0.12432525\n",
      "epoch: 138  batch: 46  loss: 0.07072115\n",
      "epoch: 138  batch: 47  loss: 0.06682496\n",
      "epoch: 138  batch: 48  loss: 0.09975363\n",
      "epoch: 138  batch: 49  loss: 0.14693300\n",
      "epoch: 138  batch: 50  loss: 0.07551205\n",
      "epoch: 138  batch: 51  loss: 0.08091196\n",
      "epoch: 138  batch: 52  loss: 0.06759511\n",
      "epoch: 138  batch: 53  loss: 0.05338691\n",
      "epoch: 138  batch: 54  loss: 0.30966598\n",
      "epoch: 138  batch: 55  loss: 0.18773375\n",
      "epoch: 138  batch: 56  loss: 0.07967756\n",
      "epoch: 138  batch: 57  loss: 0.04029159\n",
      "epoch: 138  batch: 58  loss: 0.08494110\n",
      "epoch: 138  batch: 59  loss: 0.07094555\n",
      "epoch: 138  batch: 60  loss: 0.02418607\n",
      "epoch: 138  batch: 61  loss: 0.12180117\n",
      "epoch: 138  batch: 62  loss: 0.03222468\n",
      "epoch: 138  batch: 63  loss: 0.01755043\n",
      "epoch: 138  batch: 64  loss: 0.01828915\n",
      "epoch: 138  batch: 65  loss: 0.03539486\n",
      "epoch: 138  batch: 66  loss: 0.03667184\n",
      "epoch: 138  batch: 67  loss: 0.02987249\n",
      "epoch: 138  batch: 68  loss: 0.04753850\n",
      "epoch: 139  batch: 1  loss: 0.12089361\n",
      "epoch: 139  batch: 2  loss: 0.04404635\n",
      "epoch: 139  batch: 3  loss: 0.03053615\n",
      "epoch: 139  batch: 4  loss: 0.02990295\n",
      "epoch: 139  batch: 5  loss: 0.07974970\n",
      "epoch: 139  batch: 6  loss: 0.06675448\n",
      "epoch: 139  batch: 7  loss: 0.16765755\n",
      "epoch: 139  batch: 8  loss: 0.05401275\n",
      "epoch: 139  batch: 9  loss: 0.05880757\n",
      "epoch: 139  batch: 10  loss: 0.11614021\n",
      "epoch: 139  batch: 11  loss: 0.16154577\n",
      "epoch: 139  batch: 12  loss: 0.05905511\n",
      "epoch: 139  batch: 13  loss: 0.04210468\n",
      "epoch: 139  batch: 14  loss: 0.12683699\n",
      "epoch: 139  batch: 15  loss: 0.12984590\n",
      "epoch: 139  batch: 16  loss: 0.03788574\n",
      "epoch: 139  batch: 17  loss: 0.03975638\n",
      "epoch: 139  batch: 18  loss: 0.04599763\n",
      "epoch: 139  batch: 19  loss: 0.04532254\n",
      "epoch: 139  batch: 20  loss: 0.22413348\n",
      "epoch: 139  batch: 21  loss: 0.25257161\n",
      "epoch: 139  batch: 22  loss: 0.05208652\n",
      "epoch: 139  batch: 23  loss: 0.03626111\n",
      "epoch: 139  batch: 24  loss: 0.06739099\n",
      "epoch: 139  batch: 25  loss: 0.06975780\n",
      "epoch: 139  batch: 26  loss: 0.01991849\n",
      "epoch: 139  batch: 27  loss: 0.02983743\n",
      "epoch: 139  batch: 28  loss: 0.01226631\n",
      "epoch: 139  batch: 29  loss: 0.01558667\n",
      "epoch: 139  batch: 30  loss: 0.01564970\n",
      "epoch: 139  batch: 31  loss: 0.02214771\n",
      "epoch: 139  batch: 32  loss: 0.01143394\n",
      "epoch: 139  batch: 33  loss: 0.01077677\n",
      "epoch: 139  batch: 34  loss: 0.09622767\n",
      "epoch: 139  batch: 35  loss: 0.12782238\n",
      "epoch: 139  batch: 36  loss: 0.09232307\n",
      "epoch: 139  batch: 37  loss: 0.03576848\n",
      "epoch: 139  batch: 38  loss: 0.03227007\n",
      "epoch: 139  batch: 39  loss: 0.10938329\n",
      "epoch: 139  batch: 40  loss: 0.07589237\n",
      "epoch: 139  batch: 41  loss: 0.14773272\n",
      "epoch: 139  batch: 42  loss: 0.06291232\n",
      "epoch: 139  batch: 43  loss: 0.08154812\n",
      "epoch: 139  batch: 44  loss: 0.11155678\n",
      "epoch: 139  batch: 45  loss: 0.12186956\n",
      "epoch: 139  batch: 46  loss: 0.06964137\n",
      "epoch: 139  batch: 47  loss: 0.06557327\n",
      "epoch: 139  batch: 48  loss: 0.09928185\n",
      "epoch: 139  batch: 49  loss: 0.14735696\n",
      "epoch: 139  batch: 50  loss: 0.07380653\n",
      "epoch: 139  batch: 51  loss: 0.08172508\n",
      "epoch: 139  batch: 52  loss: 0.06657410\n",
      "epoch: 139  batch: 53  loss: 0.05357290\n",
      "epoch: 139  batch: 54  loss: 0.30911842\n",
      "epoch: 139  batch: 55  loss: 0.18635920\n",
      "epoch: 139  batch: 56  loss: 0.07878576\n",
      "epoch: 139  batch: 57  loss: 0.04005937\n",
      "epoch: 139  batch: 58  loss: 0.08457240\n",
      "epoch: 139  batch: 59  loss: 0.08066096\n",
      "epoch: 139  batch: 60  loss: 0.02393040\n",
      "epoch: 139  batch: 61  loss: 0.11769301\n",
      "epoch: 139  batch: 62  loss: 0.03143690\n",
      "epoch: 139  batch: 63  loss: 0.01747452\n",
      "epoch: 139  batch: 64  loss: 0.01755274\n",
      "epoch: 139  batch: 65  loss: 0.03516511\n",
      "epoch: 139  batch: 66  loss: 0.03531039\n",
      "epoch: 139  batch: 67  loss: 0.02938371\n",
      "epoch: 139  batch: 68  loss: 0.04770927\n",
      "epoch: 140  batch: 1  loss: 0.11898677\n",
      "epoch: 140  batch: 2  loss: 0.04577128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 140  batch: 3  loss: 0.03006151\n",
      "epoch: 140  batch: 4  loss: 0.03467375\n",
      "epoch: 140  batch: 5  loss: 0.07966741\n",
      "epoch: 140  batch: 6  loss: 0.06735639\n",
      "epoch: 140  batch: 7  loss: 0.16646259\n",
      "epoch: 140  batch: 8  loss: 0.05400471\n",
      "epoch: 140  batch: 9  loss: 0.05892470\n",
      "epoch: 140  batch: 10  loss: 0.11535084\n",
      "epoch: 140  batch: 11  loss: 0.15896940\n",
      "epoch: 140  batch: 12  loss: 0.05921898\n",
      "epoch: 140  batch: 13  loss: 0.04118311\n",
      "epoch: 140  batch: 14  loss: 0.12721592\n",
      "epoch: 140  batch: 15  loss: 0.12984288\n",
      "epoch: 140  batch: 16  loss: 0.03617978\n",
      "epoch: 140  batch: 17  loss: 0.04033140\n",
      "epoch: 140  batch: 18  loss: 0.04480657\n",
      "epoch: 140  batch: 19  loss: 0.04468735\n",
      "epoch: 140  batch: 20  loss: 0.22259414\n",
      "epoch: 140  batch: 21  loss: 0.25122920\n",
      "epoch: 140  batch: 22  loss: 0.05201375\n",
      "epoch: 140  batch: 23  loss: 0.03761623\n",
      "epoch: 140  batch: 24  loss: 0.06693446\n",
      "epoch: 140  batch: 25  loss: 0.07026231\n",
      "epoch: 140  batch: 26  loss: 0.02177480\n",
      "epoch: 140  batch: 27  loss: 0.02932899\n",
      "epoch: 140  batch: 28  loss: 0.01228171\n",
      "epoch: 140  batch: 29  loss: 0.01544785\n",
      "epoch: 140  batch: 30  loss: 0.01883877\n",
      "epoch: 140  batch: 31  loss: 0.02167734\n",
      "epoch: 140  batch: 32  loss: 0.01137971\n",
      "epoch: 140  batch: 33  loss: 0.01027672\n",
      "epoch: 140  batch: 34  loss: 0.09920800\n",
      "epoch: 140  batch: 35  loss: 0.12614667\n",
      "epoch: 140  batch: 36  loss: 0.09306167\n",
      "epoch: 140  batch: 37  loss: 0.03533640\n",
      "epoch: 140  batch: 38  loss: 0.03307832\n",
      "epoch: 140  batch: 39  loss: 0.10839948\n",
      "epoch: 140  batch: 40  loss: 0.07691596\n",
      "epoch: 140  batch: 41  loss: 0.14688425\n",
      "epoch: 140  batch: 42  loss: 0.06285577\n",
      "epoch: 140  batch: 43  loss: 0.08004957\n",
      "epoch: 140  batch: 44  loss: 0.11266537\n",
      "epoch: 140  batch: 45  loss: 0.11952126\n",
      "epoch: 140  batch: 46  loss: 0.07010005\n",
      "epoch: 140  batch: 47  loss: 0.06539018\n",
      "epoch: 140  batch: 48  loss: 0.09939790\n",
      "epoch: 140  batch: 49  loss: 0.14791854\n",
      "epoch: 140  batch: 50  loss: 0.07322760\n",
      "epoch: 140  batch: 51  loss: 0.08193489\n",
      "epoch: 140  batch: 52  loss: 0.06705383\n",
      "epoch: 140  batch: 53  loss: 0.05333681\n",
      "epoch: 140  batch: 54  loss: 0.30804548\n",
      "epoch: 140  batch: 55  loss: 0.18636230\n",
      "epoch: 140  batch: 56  loss: 0.07910822\n",
      "epoch: 140  batch: 57  loss: 0.04070251\n",
      "epoch: 140  batch: 58  loss: 0.08360120\n",
      "epoch: 140  batch: 59  loss: 0.10344645\n",
      "epoch: 140  batch: 60  loss: 0.02361777\n",
      "epoch: 140  batch: 61  loss: 0.11367468\n",
      "epoch: 140  batch: 62  loss: 0.03162602\n",
      "epoch: 140  batch: 63  loss: 0.01733432\n",
      "epoch: 140  batch: 64  loss: 0.01839353\n",
      "epoch: 140  batch: 65  loss: 0.03433803\n",
      "epoch: 140  batch: 66  loss: 0.03504106\n",
      "epoch: 140  batch: 67  loss: 0.03050172\n",
      "epoch: 140  batch: 68  loss: 0.04733081\n",
      "epoch: 141  batch: 1  loss: 0.11941359\n",
      "epoch: 141  batch: 2  loss: 0.04309869\n",
      "epoch: 141  batch: 3  loss: 0.03059606\n",
      "epoch: 141  batch: 4  loss: 0.02967269\n",
      "epoch: 141  batch: 5  loss: 0.07886708\n",
      "epoch: 141  batch: 6  loss: 0.06638406\n",
      "epoch: 141  batch: 7  loss: 0.16539705\n",
      "epoch: 141  batch: 8  loss: 0.05360495\n",
      "epoch: 141  batch: 9  loss: 0.05797949\n",
      "epoch: 141  batch: 10  loss: 0.11247224\n",
      "epoch: 141  batch: 11  loss: 0.15820059\n",
      "epoch: 141  batch: 12  loss: 0.05832169\n",
      "epoch: 141  batch: 13  loss: 0.04060244\n",
      "epoch: 141  batch: 14  loss: 0.12733822\n",
      "epoch: 141  batch: 15  loss: 0.13089231\n",
      "epoch: 141  batch: 16  loss: 0.03746780\n",
      "epoch: 141  batch: 17  loss: 0.04085952\n",
      "epoch: 141  batch: 18  loss: 0.04485497\n",
      "epoch: 141  batch: 19  loss: 0.04417836\n",
      "epoch: 141  batch: 20  loss: 0.22043809\n",
      "epoch: 141  batch: 21  loss: 0.24827521\n",
      "epoch: 141  batch: 22  loss: 0.05180520\n",
      "epoch: 141  batch: 23  loss: 0.03551129\n",
      "epoch: 141  batch: 24  loss: 0.06677243\n",
      "epoch: 141  batch: 25  loss: 0.07049366\n",
      "epoch: 141  batch: 26  loss: 0.02119004\n",
      "epoch: 141  batch: 27  loss: 0.02767649\n",
      "epoch: 141  batch: 28  loss: 0.01234219\n",
      "epoch: 141  batch: 29  loss: 0.01493422\n",
      "epoch: 141  batch: 30  loss: 0.01532227\n",
      "epoch: 141  batch: 31  loss: 0.02150459\n",
      "epoch: 141  batch: 32  loss: 0.01110267\n",
      "epoch: 141  batch: 33  loss: 0.01146149\n",
      "epoch: 141  batch: 34  loss: 0.09542034\n",
      "epoch: 141  batch: 35  loss: 0.12703381\n",
      "epoch: 141  batch: 36  loss: 0.09361543\n",
      "epoch: 141  batch: 37  loss: 0.03483959\n",
      "epoch: 141  batch: 38  loss: 0.03274683\n",
      "epoch: 141  batch: 39  loss: 0.10877620\n",
      "epoch: 141  batch: 40  loss: 0.07626594\n",
      "epoch: 141  batch: 41  loss: 0.14666934\n",
      "epoch: 141  batch: 42  loss: 0.06234416\n",
      "epoch: 141  batch: 43  loss: 0.08013038\n",
      "epoch: 141  batch: 44  loss: 0.10857902\n",
      "epoch: 141  batch: 45  loss: 0.12007078\n",
      "epoch: 141  batch: 46  loss: 0.06800550\n",
      "epoch: 141  batch: 47  loss: 0.06529932\n",
      "epoch: 141  batch: 48  loss: 0.09758060\n",
      "epoch: 141  batch: 49  loss: 0.14802907\n",
      "epoch: 141  batch: 50  loss: 0.07157388\n",
      "epoch: 141  batch: 51  loss: 0.08169937\n",
      "epoch: 141  batch: 52  loss: 0.06378826\n",
      "epoch: 141  batch: 53  loss: 0.05369721\n",
      "epoch: 141  batch: 54  loss: 0.30635303\n",
      "epoch: 141  batch: 55  loss: 0.18588847\n",
      "epoch: 141  batch: 56  loss: 0.07829342\n",
      "epoch: 141  batch: 57  loss: 0.03961092\n",
      "epoch: 141  batch: 58  loss: 0.08338702\n",
      "epoch: 141  batch: 59  loss: 0.07532752\n",
      "epoch: 141  batch: 60  loss: 0.02360658\n",
      "epoch: 141  batch: 61  loss: 0.10988687\n",
      "epoch: 141  batch: 62  loss: 0.03209637\n",
      "epoch: 141  batch: 63  loss: 0.01742451\n",
      "epoch: 141  batch: 64  loss: 0.01805971\n",
      "epoch: 141  batch: 65  loss: 0.03430322\n",
      "epoch: 141  batch: 66  loss: 0.03639698\n",
      "epoch: 141  batch: 67  loss: 0.03027633\n",
      "epoch: 141  batch: 68  loss: 0.04687040\n",
      "epoch: 142  batch: 1  loss: 0.11962122\n",
      "epoch: 142  batch: 2  loss: 0.04281859\n",
      "epoch: 142  batch: 3  loss: 0.03041100\n",
      "epoch: 142  batch: 4  loss: 0.03138603\n",
      "epoch: 142  batch: 5  loss: 0.07845087\n",
      "epoch: 142  batch: 6  loss: 0.06580000\n",
      "epoch: 142  batch: 7  loss: 0.16484176\n",
      "epoch: 142  batch: 8  loss: 0.05339090\n",
      "epoch: 142  batch: 9  loss: 0.05669838\n",
      "epoch: 142  batch: 10  loss: 0.11078402\n",
      "epoch: 142  batch: 11  loss: 0.15417345\n",
      "epoch: 142  batch: 12  loss: 0.05669662\n",
      "epoch: 142  batch: 13  loss: 0.04064191\n",
      "epoch: 142  batch: 14  loss: 0.12489183\n",
      "epoch: 142  batch: 15  loss: 0.13169533\n",
      "epoch: 142  batch: 16  loss: 0.03655500\n",
      "epoch: 142  batch: 17  loss: 0.03788489\n",
      "epoch: 142  batch: 18  loss: 0.04566250\n",
      "epoch: 142  batch: 19  loss: 0.04484339\n",
      "epoch: 142  batch: 20  loss: 0.21989425\n",
      "epoch: 142  batch: 21  loss: 0.24734169\n",
      "epoch: 142  batch: 22  loss: 0.05205641\n",
      "epoch: 142  batch: 23  loss: 0.03536431\n",
      "epoch: 142  batch: 24  loss: 0.06629208\n",
      "epoch: 142  batch: 25  loss: 0.07012019\n",
      "epoch: 142  batch: 26  loss: 0.01946928\n",
      "epoch: 142  batch: 27  loss: 0.02760768\n",
      "epoch: 142  batch: 28  loss: 0.01223088\n",
      "epoch: 142  batch: 29  loss: 0.01541383\n",
      "epoch: 142  batch: 30  loss: 0.01550756\n",
      "epoch: 142  batch: 31  loss: 0.02175277\n",
      "epoch: 142  batch: 32  loss: 0.01142410\n",
      "epoch: 142  batch: 33  loss: 0.01001086\n",
      "epoch: 142  batch: 34  loss: 0.09502106\n",
      "epoch: 142  batch: 35  loss: 0.12502684\n",
      "epoch: 142  batch: 36  loss: 0.09480343\n",
      "epoch: 142  batch: 37  loss: 0.03531131\n",
      "epoch: 142  batch: 38  loss: 0.03219653\n",
      "epoch: 142  batch: 39  loss: 0.10719884\n",
      "epoch: 142  batch: 40  loss: 0.07619330\n",
      "epoch: 142  batch: 41  loss: 0.14630903\n",
      "epoch: 142  batch: 42  loss: 0.06212746\n",
      "epoch: 142  batch: 43  loss: 0.07926340\n",
      "epoch: 142  batch: 44  loss: 0.10674300\n",
      "epoch: 142  batch: 45  loss: 0.11636806\n",
      "epoch: 142  batch: 46  loss: 0.06724576\n",
      "epoch: 142  batch: 47  loss: 0.06339191\n",
      "epoch: 142  batch: 48  loss: 0.09657126\n",
      "epoch: 142  batch: 49  loss: 0.14822327\n",
      "epoch: 142  batch: 50  loss: 0.06807560\n",
      "epoch: 142  batch: 51  loss: 0.08249648\n",
      "epoch: 142  batch: 52  loss: 0.06477945\n",
      "epoch: 142  batch: 53  loss: 0.05297480\n",
      "epoch: 142  batch: 54  loss: 0.30582279\n",
      "epoch: 142  batch: 55  loss: 0.18388389\n",
      "epoch: 142  batch: 56  loss: 0.07678104\n",
      "epoch: 142  batch: 57  loss: 0.03979461\n",
      "epoch: 142  batch: 58  loss: 0.08279039\n",
      "epoch: 142  batch: 59  loss: 0.07163665\n",
      "epoch: 142  batch: 60  loss: 0.02302857\n",
      "epoch: 142  batch: 61  loss: 0.10528775\n",
      "epoch: 142  batch: 62  loss: 0.03030615\n",
      "epoch: 142  batch: 63  loss: 0.01730723\n",
      "epoch: 142  batch: 64  loss: 0.01730055\n",
      "epoch: 142  batch: 65  loss: 0.03416310\n",
      "epoch: 142  batch: 66  loss: 0.03490797\n",
      "epoch: 142  batch: 67  loss: 0.02945323\n",
      "epoch: 142  batch: 68  loss: 0.04714483\n",
      "epoch: 143  batch: 1  loss: 0.11695988\n",
      "epoch: 143  batch: 2  loss: 0.04380378\n",
      "epoch: 143  batch: 3  loss: 0.02980919\n",
      "epoch: 143  batch: 4  loss: 0.03418922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143  batch: 5  loss: 0.07826038\n",
      "epoch: 143  batch: 6  loss: 0.06611206\n",
      "epoch: 143  batch: 7  loss: 0.16350289\n",
      "epoch: 143  batch: 8  loss: 0.05326234\n",
      "epoch: 143  batch: 9  loss: 0.05699572\n",
      "epoch: 143  batch: 10  loss: 0.10875361\n",
      "epoch: 143  batch: 11  loss: 0.15188105\n",
      "epoch: 143  batch: 12  loss: 0.05747120\n",
      "epoch: 143  batch: 13  loss: 0.04007703\n",
      "epoch: 143  batch: 14  loss: 0.12522791\n",
      "epoch: 143  batch: 15  loss: 0.13184382\n",
      "epoch: 143  batch: 16  loss: 0.03465484\n",
      "epoch: 143  batch: 17  loss: 0.03824276\n",
      "epoch: 143  batch: 18  loss: 0.04384103\n",
      "epoch: 143  batch: 19  loss: 0.04433511\n",
      "epoch: 143  batch: 20  loss: 0.21858725\n",
      "epoch: 143  batch: 21  loss: 0.24626882\n",
      "epoch: 143  batch: 22  loss: 0.05179524\n",
      "epoch: 143  batch: 23  loss: 0.03580042\n",
      "epoch: 143  batch: 24  loss: 0.06531717\n",
      "epoch: 143  batch: 25  loss: 0.07093077\n",
      "epoch: 143  batch: 26  loss: 0.02056002\n",
      "epoch: 143  batch: 27  loss: 0.02700337\n",
      "epoch: 143  batch: 28  loss: 0.01194757\n",
      "epoch: 143  batch: 29  loss: 0.01512719\n",
      "epoch: 143  batch: 30  loss: 0.01770300\n",
      "epoch: 143  batch: 31  loss: 0.02083652\n",
      "epoch: 143  batch: 32  loss: 0.01113980\n",
      "epoch: 143  batch: 33  loss: 0.01020587\n",
      "epoch: 143  batch: 34  loss: 0.09707890\n",
      "epoch: 143  batch: 35  loss: 0.12421405\n",
      "epoch: 143  batch: 36  loss: 0.09590138\n",
      "epoch: 143  batch: 37  loss: 0.03439709\n",
      "epoch: 143  batch: 38  loss: 0.03291106\n",
      "epoch: 143  batch: 39  loss: 0.10667833\n",
      "epoch: 143  batch: 40  loss: 0.07730807\n",
      "epoch: 143  batch: 41  loss: 0.14558318\n",
      "epoch: 143  batch: 42  loss: 0.06206848\n",
      "epoch: 143  batch: 43  loss: 0.07764889\n",
      "epoch: 143  batch: 44  loss: 0.10492217\n",
      "epoch: 143  batch: 45  loss: 0.11501151\n",
      "epoch: 143  batch: 46  loss: 0.06667826\n",
      "epoch: 143  batch: 47  loss: 0.06324348\n",
      "epoch: 143  batch: 48  loss: 0.09605081\n",
      "epoch: 143  batch: 49  loss: 0.14849645\n",
      "epoch: 143  batch: 50  loss: 0.06768572\n",
      "epoch: 143  batch: 51  loss: 0.08173741\n",
      "epoch: 143  batch: 52  loss: 0.06316848\n",
      "epoch: 143  batch: 53  loss: 0.05240075\n",
      "epoch: 143  batch: 54  loss: 0.30459264\n",
      "epoch: 143  batch: 55  loss: 0.18301231\n",
      "epoch: 143  batch: 56  loss: 0.07688145\n",
      "epoch: 143  batch: 57  loss: 0.04007129\n",
      "epoch: 143  batch: 58  loss: 0.08190258\n",
      "epoch: 143  batch: 59  loss: 0.08463526\n",
      "epoch: 143  batch: 60  loss: 0.02263435\n",
      "epoch: 143  batch: 61  loss: 0.10183926\n",
      "epoch: 143  batch: 62  loss: 0.03135732\n",
      "epoch: 143  batch: 63  loss: 0.01722586\n",
      "epoch: 143  batch: 64  loss: 0.01818115\n",
      "epoch: 143  batch: 65  loss: 0.03384304\n",
      "epoch: 143  batch: 66  loss: 0.03528167\n",
      "epoch: 143  batch: 67  loss: 0.03052270\n",
      "epoch: 143  batch: 68  loss: 0.04666570\n",
      "epoch: 144  batch: 1  loss: 0.11797393\n",
      "epoch: 144  batch: 2  loss: 0.04338560\n",
      "epoch: 144  batch: 3  loss: 0.03008118\n",
      "epoch: 144  batch: 4  loss: 0.03065168\n",
      "epoch: 144  batch: 5  loss: 0.07742874\n",
      "epoch: 144  batch: 6  loss: 0.06498747\n",
      "epoch: 144  batch: 7  loss: 0.16258752\n",
      "epoch: 144  batch: 8  loss: 0.05293445\n",
      "epoch: 144  batch: 9  loss: 0.05557434\n",
      "epoch: 144  batch: 10  loss: 0.10696796\n",
      "epoch: 144  batch: 11  loss: 0.14959376\n",
      "epoch: 144  batch: 12  loss: 0.05508904\n",
      "epoch: 144  batch: 13  loss: 0.03977414\n",
      "epoch: 144  batch: 14  loss: 0.12391277\n",
      "epoch: 144  batch: 15  loss: 0.13283926\n",
      "epoch: 144  batch: 16  loss: 0.03559064\n",
      "epoch: 144  batch: 17  loss: 0.03830829\n",
      "epoch: 144  batch: 18  loss: 0.04558896\n",
      "epoch: 144  batch: 19  loss: 0.04419925\n",
      "epoch: 144  batch: 20  loss: 0.21654701\n",
      "epoch: 144  batch: 21  loss: 0.24307591\n",
      "epoch: 144  batch: 22  loss: 0.05173359\n",
      "epoch: 144  batch: 23  loss: 0.03467889\n",
      "epoch: 144  batch: 24  loss: 0.06530265\n",
      "epoch: 144  batch: 25  loss: 0.07074740\n",
      "epoch: 144  batch: 26  loss: 0.01933115\n",
      "epoch: 144  batch: 27  loss: 0.02587809\n",
      "epoch: 144  batch: 28  loss: 0.01198410\n",
      "epoch: 144  batch: 29  loss: 0.01487746\n",
      "epoch: 144  batch: 30  loss: 0.01540765\n",
      "epoch: 144  batch: 31  loss: 0.02123166\n",
      "epoch: 144  batch: 32  loss: 0.01109009\n",
      "epoch: 144  batch: 33  loss: 0.01017164\n",
      "epoch: 144  batch: 34  loss: 0.09393985\n",
      "epoch: 144  batch: 35  loss: 0.12391324\n",
      "epoch: 144  batch: 36  loss: 0.09638575\n",
      "epoch: 144  batch: 37  loss: 0.03427511\n",
      "epoch: 144  batch: 38  loss: 0.03228577\n",
      "epoch: 144  batch: 39  loss: 0.10630667\n",
      "epoch: 144  batch: 40  loss: 0.07654892\n",
      "epoch: 144  batch: 41  loss: 0.14529559\n",
      "epoch: 144  batch: 42  loss: 0.06149371\n",
      "epoch: 144  batch: 43  loss: 0.07733448\n",
      "epoch: 144  batch: 44  loss: 0.10325757\n",
      "epoch: 144  batch: 45  loss: 0.11409561\n",
      "epoch: 144  batch: 46  loss: 0.06532145\n",
      "epoch: 144  batch: 47  loss: 0.06253851\n",
      "epoch: 144  batch: 48  loss: 0.09440115\n",
      "epoch: 144  batch: 49  loss: 0.14851324\n",
      "epoch: 144  batch: 50  loss: 0.06568290\n",
      "epoch: 144  batch: 51  loss: 0.08262391\n",
      "epoch: 144  batch: 52  loss: 0.06247217\n",
      "epoch: 144  batch: 53  loss: 0.05294105\n",
      "epoch: 144  batch: 54  loss: 0.30312690\n",
      "epoch: 144  batch: 55  loss: 0.18209733\n",
      "epoch: 144  batch: 56  loss: 0.07546858\n",
      "epoch: 144  batch: 57  loss: 0.03949980\n",
      "epoch: 144  batch: 58  loss: 0.08150399\n",
      "epoch: 144  batch: 59  loss: 0.06913892\n",
      "epoch: 144  batch: 60  loss: 0.02222732\n",
      "epoch: 144  batch: 61  loss: 0.09862605\n",
      "epoch: 144  batch: 62  loss: 0.02970463\n",
      "epoch: 144  batch: 63  loss: 0.01721920\n",
      "epoch: 144  batch: 64  loss: 0.01719751\n",
      "epoch: 144  batch: 65  loss: 0.03339215\n",
      "epoch: 144  batch: 66  loss: 0.03468440\n",
      "epoch: 144  batch: 67  loss: 0.02964798\n",
      "epoch: 144  batch: 68  loss: 0.04674787\n",
      "epoch: 145  batch: 1  loss: 0.11540089\n",
      "epoch: 145  batch: 2  loss: 0.04546411\n",
      "epoch: 145  batch: 3  loss: 0.02976795\n",
      "epoch: 145  batch: 4  loss: 0.03298736\n",
      "epoch: 145  batch: 5  loss: 0.07707978\n",
      "epoch: 145  batch: 6  loss: 0.06508524\n",
      "epoch: 145  batch: 7  loss: 0.16132493\n",
      "epoch: 145  batch: 8  loss: 0.05282195\n",
      "epoch: 145  batch: 9  loss: 0.05553591\n",
      "epoch: 145  batch: 10  loss: 0.10560525\n",
      "epoch: 145  batch: 11  loss: 0.14676890\n",
      "epoch: 145  batch: 12  loss: 0.05629056\n",
      "epoch: 145  batch: 13  loss: 0.03930509\n",
      "epoch: 145  batch: 14  loss: 0.12251033\n",
      "epoch: 145  batch: 15  loss: 0.13321157\n",
      "epoch: 145  batch: 16  loss: 0.03330373\n",
      "epoch: 145  batch: 17  loss: 0.03737622\n",
      "epoch: 145  batch: 18  loss: 0.04307785\n",
      "epoch: 145  batch: 19  loss: 0.04388431\n",
      "epoch: 145  batch: 20  loss: 0.21560779\n",
      "epoch: 145  batch: 21  loss: 0.24275498\n",
      "epoch: 145  batch: 22  loss: 0.05150659\n",
      "epoch: 145  batch: 23  loss: 0.03495718\n",
      "epoch: 145  batch: 24  loss: 0.06442738\n",
      "epoch: 145  batch: 25  loss: 0.07137723\n",
      "epoch: 145  batch: 26  loss: 0.02021082\n",
      "epoch: 145  batch: 27  loss: 0.02558902\n",
      "epoch: 145  batch: 28  loss: 0.01188555\n",
      "epoch: 145  batch: 29  loss: 0.01523025\n",
      "epoch: 145  batch: 30  loss: 0.01717030\n",
      "epoch: 145  batch: 31  loss: 0.02033517\n",
      "epoch: 145  batch: 32  loss: 0.01104035\n",
      "epoch: 145  batch: 33  loss: 0.00975456\n",
      "epoch: 145  batch: 34  loss: 0.09608466\n",
      "epoch: 145  batch: 35  loss: 0.12242550\n",
      "epoch: 145  batch: 36  loss: 0.09762480\n",
      "epoch: 145  batch: 37  loss: 0.03395832\n",
      "epoch: 145  batch: 38  loss: 0.03269543\n",
      "epoch: 145  batch: 39  loss: 0.10490961\n",
      "epoch: 145  batch: 40  loss: 0.07759351\n",
      "epoch: 145  batch: 41  loss: 0.14463581\n",
      "epoch: 145  batch: 42  loss: 0.06154271\n",
      "epoch: 145  batch: 43  loss: 0.07584380\n",
      "epoch: 145  batch: 44  loss: 0.10153928\n",
      "epoch: 145  batch: 45  loss: 0.11126012\n",
      "epoch: 145  batch: 46  loss: 0.06463379\n",
      "epoch: 145  batch: 47  loss: 0.06145847\n",
      "epoch: 145  batch: 48  loss: 0.09417613\n",
      "epoch: 145  batch: 49  loss: 0.14876837\n",
      "epoch: 145  batch: 50  loss: 0.06474321\n",
      "epoch: 145  batch: 51  loss: 0.08223280\n",
      "epoch: 145  batch: 52  loss: 0.06139527\n",
      "epoch: 145  batch: 53  loss: 0.05210178\n",
      "epoch: 145  batch: 54  loss: 0.30201626\n",
      "epoch: 145  batch: 55  loss: 0.18129911\n",
      "epoch: 145  batch: 56  loss: 0.07491059\n",
      "epoch: 145  batch: 57  loss: 0.03994645\n",
      "epoch: 145  batch: 58  loss: 0.08064996\n",
      "epoch: 145  batch: 59  loss: 0.07974581\n",
      "epoch: 145  batch: 60  loss: 0.02193455\n",
      "epoch: 145  batch: 61  loss: 0.09492951\n",
      "epoch: 145  batch: 62  loss: 0.02998285\n",
      "epoch: 145  batch: 63  loss: 0.01719759\n",
      "epoch: 145  batch: 64  loss: 0.01817124\n",
      "epoch: 145  batch: 65  loss: 0.03318271\n",
      "epoch: 145  batch: 66  loss: 0.03483368\n",
      "epoch: 145  batch: 67  loss: 0.03054476\n",
      "epoch: 145  batch: 68  loss: 0.04632622\n",
      "epoch: 146  batch: 1  loss: 0.11585177\n",
      "epoch: 146  batch: 2  loss: 0.04300702\n",
      "epoch: 146  batch: 3  loss: 0.02977122\n",
      "epoch: 146  batch: 4  loss: 0.03070323\n",
      "epoch: 146  batch: 5  loss: 0.07611742\n",
      "epoch: 146  batch: 6  loss: 0.06424082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 146  batch: 7  loss: 0.16044235\n",
      "epoch: 146  batch: 8  loss: 0.05246551\n",
      "epoch: 146  batch: 9  loss: 0.05453310\n",
      "epoch: 146  batch: 10  loss: 0.10302982\n",
      "epoch: 146  batch: 11  loss: 0.14497155\n",
      "epoch: 146  batch: 12  loss: 0.05374439\n",
      "epoch: 146  batch: 13  loss: 0.03924600\n",
      "epoch: 146  batch: 14  loss: 0.12195687\n",
      "epoch: 146  batch: 15  loss: 0.13408184\n",
      "epoch: 146  batch: 16  loss: 0.03392220\n",
      "epoch: 146  batch: 17  loss: 0.03761266\n",
      "epoch: 146  batch: 18  loss: 0.04447570\n",
      "epoch: 146  batch: 19  loss: 0.04365760\n",
      "epoch: 146  batch: 20  loss: 0.21315779\n",
      "epoch: 146  batch: 21  loss: 0.23920569\n",
      "epoch: 146  batch: 22  loss: 0.05141273\n",
      "epoch: 146  batch: 23  loss: 0.03393367\n",
      "epoch: 146  batch: 24  loss: 0.06404047\n",
      "epoch: 146  batch: 25  loss: 0.07140861\n",
      "epoch: 146  batch: 26  loss: 0.01839125\n",
      "epoch: 146  batch: 27  loss: 0.02458297\n",
      "epoch: 146  batch: 28  loss: 0.01175275\n",
      "epoch: 146  batch: 29  loss: 0.01453990\n",
      "epoch: 146  batch: 30  loss: 0.01547038\n",
      "epoch: 146  batch: 31  loss: 0.02064952\n",
      "epoch: 146  batch: 32  loss: 0.01096981\n",
      "epoch: 146  batch: 33  loss: 0.01004446\n",
      "epoch: 146  batch: 34  loss: 0.09253111\n",
      "epoch: 146  batch: 35  loss: 0.12242356\n",
      "epoch: 146  batch: 36  loss: 0.09815682\n",
      "epoch: 146  batch: 37  loss: 0.03373424\n",
      "epoch: 146  batch: 38  loss: 0.03237352\n",
      "epoch: 146  batch: 39  loss: 0.10490651\n",
      "epoch: 146  batch: 40  loss: 0.07670546\n",
      "epoch: 146  batch: 41  loss: 0.14439246\n",
      "epoch: 146  batch: 42  loss: 0.06096229\n",
      "epoch: 146  batch: 43  loss: 0.07603446\n",
      "epoch: 146  batch: 44  loss: 0.09910503\n",
      "epoch: 146  batch: 45  loss: 0.11138643\n",
      "epoch: 146  batch: 46  loss: 0.06349194\n",
      "epoch: 146  batch: 47  loss: 0.06140014\n",
      "epoch: 146  batch: 48  loss: 0.09215239\n",
      "epoch: 146  batch: 49  loss: 0.14896247\n",
      "epoch: 146  batch: 50  loss: 0.06344248\n",
      "epoch: 146  batch: 51  loss: 0.08328779\n",
      "epoch: 146  batch: 52  loss: 0.06041008\n",
      "epoch: 146  batch: 53  loss: 0.05318873\n",
      "epoch: 146  batch: 54  loss: 0.30040941\n",
      "epoch: 146  batch: 55  loss: 0.18132469\n",
      "epoch: 146  batch: 56  loss: 0.07373990\n",
      "epoch: 146  batch: 57  loss: 0.03944862\n",
      "epoch: 146  batch: 58  loss: 0.08026750\n",
      "epoch: 146  batch: 59  loss: 0.08023617\n",
      "epoch: 146  batch: 60  loss: 0.02139500\n",
      "epoch: 146  batch: 61  loss: 0.09285073\n",
      "epoch: 146  batch: 62  loss: 0.02928988\n",
      "epoch: 146  batch: 63  loss: 0.01721474\n",
      "epoch: 146  batch: 64  loss: 0.01760822\n",
      "epoch: 146  batch: 65  loss: 0.03294025\n",
      "epoch: 146  batch: 66  loss: 0.03403321\n",
      "epoch: 146  batch: 67  loss: 0.03005386\n",
      "epoch: 146  batch: 68  loss: 0.04663298\n",
      "epoch: 147  batch: 1  loss: 0.11293533\n",
      "epoch: 147  batch: 2  loss: 0.04870120\n",
      "epoch: 147  batch: 3  loss: 0.02999793\n",
      "epoch: 147  batch: 4  loss: 0.03656025\n",
      "epoch: 147  batch: 5  loss: 0.07603665\n",
      "epoch: 147  batch: 6  loss: 0.06441947\n",
      "epoch: 147  batch: 7  loss: 0.15894389\n",
      "epoch: 147  batch: 8  loss: 0.05251981\n",
      "epoch: 147  batch: 9  loss: 0.05463857\n",
      "epoch: 147  batch: 10  loss: 0.10350761\n",
      "epoch: 147  batch: 11  loss: 0.14214480\n",
      "epoch: 147  batch: 12  loss: 0.05555264\n",
      "epoch: 147  batch: 13  loss: 0.03897766\n",
      "epoch: 147  batch: 14  loss: 0.12014197\n",
      "epoch: 147  batch: 15  loss: 0.13417096\n",
      "epoch: 147  batch: 16  loss: 0.03142803\n",
      "epoch: 147  batch: 17  loss: 0.03766793\n",
      "epoch: 147  batch: 18  loss: 0.04227438\n",
      "epoch: 147  batch: 19  loss: 0.04324691\n",
      "epoch: 147  batch: 20  loss: 0.21206312\n",
      "epoch: 147  batch: 21  loss: 0.23943901\n",
      "epoch: 147  batch: 22  loss: 0.05099655\n",
      "epoch: 147  batch: 23  loss: 0.03470661\n",
      "epoch: 147  batch: 24  loss: 0.06336126\n",
      "epoch: 147  batch: 25  loss: 0.07202987\n",
      "epoch: 147  batch: 26  loss: 0.02086924\n",
      "epoch: 147  batch: 27  loss: 0.02420268\n",
      "epoch: 147  batch: 28  loss: 0.01201131\n",
      "epoch: 147  batch: 29  loss: 0.01499130\n",
      "epoch: 147  batch: 30  loss: 0.01885751\n",
      "epoch: 147  batch: 31  loss: 0.01974945\n",
      "epoch: 147  batch: 32  loss: 0.01107975\n",
      "epoch: 147  batch: 33  loss: 0.00959124\n",
      "epoch: 147  batch: 34  loss: 0.09643521\n",
      "epoch: 147  batch: 35  loss: 0.12124299\n",
      "epoch: 147  batch: 36  loss: 0.09918290\n",
      "epoch: 147  batch: 37  loss: 0.03378064\n",
      "epoch: 147  batch: 38  loss: 0.03347950\n",
      "epoch: 147  batch: 39  loss: 0.10316218\n",
      "epoch: 147  batch: 40  loss: 0.07805335\n",
      "epoch: 147  batch: 41  loss: 0.14359979\n",
      "epoch: 147  batch: 42  loss: 0.06112579\n",
      "epoch: 147  batch: 43  loss: 0.07440191\n",
      "epoch: 147  batch: 44  loss: 0.09919298\n",
      "epoch: 147  batch: 45  loss: 0.10733153\n",
      "epoch: 147  batch: 46  loss: 0.06335189\n",
      "epoch: 147  batch: 47  loss: 0.06136608\n",
      "epoch: 147  batch: 48  loss: 0.09303551\n",
      "epoch: 147  batch: 49  loss: 0.14935561\n",
      "epoch: 147  batch: 50  loss: 0.06228392\n",
      "epoch: 147  batch: 51  loss: 0.08335572\n",
      "epoch: 147  batch: 52  loss: 0.06051639\n",
      "epoch: 147  batch: 53  loss: 0.05196495\n",
      "epoch: 147  batch: 54  loss: 0.30025584\n",
      "epoch: 147  batch: 55  loss: 0.18376002\n",
      "epoch: 147  batch: 56  loss: 0.07359339\n",
      "epoch: 147  batch: 57  loss: 0.03995929\n",
      "epoch: 147  batch: 58  loss: 0.07933756\n",
      "epoch: 147  batch: 59  loss: 0.10012630\n",
      "epoch: 147  batch: 60  loss: 0.02162344\n",
      "epoch: 147  batch: 61  loss: 0.09040484\n",
      "epoch: 147  batch: 62  loss: 0.02855688\n",
      "epoch: 147  batch: 63  loss: 0.01717428\n",
      "epoch: 147  batch: 64  loss: 0.01868639\n",
      "epoch: 147  batch: 65  loss: 0.03232791\n",
      "epoch: 147  batch: 66  loss: 0.03418078\n",
      "epoch: 147  batch: 67  loss: 0.03141066\n",
      "epoch: 147  batch: 68  loss: 0.04613983\n",
      "epoch: 148  batch: 1  loss: 0.11299966\n",
      "epoch: 148  batch: 2  loss: 0.04263797\n",
      "epoch: 148  batch: 3  loss: 0.02959936\n",
      "epoch: 148  batch: 4  loss: 0.02981309\n",
      "epoch: 148  batch: 5  loss: 0.07457791\n",
      "epoch: 148  batch: 6  loss: 0.06351481\n",
      "epoch: 148  batch: 7  loss: 0.15757149\n",
      "epoch: 148  batch: 8  loss: 0.05201094\n",
      "epoch: 148  batch: 9  loss: 0.05392717\n",
      "epoch: 148  batch: 10  loss: 0.09880757\n",
      "epoch: 148  batch: 11  loss: 0.14139771\n",
      "epoch: 148  batch: 12  loss: 0.05287018\n",
      "epoch: 148  batch: 13  loss: 0.03866643\n",
      "epoch: 148  batch: 14  loss: 0.12177555\n",
      "epoch: 148  batch: 15  loss: 0.13513169\n",
      "epoch: 148  batch: 16  loss: 0.03280096\n",
      "epoch: 148  batch: 17  loss: 0.03732619\n",
      "epoch: 148  batch: 18  loss: 0.04244266\n",
      "epoch: 148  batch: 19  loss: 0.04270345\n",
      "epoch: 148  batch: 20  loss: 0.20892839\n",
      "epoch: 148  batch: 21  loss: 0.23504508\n",
      "epoch: 148  batch: 22  loss: 0.05083586\n",
      "epoch: 148  batch: 23  loss: 0.03335199\n",
      "epoch: 148  batch: 24  loss: 0.06306116\n",
      "epoch: 148  batch: 25  loss: 0.07269890\n",
      "epoch: 148  batch: 26  loss: 0.01873737\n",
      "epoch: 148  batch: 27  loss: 0.02338257\n",
      "epoch: 148  batch: 28  loss: 0.01158841\n",
      "epoch: 148  batch: 29  loss: 0.01462218\n",
      "epoch: 148  batch: 30  loss: 0.01571962\n",
      "epoch: 148  batch: 31  loss: 0.01985022\n",
      "epoch: 148  batch: 32  loss: 0.01083990\n",
      "epoch: 148  batch: 33  loss: 0.01008328\n",
      "epoch: 148  batch: 34  loss: 0.09208508\n",
      "epoch: 148  batch: 35  loss: 0.12058759\n",
      "epoch: 148  batch: 36  loss: 0.09968832\n",
      "epoch: 148  batch: 37  loss: 0.03316462\n",
      "epoch: 148  batch: 38  loss: 0.03286750\n",
      "epoch: 148  batch: 39  loss: 0.10375328\n",
      "epoch: 148  batch: 40  loss: 0.07681447\n",
      "epoch: 148  batch: 41  loss: 0.14328372\n",
      "epoch: 148  batch: 42  loss: 0.06043377\n",
      "epoch: 148  batch: 43  loss: 0.07442626\n",
      "epoch: 148  batch: 44  loss: 0.09591705\n",
      "epoch: 148  batch: 45  loss: 0.10929541\n",
      "epoch: 148  batch: 46  loss: 0.06200659\n",
      "epoch: 148  batch: 47  loss: 0.06077012\n",
      "epoch: 148  batch: 48  loss: 0.09077227\n",
      "epoch: 148  batch: 49  loss: 0.14930619\n",
      "epoch: 148  batch: 50  loss: 0.06241173\n",
      "epoch: 148  batch: 51  loss: 0.08330178\n",
      "epoch: 148  batch: 52  loss: 0.05821248\n",
      "epoch: 148  batch: 53  loss: 0.05332855\n",
      "epoch: 148  batch: 54  loss: 0.29685089\n",
      "epoch: 148  batch: 55  loss: 0.18453920\n",
      "epoch: 148  batch: 56  loss: 0.07256174\n",
      "epoch: 148  batch: 57  loss: 0.03930906\n",
      "epoch: 148  batch: 58  loss: 0.07866608\n",
      "epoch: 148  batch: 59  loss: 0.06327482\n",
      "epoch: 148  batch: 60  loss: 0.02110086\n",
      "epoch: 148  batch: 61  loss: 0.08680503\n",
      "epoch: 148  batch: 62  loss: 0.02988197\n",
      "epoch: 148  batch: 63  loss: 0.01728727\n",
      "epoch: 148  batch: 64  loss: 0.01701250\n",
      "epoch: 148  batch: 65  loss: 0.03211904\n",
      "epoch: 148  batch: 66  loss: 0.03495449\n",
      "epoch: 148  batch: 67  loss: 0.03004728\n",
      "epoch: 148  batch: 68  loss: 0.04584546\n",
      "epoch: 149  batch: 1  loss: 0.11252748\n",
      "epoch: 149  batch: 2  loss: 0.04494892\n",
      "epoch: 149  batch: 3  loss: 0.02974403\n",
      "epoch: 149  batch: 4  loss: 0.03229713\n",
      "epoch: 149  batch: 5  loss: 0.07393873\n",
      "epoch: 149  batch: 6  loss: 0.06232254\n",
      "epoch: 149  batch: 7  loss: 0.15629166\n",
      "epoch: 149  batch: 8  loss: 0.05180709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 149  batch: 9  loss: 0.05251449\n",
      "epoch: 149  batch: 10  loss: 0.09853993\n",
      "epoch: 149  batch: 11  loss: 0.13703151\n",
      "epoch: 149  batch: 12  loss: 0.05260563\n",
      "epoch: 149  batch: 13  loss: 0.03850156\n",
      "epoch: 149  batch: 14  loss: 0.11756836\n",
      "epoch: 149  batch: 15  loss: 0.13610199\n",
      "epoch: 149  batch: 16  loss: 0.03137420\n",
      "epoch: 149  batch: 17  loss: 0.03455815\n",
      "epoch: 149  batch: 18  loss: 0.04246689\n",
      "epoch: 149  batch: 19  loss: 0.04371069\n",
      "epoch: 149  batch: 20  loss: 0.20843197\n",
      "epoch: 149  batch: 21  loss: 0.23466535\n",
      "epoch: 149  batch: 22  loss: 0.05066844\n",
      "epoch: 149  batch: 23  loss: 0.03344502\n",
      "epoch: 149  batch: 24  loss: 0.06259605\n",
      "epoch: 149  batch: 25  loss: 0.07185557\n",
      "epoch: 149  batch: 26  loss: 0.01798258\n",
      "epoch: 149  batch: 27  loss: 0.02297193\n",
      "epoch: 149  batch: 28  loss: 0.01196864\n",
      "epoch: 149  batch: 29  loss: 0.01444709\n",
      "epoch: 149  batch: 30  loss: 0.01596751\n",
      "epoch: 149  batch: 31  loss: 0.01966892\n",
      "epoch: 149  batch: 32  loss: 0.01118476\n",
      "epoch: 149  batch: 33  loss: 0.00946373\n",
      "epoch: 149  batch: 34  loss: 0.09115267\n",
      "epoch: 149  batch: 35  loss: 0.11937000\n",
      "epoch: 149  batch: 36  loss: 0.10051887\n",
      "epoch: 149  batch: 37  loss: 0.03410237\n",
      "epoch: 149  batch: 38  loss: 0.03210805\n",
      "epoch: 149  batch: 39  loss: 0.10183042\n",
      "epoch: 149  batch: 40  loss: 0.07626042\n",
      "epoch: 149  batch: 41  loss: 0.14291662\n",
      "epoch: 149  batch: 42  loss: 0.06023082\n",
      "epoch: 149  batch: 43  loss: 0.07347471\n",
      "epoch: 149  batch: 44  loss: 0.09524799\n",
      "epoch: 149  batch: 45  loss: 0.10542794\n",
      "epoch: 149  batch: 46  loss: 0.06061428\n",
      "epoch: 149  batch: 47  loss: 0.05891071\n",
      "epoch: 149  batch: 48  loss: 0.09003133\n",
      "epoch: 149  batch: 49  loss: 0.14878196\n",
      "epoch: 149  batch: 50  loss: 0.05853125\n",
      "epoch: 149  batch: 51  loss: 0.08330977\n",
      "epoch: 149  batch: 52  loss: 0.05900649\n",
      "epoch: 149  batch: 53  loss: 0.05221858\n",
      "epoch: 149  batch: 54  loss: 0.29545152\n",
      "epoch: 149  batch: 55  loss: 0.17763437\n",
      "epoch: 149  batch: 56  loss: 0.07013924\n",
      "epoch: 149  batch: 57  loss: 0.03969936\n",
      "epoch: 149  batch: 58  loss: 0.07811499\n",
      "epoch: 149  batch: 59  loss: 0.06016988\n",
      "epoch: 149  batch: 60  loss: 0.02089614\n",
      "epoch: 149  batch: 61  loss: 0.08292783\n",
      "epoch: 149  batch: 62  loss: 0.02766628\n",
      "epoch: 149  batch: 63  loss: 0.01687173\n",
      "epoch: 149  batch: 64  loss: 0.01686923\n",
      "epoch: 149  batch: 65  loss: 0.03184847\n",
      "epoch: 149  batch: 66  loss: 0.03378603\n",
      "epoch: 149  batch: 67  loss: 0.02973284\n",
      "epoch: 149  batch: 68  loss: 0.04583615\n",
      "epoch: 150  batch: 1  loss: 0.11005248\n",
      "epoch: 150  batch: 2  loss: 0.04143951\n",
      "epoch: 150  batch: 3  loss: 0.02830939\n",
      "epoch: 150  batch: 4  loss: 0.03156676\n",
      "epoch: 150  batch: 5  loss: 0.07311878\n",
      "epoch: 150  batch: 6  loss: 0.06217840\n",
      "epoch: 150  batch: 7  loss: 0.15485592\n",
      "epoch: 150  batch: 8  loss: 0.05136816\n",
      "epoch: 150  batch: 9  loss: 0.05240019\n",
      "epoch: 150  batch: 10  loss: 0.09698694\n",
      "epoch: 150  batch: 11  loss: 0.13485357\n",
      "epoch: 150  batch: 12  loss: 0.05258293\n",
      "epoch: 150  batch: 13  loss: 0.03800476\n",
      "epoch: 150  batch: 14  loss: 0.11618534\n",
      "epoch: 150  batch: 15  loss: 0.13700308\n",
      "epoch: 150  batch: 16  loss: 0.03047456\n",
      "epoch: 150  batch: 17  loss: 0.03515739\n",
      "epoch: 150  batch: 18  loss: 0.04185868\n",
      "epoch: 150  batch: 19  loss: 0.04306636\n",
      "epoch: 150  batch: 20  loss: 0.20622969\n",
      "epoch: 150  batch: 21  loss: 0.23223193\n",
      "epoch: 150  batch: 22  loss: 0.05046402\n",
      "epoch: 150  batch: 23  loss: 0.03319444\n",
      "epoch: 150  batch: 24  loss: 0.06126948\n",
      "epoch: 150  batch: 25  loss: 0.07216829\n",
      "epoch: 150  batch: 26  loss: 0.01766390\n",
      "epoch: 150  batch: 27  loss: 0.02215626\n",
      "epoch: 150  batch: 28  loss: 0.01173952\n",
      "epoch: 150  batch: 29  loss: 0.01458598\n",
      "epoch: 150  batch: 30  loss: 0.01591561\n",
      "epoch: 150  batch: 31  loss: 0.01885035\n",
      "epoch: 150  batch: 32  loss: 0.01100290\n",
      "epoch: 150  batch: 33  loss: 0.00996333\n",
      "epoch: 150  batch: 34  loss: 0.09099940\n",
      "epoch: 150  batch: 35  loss: 0.11839212\n",
      "epoch: 150  batch: 36  loss: 0.10219494\n",
      "epoch: 150  batch: 37  loss: 0.03223336\n",
      "epoch: 150  batch: 38  loss: 0.03295723\n",
      "epoch: 150  batch: 39  loss: 0.10132377\n",
      "epoch: 150  batch: 40  loss: 0.07691777\n",
      "epoch: 150  batch: 41  loss: 0.14254442\n",
      "epoch: 150  batch: 42  loss: 0.06000767\n",
      "epoch: 150  batch: 43  loss: 0.07245573\n",
      "epoch: 150  batch: 44  loss: 0.09203739\n",
      "epoch: 150  batch: 45  loss: 0.10371649\n",
      "epoch: 150  batch: 46  loss: 0.05923179\n",
      "epoch: 150  batch: 47  loss: 0.05878817\n",
      "epoch: 150  batch: 48  loss: 0.08842759\n",
      "epoch: 150  batch: 49  loss: 0.14889853\n",
      "epoch: 150  batch: 50  loss: 0.05769314\n",
      "epoch: 150  batch: 51  loss: 0.08265936\n",
      "epoch: 150  batch: 52  loss: 0.05776572\n",
      "epoch: 150  batch: 53  loss: 0.05206336\n",
      "epoch: 150  batch: 54  loss: 0.29302266\n",
      "epoch: 150  batch: 55  loss: 0.17789805\n",
      "epoch: 150  batch: 56  loss: 0.06943024\n",
      "epoch: 150  batch: 57  loss: 0.03968037\n",
      "epoch: 150  batch: 58  loss: 0.07792831\n",
      "epoch: 150  batch: 59  loss: 0.05859768\n",
      "epoch: 150  batch: 60  loss: 0.02095145\n",
      "epoch: 150  batch: 61  loss: 0.08221819\n",
      "epoch: 150  batch: 62  loss: 0.02709562\n",
      "epoch: 150  batch: 63  loss: 0.01709599\n",
      "epoch: 150  batch: 64  loss: 0.01707556\n",
      "epoch: 150  batch: 65  loss: 0.03151885\n",
      "epoch: 150  batch: 66  loss: 0.03402966\n",
      "epoch: 150  batch: 67  loss: 0.03018491\n",
      "epoch: 150  batch: 68  loss: 0.04556703\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "                \n",
    "        # Apply the model\n",
    "        y_pred = Model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "#         torch.cuda.empty_cache()\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%1 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Run the validationing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "            # Apply the model\n",
    "            \n",
    "            X_validation = X_validation.to(device)\n",
    "            y_validation = y_validation.to(device)\n",
    "            \n",
    "            y_val = Model(X_validation)\n",
    "    loss = criterion(y_val, y_validation)\n",
    "    validation_losses.append(loss.cpu().detach().numpy())\n",
    "#     validation_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7796f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:16:08.885595Z",
     "start_time": "2023-01-17T23:16:08.598603Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbEklEQVR4nOydd3zU9f3Hn9/b2SEJJIywERAUERyAW0HBulqrdduftkXqQOqsHUptaa0DqxWrrbOuulFRCCqKoqIskamsMAIhjOzc/P7++Nz3Vi7JJdzlktz7+SCPu/ve977fz/vuuHvde2q6rusIgiAIgiB0EUzJXoAgCIIgCEI8EXEjCIIgCEKXQsSNIAiCIAhdChE3giAIgiB0KUTcCIIgCILQpRBxIwiCIAhCl0LEjSAIgiAIXQpLshfQ3vh8Pnbt2kVWVhaapiV7OYIgCIIgxICu61RXV9OrVy9MpuZ9Myknbnbt2kVxcXGylyEIgiAIQhvYvn07ffr0aXaflBM3WVlZgHpysrOz43pst9vNggULmDRpElarNa7H7oikmr0gNqeCzalmL6SezalmL3QNm6uqqiguLg58jzdHyokbIxSVnZ2dEHGTnp5OdnZ2p33ztIZUsxfE5lSwOdXshdSzOdXsha5lcywpJZJQLAiCIAhClyLp4uaxxx5jwIABOBwOxowZw+LFi5vd3+l0ctddd9GvXz/sdjuDBg3iqaeeaqfVCoIgCILQ0UlqWOqVV15h+vTpPPbYY0yYMIF//etfTJ48mbVr19K3b9+oj7nooovYs2cP//nPfxg8eDDl5eV4PJ52XrkgCIIgCB2VpIqbBx98kGuuuYZrr70WgNmzZzN//nzmzJnDrFmzGu3/wQcf8Mknn7B582by8vIA6N+/f3suWRAEQYjA5/PhcrmSvYyYcbvdWCwWGhoa8Hq9yV5Ou9BZbLbZbC2WecdC0sSNy+Vi2bJl3HHHHWHbJ02axJIlS6I+Zu7cuYwdO5b77ruP559/noyMDM4991z+9Kc/kZaWFvUxTqcTp9MZuF1VVQWoF9rtdsfJGgLHDL3s6qSavSA2pwKpZi8cms0ul4vt27fj8/nivayEoes6RUVFlJaWpky/s85is8lkom/fvlGTnlvz/kyauKmoqMDr9VJYWBi2vbCwkN27d0d9zObNm/nss89wOBy8+eabVFRUMG3aNPbv399k3s2sWbO45557Gm1fsGAB6enph25IFEpKShJy3I5KqtkLYnMqkGr2QttszsvLo1u3bnTv3r1Df2kKHR9d19m7dy/Lli1j//79je6vq6uL+VhJLwWP/M+g63qT/0F8Ph+apvHCCy+Qk5MDqNDWhRdeyD//+c+o3ps777yTGTNmBG4bdfKTJk1KSCl4SUkJEydO7PSldrGQavaC2JwKNqeavdB2mz0eD1u2bKFXr15x/zxNJEan21TqVN9ZbLbb7ZhMJsaOHYvFEi5RjMhLLCRN3BQUFGA2mxt5acrLyxt5cwx69uxJ7969A8IGYPjw4ei6zo4dOxgyZEijx9jtdux2e6PtVqs1YR9ciTx2RyTV7AWxORVINXuh9TZ7vV40TQt8IXUWjBCapmmdat2HQmex2W63o2kamqY1ei+25r2ZNAttNhtjxoxp5AYtKSlh/PjxUR8zYcIEdu3aRU1NTWDbxo0bMZlMLbZiFgRBEBJDR/YECJ2LeL2XkirfZsyYwb///W+eeuop1q1bx80330xpaSlTp04FVEjpyiuvDOx/6aWXkp+fz89//nPWrl3Lp59+yq233sr//d//NZlQLAiCIAhCapHUnJuLL76Yffv2MXPmTMrKyhg5ciTz5s2jX79+AJSVlVFaWhrYPzMzk5KSEm644QbGjh1Lfn4+F110Effee2+yTBAEQRAEoYOR9MDbtGnT2Lp1K06nk2XLlnHSSScF7nvmmWdYtGhR2P7Dhg2jpKSEuro6tm/fzgMPPCBeG0EQBCFp9O/fn9mzZ8e8/6JFi9A0jYMHDyZsTaC+Q3NzcxN6jo5K0qulBIXXp+Px+bBbzMleiiAIQpfmtNNOY/jw4fzzn/+My/G+/vprMjIyYt5//PjxlJWVhRXHCPEl6Z4bQXHJE19yyt8X0eDuuJ0jBUEQUgVd12Me7dO9e/dW9U2z2WwUFRVJInYCEXHTQVheeoCyygbKq5wt7ywIgtAB0XWdOpcnKX+6rse0xquvvppPPvmExx9/HLPZjKZpbN26NRAqmj9/PmPHjsVut7N48WI2bdrEeeedR2FhIZmZmRxzzDEsXLgw7JiRYSlN0/j3v//NBRdcQHp6OkOGDGHu3LmB+yPDUkb4aP78+QwfPpzMzEzOOussysrKAo/xeDzceOON5Obmkp+fz+23385VV13F+eef36rXaM6cOQwaNAibzcbQoUN5/vnnw+6/++676du3L3a7nV69enHjjTcG7nvssccYMmQIDoeDwsJCLrzwwladuz2RsFQHwOfT8fjUf0yXt/O0MBcEQQil3u3l8D/MT8q51848k3Rby19pDz/8MBs3buSwww7jL3/5CyaTie7du7N161YAbrvtNu6//34GDhxIbm4uO3bsYMqUKdx77704HA6effZZzjnnHDZs2NDkgGeAe+65h/vuu4+///3vPPLII1x22WVs27YtMBcxkrq6Ou6//36ef/55TCYTl19+ObfccgsvvPACAH/729944YUXePrppxk+fDgPP/wwb731FqeeemrMz9G7777LzTffzOzZsznjjDN49913+fnPf06fPn049dRTee2113jooYd4+eWXGTFiBLt372bVqlUAfPPNN9x44408//zzjB8/nv3797N48eKYz93eiLjpAIQKGreIG0EQhISRk5ODzWYjLS2NoqKiRg3tZs6cycSJEwO38/PzGTVqVOD2vffey5tvvsncuXO5/vrrmzzP1VdfzSWXXALAX/7yFx555BGWLl3KWWedFXV/t9vN448/zqBBgwC4/vrrmTlzZuD+Rx55hDvvvJMLLrgAgEcffZR58+a1yvZHHnmEq666imnTpgGqHcuXX37J/fffz6mnnkppaSlFRUWcccYZWK1W+vbty7HHHgtAaWkpGRkZ/OhHPyIrK4t+/foxevToVp2/PRFx0wFwi7gRBKELkGY1s3bmmUk7dzwYO3Zs2O3a2lruuece3n33XXbt2oXH46G+vj6sTUk0jjzyyMD1jIwMsrKyKC8vb3L/9PT0gLAB1ZHf2L+yspI9e/YEhAaA2WxmzJgxrRpYunHjxkAfOYMJEybw8MMPA/DTn/6U2bNnM3DgQM466yymTJnCOeecg8ViYeLEifTr1y9w31lnnRUIu3VEJOemA+D26lGvC4IgdCY0TSPdZknKX7yScyOrnm699VZef/11/vznP7N48WJWrlzJEUccgcvlavY4kaMCNE1rVohE2z8yjyjaLMbW0tw8x+LiYjZs2BCY1Tht2jROOukk3G43WVlZLF++nJdeeomePXvyhz/8gVGjRiW8nL2tiLjpALg84rkRBEFoL6xWK15vbJWpixcv5uqrr+aCCy7giCOOoKioKJCf017k5ORQWFjI0qVLA9u8Xi8rVqxo1XEOO+wwPv/887BtS5YsYfjw4YHbaWlpnHvuufzjH/9g0aJFfPHFF6xevRoAi8XCGWecwX333ce3337L1q1b+eijjw7BssQhYakOgISlBEEQ2o/+/fuzbNkytm7dSnZ2dpNJvgCDBw/mjTfe4JxzzkHTNH7/+9+3KhQUL2644QZmzZrF4MGDGTZsGI888ggHDhxolcfqxhtv5Oc//zljxozh9NNP55133uGNN94IVH8988wzeL1ejjvuONLT03n++edJS0ujX79+vPvuu2zevJmTTjqJbt26MW/ePHw+H0OHDk2UyYeEeG46AE7x3AiCILQbv/nNbzCbzYwcOZLu3bs3mz/z0EMP0a1bN8aPH88555zDmWeeydFHH92Oq1XcfvvtXHLJJVx55ZWMGzeOzMxMzjzzTBwOR8zHOPvss3nooYf4+9//zogRI/jXv/7F008/zSmnnAJAbm4uTz75JBMmTODII4/kww8/5J133iE/P5/c3FzeeOONQAPExx9/nJdeeokRI0YkyOJDQ9PbErTrxFRVVZGTk0NlZSXZ2dlxPbbb7WbevHlMmTKlVaPZ15VVMflhVVL3+OVjOGtkUVzXlSjaam9nRmzu+janmr3QdpsbGhrYsmULAwYMaNWXbLLx+XxUVVWRnZ3dqFqqs+Dz+Rg+fDgXXXQRf/rTn2LavzPY3Nx7qjXf3xKW6gBIzo0gCILQHNu2bWPBggWcfPLJOJ1OHn30UbZs2cKll16a7KV1SDqufEshQgWNJwmxXEEQBKFjYzKZeOaZZzjmmGOYMGECq1evZuHChWHJwEIQ8dx0AMI8N56UihIKgiAIMVBcXNyo0kloGvHcdABCOxTL+AVBEARBODRE3HQAwpv4ibgRBEEQhENBxE0HQBKKBUEQBCF+iLjpAIQ38ZOcG0EQBEE4FETcdABCPTeh1wVBEARBaD0ibjoALikFFwRB6FT079+f2bNnB25rmsZbb73V5P5bt25F0zRWrlx5SOeN13Fa4uqrr+b8889P6DkSiZSCdwDCc24kLCUIgtDZKCsro1u3bnE95tVXX83BgwfDRFNxcTFlZWUUFBTE9VxdDRE3HYDQnBsJSwmCIHQ+ioraZ2yO2Wxut3N1ZiQs1QGQailBEIT24V//+hfFxcWNJnufe+65XHXVVQBs2rSJ8847j8LCQjIzMznmmGMCk7ObIjIstXTpUkaPHo3D4WDs2LGsWLEibH+v18s111zDgAEDSEtLY+jQoTz88MOB+++++26effZZ3n77bTRNQ9M0Fi1aFDUs9cknn3Dsscdit9vp2bMnd9xxBx6PJ3D/Kaecwk033cQf/vAHCgoKKCoq4u67727V8+Z0Ornxxhvp0aMHDoeDE044ga+//jpw/4EDB7jsssvo3r07aWlpDBkyhKeffhoAl8vF9ddfT8+ePXE4HPTv359Zs2a16vytRTw3HYDwaikRN4IgdFJ0Hdx1yTm3NR00rcXdfvrTn3LjjTeyePFizjnnHEB9Mc+fP5933nkHgJqaGqZMmcK9996Lw+Hg2Wef5ZxzzmHDhg307du3xXPU1tbyox/9iNNOO43//ve/bNmyhZtuuilsH5/PR58+ffjf//5HQUEBS5Ys4Ze//CU9e/bkoosu4pZbbmHdunVUVVUFREJeXh67du0KO87OnTuZMmUKV199Nc899xzr16/nF7/4BQ6HI0zAPPfcc0ybNo0vvviCr776iquvvpoJEyYwceLEFu0BuO2223j99dd59tln6devH/fddx9nnnkmP/zwA3l5efz+979n7dq1vP/++xQUFPDDDz9QX18PwD/+8Q/mzp3L//73P/r27cv27dvZvn17TOdtKyJuOgCusCZ+knMjCEInxV0Hf+mVnHP/dhfYMlrcLS8vjzPPPJPXXnstIG5effVV8vLyOP300wEYNWoUo0aNCjzm3nvv5c0332Tu3Llcf/31LZ7jhRdewOv18tRTT5Gens6IESPYsWMH1113XWAfq9XKPffcE7g9YMAAlixZwv/+9z8uuugiMjMzSUtLw+l0NhuGeuyxxyguLubRRx9F0zSGDRvGrl27uP322/nDH/4QmAB+5JFHcvvtt5Odnc3QoUN59NFH+fDDD2MSN7W1tcyZM4dnnnmGyZMnA/Dkk09SUlLCf/7zH2699VZKS0sZPXo0Y8eOBVTCtUFpaSlDhgzhhBNOQNM0+vXr1+I5DxUJS3UAJCwlCILQflx66aXMnTsXp9MJKDHys5/9DLPZDKgv89tuu43DDz+c3NxcMjMzWb9+PaWlpTEdf926dYwaNYr09PTAtnHjxjXa7/HHH2fs2LF0796dzMxMnnzyyZjPEXqucePGoYV4rSZMmEBNTQ07duwIbDviiCPCHtezZ0/Ky8tjOsemTZtwu91MmDAhsM1qtXLssceybt06AK677jpefvlljjrqKG677TaWLFkS2Pfqq69m5cqVDB06lBtvvJEFCxa0ysa2IJ6bDoCEpQRB6BJY05UHJVnnjpFzzjmHX/7yl7z33nscd9xxLF68mAcffDBw/6233sr8+fO5//77GTx4MGlpaVx44YW4XK6Yjq/rLXvg//e//3HzzTfzwAMPMG7cOLKysvj73//OV199FbMdxrm0iHCccf7Q7VarNWwfTdMa5R01d47I40Wee/LkyWzbto333nuPhQsXcvrpp/PrX/+a+++/n6OPPpotW7bw/vvvs3DhQi666CLOOOMMXnvttVbZ2hpE3HQApBRcEIQugabFFBpKNmlpafzoRz/ixRdfZPPmzRx22GGMGTMmcP/ixYu5+uqrueCCCwCVg7N169aYj3/44Yfz/PPPU19fT1paGgBffvll2D6LFy9m/PjxTJs2LbBt06ZNYfvYbDa8Xm+L53r99dfDhMaSJUvIysqid+/eMa+5OQYPHozNZuOzzz7j0ksvBcDtdvPNN98wffr0wH7du3fn6quv5uqrr+bEE0/k1ltv5f777wcgOzubiy++mIsvvpgLL7yQs846i/3795OXlxeXNUYiYakOgHhuBEEQ2pef/vSnzJs3j6eeeorLL7887L7BgwfzxhtvsHLlSlatWsWll14as5cDVNjLZDJxzTXXsHbtWubNmxf4kg89xzfffMP8+fPZuHEjv//978Oqj0DlrXz77bds2LCBiooK3G53o3NNmzaN7du3c8MNN7B+/Xrefvtt/vjHPzJjxoxAvs2hkpGRwXXXXcett97KBx98wNq1a/nFL35BXV0d11xzDQB/+MMfePvtt/nhhx9Ys2YN7777LsOHDwfgoYce4uWXX2b9+vVs3LiRV199laKiInJzc+OyvmiIuOkAOKXPjSAIQrty0kknkZeXx4YNGwLeCIOHHnqIbt26MX78eM455xzOPPNMjj766JiPnZmZyTvvvMPatWsZPXo0d911F3/729/C9pk6dSo//vGPufjiiznuuOPYt29fmBcH4Be/+AVDhw4N5OV8/vnnjc7Vu3dv5s2bx9KlSxk1ahRTp07lmmuu4Xe/+10rno2W+etf/8pPfvITrrjiCo4++mh++OEH5s+fH2hcaLPZuPPOOznyyCM56aSTMJvNvPzyy4Hn429/+xtjx47lmGOOYevWrcybNy9u4isamh5LcLALUVVVRU5ODpWVlWRnZ8f12G63m3nz5jFlypRG8c3m+OVz37Bg7R4Aju6byxvTJrTwiI5BW+3tzIjNXd/mVLMX2m5zQ0MDW7ZsYcCAATgcjgSuML74fD6qqqrIzs5O6BdsR6Kz2Nzce6o1398d18IUIny2VEppTUEQBEGIOyJuOgAyfkEQBEEQ4oeImw6A2xPaxE/EjSAIgiAcCiJuOgBOr5SCC4IgCEK8EHHTAXBLh2JBEDoxKVaXIiSQeL2XRNx0AFzS50YQhE6IMa4g1s69gtASxnvJeG+1FelQ3AFwS1hKEIROiMViIT09nb1792K1Wjt0iXEoPp8Pl8tFQ0NDp1nzodIZbPb5fOzdu5f09HQslkOTJyJuOgAyOFMQhM6Ipmn07NmTLVu2sG3btmQvJ2Z0XQ+MRoicl9RV6Sw2m0wm+vbte8hrFHHTAZDxC4IgdFZsNhtDhgzpVKEpt9vNp59+ykknnZRSjRo7g802my0uniURNx0AZ8TgzGhTXgVBEDoqJpOpU3UoNpvNeDweHA5Hh/6ijyepZnPHDLylGJHeGsm7EQRBEIS2I+KmAxDZlVhCU4IgCILQdkTcJBmvTydynJSIG0EQBEFoOyJukkw0ISNhKUEQBEFoOyJukkxoMrGRQyyeG0EQBEFoOyJuEkX1bqjZ2+JuoUImzWputE0QBEEQhNYh4iYReF3w2PHwr5PA17xQMZKJbWYTNot6OUTcCIIgCELbkT43icBZDfUHgAPg84DJ1uSuhpCxWUxYzUrcuDyScyMIgiAIbSXpnpvHHnuMAQMG4HA4GDNmDIsXL25y30WLFqFpWqO/9evXt+OKY8DnCV7Xvc3uanhurGYNm1k8N4IgCIJwqCRV3LzyyitMnz6du+66ixUrVnDiiScyefJkSktLm33chg0bKCsrC/wNGTKknVYcIz5v9OtRMCaCW80mLGaVUexpIZQlCIIgCELTJFXcPPjgg1xzzTVce+21DB8+nNmzZ1NcXMycOXOafVyPHj0oKioK/B3qaPS40wbPjYSlBEEQBCE+JC3nxuVysWzZMu64446w7ZMmTWLJkiXNPnb06NE0NDRw+OGH87vf/Y5TTz21yX2dTidOpzNwu6qqClBDxNxu9yFY0BjjeB5XA8bkDrfLCeamz1PvVPdZTRoWk/Lc1LtccV9bIjDW2BnWGi/E5q5PqtkLqWdzqtkLXcPm1qw9aeKmoqICr9dLYWFh2PbCwkJ2794d9TE9e/bkiSeeYMyYMTidTp5//nlOP/10Fi1axEknnRT1MbNmzeKee+5ptH3BggWkp6cfuiFRWPLZp5zuv75wwXx2ebMBKIgyV25DpQaYaaivxdsAoPHFV19TvbHzeG9KSkqSvYR2R2zu+qSavZB6NqeavdC5ba6rq4t536RXS0VOv25uIvbQoUMZOnRo4Pa4cePYvn07999/f5Pi5s4772TGjBmB21VVVRQXFzNp0iSys7PjYEEQt9tNSUkJ448/DtapbSeffDLjH1MJz0tuPzkQejJI37gX1q4gPzcHu8VEae1BRh11NGeOKIw8fIfDsHfixIkpMWUWxOZUsDnV7IXUsznV7IWuYbMReYmFpImbgoICzGZzIy9NeXl5I29Ocxx//PH897//bfJ+u92O3W5vtN1qtSbsBbaE6Jdal5eD9f5wFSbSI87p86c92a3mQLWUTzN1qjdfIp/LjorY3PVJNXsh9WxONXuhc9vcmnUnLaHYZrMxZsyYRi6ykpISxo8fH/NxVqxYQc+ePeO9vENCC0korq4P5vu4PY2roEJLwa1+VeSRUnBBEARBaDNJDUvNmDGDK664grFjxzJu3DieeOIJSktLmTp1KqBCSjt37uS5554DYPbs2fTv358RI0bgcrn473//y+uvv87rr7+eTDMaE1IhVV3vClyPNhAz2MTPjNWfUCx9bgRBEASh7SRV3Fx88cXs27ePmTNnUlZWxsiRI5k3bx79+vUDoKysLKznjcvl4pZbbmHnzp2kpaUxYsQI3nvvPaZMmZIsE6IT4rmpCfXcRBEtwfELGhaTvxRcpoILgiAIQptJekLxtGnTmDZtWtT7nnnmmbDbt912G7fddls7rOoQaYW4cYc18fN3KI4SvhIEQRAEITaSLm66JCEdhmsaQsVNY4+MM6SJn1nCUoIgCIJwyIi4SQQhnpvaFj03SvBYzaZAEz8RN4IgCILQdpI+OLNLEipuGkITipsOS4WOX4jm4REEQRAEITbEc5MIQsRNXYML/MMYoomWYEKxCaN3oXhuBEEQBKHtiOcmEYSUgteGzLWK1r8m1HNjC3huRNwIgiAIQlsRz00iaOS5UbiiiBZnSBM/DSPnRsJSgiAIgtBWRNwkghBxU++MsYmf2RzYFk0ECYIgCIIQGyJuEoEvGJYKFTfRwlKB8QuW4LBQ6XMjCIIgCG1HxE0iCPXcuNyB69E8MkHPjanRNkEQBEEQWo+ImwQQOjjT5w1ej1otFZJQrPvvdvsk50YQBEEQ2oqIm0QQEpYyERQq0cNSwSZ+Pr+6kbCUIAiCILQdETeJIMRzYyYoVJpt4mc24TXEjYSlBEEQBKHNiLhJBHqo5yYoVKJN+w4mFJsw+wxxI2EpQRAEQWgrIm4SQROem2ab+JlNeDUlaqQUXBAEQRDajoibROCL7rmJFm4KJhRreLxN7ycIgiAIQmyIuEkETXhumgtL2cxmNE1d90hYShAEQRDajIibRNCKsJThubGaNYxRX+K5EQRBEIS2I+ImEbQiLGVss1pM4N9Xcm4EQRAEoe3IVPBEEOG5sVkMj0xzYSmTX+CI50YQBEEQDgURN4kgVNxoPgoybEBTnhsleGwWU2AEg9sjOTeCIAiC0FZE3CSCiA7FBVl2oIlqqVDPjVk8N4IgCIJwqEjOTSKICEsVZBripunZUlZLyPgFETeCIAiC0GZE3CSA0MGZJnzkNxGW0nU9rImfTzoUC4IgCMIhI+ImEehBEWPCR/cmwlIenx6YBG4zm/D6xHMjCIIgCIeK5NwkghjDUqEixmYx+XvdKNFjeHEEQRAEQWgdIm4SQYi4sWg6OWlWoLFHxkgmBtXEzygFB3D7xHsjCIIgCG1BxE2c2LavlmkvruQf35nDxE2GVQvpcxMhbvy3NQ3MJi1QCq72Fc+NIAiCILQFybmJE5l2CyXrygENl9uNw7893Uog3BQpWELLwDVNC5SCQ/RRDYIgCIIgtIx4buJEfqadQd0zAKisrQ9sT7cERUukYAk08PPfbzZpmJQOkhEMgiAIgtBGRNzEkbH9ugFQVdsQ2JZmJSBuIqeCBzw3Ibk2FnPToxoEQRAEQWgZETdx5Jh+uQBU1wfFTbpFwxIIS0V6boyJ4MGXITiCQTw3giAIgtAWRNzEkbH9leemwekKbEuz6AHBEhmWMkJPoZ4baxNCSBAEQRCE2BBxE0d656aRa9MxE5wt5TATMjMqeljKEDTquhHCEnEjCIIgCG1BxE2cGZStYyYoTNJiCEvZLObAtqaEkCAIgiAIsSHiJs4MytaxRHhubE1M+w6Wggc9N0aISkrBBUEQBKFtSJ+bODMoS8cU4rmxm3VowhsTLaHY4q8Fl7CUIAiCILQNETdxpjAN7KZQcaPhbSIs5YxSCi5hKUEQBEE4NCQsFWc0DTKtwTCT3aw3GZYyBEyo58aYLyWl4IIgCILQNkTcJIB0S9DrYg+plvLp4A2Z9h2tiZ8txlLwb3cc5JWvS9F18fAIgiAIQigSlkoAaSHixmbS8YUkDLu9Pswmc+A6EDYwM9ZS8N/8bxXfl9cwolcOI3vnxG3tgiAIgtDZEc9NArBpQXFj0XxhYadQj4w7ahM/o1qqaY+Mruts218HwK6D9Y3ud0lISxAEQUhhRNwkAE33hFyPFDdB0eJspolfc2GpA3XugIA5UOcKu+93b61mzJ9KoooeQRAEQUgFRNwkAp837HrotG9Pi56blnNudlcGZ1ftqw0XN4u/r6Da6WFdWVWbly8IgiAInRkRN4nAF/TcoCuhEy2XJjh+IVrOTdNhqd1VQa/MgQhxs79G3a53exEEQRCEVETETSIIFTd+L44tSv+a5hKKm/fcOAPXQz03DW4v1U517nqXiBtBEAQhNRFxkwhCw1J+z40xX8oTxXMTVgpu8YelmkkK3l0VDEvtDxE3+yOEjiAIgiCkIiJuEkGY5yY89BQWlorWxM/w3PiaCUtVRg9L7asJXpewlCAIgpCqiLhJBHpjz020sQrRPDcxhaWqooelKmqD2+tdUg4uCIIgpCYibuKNrqNFybmxRglLRR2caW45LLUnpFpKPDeCIAiCEE7Sxc1jjz3GgAEDcDgcjBkzhsWLF8f0uM8//xyLxcJRRx2V2AW2mohwkt5MWCrq+IVYPDdBcVPr8gbya/bVBD03knMjCIIgpCpJFTevvPIK06dP56677mLFihWceOKJTJ48mdLS0mYfV1lZyZVXXsnpp5/eTiuNHZMeISqaCUsFq6UaN/FrqhS83uWlst4dts1o5BdZOSUIgiAIqUhSxc2DDz7INddcw7XXXsvw4cOZPXs2xcXFzJkzp9nH/epXv+LSSy9l3Lhx7bTS2NH0CI9LM2EpVzPjF5ry3Bhem3Sbme5ZdiAYjqoI8dxIWEoQBEFIVZI2ONPlcrFs2TLuuOOOsO2TJk1iyZIlTT7u6aefZtOmTfz3v//l3nvvbfE8TqcTpzP4pV9VpTr3ut1u3G53Uw9rE263G41wUeHzefC63Vj8LYrrncHzOv0CxKTrgW1m/1wql9sbdX0799cAUJhlx2Yxsbfayd6qetw90qmoDoar6pyeuNsXiXH8RJ+nIyE2d31SzV5IPZtTzV7oGja3Zu1JEzcVFRV4vV4KCwvDthcWFrJ79+6oj/n++++54447WLx4MRZLbEufNWsW99xzT6PtCxYsID09vfULbwFrRFjqwL4KPps3j6qDJsDE18uW492mBEx5hRnQ+HbVCtiutm3crQFmSnfuZN687Y2O//Vedb/FXYPPDWDio8+XUrVRZ/MudTyA7bt2M2/evLjbF42SkpJ2OU9HQmzu+qSavZB6NqeavdC5ba6rq4t536SJGwNN08Ju67reaBuA1+vl0ksv5Z577uGwww6L+fh33nknM2bMCNyuqqqiuLiYSZMmkZ2d3faFR8HtdvPpvNfCtnXLzWHKlCm8uncZ31ftY+SRo5hyVC8Antj2BdRUM+7YsZx8WHe1vq938NqWtRR0L2TKlNGNzrH90y3ww/ccPqA3bq+P77/bQ9/DDmfKuH7MWvMJoLxUmbl5TJlybFzti2ZvSUkJEydOxGq1JvRcHQWxuevbnGr2QurZnGr2Qtew2Yi8xELSxE1BQQFms7mRl6a8vLyRNwegurqab775hhUrVnD99dcD4PP50HUdi8XCggULOO200xo9zm63Y7fbG223Wq0JeYG1CM+NSfdhslqxW8xqzWiB83r8u6bZbYFtDpt6STw6UddXUavccr26pVPrH7VQ1eDFYrGwvzbosmvw+NrtDZyo57IjIzZ3fVLNXkg9m1PNXujcNrdm3UlLKLbZbIwZM6aRi6ykpITx48c32j87O5vVq1ezcuXKwN/UqVMZOnQoK1eu5LjjjmuvpTeLRkQicKPBmSFN/KIkFBvXm0wo9ve4Kcp20C3dBqgqqWqnJ6zMXGZLCYIgCKlKUsNSM2bM4IorrmDs2LGMGzeOJ554gtLSUqZOnQqokNLOnTt57rnnMJlMjBw5MuzxPXr0wOFwNNqeTCI9N8b4heZmS0Udv+CJXgpe5q+WKsx2YETvDtS6whr4ATS4pUOxIAiCkJokVdxcfPHF7Nu3j5kzZ1JWVsbIkSOZN28e/fr1A6CsrKzFnjcdjUal4HrkVPAopeBRxI2rCc+N0Z24Z44jcKx9ta6wBn4gfW4EQRCE1CXpCcXTpk1j2rRpUe975plnmn3s3Xffzd133x3/RR0Cpib73DTTxM8S2sTP7+HxNRY3Xp/OXr+IKcpxBHJuDtS6qPB7bgoy7VTUOKXPjSAIgpCyJH38Qlcjss+N4bkJzIwKnS1ljF8wmwPbbM2EpSpqnHh9OmaTRkGmnW4ZKudmf62Lff6hmX26pQGqiZ+uNz1ZXBAEQRC6KiJu4kzTHYqbDktZQzw3lmY6FJf5Q1I9suyYTRr5fnFzoM7F3upwcaPr4Gxm+KYgCIIgdFVE3MSZRgnFenhFlBGW8vr0wHWjTByCYaloOTdGpVRhtgOAXH+1lE+HzXtrAejtFzcgeTeCIAhCaiLiJs40Tij2V0uZwsNSdS5PYJd0W6i4adpzs6cqWAYOSjBlOVTa1MY91YH7AqMeRNwIgiAIKYiImzhjisy5aSIsZfSh0TSwR+1z0zhfxghLFeU4Atvy/KGpzRXKc5OfaSfNag47hyAIgiCkEiJu4kyTpeCW8EThOr/wSLeaw8ZNxOS5iSJujJ45BRk2HH5PkPS6EQRBEFIRETdxJpBzo/lDTX7PTSAs5TPCUn5xYw+vxrdGqaoyCO1ObJDnz7sxCPPcSFhKEARBSEFE3MSZgOfG4p9npUfvc1PvVjk3ofk20fYLZU9VeEIxBD03BvmZtoC4kYRiQRAEIRURcRNnAjk3Zr/o8Bnl3kZYSt2udar9DCFiYIgbr0/H6wsXOJX1ajBmt4zg8LC8zKC40TTolh4MS0nOjSAIgpCKiLiJM4GwVKTnxhTeeTgQlmrkuQnm30SGpmr9FVYZtmAoKzQs1S3dhtmkkWZVL6uEpQRBEIRURMRNnNGMrsBmv7jxRZ8KHgxLRebcBF+SUHHj9emBBOGMkDyd0LCU0dRPcm4EQRCEVEbETZwJem78osPw3ESEpQzPTVoTOTcAnpC8m6b64oSJG3+IyiE5N4IgCEIKI+Imzmj4vS2RnpuIsJSRD5MRIW7MJg2zqXHFlCGGzCYtrC9OuLhR55Q+N4IgCEIqI+Imzpia8txEhKWCnpvGg9mjjWAwJoCn28L74oSKmwL/delzIwiCIKQyIm7iTCAsZQ4p0fb5GldLuaKXgkOIEPI09txkRIihZj03EpYSBEEQUhARN3Em0OcmVNzo3ibDUtHEjbGtLiSs1FR1VabdEvD0GDk30udGEARBSGVE3MQZLbLPDYAe4rlpFJZqLG6MaqgaZzCJOODpsYfvr2lawHuTn2EPO6bk3AiCIAipiIibONOoQzGAz9so1FTfRJgJlDcGgnk2AHVOw3PTeP/hPbPRNBhalAUEq6UkLCUIgiCkIo2/KYVDwhQt50b3BmZLBZv4KeESzXOT2YznJrK6CmDOZWOoqHFSnJeujiniRhAEQUhhxHMTZ5ry3NgiwlK1zeTcRAtL1RnVUvbGejTNZg4IGwCHv0Ox5NwIgiAIqYiImzjTZM6NObxaqrmE4mhhqdom+uJEQ/rcCIIgCKmMiJs4E7VayhcMS7kjw1LWxp6YDH/ScI0ztFoq+riGaAT63HhE3AiCIAiph4ibOBMUN1bQ/E+v3jgsFUgotkfz3Kip32GeG2fT+0cinhtBEAQhlRFxE2cCCcUmC2h+IRJSLeX16fh8OnXu5sJSfs9NQ1DcBMNYLXtugn1upEOxIAiCkHqIuIkzgdlSJrP6A1UtZQ6OTHD7fM2OXwgkFLui9LmJJefGJtVSgiAIQuoi4ibOaE14bmwh074bXL5Av5t0a9PVUmF9bprpixOJhKUEQRCEVEbETZwJ5NyYLCGem2C1FEBVgztwvbk+N+E5N9E7FEcjtImfruutM0AQBEEQOjkibuJMwHOjmcGY3u3zYjZpgZuV9UrcmDSwWxq/BMEmfo1nS8XkuQkRTE6P5N0IgiAIqYWImzhjCs250YI5NxCc9m2ImwybBU3TGh0j2MQv6OFpTc6NI0QwSWhKEARBSDVE3MSZsJybkLAUEMi7McRNtJAUhIalQjw3gVLwlj03FrMpMClcet0IgiAIqYaImzgTlnMTklAMBCqmDHHTlBcm2MSvbdVSEJJ3I54bQRAEIcUQcRNnontuooelopWBA2T5m/i5PKqqStf1VvW5ARmeKQiCIKQuIm7iTNScG194WKoqRs8NqCopl9eHx6eqnmKploJgyMsYnun16eytdrbCEkEQBEHonIi4iTPhnpvg+AWIPSxlMZsCVVQ1Tk8g3wai98WJRrDXjRJWd725mmP/spDvdla2whpBEARB6HyIuIkzzeXcRIalmsufCSQVuzyBfBu7xYTFHNtL5ogIS32z7QC6Dj+U17TCGkEQBEHofIi4iTPRm/g1JW6azp/JdAQb+QV63MRQKWWQFtHIr+xgfeC2IAiCIHRlYv+2FGJCI/r4BSBQnl3VQik4BJv11Ti9mPy9cGKtlAJwWJWQanB5qWrwUOsXSFI9JQiCIHR1RNzEmaDnxtyy56aZ/JlAl+IGDxaTEjexdCc2CCQUe7yUVdYHtkvfG0EQBKGrI+ImzpjCBmf6o37+aqmA56ah5Z41RsVUrdMTeFyslVIQ3udm18EQcSOeG0EQBKGL06acm+3bt7Njx47A7aVLlzJ9+nSeeOKJuC2ssxKslorBc9NMDk1wBEMw56Y1YanQnJtdBxsC2yXnRhAEQejqtEncXHrppXz88ccA7N69m4kTJ7J06VJ++9vfMnPmzLgusLOhEVotZXhuwsWN1+hZ04xYyYqSUBxrAz8IFzehYSkRN4IgCEJXp03i5rvvvuPYY48F4H//+x8jR45kyZIlvPjiizzzzDPxXF+nI8xz02hwZviQzLRmcm6CCcUe6vyl4Bmt8dwYOTcuL2UhnpsGt0wJFwRBELo2bRI3brcbu90OwMKFCzn33HMBGDZsGGVlZfFbXSfEFLUUXG2L7FHTnCcmNCxlDNBsLowVSWifm13NeG50XaeiRjoXC4IgCF2HNombESNG8Pjjj7N48WJKSko466yzANi1axf5+flxXWBnI6xDcUQpuK2RuImhiV9bPTcBceOjrDLEcxORUDzr/fWMvXchX2/dH/OxBUEQBKEj0yZx87e//Y1//etfnHLKKVxyySWMGjUKgLlz5wbCValKWM5NYPxCeLWUQbPixhHscxOcCN4Gz43LEyZuIj03a3apcQxrZCyDIAiC0EVoUyn4KaecQkVFBVVVVXTr1i2w/Ze//CXp6elxW1xnpLnxC20JS9U6PdQ5Lf5trcm5UefaebABlyeYZ9MQIW6MZGWjPF0QBEEQOjtt8tzU19fjdDoDwmbbtm3Mnj2bDRs20KNHj7gusLPRXCl4ZFiquQ7FmX4hU+P0tMlzY4SltlSEz5Kqj0goNjoWG12TBUEQBKGz0yZxc9555/Hcc88BcPDgQY477jgeeOABzj//fObMmRPXBXY2TM0Ozow9LGVUS9W2sc+NEZYyqqP8Exya8dyIuBEEQRC6Bm0SN8uXL+fEE08E4LXXXqOwsJBt27bx3HPP8Y9//COuC+xshM2WivDcNA5LNdehOFoTv9Z7bgx656YBzYibeglLCYIgCF2DNomburo6srKyAFiwYAE//vGPMZlMHH/88Wzbtq1Vx3rssccYMGAADoeDMWPGsHjx4ib3/eyzz5gwYQL5+fmkpaUxbNgwHnroobaYkDDCc26iN/EzaE6shDbxq3X6q6ValXMTvu/A7plA44Tien/ISzw3giAIQlehTeJm8ODBvPXWW2zfvp358+czadIkAMrLy8nOzo75OK+88grTp0/nrrvuYsWKFZx44olMnjyZ0tLSqPtnZGRw/fXX8+mnn7Ju3Tp+97vf8bvf/a5DjX2InnOjBI8tJCxlMWnYLE0//YGEYpeXGmfbc24MBhZkAOFTwXVdp84tYSlBEASha9EmcfOHP/yBW265hf79+3Pssccybtw4QHlxRo8eHfNxHnzwQa655hquvfZahg8fzuzZsykuLm4yb2f06NFccskljBgxgv79+3P55Zdz5plnNuvtaW9irZZqLpkYgn1uAPZWqyZ7rfHcOCLEzaDuStw4PT58/vEPTo8PXV2VsJQgCILQZWhTKfiFF17ICSecQFlZWaDHDcDpp5/OBRdcENMxXC4Xy5Yt44477gjbPmnSJJYsWRLTMVasWMGSJUu49957m9zH6XTidAY78FZVVQGqy7LbHV9vhdvtxuHPuXF7dcxomACvx4XP7caEHtg33Wpu9vwmXcds0vD6dJz+Um6bSY95zRYtvCqqbzdH4HpNvZM0m5nKWldgW2W9q9XPh7F/vJ/HjozY3PVJNXsh9WxONXuha9jcmrW3SdwAFBUVUVRUxI4dO9A0jd69e7eqgV9FRQVer5fCwsKw7YWFhezevbvZx/bp04e9e/fi8Xi4++67ufbaa5vcd9asWdxzzz2Nti9YsCAhPXnO9XtuPvx4ESN2lVEMrFu7hk375rFxtwYoj4rP3cC8efOaPZZdM1NHMJT1xaeLWG2NbR0NXgh9ebd8+1Xg9jvvzyfTCvsagvtU1bt59715mLTII7VMSUlJ6x/UyRGbuz6pZi+kns2pZi90bpvr6upi3rdN4sbn83HvvffywAMPUFOj+qhkZWXxm9/8hrvuuguTKfZol6aFf5vqut5oWySLFy+mpqaGL7/8kjvuuIPBgwdzySWXRN33zjvvZMaMGYHbVVVVFBcXM2nSpFblB8WC2+VEW6G8M6dPPBPzh0vgwBKGDz2MoeOnUP3NDl7bshaAgtxspkwZ1+zx/rb2U+pCugufO+XMRuGmpvB4fdy+dCGg8nt+dt5k/rxqIW6vzgknn0qv3DS+31MDK5SXTEfj5NMnBRKZY7LX7aakpISJEyditcaoujo5YnPXtznV7IXUsznV7IWuYbMReYmFNombu+66i//85z/89a9/ZcKECei6zueff87dd99NQ0MDf/7zn1s8RkFBAWazuZGXpry8vJE3J5IBAwYAcMQRR7Bnzx7uvvvuJsWN3W4PDPkMxWq1xv8F9gbDPFabA8zq6TWbwGy14rAFz5fpsLR4/kyHBfxTETQNMtPsLQq/wPmtqmmgy+ujMNuBw24jzWrG7fXgwYTVasWlhx+r3gt5bXhOEvJcdnDE5q5PqtkLqWdzqtkLndvm1qy7TQnFzz77LP/+97+57rrrOPLIIxk1ahTTpk3jySef5JlnnonpGDabjTFjxjRykZWUlDB+/PiY16LrelhOTVLxhSTlhiUUN54tlRZD5VNGSFJxhs0Ss7AxcFjVy9sr1+E/pzFvSuUFGQM5DaRLsSAIgtAVaJPnZv/+/QwbNqzR9mHDhrF/f+zTpWfMmMEVV1zB2LFjGTduHE888QSlpaVMnToVUCGlnTt3Broh//Of/6Rv376Bc3/22Wfcf//93HDDDW0xI/74QnrIRGniF9rnJj2G8FJoxVRruhMbpNnMVDV46JmjGvgFuxar9dRHTAgXcSMIgiB0BdokbkaNGsWjjz7aqBvxo48+ypFHHhnzcS6++GL27dvHzJkzKSsrY+TIkcybN49+/foBUFZWFtbzxufzceedd7JlyxYsFguDBg3ir3/9K7/61a/aYkb8iRQ3jcYvhIibGMRKqLgJ9eLEitHrppe/O7Fx22jkVxcpbmR4piAIgtAFaJO4ue+++zj77LNZuHAh48aNQ9M0lixZwvbt21usAIpk2rRpTJs2Lep9kSGuG264oeN4aaIRFpZqPDgzPCzVsrjJOETPjSMgbhxht415U+K5EQRBELoibcq5Ofnkk9m4cSMXXHABBw8eZP/+/fz4xz9mzZo1PP300/FeY+fBL250zawygJvx3MTiicmMyLlpLQWZKpF6gL87sZGDE/TcROTcSJdiQRAEoQvQ5j43vXr1alQVtWrVKp599lmeeuqpQ15Yp0QPGZoJYJTER8m5iRyPEI3QjsTprehObHDPeSNYtvUAEwYVhJ2zwUgodkd6biQsJQiCIHR+2ixuhCgYYSlD3DRTLRVbzk2w7K0tnptB3TMZ5B+YCcFQWIPHL26ckTk34rkRBEEQOj9tCksJTRAQN+bwy2jVUjGJm+A+seTotISRcxMsBVeXRldiybkRBEEQugIibuKJL2QiODSbc9P6PjdxFDdGKbhbibHuWSo3Rzw3giAIQlegVbGOH//4x83ef/DgwUNZS+cnMizVTLVULGIlrFqqDaXgkTRVCl6U7WBPlVNybgRBEIQuQau+MXNyclq8/8orrzykBXVqDHFjeGw0v6cmquemZXGTFWfPjSFunP5S8IC4yXGwakcllRKWEgRBELoArRI3KV3mHQNao4Tipqul0lsZlopl/5YIlIK7wjsUF2WrPjihYakfyqt5Y/lOfnXSIHLSO+ccEkEQBCE1kZybeOKLLAU3wlJqUnhrq6XCcm7aUAoeSWTOjdHnpjDHL25CPDcPf/gDjy3axOvLdxzyeQVBEAShPRFxE0/05hOKLa0MS2XG2XMTKAWPknMDUO304PMpIbalogaA7QfqDvm8giAIgtCeiLiJJy0kFNtaWwruiK/nJjKh2Lg0xI2uQ43fm7PjQD0AZQcbDvm8giAIgtCeSBO/eBIZlorw3NgsJrLsFlxeH7lpthYPFzo5PM0aj5yb6J6b3HQbNosJl8dHVb0bDThYp0JUZVUibgRBEITOhYibeNJCEz+zSeP5a4/D7fXFFJYymTQybGZqXd6EeG7qnGq96TYz2Q4rFTWqHDy0JLzsYH3YMXRdZ1+tKzC3ShAEQRA6GhKWiifG4MzIailfcMzBUcW5HNM/L+ZDjuydQ6bdQr+8jENeXuhUcF3XA7Ol0m1mctLUmqsa3GF5NntrnLg8vsDt/3y2hbH3LuTdb3cd8noEQRAEIRGI5yaeNFkt5Yu+fww8f81x1Lu95KQdejl2aCm40+MzirhIs5nJ9h+/qt7N9v1BcaPrUF7dQJ9u6QB8sWkfACtLD3Lm8O6HvCZBEARBiDfiuYknkWGpiJybtmCzmOIibCC8WsrItwFViZXt8IubBk8gmdigrDKYd7N1Xy0AFTXOuKxJEARBEOKNiJt4EtmhOCLnJtmE5twYPW7sFhNmkxbmudkRUf69y5934/XpbN+vrlfUuNpr2YIgCILQKkTcxJNGHYoP3XMTT9JCqqWM7sRGSXq2IyTnxi9g8jNURdduv+dmd1UDLq8KsYnnRhAEQeioiLiJJ03m3HQMcWP3ixufDgf93YiN5oCG56ayPphQbCQ+G2GpbRW1gWPtrRZxIwiCIHRMRNzEk0Y5N/5xC762JxTHk7SQvjn7a1VYKS3guVHiZtu+ukA+ztj+3YBgWGrrvmC4an+dC4+3Y9glCIIgCKGIuIkjjQdndizPjdWsYTYpwWWIm0BYyl8KvmZXJQCF2Xb65avy893+Rn7b9gU9N7oOB+pkirggCILQ8RBxE0+Mku84loLHE03TcFjUS77PnzNjeHMMz82eKrW9uFs6Pf0DNXf5RzBsDRE3IEnFgiAIQsdExE08SUApeLwxwlD7GnluwsvNi/PS6ZWbBqjkYafHy7Z94VVUFbWSdyMIgiB0PETcxJMWBmd2BIwuxQcMceOfPJ7tCO/n2KdbGt3Srdj9np49lc6A56a3X/TsE8+NIAiC0AERcRNPDA+N1jFLwSEYhgp4bqxNeG66paNpWiA0tXLHQRrcPswmjaP65gJqNIMgCIIgdDRE3MSTRoMz/U9vB8m5gaDnJjKhOLILcp885Z3pmaMujbELvXPT6JmtBI94bgRBEISOiIibeNJocGbH9dwcCJSCq7VmRYSliv2zpHrmKiHz1WYlbvrlp1OQpSaCS0KxIAiC0BERcRNPOngTPwBHEwnFdos5MFjTbAqGo4zLzf4Gfv3zMyjIFHEjCIIgdFxE3MQT3QhL+Z/WDum5UWtzelSozBA3ECwH75njwGI2+a+nhT2+X3463f2em32ScyMIgiB0QETcxJNOVC1lkBYqbvx5N0ZICqCXPyxloDw3auZURa14bgRBEISOh6XlXYSYaXJwZsdJKE6LEDfhnhu17uK8oLemKLux58ZIPt5f68KnJ2qlgiAIgtA2RNzEk8hS8EC1VAf23FiDb4GWPDeappr7WUwamqYGcNbIBAZBEAShgyFhqXgSSCg2OhSbwrd3ACLFTYY9ePukId3JsJk58bDugW05adaAt6dntgOH1YzFbKJbugpNVYu4EQRBEDoY4rmJIx19cCY0H5b6vxMGcNX4/oHhmqDmUfXMdbB5b21gkCZAQaaN/bUuqt0agiAIgtCREM9NPGmyFLwD5dzYwl/y0LAUECZsDIxy8P4FwXCVUQ4unhtBEAShoyHiJp7onWBwZjOem6YY1D0TgKGFWYFtRjm4iBtBEAShoyFhqXjSZCl4x/Hc2Nsgbm46fQhH9snl7CN6BrYFPDcuCUsJgiAIHQsRN/EkMizVAROKIz03aTGIm/xMOxeO6RO2TcJSgiAIQkdFwlLxpNHgzM6QUNw2fWs08hNxIwiCIHQ0RNzEk04wODO0FNxmMUVNII6FgkDOjYSlBEEQhI6FiJt40gkGZ4ZWS2XEEJJqiu4SlhIEQRA6KCJu4okRltIiBmfqPtA7xpyCUM9NW0NSEMy5qXGD16ej6zpbKmrxyTwGQRAEIcmIuIknTVVLQYepmArNuYklmbgp8v05Nz40Dta5mPX+ek69fxEvLi095DUKgiAIwqEg4iaeNOpQHPL0dpC8m3DPTdvFjdVsolu6mkX1/po9PPHpZgA27qk+tAUKgiAIwiEi4iaeGN6ZqJ6bjiFuwjw31raLG4D8DOW9+cv7GwLbaho8h3RMQRAEQThURNzEk8hS8A7ouQkNRR2K5waC5eBubzDPptop4kYQBEFILiJu4kiTgzOhw3hu7JbgS34oCcWgmvsZ/NTf5E88N4IgCEKyEXETT5oqBYcOk1CsaRoOq3rZDyWhGOCwHmrm1MVj+zDFP5qhpp08N16pyhIEQRCaQMRNPGkUlgoRD76OIW4gmGtzqGGpayb044bDPdxzznAyHUrQ1baDuCndV8dRMxfwl3nrEn4uQRAEofMh4iaeNCoFD3l6O0hYCkLFzaGFpexWM4NzwGzSyPAfqz1ybr7YXEF1g4cFa3Yn/FyCIAhC5yPp4uaxxx5jwIABOBwOxowZw+LFi5vc94033mDixIl0796d7Oxsxo0bx/z589txtS0QGZaCDj2C4VA9N6Fk+T037ZFzs21fHQA7D9ZLeEpoO84a9ScIQpcjqeLmlVdeYfr06dx1112sWLGCE088kcmTJ1NaGr0R3KeffsrEiROZN28ey5Yt49RTT+Wcc85hxYoV7bzyJgh0KA4RDR1wBEMixE2mXYmbercXjzexIbht+5W4cXt19lQ1JPRcQhfF64HHjoc54zrUDw9BEOLDocUlDpEHH3yQa665hmuvvRaA2bNnM3/+fObMmcOsWbMa7T979uyw23/5y194++23eeeddxg9enTUczidTpxOZ+B2VVUVAG63G7c7voORzD4PGuD2ge4/tkUzq20uJ8T5fG3FSCi2mTmk58B4rNvtxhaSPH2wtoGcNOuhLbIZSvfVBq5v2VtF94z2exuH2pwqdEmb6/ZjrdwOgLuuEuxZgbu6pL0tkGo2p5q90DVsbs3akyZuXC4Xy5Yt44477gjbPmnSJJYsWRLTMXw+H9XV1eTl5TW5z6xZs7jnnnsabV+wYAHp6emtW3QLnNlQhwP44qulVH9bBsDZPh0LsOjjD6mzF8b1fG3FWW0CTGxZ/x3z9q4+5OOVlJQAYNXMuHWNdz4oIc/ewoMOgU27zYCaRj5v0VdU9Gj/0JRhcyrRlWx2uPZxpv/6hx+8i9Oa02ifrmRvrKSazalmL3Rum+vq6mLeN2nipqKiAq/XS2Fh+Bd+YWEhu3fHlij6wAMPUFtby0UXXdTkPnfeeSczZswI3K6qqqK4uJhJkyaRnZ3dtsU3gWWdGTwwbsIJWIpGAGBeawNnA6ecdCLkD47r+drKoKOr+WjDXn4+vl/YOIbW4na7KSkpYeLEiVitVmZ+u4h9tS6OGXciQ4uyWj5AG6isd1P3xceB23l9hzDltPZ7XiNtTgW6pM37voc16urpp5wAOcWBu7qkvS2Qajanmr3QNWw2Ii+xkNSwFKi+K6Hout5oWzReeukl7r77bt5++2169OjR5H52ux27vbEbwWq1xv0F1nWVc2OxOYLH9odrrGYTdJA31MjiPEYWN+3tai3Gc5npsLCv1kWDl4T95ynbE67cd1Y6k/IfNRHvn45Ol7JZD7q3rXij/t/sUvbGSKrZnGr2Que2uTXrTpq4KSgowGw2N/LSlJeXN/LmRPLKK69wzTXX8Oqrr3LGGWckcpmtwxcxWwo6ZLVUojCSihPZyK90f7i42bG/PmHnErow7pD3jUeS0gWhq5G0aimbzcaYMWMaxf9KSkoYP358k4976aWXuPrqq3nxxRc5++yzE73M1hHZ5wY6ZLVUomgPcbNtv0omHlCQAcD2A7HHYAUhQKi4cYu4EYSuRlLDUjNmzOCKK65g7NixjBs3jieeeILS0lKmTp0KqHyZnTt38txzzwFK2Fx55ZU8/PDDHH/88QGvT1paGjk5jRMC251opeDG8MwU8Ny0R6+bUn+PmwmD89lSUcvuqgacHi92S/zK2oUUQDw3gtClSWqfm4svvpjZs2czc+ZMjjrqKD799FPmzZtHv379ACgrKwvrefOvf/0Lj8fDr3/9a3r27Bn4u+mmm5JlQhBdR9ObaeInnpu4YISlRhd3I81qRtdh10H5chJaiTvE4+dxNr2fIAidkqQnFE+bNo1p06ZFve+ZZ54Ju71o0aLEL6ithHpmwsJShuem48yWShTGfKnqBHpujO7E/QvS6dMtje/La9i+vy4QphKEmAjz3EjeliB0NZI+fqHL4Av5Qg+dBh7w3KSAuLGrTPZEeW5cHh9lleqLqDgvneI81adI8m6EVhMmbtrXc7PzYD0L1uxG12V0iCAkChE38SJM3KRqQrGyNVE5NzsP1uPT1eDP7pl2irulAbBdKqaE1uJJXs7NnW+s5pfPL2PZtgPtel5BSCVE3MSLpsRNKpaCuxIjbox8m7556WiaJp4boe0kMaF4T6U6354qyfURhEQh4iZehOXcdOzBmYki0+EPSyXIc2PMlOqbr0RNn27qcsf+2MWNruu8vmwHS7fsj/8Chc5DaEJxO5eC17nV/4+6BP0IEARBxE388HtudLRg+TekpucmQTk3RjJxX7/HpjjPH5Y6EHtY6vMf9vGbV1dx08sdZJK8kByS6Lmpd6n8uwZ31/9MEIRkIeImXpjM+PqOY1/mYRHb/U9xCiQUJ7rPjRGW6pdviBt1ub/WFbOgevlr1VqgrLJBvlxSmSSWgte7DM+NvP8EIVGIuIkXGQV4r3iHz4fcFb69o3tuvG7Ytykuh0q05yY05wYg22ElJ02FwrbHEJo6UOtiwZo9gdt7qqQ/TsoSGopqx1JwXdep94vqehHXgpAwRNwkmo6ec/PBnfDI0bB50SEfKsNu9Llxt7Bn69F1vZG4gZDQVAzi5s0VO3F5gx60skoRNylLkkrBXV4fPn8FeL14bgQhYYi4STQd3XOz73t1Wb7ukA8VCEs5PXHv4VFR46LO5UXTgonEAMXdjIop9WWl63rUc+u6zitfbwfAGDq/W8RN6hIWlmq/90GooBHPjSAkDhE3iaaje26MX7D1h95zwwhL+XRocMc3x8jw2vTKScNmCb5tjbybldsP8pd56zhqZgl/nLum0eNX7ahkw55q7BYTpw9TU+fFc5PCJMlzEypoJOdGEBKHiJtE09EHZxq/YOsPHvKh0m3mgFek2hnf0NQOfy+bPv7GfQZGI793Vu3iiU83U1nvZuHaPY0e/4o/kXjKET0ZWpQJEOh2LKQgYaXg7fc+qBPPjSC0CyJuEo3WwauljMTKOHhuNE0LJhXHuWLKSP7tmeMI2z6kMCtw/cg+ajJ8ebUTny8YmqpzeXhnVRkAFx9TTFGOEkTiuUlhQkNR7em5CRU34rkRhISR9MGZXR5TB8+5MX61NhyMy+Gy7BaqGzxxr5jaXam+gAojxM1xA/J45JLR9OmWxsjeORz2u/fx+HQO1LnIz7QD8N3OKmqcHoqyHRw3IC8gvCTnJoVJUp+b0PYDIm4EIXGIuEk0HX1wZhzDUuCfDF6ZAM9NtfoCKswKFzeapnHOqF6B2/kZNipqXOypcgbEjRF+6pevxjb0zHX4t4u4SVmSlFAcGpaqk7CUICQMCUslmhRKKIaQcvA4e27K/WGpwmxHs/v18IsfQwxB45BWT39YqqLGicvTQUWnkFiS5LkJzbNpEM+NICQMETeJpiOXgut6sIFZnMJSicq52e0XKEU59mb3K8xW95eHNOgzPDRGrk23dGug4iq0kd+r32zn4w3l8Vu00DHR9aRVS4WGpYwZU4IgxB8RN4kmMH6hA4qb0F+s9QfUh/4hYvS6qfW3mK+sdzN74cYwsdFadF0PTFDukRWj5yZk4rKRW2N4bjRNC1w3hM+2fbXc+tq33PDiirBkZKEL4nECIa9xksJSxowpQRDij4ibRBPw3HTAD7LQX68+D7hqD/mQmYEuxUrcPPP5VmYv/J4/vdf2JoGV9e5A+KhHdoyem+ponpugMCrKNsSNeg5W7agEVAPC8ur2nTUkJIDPHoJVr0S/zx3Rzbodp4KHJhHLbDNBSBwibhJNR865ifyQj0sjPzXryaiW2rinGoBF68vbnN9ihKTyMmzYLeZm9+2R3bTnpigkX8fw3Bj3rdlZGbivNIZRDkIHpuJ7WHg3vPeb6PdH9rVJUs5NnSv+nbwFQVCIuEk0HTnnJvJDPg55N5kRk8E3VyhvULXTw9db97fpmMGQVPNeGwgmHBthMI/Xx94a9fjQHjk9c8N73Xy3KyhuYplTJXRg9q5Xl67q6P/vGomb5PS58emEzToTBCF+iLhJNB3acxPxIR+HcvBMu7K3xunB59PZWhEMdS1c17hzcCzsibFSCoICyBBEFTUuvD4di0kLlIZDuOdG13W+21kVuE88N52ciu+D1yO9kxBMojcabHrq45JvFguRXYml140gJAYRN4mmM3lu4hiWqm7wsKe6IezD/MN15W1yw++JElZqCkMA7a1RXYqNnJrCbAdmkxbYLzTnZseBeirrg+MixHPTyQkVN64or6Xxvk/rFtzmdSV2TX4i50nJCAZBSAwibhJNR66WivxVG8+wlNPNlr3Ka9Mzx4HNbKJ0fx0/lNe0+piBBn4tJBMDFGTa0DTw+nT21bqC+TYRnY17hoxg+C4k3wZg+wERN52aio3B664o7zfjfe/IDW5rp7ybyCRiGZ4pCIlBxE2iCQzO7ICx9QR4brL81VK1Ti+b/CGpw3tmM25QPgAL17W+j0wg5yYGz43FbCI/wwhNNUStlAq9vbfGycrtBwEY3jMbkLBUp0bXWw5LGe97Rw7g9+a1U95NnSu8t42EpQQhMYi4STRaEnNuaitg62dN5xM0qpY6eMinDHpuPAHPzcDuGZwxvAcAH7Yh78bIuYklLAXh5eBNPTY/w4bVrKHr8NF6JbjOPqLIfz6nlOl2VmrKwRniiYsalvJvs2WAxf++aKfJ4PVuX8RteZ8JQiIQcZNokjk48+1fwzNnw46vo98f6YqPR1gqpM/NlgoVEhhQkMlpwwsBWF56gP21rctvaE1Cceh+5VXOgOcmcpq4yaQFvDff+0NlEwYXBDxPOyQ01TnZ9334bXeU3k1GXxtrGlj8oc528txEjlwQz40gJAYRN4kmmYMz929Wl/t+iH5/QhKKQ3Ju/GGpAQUZ9M5NY3jPbHw6fLw+9tCU16ez199UL5acm9D99lQ5m8y5AeiZnRa4bjZpDO+ZTZ+8dAC272+fX/JCnAnNt4HmPTfWtKDnpp1ybiJHLkjOjSAkBhE3iSaZpeCGWKnbF/1+40PeEGBxKQVX4qbB7QvkrgzsngHAxMOV9+bJxZtxemJ7PipqnPh0JT5CS7mbo3vI8MyyKiVSIj03EC54hvTIxGE10zdPCR7Ju+mkVER4bqJ13TZEvSUNrO0rbgxPjdWscn0k/CkIiUHETaIJJBS384eYrgfFTW1F9H2MD/kslWsSD8+NMRUcVJOyDJs50HvmynH9yMuwsX53Nf/48PumDhGGEZLqnmkPK+VujoDnprKBPZXK62MMzQwlVPCM6JUDQF+/50bETScl0nMTNSyl3vdbq3SqPX5h387iJi/DBojnRhAShYibRGNKUljKVavmRUEznhu/uMnupS7jkHNjs5iwW4JvqwHdM9A0JUoKMu38+fyRAMxZtClQpdQcRqVUrCEpgEK/52b97mpcXh+aFr27cajnZmRvVSkl4qaTY3husvuoy2bCUh9uqmZbpf//ZTvl3BgJxHn+ij5JKBaExCDiJtEkq4lfqBemromxBwHPTU//Yw7G5dTGZHBQycShTD6iJ+eO6oVPh9/8b2WLbvndrUwmDt1350FlX0GmHau58Vu9Z4g3Z2Rv5bkJ5tyIuOl0uOvhYKm63uso/7ZoHYrVe6pOt9GANWxbojHETL7fcyNhKUFIDCJuEk2ycm5CvTAt5dwEPDeVcenHk2kPFTcZje6fed4IumfZ2bS3lr++v77ZY5W3QdxETg6Plm8Tul3Tgj1u+oaIGxlq2MnYtwnQVXO+3L5qW9ScG/W+r9dtNOh+cdMOk8F9Pp0Gfyl4t0BYytPcQwRBaCMibhJNh/DctJRz4/fcoIf3CGkjmSGem4FRxE1uuo2//eQIAJ5ZspX3V5c1eaxgGXjsYan8DBuh6TlN9ccZWpTF4T2zuWB074Ag652bhqZBrcvb6pJ1IckY+TYFh4FVidTmmvg5seFEiYz28Nw0hCTRG56belcHbO4pCF0AETeJJlnjF8LETQs5N46c4JdBPJKKbSHipntjcQNw2rBCfnXSQABue+3bsAGboewO5NzE7rmxmE0URBmSGYnDambeTSfy4EVHhW0zxJDk3XQyjJYHBYepBn3QbLVUPXac7RiWCk0e7pbuFzdu8dwIQiIQcZNoAp6bdv6FFpo/U38QvFE+RI3pyNb04BDBOOTdhObc9I/iuTG45cyhHNO/G9VOD9e9sDxq/kFbwlKR+0erlGqOYiM0dUB63XQqAp6bIS2Im5CwVDt6boxKKbvFRIbdHLZNEIT4IuIm0SQr5ybMA6NH98gYnhtrWnCIYBwb+RVk2sl2WJvcz2o28eilR1OQaWNdWRUPlWxstE9ruxMbhFZHFeXEHtICKO4mScWdklBx02xYSr2n6rHj1NvPc2OI93SbmTSb+lyQUnBBSAwibhJNsvrcRJZ1RwtNhXZqNTw3cZwMHi3fJpLCbAf3+svDX1++A4836OFqcHs5UOcGYp8rZRA6ZLMou3Wem0A5+D4RN50GXYeK0LCUX9w0UwregC0kLJX4UnBDyKRZzaT7xY2UggtCYhBxk2iSNTgz0gMTVdyEeG7Scv2PO3jIp85JU18YTeXbRHL68EJy061U1LhYuiVYtm6MXbBbTGSnWZp6eFRCE5Cbyrlpir750qW401G1SzXsM1mgW3+w+t97zTTxa6Cdw1J+IeOwmUmzSlhKEBKJiJtEk6zBmW0WN4celvrJ0X04Z1Qvrp7QP6b9rWYTZ41QXZLf+TZYORUakjIaAcZKeM5NK8VNIOdGxE2n4cBWdZnbF8zW2BKK9RDPTTuUghtCRoWllFgXz40gJAYRN4nGCEu1d4fiSA9MtHJwd0hCsZFzE4ew1MDumTxyyWiGFWXH/JgfHal67XzwXVkgNLV+dzXQujJwAyPnplu6FYf/V3Ks9M1TX4y7DtbLL+vOwsFt6tLobxNDWKq9c24MIZNmFc+NICQaETeJJlnjFwwPjNHDph09N23h+IF55GfYOFDnZsmmfVQ3uAPzp04bVtjq4x3RO4d0m5njB+a3+rEFmTYKMu34dFi/u6rVjxeSgNGZ2BA3zYWlPEZCcfvm3BhCJs1mCYob8dwIQkIQcZNoktbE76C6zBukLiNHMOh6MKHYkhbXUvC2YDGbOGukCk29920Zj3z0A+XVTvrnp/N/J/Rv9fF6ZDv4+q4z+OelR7f6sZqmMaKX8jqt2SXiplMQEDf91GVTnpuQ932Dbg9p4pf4sv+6gOfGJNVSgpBgRNwkmmSPX8g3xE2E58bjBPzjBUJLwRsOvUNxWzn7SOVlem91GU99tgWAP547AruldWElgwy7BVOMk8QjMQZprtmVvOdDaAUHjLCUX9wYnhuvM7zHk9cV8KK2d7VUQ0i1VJpUSwlCQhFxk2iS4bnxesDp9zgUDFGXtRE5N6H9P0JLwZMUlgI4bkA+BZl2apwePD6dM4YXcurQHklZy8heapDmdzvFc9MpiAxL2UIq9UJDUyHv+3psOHXlufG1Q0JxXUhYKt0flnJ5fHh9MsNMEOKNiJtEkwzPTaj3JU+NOGjsufF/mJusqrokjqXgbcVs0phyhApN2Swm/vCjw5O2lhF+cbNhdzVur8z/6dB4PVC1U103xI3FHkzmDw1N+fPM3LoZk9lGg6Y8Nx5X4sNSYQnFNnOj7YIgxA8RN4kmGU38DO+LPRsy/cm4kTk3oZVS0CE8NwA/nzCAoYVZ3H3OCPrmpydtHcV5aWQ5LLi8Pr7fU5O0dQgxULVD/Xgw24Pvd00LSSpuLG7qsZGbbsViUz2NfO0gbkI7FNstJozuBlIxJQjxR8RNommPaqmyb2HZsypZEoICxZEL6f5qochS8EB3YkdwX1AufK87cWttgQEFGcy/+SQuPa5v0tYAkUnFknfT7tQfgDkT4JP7Wt43EJIqDg6qhZCk4tCwlNHAz05uuhWbXYkbvV3CUir3J81mRtM0KQcXhAQi4ibRxDPn5sA22L608fa3p8E7N8L2r9RtI5k4LTcobtx1Ud3zWP2jCRw5wfuSGJrqSBh5N1IxlQS2L4U938Gql1reNzLfxiDafClD3OhWctNtWB3Ku6O3S58b9QPH6LskIxgEIXGIuEk08cq58fng+fPhqTNh36bgdl2HCtUPhr3r1aXhuUnrBvYslVcDUB8SmooMS5nMQYGT5NBUR2FkbyOpWDw37Y6RIxaL0I6slDKwZapLV0hYMaSBX26aFbtDvf+1dpkKrjw3hqgxRI7h0REEIX4kXdw89thjDBgwAIfDwZgxY1i8eHGT+5aVlXHppZcydOhQTCYT06dPb7+FtpVYc258PjUfp2wVfL8Qdn8Xfv+u5bB/swpv7VkT3F67N5gcvF+VTwe+ENJyVe5BIDQVklQc6bmBuHYp7goYYam1ZVX4pKKlfTHeqw0H1f+N5mjKcxOt101Ezk1amtrH5G2HJn4hCcUgnhtBSCRJFTevvPIK06dP56677mLFihWceOKJTJ48mdLS0qj7O51Ounfvzl133cWoUaPaebVtJNbBmf+9AB4cDv86CV74CTxxSnDKMcC6ucHrxhwdCH6wAxwwxE2I5wYgo0BdhpaDB3JuQpJ2O0hScUdhYPdMHFYTdS4vW/ZF6XQrJA5D3Og+cFU3v29rwlKe0JwbG450FZYy+VyHuuIWCXYoVp8JknMjCImjdaOW48yDDz7INddcw7XXXgvA7NmzmT9/PnPmzGHWrFmN9u/fvz8PP/wwAE899VRM53A6nTidwV9lVVUqf8LtduN2xzdx1jhe6HE1n44F0L1ePE2dz1mNdfMiAPSMHuBzo9UfwLv0SXwT7wVdx7J2LkY7Ou/+Lfj8x9L2bQ68iPq+zXjcbky1+zADXls2Prcbc1o3TICnuhzdeFxDDRbAZ7bj9W8zO3LUfjUVgf1aa29XY1hRFiu3V/Jt6X765tpTwuZIkmGzuWZv4JeXu7oCzE1XzlkObEUDPFm9w963ZksaJsBbXxX8/+J/3zfoNrJsJkxe5bm0+py4XS7QtITZW+dU4SerScftduOwKgtr6l1Jfz+l2vs61eyFrmFza9aeNHHjcrlYtmwZd9xxR9j2SZMmsWTJkridZ9asWdxzzz2Nti9YsID09MSUGpeUlASud6/6jvFAVVUli+bNi7p/dt02TgWcliw+OOx+elSuYtzmB/Aue44FzjGkO8s5zfDKABUbv+FLnzrW4D0ljPBv9+z9gXnvvcfo0u/oC6zftocf5s1j7EEnvYF133zG5lJlc/+9XzMK2L2vkq/96xpd6aMvsPmreazbntkme7samS4TYOKdz1dh2rEisL0r29wU7WnzsVvW4Z+KxucL36UyvX/U/TSfh3Oq1ST5hd98j3NVeeC+o/cepBhY9+1yNu1RJeLG+74eGzs2b0ALGbvwwXtv4zPZArfjbW9FpRnQWPnNUqo3QvUB9d76ctkK2N4xwp6p9r5ONXuhc9tcVxdlEG4TJE3cVFRU4PV6KSwMH4pYWFjI7t2743aeO++8kxkzZgRuV1VVUVxczKRJk8jOjn1qdSy43W5KSkqYOHEiVqtK4tW2ZsEmyM5MZ8qUKVEfp61/BzaAtXCo2sd3Jvpjr2KrLOWs4nq0ykpYD3p6PlrdPnpYawPHMr3/EexSx7H66ply6vGY33kB9sPQo47nsNFTMH3wCSxbyuH9Cxl2iv9xX26BHVBUPCBwLG11DcxdzBC2MaCJtbZkb1ej5psdfPb2WhocBUyZMjYlbI4kGTabn3sM/HncJ4wZiT7gpOg7HtiCtkpHtzg4/dyfEWgeA5jmfQgHljB8UDFDTwp/39djZ8Ixo3E5nfCB2v+sM04FR07C7P3zd59Ag5PTTjqBEb2yeb9qFWsP7uGw4SOYkuTWB6n2vk41e6Fr2GxEXmIhqWEpUP1EQtF1vdG2Q8Fut2O32xttt1qtCXuBw45tVefWdF/T56tU1R6mvIGYrFbACmN/Dh/eg2X5M4G5N9qxv4RFs9Aqt2M1m1VPj6od4eeu3hEYvWDJzAerFTK7A2B2HsBsrMGfY2CyZfjPCRw2SZ1nz2qsDfshK7Zp3Il8LpPNqL55AKwpq8aLKWBnV7Z5894a/vXJZq47ZRD9C4JjDNrV5pDKPou7Wr2Po1GtOhNruX2x2mzh9zmyADB7Gxq97xt0G/2z0qi3W/HqGmZNx4o37DzxttdIHM5Kt2O1Wsmwq2M7vXSY91JXfl9HI9Xshc5tc2vWnbSE4oKCAsxmcyMvTXl5eSNvTqcmllLw/ZvVpTEqAWD0FWC2qSqp8jUqMXnsNerS6wK/Kz6QTGmUe+/f0jihOGq1lJFQHFItldkdeh6lrm/6KGYTuzKHFWbRI8tOZb2bhz/8PtnLSTguj49pLyznlW+2c9tr36LrSQqXhL5Xm6vei5wGHkozfW7qsZOTbiU3w9Zuk8FDOxQDpNnUx68kFAtC/EmauLHZbIwZM6ZR/K+kpITx48cnaVUJIJYmfkYJd96A4LbM7nD4ecHbA05U23KL1e2D21SPG+PDvfhYdXlgS3iHYoAMQ9xE63MTIm4ABp+hLn9Y2KxZqYLNYuJP548E4F+fbOLbHV27582/PtnE+t2qOmnp1v18uK68hUckAJ8vvGKvuV43TVVKQdRScN0vdBpQTfxy0tpnMrjb68PtVUIxWAquHOdSCi4I8SeppeAzZszg3//+N0899RTr1q3j5ptvprS0lKlTpwIqX+bKK68Me8zKlStZuXIlNTU17N27l5UrV7J27dpkLD82jHbwxvgFr6ex0AmIm4Hh24+5Nnh9+Lnqslt/dXlga0iPGw36nxA8VqBDcYTnJmopeBPiZtNH7TsPqwNz5ogizh3VC58Od7z5HZ4uMEezss7NAws28KNHFvPiV6X4fDo/lFfzyEeq/cCo4lwA/vbBejxtGByq6zrf7jjI059vYfv+2JIA99e6eH91Gbv37g4fVxIqdDwueOkS+OjPfnFvNPCLIm4Cs6WCZfxep7+Jn26nW7qV3HRrQNx4EzhfKlTAGM37HFIKLggJI6k5NxdffDH79u1j5syZlJWVMXLkSObNm0e/fsrFXFZW1qjnzejRowPXly1bxosvvki/fv3YunVrey49dkI9Nz4vPHmK+oU49TM1udjdEJxoHCluio+DgadA+bqgF8dwvx/YFvzVmt0LCg5T18vXqLAVtBCW8jf+s0ZUjPU5Buw5Kudh10roM6aNhnct7j53BEs2VfB9eS1vm0ycXO+moBPGrffXunjui638Z/EWqv2lyb99czWvLduOx6fj8vo4dWh3Zv9sNCf//WO+L6/hzZVlZLRwXIOqBjf//OgH3v22jJ0HlVj4/Id9/PuqsVH393h9vPT1dt5dtYuvt+7Hp8Mp+ZU8E7pTaFhq5zLYME/9ObJb8Nz4Vx0yW8rVUIsFcJscpFnNWM0mduo20KC2tpb4lhiEmOAXMCYN7Bb1g0ea+AlC4kh6QvG0adOYNm1a1PueeeaZRtuSlgPQVkJzbsrXwu7V6nbZt1B8jP+Xpw62rKAIMdA0uPyN8OOEem5Cf7UaIS2je7HJEvxwDxU3uq6O25TnxmyBgSerpoE/LBRx4ycvw8afzhvJdS8s59PdJo6d9TFH9+3G+MEFjOqTwxF9cijIULk5++tcNLi9WEwmzCaNdJuZgkw7NosJp8fLytKDfLF5H5X1bo4qzuWY/nn0yk2jwe3lQJ2LmgYPLq8Pr0/HpGn0yLZTkGHHZNLweH0cqHNzoM7FvhoX+2td6OicOLg7OelKbDW4vbyxfCdfb91Pn25pDCnMwm4x8daKnSxctycQHhlWlMVpw3rw7JKtLC89CECGzcyfLziCnDQr1586mHvfW8fDH/3AGd01PntrDdv21zN5ZBFXHN8Piznc8VtZ5+aKp74KhO5sZhMur49l2/ZHLRTw+XRue+1b3lixM7DNbNKo2r8HQmsAQsNSNXuC1xf8Xv1AAOgWJecmSljK0+AXOtY0NE3DatZwayrnprauJmHips5o4Gc1B54HaeInCIkj6eKmyxPquSn9Mrh9x9dK3ASSiQeElbEGMESNgfEhfmBr+K/Wbn5x4/PPqUnrFjyeIW50LzRUqrEMRs6NJULcgApNrZsLP5TAKbfHammXZ/IRPfndlKH8++P17K7X+GbbAb7ZFgyZaFpwMHs0uqVbqXd7aXA3DvPYLSaczcS7LH6RVNUQfQ6R1axx8mHdGdg9k1e/2c6BuqabXR3RO4epJw9i8sgiTCaNK8f1Z+a7ayhZu4d7zhtJr1z1nrj8+H48/flWdh6s54UqM6BEyNIt+3n1mx3ce8FIju6rvIMHal1c/p+vWLOrirwMG/eeP5IThhQw9k8LOVDnpnR/Hf3yg/4fXde5663veGPFTswmjVsmDeWcUT159ZsdrPn4m/AFh3puaveqS82s3s/G6JGoCcVRwlJ+oWOyBT2WXpMNdKirS1wX6sDoBVvwIzdNPDeCkDBE3CSaUM+NMbUblLiB6JVSzWF4bg5uCxc36Xlq8GWDP+HVSCYG9evWlqXa2NftCxc3kZ4bgMGnq8udy1QScnpebGtLAa4a14/uB9Zw1PhT+XzzQZZtO8DqnQf5vrwmIGyy7BYcNjM+n47Hp1Pr9ODx6QHBUZBpY9ygAvIzbCwvPcCaXVUBYWMxaWQ6LFjNpoDnY1+NE49PDwgbTYPcNCt5GTbyMmxU1rvZuKeGhevKwZ8A3KdbGucf1ZuKGicb91RzoM7NqUN78NOxfRjeM9w/UZTj4LHLxuDx+sK8MQ6rmZnnjeCWV1eRY3Ix8agB5GU6ePyTTawtq+LHjy2hT7c0+udnsOtgPZsrainItPHCtccztEiVYR/eK5uV2w+ycvvBgLjRdZ2Z767lpaWlaBo8dPFRnDuqFwA/n9Cf+xcrkeHTzJh0b3jOTY0/wXn0ZbBvM2z7TIVWI72eENVz4/NftziC4sZjtoMH6hMobgKeG1vw+U2TwZmCkDBE3CSawOBMX2PPDUSvlGoOw0NTXQZ7N6rrRr5BtwFQtlJdN/JtDNLzguImf1Cw7DUy5wYgpw90Hw5718Hmj2HkT2JbWwrRKzeNS4/L5lJ/87Vap4dal4fcNBs2S3i4xufTqax3U17txGLWGFiQERaiqXV62F/rIifdSpbd0ih84/H6qKhxUeN00y3dRm66DbMpfJ+Ne6qZu3IXW/fVcvYRPZl4eGGjsFFLRNv/9OGFLL3zVObNm8eUMw/DarVy0dg+/PX99by6bAc7DtSz44B6L3XPsvPSL45jcI+swOOPKs5l5faDrNpeyXlH9QZg0Ya9PP35VgD+9pMjA8IGIDfdxun9LLAdykyF9PbuCg9L1frFTXZvOP1ueGuqyhOL5vVsphTc6gjxIvnFTUN97N1PW0tDxNBMCM256QIZ6oLQwRBxk2gMceOsAmelP0ylQ+V2qCprvecmrVvQC2MIJEPc5DUjbjIKlLfHqJhqznMDMOg0v7j5RMRNDGTYLWTYo/93Mpk0umXY6JZhi3p/c48FJTqKchyAo8l9DivM4pYzh7ZqzW0lP9PO3386ijsmD2NLRS1b99VxsM7F5CN60js3/P00qjgHgJXbg96XeatVj6bLjuvLRWOLGx3/uEIdtsMGVw96m3eFh6Vq/GGpjO6qxcFlrza9UJt/hIirJrBJ87/vbSHiBosdnOCsT2BYyhUlLBXIuRHPjSDEGxE3iSaQM+OPWRQdofJi9nwHO78JTvLuFqPnRtNUaGrPavD6+3IY+Qahx0jLDX9cln9ST6W/o3G0qeChDDgRvvwnbF0c27qElCM/005+pp2x/ZsOWx5VrET2d7uqcHt9mDWNjzco78vkkT2jPibdo0KrW/UitaGhSuWsmcxBz01mj5YXGCUsZfJ7LO1pwdlpuj/vzNWQuFLwuoDnJiQsJTk3gpAwktrnJiXQIhKC+46DPv6y2G1fBPNmYvXcQHhliGZSLnoID21Fem5Cc3UgxHPThDeg33h17P2boXJn9H06Ix4X/PdC+PgvyV5JStA/P51shwWXx8eG3dWs3HGQihoXWXYLxw5oQhT5WxZsC4zO1IO5ZEbOTUYM4sYQ7j43eFW+k9mnfhA40oPixuT/P+B2JTAs5TK6E0dJKJZqKUGIOyJuEk1ktVPf41SOAMDat5QXx+IIelZiwRAqAFm9wOIPd4R6bkITikMfc2CrumwpLOXIgZ6j1PWu5L3ZtVxVgX3+sMqDEg4dnw82fRzmITHQNC3QEHDF9oN85E94Pmlo90a5SQH84qZ3cT9qdX+ptxGaMqql/PPSmsUWEnry97qxeFV1VXpGUNyY/eLG40yg58YfegrNuZFScEFIHCJuEk2k56b4+KC4MZr3desf7GQcC6HiJrR5WSyemwNbVb2yu5mEYoP+J6rLLV1I3BjiztOg8p6EQ2fVi/D8+fBB9LYBR/nFzartB1m4TvWpOWN4M54X/9DMCUcOo9LfPrDmQAU4a4Lh1Fg8N2Zb8P+fuw50HZuuxE1GRjDp2WxXAj+xHYqVkHaEihu/56bO7e18/bsEoYMj4ibRhHpucvtBdk/IH6K6ABu0JiRlHCdwPUTcZPUCs/+XbqS4Ce1s7HUFB3k25bkBGHCyutz6afh2j6t16+1IGOIGYF/XH4TZLhhDVte8FXU+kyFuFm0oZ/3uakwanHJYM+LE77k5fFB/GsyqbH3x6h+C+TbWdLBnous6ry/bwcfry6OLA00LSSquA68bM0pkZGYFy+Et/twcn6shRoNj4x8ffs+Fc5awr8YZyKsxKqQg6LnRdZrtcSQIQusRcZNotJCnuO84dWkyhXf+ba24acpzYzIFvTfGsMzI/VzVwaRiaN5z0/d41en4YKkSRaDCOff2gPXvtW7NHYVQcVPxQ9KW0aUwqvacVbB5UaO7j+yTC0BFjRLFY/vlNVk5htcTKP3W0gvIyC0A4Kt1m/BVG/k2KiT16rId/ObVVfz8ma/55fPL2F0ZRZwEkoprwkrCszKDYSmbQwl83RM/cdPg9vLYoh/4ZtsBnv1iW6AiKi2KuAEJTQlCvBFxk2hCPTd9jwteN0JTEC5WYiFU0ETO1Jn4Jzj2l8GQkoE1JK+nfJ261MxgbmY+kj0Teh2trm9dDBXfw0f3AjosfaJ1a+4ohImbjUlbRpehek8wKR5g7duNdumeZQ8rET+9uZBUw0EClYVp3cgvUPu6a/az5nu/GM3oTnlVA/e+GxyYW7J2DxMf/IQ3lu8IP15Irxvd/9of1DPIyQzm49iMhn5xFDdfbNoX6ET94lfbqKxXCc2hgsbib9QIUjElCPFGxE2iCc25MTw3AH2ODV5vrefG6lAhKGg8U+ewSTDl78GZO6EYImqvX9w057UxGGDk3XwK7/0mOJRzy+LwQZydBQlLxZed/lEJFn/V3fp3g2HLuv1Q8gcoWxUITYFqDNgkxnvKkQtmCxZ/d+wcavlkuX9uWmYP/jh3DVUNHo7oncO8G0/kqOJcqp0efvPqqkCpORBWDl6z4zsANujFdMsI/v9wpCmho3mccct9+XB9cAZWRY2L91fvBsI9N6G368RzIwhxRcRNorFlwOCJ6q8gpMla76OD11srbgAm3gNHXwV9x8f+GEPclK9Xl83l2xgYHqDvXoctn6gvsW79QfeibehkoSl3versbCBhqUNn+1J1OfJCFS5qqFQ5WroO79yowpglfwg08+ufn86g7s3MGDfEjTFOwd+vqcBSj6tSiZZl+6y8/91uLCaNv/3kSA7vlc3r143n4rHF6Drc9NIKtlb4G/L5c258rho+/Uzlju1xDAzPffGLGxsu/vvltkN9RtB1nY/Xq6ouo9zdmMAe6rkJvd0gnhtBiCsibhKNpsHlr6m/0Iqo9Dw4669wyp2xj14I5ciL4Nx/qCnesWIkFRthqVjETfFxYLIGB3Ke+Bs4+koATOsahyA6NEb4xEi6rt4FzurkracrsMPvuel7HAw/R11fOxfWvAHr3lG3dy7nJ6N7cfJh3bn9rGGNxkuE0YS4ufDwDIZmqWqmz3erx//q5IEc3kslBptNGjPPH8HRfXOpavDwy+e/ocbpCXgnP/p2K44DKgx5zLETwtZg9VdLOXDx+7fX8M9Fm5sdgNoSG/fUsPNgPXaLidkXH4U9pOQ90nOTLo38BCEhiLhJJsdfB6fc0X7nMzw3RjgmlrCULR2K/SG0/MEw4SY4/HwAtK2fYfN0InFgJEUXHBYsJd4n3ps24/WovkGgcsgOP09dXzcX3rsluJ+zinznDp79v2OZfEQL/ZwixY2/X1M2NUzur4TAPj2HYUVZ3HDakLCH2i1m5lw+hu5ZdjbuqeHSJ79kS5VSKZ9+t5WhJlX633Pw6PBz+vvcDMpT+WezP/yBZ7838cLS7Xz2fQUHaltXHWiEpCYMLqBXbhoXjO4duC/Sc2OUhm/eW4PHG6yY8vp0dh6s5+P15cxZtIm7567hyU83U7J2D5v21kjpuCC0gIxfSCWM/Bwjb6ap7sSRHD9NhRt+9JDK5ckfBEVHou3+lp4HvwEuTshy446Rb9OtHziyVWlxxffQa3SzDxOaoHytqkCyZ6uQa/4QSMsL9Kmh8AjlWdy1Qv0VDGn+eBDFc+NvaVB/EJPfezjjghOwHjk+rGeMQWG2g8cvH8MlT37JtzsqWW51McAM+dpB+mj+uWo9hoc/yJ8v1DfLxB+PPZx73lnLin0mVryjPJxpVjN/POdwLj6muHmvk5+P16vw2anDlIC+ekJ/Xv5aCav0CM9Ndpr6CL799dX8ce4a+uVlcKDOxb5aF15f0wImL8PGcQPyGDcon/OO6k1OWjOFAYKQgojnJpWIrMqKxXMDMPxHcN3nQQ8OwIjzAeh18Ou4LC0m6g8ob0FbCYib/soLBUrcCG3DKAHvfbQKuZotMOxstc1kgQvmqLAmwM7lsR2zzi+M/InEgRlpDQcDoxdyCnqHjTGIZEy/bpTcfBK/O3s4ebnq8Sek+UOSmUXBYxsYyfeeBn4+YQDPXj2GU3r6OHVoAcV5adS7vdzxxmqmvbCcg3XNe3EO1LpYtk0NCT3NL26GFWXzoyN7YreYGN4zO2z/v/RdxoLse+nvqKHB7WPDnmrKq514fToWk8ZhhZmcM6oXvzppID86sicje2fjsJrYX+vi/e9284e31zDhrx/x1/fXs7e6cY8hQUhVxHOTSmQWqXwTY+BmLDk3TXH4+fDhTAqq1+Kt2wc5RXFZYpNs/xqePgtG/QzO+2fbjhEqboxmc9EqprweeOs6NZPo9D+0LeE7FTDETWhbg+OmqsTz8TeqIbFGK4FdsYobw3PjFyCOoOcmMF8qhqGZ/fIzuPbEgVA/AJbAGMtmcNPYawPBSi9/Kfj4Qfkc7O9jypSjMZstPLF4M/fP38D73+3ms+8rOGZAHmP7d2NsvzyO7JMT5kH69Pu9+HQYVpQVVv4+++Kj8Pj0cG+TrjNwzT/BtYuPJlWwZcjZ7DhQT36GjR5ZdvIybFjMjX9/ujw+Vu88yJeb9zN35S427Knm8U828fTnWzh3VC+uHNefI/rkNHqcIKQSIm5SCZNJ9cUJ5NwcgrjJH4ReeASmPavh3Rvh9N+rL7NE8dXjKql55Utw2u8hqw1iKiBuBgQ7NEfz3PxQAqv/p65veB9OugXG3xSc4WXgblBNGiO3pwoBcRPi0SsaCdNXB28bVYFl3yrR2FICfMBzE55QTE15UJRnxDBXysDqr8yqV94UehzeeB//VPBofW5MJo2pJw9i/KB8pr+yks17a/lofTkf+UNPNrOJI/rkMKRHJj5dZ0XpQSAYkgqcwmzCEhlF279ZJbUDpu1fMGj8rxnUPZOWsFlMjOmXx5h+eVx38iA+Wl/Oqvf/zZVV/+LGFddzzrIRjCrOZcKgfI7oncOIXjkU5tixN1qAIHRdRNykGt36B8WN5RDEDeA9fhqWt6/D9P18+H4+DD4DzvkH5PRu+cGtof5AsPJG98LKF1TVVmvQ9XDPjVG5tm+TGvwYWsm28gV1aeSPfHQvfPoAZPfEnFnIifv2Yvn+VqjZo57DgSfDkImQ2x8OblXnySmGsde0rpqtM1G3P5iMbUy5j0beIJWT46xS/ZVaEsBNJBQHhI3Zpoa6xootIvQa1XNjhKWaDusc2SeXBdNPYm1ZFV9vPcCybftZuuUAFTVOlm07EAhFGUw8vJlePgahA2lLv1Tv0RhyekIxmTTOGNad00v+h6ZV8uectzmzaiSrth9k1faDYftm2S3kZ9rIy7CRl2EnP8NGpsNCht1CmkVj824N96oyctLtZNjNZNjUfek2M2lWM2k2M3aLKaa8I0FINl30k1doktCmf4fiuQH0kT9l0fq9nGRejmndXPhhIbx7M1z2v9gOUPEDlC6BncuUIBh1iQo7RbL6NfXlZrKqUNHy52DCza0bNlpbAe5aQIPcYpUTYraBpx6qdgQ7Pdfugw0fqOtXvaPK5uf/ViUf79+Maf9mwjI2PPWw8QP1F8n69+CnzzTO8WgKr0cl3rpr1VyvjvwlsnOZuswb1Lx9JpOaLr91scq7abW4iRAyGT1a97xE5pVF9dz4w1Lu5jsUW8wmjuyTy5F9crnmhAHouk7p/jq+3nqAXQfrMZs0rGaNfvkZHN23W7PHAsIH0tbuVZ6c/EEtPy6SzR+j+YX7wPrvWPrzAubtK2T1jkpW76xk455q3F6daqeHaqeHrfsaT29XmHl1y+om7lNomkqwNsROs5dWM+k2Mw5byPWQx4beTrdZSLOacdhU12YRUMKhIuIm1QhNKo41obgZKtP7450yDdOJ6+CJU5QHZ/vS8OTjaCx/HubeQKDVPqi5RPt+gFPvCv8CMzwpp9wOn/9DCaGtn8LAU2D3anjpEvWrO6sIsnupxoOjLw+GNCDotcnuHfylnjcQ9q5XYxgMcbP6VSWgeo5SIZaikSp5unI7VO/Gc2A7K1Z+y+hTz8NSMEg1Bfx+gRJ29QfU85vVE1a9rHJPnjwNzvyzKkPftUKJqmOuCXo73A2qdHrdXNUF2sgrOfpKmPJA45CXxwmL/qqOdf5jyt72Rtfhq3+p60bCcHP0PlqJm13LYcxVze8bGZYyW4KeH4DMVoSkQDXRDKX70Mb7WMNzbmJF05SQ6ZffTFPCptD1oOfGlqVmvpV+0TZx881T6tIv/rutfprLLpgDxxmn0qmq91BR62R/rYt9NS721To5UOui2umh1umhpt7NptKdZHUroNbto87Y7vTQ4Pbh8pep67rqplzn8kJt65caC2aTpoSOXxAp0WMmPUQ4Be6zhe8X6mGymk1YzBoWkwmbxbg0YbeYMOOj2g3VDR4yNTNWsyaCqosh4ibVCBM3h+a5CaPnkXDUpbDiefjoT8rrAbBtCXz6dzXvauhktW3fJnj/NkBX+Rr9xqkv7a8eV/se3A7nPqK+2Hd/5xcFVhjzc6gqg2/+A8ueVRVPL/w02HW4thx2f6u8KB//BY66BE64GXL6wMFtje0vGOIXNz+okBoEhdRRlwX3M1uVEMobiN7Lza5tDo7qNRqsVjWgtGgknDgj/Pk45hp46WdwYAu8fGn4fatehH4nQOHh8O3//POU/DhyVGPB5c+pdV38PGSo4ZHsWQOv/wLK/WMIPrpXCZz2ZuULKi/JbFN9j1oikFS8Ql3u+AZevkwJnVN/G9zP6wanX9wZ4gZUaMoQNxktJxOHESpucvuqeWmRGJ4br5ND6t7XGiq+V2FNs10J2S//qcTN6Mtbd5yqXSovDOCc2fD2r+G712DizIAQ1DSNnHQrOelWBjWhDd1uN/PmbWfKlLFYrY3Lyj1eH/VuL/VuLw0uH3VuD+7K3di3f0Z62VdYa8uwNOzH5tyP2duAyevCpLvR0fBqFjxYqDFlsd+Uxz66sZdc9ui5lHlz2O9xUOUxU++zYMaHAxcOtwuH24293qVuG3+aCx8m6nUbDdjZruexWh/IDr0AUOJEw4eOFrjdNBZ+981HgVsmDUyahsmkYdLA7L9utyixZLcExZHVHBRPJk3D7fXh8vjw6qrKTd1nwmrSsJi14P4mTW03a4HHW02GCNPw+HQ8Xh2vrmO3mAJCzmE14bCaQ/KmdHRd/TRUl8HbGpCTZiU/00Z+hkpMt1nCvdy6rnd5MSfiJtXIDQ1LHbrnJoyTb4dvX1EeiM2fKC/FCxeqXihbPoWfPqsEzlvT1Lb+J8KVc4PhpcIR8M50+PZllZ9xzj/U8QCGnqW+5MdcpcTN+ndVn5XqMug+DM57DOoqlHBa8by67+t/w/cl8OulSmRAeFgu3993xRiguXu1EkcmKxzx00N7LgpHwC8WqREEZd8qAdTzKCWyvn0Ftn2m/kDl5xx1KQyZpHrubPoIXvs/FbJ7dCxk91FCtGyl6lGU1k15iVa9pHKP2vJrv61U7oQP7lTXT/0t9BjW8mOMpOI9a5Q4/d9VULNbjWY4bmowrGV4bTRTeDgqLQf8mqdVycQQTCiG6CEpCJ/D5nEC7ZB4u1WNgqD4WOWB/PKfsO2L1h9n+fMqD63veCWMvnlKhQyXPQMn3xq35VrMJrI8dWTt/kJ5WDcvgj3fteoY2d4D9KK08R0acIhtemrNOVSbssnwVpHhq2a3uYh/p1/LEvMxeHw6bq8Pj1fH6fHh8nixeGo5zLeJwdpOBmm7qMPO057JVOg5ENFfqJpDaD/RQchyWMhNs1JVa+a3yz+kzuUl22Gle5ad7pl2zCYl0Hy6TqbdQn6mEkUuj4/qBg/VDW4y7Ra6Z9vpkeWgW7qVLIeVLIcFa0hFn8NqIstuJcNuJtNhSWoSu4ibVCMs5ybGJn6xklsMY65WE8Pn3aK+CN11kF6ghMerV6s+KNu/VK748x8Lz5s5+ko1EPT1/4OyVfDkqcFRCaOvUJc9RymRULZSeV0yC+GyV8Onox9/nXL5v/ErJSa+fCw8mdjAaCpXvk4Ne1z5kro9dHLseTLNkZEPP3uh8fZT71LPUU05jPwxDDotfHr8kIlw7UJ48WIlyoxKH4DDzlJerbk3KA/Vor/CT5489LXGgjEvylkFvcfCuBtie1xOcfA98Nx5KscJVBho5Qsw3n8cI98mrVv482E08oM2hKVCBHy0ZGJQIt/iUOvZuw66j2zdOdqCkW8z4CQoPgbQYP8m9Z6IodQdUDlay59V18f+n7o8biq88Qsl7E+YrryObaW2QiU6l36h/spWBcewGBQdofLDCg5TPz7SC5S3zGxT59Z96jFel3p9q/coYRt66apRotLrVIOGrQ6VqG+xK1FvcYRf6rr6XHHXqR8ze9aQ4a0kw1sZWFYv7y7+UD0Thk5R/9+69Vdeu/J1sPRJ9FUvo7nD42rXpX9E7bE3U3XUtfhMNny6jtur4/ILIpfbg8un4fR4cXl8uH06Hq8Pnw5Ws4bdYsKkaXh9Oi6/mPL4fLi9QXHl9vlwe4LbPV4fbq86lterB7w8Jk2dp97txelWXrMG/x8ob5yGit5raPj/oWlKm1XWudlX6+JAnWoGqQSKB7WXOkZlvZvKejc/lNe0/T3SDLnpVlb+YVJCjh0LIm5SDUdO8Jd/PMNSBif+Rv2aNLwhA0+Bi19QX4rfvQ5r31Lbz5oVLkgMhpwBv/4aPrhDzSfy1Kv+PINOD+4z5mp4d7r6VX7p/xofR9PUl8YZd8Obv4TFD6gvWIgQN4epy9IlcG9IompoSCoR5PRWg0+bo/tQmPalEnGuWjX0My0X+k1Q6zzlTiVuVr+qnvNYPChtRdfJr16H+X/Pq9wisx3OnxN7JZimKY/UDyVQsUE9fszVsPRf6kv4+F8rkVupuviGhaQgWDEFrQ9LhXonm/LcmMxKdH/3Oqx8ESb+pXXnaC26Dlv9Xrv+J6r/jz0OV+HG0i/h8HNjO873C6Bqp3q+jMccfj4s+J0SDm/8QnUX73NM80nYXjccLKVH1beYvtqmXqPtX0XvAZXbFwaeqioEB5wcDJkmE3eDeu5cteq5sGfB1/+BLx6FDfPUH6jPC7+g0YA6az6OfmMw9RgKWz/DtGsFWZ/9iazlc5S3sXCkev/s+Bp2LAVXnQpfH36e+gGS1q1jJ/0DPp9OVYObihoX+6rr+frLJZx1+ilkpdupqnezt9rJ3hpVJWg2qRBbVb1fGNW6sFpMZDusZDos1DR4KK9uoLzaSVW9myq/R8fr0wOhsQa3j5oGD/VuLxnNNNpsD0TcpCLd+itxc4il4FHJKoLjp8JnD6kP7p+9pH49X/AE+LxK3Aw9u/ncgqxC+OnTKlTz5RwVigr9Ih19hUq87X8i9Dqq6eMc8VP1BbpzmfpFDuHipucoJZq2fa5+teu6CtsNPj3q4dodqwP6Hh/9vl5HwbAfqfDcJ39VVVnxYu8GVXpfuxfq9mHZs5YTjDwfUAnS3Q9r3TF7H63EDcDkv8KRP1PhxwNblWDqf4L6UobwpoAQnhgeq1fDIDTnpinPDaj32nevK7F46h9bd47WUr5OebGs6dB7jNrW9/jWiRt3A3w4U10/6tJgaM1iU2L3/dtgzZvqr+AwJUqsaUpYuutVArOzGqp3Q80erLqPcQCbIs7TfbhaW7/xKnk81PPbUbA6gs+jwcR7VPXl/N8qr5O7TgkbzQTDzsZz9P9RsqaKKWefjclqVe0gvn0FPrwnWCTw/YLG59rwnvoD5UnK6K4GH59ws/LAdjBMJo3cdBu56Tb6dbOz+zvol5+O1WqlMNvBkMKshJzX4/XR4PG1vGMCEXGTioy+XP0K6X9CYo5/6u/Ur7u+xwc/dM0WuPAp2HWDCivF8otnyET1F4nZolzuLWEywZmz4KkQ12iouDFb4Yo3lKiprfCXhPc7NFd+e3LKnUrcrHlTJe0e+8tgqLGmXOVEZPRQniJLmson2vENVO6AQaeq18gQje4G2PShCpdtXhR2Gg3waDa00ZdhHv/r2GZERTLsbFj8oCr1H/Nz9fofdbnKNfn6Sdj4vvL2ZRbBxD+FPzY0LNXanBvD62OyBnOsojHwVFVJV7UT7fsPOOQkkOYwqqSKjwtWw/Ubr3LJSpfEdowP71GCPaO7ajAZynG/UsJ92bPqvVGxMehJbQLdZKXG1p2M/mMw9Rimwo7Fx8YnPJssegxT/7/BL+T2KM91Znd0txvWzgvuazKpAoQRF6jw2+5vVQ6eu0793yo+Tn0urHtHVTbuXa9+EFVuV39bPlVenYkzVb5dNLxu9bjq3cpTZ/QD87pVXl7lduURC32/d1IsZhOZUbprt+saknp2ITkcc636SxRmi/pPGonJ3HzDt0TQ9zgY8WMV4rKmR/9y1DSVy9HafI5kUzRSCYSV/4WS36vy7FEXq8TU0i8IK7OP5Mt/KuEzZKKq3Nm1QpXAg/p1O2SS+gBOz8fj6MaCLToTJ1+MOUolTUz0HAW/3RmevHvMNWodob+QL5ijcpVCCQ1LtdZzk9kdJv9dfUk3l2NmMivhtfgBTKteguwrW3eeWHE3wHf+L9wBJwa3Gx66sm/BWRO9qstg00cqjwxUIn20923f49XfWbOUmHJWqy9qj0s9D7YsdY6sIsjujceWw0fvf8CUKVOUJ6OrYc9Sfy1hdajPjL5NtDjoeSScdpcKgdXuhZq96rNl6ZPKA/nDQuVRPuoyFRrftRy2fq7CfHvWBJtRgsovzO3rF1H+/B9ruv8HwNWqiajPrd4zlTugslQJNItNvX7WNJWr5KpRSeWHn9+2Hx5dFBE3Qtdn4j0qbj7gpA4fI2815zysSuk/nqU8T4sfCN6XN0iVmRuJuhndVcgno0A1GKwtD5a+g/KajLpYdVYOCT/objfu7SG/cttKqLABVeU16HTlMQIYd310135oWKq1OTcAx/0ytv2OugwWP4C2+SMcI85R2zxOFU6N7HTcFmr3wcuXqC86kxWGnRO8L6ePygur3A7/GK1aD2QVqqRhTz2gqS+u7kPhk/vUY465Fg5rIWEzLReGn9P8PgBud1utSk1sGeqvW3+VEH7MtcqbtnauEpOh3adDsWerPlj7vlejN/zjN3Dkqnyh/ZtUxZvRu6g1fDwLxv4cTr4jXPBW74a1b2PespjBVelQdzzkFCqP0fr3VO5ez1FKUCUiDzNJiLgRuj65fdW8o64mbEB5yUZfDiMvVB+I27+CvuNUGCjXn0TtqlO/7jK6B5+Dsx9UvzJLv1Sl9H2PVx/U7f0cjfu1EjdFR6ohpdEwPDeaObEu+/xB0HccWukXDCxfgGlRKXzzb/WBP/Wztnv26g/ArpXw3gzVhdiRAxf/t3He0lGXwid/U6KztrzxcQwRCCqPJjJ8JySP/EFw0XOqR9eql5U39cBWKBiqwv/9xqu8s9z+KgTmqlXvicrt6r3ffZj6v7ftc9Xva+MCQFci2GJXIdPcvsrT5nWp/8/uepX3Y8tQ/Y42f6wS9Fe+BPkDVQK1z+PvJq5jAkYA+iNvq4rQ0q+C4mrVS6o1w4m/Uefav1klqw88tWkBvXO56qtUtVPlclkcMPAkOGNmY+9rEhBxI6QGXVHYhGJ1wLhp6i8SW3pjz4PZqj7gjMaKyWLw6Uo4dOvf2LNjYAiajO6tG7nRFo66FEq/YEj5e1DuTxx1VsKSh2HSva071tIn1ReGUQUG6gvqsteid0o+9beqlPvAFtXRunavKqm2ONSXVMUGlYxcf0D1gIqHN0mIL7nFqr/QSbeoMGBkh2wDWwb0n9B4e/8T2p4LuWWxSsovW6lCXaH0OQZv/5OoXvYaufXbVC4WqP9Th5+vvDeV21ULj1C+fEz9cJp8X7hgWf8evHaN36sYwor/qvE1U+5T6QBJ/NwVcSMIQnJpad5Uz1EqZNMeQmzEBegLfo/WcBBf0ShMQ85Qob6l/1aJu7F6bzYvCv+iyOmrvGNn/rn5vKH0PPUXWf0jdC40rWlhkygGnAi/+Fjlz9UfUHk8XrdKDM/ti8/t5pOaIzn7yAIsmxZAjxFqtIzFrt6Xy59T3l+jI7slTVU0fveaej8feZF67zZUwmezAV0lUU+6V4Vuq3crcbV3nWpC+u2rqpdZkpLSRdwIgtCxSc9rv7CiPQvP1R/wxUfvMe7CG1Vy7eZFyrX/+Wz1JdASdfvhzevU9dGXw6Q/h+cNCUKiMJmgTzPCWNPQi4+DgRHeIYsdjv2F+gvl2Gvh7etVx3cjid1gzM9hyv3BisuikSqv8bOH1BidA1vaX+CFIOJGEISOT3u6t/MHcyBjiL/9q79h4gsXqsZwE25SXXc/e0jlVww5QyUGGx4dXYd3b1a5DPmDlTs/iR/wgnBI9B4Dv/xEeXAqvvf3vtqvxuEYLR1CsdjUgOPDz1W5QU2FmtsBETeCIAjNMfgM1fdl5zdqCOqetcHS3Q3vwXu/8YfO+qgE0LVvqblqP35ShI3Q+bHY1Gic1tBcw8x2IrlddgRBEDo6hvcGVEsBd60SO6f8Vo2V0H0qz2HdO6rnCcApdwQHhgqC0O6I50YQBKElBp8OR16scg9OmKE62WqacsEfLFVdbat3q9b9jhzVs0cQhKQh4kYQBKElNA1+/ET0+3L7Rh8CKwhC0pCwlCAIgiAIXQoRN4IgCIIgdClE3AiCIAiC0KUQcSMIgiAIQpdCxI0gCIIgCF0KETeCIAiCIHQpRNwIgiAIgtClEHEjCIIgCEKXQsSNIAiCIAhdChE3giAIgiB0KZIubh577DEGDBiAw+FgzJgxLF68uNn9P/nkE8aMGYPD4WDgwIE8/vjj7bRSQRAEQRA6A0kVN6+88grTp0/nrrvuYsWKFZx44olMnjyZ0tLSqPtv2bKFKVOmcOKJJ7JixQp++9vfcuONN/L666+388oFQRAEQeioJHVw5oMPPsg111zDtddeC8Ds2bOZP38+c+bMYdasWY32f/zxx+nbty+zZ88GYPjw4XzzzTfcf//9/OQnP4l6DqfTidPpDNyuqqoCwO1243a742qPcbx4H7ejkmr2gticCqSavZB6NqeavdA1bG7N2jVd1/UErqVJXC4X6enpvPrqq1xwwQWB7TfddBMrV67kk08+afSYk046idGjR/Pwww8Htr355ptcdNFF1NXVYbVaGz3m7rvv5p577mm0/cUXXyQ9PT1O1giCIAiCkEjq6uq49NJLqaysJDs7u9l9k+a5qaiowOv1UlhYGLa9sLCQ3bt3R33M7t27o+7v8XioqKigZ8+ejR5z5513MmPGjMDtyspK+vbty7hx48jKyoqDJUHcbjcff/wxp556alSh1dVINXtBbE4Fm1PNXkg9m1PNXugaNldXVwMQi08mqWEpAE3Twm7rut5oW0v7R9tuYLfbsdvtgdtGWGrAgAFtWq8gCIIgCMmjurqanJycZvdJmrgpKCjAbDY38tKUl5c38s4YFBUVRd3fYrGQn58f03l79erF9u3bycrKalZEtYWqqiqKi4vZvn17iy6zrkCq2QticyrYnGr2QurZnGr2QtewWdd1qqur6dWrV4v7Jk3c2Gw2xowZQ0lJSVjOTUlJCeedd17Ux4wbN4533nknbNuCBQsYO3ZszG42k8lEnz592r7wGMjOzu60b562kGr2gticCqSavZB6NqeavdD5bW7JY2OQ1FLwGTNm8O9//5unnnqKdevWcfPNN1NaWsrUqVMBlS9z5ZVXBvafOnUq27ZtY8aMGaxbt46nnnqK//znP9xyyy3JMkEQBEEQhA5GUnNuLr74Yvbt28fMmTMpKytj5MiRzJs3j379+gFQVlYW1vNmwIABzJs3j5tvvpl//vOf9OrVi3/84x9NloELgiAIgpB6JD2heNq0aUybNi3qfc8880yjbSeffDLLly9P8Kraht1u549//GNYAnNXJtXsBbE5FUg1eyH1bE41eyH1bE5anxtBEARBEIREkPTZUoIgCIIgCPFExI0gCIIgCF0KETeCIAiCIHQpRNwIgiAIgtClEHETJx577DEGDBiAw+FgzJgxLF68ONlLihuzZs3imGOOISsrix49enD++eezYcOGsH10Xefuu++mV69epKWlccopp7BmzZokrTi+zJo1C03TmD59emBbV7R3586dXH755eTn55Oens5RRx3FsmXLAvd3JZs9Hg+/+93vGDBgAGlpaQwcOJCZM2fi8/kC+3R2ez/99FPOOeccevXqhaZpvPXWW2H3x2Kf0+nkhhtuoKCggIyMDM4991x27NjRjlbETnP2ut1ubr/9do444ggyMjLo1asXV155Jbt27Qo7RmeyF1p+jUP51a9+haZpzJ49O2x7Z7M5VkTcxIFXXnmF6dOnc9ddd7FixQpOPPFEJk+eHNajpzPzySef8Otf/5ovv/ySkpISPB4PkyZNora2NrDPfffdx4MPPsijjz7K119/TVFRERMnTgwMOuusfP311zzxxBMceeSRYdu7mr0HDhxgwoQJWK1W3n//fdauXcsDDzxAbm5uYJ+uZPPf/vY3Hn/8cR599FHWrVvHfffdx9///nceeeSRwD6d3d7a2lpGjRrFo48+GvX+WOybPn06b775Ji+//DKfffYZNTU1/OhHP8Lr9baXGTHTnL11dXUsX76c3//+9yxfvpw33niDjRs3cu6554bt15nshZZfY4O33nqLr776KurYgs5mc8zowiFz7LHH6lOnTg3bNmzYMP2OO+5I0ooSS3l5uQ7on3zyia7ruu7z+fSioiL9r3/9a2CfhoYGPScnR3/88ceTtcxDprq6Wh8yZIheUlKin3zyyfpNN92k63rXtPf222/XTzjhhCbv72o2n3322fr//d//hW378Y9/rF9++eW6rnc9ewH9zTffDNyOxb6DBw/qVqtVf/nllwP77Ny5UzeZTPoHH3zQbmtvC5H2RmPp0qU6oG/btk3X9c5tr643bfOOHTv03r176999953er18//aGHHgrc19ltbg7x3BwiLpeLZcuWMWnSpLDtkyZNYsmSJUlaVWKprKwEIC8vD4AtW7awe/fusOfAbrdz8sknd+rn4Ne//jVnn302Z5xxRtj2rmjv3LlzGTt2LD/96U/p0aMHo0eP5sknnwzc39VsPuGEE/jwww/ZuHEjAKtWreKzzz5jypQpQNezN5JY7Fu2bBlutztsn169ejFy5Mgu8RxUVlaiaVrAO9kV7fX5fFxxxRXceuutjBgxotH9XdFmg6R3KO7sVFRU4PV6G00yLywsbDTBvCug6zozZszghBNOYOTIkQABO6M9B9u2bWv3NcaDl19+meXLl/P11183uq8r2rt582bmzJnDjBkz+O1vf8vSpUu58cYbsdvtXHnllV3O5ttvv53KykqGDRuG2WzG6/Xy5z//mUsuuQTomq9xKLHYt3v3bmw2G926dWu0T2f/bGtoaOCOO+7g0ksvDQyR7Ir2/u1vf8NisXDjjTdGvb8r2mwg4iZOaJoWdlvX9UbbugLXX3893377LZ999lmj+7rKc7B9+3ZuuukmFixYgMPhaHK/rmIvqF94Y8eO5S9/+QsAo0ePZs2aNcyZMydseG1XsfmVV17hv//9Ly+++CIjRoxg5cqVTJ8+nV69enHVVVcF9usq9jZFW+zr7M+B2+3mZz/7GT6fj8cee6zF/TurvcuWLePhhx9m+fLlrV5/Z7U5FAlLHSIFBQWYzeZGKre8vLzRr6LOzg033MDcuXP5+OOP6dOnT2B7UVERQJd5DpYtW0Z5eTljxozBYrFgsVj45JNP+Mc//oHFYgnY1FXsBejZsyeHH3542Lbhw4cHkuK72mt86623cscdd/Czn/2MI444giuuuIKbb76ZWbNmAV3P3khisa+oqAiXy8WBAwea3Kez4Xa7ueiii9iyZQslJSUBrw10PXsXL15MeXk5ffv2DXyObdu2jd/85jf0798f6Ho2hyLi5hCx2WyMGTOGkpKSsO0lJSWMHz8+SauKL7quc/311/PGG2/w0UcfMWDAgLD7BwwYQFFRUdhz4HK5+OSTTzrlc3D66aezevVqVq5cGfgbO3Ysl112GStXrmTgwIFdyl6ACRMmNCrv37hxI/369QO63mtcV1eHyRT+8Wc2mwOl4F3N3khisW/MmDFYrdawfcrKyvjuu+865XNgCJvvv/+ehQsXkp+fH3Z/V7P3iiuu4Ntvvw37HOvVqxe33nor8+fPB7qezWEkKZG5S/Hyyy/rVqtV/89//qOvXbtWnz59up6RkaFv3bo12UuLC9ddd52ek5OjL1q0SC8rKwv81dXVBfb561//qufk5OhvvPGGvnr1av2SSy7Re/bsqVdVVSVx5fEjtFpK17uevUuXLtUtFov+5z//Wf/+++/1F154QU9PT9f/+9//BvbpSjZfddVVeu/evfV3331X37Jli/7GG2/oBQUF+m233RbYp7PbW11dra9YsUJfsWKFDugPPvigvmLFikB1UCz2TZ06Ve/Tp4++cOFCffny5fppp52mjxo1Svd4PMkyq0mas9ftduvnnnuu3qdPH33lypVhn2NOpzNwjM5kr663/BpHElktpeudz+ZYEXETJ/75z3/q/fr10202m3700UcHyqS7AkDUv6effjqwj8/n0//4xz/qRUVFut1u10866SR99erVyVt0nIkUN13R3nfeeUcfOXKkbrfb9WHDhulPPPFE2P1dyeaqqir9pptu0vv27as7HA594MCB+l133RX2RdfZ7f3444+j/r+96qqrdF2Pzb76+nr9+uuv1/Py8vS0tDT9Rz/6kV5aWpoEa1qmOXu3bNnS5OfYxx9/HDhGZ7JX11t+jSOJJm46m82xoum6rreHh0gQBEEQBKE9kJwbQRAEQRC6FCJuBEEQBEHoUoi4EQRBEAShSyHiRhAEQRCELoWIG0EQBEEQuhQibgRBEARB6FKIuBEEQRAEoUsh4kYQBEEQhC6FiBtBEATUhOy33nor2csQBCEOiLgRBCHpXH311Wia1ujvrLPOSvbSBEHohFiSvQBBEASAs846i6effjpsm91uT9JqBEHozIjnRhCEDoHdbqeoqCjsr1u3boAKGc2ZM4fJkyeTlpbGgAEDePXVV8Mev3r1ak477TTS0tLIz8/nl7/8JTU1NWH7PPXUU4wYMQK73U7Pnj25/vrrw+6vqKjgggsuID09nSFDhjB37tzEGi0IQkIQcSMIQqfg97//PT/5yU9YtWoVl19+OZdccgnr1q0DoK6ujrPOOotu3brx9ddf8+qrr7Jw4cIw8TJnzhx+/etf88tf/pLVq1czd+5cBg8eHHaOe+65h4suuohvv/2WKVOmcNlll7F///52tVMQhDiQ7LHkgiAIV111lW42m/WMjIywv5kzZ+q6ruuAPnXq1LDHHHfccfp1112n67quP/HEE3q3bt30mpqawP3vvfeebjKZ9N27d+u6ruu9evXS77rrribXAOi/+93vArdramp0TdP0999/P252CoLQPkjOjSAIHYJTTz2VOXPmhG3Ly8sLXB83blzYfePGjWPlypUArFu3jlGjRpGRkRG4f8KECfh8PjZs2ICmaezatYvTTz+92TUceeSRgesZGRlkZWVRXl7eVpMEQUgSIm4EQegQZGRkNAoTtYSmaQDouh64Hm2ftLS0mI5ntVobPdbn87VqTYIgJB/JuREEoVPw5ZdfNro9bNgwAA4//HBWrlxJbW1t4P7PP/8ck8nEYYcdRlZWFv379+fDDz9s1zULgpAcxHMjCEKHwOl0snv37rBtFouFgoICAF599VXGjh3LCSecwAsvvMDSpUv5z3/+A8Bll13GH//4R6666iruvvtu9u7dyw033MAVV1xBYWEhAHfffTdTp06lR48eTJ48merqaj7//HNuuOGG9jVUEISEI+JGEIQOwQcffEDPnj3Dtg0dOpT169cDqpLp5ZdfZtq0aRQVFfHCCy9w+OGHA5Cens78+fO56aabOOaYY0hPT+cnP/kJDz74YOBYV111FQ0NDTz00EPccsstFBQUcOGFF7afgYIgtBuarut6shchCILQHJqm8eabb3L++ecneymCIHQCJOdGEARBEIQuhYgbQRAEQRC6FJJzIwj/354d0wAAwDAM4896GPpNkY0iannPew4sLDcAQIq4AQBSxA0AkCJuAIAUcQMApIgbACBF3AAAKeIGAEg5xXMEGHo6Y0oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(validation_losses, label='validation loss')\n",
    "plt.legend();\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fce3df",
   "metadata": {},
   "source": [
    "# Cheking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb8d7322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:32:45.626986Z",
     "start_time": "2023-01-17T23:32:45.617606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(color_im)\n",
    "    depth_raw = o3d.geometry.Image(depth_im)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "#     PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,0,1]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d61af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e456c1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:32:47.038155Z",
     "start_time": "2023-01-17T23:32:47.034049Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_resize = transforms.Resize(480, interpolation=transforms.InterpolationMode.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a78878d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T00:06:41.095845Z",
     "start_time": "2023-01-18T00:06:40.993879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AoRNet(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('Modele/Small2_RN_150Epoch'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c474164f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T00:07:26.041730Z",
     "start_time": "2023-01-18T00:06:41.503806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.18031,     -0.68596,      2.04405], [    -0.18065,      0.74180,      2.02463]]\n",
      "REAL:\n",
      "[[    -0.31443,     -0.78609,      2.03800], [    -0.27390,      0.83152,      2.06900]]\n",
      "DIFFERENCE:\n",
      "[[     0.13413,      0.10013,      0.00605], [     0.09325,      0.08972,      0.04437]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.12519,     -0.68475,      2.20321], [    -0.11886,      0.76448,      2.18788]]\n",
      "REAL:\n",
      "[[    -0.10629,     -0.86348,      2.23850], [    -0.13628,      0.79469,      2.26800]]\n",
      "DIFFERENCE:\n",
      "[[     0.01891,      0.17872,      0.03528], [     0.01742,      0.03021,      0.08012]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.13132,     -0.70090,      2.18028], [    -0.12264,      0.76835,      2.17834]]\n",
      "REAL:\n",
      "[[    -0.10629,     -0.86348,      2.23850], [    -0.13628,      0.79469,      2.26800]]\n",
      "DIFFERENCE:\n",
      "[[     0.02504,      0.16258,      0.05822], [     0.01364,      0.02635,      0.08966]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.18417,     -0.66763,      1.99314], [    -0.18701,      0.69142,      1.99114]]\n",
      "REAL:\n",
      "[[    -0.35519,     -0.78803,      2.03800], [    -0.36082,      0.85092,      2.02600]]\n",
      "DIFFERENCE:\n",
      "[[     0.17102,      0.12040,      0.04486], [     0.17381,      0.15950,      0.03486]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.20456,     -0.68179,      2.00711], [    -0.20468,      0.69617,      2.00512]]\n",
      "REAL:\n",
      "[[    -0.35519,     -0.78803,      2.03800], [    -0.36082,      0.85092,      2.02600]]\n",
      "DIFFERENCE:\n",
      "[[     0.15064,      0.10624,      0.03089], [     0.15614,      0.15475,      0.02088]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.17847,     -0.67601,      2.03699], [    -0.18064,      0.70816,      2.03361]]\n",
      "REAL:\n",
      "[[    -0.14792,     -0.80852,      2.18800], [    -0.14852,      0.88116,      2.10750]]\n",
      "DIFFERENCE:\n",
      "[[     0.03055,      0.13252,      0.15101], [     0.03211,      0.17300,      0.07389]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.16848,     -0.71542,      2.43752], [    -0.15960,      0.68070,      2.43674]]\n",
      "REAL:\n",
      "[[    -0.31430,     -1.02671,      3.14300], [    -0.30916,      0.74329,      3.27900]]\n",
      "DIFFERENCE:\n",
      "[[     0.14582,      0.31129,      0.70548], [     0.14956,      0.06259,      0.84226]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.00528,     -0.55287,      2.55320], [     0.01915,      0.81937,      2.34774]]\n",
      "REAL:\n",
      "[[    -0.03229,     -0.63381,      2.80800], [     0.00230,      1.04900,      2.50900]]\n",
      "DIFFERENCE:\n",
      "[[     0.03757,      0.08093,      0.25480], [     0.01684,      0.22964,      0.16126]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 8 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.24229,     -0.76312,      2.29320], [    -0.23739,      0.83934,      2.22742]]\n",
      "REAL:\n",
      "[[    -0.30493,     -0.81315,      2.48200], [    -0.30081,      0.95081,      2.42900]]\n",
      "DIFFERENCE:\n",
      "[[     0.06265,      0.05003,      0.18880], [     0.06343,      0.11147,      0.20158]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 9 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.00624,     -0.53965,      1.74226], [    -0.00343,      0.63665,      1.76774]]\n",
      "REAL:\n",
      "[[    -0.03908,     -0.54405,      1.41400], [    -0.02759,      0.64029,      1.52450]]\n",
      "DIFFERENCE:\n",
      "[[     0.03284,      0.00440,      0.32826], [     0.02416,      0.00364,      0.24324]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m PREDICTED \u001b[38;5;241m=\u001b[39m [[y_val[j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()],\n\u001b[1;32m     43\u001b[0m              [y_val[j][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_val[j][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]]\n\u001b[1;32m     44\u001b[0m REAL \u001b[38;5;241m=\u001b[39m [[y_validation[j][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()],\n\u001b[1;32m     45\u001b[0m         [y_validation[j][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y_validation[j][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]]\n\u001b[0;32m---> 46\u001b[0m \u001b[43mdraw_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mREAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPREDICTED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> BATCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <-- | --> ROW: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [51], line 32\u001b[0m, in \u001b[0;36mdraw_arrow\u001b[0;34m(pcd, points_real, points_extimated)\u001b[0m\n\u001b[1;32m     26\u001b[0m line_set \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mLineSet(\n\u001b[1;32m     27\u001b[0m     points\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector3dVector(points),\n\u001b[1;32m     28\u001b[0m     lines\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector2iVector(lines),\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m line_set\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m=\u001b[39mo3d\u001b[38;5;241m.\u001b[39mutility\u001b[38;5;241m.\u001b[39mVector3dVector(colors)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mline_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "diff_X1 = []\n",
    "diff_Y1 = []\n",
    "diff_Z1 = []\n",
    "diff_X2 = []\n",
    "diff_Y2 = []\n",
    "diff_Z2 = []\n",
    "\n",
    "X1 = [] \n",
    "Y1 = [] \n",
    "Z1 = []\n",
    "X2 = []\n",
    "Y2 = []\n",
    "Z2 = [] \n",
    "\n",
    "hX1 = [] \n",
    "hY1 = [] \n",
    "hZ1 = []\n",
    "hX2 = []\n",
    "hY2 = []\n",
    "hZ2 = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "#         Apply the model\n",
    "        \n",
    "        X_validation = X_validation.to(device)\n",
    "        y_validation = y_validation.to(device)\n",
    "        \n",
    "\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = X_invNorm[0].cpu().numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "#             RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "            DEPTH_buff = X_invNorm[1].cpu().numpy()*5500\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_validation[j][0].cpu().numpy(), y_validation[j][1].cpu().numpy(), y_validation[j][2].cpu().numpy()],\n",
    "                    [y_validation[j][3].cpu().numpy(), y_validation[j][4].cpu().numpy(), y_validation[j][5].cpu().numpy()]]\n",
    "            draw_arrow(PC, REAL, PREDICTED)\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            diff_X1.append(diff[j][0])\n",
    "            diff_Y1.append(diff[j][1])\n",
    "            diff_Z1.append(diff[j][2])\n",
    "            diff_X2.append(diff[j][3])\n",
    "            diff_Y2.append(diff[j][4])\n",
    "            diff_Z2.append(diff[j][5])\n",
    "            \n",
    "            X1.append(y_validation[j][0].cpu().numpy())\n",
    "            Y1.append(y_validation[j][1].cpu().numpy())\n",
    "            Z1.append(y_validation[j][2].cpu().numpy())\n",
    "            X2.append(y_validation[j][3].cpu().numpy())\n",
    "            Y2.append(y_validation[j][4].cpu().numpy())\n",
    "            Z2.append(y_validation[j][5].cpu().numpy())\n",
    "\n",
    "            hX1.append(y_val[j][0].cpu().numpy()) \n",
    "            hY1.append(y_val[j][1].cpu().numpy()) \n",
    "            hZ1.append(y_val[j][2].cpu().numpy())\n",
    "            hX2.append(y_val[j][3].cpu().numpy())\n",
    "            hY2.append(y_val[j][4].cpu().numpy())\n",
    "            hZ2.append(y_val[j][5].cpu().numpy()) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80527311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T00:03:18.002260Z",
     "start_time": "2023-01-18T00:03:17.999130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# torch.save(Model.state_dict(), 'Modele/Big2_RN_150Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d673a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:29:10.841733Z",
     "start_time": "2023-01-17T23:29:10.220295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "fig, axs = plt.subplots(2, 3,figsize=(14,7))\n",
    "axs[0, 0].plot(X1[0:20],'o')\n",
    "axs[0, 0].plot(hX1[0:20],'+r')\n",
    "axs[0, 0].set_title('X_1')\n",
    "axs[0, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[0, 1].plot(Y1[0:20],'o')\n",
    "axs[0, 1].plot(hY1[0:20],'+r')\n",
    "axs[0, 1].set_title('Y_1')\n",
    "\n",
    "axs[0, 2].plot(Z1[0:20],'o')\n",
    "axs[0, 2].plot(hZ1[0:20],'+r')\n",
    "axs[0, 2].set_title('Z_1')\n",
    "\n",
    "axs[1, 0].plot(X2[0:20],'o')\n",
    "axs[1, 0].plot(hX2[0:20],'+r')\n",
    "axs[1, 0].set_title('X_2')\n",
    "axs[1, 0].set(ylabel='Odległość [m]')\n",
    "\n",
    "axs[1, 1].plot(Y2[0:20],'o')\n",
    "axs[1, 1].plot(hY2[0:20],'+r')\n",
    "axs[1, 1].set_title('Y_2')\n",
    "axs[1, 1].set(xlabel='Numer zdjęcia')\n",
    "\n",
    "axs[1, 2].plot(Z2[0:20],'o')\n",
    "axs[1, 2].plot(hZ2[0:20],'+r')\n",
    "axs[1, 2].set_title('Z_2')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()\n",
    "\n",
    "fig.legend(['Współrzędne rzeczywiste','Współrzędne esymowne'])\n",
    "\n",
    "plt.show()\n",
    "SAVE_DIR = '/home/el_zlociako/Documents/Praca_inzynierska/CNN/Ploty_do_inz/'\n",
    "fig.savefig(SAVE_DIR+'Big_REG_valid.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db49c8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T23:27:01.052752Z",
     "start_time": "2023-01-17T23:27:01.049306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15443961, 0.19012596, 0.25560942, 0.15443961, 0.20903291, 0.29506782]\n"
     ]
    }
   ],
   "source": [
    "X1_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y1_MEAN_DIFF = np.mean(diff_Y1)\n",
    "Z1_MEAN_DIFF = np.mean(diff_Z1)\n",
    "X2_MEAN_DIFF = np.mean(diff_X1)\n",
    "Y2_MEAN_DIFF = np.mean(diff_Y2)\n",
    "Z2_MEAN_DIFF = np.mean(diff_Z2)\n",
    "\n",
    "MEAN_ERR = [X1_MEAN_DIFF, Y1_MEAN_DIFF, Z1_MEAN_DIFF, X2_MEAN_DIFF, Y2_MEAN_DIFF, Z2_MEAN_DIFF]\n",
    "print(MEAN_ERR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351666d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28057c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b361d4100cabf439e872d27edcfc9e968620b5cc1a2991a8793a2beed62efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
