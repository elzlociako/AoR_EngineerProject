{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d70ecdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:17.155693Z",
     "start_time": "2023-01-24T20:36:12.739931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import open3d as o3d\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2190b7",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4c59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:17.159889Z",
     "start_time": "2023-01-24T20:36:17.157727Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./testFiles/data.csv') \n",
    "# df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "# df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "# df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ecfe96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:17.774900Z",
     "start_time": "2023-01-24T20:36:17.160815Z"
    }
   },
   "outputs": [],
   "source": [
    "from sympy import Line2D, Point2D, Segment3D, Point3D, Line3D, Symbol, solve\n",
    "from sympy.plotting import plot as symplot\n",
    "\n",
    "from sympy import symbols\n",
    "from numpy import linspace\n",
    "from sympy import lambdify\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "import threading as thr\n",
    "from shutil import copyfile\n",
    "import multiprocessing as mp\n",
    "# from visualiser import Visualiser\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as im\n",
    "\n",
    "def draw_point(pt, img, img_size, divider, K):\n",
    "    new_K = np.resize(K, (3, 3))\n",
    "    X = np.matmul(new_K, [pt[0], pt[1], pt[2]])\n",
    "    x1 = int(X[0] / X[2] / divider)\n",
    "    y1 = int(X[1] / X[2] / divider)\n",
    "    if y1 > img_size[0] or x1 > img_size[1] or y1 < 0 or x1 < 0:\n",
    "        return False\n",
    "    image = np.zeros(img_size, float)\n",
    "    image = cv.circle(image, (x1, y1), radius=1, color=255, thickness=-1)\n",
    "    # image = cv.flip(image, 1)\n",
    "    img[np.where(image==255)] = pt[2]\n",
    "    return True\n",
    "\n",
    "def calc_xz_for_y(pt1, pt2, y):\n",
    "    t = (y - pt1[1])/(pt2[1] - pt1[1])\n",
    "    x = pt1[0] + (pt2[0] - pt1[0]) * t\n",
    "    z = pt1[2] + (pt2[2] - pt1[2]) * t\n",
    "    # if x> 2 or x < -2:\n",
    "    #     print(x, y, z)\n",
    "    # print([x, y, z])\n",
    "    return [x,y,z]\n",
    "\n",
    "def get_pixel(pt, img_size, divider, K):\n",
    "    new_K = np.resize(K, (3, 3))\n",
    "    X = np.matmul(new_K, [pt[0], pt[1], pt[2]])\n",
    "    x1 = int(X[0] / X[2] / divider)\n",
    "    y1 = int(X[1] / X[2] / divider)\n",
    "    if y1 > img_size[0] or x1 > img_size[1] or y1 < 0 or x1 < 0:\n",
    "        return\n",
    "    return x1, y1, pt[2]\n",
    "\n",
    "def convert_csv(p1a, p2a):\n",
    "    DIVIDER = 1\n",
    "    IMG_SIZE = (480//DIVIDER, 640//DIVIDER)\n",
    "\n",
    "    img = np.zeros(IMG_SIZE, float)\n",
    "\n",
    "    pt1 = p1a\n",
    "    pt2 = p2a\n",
    "\n",
    "    K = [570.0,0.0,320.0,0.0,570.0,240.0,0.0,0.0,1.0]\n",
    "\n",
    "    switch_to_Y = abs(pt2[0]-pt1[0]) < abs(pt2[1]-pt1[1])\n",
    "\n",
    "    min_ran = pt1[1]\n",
    "    max_ran = pt2[1]\n",
    "\n",
    "    if switch_to_Y:\n",
    "        step = (max_ran - min_ran) / (IMG_SIZE[1])\n",
    "    else:\n",
    "        step = (max_ran - min_ran) / (IMG_SIZE[0])\n",
    "    ran = np.arange(min_ran, max_ran, step)\n",
    "    a = []\n",
    "    if switch_to_Y:\n",
    "        for y_i in ran:\n",
    "            a.append(calc_xz_for_y(pt1, pt2, y_i))\n",
    "    else:\n",
    "        for x_i in ran:\n",
    "            a.append(calc_yz_for_x(pt1, pt2, x_i))\n",
    "\n",
    "    a_px = [get_pixel(px, IMG_SIZE, DIVIDER, K) for px in a]\n",
    "    a_px = [np.array([int(i[0]), int(i[1]), float(i[2])]) for i in a_px if i is not None]\n",
    "\n",
    "    linspace = np.linalg.norm(a_px[0] - a_px[-1])\n",
    "    points_on_line = np.linspace(a_px[0], a_px[-1], int(linspace))\n",
    "    for pt in points_on_line:\n",
    "        tmp_img = np.zeros(IMG_SIZE, float)\n",
    "        # depth_img = np.load(data['depth_img_II'].iloc[i])\n",
    "        # depth_img = cv.imread(data['depth_img_I'].iloc[i], cv.IMREAD_UNCHANGED)\n",
    "        cv.circle(tmp_img, (int(pt[0]), int(pt[1])), radius=5, color=pt[2], thickness=-1)\n",
    "        # if np.sum(tmp_img*depth_img):\n",
    "        img[np.where(tmp_img!=0)] = tmp_img[np.where(tmp_img!=0)]\n",
    "        \n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c7a87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:17.784287Z",
     "start_time": "2023-01-24T20:36:17.777067Z"
    }
   },
   "outputs": [],
   "source": [
    "ResizeData = transforms.Resize([256, 320], interpolation=transforms.InterpolationMode.NEAREST)\n",
    "\n",
    "# Functions \n",
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(np.uint8(color_im))\n",
    "    depth_raw = o3d.geometry.Image(np.float32(depth_im))\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "#     PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def CreateAxisCloud(depth_im):\n",
    "    depth_raw  = o3d.geometry.Image(np.float32(depth_im/1)) # Converts depth data into image format\n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_depth_image(depth_raw,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "    # PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,1,0]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c8f3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:17.798829Z",
     "start_time": "2023-01-24T20:36:17.785950Z"
    }
   },
   "outputs": [],
   "source": [
    "# RGBimg_begin = load_from_csv(df_INPUT_RGB, 'rgb' ,0)\n",
    "# DEPTHimg_begin = load_from_csv(df_INPUT_DEPTH, 'depth',0)\n",
    "# DEPTHimg_end = load_from_csv(df_INPUT_DEPTH, 'depth', 1)\n",
    "\n",
    "# # Taking first rgb image\n",
    "# rgb_in = torch.IntTensor(RGBimg_begin.transpose(0,3,1,2))\n",
    "# gray_in = RGBtoGRAY(rgb_in).div(255)\n",
    "# # plt.imshow(gray_in[0].numpy().transpose(1,2,0),cmap='gray')\n",
    "\n",
    "# # Taking depth beginning state of the movement\n",
    "# depthBeg_in = NormImage(DEPTHimg_begin,5500,reshape=True)\n",
    "\n",
    "# # Taking depth end state of the movement\n",
    "# depthEnd_in = NormImage(DEPTHimg_end,5500,reshape=True)\n",
    "\n",
    "# # Taking depth difference between movements\n",
    "# depthDiff_in = NormImage(abs(DEPTHimg_begin - DEPTHimg_end),5500,reshape=True)\n",
    "\n",
    "# # Taking outputs\n",
    "# axis_out = df_OUTPUT.values\n",
    "# y_test = torch.Tensor(axis_out)\n",
    "\n",
    "# X_test = ResizeData(torch.cat((gray_in, depthBeg_in, depthDiff_in),axis=1))\n",
    "# print(RGBD_input.shape)\n",
    "# # RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47692263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:20.260770Z",
     "start_time": "2023-01-24T20:36:17.800498Z"
    }
   },
   "outputs": [],
   "source": [
    "from Libraries.dataloader import DataLoader as DL\n",
    "\n",
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "\n",
    "X, y = dl.load(DATASET_ROOTDIR, 'files/data.csv', 'R')\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# X_train_aug = X_train.clone()\n",
    "# for i in range(X_train_aug.shape[0]):\n",
    "#      X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "# X_train = torch.cat((X_train, X_train_aug),axis=0)\n",
    "# y_train = torch.cat((y_train, y_train),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2540beb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:20.264561Z",
     "start_time": "2023-01-24T20:36:20.261920Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_validation, y_validation)\n",
    "# test_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_args = dict(batch_size=10, num_workers=os.cpu_count(), pin_memory=True, drop_last=True)\n",
    "train_loader = DataLoader(train_set,shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set,shuffle=False, **loader_args)\n",
    "# test_loader = DataLoader(test_set,shuffle=False, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52529293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:20.280728Z",
     "start_time": "2023-01-24T20:36:20.265496Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(depthDiff_in[2].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495f9e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:20.309814Z",
     "start_time": "2023-01-24T20:36:20.282040Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(rgb_in[6].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bf10d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:20.325999Z",
     "start_time": "2023-01-24T20:36:20.311965Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=3, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d2be74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:22.149147Z",
     "start_time": "2023-01-24T20:36:20.327474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AoRNet(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('Modele/Big2_RN_150Epoch'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "239873d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:36:22.152631Z",
     "start_time": "2023-01-24T20:36:22.150447Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_resize = transforms.Resize(480, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "LossFCN = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c86646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T20:38:35.590470Z",
     "start_time": "2023-01-24T20:38:23.275758Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.13260,     -0.53972,      1.85931], [    -0.13040,      0.62878,      1.79380]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01628,     -0.43338,      1.73877], [    -0.00616,      0.48030,      1.67726]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04493,     -0.46468,      1.77392], [    -0.03432,      0.51953,      1.70894]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m PC_realAxis \u001b[38;5;241m=\u001b[39m CreateAxisCloud(SEG_REAL)\n\u001b[1;32m     59\u001b[0m PC_predAxis \u001b[38;5;241m=\u001b[39m CreateAxisCloud(SEG_ESTI)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mPC_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPC_predAxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> BATCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <-- | --> ROW: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "val_err = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(val_loader):\n",
    "#         Apply the model\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = X_invNorm[0].numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "#             RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "    \n",
    "            X1E = y_val[j][0].cpu().numpy()\n",
    "            Y1E = y_val[j][1].cpu().numpy()\n",
    "            Z1E = y_val[j][2].cpu().numpy()\n",
    "            \n",
    "            X2E = y_val[j][3].cpu().numpy()\n",
    "            Y2E = y_val[j][4].cpu().numpy()\n",
    "            Z2E = y_val[j][5].cpu().numpy()\n",
    "            \n",
    "            X1R = y_validation[j][0].cpu().numpy()\n",
    "            Y1R = y_validation[j][1].cpu().numpy()\n",
    "            Z1R = y_validation[j][2].cpu().numpy()\n",
    "            \n",
    "            X2R = y_validation[j][3].cpu().numpy()\n",
    "            Y2R = y_validation[j][4].cpu().numpy()\n",
    "            Z2R = y_validation[j][5].cpu().numpy()\n",
    "            \n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'REAL:')\n",
    "            SEG_REAL = convert_csv([X1R, Y1R, Z1R],  [X2R, Y2R, Z2R])\n",
    "            \n",
    "            print(f'ESTIMATED:')\n",
    "            SEG_ESTI = convert_csv([X1E, Y1E, Z1E],  [X2E, Y2E, Z2E])\n",
    "            \n",
    "#             tp, fp, fn, tn = smp.metrics.get_stats(torch.Tensor(SEG_ESTI).long(), torch.Tensor(SEG_REAL).long(), mode='binary', threshold=0.1)\n",
    "#             err = smp.metrics.f1_score(tp, fp, fn, tn)\n",
    "#             err = LossFCN(torch.Tensor(SEG_ESTI), torch.Tensor(SEG_REAL))\n",
    "#             val_err.append(err.cpu().detach().numpy())\n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            \n",
    "            DEPTH_buff = X_invNorm[1].numpy()*5500\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_validation[j][0].cpu().numpy(), y_validation[j][1].cpu().numpy(), y_validation[j][2].cpu().numpy()],\n",
    "                    [y_validation[j][3].cpu().numpy(), y_validation[j][4].cpu().numpy(), y_validation[j][5].cpu().numpy()]]\n",
    "            \n",
    "            \n",
    "#             draw_arrow(PC, REAL, PREDICTED)\n",
    "            \n",
    "            PC_object = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PC_realAxis = CreateAxisCloud(SEG_REAL)\n",
    "            PC_predAxis = CreateAxisCloud(SEG_ESTI)\n",
    "            \n",
    "            o3d.visualization.draw_geometries([PC_object,PC_predAxis])\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())#             print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')())\n",
    "#             print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "# loss = criterion(y_val, y_validation.cuda())\n",
    "# diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "# print(f'RMSE: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ac8d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-24T19:25:34.181200Z",
     "start_time": "2023-01-24T19:25:34.175980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09021792"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_err) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf8455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T12:49:17.684140Z",
     "start_time": "2023-01-04T12:49:17.684129Z"
    }
   },
   "outputs": [],
   "source": [
    "qqqqqqqqqqqqqqq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
