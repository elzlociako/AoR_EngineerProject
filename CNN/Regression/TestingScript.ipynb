{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d70ecdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:28.777523Z",
     "start_time": "2023-02-03T23:25:24.939419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import open3d as o3d\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2190b7",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4c59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:28.781986Z",
     "start_time": "2023-02-03T23:25:28.779590Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./testFiles/data.csv') \n",
    "# df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "# df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "# df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ecfe96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:29.146114Z",
     "start_time": "2023-02-03T23:25:28.783441Z"
    }
   },
   "outputs": [],
   "source": [
    "from sympy import Line2D, Point2D, Segment3D, Point3D, Line3D, Symbol, solve\n",
    "from sympy.plotting import plot as symplot\n",
    "\n",
    "from sympy import symbols\n",
    "from numpy import linspace\n",
    "from sympy import lambdify\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import tqdm\n",
    "import threading as thr\n",
    "from shutil import copyfile\n",
    "import multiprocessing as mp\n",
    "# from visualiser import Visualiser\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as im\n",
    "\n",
    "def draw_point(pt, img, img_size, divider, K):\n",
    "    new_K = np.resize(K, (3, 3))\n",
    "    X = np.matmul(new_K, [pt[0], pt[1], pt[2]])\n",
    "    x1 = int(X[0] / X[2] / divider)\n",
    "    y1 = int(X[1] / X[2] / divider)\n",
    "    if y1 > img_size[0] or x1 > img_size[1] or y1 < 0 or x1 < 0:\n",
    "        return False\n",
    "    image = np.zeros(img_size, float)\n",
    "    image = cv.circle(image, (x1, y1), radius=1, color=255, thickness=-1)\n",
    "    # image = cv.flip(image, 1)\n",
    "    img[np.where(image==255)] = pt[2]\n",
    "    return True\n",
    "\n",
    "def calc_xz_for_y(pt1, pt2, y):\n",
    "    t = (y - pt1[1])/(pt2[1] - pt1[1])\n",
    "    x = pt1[0] + (pt2[0] - pt1[0]) * t\n",
    "    z = pt1[2] + (pt2[2] - pt1[2]) * t\n",
    "    # if x> 2 or x < -2:\n",
    "    #     print(x, y, z)\n",
    "    # print([x, y, z])\n",
    "    return [x,y,z]\n",
    "\n",
    "def get_pixel(pt, img_size, divider, K):\n",
    "    new_K = np.resize(K, (3, 3))\n",
    "    X = np.matmul(new_K, [pt[0], pt[1], pt[2]])\n",
    "    x1 = int(X[0] / X[2] / divider)\n",
    "    y1 = int(X[1] / X[2] / divider)\n",
    "    if y1 > img_size[0] or x1 > img_size[1] or y1 < 0 or x1 < 0:\n",
    "        return\n",
    "    return x1, y1, pt[2]\n",
    "\n",
    "def convert_csv(p1a, p2a):\n",
    "    DIVIDER = 1\n",
    "    IMG_SIZE = (480//DIVIDER, 640//DIVIDER)\n",
    "\n",
    "    img = np.zeros(IMG_SIZE, float)\n",
    "\n",
    "    pt1 = p1a\n",
    "    pt2 = p2a\n",
    "\n",
    "    K = [570.0,0.0,320.0,0.0,570.0,240.0,0.0,0.0,1.0]\n",
    "\n",
    "    switch_to_Y = abs(pt2[0]-pt1[0]) < abs(pt2[1]-pt1[1])\n",
    "\n",
    "    min_ran = pt1[1]\n",
    "    max_ran = pt2[1]\n",
    "\n",
    "    if switch_to_Y:\n",
    "        step = (max_ran - min_ran) / (IMG_SIZE[1])\n",
    "    else:\n",
    "        step = (max_ran - min_ran) / (IMG_SIZE[0])\n",
    "    ran = np.arange(min_ran, max_ran, step)\n",
    "    a = []\n",
    "    if switch_to_Y:\n",
    "        for y_i in ran:\n",
    "            a.append(calc_xz_for_y(pt1, pt2, y_i))\n",
    "    else:\n",
    "        for x_i in ran:\n",
    "            a.append(calc_yz_for_x(pt1, pt2, x_i))\n",
    "\n",
    "    a_px = [get_pixel(px, IMG_SIZE, DIVIDER, K) for px in a]\n",
    "    a_px = [np.array([int(i[0]), int(i[1]), float(i[2])]) for i in a_px if i is not None]\n",
    "\n",
    "    linspace = np.linalg.norm(a_px[0] - a_px[-1])\n",
    "    points_on_line = np.linspace(a_px[0], a_px[-1], int(linspace))\n",
    "    for pt in points_on_line:\n",
    "        tmp_img = np.zeros(IMG_SIZE, float)\n",
    "        # depth_img = np.load(data['depth_img_II'].iloc[i])\n",
    "        # depth_img = cv.imread(data['depth_img_I'].iloc[i], cv.IMREAD_UNCHANGED)\n",
    "        cv.circle(tmp_img, (int(pt[0]), int(pt[1])), radius=5, color=pt[2], thickness=-1)\n",
    "        # if np.sum(tmp_img*depth_img):\n",
    "        img[np.where(tmp_img!=0)] = tmp_img[np.where(tmp_img!=0)]\n",
    "        \n",
    "    return img\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c7a87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:29.154181Z",
     "start_time": "2023-02-03T23:25:29.148403Z"
    }
   },
   "outputs": [],
   "source": [
    "ResizeData = transforms.Resize([256, 320], interpolation=transforms.InterpolationMode.NEAREST)\n",
    "\n",
    "# Functions \n",
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(np.uint8(color_im))\n",
    "    depth_raw = o3d.geometry.Image(np.float32(depth_im))\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "#     PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def CreateAxisCloud(depth_im):\n",
    "    depth_raw  = o3d.geometry.Image(np.float32(depth_im/1)) # Converts depth data into image format\n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_depth_image(depth_raw,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "    # PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,1,0]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c8f3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:29.166612Z",
     "start_time": "2023-02-03T23:25:29.155696Z"
    }
   },
   "outputs": [],
   "source": [
    "# RGBimg_begin = load_from_csv(df_INPUT_RGB, 'rgb' ,0)\n",
    "# DEPTHimg_begin = load_from_csv(df_INPUT_DEPTH, 'depth',0)\n",
    "# DEPTHimg_end = load_from_csv(df_INPUT_DEPTH, 'depth', 1)\n",
    "\n",
    "# # Taking first rgb image\n",
    "# rgb_in = torch.IntTensor(RGBimg_begin.transpose(0,3,1,2))\n",
    "# gray_in = RGBtoGRAY(rgb_in).div(255)\n",
    "# # plt.imshow(gray_in[0].numpy().transpose(1,2,0),cmap='gray')\n",
    "\n",
    "# # Taking depth beginning state of the movement\n",
    "# depthBeg_in = NormImage(DEPTHimg_begin,5500,reshape=True)\n",
    "\n",
    "# # Taking depth end state of the movement\n",
    "# depthEnd_in = NormImage(DEPTHimg_end,5500,reshape=True)\n",
    "\n",
    "# # Taking depth difference between movements\n",
    "# depthDiff_in = NormImage(abs(DEPTHimg_begin - DEPTHimg_end),5500,reshape=True)\n",
    "\n",
    "# # Taking outputs\n",
    "# axis_out = df_OUTPUT.values\n",
    "# y_test = torch.Tensor(axis_out)\n",
    "\n",
    "# X_test = ResizeData(torch.cat((gray_in, depthBeg_in, depthDiff_in),axis=1))\n",
    "# print(RGBD_input.shape)\n",
    "# # RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47692263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:33.709589Z",
     "start_time": "2023-02-03T23:25:29.167998Z"
    }
   },
   "outputs": [],
   "source": [
    "from Libraries.dataloader import DataLoader as DL\n",
    "\n",
    "DATASET_ROOTDIR='/home/el_zlociako/Documents/Praca_inzynierska/Dataset/'\n",
    "dl = DL()\n",
    "\n",
    "X, y = dl.load(DATASET_ROOTDIR, 'files/data.csv', 'R')\n",
    "X_test, y_test = dl.load(DATASET_ROOTDIR, 'files_Test/data_Test.csv', 'R')\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# X_train_aug = X_train.clone()\n",
    "# for i in range(X_train_aug.shape[0]):\n",
    "#      X_train_aug[i] = DataAug(X_train_aug[i])\n",
    "        \n",
    "# X_train = torch.cat((X_train, X_train_aug),axis=0)\n",
    "# y_train = torch.cat((y_train, y_train),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2540beb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:33.714379Z",
     "start_time": "2023-02-03T23:25:33.711009Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = TensorDataset(X_train, y_train)\n",
    "val_set = TensorDataset(X_validation, y_validation)\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "\n",
    "loader_args = dict(batch_size=10, num_workers=os.cpu_count(), pin_memory=True, drop_last=True)\n",
    "train_loader = DataLoader(train_set,shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set,shuffle=False, **loader_args)\n",
    "test_loader = DataLoader(test_set,shuffle=False, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52529293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:33.729683Z",
     "start_time": "2023-02-03T23:25:33.715400Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(depthDiff_in[2].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495f9e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:33.752120Z",
     "start_time": "2023-02-03T23:25:33.730891Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(rgb_in[6].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96bf10d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:29:52.865405Z",
     "start_time": "2023-02-03T23:29:52.862071Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=3, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1d2be74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:30:02.726277Z",
     "start_time": "2023-02-03T23:30:02.431714Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Modele/SMALL2_RN_150Epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Model \u001b[38;5;241m=\u001b[39m AoRNet()\n\u001b[0;32m----> 2\u001b[0m Model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModele/SMALL2_RN_150Epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m Model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/AoR_CNN/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/AoR_CNN/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/AoR_CNN/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Modele/SMALL2_RN_150Epoch'"
     ]
    }
   ],
   "source": [
    "Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('Modele/SMALL2_RN_150Epoch'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "239873d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:25:35.561395Z",
     "start_time": "2023-02-03T23:25:35.558872Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_resize = transforms.Resize(480, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "LossFCN = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c86646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:29:20.798646Z",
     "start_time": "2023-02-03T23:28:16.590206Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.13260,     -0.53972,      1.85931], [    -0.13040,      0.62878,      1.79380]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.10642,      0.12065,      0.25469], [     0.09660,      0.30213,      0.42270]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01628,     -0.43338,      1.73877], [    -0.00616,      0.48030,      1.67726]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.24589,      0.25515,      0.05277], [     0.23784,      0.14429,      0.06626]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.04493,     -0.46468,      1.77392], [    -0.03432,      0.51953,      1.70894]]\n",
      "REAL:\n",
      "[[     0.22962,     -0.17823,      1.68600], [     0.23168,      0.33602,      1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.27455,      0.28645,      0.08792], [     0.26599,      0.18352,      0.09794]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07283,     -0.48854,      1.68518], [    -0.05441,      0.52500,      1.62830]]\n",
      "REAL:\n",
      "[[     0.09985,     -0.33658,      1.17800], [     0.10554,      0.18001,      1.30350]]\n",
      "DIFFERENCE:\n",
      "[[     0.17268,      0.15196,      0.50718], [     0.15995,      0.34500,      0.32480]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.12873,     -0.67455,      2.08400], [    -0.13389,      0.70628,      1.95505]]\n",
      "REAL:\n",
      "[[    -0.31430,     -1.02671,      3.14300], [    -0.30916,      0.74329,      3.27900]]\n",
      "DIFFERENCE:\n",
      "[[     0.18557,      0.35216,      1.05900], [     0.17527,      0.03701,      1.32395]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.10328,     -0.56192,      1.97504], [    -0.10327,      0.64904,      1.88703]]\n",
      "REAL:\n",
      "[[    -0.02617,     -0.66037,      2.11400], [    -0.03380,      0.93092,      2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.07711,      0.09845,      0.13896], [     0.06947,      0.28188,      0.32947]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14137,     -0.58938,      2.05284], [    -0.13947,      0.68608,      1.96577]]\n",
      "REAL:\n",
      "[[    -0.03229,     -0.63381,      2.80800], [     0.00230,      1.04900,      2.50900]]\n",
      "DIFFERENCE:\n",
      "[[     0.10908,      0.04443,      0.75516], [     0.14177,      0.36292,      0.54323]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "REAL:\n",
      "ESTIMATED:\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#             PC_realAxis = CreateAxisCloud(SEG_REAL)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m             PC_predAxis \u001b[38;5;241m=\u001b[39m CreateAxisCloud(SEG_ESTI)\n\u001b[0;32m---> 53\u001b[0m             \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_geometries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mPC_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPC_predAxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> BATCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <-- | --> ROW: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "val_err = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(val_loader):\n",
    "#         Apply the model\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = X_invNorm[0].numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "#             RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "    \n",
    "            X1E = y_val[j][0].cpu().numpy()\n",
    "            Y1E = y_val[j][1].cpu().numpy()\n",
    "            Z1E = y_val[j][2].cpu().numpy()\n",
    "            \n",
    "            X2E = y_val[j][3].cpu().numpy()\n",
    "            Y2E = y_val[j][4].cpu().numpy()\n",
    "            Z2E = y_val[j][5].cpu().numpy()\n",
    "            \n",
    "            X1R = y_validation[j][0].cpu().numpy()\n",
    "            Y1R = y_validation[j][1].cpu().numpy()\n",
    "            Z1R = y_validation[j][2].cpu().numpy()\n",
    "            \n",
    "            X2R = y_validation[j][3].cpu().numpy()\n",
    "            Y2R = y_validation[j][4].cpu().numpy()\n",
    "            Z2R = y_validation[j][5].cpu().numpy()\n",
    "            \n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'REAL:')\n",
    "            SEG_REAL = convert_csv([X1R, Y1R, Z1R],  [X2R, Y2R, Z2R])\n",
    "            \n",
    "            print(f'ESTIMATED:')\n",
    "            SEG_ESTI = convert_csv([X1E, Y1E, Z1E],  [X2E, Y2E, Z2E])\n",
    "            \n",
    "#             tp, fp, fn, tn = smp.metrics.get_stats(torch.Tensor(SEG_ESTI).long(), torch.Tensor(SEG_REAL).long(), mode='binary', threshold=0.1)\n",
    "#             err = smp.metrics.f1_score(tp, fp, fn, tn)\n",
    "#             err = LossFCN(torch.Tensor(SEG_ESTI), torch.Tensor(SEG_REAL))\n",
    "#             val_err.append(err.cpu().detach().numpy())\n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            \n",
    "            DEPTH_buff = X_invNorm[1].numpy()*5500\n",
    "            \n",
    "            PC_object = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "#             PC_realAxis = CreateAxisCloud(SEG_REAL)\n",
    "            PC_predAxis = CreateAxisCloud(SEG_ESTI)\n",
    "            \n",
    "            o3d.visualization.draw_geometries([PC_object,PC_predAxis])\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())# \n",
    "#             print(diff)\n",
    "            val_err.append([diff[j][0], diff[j][1], diff[j][2], diff[j][3], diff[j][4], diff[j][5]])\n",
    "#             print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            \n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "# loss = criterion(y_val, y_validation.cuda())\n",
    "# diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "# print(f'RMSE: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ac8d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:27:47.957812Z",
     "start_time": "2023-02-03T22:27:47.953366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN XYZ0: 0.2172006368637085\n",
      " STD XYZ0: 0.12040547281503677\n",
      "MEAN XYZ1: 0.16703279316425323\n",
      " STD XYZ1: 0.08438583463430405\n",
      "MEAN XYZ2: 0.19939564168453217\n",
      " STD XYZ2: 0.08229247480630875\n",
      "MEAN XYZ3: 0.27692553400993347\n",
      " STD XYZ3: 0.12916994094848633\n",
      "MEAN XYZ4: 0.5221603512763977\n",
      " STD XYZ4: 0.48801806569099426\n",
      "MEAN XYZ5: 0.16588915884494781\n",
      " STD XYZ5: 0.10219450294971466\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(f'MEAN XYZ{i}: {np.mean(val_err[i])}')\n",
    "    print(f' STD XYZ{i}: {np.std(val_err[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37cf8455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T22:27:48.200246Z",
     "start_time": "2023-02-03T22:27:48.194678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12040547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(val_err[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82fe71f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-03T23:24:27.724788Z",
     "start_time": "2023-02-03T23:24:25.776588Z"
    }
   },
   "outputs": [],
   "source": [
    "# aaa\n",
    "Model.eval()\n",
    "\n",
    "num = 5 #6 8 11 19 30 #1 8 12 23 31\n",
    "One_photo_x = X_validation[num].reshape(1,\n",
    "                                      X_validation[num].shape[0],\n",
    "                                      X_validation[num].shape[1],\n",
    "                                      X_validation[num].shape[2]\n",
    "                                     )\n",
    "\n",
    "One_photo_y = y_validation[num]\n",
    "\n",
    "# One_photo_x = X_test[num].reshape(1,\n",
    "#                                       X_test[num].shape[0],\n",
    "#                                       X_test[num].shape[1],\n",
    "#                                       X_test[num].shape[2]\n",
    "#                                      )\n",
    "\n",
    "# One_photo_y = y_test[num].reshape(1,\n",
    "#                                       y_test[num].shape[0],\n",
    "#                                       y_test[num].shape[1],\n",
    "#                                       y_test[num].shape[2]\n",
    "#                                      ).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val = Model(One_photo_x)\n",
    "\n",
    "    images_buff = inv_resize(One_photo_x[0])\n",
    "    RGB_buff = images_buff[0].cpu().numpy()*255\n",
    "    RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "    X1E = y_val[0][0].cpu().numpy()\n",
    "    Y1E = y_val[0][1].cpu().numpy()\n",
    "    Z1E = y_val[0][2].cpu().numpy()\n",
    "\n",
    "    X2E = y_val[0][3].cpu().numpy()\n",
    "    Y2E = y_val[0][4].cpu().numpy()\n",
    "    Z2E = y_val[0][5].cpu().numpy()\n",
    "\n",
    "    X1R = One_photo_y[0].cpu().numpy()\n",
    "    Y1R = One_photo_y[1].cpu().numpy()\n",
    "    Z1R = One_photo_y[2].cpu().numpy()\n",
    "\n",
    "    X2R = One_photo_y[3].cpu().numpy()\n",
    "    Y2R = One_photo_y[4].cpu().numpy()\n",
    "    Z2R = One_photo_y[5].cpu().numpy()\n",
    "\n",
    "    SEG_REAL = convert_csv([X1R, Y1R, Z1R],  [X2R, Y2R, Z2R])\n",
    "    SEG_ESTI = convert_csv([X1E, Y1E, Z1E],  [X2E, Y2E, Z2E])\n",
    "    \n",
    "    DEPTH_buff = images_buff[1].numpy()*5500\n",
    "    \n",
    "    PC_object = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "    PC_realAxis = CreateAxisCloud(SEG_REAL)\n",
    "    PC_predAxis = CreateAxisCloud(SEG_ESTI)\n",
    "\n",
    "#     o3d.visualization.draw_geometries([PC_object, PC_realAxis])\n",
    "    o3d.visualization.draw_geometries([PC_object, PC_predAxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f5ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
