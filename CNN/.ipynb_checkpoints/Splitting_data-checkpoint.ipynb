{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1329c18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:42.377443Z",
     "start_time": "2022-12-08T14:01:39.801855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import open3d as o3d\n",
    "\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf2dd0",
   "metadata": {},
   "source": [
    "# Wczytanie pliku .csv\n",
    "Zaczynamy od wczytania pliku csv w którym są zapisane ścieżki do poszczególnych zdjęć oraz współrzędne punktów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6818c902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:42.417949Z",
     "start_time": "2022-12-08T14:01:42.379137Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./files/data.csv') \n",
    "df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1beb3411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:42.456418Z",
     "start_time": "2022-12-08T14:01:42.419299Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ce45e",
   "metadata": {},
   "source": [
    "# Funkcje\n",
    "Stworzenie fukncji, które tłumaczą pliki na język matematyczny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb2102a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:42.473349Z",
     "start_time": "2022-12-08T14:01:42.459446Z"
    }
   },
   "outputs": [],
   "source": [
    "TrasformData = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "ResizeData = transforms.Resize(480)\n",
    "\n",
    "\n",
    "def load_rgb_dataset(top_dir='./files/images/rgb_img_I'):\n",
    "    images_dataset = []\n",
    "    for root, dirs, files in os.walk(top_dir):\n",
    "        for name in files:\n",
    "            # print(os.path.join(root, name))\n",
    "            img = np.array(Image.open(os.path.join(root, name)))\n",
    "            np.array(images_dataset.append(img))\n",
    "    return np.array(images_dataset)\n",
    "\n",
    "def load_depth_dataset(depth_series, row=0):    \n",
    "    depth_dataset = []\n",
    "    for n in range(depth_series.shape[0]):\n",
    "        depth = np.array(np.load(depth_series.iloc[n,row]))\n",
    "        np.array(depth_dataset.append(depth))\n",
    "    \n",
    "    return np.array(depth_dataset)\n",
    "\n",
    "def NormImage(img,div_val,reshape=False,transform=False):\n",
    "    if reshape == True:\n",
    "        img = img.reshape((img.shape[0], img.shape[1], img.shape[2], 1))\n",
    "                    \n",
    "    img = img.transpose(0,3,1,2)\n",
    "    img = torch.FloatTensor(img).div(div_val)\n",
    "    if transform == True:\n",
    "        img = TrasformData(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68719e44",
   "metadata": {},
   "source": [
    "# Załadowanie danych\n",
    "Ładujemy dane do zmiennych a następnie odpowiednio przekształcamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b130e12a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:44.244445Z",
     "start_time": "2022-12-08T14:01:42.475103Z"
    }
   },
   "outputs": [],
   "source": [
    "RGBimg_begin = load_rgb_dataset('./files/images/rgb_img_I')\n",
    "RGBimg_end = load_rgb_dataset('./files/images/rgb_img_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201c2d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:44.797148Z",
     "start_time": "2022-12-08T14:01:44.246136Z"
    }
   },
   "outputs": [],
   "source": [
    "DEPTHimg_begin = load_depth_dataset(df_INPUT_DEPTH,0)\n",
    "DEPTHimg_end = load_depth_dataset(df_INPUT_DEPTH,1)\n",
    "# print(DEPTHimg_end[30][400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e31d631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:46.291793Z",
     "start_time": "2022-12-08T14:01:44.798494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([155, 3, 480, 640])\n",
      "torch.Size([155, 6, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "# Taking first rgb image\n",
    "rgb_in = NormImage(RGBimg_begin,255,transform=True)\n",
    "\n",
    "# Taking depth beginning state of the movement\n",
    "depthBeg_in = NormImage(DEPTHimg_begin,65535,reshape=True)\n",
    "\n",
    "# Taking depth end state of the movement\n",
    "depthEnd_in = NormImage(DEPTHimg_end,65535,reshape=True)\n",
    "\n",
    "# Taking depth difference between movements\n",
    "depthDiff_in = NormImage(abs(DEPTHimg_begin - DEPTHimg_end),65535,reshape=True)\n",
    "\n",
    "# Taking outputs\n",
    "axis_out = df_OUTPUT.values\n",
    "axis_out = torch.Tensor(axis_out)\n",
    "\n",
    "# Connected input for model\n",
    "DDD_in = torch.cat((depthBeg_in, depthEnd_in, depthDiff_in),axis=1)\n",
    "# DDD_in = TrasformData(DDD_in)\n",
    "print(DDD_in.shape)\n",
    "\n",
    "RGBD_input = ResizeData(torch.cat((rgb_in, DDD_in),axis=1))\n",
    "print(RGBD_input.shape)\n",
    "# RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0844fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:46.295063Z",
     "start_time": "2022-12-08T14:01:46.293162Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(RGBD_input[30][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d92a",
   "metadata": {},
   "source": [
    "# RGB + D \n",
    "Na wejście do modelu zostanie podany tensor zawieający kombinację RGB + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2280a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:46.475003Z",
     "start_time": "2022-12-08T14:01:46.295967Z"
    }
   },
   "outputs": [],
   "source": [
    "# rgb_inTensor = torch.tensor(rgb_in.astype(float), dtype=torch.float)\n",
    "# depth_inTensor = torch.tensor(depth_in.astype(float), dtype=torch.float)\n",
    "# axis_outTensor = torch.tensor(axis_out.astype(float), dtype=torch.float)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(RGBD_input, axis_out, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffca8d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:46.893944Z",
     "start_time": "2022-12-08T14:01:46.889383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 480, 640])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23db3ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:47.322454Z",
     "start_time": "2022-12-08T14:01:47.318247Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_trainDataset = TensorDataset(X_train, y_train)\n",
    "AoRD_validationDataset = TensorDataset(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:47.925002Z",
     "start_time": "2022-12-08T14:01:47.918009Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AoRD_trainDataset, batch_size=5, shuffle=True)\n",
    "validation_loader = DataLoader(AoRD_validationDataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23f0d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:48.408280Z",
     "start_time": "2022-12-08T14:01:48.404405Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(rgb_in[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e61e9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:48.628217Z",
     "start_time": "2022-12-08T14:01:48.624254Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResNetModel = models.resnet101(pretrained=False)\n",
    "# ResNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "962968f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:49.185690Z",
     "start_time": "2022-12-08T14:01:49.181214Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResNetModel.conv1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159076ba",
   "metadata": {},
   "source": [
    "# Wyciąganie pojedyńczego elementu z batcha\n",
    "Można zrobić to na kilka sposobów, ale ten jest najszybszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab99ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:14:36.642765Z",
     "start_time": "2022-12-07T23:14:36.356013Z"
    }
   },
   "outputs": [],
   "source": [
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f83ac1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:14:36.647087Z",
     "start_time": "2022-12-07T23:14:36.644069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "# Stworzenie modelu\n",
    "Nazwałem model AoRNet od angielsiego **A**xis **o**f **R**rotation oraz od nazwy modelu matki Res**Net**`u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e0db1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:55.438867Z",
     "start_time": "2022-12-08T14:01:55.430160Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=6, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a67d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:57.572299Z",
     "start_time": "2022-12-08T14:01:56.096715Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = AoRNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0f079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:57.579139Z",
     "start_time": "2022-12-08T14:01:57.574570Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7793f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:01:59.885649Z",
     "start_time": "2022-12-08T14:01:59.881820Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>8}')\n",
    "    print(f'________\\n{sum(params):>8}')\n",
    "# count_parameters(My_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad777bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:45:18.817760Z",
     "start_time": "2022-12-07T23:14:38.016739Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch: 1  loss: 2.77987123\n",
      "epoch:  1  batch: 2  loss: 2.13590026\n",
      "epoch:  1  batch: 3  loss: 0.40691528\n",
      "epoch:  1  batch: 4  loss: 0.40870586\n",
      "epoch:  1  batch: 5  loss: 0.25745320\n",
      "epoch:  1  batch: 6  loss: 0.13410991\n",
      "epoch:  1  batch: 7  loss: 0.08647025\n",
      "epoch:  1  batch: 8  loss: 0.09429970\n",
      "epoch:  1  batch: 9  loss: 0.05336744\n",
      "epoch:  1  batch: 10  loss: 0.27108589\n",
      "epoch:  1  batch: 11  loss: 0.11276813\n",
      "epoch:  1  batch: 12  loss: 0.07010373\n",
      "epoch:  1  batch: 13  loss: 0.08267649\n",
      "epoch:  1  batch: 14  loss: 0.07709704\n",
      "epoch:  1  batch: 15  loss: 0.09936238\n",
      "epoch:  1  batch: 16  loss: 0.06645229\n",
      "epoch:  1  batch: 17  loss: 0.07738516\n",
      "epoch:  1  batch: 18  loss: 0.11031090\n",
      "epoch:  1  batch: 19  loss: 0.07467216\n",
      "epoch:  1  batch: 20  loss: 0.12405441\n",
      "epoch:  1  batch: 21  loss: 0.06330313\n",
      "epoch:  1  batch: 22  loss: 0.03751905\n",
      "epoch:  1  batch: 23  loss: 0.05915470\n",
      "epoch:  1  batch: 24  loss: 0.08281343\n",
      "epoch:  1  batch: 25  loss: 0.02921475\n",
      "epoch:  1  batch: 26  loss: 0.01852662\n",
      "epoch:  1  batch: 27  loss: 0.07754225\n",
      "epoch:  1  batch: 28  loss: 0.09534308\n",
      "epoch:  2  batch: 1  loss: 0.04633045\n",
      "epoch:  2  batch: 2  loss: 0.05605972\n",
      "epoch:  2  batch: 3  loss: 0.03018265\n",
      "epoch:  2  batch: 4  loss: 0.10638499\n",
      "epoch:  2  batch: 5  loss: 0.06030808\n",
      "epoch:  2  batch: 6  loss: 0.04506664\n",
      "epoch:  2  batch: 7  loss: 0.06630015\n",
      "epoch:  2  batch: 8  loss: 0.04633516\n",
      "epoch:  2  batch: 9  loss: 0.05628241\n",
      "epoch:  2  batch: 10  loss: 0.03798328\n",
      "epoch:  2  batch: 11  loss: 0.03248792\n",
      "epoch:  2  batch: 12  loss: 0.03240392\n",
      "epoch:  2  batch: 13  loss: 0.08392441\n",
      "epoch:  2  batch: 14  loss: 0.08486660\n",
      "epoch:  2  batch: 15  loss: 0.03091986\n",
      "epoch:  2  batch: 16  loss: 0.04463234\n",
      "epoch:  2  batch: 17  loss: 0.02973764\n",
      "epoch:  2  batch: 18  loss: 0.13009508\n",
      "epoch:  2  batch: 19  loss: 0.07523081\n",
      "epoch:  2  batch: 20  loss: 0.03810570\n",
      "epoch:  2  batch: 21  loss: 0.09549868\n",
      "epoch:  2  batch: 22  loss: 0.09335738\n",
      "epoch:  2  batch: 23  loss: 0.08631703\n",
      "epoch:  2  batch: 24  loss: 0.10858878\n",
      "epoch:  2  batch: 25  loss: 0.02606161\n",
      "epoch:  2  batch: 26  loss: 0.06721991\n",
      "epoch:  2  batch: 27  loss: 0.16297925\n",
      "epoch:  2  batch: 28  loss: 0.05449471\n",
      "epoch:  3  batch: 1  loss: 0.03282836\n",
      "epoch:  3  batch: 2  loss: 0.04545240\n",
      "epoch:  3  batch: 3  loss: 0.03466252\n",
      "epoch:  3  batch: 4  loss: 0.01279610\n",
      "epoch:  3  batch: 5  loss: 0.04214213\n",
      "epoch:  3  batch: 6  loss: 0.03981265\n",
      "epoch:  3  batch: 7  loss: 0.24766050\n",
      "epoch:  3  batch: 8  loss: 0.14784321\n",
      "epoch:  3  batch: 9  loss: 0.07800132\n",
      "epoch:  3  batch: 10  loss: 0.24462233\n",
      "epoch:  3  batch: 11  loss: 0.06773756\n",
      "epoch:  3  batch: 12  loss: 0.08485631\n",
      "epoch:  3  batch: 13  loss: 0.04945923\n",
      "epoch:  3  batch: 14  loss: 0.04104543\n",
      "epoch:  3  batch: 15  loss: 0.04793167\n",
      "epoch:  3  batch: 16  loss: 0.02212637\n",
      "epoch:  3  batch: 17  loss: 0.05586292\n",
      "epoch:  3  batch: 18  loss: 0.02760725\n",
      "epoch:  3  batch: 19  loss: 0.03422258\n",
      "epoch:  3  batch: 20  loss: 0.06542096\n",
      "epoch:  3  batch: 21  loss: 0.09566461\n",
      "epoch:  3  batch: 22  loss: 0.04440341\n",
      "epoch:  3  batch: 23  loss: 0.05016442\n",
      "epoch:  3  batch: 24  loss: 0.04385750\n",
      "epoch:  3  batch: 25  loss: 0.01631705\n",
      "epoch:  3  batch: 26  loss: 0.07267352\n",
      "epoch:  3  batch: 27  loss: 0.01280031\n",
      "epoch:  3  batch: 28  loss: 0.07188457\n",
      "epoch:  4  batch: 1  loss: 0.16974443\n",
      "epoch:  4  batch: 2  loss: 0.02032172\n",
      "epoch:  4  batch: 3  loss: 0.04141399\n",
      "epoch:  4  batch: 4  loss: 0.03395881\n",
      "epoch:  4  batch: 5  loss: 0.15535180\n",
      "epoch:  4  batch: 6  loss: 0.05321097\n",
      "epoch:  4  batch: 7  loss: 0.02443228\n",
      "epoch:  4  batch: 8  loss: 0.02802687\n",
      "epoch:  4  batch: 9  loss: 0.04726906\n",
      "epoch:  4  batch: 10  loss: 0.04164595\n",
      "epoch:  4  batch: 11  loss: 0.10379770\n",
      "epoch:  4  batch: 12  loss: 0.17501637\n",
      "epoch:  4  batch: 13  loss: 0.09433489\n",
      "epoch:  4  batch: 14  loss: 0.04757134\n",
      "epoch:  4  batch: 15  loss: 0.02589317\n",
      "epoch:  4  batch: 16  loss: 0.12549549\n",
      "epoch:  4  batch: 17  loss: 0.07694450\n",
      "epoch:  4  batch: 18  loss: 0.03204964\n",
      "epoch:  4  batch: 19  loss: 0.07518047\n",
      "epoch:  4  batch: 20  loss: 0.11785802\n",
      "epoch:  4  batch: 21  loss: 0.08817381\n",
      "epoch:  4  batch: 22  loss: 0.03976520\n",
      "epoch:  4  batch: 23  loss: 0.07804270\n",
      "epoch:  4  batch: 24  loss: 0.06144642\n",
      "epoch:  4  batch: 25  loss: 0.06614953\n",
      "epoch:  4  batch: 26  loss: 0.03102066\n",
      "epoch:  4  batch: 27  loss: 0.21216756\n",
      "epoch:  4  batch: 28  loss: 0.07818297\n",
      "epoch:  5  batch: 1  loss: 0.15479051\n",
      "epoch:  5  batch: 2  loss: 0.09491672\n",
      "epoch:  5  batch: 3  loss: 0.09248880\n",
      "epoch:  5  batch: 4  loss: 0.06091038\n",
      "epoch:  5  batch: 5  loss: 0.04626242\n",
      "epoch:  5  batch: 6  loss: 0.09210069\n",
      "epoch:  5  batch: 7  loss: 0.07846688\n",
      "epoch:  5  batch: 8  loss: 0.07737114\n",
      "epoch:  5  batch: 9  loss: 0.04796891\n",
      "epoch:  5  batch: 10  loss: 0.04018494\n",
      "epoch:  5  batch: 11  loss: 0.02299896\n",
      "epoch:  5  batch: 12  loss: 0.08988739\n",
      "epoch:  5  batch: 13  loss: 0.03235662\n",
      "epoch:  5  batch: 14  loss: 0.14762911\n",
      "epoch:  5  batch: 15  loss: 0.08081991\n",
      "epoch:  5  batch: 16  loss: 0.09156234\n",
      "epoch:  5  batch: 17  loss: 0.03997863\n",
      "epoch:  5  batch: 18  loss: 0.10120766\n",
      "epoch:  5  batch: 19  loss: 0.08077053\n",
      "epoch:  5  batch: 20  loss: 0.07214537\n",
      "epoch:  5  batch: 21  loss: 0.04284023\n",
      "epoch:  5  batch: 22  loss: 0.06247301\n",
      "epoch:  5  batch: 23  loss: 0.03542538\n",
      "epoch:  5  batch: 24  loss: 0.07898352\n",
      "epoch:  5  batch: 25  loss: 0.10488522\n",
      "epoch:  5  batch: 26  loss: 0.07037382\n",
      "epoch:  5  batch: 27  loss: 0.05343248\n",
      "epoch:  5  batch: 28  loss: 0.02497958\n",
      "epoch:  6  batch: 1  loss: 0.07629210\n",
      "epoch:  6  batch: 2  loss: 0.06056058\n",
      "epoch:  6  batch: 3  loss: 0.05833529\n",
      "epoch:  6  batch: 4  loss: 0.04167655\n",
      "epoch:  6  batch: 5  loss: 0.11506909\n",
      "epoch:  6  batch: 6  loss: 0.05248838\n",
      "epoch:  6  batch: 7  loss: 0.05950495\n",
      "epoch:  6  batch: 8  loss: 0.03225505\n",
      "epoch:  6  batch: 9  loss: 0.12480127\n",
      "epoch:  6  batch: 10  loss: 0.08972858\n",
      "epoch:  6  batch: 11  loss: 0.07259147\n",
      "epoch:  6  batch: 12  loss: 0.07016615\n",
      "epoch:  6  batch: 13  loss: 0.03265576\n",
      "epoch:  6  batch: 14  loss: 0.09780908\n",
      "epoch:  6  batch: 15  loss: 0.11572055\n",
      "epoch:  6  batch: 16  loss: 0.31284827\n",
      "epoch:  6  batch: 17  loss: 0.03755388\n",
      "epoch:  6  batch: 18  loss: 0.03833826\n",
      "epoch:  6  batch: 19  loss: 0.05589021\n",
      "epoch:  6  batch: 20  loss: 0.06110995\n",
      "epoch:  6  batch: 21  loss: 0.05876996\n",
      "epoch:  6  batch: 22  loss: 0.06678241\n",
      "epoch:  6  batch: 23  loss: 0.02413709\n",
      "epoch:  6  batch: 24  loss: 0.03602419\n",
      "epoch:  6  batch: 25  loss: 0.10155295\n",
      "epoch:  6  batch: 26  loss: 0.06121311\n",
      "epoch:  6  batch: 27  loss: 0.04093312\n",
      "epoch:  6  batch: 28  loss: 0.04175318\n",
      "epoch:  7  batch: 1  loss: 0.03804007\n",
      "epoch:  7  batch: 2  loss: 0.07440931\n",
      "epoch:  7  batch: 3  loss: 0.03267314\n",
      "epoch:  7  batch: 4  loss: 0.04940008\n",
      "epoch:  7  batch: 5  loss: 0.02916537\n",
      "epoch:  7  batch: 6  loss: 0.03012806\n",
      "epoch:  7  batch: 7  loss: 0.01049268\n",
      "epoch:  7  batch: 8  loss: 0.03907844\n",
      "epoch:  7  batch: 9  loss: 0.05066713\n",
      "epoch:  7  batch: 10  loss: 0.04630071\n",
      "epoch:  7  batch: 11  loss: 0.03277856\n",
      "epoch:  7  batch: 12  loss: 0.04040510\n",
      "epoch:  7  batch: 13  loss: 0.05586228\n",
      "epoch:  7  batch: 14  loss: 0.05282823\n",
      "epoch:  7  batch: 15  loss: 0.03877528\n",
      "epoch:  7  batch: 16  loss: 0.02361304\n",
      "epoch:  7  batch: 17  loss: 0.02994070\n",
      "epoch:  7  batch: 18  loss: 0.05942586\n",
      "epoch:  7  batch: 19  loss: 0.04810573\n",
      "epoch:  7  batch: 20  loss: 0.01733328\n",
      "epoch:  7  batch: 21  loss: 0.01700611\n",
      "epoch:  7  batch: 22  loss: 0.07525341\n",
      "epoch:  7  batch: 23  loss: 0.02253733\n",
      "epoch:  7  batch: 24  loss: 0.01686703\n",
      "epoch:  7  batch: 25  loss: 0.02444189\n",
      "epoch:  7  batch: 26  loss: 0.02108496\n",
      "epoch:  7  batch: 27  loss: 0.02275494\n",
      "epoch:  7  batch: 28  loss: 0.05580629\n",
      "epoch:  8  batch: 1  loss: 0.05732366\n",
      "epoch:  8  batch: 2  loss: 0.01688426\n",
      "epoch:  8  batch: 3  loss: 0.01894782\n",
      "epoch:  8  batch: 4  loss: 0.07627367\n",
      "epoch:  8  batch: 5  loss: 0.04190228\n",
      "epoch:  8  batch: 6  loss: 0.10421745\n",
      "epoch:  8  batch: 7  loss: 0.01523057\n",
      "epoch:  8  batch: 8  loss: 0.07254640\n",
      "epoch:  8  batch: 9  loss: 0.07242566\n",
      "epoch:  8  batch: 10  loss: 0.01979998\n",
      "epoch:  8  batch: 11  loss: 0.04038358\n",
      "epoch:  8  batch: 12  loss: 0.07313457\n",
      "epoch:  8  batch: 13  loss: 0.05539403\n",
      "epoch:  8  batch: 14  loss: 0.01584340\n",
      "epoch:  8  batch: 15  loss: 0.01051366\n",
      "epoch:  8  batch: 16  loss: 0.05352379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8  batch: 17  loss: 0.03073475\n",
      "epoch:  8  batch: 18  loss: 0.02411196\n",
      "epoch:  8  batch: 19  loss: 0.01096667\n",
      "epoch:  8  batch: 20  loss: 0.02920349\n",
      "epoch:  8  batch: 21  loss: 0.03204548\n",
      "epoch:  8  batch: 22  loss: 0.06185277\n",
      "epoch:  8  batch: 23  loss: 0.01997651\n",
      "epoch:  8  batch: 24  loss: 0.04428843\n",
      "epoch:  8  batch: 25  loss: 0.03709837\n",
      "epoch:  8  batch: 26  loss: 0.01388501\n",
      "epoch:  8  batch: 27  loss: 0.02052389\n",
      "epoch:  8  batch: 28  loss: 0.01125665\n",
      "epoch:  9  batch: 1  loss: 0.03055094\n",
      "epoch:  9  batch: 2  loss: 0.04751106\n",
      "epoch:  9  batch: 3  loss: 0.03224637\n",
      "epoch:  9  batch: 4  loss: 0.01474689\n",
      "epoch:  9  batch: 5  loss: 0.07403738\n",
      "epoch:  9  batch: 6  loss: 0.02731878\n",
      "epoch:  9  batch: 7  loss: 0.02051228\n",
      "epoch:  9  batch: 8  loss: 0.05491201\n",
      "epoch:  9  batch: 9  loss: 0.03595900\n",
      "epoch:  9  batch: 10  loss: 0.03837840\n",
      "epoch:  9  batch: 11  loss: 0.01810339\n",
      "epoch:  9  batch: 12  loss: 0.04211831\n",
      "epoch:  9  batch: 13  loss: 0.06902790\n",
      "epoch:  9  batch: 14  loss: 0.03512242\n",
      "epoch:  9  batch: 15  loss: 0.03749043\n",
      "epoch:  9  batch: 16  loss: 0.04299006\n",
      "epoch:  9  batch: 17  loss: 0.02902781\n",
      "epoch:  9  batch: 18  loss: 0.13421237\n",
      "epoch:  9  batch: 19  loss: 0.07667973\n",
      "epoch:  9  batch: 20  loss: 0.16750976\n",
      "epoch:  9  batch: 21  loss: 0.06413583\n",
      "epoch:  9  batch: 22  loss: 0.05270012\n",
      "epoch:  9  batch: 23  loss: 0.03446313\n",
      "epoch:  9  batch: 24  loss: 0.04444643\n",
      "epoch:  9  batch: 25  loss: 0.08334928\n",
      "epoch:  9  batch: 26  loss: 0.01571129\n",
      "epoch:  9  batch: 27  loss: 0.01658596\n",
      "epoch:  9  batch: 28  loss: 0.04550613\n",
      "epoch: 10  batch: 1  loss: 0.02604922\n",
      "epoch: 10  batch: 2  loss: 0.03618441\n",
      "epoch: 10  batch: 3  loss: 0.05538091\n",
      "epoch: 10  batch: 4  loss: 0.02957402\n",
      "epoch: 10  batch: 5  loss: 0.04388626\n",
      "epoch: 10  batch: 6  loss: 0.04044744\n",
      "epoch: 10  batch: 7  loss: 0.03849287\n",
      "epoch: 10  batch: 8  loss: 0.04306947\n",
      "epoch: 10  batch: 9  loss: 0.04150038\n",
      "epoch: 10  batch: 10  loss: 0.01995192\n",
      "epoch: 10  batch: 11  loss: 0.03141047\n",
      "epoch: 10  batch: 12  loss: 0.02789333\n",
      "epoch: 10  batch: 13  loss: 0.02353094\n",
      "epoch: 10  batch: 14  loss: 0.03486529\n",
      "epoch: 10  batch: 15  loss: 0.11065746\n",
      "epoch: 10  batch: 16  loss: 0.05275312\n",
      "epoch: 10  batch: 17  loss: 0.02858207\n",
      "epoch: 10  batch: 18  loss: 0.04041293\n",
      "epoch: 10  batch: 19  loss: 0.05957606\n",
      "epoch: 10  batch: 20  loss: 0.02023464\n",
      "epoch: 10  batch: 21  loss: 0.06412423\n",
      "epoch: 10  batch: 22  loss: 0.04553438\n",
      "epoch: 10  batch: 23  loss: 0.04372499\n",
      "epoch: 10  batch: 24  loss: 0.10512985\n",
      "epoch: 10  batch: 25  loss: 0.09661045\n",
      "epoch: 10  batch: 26  loss: 0.17159297\n",
      "epoch: 10  batch: 27  loss: 0.04775926\n",
      "epoch: 10  batch: 28  loss: 0.04336892\n",
      "epoch: 11  batch: 1  loss: 0.06640916\n",
      "epoch: 11  batch: 2  loss: 0.17673185\n",
      "epoch: 11  batch: 3  loss: 0.07104456\n",
      "epoch: 11  batch: 4  loss: 0.02413499\n",
      "epoch: 11  batch: 5  loss: 0.02762918\n",
      "epoch: 11  batch: 6  loss: 0.00630607\n",
      "epoch: 11  batch: 7  loss: 0.03101148\n",
      "epoch: 11  batch: 8  loss: 0.12931067\n",
      "epoch: 11  batch: 9  loss: 0.13069120\n",
      "epoch: 11  batch: 10  loss: 0.03358706\n",
      "epoch: 11  batch: 11  loss: 0.10484295\n",
      "epoch: 11  batch: 12  loss: 0.05465726\n",
      "epoch: 11  batch: 13  loss: 0.05436198\n",
      "epoch: 11  batch: 14  loss: 0.02065216\n",
      "epoch: 11  batch: 15  loss: 0.01602506\n",
      "epoch: 11  batch: 16  loss: 0.03884244\n",
      "epoch: 11  batch: 17  loss: 0.06629151\n",
      "epoch: 11  batch: 18  loss: 0.03950368\n",
      "epoch: 11  batch: 19  loss: 0.01915875\n",
      "epoch: 11  batch: 20  loss: 0.04102117\n",
      "epoch: 11  batch: 21  loss: 0.03296281\n",
      "epoch: 11  batch: 22  loss: 0.02318832\n",
      "epoch: 11  batch: 23  loss: 0.01869234\n",
      "epoch: 11  batch: 24  loss: 0.06327932\n",
      "epoch: 11  batch: 25  loss: 0.11493935\n",
      "epoch: 11  batch: 26  loss: 0.04853540\n",
      "epoch: 11  batch: 27  loss: 0.03541757\n",
      "epoch: 11  batch: 28  loss: 0.01203201\n",
      "epoch: 12  batch: 1  loss: 0.02893500\n",
      "epoch: 12  batch: 2  loss: 0.06620224\n",
      "epoch: 12  batch: 3  loss: 0.03156856\n",
      "epoch: 12  batch: 4  loss: 0.02518587\n",
      "epoch: 12  batch: 5  loss: 0.02389310\n",
      "epoch: 12  batch: 6  loss: 0.03519382\n",
      "epoch: 12  batch: 7  loss: 0.01676003\n",
      "epoch: 12  batch: 8  loss: 0.08114854\n",
      "epoch: 12  batch: 9  loss: 0.03017987\n",
      "epoch: 12  batch: 10  loss: 0.06564680\n",
      "epoch: 12  batch: 11  loss: 0.04159347\n",
      "epoch: 12  batch: 12  loss: 0.03184563\n",
      "epoch: 12  batch: 13  loss: 0.01264010\n",
      "epoch: 12  batch: 14  loss: 0.03005324\n",
      "epoch: 12  batch: 15  loss: 0.01694231\n",
      "epoch: 12  batch: 16  loss: 0.02799129\n",
      "epoch: 12  batch: 17  loss: 0.01986214\n",
      "epoch: 12  batch: 18  loss: 0.02159201\n",
      "epoch: 12  batch: 19  loss: 0.01733527\n",
      "epoch: 12  batch: 20  loss: 0.12446576\n",
      "epoch: 12  batch: 21  loss: 0.03477632\n",
      "epoch: 12  batch: 22  loss: 0.01918419\n",
      "epoch: 12  batch: 23  loss: 0.11665256\n",
      "epoch: 12  batch: 24  loss: 0.10594491\n",
      "epoch: 12  batch: 25  loss: 0.01539572\n",
      "epoch: 12  batch: 26  loss: 0.05638485\n",
      "epoch: 12  batch: 27  loss: 0.07924046\n",
      "epoch: 12  batch: 28  loss: 0.03161237\n",
      "epoch: 13  batch: 1  loss: 0.05928991\n",
      "epoch: 13  batch: 2  loss: 0.06247463\n",
      "epoch: 13  batch: 3  loss: 0.04507534\n",
      "epoch: 13  batch: 4  loss: 0.02486010\n",
      "epoch: 13  batch: 5  loss: 0.09627702\n",
      "epoch: 13  batch: 6  loss: 0.13075015\n",
      "epoch: 13  batch: 7  loss: 0.02433466\n",
      "epoch: 13  batch: 8  loss: 0.02525536\n",
      "epoch: 13  batch: 9  loss: 0.02018727\n",
      "epoch: 13  batch: 10  loss: 0.07173008\n",
      "epoch: 13  batch: 11  loss: 0.02911224\n",
      "epoch: 13  batch: 12  loss: 0.14189856\n",
      "epoch: 13  batch: 13  loss: 0.02544112\n",
      "epoch: 13  batch: 14  loss: 0.02478639\n",
      "epoch: 13  batch: 15  loss: 0.02339857\n",
      "epoch: 13  batch: 16  loss: 0.04503997\n",
      "epoch: 13  batch: 17  loss: 0.16612490\n",
      "epoch: 13  batch: 18  loss: 0.04216475\n",
      "epoch: 13  batch: 19  loss: 0.02809710\n",
      "epoch: 13  batch: 20  loss: 0.01908962\n",
      "epoch: 13  batch: 21  loss: 0.06201971\n",
      "epoch: 13  batch: 22  loss: 0.01633790\n",
      "epoch: 13  batch: 23  loss: 0.03566771\n",
      "epoch: 13  batch: 24  loss: 0.02863349\n",
      "epoch: 13  batch: 25  loss: 0.03184806\n",
      "epoch: 13  batch: 26  loss: 0.02035758\n",
      "epoch: 13  batch: 27  loss: 0.03508794\n",
      "epoch: 13  batch: 28  loss: 0.03358940\n",
      "epoch: 14  batch: 1  loss: 0.02724782\n",
      "epoch: 14  batch: 2  loss: 0.02069512\n",
      "epoch: 14  batch: 3  loss: 0.00632946\n",
      "epoch: 14  batch: 4  loss: 0.02881535\n",
      "epoch: 14  batch: 5  loss: 0.02131784\n",
      "epoch: 14  batch: 6  loss: 0.11155041\n",
      "epoch: 14  batch: 7  loss: 0.01434159\n",
      "epoch: 14  batch: 8  loss: 0.01423351\n",
      "epoch: 14  batch: 9  loss: 0.03229360\n",
      "epoch: 14  batch: 10  loss: 0.01920788\n",
      "epoch: 14  batch: 11  loss: 0.01165075\n",
      "epoch: 14  batch: 12  loss: 0.01537871\n",
      "epoch: 14  batch: 13  loss: 0.02921040\n",
      "epoch: 14  batch: 14  loss: 0.04356347\n",
      "epoch: 14  batch: 15  loss: 0.03115661\n",
      "epoch: 14  batch: 16  loss: 0.02365000\n",
      "epoch: 14  batch: 17  loss: 0.04126608\n",
      "epoch: 14  batch: 18  loss: 0.03067140\n",
      "epoch: 14  batch: 19  loss: 0.02859689\n",
      "epoch: 14  batch: 20  loss: 0.04661931\n",
      "epoch: 14  batch: 21  loss: 0.03491282\n",
      "epoch: 14  batch: 22  loss: 0.02069135\n",
      "epoch: 14  batch: 23  loss: 0.06262612\n",
      "epoch: 14  batch: 24  loss: 0.02406734\n",
      "epoch: 14  batch: 25  loss: 0.08666680\n",
      "epoch: 14  batch: 26  loss: 0.07601326\n",
      "epoch: 14  batch: 27  loss: 0.06699558\n",
      "epoch: 14  batch: 28  loss: 0.02846476\n",
      "epoch: 15  batch: 1  loss: 0.03962882\n",
      "epoch: 15  batch: 2  loss: 0.05604155\n",
      "epoch: 15  batch: 3  loss: 0.12235665\n",
      "epoch: 15  batch: 4  loss: 0.03054527\n",
      "epoch: 15  batch: 5  loss: 0.02907111\n",
      "epoch: 15  batch: 6  loss: 0.03554459\n",
      "epoch: 15  batch: 7  loss: 0.14083834\n",
      "epoch: 15  batch: 8  loss: 0.02822016\n",
      "epoch: 15  batch: 9  loss: 0.02923397\n",
      "epoch: 15  batch: 10  loss: 0.10563138\n",
      "epoch: 15  batch: 11  loss: 0.05623737\n",
      "epoch: 15  batch: 12  loss: 0.04107393\n",
      "epoch: 15  batch: 13  loss: 0.03281850\n",
      "epoch: 15  batch: 14  loss: 0.01566657\n",
      "epoch: 15  batch: 15  loss: 0.07659254\n",
      "epoch: 15  batch: 16  loss: 0.03494672\n",
      "epoch: 15  batch: 17  loss: 0.01732071\n",
      "epoch: 15  batch: 18  loss: 0.04023104\n",
      "epoch: 15  batch: 19  loss: 0.03139766\n",
      "epoch: 15  batch: 20  loss: 0.01208917\n",
      "epoch: 15  batch: 21  loss: 0.02783244\n",
      "epoch: 15  batch: 22  loss: 0.02429921\n",
      "epoch: 15  batch: 23  loss: 0.05718733\n",
      "epoch: 15  batch: 24  loss: 0.03093164\n",
      "epoch: 15  batch: 25  loss: 0.03163426\n",
      "epoch: 15  batch: 26  loss: 0.05457403\n",
      "epoch: 15  batch: 27  loss: 0.05647964\n",
      "epoch: 15  batch: 28  loss: 0.35039032\n",
      "epoch: 16  batch: 1  loss: 0.11898118\n",
      "epoch: 16  batch: 2  loss: 0.07339254\n",
      "epoch: 16  batch: 3  loss: 0.06419501\n",
      "epoch: 16  batch: 4  loss: 0.13440000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16  batch: 5  loss: 0.04501213\n",
      "epoch: 16  batch: 6  loss: 0.06077906\n",
      "epoch: 16  batch: 7  loss: 0.07162433\n",
      "epoch: 16  batch: 8  loss: 0.17212296\n",
      "epoch: 16  batch: 9  loss: 0.13831285\n",
      "epoch: 16  batch: 10  loss: 0.04777497\n",
      "epoch: 16  batch: 11  loss: 0.03923805\n",
      "epoch: 16  batch: 12  loss: 0.17826211\n",
      "epoch: 16  batch: 13  loss: 0.04901672\n",
      "epoch: 16  batch: 14  loss: 0.04651303\n",
      "epoch: 16  batch: 15  loss: 0.02177637\n",
      "epoch: 16  batch: 16  loss: 0.05341881\n",
      "epoch: 16  batch: 17  loss: 0.05477630\n",
      "epoch: 16  batch: 18  loss: 0.03114882\n",
      "epoch: 16  batch: 19  loss: 0.03101228\n",
      "epoch: 16  batch: 20  loss: 0.03951875\n",
      "epoch: 16  batch: 21  loss: 0.01806356\n",
      "epoch: 16  batch: 22  loss: 0.03335533\n",
      "epoch: 16  batch: 23  loss: 0.03561433\n",
      "epoch: 16  batch: 24  loss: 0.02659368\n",
      "epoch: 16  batch: 25  loss: 0.01467277\n",
      "epoch: 16  batch: 26  loss: 0.04990435\n",
      "epoch: 16  batch: 27  loss: 0.01887333\n",
      "epoch: 16  batch: 28  loss: 0.01604225\n",
      "epoch: 17  batch: 1  loss: 0.02350834\n",
      "epoch: 17  batch: 2  loss: 0.05623984\n",
      "epoch: 17  batch: 3  loss: 0.01644711\n",
      "epoch: 17  batch: 4  loss: 0.00792821\n",
      "epoch: 17  batch: 5  loss: 0.13419712\n",
      "epoch: 17  batch: 6  loss: 0.02673421\n",
      "epoch: 17  batch: 7  loss: 0.05909431\n",
      "epoch: 17  batch: 8  loss: 0.01889575\n",
      "epoch: 17  batch: 9  loss: 0.05824263\n",
      "epoch: 17  batch: 10  loss: 0.01425863\n",
      "epoch: 17  batch: 11  loss: 0.02034097\n",
      "epoch: 17  batch: 12  loss: 0.03340954\n",
      "epoch: 17  batch: 13  loss: 0.03185806\n",
      "epoch: 17  batch: 14  loss: 0.01053782\n",
      "epoch: 17  batch: 15  loss: 0.03406342\n",
      "epoch: 17  batch: 16  loss: 0.01429988\n",
      "epoch: 17  batch: 17  loss: 0.01758201\n",
      "epoch: 17  batch: 18  loss: 0.03014782\n",
      "epoch: 17  batch: 19  loss: 0.03992534\n",
      "epoch: 17  batch: 20  loss: 0.08017327\n",
      "epoch: 17  batch: 21  loss: 0.00843535\n",
      "epoch: 17  batch: 22  loss: 0.10566738\n",
      "epoch: 17  batch: 23  loss: 0.04596579\n",
      "epoch: 17  batch: 24  loss: 0.20620374\n",
      "epoch: 17  batch: 25  loss: 0.11282025\n",
      "epoch: 17  batch: 26  loss: 0.01789596\n",
      "epoch: 17  batch: 27  loss: 0.03617436\n",
      "epoch: 17  batch: 28  loss: 0.05481098\n",
      "epoch: 18  batch: 1  loss: 0.10783495\n",
      "epoch: 18  batch: 2  loss: 0.12574515\n",
      "epoch: 18  batch: 3  loss: 0.18048018\n",
      "epoch: 18  batch: 4  loss: 0.04850192\n",
      "epoch: 18  batch: 5  loss: 0.03018168\n",
      "epoch: 18  batch: 6  loss: 0.16496859\n",
      "epoch: 18  batch: 7  loss: 0.20650473\n",
      "epoch: 18  batch: 8  loss: 0.11847973\n",
      "epoch: 18  batch: 9  loss: 0.03554071\n",
      "epoch: 18  batch: 10  loss: 0.02037900\n",
      "epoch: 18  batch: 11  loss: 0.04062964\n",
      "epoch: 18  batch: 12  loss: 0.07951556\n",
      "epoch: 18  batch: 13  loss: 0.15733461\n",
      "epoch: 18  batch: 14  loss: 0.07238107\n",
      "epoch: 18  batch: 15  loss: 0.05455621\n",
      "epoch: 18  batch: 16  loss: 0.02333487\n",
      "epoch: 18  batch: 17  loss: 0.01876261\n",
      "epoch: 18  batch: 18  loss: 0.03309800\n",
      "epoch: 18  batch: 19  loss: 0.01730807\n",
      "epoch: 18  batch: 20  loss: 0.09410229\n",
      "epoch: 18  batch: 21  loss: 0.06439444\n",
      "epoch: 18  batch: 22  loss: 0.07841542\n",
      "epoch: 18  batch: 23  loss: 0.02980372\n",
      "epoch: 18  batch: 24  loss: 0.04755626\n",
      "epoch: 18  batch: 25  loss: 0.04730839\n",
      "epoch: 18  batch: 26  loss: 0.04581282\n",
      "epoch: 18  batch: 27  loss: 0.05149690\n",
      "epoch: 18  batch: 28  loss: 0.03945115\n",
      "epoch: 19  batch: 1  loss: 0.03829739\n",
      "epoch: 19  batch: 2  loss: 0.03909222\n",
      "epoch: 19  batch: 3  loss: 0.03932749\n",
      "epoch: 19  batch: 4  loss: 0.01253364\n",
      "epoch: 19  batch: 5  loss: 0.03633226\n",
      "epoch: 19  batch: 6  loss: 0.02039533\n",
      "epoch: 19  batch: 7  loss: 0.04547041\n",
      "epoch: 19  batch: 8  loss: 0.04644314\n",
      "epoch: 19  batch: 9  loss: 0.04132688\n",
      "epoch: 19  batch: 10  loss: 0.03494446\n",
      "epoch: 19  batch: 11  loss: 0.02012948\n",
      "epoch: 19  batch: 12  loss: 0.04030437\n",
      "epoch: 19  batch: 13  loss: 0.03332325\n",
      "epoch: 19  batch: 14  loss: 0.07719050\n",
      "epoch: 19  batch: 15  loss: 0.03444295\n",
      "epoch: 19  batch: 16  loss: 0.08079552\n",
      "epoch: 19  batch: 17  loss: 0.04681499\n",
      "epoch: 19  batch: 18  loss: 0.01627982\n",
      "epoch: 19  batch: 19  loss: 0.02483780\n",
      "epoch: 19  batch: 20  loss: 0.02445139\n",
      "epoch: 19  batch: 21  loss: 0.01621644\n",
      "epoch: 19  batch: 22  loss: 0.02041357\n",
      "epoch: 19  batch: 23  loss: 0.01870223\n",
      "epoch: 19  batch: 24  loss: 0.01467054\n",
      "epoch: 19  batch: 25  loss: 0.02463405\n",
      "epoch: 19  batch: 26  loss: 0.01328911\n",
      "epoch: 19  batch: 27  loss: 0.04478173\n",
      "epoch: 19  batch: 28  loss: 0.01526780\n",
      "epoch: 20  batch: 1  loss: 0.03696806\n",
      "epoch: 20  batch: 2  loss: 0.02434026\n",
      "epoch: 20  batch: 3  loss: 0.02536002\n",
      "epoch: 20  batch: 4  loss: 0.01999227\n",
      "epoch: 20  batch: 5  loss: 0.01792596\n",
      "epoch: 20  batch: 6  loss: 0.05362311\n",
      "epoch: 20  batch: 7  loss: 0.02569427\n",
      "epoch: 20  batch: 8  loss: 0.04007565\n",
      "epoch: 20  batch: 9  loss: 0.03149014\n",
      "epoch: 20  batch: 10  loss: 0.01337483\n",
      "epoch: 20  batch: 11  loss: 0.01651297\n",
      "epoch: 20  batch: 12  loss: 0.00491761\n",
      "epoch: 20  batch: 13  loss: 0.02421999\n",
      "epoch: 20  batch: 14  loss: 0.00950890\n",
      "epoch: 20  batch: 15  loss: 0.00439899\n",
      "epoch: 20  batch: 16  loss: 0.00831974\n",
      "epoch: 20  batch: 17  loss: 0.01745388\n",
      "epoch: 20  batch: 18  loss: 0.00866960\n",
      "epoch: 20  batch: 19  loss: 0.01347243\n",
      "epoch: 20  batch: 20  loss: 0.00860894\n",
      "epoch: 20  batch: 21  loss: 0.03943887\n",
      "epoch: 20  batch: 22  loss: 0.02181084\n",
      "epoch: 20  batch: 23  loss: 0.02232769\n",
      "epoch: 20  batch: 24  loss: 0.01370800\n",
      "epoch: 20  batch: 25  loss: 0.01968296\n",
      "epoch: 20  batch: 26  loss: 0.01222086\n",
      "epoch: 20  batch: 27  loss: 0.01194334\n",
      "epoch: 20  batch: 28  loss: 0.00669273\n",
      "epoch: 21  batch: 1  loss: 0.01249450\n",
      "epoch: 21  batch: 2  loss: 0.01344171\n",
      "epoch: 21  batch: 3  loss: 0.00826611\n",
      "epoch: 21  batch: 4  loss: 0.03536790\n",
      "epoch: 21  batch: 5  loss: 0.01408339\n",
      "epoch: 21  batch: 6  loss: 0.01955853\n",
      "epoch: 21  batch: 7  loss: 0.00697014\n",
      "epoch: 21  batch: 8  loss: 0.00853151\n",
      "epoch: 21  batch: 9  loss: 0.08076926\n",
      "epoch: 21  batch: 10  loss: 0.01408893\n",
      "epoch: 21  batch: 11  loss: 0.01573583\n",
      "epoch: 21  batch: 12  loss: 0.03132399\n",
      "epoch: 21  batch: 13  loss: 0.00889311\n",
      "epoch: 21  batch: 14  loss: 0.01324018\n",
      "epoch: 21  batch: 15  loss: 0.01836840\n",
      "epoch: 21  batch: 16  loss: 0.00918046\n",
      "epoch: 21  batch: 17  loss: 0.01701338\n",
      "epoch: 21  batch: 18  loss: 0.02226258\n",
      "epoch: 21  batch: 19  loss: 0.01280671\n",
      "epoch: 21  batch: 20  loss: 0.00520380\n",
      "epoch: 21  batch: 21  loss: 0.01439297\n",
      "epoch: 21  batch: 22  loss: 0.01603337\n",
      "epoch: 21  batch: 23  loss: 0.00933663\n",
      "epoch: 21  batch: 24  loss: 0.01448120\n",
      "epoch: 21  batch: 25  loss: 0.04023914\n",
      "epoch: 21  batch: 26  loss: 0.04885363\n",
      "epoch: 21  batch: 27  loss: 0.01050662\n",
      "epoch: 21  batch: 28  loss: 0.01479527\n",
      "epoch: 22  batch: 1  loss: 0.00859853\n",
      "epoch: 22  batch: 2  loss: 0.01433093\n",
      "epoch: 22  batch: 3  loss: 0.00742215\n",
      "epoch: 22  batch: 4  loss: 0.00685821\n",
      "epoch: 22  batch: 5  loss: 0.01738242\n",
      "epoch: 22  batch: 6  loss: 0.00993244\n",
      "epoch: 22  batch: 7  loss: 0.01967726\n",
      "epoch: 22  batch: 8  loss: 0.03462140\n",
      "epoch: 22  batch: 9  loss: 0.01047030\n",
      "epoch: 22  batch: 10  loss: 0.01037908\n",
      "epoch: 22  batch: 11  loss: 0.02698442\n",
      "epoch: 22  batch: 12  loss: 0.00937509\n",
      "epoch: 22  batch: 13  loss: 0.01676215\n",
      "epoch: 22  batch: 14  loss: 0.02340575\n",
      "epoch: 22  batch: 15  loss: 0.01379764\n",
      "epoch: 22  batch: 16  loss: 0.01697621\n",
      "epoch: 22  batch: 17  loss: 0.01371302\n",
      "epoch: 22  batch: 18  loss: 0.01651692\n",
      "epoch: 22  batch: 19  loss: 0.01170550\n",
      "epoch: 22  batch: 20  loss: 0.00634522\n",
      "epoch: 22  batch: 21  loss: 0.01106727\n",
      "epoch: 22  batch: 22  loss: 0.01733762\n",
      "epoch: 22  batch: 23  loss: 0.01885074\n",
      "epoch: 22  batch: 24  loss: 0.04554341\n",
      "epoch: 22  batch: 25  loss: 0.01101106\n",
      "epoch: 22  batch: 26  loss: 0.02145578\n",
      "epoch: 22  batch: 27  loss: 0.01274516\n",
      "epoch: 22  batch: 28  loss: 0.01556340\n",
      "epoch: 23  batch: 1  loss: 0.00471113\n",
      "epoch: 23  batch: 2  loss: 0.02173851\n",
      "epoch: 23  batch: 3  loss: 0.00966605\n",
      "epoch: 23  batch: 4  loss: 0.00417685\n",
      "epoch: 23  batch: 5  loss: 0.01630630\n",
      "epoch: 23  batch: 6  loss: 0.01963374\n",
      "epoch: 23  batch: 7  loss: 0.00532808\n",
      "epoch: 23  batch: 8  loss: 0.01091073\n",
      "epoch: 23  batch: 9  loss: 0.04825941\n",
      "epoch: 23  batch: 10  loss: 0.00700374\n",
      "epoch: 23  batch: 11  loss: 0.02240000\n",
      "epoch: 23  batch: 12  loss: 0.00713799\n",
      "epoch: 23  batch: 13  loss: 0.01298360\n",
      "epoch: 23  batch: 14  loss: 0.01303282\n",
      "epoch: 23  batch: 15  loss: 0.00325435\n",
      "epoch: 23  batch: 16  loss: 0.03389606\n",
      "epoch: 23  batch: 17  loss: 0.02218713\n",
      "epoch: 23  batch: 18  loss: 0.02037595\n",
      "epoch: 23  batch: 19  loss: 0.03111768\n",
      "epoch: 23  batch: 20  loss: 0.01517760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23  batch: 21  loss: 0.01718898\n",
      "epoch: 23  batch: 22  loss: 0.01391705\n",
      "epoch: 23  batch: 23  loss: 0.00920560\n",
      "epoch: 23  batch: 24  loss: 0.00292695\n",
      "epoch: 23  batch: 25  loss: 0.00448962\n",
      "epoch: 23  batch: 26  loss: 0.02371311\n",
      "epoch: 23  batch: 27  loss: 0.00233507\n",
      "epoch: 23  batch: 28  loss: 0.02494265\n",
      "epoch: 24  batch: 1  loss: 0.01020098\n",
      "epoch: 24  batch: 2  loss: 0.01257771\n",
      "epoch: 24  batch: 3  loss: 0.01682682\n",
      "epoch: 24  batch: 4  loss: 0.00383343\n",
      "epoch: 24  batch: 5  loss: 0.06505097\n",
      "epoch: 24  batch: 6  loss: 0.18674730\n",
      "epoch: 24  batch: 7  loss: 0.00491677\n",
      "epoch: 24  batch: 8  loss: 0.00544609\n",
      "epoch: 24  batch: 9  loss: 0.00696608\n",
      "epoch: 24  batch: 10  loss: 0.00972205\n",
      "epoch: 24  batch: 11  loss: 0.00665667\n",
      "epoch: 24  batch: 12  loss: 0.01778626\n",
      "epoch: 24  batch: 13  loss: 0.00567752\n",
      "epoch: 24  batch: 14  loss: 0.02518505\n",
      "epoch: 24  batch: 15  loss: 0.01582591\n",
      "epoch: 24  batch: 16  loss: 0.02618512\n",
      "epoch: 24  batch: 17  loss: 0.02461114\n",
      "epoch: 24  batch: 18  loss: 0.00860747\n",
      "epoch: 24  batch: 19  loss: 0.02143721\n",
      "epoch: 24  batch: 20  loss: 0.09958400\n",
      "epoch: 24  batch: 21  loss: 0.01569828\n",
      "epoch: 24  batch: 22  loss: 0.00643240\n",
      "epoch: 24  batch: 23  loss: 0.00223373\n",
      "epoch: 24  batch: 24  loss: 0.01221795\n",
      "epoch: 24  batch: 25  loss: 0.00627686\n",
      "epoch: 24  batch: 26  loss: 0.00778174\n",
      "epoch: 24  batch: 27  loss: 0.01096662\n",
      "epoch: 24  batch: 28  loss: 0.00640288\n",
      "epoch: 25  batch: 1  loss: 0.00307736\n",
      "epoch: 25  batch: 2  loss: 0.00504191\n",
      "epoch: 25  batch: 3  loss: 0.00510017\n",
      "epoch: 25  batch: 4  loss: 0.00766664\n",
      "epoch: 25  batch: 5  loss: 0.00815718\n",
      "epoch: 25  batch: 6  loss: 0.01540796\n",
      "epoch: 25  batch: 7  loss: 0.00912810\n",
      "epoch: 25  batch: 8  loss: 0.00327855\n",
      "epoch: 25  batch: 9  loss: 0.00793275\n",
      "epoch: 25  batch: 10  loss: 0.01740453\n",
      "epoch: 25  batch: 11  loss: 0.02163320\n",
      "epoch: 25  batch: 12  loss: 0.01341836\n",
      "epoch: 25  batch: 13  loss: 0.02407862\n",
      "epoch: 25  batch: 14  loss: 0.00543951\n",
      "epoch: 25  batch: 15  loss: 0.04193043\n",
      "epoch: 25  batch: 16  loss: 0.01366068\n",
      "epoch: 25  batch: 17  loss: 0.00781319\n",
      "epoch: 25  batch: 18  loss: 0.00678949\n",
      "epoch: 25  batch: 19  loss: 0.02179276\n",
      "epoch: 25  batch: 20  loss: 0.01310975\n",
      "epoch: 25  batch: 21  loss: 0.00342228\n",
      "epoch: 25  batch: 22  loss: 0.00444553\n",
      "epoch: 25  batch: 23  loss: 0.01259127\n",
      "epoch: 25  batch: 24  loss: 0.00471129\n",
      "epoch: 25  batch: 25  loss: 0.00430586\n",
      "epoch: 25  batch: 26  loss: 0.01678528\n",
      "epoch: 25  batch: 27  loss: 0.04185206\n",
      "epoch: 25  batch: 28  loss: 0.01566768\n",
      "epoch: 26  batch: 1  loss: 0.01191844\n",
      "epoch: 26  batch: 2  loss: 0.01692310\n",
      "epoch: 26  batch: 3  loss: 0.02902243\n",
      "epoch: 26  batch: 4  loss: 0.01367379\n",
      "epoch: 26  batch: 5  loss: 0.00536759\n",
      "epoch: 26  batch: 6  loss: 0.00641293\n",
      "epoch: 26  batch: 7  loss: 0.01153932\n",
      "epoch: 26  batch: 8  loss: 0.01405784\n",
      "epoch: 26  batch: 9  loss: 0.00554293\n",
      "epoch: 26  batch: 10  loss: 0.01870034\n",
      "epoch: 26  batch: 11  loss: 0.01036554\n",
      "epoch: 26  batch: 12  loss: 0.01353895\n",
      "epoch: 26  batch: 13  loss: 0.07254854\n",
      "epoch: 26  batch: 14  loss: 0.00268900\n",
      "epoch: 26  batch: 15  loss: 0.00967322\n",
      "epoch: 26  batch: 16  loss: 0.00772443\n",
      "epoch: 26  batch: 17  loss: 0.00748964\n",
      "epoch: 26  batch: 18  loss: 0.00802035\n",
      "epoch: 26  batch: 19  loss: 0.01086368\n",
      "epoch: 26  batch: 20  loss: 0.03351371\n",
      "epoch: 26  batch: 21  loss: 0.01564923\n",
      "epoch: 26  batch: 22  loss: 0.00721657\n",
      "epoch: 26  batch: 23  loss: 0.00855526\n",
      "epoch: 26  batch: 24  loss: 0.00827328\n",
      "epoch: 26  batch: 25  loss: 0.02536914\n",
      "epoch: 26  batch: 26  loss: 0.01786469\n",
      "epoch: 26  batch: 27  loss: 0.00615711\n",
      "epoch: 26  batch: 28  loss: 0.00469531\n",
      "epoch: 27  batch: 1  loss: 0.01035375\n",
      "epoch: 27  batch: 2  loss: 0.00764113\n",
      "epoch: 27  batch: 3  loss: 0.00896472\n",
      "epoch: 27  batch: 4  loss: 0.01257294\n",
      "epoch: 27  batch: 5  loss: 0.00467724\n",
      "epoch: 27  batch: 6  loss: 0.00987071\n",
      "epoch: 27  batch: 7  loss: 0.00247417\n",
      "epoch: 27  batch: 8  loss: 0.00764759\n",
      "epoch: 27  batch: 9  loss: 0.01601251\n",
      "epoch: 27  batch: 10  loss: 0.00708162\n",
      "epoch: 27  batch: 11  loss: 0.00448023\n",
      "epoch: 27  batch: 12  loss: 0.00753254\n",
      "epoch: 27  batch: 13  loss: 0.02503751\n",
      "epoch: 27  batch: 14  loss: 0.03169755\n",
      "epoch: 27  batch: 15  loss: 0.00617994\n",
      "epoch: 27  batch: 16  loss: 0.00787989\n",
      "epoch: 27  batch: 17  loss: 0.03446817\n",
      "epoch: 27  batch: 18  loss: 0.00869522\n",
      "epoch: 27  batch: 19  loss: 0.00756726\n",
      "epoch: 27  batch: 20  loss: 0.01047995\n",
      "epoch: 27  batch: 21  loss: 0.00557044\n",
      "epoch: 27  batch: 22  loss: 0.01253207\n",
      "epoch: 27  batch: 23  loss: 0.00779320\n",
      "epoch: 27  batch: 24  loss: 0.00412191\n",
      "epoch: 27  batch: 25  loss: 0.00745250\n",
      "epoch: 27  batch: 26  loss: 0.00676296\n",
      "epoch: 27  batch: 27  loss: 0.03684397\n",
      "epoch: 27  batch: 28  loss: 0.00769765\n",
      "epoch: 28  batch: 1  loss: 0.01518879\n",
      "epoch: 28  batch: 2  loss: 0.00754838\n",
      "epoch: 28  batch: 3  loss: 0.00712785\n",
      "epoch: 28  batch: 4  loss: 0.02578892\n",
      "epoch: 28  batch: 5  loss: 0.00682676\n",
      "epoch: 28  batch: 6  loss: 0.01257322\n",
      "epoch: 28  batch: 7  loss: 0.01370504\n",
      "epoch: 28  batch: 8  loss: 0.02503366\n",
      "epoch: 28  batch: 9  loss: 0.01624899\n",
      "epoch: 28  batch: 10  loss: 0.01393292\n",
      "epoch: 28  batch: 11  loss: 0.00760764\n",
      "epoch: 28  batch: 12  loss: 0.00634719\n",
      "epoch: 28  batch: 13  loss: 0.00693242\n",
      "epoch: 28  batch: 14  loss: 0.00949394\n",
      "epoch: 28  batch: 15  loss: 0.00827747\n",
      "epoch: 28  batch: 16  loss: 0.02028649\n",
      "epoch: 28  batch: 17  loss: 0.00537418\n",
      "epoch: 28  batch: 18  loss: 0.02539643\n",
      "epoch: 28  batch: 19  loss: 0.00568337\n",
      "epoch: 28  batch: 20  loss: 0.00844867\n",
      "epoch: 28  batch: 21  loss: 0.00632676\n",
      "epoch: 28  batch: 22  loss: 0.00903193\n",
      "epoch: 28  batch: 23  loss: 0.00893331\n",
      "epoch: 28  batch: 24  loss: 0.00417147\n",
      "epoch: 28  batch: 25  loss: 0.00674599\n",
      "epoch: 28  batch: 26  loss: 0.01338630\n",
      "epoch: 28  batch: 27  loss: 0.00752186\n",
      "epoch: 28  batch: 28  loss: 0.00604328\n",
      "epoch: 29  batch: 1  loss: 0.01026736\n",
      "epoch: 29  batch: 2  loss: 0.00590941\n",
      "epoch: 29  batch: 3  loss: 0.00232461\n",
      "epoch: 29  batch: 4  loss: 0.00678206\n",
      "epoch: 29  batch: 5  loss: 0.00592358\n",
      "epoch: 29  batch: 6  loss: 0.00972054\n",
      "epoch: 29  batch: 7  loss: 0.00944599\n",
      "epoch: 29  batch: 8  loss: 0.03220826\n",
      "epoch: 29  batch: 9  loss: 0.00543756\n",
      "epoch: 29  batch: 10  loss: 0.03161020\n",
      "epoch: 29  batch: 11  loss: 0.00902291\n",
      "epoch: 29  batch: 12  loss: 0.00513346\n",
      "epoch: 29  batch: 13  loss: 0.01406813\n",
      "epoch: 29  batch: 14  loss: 0.01039422\n",
      "epoch: 29  batch: 15  loss: 0.00587977\n",
      "epoch: 29  batch: 16  loss: 0.00437938\n",
      "epoch: 29  batch: 17  loss: 0.00991371\n",
      "epoch: 29  batch: 18  loss: 0.00986318\n",
      "epoch: 29  batch: 19  loss: 0.00338025\n",
      "epoch: 29  batch: 20  loss: 0.00851731\n",
      "epoch: 29  batch: 21  loss: 0.02994950\n",
      "epoch: 29  batch: 22  loss: 0.01884056\n",
      "epoch: 29  batch: 23  loss: 0.00833306\n",
      "epoch: 29  batch: 24  loss: 0.00709785\n",
      "epoch: 29  batch: 25  loss: 0.03082849\n",
      "epoch: 29  batch: 26  loss: 0.00645702\n",
      "epoch: 29  batch: 27  loss: 0.01147321\n",
      "epoch: 29  batch: 28  loss: 0.01719514\n",
      "epoch: 30  batch: 1  loss: 0.00578000\n",
      "epoch: 30  batch: 2  loss: 0.00770403\n",
      "epoch: 30  batch: 3  loss: 0.00832724\n",
      "epoch: 30  batch: 4  loss: 0.02252335\n",
      "epoch: 30  batch: 5  loss: 0.01293101\n",
      "epoch: 30  batch: 6  loss: 0.00809149\n",
      "epoch: 30  batch: 7  loss: 0.01224096\n",
      "epoch: 30  batch: 8  loss: 0.00686950\n",
      "epoch: 30  batch: 9  loss: 0.00434205\n",
      "epoch: 30  batch: 10  loss: 0.00218525\n",
      "epoch: 30  batch: 11  loss: 0.00221987\n",
      "epoch: 30  batch: 12  loss: 0.00345924\n",
      "epoch: 30  batch: 13  loss: 0.00900633\n",
      "epoch: 30  batch: 14  loss: 0.01134153\n",
      "epoch: 30  batch: 15  loss: 0.02932935\n",
      "epoch: 30  batch: 16  loss: 0.00962641\n",
      "epoch: 30  batch: 17  loss: 0.00901523\n",
      "epoch: 30  batch: 18  loss: 0.00614246\n",
      "epoch: 30  batch: 19  loss: 0.00593485\n",
      "epoch: 30  batch: 20  loss: 0.04980655\n",
      "epoch: 30  batch: 21  loss: 0.00520102\n",
      "epoch: 30  batch: 22  loss: 0.00817192\n",
      "epoch: 30  batch: 23  loss: 0.01052051\n",
      "epoch: 30  batch: 24  loss: 0.03574158\n",
      "epoch: 30  batch: 25  loss: 0.00314829\n",
      "epoch: 30  batch: 26  loss: 0.00637997\n",
      "epoch: 30  batch: 27  loss: 0.00349934\n",
      "epoch: 30  batch: 28  loss: 0.00630242\n",
      "epoch: 31  batch: 1  loss: 0.00586977\n",
      "epoch: 31  batch: 2  loss: 0.00324300\n",
      "epoch: 31  batch: 3  loss: 0.01553489\n",
      "epoch: 31  batch: 4  loss: 0.00678952\n",
      "epoch: 31  batch: 5  loss: 0.00253946\n",
      "epoch: 31  batch: 6  loss: 0.01880719\n",
      "epoch: 31  batch: 7  loss: 0.00637444\n",
      "epoch: 31  batch: 8  loss: 0.00798774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31  batch: 9  loss: 0.01424555\n",
      "epoch: 31  batch: 10  loss: 0.00309240\n",
      "epoch: 31  batch: 11  loss: 0.01234553\n",
      "epoch: 31  batch: 12  loss: 0.00573700\n",
      "epoch: 31  batch: 13  loss: 0.01841266\n",
      "epoch: 31  batch: 14  loss: 0.03725782\n",
      "epoch: 31  batch: 15  loss: 0.00283672\n",
      "epoch: 31  batch: 16  loss: 0.00602878\n",
      "epoch: 31  batch: 17  loss: 0.00553261\n",
      "epoch: 31  batch: 18  loss: 0.00521779\n",
      "epoch: 31  batch: 19  loss: 0.01667085\n",
      "epoch: 31  batch: 20  loss: 0.01557848\n",
      "epoch: 31  batch: 21  loss: 0.00514405\n",
      "epoch: 31  batch: 22  loss: 0.00890283\n",
      "epoch: 31  batch: 23  loss: 0.01653669\n",
      "epoch: 31  batch: 24  loss: 0.00461402\n",
      "epoch: 31  batch: 25  loss: 0.00763331\n",
      "epoch: 31  batch: 26  loss: 0.03503365\n",
      "epoch: 31  batch: 27  loss: 0.00541289\n",
      "epoch: 31  batch: 28  loss: 0.01353684\n",
      "epoch: 32  batch: 1  loss: 0.01109902\n",
      "epoch: 32  batch: 2  loss: 0.01490990\n",
      "epoch: 32  batch: 3  loss: 0.01312821\n",
      "epoch: 32  batch: 4  loss: 0.00866296\n",
      "epoch: 32  batch: 5  loss: 0.00759000\n",
      "epoch: 32  batch: 6  loss: 0.00280623\n",
      "epoch: 32  batch: 7  loss: 0.01961583\n",
      "epoch: 32  batch: 8  loss: 0.01506526\n",
      "epoch: 32  batch: 9  loss: 0.00289799\n",
      "epoch: 32  batch: 10  loss: 0.00500289\n",
      "epoch: 32  batch: 11  loss: 0.00489551\n",
      "epoch: 32  batch: 12  loss: 0.00753792\n",
      "epoch: 32  batch: 13  loss: 0.00653045\n",
      "epoch: 32  batch: 14  loss: 0.00472696\n",
      "epoch: 32  batch: 15  loss: 0.00404864\n",
      "epoch: 32  batch: 16  loss: 0.01582861\n",
      "epoch: 32  batch: 17  loss: 0.00498122\n",
      "epoch: 32  batch: 18  loss: 0.00984361\n",
      "epoch: 32  batch: 19  loss: 0.00496443\n",
      "epoch: 32  batch: 20  loss: 0.00784851\n",
      "epoch: 32  batch: 21  loss: 0.01263434\n",
      "epoch: 32  batch: 22  loss: 0.00609309\n",
      "epoch: 32  batch: 23  loss: 0.00436612\n",
      "epoch: 32  batch: 24  loss: 0.01045447\n",
      "epoch: 32  batch: 25  loss: 0.03407612\n",
      "epoch: 32  batch: 26  loss: 0.02563843\n",
      "epoch: 32  batch: 27  loss: 0.00595628\n",
      "epoch: 32  batch: 28  loss: 0.01181885\n",
      "epoch: 33  batch: 1  loss: 0.00757185\n",
      "epoch: 33  batch: 2  loss: 0.00684047\n",
      "epoch: 33  batch: 3  loss: 0.00583153\n",
      "epoch: 33  batch: 4  loss: 0.00566445\n",
      "epoch: 33  batch: 5  loss: 0.00939652\n",
      "epoch: 33  batch: 6  loss: 0.01016186\n",
      "epoch: 33  batch: 7  loss: 0.00857156\n",
      "epoch: 33  batch: 8  loss: 0.01143340\n",
      "epoch: 33  batch: 9  loss: 0.01128835\n",
      "epoch: 33  batch: 10  loss: 0.02831187\n",
      "epoch: 33  batch: 11  loss: 0.00310575\n",
      "epoch: 33  batch: 12  loss: 0.00404593\n",
      "epoch: 33  batch: 13  loss: 0.00742370\n",
      "epoch: 33  batch: 14  loss: 0.00353140\n",
      "epoch: 33  batch: 15  loss: 0.00341457\n",
      "epoch: 33  batch: 16  loss: 0.00579622\n",
      "epoch: 33  batch: 17  loss: 0.00512103\n",
      "epoch: 33  batch: 18  loss: 0.02322080\n",
      "epoch: 33  batch: 19  loss: 0.00614163\n",
      "epoch: 33  batch: 20  loss: 0.00933624\n",
      "epoch: 33  batch: 21  loss: 0.00432242\n",
      "epoch: 33  batch: 22  loss: 0.01211903\n",
      "epoch: 33  batch: 23  loss: 0.02834947\n",
      "epoch: 33  batch: 24  loss: 0.00744143\n",
      "epoch: 33  batch: 25  loss: 0.05619404\n",
      "epoch: 33  batch: 26  loss: 0.01371367\n",
      "epoch: 33  batch: 27  loss: 0.00306231\n",
      "epoch: 33  batch: 28  loss: 0.01493095\n",
      "epoch: 34  batch: 1  loss: 0.01232435\n",
      "epoch: 34  batch: 2  loss: 0.00625048\n",
      "epoch: 34  batch: 3  loss: 0.00242060\n",
      "epoch: 34  batch: 4  loss: 0.01717087\n",
      "epoch: 34  batch: 5  loss: 0.01254092\n",
      "epoch: 34  batch: 6  loss: 0.01825247\n",
      "epoch: 34  batch: 7  loss: 0.00936500\n",
      "epoch: 34  batch: 8  loss: 0.01368627\n",
      "epoch: 34  batch: 9  loss: 0.00804368\n",
      "epoch: 34  batch: 10  loss: 0.00930144\n",
      "epoch: 34  batch: 11  loss: 0.00663379\n",
      "epoch: 34  batch: 12  loss: 0.00201261\n",
      "epoch: 34  batch: 13  loss: 0.01353857\n",
      "epoch: 34  batch: 14  loss: 0.00626261\n",
      "epoch: 34  batch: 15  loss: 0.00783726\n",
      "epoch: 34  batch: 16  loss: 0.03331139\n",
      "epoch: 34  batch: 17  loss: 0.01011654\n",
      "epoch: 34  batch: 18  loss: 0.00461306\n",
      "epoch: 34  batch: 19  loss: 0.00824512\n",
      "epoch: 34  batch: 20  loss: 0.00592878\n",
      "epoch: 34  batch: 21  loss: 0.01400831\n",
      "epoch: 34  batch: 22  loss: 0.00643848\n",
      "epoch: 34  batch: 23  loss: 0.00639613\n",
      "epoch: 34  batch: 24  loss: 0.00444064\n",
      "epoch: 34  batch: 25  loss: 0.00137043\n",
      "epoch: 34  batch: 26  loss: 0.00914230\n",
      "epoch: 34  batch: 27  loss: 0.01090247\n",
      "epoch: 34  batch: 28  loss: 0.03444928\n",
      "epoch: 35  batch: 1  loss: 0.00844783\n",
      "epoch: 35  batch: 2  loss: 0.00827894\n",
      "epoch: 35  batch: 3  loss: 0.02312819\n",
      "epoch: 35  batch: 4  loss: 0.00601399\n",
      "epoch: 35  batch: 5  loss: 0.00412123\n",
      "epoch: 35  batch: 6  loss: 0.00772766\n",
      "epoch: 35  batch: 7  loss: 0.01135567\n",
      "epoch: 35  batch: 8  loss: 0.00742559\n",
      "epoch: 35  batch: 9  loss: 0.00715876\n",
      "epoch: 35  batch: 10  loss: 0.00880395\n",
      "epoch: 35  batch: 11  loss: 0.00399853\n",
      "epoch: 35  batch: 12  loss: 0.00841879\n",
      "epoch: 35  batch: 13  loss: 0.00324389\n",
      "epoch: 35  batch: 14  loss: 0.00300715\n",
      "epoch: 35  batch: 15  loss: 0.00367902\n",
      "epoch: 35  batch: 16  loss: 0.00192995\n",
      "epoch: 35  batch: 17  loss: 0.00293224\n",
      "epoch: 35  batch: 18  loss: 0.00159705\n",
      "epoch: 35  batch: 19  loss: 0.00839307\n",
      "epoch: 35  batch: 20  loss: 0.00707780\n",
      "epoch: 35  batch: 21  loss: 0.01308751\n",
      "epoch: 35  batch: 22  loss: 0.00769333\n",
      "epoch: 35  batch: 23  loss: 0.03004974\n",
      "epoch: 35  batch: 24  loss: 0.00379257\n",
      "epoch: 35  batch: 25  loss: 0.00464905\n",
      "epoch: 35  batch: 26  loss: 0.00310038\n",
      "epoch: 35  batch: 27  loss: 0.01098236\n",
      "epoch: 35  batch: 28  loss: 0.01815834\n",
      "epoch: 36  batch: 1  loss: 0.00188672\n",
      "epoch: 36  batch: 2  loss: 0.00492753\n",
      "epoch: 36  batch: 3  loss: 0.01384299\n",
      "epoch: 36  batch: 4  loss: 0.00649377\n",
      "epoch: 36  batch: 5  loss: 0.00790746\n",
      "epoch: 36  batch: 6  loss: 0.02845912\n",
      "epoch: 36  batch: 7  loss: 0.01088984\n",
      "epoch: 36  batch: 8  loss: 0.00289192\n",
      "epoch: 36  batch: 9  loss: 0.00270321\n",
      "epoch: 36  batch: 10  loss: 0.00365879\n",
      "epoch: 36  batch: 11  loss: 0.00209431\n",
      "epoch: 36  batch: 12  loss: 0.00237169\n",
      "epoch: 36  batch: 13  loss: 0.00330600\n",
      "epoch: 36  batch: 14  loss: 0.01040172\n",
      "epoch: 36  batch: 15  loss: 0.00571044\n",
      "epoch: 36  batch: 16  loss: 0.00860924\n",
      "epoch: 36  batch: 17  loss: 0.00630702\n",
      "epoch: 36  batch: 18  loss: 0.00423155\n",
      "epoch: 36  batch: 19  loss: 0.00501554\n",
      "epoch: 36  batch: 20  loss: 0.00451798\n",
      "epoch: 36  batch: 21  loss: 0.00624070\n",
      "epoch: 36  batch: 22  loss: 0.02649595\n",
      "epoch: 36  batch: 23  loss: 0.00356353\n",
      "epoch: 36  batch: 24  loss: 0.01261165\n",
      "epoch: 36  batch: 25  loss: 0.02934116\n",
      "epoch: 36  batch: 26  loss: 0.00265548\n",
      "epoch: 36  batch: 27  loss: 0.00939967\n",
      "epoch: 36  batch: 28  loss: 0.00920767\n",
      "epoch: 37  batch: 1  loss: 0.00867530\n",
      "epoch: 37  batch: 2  loss: 0.00695416\n",
      "epoch: 37  batch: 3  loss: 0.03701376\n",
      "epoch: 37  batch: 4  loss: 0.00489250\n",
      "epoch: 37  batch: 5  loss: 0.00502198\n",
      "epoch: 37  batch: 6  loss: 0.00731247\n",
      "epoch: 37  batch: 7  loss: 0.00290824\n",
      "epoch: 37  batch: 8  loss: 0.02999835\n",
      "epoch: 37  batch: 9  loss: 0.00859562\n",
      "epoch: 37  batch: 10  loss: 0.00416378\n",
      "epoch: 37  batch: 11  loss: 0.00966464\n",
      "epoch: 37  batch: 12  loss: 0.00619089\n",
      "epoch: 37  batch: 13  loss: 0.00195919\n",
      "epoch: 37  batch: 14  loss: 0.01380392\n",
      "epoch: 37  batch: 15  loss: 0.02015428\n",
      "epoch: 37  batch: 16  loss: 0.00324406\n",
      "epoch: 37  batch: 17  loss: 0.00676780\n",
      "epoch: 37  batch: 18  loss: 0.00810100\n",
      "epoch: 37  batch: 19  loss: 0.01302944\n",
      "epoch: 37  batch: 20  loss: 0.01000366\n",
      "epoch: 37  batch: 21  loss: 0.00644610\n",
      "epoch: 37  batch: 22  loss: 0.00831213\n",
      "epoch: 37  batch: 23  loss: 0.00296396\n",
      "epoch: 37  batch: 24  loss: 0.00780065\n",
      "epoch: 37  batch: 25  loss: 0.02024474\n",
      "epoch: 37  batch: 26  loss: 0.00162519\n",
      "epoch: 37  batch: 27  loss: 0.00973190\n",
      "epoch: 37  batch: 28  loss: 0.00250031\n",
      "epoch: 38  batch: 1  loss: 0.02528103\n",
      "epoch: 38  batch: 2  loss: 0.01096004\n",
      "epoch: 38  batch: 3  loss: 0.00301685\n",
      "epoch: 38  batch: 4  loss: 0.00790561\n",
      "epoch: 38  batch: 5  loss: 0.00976921\n",
      "epoch: 38  batch: 6  loss: 0.00319766\n",
      "epoch: 38  batch: 7  loss: 0.00478208\n",
      "epoch: 38  batch: 8  loss: 0.02096918\n",
      "epoch: 38  batch: 9  loss: 0.00825238\n",
      "epoch: 38  batch: 10  loss: 0.00365333\n",
      "epoch: 38  batch: 11  loss: 0.01417559\n",
      "epoch: 38  batch: 12  loss: 0.00365660\n",
      "epoch: 38  batch: 13  loss: 0.00691405\n",
      "epoch: 38  batch: 14  loss: 0.01242033\n",
      "epoch: 38  batch: 15  loss: 0.00516606\n",
      "epoch: 38  batch: 16  loss: 0.00582541\n",
      "epoch: 38  batch: 17  loss: 0.00233113\n",
      "epoch: 38  batch: 18  loss: 0.01499990\n",
      "epoch: 38  batch: 19  loss: 0.03879807\n",
      "epoch: 38  batch: 20  loss: 0.00435512\n",
      "epoch: 38  batch: 21  loss: 0.00861651\n",
      "epoch: 38  batch: 22  loss: 0.00659860\n",
      "epoch: 38  batch: 23  loss: 0.00603289\n",
      "epoch: 38  batch: 24  loss: 0.00199642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38  batch: 25  loss: 0.00736521\n",
      "epoch: 38  batch: 26  loss: 0.01137324\n",
      "epoch: 38  batch: 27  loss: 0.00868015\n",
      "epoch: 38  batch: 28  loss: 0.00305318\n",
      "epoch: 39  batch: 1  loss: 0.00505351\n",
      "epoch: 39  batch: 2  loss: 0.02092802\n",
      "epoch: 39  batch: 3  loss: 0.02913116\n",
      "epoch: 39  batch: 4  loss: 0.00626676\n",
      "epoch: 39  batch: 5  loss: 0.01370944\n",
      "epoch: 39  batch: 6  loss: 0.00491000\n",
      "epoch: 39  batch: 7  loss: 0.00393745\n",
      "epoch: 39  batch: 8  loss: 0.00495561\n",
      "epoch: 39  batch: 9  loss: 0.01020581\n",
      "epoch: 39  batch: 10  loss: 0.00621899\n",
      "epoch: 39  batch: 11  loss: 0.01037931\n",
      "epoch: 39  batch: 12  loss: 0.00149806\n",
      "epoch: 39  batch: 13  loss: 0.00272775\n",
      "epoch: 39  batch: 14  loss: 0.01393400\n",
      "epoch: 39  batch: 15  loss: 0.00394950\n",
      "epoch: 39  batch: 16  loss: 0.00840202\n",
      "epoch: 39  batch: 17  loss: 0.00506222\n",
      "epoch: 39  batch: 18  loss: 0.00524521\n",
      "epoch: 39  batch: 19  loss: 0.00291195\n",
      "epoch: 39  batch: 20  loss: 0.00713525\n",
      "epoch: 39  batch: 21  loss: 0.00852131\n",
      "epoch: 39  batch: 22  loss: 0.00446576\n",
      "epoch: 39  batch: 23  loss: 0.04849216\n",
      "epoch: 39  batch: 24  loss: 0.00822522\n",
      "epoch: 39  batch: 25  loss: 0.00994363\n",
      "epoch: 39  batch: 26  loss: 0.00476232\n",
      "epoch: 39  batch: 27  loss: 0.00648730\n",
      "epoch: 39  batch: 28  loss: 0.00815796\n",
      "epoch: 40  batch: 1  loss: 0.00559899\n",
      "epoch: 40  batch: 2  loss: 0.00287665\n",
      "epoch: 40  batch: 3  loss: 0.00711259\n",
      "epoch: 40  batch: 4  loss: 0.06999855\n",
      "epoch: 40  batch: 5  loss: 0.01115420\n",
      "epoch: 40  batch: 6  loss: 0.01144024\n",
      "epoch: 40  batch: 7  loss: 0.00350337\n",
      "epoch: 40  batch: 8  loss: 0.00803475\n",
      "epoch: 40  batch: 9  loss: 0.01351595\n",
      "epoch: 40  batch: 10  loss: 0.01198718\n",
      "epoch: 40  batch: 11  loss: 0.00285479\n",
      "epoch: 40  batch: 12  loss: 0.00542481\n",
      "epoch: 40  batch: 13  loss: 0.00764960\n",
      "epoch: 40  batch: 14  loss: 0.00323343\n",
      "epoch: 40  batch: 15  loss: 0.01250746\n",
      "epoch: 40  batch: 16  loss: 0.00480243\n",
      "epoch: 40  batch: 17  loss: 0.00972647\n",
      "epoch: 40  batch: 18  loss: 0.00330558\n",
      "epoch: 40  batch: 19  loss: 0.00246918\n",
      "epoch: 40  batch: 20  loss: 0.00241096\n",
      "epoch: 40  batch: 21  loss: 0.00775236\n",
      "epoch: 40  batch: 22  loss: 0.00584286\n",
      "epoch: 40  batch: 23  loss: 0.01605115\n",
      "epoch: 40  batch: 24  loss: 0.00742734\n",
      "epoch: 40  batch: 25  loss: 0.00891726\n",
      "epoch: 40  batch: 26  loss: 0.00720026\n",
      "epoch: 40  batch: 27  loss: 0.01420087\n",
      "epoch: 40  batch: 28  loss: 0.06297956\n",
      "epoch: 41  batch: 1  loss: 0.00551467\n",
      "epoch: 41  batch: 2  loss: 0.00272441\n",
      "epoch: 41  batch: 3  loss: 0.00919870\n",
      "epoch: 41  batch: 4  loss: 0.01981587\n",
      "epoch: 41  batch: 5  loss: 0.26005930\n",
      "epoch: 41  batch: 6  loss: 0.00515737\n",
      "epoch: 41  batch: 7  loss: 0.00214390\n",
      "epoch: 41  batch: 8  loss: 0.00687224\n",
      "epoch: 41  batch: 9  loss: 0.00689614\n",
      "epoch: 41  batch: 10  loss: 0.01247931\n",
      "epoch: 41  batch: 11  loss: 0.00635526\n",
      "epoch: 41  batch: 12  loss: 0.01601361\n",
      "epoch: 41  batch: 13  loss: 0.02114820\n",
      "epoch: 41  batch: 14  loss: 0.00827057\n",
      "epoch: 41  batch: 15  loss: 0.00811929\n",
      "epoch: 41  batch: 16  loss: 0.05926489\n",
      "epoch: 41  batch: 17  loss: 0.01526437\n",
      "epoch: 41  batch: 18  loss: 0.01014824\n",
      "epoch: 41  batch: 19  loss: 0.01257374\n",
      "epoch: 41  batch: 20  loss: 0.00638228\n",
      "epoch: 41  batch: 21  loss: 0.01266024\n",
      "epoch: 41  batch: 22  loss: 0.00416120\n",
      "epoch: 41  batch: 23  loss: 0.00427038\n",
      "epoch: 41  batch: 24  loss: 0.00506001\n",
      "epoch: 41  batch: 25  loss: 0.04155634\n",
      "epoch: 41  batch: 26  loss: 0.01222732\n",
      "epoch: 41  batch: 27  loss: 0.03426481\n",
      "epoch: 41  batch: 28  loss: 0.01121033\n",
      "epoch: 42  batch: 1  loss: 0.02856013\n",
      "epoch: 42  batch: 2  loss: 0.00313766\n",
      "epoch: 42  batch: 3  loss: 0.00545258\n",
      "epoch: 42  batch: 4  loss: 0.02076328\n",
      "epoch: 42  batch: 5  loss: 0.02429137\n",
      "epoch: 42  batch: 6  loss: 0.01222630\n",
      "epoch: 42  batch: 7  loss: 0.01005244\n",
      "epoch: 42  batch: 8  loss: 0.00783013\n",
      "epoch: 42  batch: 9  loss: 0.00693764\n",
      "epoch: 42  batch: 10  loss: 0.00870360\n",
      "epoch: 42  batch: 11  loss: 0.00294011\n",
      "epoch: 42  batch: 12  loss: 0.01479268\n",
      "epoch: 42  batch: 13  loss: 0.00382997\n",
      "epoch: 42  batch: 14  loss: 0.00709483\n",
      "epoch: 42  batch: 15  loss: 0.00954833\n",
      "epoch: 42  batch: 16  loss: 0.00553646\n",
      "epoch: 42  batch: 17  loss: 0.01040877\n",
      "epoch: 42  batch: 18  loss: 0.00221046\n",
      "epoch: 42  batch: 19  loss: 0.00240525\n",
      "epoch: 42  batch: 20  loss: 0.00500182\n",
      "epoch: 42  batch: 21  loss: 0.00353537\n",
      "epoch: 42  batch: 22  loss: 0.00666866\n",
      "epoch: 42  batch: 23  loss: 0.00838001\n",
      "epoch: 42  batch: 24  loss: 0.01398590\n",
      "epoch: 42  batch: 25  loss: 0.00423825\n",
      "epoch: 42  batch: 26  loss: 0.00335145\n",
      "epoch: 42  batch: 27  loss: 0.01313074\n",
      "epoch: 42  batch: 28  loss: 0.01503274\n",
      "epoch: 43  batch: 1  loss: 0.00423507\n",
      "epoch: 43  batch: 2  loss: 0.00625817\n",
      "epoch: 43  batch: 3  loss: 0.00083676\n",
      "epoch: 43  batch: 4  loss: 0.00316033\n",
      "epoch: 43  batch: 5  loss: 0.00322059\n",
      "epoch: 43  batch: 6  loss: 0.01564128\n",
      "epoch: 43  batch: 7  loss: 0.00386435\n",
      "epoch: 43  batch: 8  loss: 0.00509393\n",
      "epoch: 43  batch: 9  loss: 0.01246233\n",
      "epoch: 43  batch: 10  loss: 0.01856391\n",
      "epoch: 43  batch: 11  loss: 0.00225793\n",
      "epoch: 43  batch: 12  loss: 0.00473062\n",
      "epoch: 43  batch: 13  loss: 0.00460202\n",
      "epoch: 43  batch: 14  loss: 0.03128086\n",
      "epoch: 43  batch: 15  loss: 0.00441110\n",
      "epoch: 43  batch: 16  loss: 0.00404488\n",
      "epoch: 43  batch: 17  loss: 0.00408928\n",
      "epoch: 43  batch: 18  loss: 0.00306682\n",
      "epoch: 43  batch: 19  loss: 0.00407112\n",
      "epoch: 43  batch: 20  loss: 0.00917236\n",
      "epoch: 43  batch: 21  loss: 0.01504898\n",
      "epoch: 43  batch: 22  loss: 0.00795556\n",
      "epoch: 43  batch: 23  loss: 0.00850362\n",
      "epoch: 43  batch: 24  loss: 0.00670293\n",
      "epoch: 43  batch: 25  loss: 0.00820571\n",
      "epoch: 43  batch: 26  loss: 0.00733207\n",
      "epoch: 43  batch: 27  loss: 0.01108067\n",
      "epoch: 43  batch: 28  loss: 0.00377216\n",
      "epoch: 44  batch: 1  loss: 0.00406941\n",
      "epoch: 44  batch: 2  loss: 0.00329697\n",
      "epoch: 44  batch: 3  loss: 0.00501393\n",
      "epoch: 44  batch: 4  loss: 0.00731581\n",
      "epoch: 44  batch: 5  loss: 0.01210333\n",
      "epoch: 44  batch: 6  loss: 0.00658280\n",
      "epoch: 44  batch: 7  loss: 0.00495225\n",
      "epoch: 44  batch: 8  loss: 0.00585746\n",
      "epoch: 44  batch: 9  loss: 0.00459350\n",
      "epoch: 44  batch: 10  loss: 0.00168369\n",
      "epoch: 44  batch: 11  loss: 0.00603265\n",
      "epoch: 44  batch: 12  loss: 0.02533724\n",
      "epoch: 44  batch: 13  loss: 0.00471894\n",
      "epoch: 44  batch: 14  loss: 0.00536394\n",
      "epoch: 44  batch: 15  loss: 0.00360343\n",
      "epoch: 44  batch: 16  loss: 0.00295976\n",
      "epoch: 44  batch: 17  loss: 0.00564214\n",
      "epoch: 44  batch: 18  loss: 0.00353081\n",
      "epoch: 44  batch: 19  loss: 0.00887913\n",
      "epoch: 44  batch: 20  loss: 0.01939918\n",
      "epoch: 44  batch: 21  loss: 0.01063089\n",
      "epoch: 44  batch: 22  loss: 0.01054979\n",
      "epoch: 44  batch: 23  loss: 0.02416313\n",
      "epoch: 44  batch: 24  loss: 0.00239214\n",
      "epoch: 44  batch: 25  loss: 0.00771632\n",
      "epoch: 44  batch: 26  loss: 0.00600831\n",
      "epoch: 44  batch: 27  loss: 0.00542812\n",
      "epoch: 44  batch: 28  loss: 0.00389786\n",
      "epoch: 45  batch: 1  loss: 0.00571808\n",
      "epoch: 45  batch: 2  loss: 0.00665828\n",
      "epoch: 45  batch: 3  loss: 0.00981475\n",
      "epoch: 45  batch: 4  loss: 0.00694101\n",
      "epoch: 45  batch: 5  loss: 0.00685971\n",
      "epoch: 45  batch: 6  loss: 0.00984344\n",
      "epoch: 45  batch: 7  loss: 0.00383509\n",
      "epoch: 45  batch: 8  loss: 0.00560641\n",
      "epoch: 45  batch: 9  loss: 0.01505360\n",
      "epoch: 45  batch: 10  loss: 0.03344468\n",
      "epoch: 45  batch: 11  loss: 0.00471716\n",
      "epoch: 45  batch: 12  loss: 0.01094415\n",
      "epoch: 45  batch: 13  loss: 0.00319231\n",
      "epoch: 45  batch: 14  loss: 0.00289683\n",
      "epoch: 45  batch: 15  loss: 0.00618646\n",
      "epoch: 45  batch: 16  loss: 0.00359741\n",
      "epoch: 45  batch: 17  loss: 0.00344051\n",
      "epoch: 45  batch: 18  loss: 0.00313703\n",
      "epoch: 45  batch: 19  loss: 0.00368511\n",
      "epoch: 45  batch: 20  loss: 0.00615024\n",
      "epoch: 45  batch: 21  loss: 0.00733637\n",
      "epoch: 45  batch: 22  loss: 0.00839514\n",
      "epoch: 45  batch: 23  loss: 0.00607617\n",
      "epoch: 45  batch: 24  loss: 0.00435831\n",
      "epoch: 45  batch: 25  loss: 0.01063237\n",
      "epoch: 45  batch: 26  loss: 0.00409689\n",
      "epoch: 45  batch: 27  loss: 0.00530799\n",
      "epoch: 45  batch: 28  loss: 0.02174737\n",
      "epoch: 46  batch: 1  loss: 0.00834106\n",
      "epoch: 46  batch: 2  loss: 0.00235826\n",
      "epoch: 46  batch: 3  loss: 0.00131950\n",
      "epoch: 46  batch: 4  loss: 0.00294620\n",
      "epoch: 46  batch: 5  loss: 0.00156019\n",
      "epoch: 46  batch: 6  loss: 0.02126814\n",
      "epoch: 46  batch: 7  loss: 0.00419385\n",
      "epoch: 46  batch: 8  loss: 0.00186415\n",
      "epoch: 46  batch: 9  loss: 0.00231688\n",
      "epoch: 46  batch: 10  loss: 0.00322315\n",
      "epoch: 46  batch: 11  loss: 0.02110259\n",
      "epoch: 46  batch: 12  loss: 0.00429743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46  batch: 13  loss: 0.00296361\n",
      "epoch: 46  batch: 14  loss: 0.00683887\n",
      "epoch: 46  batch: 15  loss: 0.01443273\n",
      "epoch: 46  batch: 16  loss: 0.00678823\n",
      "epoch: 46  batch: 17  loss: 0.00447670\n",
      "epoch: 46  batch: 18  loss: 0.00724740\n",
      "epoch: 46  batch: 19  loss: 0.00672037\n",
      "epoch: 46  batch: 20  loss: 0.00300844\n",
      "epoch: 46  batch: 21  loss: 0.00920757\n",
      "epoch: 46  batch: 22  loss: 0.00402649\n",
      "epoch: 46  batch: 23  loss: 0.00405417\n",
      "epoch: 46  batch: 24  loss: 0.01549707\n",
      "epoch: 46  batch: 25  loss: 0.01371940\n",
      "epoch: 46  batch: 26  loss: 0.00350746\n",
      "epoch: 46  batch: 27  loss: 0.00559805\n",
      "epoch: 46  batch: 28  loss: 0.00349344\n",
      "epoch: 47  batch: 1  loss: 0.00512720\n",
      "epoch: 47  batch: 2  loss: 0.00718183\n",
      "epoch: 47  batch: 3  loss: 0.00668633\n",
      "epoch: 47  batch: 4  loss: 0.00673876\n",
      "epoch: 47  batch: 5  loss: 0.00597318\n",
      "epoch: 47  batch: 6  loss: 0.01492998\n",
      "epoch: 47  batch: 7  loss: 0.01493251\n",
      "epoch: 47  batch: 8  loss: 0.00326443\n",
      "epoch: 47  batch: 9  loss: 0.01064783\n",
      "epoch: 47  batch: 10  loss: 0.01053570\n",
      "epoch: 47  batch: 11  loss: 0.00546848\n",
      "epoch: 47  batch: 12  loss: 0.02220796\n",
      "epoch: 47  batch: 13  loss: 0.02818856\n",
      "epoch: 47  batch: 14  loss: 0.00824870\n",
      "epoch: 47  batch: 15  loss: 0.01885792\n",
      "epoch: 47  batch: 16  loss: 0.00839969\n",
      "epoch: 47  batch: 17  loss: 0.01542250\n",
      "epoch: 47  batch: 18  loss: 0.00338941\n",
      "epoch: 47  batch: 19  loss: 0.00414822\n",
      "epoch: 47  batch: 20  loss: 0.00411735\n",
      "epoch: 47  batch: 21  loss: 0.00714209\n",
      "epoch: 47  batch: 22  loss: 0.00384335\n",
      "epoch: 47  batch: 23  loss: 0.00608120\n",
      "epoch: 47  batch: 24  loss: 0.00645073\n",
      "epoch: 47  batch: 25  loss: 0.00374990\n",
      "epoch: 47  batch: 26  loss: 0.00753422\n",
      "epoch: 47  batch: 27  loss: 0.01325199\n",
      "epoch: 47  batch: 28  loss: 0.00412332\n",
      "epoch: 48  batch: 1  loss: 0.00404854\n",
      "epoch: 48  batch: 2  loss: 0.00611709\n",
      "epoch: 48  batch: 3  loss: 0.00289856\n",
      "epoch: 48  batch: 4  loss: 0.00184738\n",
      "epoch: 48  batch: 5  loss: 0.00899454\n",
      "epoch: 48  batch: 6  loss: 0.00549772\n",
      "epoch: 48  batch: 7  loss: 0.00440814\n",
      "epoch: 48  batch: 8  loss: 0.01201486\n",
      "epoch: 48  batch: 9  loss: 0.00456429\n",
      "epoch: 48  batch: 10  loss: 0.00393346\n",
      "epoch: 48  batch: 11  loss: 0.00354152\n",
      "epoch: 48  batch: 12  loss: 0.00442959\n",
      "epoch: 48  batch: 13  loss: 0.00646534\n",
      "epoch: 48  batch: 14  loss: 0.01347520\n",
      "epoch: 48  batch: 15  loss: 0.01563284\n",
      "epoch: 48  batch: 16  loss: 0.00792033\n",
      "epoch: 48  batch: 17  loss: 0.00232177\n",
      "epoch: 48  batch: 18  loss: 0.00911375\n",
      "epoch: 48  batch: 19  loss: 0.04620707\n",
      "epoch: 48  batch: 20  loss: 0.00713897\n",
      "epoch: 48  batch: 21  loss: 0.00298087\n",
      "epoch: 48  batch: 22  loss: 0.00275316\n",
      "epoch: 48  batch: 23  loss: 0.00359658\n",
      "epoch: 48  batch: 24  loss: 0.00886053\n",
      "epoch: 48  batch: 25  loss: 0.00825737\n",
      "epoch: 48  batch: 26  loss: 0.00275154\n",
      "epoch: 48  batch: 27  loss: 0.03590151\n",
      "epoch: 48  batch: 28  loss: 0.02621986\n",
      "epoch: 49  batch: 1  loss: 0.00951341\n",
      "epoch: 49  batch: 2  loss: 0.00431089\n",
      "epoch: 49  batch: 3  loss: 0.00520610\n",
      "epoch: 49  batch: 4  loss: 0.00212623\n",
      "epoch: 49  batch: 5  loss: 0.00454131\n",
      "epoch: 49  batch: 6  loss: 0.00152392\n",
      "epoch: 49  batch: 7  loss: 0.00591876\n",
      "epoch: 49  batch: 8  loss: 0.00830851\n",
      "epoch: 49  batch: 9  loss: 0.00558085\n",
      "epoch: 49  batch: 10  loss: 0.01219655\n",
      "epoch: 49  batch: 11  loss: 0.00274507\n",
      "epoch: 49  batch: 12  loss: 0.01680871\n",
      "epoch: 49  batch: 13  loss: 0.00842420\n",
      "epoch: 49  batch: 14  loss: 0.00565404\n",
      "epoch: 49  batch: 15  loss: 0.00547271\n",
      "epoch: 49  batch: 16  loss: 0.00212456\n",
      "epoch: 49  batch: 17  loss: 0.00252067\n",
      "epoch: 49  batch: 18  loss: 0.00743380\n",
      "epoch: 49  batch: 19  loss: 0.00905357\n",
      "epoch: 49  batch: 20  loss: 0.00453661\n",
      "epoch: 49  batch: 21  loss: 0.00364483\n",
      "epoch: 49  batch: 22  loss: 0.00417385\n",
      "epoch: 49  batch: 23  loss: 0.00128040\n",
      "epoch: 49  batch: 24  loss: 0.00182007\n",
      "epoch: 49  batch: 25  loss: 0.00526039\n",
      "epoch: 49  batch: 26  loss: 0.00530365\n",
      "epoch: 49  batch: 27  loss: 0.01887741\n",
      "epoch: 49  batch: 28  loss: 0.00417314\n",
      "epoch: 50  batch: 1  loss: 0.01685787\n",
      "epoch: 50  batch: 2  loss: 0.00099981\n",
      "epoch: 50  batch: 3  loss: 0.00549310\n",
      "epoch: 50  batch: 4  loss: 0.00754956\n",
      "epoch: 50  batch: 5  loss: 0.00446249\n",
      "epoch: 50  batch: 6  loss: 0.00732483\n",
      "epoch: 50  batch: 7  loss: 0.00837797\n",
      "epoch: 50  batch: 8  loss: 0.00357738\n",
      "epoch: 50  batch: 9  loss: 0.00233676\n",
      "epoch: 50  batch: 10  loss: 0.00271061\n",
      "epoch: 50  batch: 11  loss: 0.00504613\n",
      "epoch: 50  batch: 12  loss: 0.00130050\n",
      "epoch: 50  batch: 13  loss: 0.00297991\n",
      "epoch: 50  batch: 14  loss: 0.00524499\n",
      "epoch: 50  batch: 15  loss: 0.01588573\n",
      "epoch: 50  batch: 16  loss: 0.00818727\n",
      "epoch: 50  batch: 17  loss: 0.02672213\n",
      "epoch: 50  batch: 18  loss: 0.00414151\n",
      "epoch: 50  batch: 19  loss: 0.00470266\n",
      "epoch: 50  batch: 20  loss: 0.00797091\n",
      "epoch: 50  batch: 21  loss: 0.01222122\n",
      "epoch: 50  batch: 22  loss: 0.00165222\n",
      "epoch: 50  batch: 23  loss: 0.00385399\n",
      "epoch: 50  batch: 24  loss: 0.01302418\n",
      "epoch: 50  batch: 25  loss: 0.00655396\n",
      "epoch: 50  batch: 26  loss: 0.00189529\n",
      "epoch: 50  batch: 27  loss: 0.00422228\n",
      "epoch: 50  batch: 28  loss: 0.00398781\n",
      "epoch: 51  batch: 1  loss: 0.00246977\n",
      "epoch: 51  batch: 2  loss: 0.00288016\n",
      "epoch: 51  batch: 3  loss: 0.00096063\n",
      "epoch: 51  batch: 4  loss: 0.00311081\n",
      "epoch: 51  batch: 5  loss: 0.02328582\n",
      "epoch: 51  batch: 6  loss: 0.00221341\n",
      "epoch: 51  batch: 7  loss: 0.00262400\n",
      "epoch: 51  batch: 8  loss: 0.00232259\n",
      "epoch: 51  batch: 9  loss: 0.00655556\n",
      "epoch: 51  batch: 10  loss: 0.00827241\n",
      "epoch: 51  batch: 11  loss: 0.00204209\n",
      "epoch: 51  batch: 12  loss: 0.00891899\n",
      "epoch: 51  batch: 13  loss: 0.00797604\n",
      "epoch: 51  batch: 14  loss: 0.00332461\n",
      "epoch: 51  batch: 15  loss: 0.00932036\n",
      "epoch: 51  batch: 16  loss: 0.01302973\n",
      "epoch: 51  batch: 17  loss: 0.00169304\n",
      "epoch: 51  batch: 18  loss: 0.00139730\n",
      "epoch: 51  batch: 19  loss: 0.00463207\n",
      "epoch: 51  batch: 20  loss: 0.00401738\n",
      "epoch: 51  batch: 21  loss: 0.00492974\n",
      "epoch: 51  batch: 22  loss: 0.00677778\n",
      "epoch: 51  batch: 23  loss: 0.00440600\n",
      "epoch: 51  batch: 24  loss: 0.01027107\n",
      "epoch: 51  batch: 25  loss: 0.00905416\n",
      "epoch: 51  batch: 26  loss: 0.00435331\n",
      "epoch: 51  batch: 27  loss: 0.02019111\n",
      "epoch: 51  batch: 28  loss: 0.00619287\n",
      "epoch: 52  batch: 1  loss: 0.01391415\n",
      "epoch: 52  batch: 2  loss: 0.00214730\n",
      "epoch: 52  batch: 3  loss: 0.00467247\n",
      "epoch: 52  batch: 4  loss: 0.01132039\n",
      "epoch: 52  batch: 5  loss: 0.02272684\n",
      "epoch: 52  batch: 6  loss: 0.00802831\n",
      "epoch: 52  batch: 7  loss: 0.00296804\n",
      "epoch: 52  batch: 8  loss: 0.00371325\n",
      "epoch: 52  batch: 9  loss: 0.00249245\n",
      "epoch: 52  batch: 10  loss: 0.00380332\n",
      "epoch: 52  batch: 11  loss: 0.00266719\n",
      "epoch: 52  batch: 12  loss: 0.00363120\n",
      "epoch: 52  batch: 13  loss: 0.00332559\n",
      "epoch: 52  batch: 14  loss: 0.00349909\n",
      "epoch: 52  batch: 15  loss: 0.00209962\n",
      "epoch: 52  batch: 16  loss: 0.00165011\n",
      "epoch: 52  batch: 17  loss: 0.00467956\n",
      "epoch: 52  batch: 18  loss: 0.00264037\n",
      "epoch: 52  batch: 19  loss: 0.00306945\n",
      "epoch: 52  batch: 20  loss: 0.00450606\n",
      "epoch: 52  batch: 21  loss: 0.00557083\n",
      "epoch: 52  batch: 22  loss: 0.00453026\n",
      "epoch: 52  batch: 23  loss: 0.00526038\n",
      "epoch: 52  batch: 24  loss: 0.00611086\n",
      "epoch: 52  batch: 25  loss: 0.00534749\n",
      "epoch: 52  batch: 26  loss: 0.00546503\n",
      "epoch: 52  batch: 27  loss: 0.00965954\n",
      "epoch: 52  batch: 28  loss: 0.00323533\n",
      "epoch: 53  batch: 1  loss: 0.02448812\n",
      "epoch: 53  batch: 2  loss: 0.00289868\n",
      "epoch: 53  batch: 3  loss: 0.00162884\n",
      "epoch: 53  batch: 4  loss: 0.00524444\n",
      "epoch: 53  batch: 5  loss: 0.00207059\n",
      "epoch: 53  batch: 6  loss: 0.00102221\n",
      "epoch: 53  batch: 7  loss: 0.00304520\n",
      "epoch: 53  batch: 8  loss: 0.00228600\n",
      "epoch: 53  batch: 9  loss: 0.00213880\n",
      "epoch: 53  batch: 10  loss: 0.01204455\n",
      "epoch: 53  batch: 11  loss: 0.00714969\n",
      "epoch: 53  batch: 12  loss: 0.01537013\n",
      "epoch: 53  batch: 13  loss: 0.00224658\n",
      "epoch: 53  batch: 14  loss: 0.02931700\n",
      "epoch: 53  batch: 15  loss: 0.00348593\n",
      "epoch: 53  batch: 16  loss: 0.01295183\n",
      "epoch: 53  batch: 17  loss: 0.00813330\n",
      "epoch: 53  batch: 18  loss: 0.00287826\n",
      "epoch: 53  batch: 19  loss: 0.00352983\n",
      "epoch: 53  batch: 20  loss: 0.00317032\n",
      "epoch: 53  batch: 21  loss: 0.00393546\n",
      "epoch: 53  batch: 22  loss: 0.00325763\n",
      "epoch: 53  batch: 23  loss: 0.00265883\n",
      "epoch: 53  batch: 24  loss: 0.00425162\n",
      "epoch: 53  batch: 25  loss: 0.00334543\n",
      "epoch: 53  batch: 26  loss: 0.00267727\n",
      "epoch: 53  batch: 27  loss: 0.00137666\n",
      "epoch: 53  batch: 28  loss: 0.00303862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 54  batch: 1  loss: 0.00398049\n",
      "epoch: 54  batch: 2  loss: 0.00191866\n",
      "epoch: 54  batch: 3  loss: 0.00715553\n",
      "epoch: 54  batch: 4  loss: 0.00243594\n",
      "epoch: 54  batch: 5  loss: 0.00300573\n",
      "epoch: 54  batch: 6  loss: 0.00142835\n",
      "epoch: 54  batch: 7  loss: 0.00655761\n",
      "epoch: 54  batch: 8  loss: 0.00623864\n",
      "epoch: 54  batch: 9  loss: 0.00248534\n",
      "epoch: 54  batch: 10  loss: 0.00213433\n",
      "epoch: 54  batch: 11  loss: 0.00440299\n",
      "epoch: 54  batch: 12  loss: 0.01519646\n",
      "epoch: 54  batch: 13  loss: 0.00842865\n",
      "epoch: 54  batch: 14  loss: 0.00407317\n",
      "epoch: 54  batch: 15  loss: 0.00942051\n",
      "epoch: 54  batch: 16  loss: 0.00514378\n",
      "epoch: 54  batch: 17  loss: 0.00293544\n",
      "epoch: 54  batch: 18  loss: 0.00362836\n",
      "epoch: 54  batch: 19  loss: 0.00990633\n",
      "epoch: 54  batch: 20  loss: 0.00874521\n",
      "epoch: 54  batch: 21  loss: 0.00412256\n",
      "epoch: 54  batch: 22  loss: 0.00194791\n",
      "epoch: 54  batch: 23  loss: 0.00531538\n",
      "epoch: 54  batch: 24  loss: 0.00127961\n",
      "epoch: 54  batch: 25  loss: 0.02313403\n",
      "epoch: 54  batch: 26  loss: 0.00463722\n",
      "epoch: 54  batch: 27  loss: 0.00441870\n",
      "epoch: 54  batch: 28  loss: 0.00185406\n",
      "epoch: 55  batch: 1  loss: 0.00312385\n",
      "epoch: 55  batch: 2  loss: 0.00220191\n",
      "epoch: 55  batch: 3  loss: 0.00805596\n",
      "epoch: 55  batch: 4  loss: 0.00696620\n",
      "epoch: 55  batch: 5  loss: 0.00397234\n",
      "epoch: 55  batch: 6  loss: 0.02476762\n",
      "epoch: 55  batch: 7  loss: 0.00452939\n",
      "epoch: 55  batch: 8  loss: 0.00556577\n",
      "epoch: 55  batch: 9  loss: 0.01439014\n",
      "epoch: 55  batch: 10  loss: 0.00351177\n",
      "epoch: 55  batch: 11  loss: 0.00444694\n",
      "epoch: 55  batch: 12  loss: 0.00349163\n",
      "epoch: 55  batch: 13  loss: 0.00987638\n",
      "epoch: 55  batch: 14  loss: 0.00358681\n",
      "epoch: 55  batch: 15  loss: 0.01460930\n",
      "epoch: 55  batch: 16  loss: 0.00527578\n",
      "epoch: 55  batch: 17  loss: 0.00355083\n",
      "epoch: 55  batch: 18  loss: 0.01087239\n",
      "epoch: 55  batch: 19  loss: 0.00802106\n",
      "epoch: 55  batch: 20  loss: 0.00323252\n",
      "epoch: 55  batch: 21  loss: 0.00321423\n",
      "epoch: 55  batch: 22  loss: 0.01121787\n",
      "epoch: 55  batch: 23  loss: 0.00374846\n",
      "epoch: 55  batch: 24  loss: 0.00401528\n",
      "epoch: 55  batch: 25  loss: 0.00366728\n",
      "epoch: 55  batch: 26  loss: 0.00162631\n",
      "epoch: 55  batch: 27  loss: 0.00524159\n",
      "epoch: 55  batch: 28  loss: 0.00381274\n",
      "epoch: 56  batch: 1  loss: 0.00272093\n",
      "epoch: 56  batch: 2  loss: 0.00490107\n",
      "epoch: 56  batch: 3  loss: 0.00826039\n",
      "epoch: 56  batch: 4  loss: 0.00465471\n",
      "epoch: 56  batch: 5  loss: 0.00360754\n",
      "epoch: 56  batch: 6  loss: 0.00439043\n",
      "epoch: 56  batch: 7  loss: 0.00311661\n",
      "epoch: 56  batch: 8  loss: 0.00693777\n",
      "epoch: 56  batch: 9  loss: 0.03705564\n",
      "epoch: 56  batch: 10  loss: 0.00783635\n",
      "epoch: 56  batch: 11  loss: 0.00738626\n",
      "epoch: 56  batch: 12  loss: 0.00448483\n",
      "epoch: 56  batch: 13  loss: 0.00393381\n",
      "epoch: 56  batch: 14  loss: 0.01616558\n",
      "epoch: 56  batch: 15  loss: 0.00421969\n",
      "epoch: 56  batch: 16  loss: 0.00229235\n",
      "epoch: 56  batch: 17  loss: 0.00951713\n",
      "epoch: 56  batch: 18  loss: 0.00270067\n",
      "epoch: 56  batch: 19  loss: 0.00420165\n",
      "epoch: 56  batch: 20  loss: 0.00926944\n",
      "epoch: 56  batch: 21  loss: 0.00573146\n",
      "epoch: 56  batch: 22  loss: 0.00404083\n",
      "epoch: 56  batch: 23  loss: 0.00435020\n",
      "epoch: 56  batch: 24  loss: 0.00224238\n",
      "epoch: 56  batch: 25  loss: 0.00404100\n",
      "epoch: 56  batch: 26  loss: 0.00351710\n",
      "epoch: 56  batch: 27  loss: 0.00258494\n",
      "epoch: 56  batch: 28  loss: 0.00353485\n",
      "epoch: 57  batch: 1  loss: 0.00312337\n",
      "epoch: 57  batch: 2  loss: 0.00403478\n",
      "epoch: 57  batch: 3  loss: 0.00151997\n",
      "epoch: 57  batch: 4  loss: 0.00378432\n",
      "epoch: 57  batch: 5  loss: 0.00356880\n",
      "epoch: 57  batch: 6  loss: 0.00184549\n",
      "epoch: 57  batch: 7  loss: 0.00774434\n",
      "epoch: 57  batch: 8  loss: 0.00381299\n",
      "epoch: 57  batch: 9  loss: 0.01012212\n",
      "epoch: 57  batch: 10  loss: 0.00183413\n",
      "epoch: 57  batch: 11  loss: 0.00532535\n",
      "epoch: 57  batch: 12  loss: 0.02423549\n",
      "epoch: 57  batch: 13  loss: 0.00339477\n",
      "epoch: 57  batch: 14  loss: 0.00504484\n",
      "epoch: 57  batch: 15  loss: 0.00282226\n",
      "epoch: 57  batch: 16  loss: 0.00187160\n",
      "epoch: 57  batch: 17  loss: 0.00389903\n",
      "epoch: 57  batch: 18  loss: 0.00862803\n",
      "epoch: 57  batch: 19  loss: 0.00592709\n",
      "epoch: 57  batch: 20  loss: 0.00244947\n",
      "epoch: 57  batch: 21  loss: 0.00982079\n",
      "epoch: 57  batch: 22  loss: 0.00185252\n",
      "epoch: 57  batch: 23  loss: 0.02717921\n",
      "epoch: 57  batch: 24  loss: 0.00182221\n",
      "epoch: 57  batch: 25  loss: 0.00434017\n",
      "epoch: 57  batch: 26  loss: 0.02103527\n",
      "epoch: 57  batch: 27  loss: 0.00600536\n",
      "epoch: 57  batch: 28  loss: 0.01121819\n",
      "epoch: 58  batch: 1  loss: 0.00259781\n",
      "epoch: 58  batch: 2  loss: 0.00251778\n",
      "epoch: 58  batch: 3  loss: 0.01061892\n",
      "epoch: 58  batch: 4  loss: 0.01225921\n",
      "epoch: 58  batch: 5  loss: 0.00882614\n",
      "epoch: 58  batch: 6  loss: 0.00465547\n",
      "epoch: 58  batch: 7  loss: 0.00610588\n",
      "epoch: 58  batch: 8  loss: 0.00275462\n",
      "epoch: 58  batch: 9  loss: 0.00482315\n",
      "epoch: 58  batch: 10  loss: 0.00614721\n",
      "epoch: 58  batch: 11  loss: 0.00401921\n",
      "epoch: 58  batch: 12  loss: 0.00516832\n",
      "epoch: 58  batch: 13  loss: 0.00263789\n",
      "epoch: 58  batch: 14  loss: 0.00290946\n",
      "epoch: 58  batch: 15  loss: 0.00319381\n",
      "epoch: 58  batch: 16  loss: 0.00292086\n",
      "epoch: 58  batch: 17  loss: 0.00488401\n",
      "epoch: 58  batch: 18  loss: 0.01144776\n",
      "epoch: 58  batch: 19  loss: 0.01123675\n",
      "epoch: 58  batch: 20  loss: 0.00306063\n",
      "epoch: 58  batch: 21  loss: 0.02108984\n",
      "epoch: 58  batch: 22  loss: 0.00354435\n",
      "epoch: 58  batch: 23  loss: 0.00153048\n",
      "epoch: 58  batch: 24  loss: 0.00156800\n",
      "epoch: 58  batch: 25  loss: 0.00905750\n",
      "epoch: 58  batch: 26  loss: 0.00696577\n",
      "epoch: 58  batch: 27  loss: 0.00570679\n",
      "epoch: 58  batch: 28  loss: 0.00223596\n",
      "epoch: 59  batch: 1  loss: 0.00391402\n",
      "epoch: 59  batch: 2  loss: 0.01136239\n",
      "epoch: 59  batch: 3  loss: 0.00610772\n",
      "epoch: 59  batch: 4  loss: 0.00743203\n",
      "epoch: 59  batch: 5  loss: 0.00209889\n",
      "epoch: 59  batch: 6  loss: 0.00521709\n",
      "epoch: 59  batch: 7  loss: 0.01161636\n",
      "epoch: 59  batch: 8  loss: 0.00310551\n",
      "epoch: 59  batch: 9  loss: 0.00285783\n",
      "epoch: 59  batch: 10  loss: 0.01275586\n",
      "epoch: 59  batch: 11  loss: 0.00391686\n",
      "epoch: 59  batch: 12  loss: 0.00310439\n",
      "epoch: 59  batch: 13  loss: 0.00356561\n",
      "epoch: 59  batch: 14  loss: 0.00725171\n",
      "epoch: 59  batch: 15  loss: 0.00992879\n",
      "epoch: 59  batch: 16  loss: 0.00150252\n",
      "epoch: 59  batch: 17  loss: 0.00359639\n",
      "epoch: 59  batch: 18  loss: 0.00190873\n",
      "epoch: 59  batch: 19  loss: 0.00397562\n",
      "epoch: 59  batch: 20  loss: 0.00547714\n",
      "epoch: 59  batch: 21  loss: 0.00433745\n",
      "epoch: 59  batch: 22  loss: 0.00826706\n",
      "epoch: 59  batch: 23  loss: 0.00383108\n",
      "epoch: 59  batch: 24  loss: 0.02256811\n",
      "epoch: 59  batch: 25  loss: 0.00178860\n",
      "epoch: 59  batch: 26  loss: 0.00201275\n",
      "epoch: 59  batch: 27  loss: 0.00973920\n",
      "epoch: 59  batch: 28  loss: 0.01010187\n",
      "epoch: 60  batch: 1  loss: 0.02481929\n",
      "epoch: 60  batch: 2  loss: 0.00918636\n",
      "epoch: 60  batch: 3  loss: 0.00416791\n",
      "epoch: 60  batch: 4  loss: 0.00128347\n",
      "epoch: 60  batch: 5  loss: 0.00502785\n",
      "epoch: 60  batch: 6  loss: 0.00232880\n",
      "epoch: 60  batch: 7  loss: 0.00363826\n",
      "epoch: 60  batch: 8  loss: 0.00767942\n",
      "epoch: 60  batch: 9  loss: 0.00592570\n",
      "epoch: 60  batch: 10  loss: 0.01053375\n",
      "epoch: 60  batch: 11  loss: 0.00400083\n",
      "epoch: 60  batch: 12  loss: 0.00374509\n",
      "epoch: 60  batch: 13  loss: 0.00519602\n",
      "epoch: 60  batch: 14  loss: 0.00526106\n",
      "epoch: 60  batch: 15  loss: 0.00877279\n",
      "epoch: 60  batch: 16  loss: 0.00342008\n",
      "epoch: 60  batch: 17  loss: 0.00554770\n",
      "epoch: 60  batch: 18  loss: 0.01280007\n",
      "epoch: 60  batch: 19  loss: 0.00159376\n",
      "epoch: 60  batch: 20  loss: 0.00226735\n",
      "epoch: 60  batch: 21  loss: 0.01762211\n",
      "epoch: 60  batch: 22  loss: 0.00295333\n",
      "epoch: 60  batch: 23  loss: 0.00490679\n",
      "epoch: 60  batch: 24  loss: 0.00059264\n",
      "epoch: 60  batch: 25  loss: 0.00676447\n",
      "epoch: 60  batch: 26  loss: 0.00796481\n",
      "epoch: 60  batch: 27  loss: 0.00119443\n",
      "epoch: 60  batch: 28  loss: 0.00100953\n",
      "epoch: 61  batch: 1  loss: 0.00497930\n",
      "epoch: 61  batch: 2  loss: 0.00606547\n",
      "epoch: 61  batch: 3  loss: 0.00267815\n",
      "epoch: 61  batch: 4  loss: 0.00333293\n",
      "epoch: 61  batch: 5  loss: 0.00217680\n",
      "epoch: 61  batch: 6  loss: 0.01791644\n",
      "epoch: 61  batch: 7  loss: 0.00304213\n",
      "epoch: 61  batch: 8  loss: 0.00232695\n",
      "epoch: 61  batch: 9  loss: 0.00314562\n",
      "epoch: 61  batch: 10  loss: 0.00760364\n",
      "epoch: 61  batch: 11  loss: 0.00144565\n",
      "epoch: 61  batch: 12  loss: 0.00154329\n",
      "epoch: 61  batch: 13  loss: 0.00246107\n",
      "epoch: 61  batch: 14  loss: 0.01339822\n",
      "epoch: 61  batch: 15  loss: 0.00628149\n",
      "epoch: 61  batch: 16  loss: 0.00394373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 61  batch: 17  loss: 0.01061077\n",
      "epoch: 61  batch: 18  loss: 0.00802185\n",
      "epoch: 61  batch: 19  loss: 0.00217963\n",
      "epoch: 61  batch: 20  loss: 0.00576146\n",
      "epoch: 61  batch: 21  loss: 0.04058519\n",
      "epoch: 61  batch: 22  loss: 0.00211691\n",
      "epoch: 61  batch: 23  loss: 0.00576417\n",
      "epoch: 61  batch: 24  loss: 0.01008681\n",
      "epoch: 61  batch: 25  loss: 0.00276529\n",
      "epoch: 61  batch: 26  loss: 0.00352122\n",
      "epoch: 61  batch: 27  loss: 0.01155243\n",
      "epoch: 61  batch: 28  loss: 0.00311443\n",
      "epoch: 62  batch: 1  loss: 0.00169339\n",
      "epoch: 62  batch: 2  loss: 0.00327089\n",
      "epoch: 62  batch: 3  loss: 0.00526732\n",
      "epoch: 62  batch: 4  loss: 0.00796407\n",
      "epoch: 62  batch: 5  loss: 0.00633893\n",
      "epoch: 62  batch: 6  loss: 0.00451753\n",
      "epoch: 62  batch: 7  loss: 0.00366386\n",
      "epoch: 62  batch: 8  loss: 0.00385873\n",
      "epoch: 62  batch: 9  loss: 0.02223451\n",
      "epoch: 62  batch: 10  loss: 0.00328600\n",
      "epoch: 62  batch: 11  loss: 0.00132230\n",
      "epoch: 62  batch: 12  loss: 0.00257692\n",
      "epoch: 62  batch: 13  loss: 0.00152246\n",
      "epoch: 62  batch: 14  loss: 0.00357131\n",
      "epoch: 62  batch: 15  loss: 0.00424770\n",
      "epoch: 62  batch: 16  loss: 0.00364362\n",
      "epoch: 62  batch: 17  loss: 0.00914523\n",
      "epoch: 62  batch: 18  loss: 0.00593359\n",
      "epoch: 62  batch: 19  loss: 0.00306324\n",
      "epoch: 62  batch: 20  loss: 0.02030217\n",
      "epoch: 62  batch: 21  loss: 0.00139679\n",
      "epoch: 62  batch: 22  loss: 0.00324120\n",
      "epoch: 62  batch: 23  loss: 0.00784059\n",
      "epoch: 62  batch: 24  loss: 0.01031456\n",
      "epoch: 62  batch: 25  loss: 0.00231086\n",
      "epoch: 62  batch: 26  loss: 0.00527528\n",
      "epoch: 62  batch: 27  loss: 0.00178722\n",
      "epoch: 62  batch: 28  loss: 0.01127434\n",
      "epoch: 63  batch: 1  loss: 0.01775689\n",
      "epoch: 63  batch: 2  loss: 0.00237107\n",
      "epoch: 63  batch: 3  loss: 0.00129483\n",
      "epoch: 63  batch: 4  loss: 0.00725067\n",
      "epoch: 63  batch: 5  loss: 0.00760485\n",
      "epoch: 63  batch: 6  loss: 0.00871916\n",
      "epoch: 63  batch: 7  loss: 0.00145479\n",
      "epoch: 63  batch: 8  loss: 0.00266104\n",
      "epoch: 63  batch: 9  loss: 0.00229352\n",
      "epoch: 63  batch: 10  loss: 0.00773321\n",
      "epoch: 63  batch: 11  loss: 0.00098236\n",
      "epoch: 63  batch: 12  loss: 0.00385075\n",
      "epoch: 63  batch: 13  loss: 0.00207305\n",
      "epoch: 63  batch: 14  loss: 0.00204541\n",
      "epoch: 63  batch: 15  loss: 0.00414644\n",
      "epoch: 63  batch: 16  loss: 0.00095516\n",
      "epoch: 63  batch: 17  loss: 0.00301267\n",
      "epoch: 63  batch: 18  loss: 0.03747721\n",
      "epoch: 63  batch: 19  loss: 0.00319040\n",
      "epoch: 63  batch: 20  loss: 0.02201512\n",
      "epoch: 63  batch: 21  loss: 0.00589022\n",
      "epoch: 63  batch: 22  loss: 0.00331888\n",
      "epoch: 63  batch: 23  loss: 0.00388828\n",
      "epoch: 63  batch: 24  loss: 0.01140768\n",
      "epoch: 63  batch: 25  loss: 0.00444644\n",
      "epoch: 63  batch: 26  loss: 0.00680292\n",
      "epoch: 63  batch: 27  loss: 0.01125678\n",
      "epoch: 63  batch: 28  loss: 0.00538959\n",
      "epoch: 64  batch: 1  loss: 0.00132651\n",
      "epoch: 64  batch: 2  loss: 0.00251052\n",
      "epoch: 64  batch: 3  loss: 0.00611828\n",
      "epoch: 64  batch: 4  loss: 0.00228570\n",
      "epoch: 64  batch: 5  loss: 0.00328508\n",
      "epoch: 64  batch: 6  loss: 0.00722345\n",
      "epoch: 64  batch: 7  loss: 0.01076515\n",
      "epoch: 64  batch: 8  loss: 0.00373755\n",
      "epoch: 64  batch: 9  loss: 0.00070637\n",
      "epoch: 64  batch: 10  loss: 0.01249261\n",
      "epoch: 64  batch: 11  loss: 0.00954995\n",
      "epoch: 64  batch: 12  loss: 0.01093838\n",
      "epoch: 64  batch: 13  loss: 0.00263372\n",
      "epoch: 64  batch: 14  loss: 0.00272247\n",
      "epoch: 64  batch: 15  loss: 0.00598902\n",
      "epoch: 64  batch: 16  loss: 0.00137005\n",
      "epoch: 64  batch: 17  loss: 0.00420142\n",
      "epoch: 64  batch: 18  loss: 0.00201092\n",
      "epoch: 64  batch: 19  loss: 0.00284550\n",
      "epoch: 64  batch: 20  loss: 0.00520302\n",
      "epoch: 64  batch: 21  loss: 0.00236992\n",
      "epoch: 64  batch: 22  loss: 0.00611939\n",
      "epoch: 64  batch: 23  loss: 0.00502112\n",
      "epoch: 64  batch: 24  loss: 0.00187433\n",
      "epoch: 64  batch: 25  loss: 0.02307804\n",
      "epoch: 64  batch: 26  loss: 0.00299887\n",
      "epoch: 64  batch: 27  loss: 0.00802585\n",
      "epoch: 64  batch: 28  loss: 0.00095435\n",
      "epoch: 65  batch: 1  loss: 0.00159829\n",
      "epoch: 65  batch: 2  loss: 0.00357183\n",
      "epoch: 65  batch: 3  loss: 0.00377007\n",
      "epoch: 65  batch: 4  loss: 0.00203554\n",
      "epoch: 65  batch: 5  loss: 0.00346495\n",
      "epoch: 65  batch: 6  loss: 0.00146766\n",
      "epoch: 65  batch: 7  loss: 0.02697143\n",
      "epoch: 65  batch: 8  loss: 0.00539473\n",
      "epoch: 65  batch: 9  loss: 0.00456354\n",
      "epoch: 65  batch: 10  loss: 0.01338608\n",
      "epoch: 65  batch: 11  loss: 0.00286589\n",
      "epoch: 65  batch: 12  loss: 0.00664472\n",
      "epoch: 65  batch: 13  loss: 0.00344776\n",
      "epoch: 65  batch: 14  loss: 0.00233133\n",
      "epoch: 65  batch: 15  loss: 0.00944570\n",
      "epoch: 65  batch: 16  loss: 0.00632025\n",
      "epoch: 65  batch: 17  loss: 0.00856960\n",
      "epoch: 65  batch: 18  loss: 0.00204315\n",
      "epoch: 65  batch: 19  loss: 0.00178441\n",
      "epoch: 65  batch: 20  loss: 0.01795515\n",
      "epoch: 65  batch: 21  loss: 0.00185655\n",
      "epoch: 65  batch: 22  loss: 0.00262939\n",
      "epoch: 65  batch: 23  loss: 0.00146707\n",
      "epoch: 65  batch: 24  loss: 0.00444188\n",
      "epoch: 65  batch: 25  loss: 0.00222590\n",
      "epoch: 65  batch: 26  loss: 0.00687806\n",
      "epoch: 65  batch: 27  loss: 0.00879241\n",
      "epoch: 65  batch: 28  loss: 0.00670663\n",
      "epoch: 66  batch: 1  loss: 0.00154994\n",
      "epoch: 66  batch: 2  loss: 0.01080764\n",
      "epoch: 66  batch: 3  loss: 0.01980159\n",
      "epoch: 66  batch: 4  loss: 0.01862643\n",
      "epoch: 66  batch: 5  loss: 0.00146159\n",
      "epoch: 66  batch: 6  loss: 0.00287469\n",
      "epoch: 66  batch: 7  loss: 0.00170966\n",
      "epoch: 66  batch: 8  loss: 0.00902151\n",
      "epoch: 66  batch: 9  loss: 0.00810319\n",
      "epoch: 66  batch: 10  loss: 0.00419818\n",
      "epoch: 66  batch: 11  loss: 0.00554351\n",
      "epoch: 66  batch: 12  loss: 0.00355406\n",
      "epoch: 66  batch: 13  loss: 0.00198424\n",
      "epoch: 66  batch: 14  loss: 0.00997401\n",
      "epoch: 66  batch: 15  loss: 0.00122187\n",
      "epoch: 66  batch: 16  loss: 0.00137510\n",
      "epoch: 66  batch: 17  loss: 0.00189833\n",
      "epoch: 66  batch: 18  loss: 0.00682948\n",
      "epoch: 66  batch: 19  loss: 0.00195027\n",
      "epoch: 66  batch: 20  loss: 0.00125434\n",
      "epoch: 66  batch: 21  loss: 0.00946652\n",
      "epoch: 66  batch: 22  loss: 0.00382269\n",
      "epoch: 66  batch: 23  loss: 0.00398360\n",
      "epoch: 66  batch: 24  loss: 0.00442779\n",
      "epoch: 66  batch: 25  loss: 0.00321431\n",
      "epoch: 66  batch: 26  loss: 0.00631220\n",
      "epoch: 66  batch: 27  loss: 0.01234073\n",
      "epoch: 66  batch: 28  loss: 0.00502860\n",
      "epoch: 67  batch: 1  loss: 0.00242500\n",
      "epoch: 67  batch: 2  loss: 0.00302772\n",
      "epoch: 67  batch: 3  loss: 0.00960671\n",
      "epoch: 67  batch: 4  loss: 0.01713094\n",
      "epoch: 67  batch: 5  loss: 0.00284427\n",
      "epoch: 67  batch: 6  loss: 0.00663536\n",
      "epoch: 67  batch: 7  loss: 0.00791392\n",
      "epoch: 67  batch: 8  loss: 0.00162613\n",
      "epoch: 67  batch: 9  loss: 0.01309865\n",
      "epoch: 67  batch: 10  loss: 0.00048827\n",
      "epoch: 67  batch: 11  loss: 0.00118003\n",
      "epoch: 67  batch: 12  loss: 0.00385543\n",
      "epoch: 67  batch: 13  loss: 0.00585951\n",
      "epoch: 67  batch: 14  loss: 0.00583979\n",
      "epoch: 67  batch: 15  loss: 0.00453373\n",
      "epoch: 67  batch: 16  loss: 0.00230165\n",
      "epoch: 67  batch: 17  loss: 0.01712182\n",
      "epoch: 67  batch: 18  loss: 0.00271791\n",
      "epoch: 67  batch: 19  loss: 0.00198939\n",
      "epoch: 67  batch: 20  loss: 0.00341278\n",
      "epoch: 67  batch: 21  loss: 0.00679359\n",
      "epoch: 67  batch: 22  loss: 0.00246903\n",
      "epoch: 67  batch: 23  loss: 0.00257373\n",
      "epoch: 67  batch: 24  loss: 0.00501687\n",
      "epoch: 67  batch: 25  loss: 0.00226034\n",
      "epoch: 67  batch: 26  loss: 0.00284732\n",
      "epoch: 67  batch: 27  loss: 0.00452669\n",
      "epoch: 67  batch: 28  loss: 0.00126120\n",
      "epoch: 68  batch: 1  loss: 0.00208758\n",
      "epoch: 68  batch: 2  loss: 0.00220434\n",
      "epoch: 68  batch: 3  loss: 0.00377094\n",
      "epoch: 68  batch: 4  loss: 0.13759133\n",
      "epoch: 68  batch: 5  loss: 0.00362113\n",
      "epoch: 68  batch: 6  loss: 0.01106436\n",
      "epoch: 68  batch: 7  loss: 0.00838313\n",
      "epoch: 68  batch: 8  loss: 0.00462449\n",
      "epoch: 68  batch: 9  loss: 0.00238048\n",
      "epoch: 68  batch: 10  loss: 0.13191593\n",
      "epoch: 68  batch: 11  loss: 0.00407377\n",
      "epoch: 68  batch: 12  loss: 0.00137942\n",
      "epoch: 68  batch: 13  loss: 0.00467026\n",
      "epoch: 68  batch: 14  loss: 0.00118251\n",
      "epoch: 68  batch: 15  loss: 0.00671622\n",
      "epoch: 68  batch: 16  loss: 0.02119010\n",
      "epoch: 68  batch: 17  loss: 0.00337741\n",
      "epoch: 68  batch: 18  loss: 0.00771837\n",
      "epoch: 68  batch: 19  loss: 0.00199900\n",
      "epoch: 68  batch: 20  loss: 0.01000155\n",
      "epoch: 68  batch: 21  loss: 0.00430351\n",
      "epoch: 68  batch: 22  loss: 0.00258487\n",
      "epoch: 68  batch: 23  loss: 0.00447382\n",
      "epoch: 68  batch: 24  loss: 0.00541051\n",
      "epoch: 68  batch: 25  loss: 0.00845710\n",
      "epoch: 68  batch: 26  loss: 0.00899981\n",
      "epoch: 68  batch: 27  loss: 0.00387998\n",
      "epoch: 68  batch: 28  loss: 0.00151464\n",
      "epoch: 69  batch: 1  loss: 0.01123896\n",
      "epoch: 69  batch: 2  loss: 0.00235476\n",
      "epoch: 69  batch: 3  loss: 0.02271486\n",
      "epoch: 69  batch: 4  loss: 0.00264846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 69  batch: 5  loss: 0.00216015\n",
      "epoch: 69  batch: 6  loss: 0.00341273\n",
      "epoch: 69  batch: 7  loss: 0.01152800\n",
      "epoch: 69  batch: 8  loss: 0.00422645\n",
      "epoch: 69  batch: 9  loss: 0.00334851\n",
      "epoch: 69  batch: 10  loss: 0.00578682\n",
      "epoch: 69  batch: 11  loss: 0.00722482\n",
      "epoch: 69  batch: 12  loss: 0.00324116\n",
      "epoch: 69  batch: 13  loss: 0.00196473\n",
      "epoch: 69  batch: 14  loss: 0.02132596\n",
      "epoch: 69  batch: 15  loss: 0.00103741\n",
      "epoch: 69  batch: 16  loss: 0.00445250\n",
      "epoch: 69  batch: 17  loss: 0.00136278\n",
      "epoch: 69  batch: 18  loss: 0.00968396\n",
      "epoch: 69  batch: 19  loss: 0.00289380\n",
      "epoch: 69  batch: 20  loss: 0.00533204\n",
      "epoch: 69  batch: 21  loss: 0.00400736\n",
      "epoch: 69  batch: 22  loss: 0.01149686\n",
      "epoch: 69  batch: 23  loss: 0.00431862\n",
      "epoch: 69  batch: 24  loss: 0.00658526\n",
      "epoch: 69  batch: 25  loss: 0.00271594\n",
      "epoch: 69  batch: 26  loss: 0.01567597\n",
      "epoch: 69  batch: 27  loss: 0.00178466\n",
      "epoch: 69  batch: 28  loss: 0.00719803\n",
      "epoch: 70  batch: 1  loss: 0.00327727\n",
      "epoch: 70  batch: 2  loss: 0.00442677\n",
      "epoch: 70  batch: 3  loss: 0.00477938\n",
      "epoch: 70  batch: 4  loss: 0.00462038\n",
      "epoch: 70  batch: 5  loss: 0.00430976\n",
      "epoch: 70  batch: 6  loss: 0.00201243\n",
      "epoch: 70  batch: 7  loss: 0.00647431\n",
      "epoch: 70  batch: 8  loss: 0.00110227\n",
      "epoch: 70  batch: 9  loss: 0.00464057\n",
      "epoch: 70  batch: 10  loss: 0.00317722\n",
      "epoch: 70  batch: 11  loss: 0.01449908\n",
      "epoch: 70  batch: 12  loss: 0.00599778\n",
      "epoch: 70  batch: 13  loss: 0.00497780\n",
      "epoch: 70  batch: 14  loss: 0.00184975\n",
      "epoch: 70  batch: 15  loss: 0.00123527\n",
      "epoch: 70  batch: 16  loss: 0.00569460\n",
      "epoch: 70  batch: 17  loss: 0.00474469\n",
      "epoch: 70  batch: 18  loss: 0.00595922\n",
      "epoch: 70  batch: 19  loss: 0.00197789\n",
      "epoch: 70  batch: 20  loss: 0.01053389\n",
      "epoch: 70  batch: 21  loss: 0.00282987\n",
      "epoch: 70  batch: 22  loss: 0.00536885\n",
      "epoch: 70  batch: 23  loss: 0.00371188\n",
      "epoch: 70  batch: 24  loss: 0.00502075\n",
      "epoch: 70  batch: 25  loss: 0.00309887\n",
      "epoch: 70  batch: 26  loss: 0.02374874\n",
      "epoch: 70  batch: 27  loss: 0.00131465\n",
      "epoch: 70  batch: 28  loss: 0.00382544\n",
      "epoch: 71  batch: 1  loss: 0.00708758\n",
      "epoch: 71  batch: 2  loss: 0.00182534\n",
      "epoch: 71  batch: 3  loss: 0.00561422\n",
      "epoch: 71  batch: 4  loss: 0.00279853\n",
      "epoch: 71  batch: 5  loss: 0.01667777\n",
      "epoch: 71  batch: 6  loss: 0.00975890\n",
      "epoch: 71  batch: 7  loss: 0.00669804\n",
      "epoch: 71  batch: 8  loss: 0.00234508\n",
      "epoch: 71  batch: 9  loss: 0.00214061\n",
      "epoch: 71  batch: 10  loss: 0.00455173\n",
      "epoch: 71  batch: 11  loss: 0.00349318\n",
      "epoch: 71  batch: 12  loss: 0.00441429\n",
      "epoch: 71  batch: 13  loss: 0.00369112\n",
      "epoch: 71  batch: 14  loss: 0.00667817\n",
      "epoch: 71  batch: 15  loss: 0.00197511\n",
      "epoch: 71  batch: 16  loss: 0.00193927\n",
      "epoch: 71  batch: 17  loss: 0.00418962\n",
      "epoch: 71  batch: 18  loss: 0.00512936\n",
      "epoch: 71  batch: 19  loss: 0.00124541\n",
      "epoch: 71  batch: 20  loss: 0.00473724\n",
      "epoch: 71  batch: 21  loss: 0.01573989\n",
      "epoch: 71  batch: 22  loss: 0.00126203\n",
      "epoch: 71  batch: 23  loss: 0.00546096\n",
      "epoch: 71  batch: 24  loss: 0.00604987\n",
      "epoch: 71  batch: 25  loss: 0.00139240\n",
      "epoch: 71  batch: 26  loss: 0.00716403\n",
      "epoch: 71  batch: 27  loss: 0.00253388\n",
      "epoch: 71  batch: 28  loss: 0.01280794\n",
      "epoch: 72  batch: 1  loss: 0.00222351\n",
      "epoch: 72  batch: 2  loss: 0.00224742\n",
      "epoch: 72  batch: 3  loss: 0.00218501\n",
      "epoch: 72  batch: 4  loss: 0.00271699\n",
      "epoch: 72  batch: 5  loss: 0.00551105\n",
      "epoch: 72  batch: 6  loss: 0.00454666\n",
      "epoch: 72  batch: 7  loss: 0.01190821\n",
      "epoch: 72  batch: 8  loss: 0.00566807\n",
      "epoch: 72  batch: 9  loss: 0.00387433\n",
      "epoch: 72  batch: 10  loss: 0.00374267\n",
      "epoch: 72  batch: 11  loss: 0.00814302\n",
      "epoch: 72  batch: 12  loss: 0.00271494\n",
      "epoch: 72  batch: 13  loss: 0.01451190\n",
      "epoch: 72  batch: 14  loss: 0.00286572\n",
      "epoch: 72  batch: 15  loss: 0.01226141\n",
      "epoch: 72  batch: 16  loss: 0.00213707\n",
      "epoch: 72  batch: 17  loss: 0.00488203\n",
      "epoch: 72  batch: 18  loss: 0.00490003\n",
      "epoch: 72  batch: 19  loss: 0.00480680\n",
      "epoch: 72  batch: 20  loss: 0.01101168\n",
      "epoch: 72  batch: 21  loss: 0.10382707\n",
      "epoch: 72  batch: 22  loss: 0.00293649\n",
      "epoch: 72  batch: 23  loss: 0.00455242\n",
      "epoch: 72  batch: 24  loss: 0.02438680\n",
      "epoch: 72  batch: 25  loss: 0.00191493\n",
      "epoch: 72  batch: 26  loss: 0.00269748\n",
      "epoch: 72  batch: 27  loss: 0.00483377\n",
      "epoch: 72  batch: 28  loss: 0.00493538\n",
      "epoch: 73  batch: 1  loss: 0.00374466\n",
      "epoch: 73  batch: 2  loss: 0.00265334\n",
      "epoch: 73  batch: 3  loss: 0.00199149\n",
      "epoch: 73  batch: 4  loss: 0.00479775\n",
      "epoch: 73  batch: 5  loss: 0.00377941\n",
      "epoch: 73  batch: 6  loss: 0.00366502\n",
      "epoch: 73  batch: 7  loss: 0.00423653\n",
      "epoch: 73  batch: 8  loss: 0.00205462\n",
      "epoch: 73  batch: 9  loss: 0.00953944\n",
      "epoch: 73  batch: 10  loss: 0.00397076\n",
      "epoch: 73  batch: 11  loss: 0.00541080\n",
      "epoch: 73  batch: 12  loss: 0.01299875\n",
      "epoch: 73  batch: 13  loss: 0.00168454\n",
      "epoch: 73  batch: 14  loss: 0.00663354\n",
      "epoch: 73  batch: 15  loss: 0.00676841\n",
      "epoch: 73  batch: 16  loss: 0.02288420\n",
      "epoch: 73  batch: 17  loss: 0.00331023\n",
      "epoch: 73  batch: 18  loss: 0.00402338\n",
      "epoch: 73  batch: 19  loss: 0.00544745\n",
      "epoch: 73  batch: 20  loss: 0.00574340\n",
      "epoch: 73  batch: 21  loss: 0.00311400\n",
      "epoch: 73  batch: 22  loss: 0.00168526\n",
      "epoch: 73  batch: 23  loss: 0.00182648\n",
      "epoch: 73  batch: 24  loss: 0.00353032\n",
      "epoch: 73  batch: 25  loss: 0.01012361\n",
      "epoch: 73  batch: 26  loss: 0.00206697\n",
      "epoch: 73  batch: 27  loss: 0.04559282\n",
      "epoch: 73  batch: 28  loss: 0.00235240\n",
      "epoch: 74  batch: 1  loss: 0.00191767\n",
      "epoch: 74  batch: 2  loss: 0.00325452\n",
      "epoch: 74  batch: 3  loss: 0.00261922\n",
      "epoch: 74  batch: 4  loss: 0.00455067\n",
      "epoch: 74  batch: 5  loss: 0.01047996\n",
      "epoch: 74  batch: 6  loss: 0.02719752\n",
      "epoch: 74  batch: 7  loss: 0.00340592\n",
      "epoch: 74  batch: 8  loss: 0.00403319\n",
      "epoch: 74  batch: 9  loss: 0.00495062\n",
      "epoch: 74  batch: 10  loss: 0.00222013\n",
      "epoch: 74  batch: 11  loss: 0.00528139\n",
      "epoch: 74  batch: 12  loss: 0.00302368\n",
      "epoch: 74  batch: 13  loss: 0.00204789\n",
      "epoch: 74  batch: 14  loss: 0.00620125\n",
      "epoch: 74  batch: 15  loss: 0.00227275\n",
      "epoch: 74  batch: 16  loss: 0.00749857\n",
      "epoch: 74  batch: 17  loss: 0.01526739\n",
      "epoch: 74  batch: 18  loss: 0.00357334\n",
      "epoch: 74  batch: 19  loss: 0.00113079\n",
      "epoch: 74  batch: 20  loss: 0.01960891\n",
      "epoch: 74  batch: 21  loss: 0.00264945\n",
      "epoch: 74  batch: 22  loss: 0.00265561\n",
      "epoch: 74  batch: 23  loss: 0.00424569\n",
      "epoch: 74  batch: 24  loss: 0.00956227\n",
      "epoch: 74  batch: 25  loss: 0.00453252\n",
      "epoch: 74  batch: 26  loss: 0.00766561\n",
      "epoch: 74  batch: 27  loss: 0.00475680\n",
      "epoch: 74  batch: 28  loss: 0.00325078\n",
      "epoch: 75  batch: 1  loss: 0.00681597\n",
      "epoch: 75  batch: 2  loss: 0.00522428\n",
      "epoch: 75  batch: 3  loss: 0.00267213\n",
      "epoch: 75  batch: 4  loss: 0.01226616\n",
      "epoch: 75  batch: 5  loss: 0.00295333\n",
      "epoch: 75  batch: 6  loss: 0.00554667\n",
      "epoch: 75  batch: 7  loss: 0.00406453\n",
      "epoch: 75  batch: 8  loss: 0.00180160\n",
      "epoch: 75  batch: 9  loss: 0.00255691\n",
      "epoch: 75  batch: 10  loss: 0.01952040\n",
      "epoch: 75  batch: 11  loss: 0.00215595\n",
      "epoch: 75  batch: 12  loss: 0.01256928\n",
      "epoch: 75  batch: 13  loss: 0.00313181\n",
      "epoch: 75  batch: 14  loss: 0.00313635\n",
      "epoch: 75  batch: 15  loss: 0.00308730\n",
      "epoch: 75  batch: 16  loss: 0.00254014\n",
      "epoch: 75  batch: 17  loss: 0.00616634\n",
      "epoch: 75  batch: 18  loss: 0.00224374\n",
      "epoch: 75  batch: 19  loss: 0.00215795\n",
      "epoch: 75  batch: 20  loss: 0.00735370\n",
      "epoch: 75  batch: 21  loss: 0.00364993\n",
      "epoch: 75  batch: 22  loss: 0.00484349\n",
      "epoch: 75  batch: 23  loss: 0.00312370\n",
      "epoch: 75  batch: 24  loss: 0.01901131\n",
      "epoch: 75  batch: 25  loss: 0.00463757\n",
      "epoch: 75  batch: 26  loss: 0.00832405\n",
      "epoch: 75  batch: 27  loss: 0.00718541\n",
      "epoch: 75  batch: 28  loss: 0.00609723\n",
      "epoch: 76  batch: 1  loss: 0.00139160\n",
      "epoch: 76  batch: 2  loss: 0.00431675\n",
      "epoch: 76  batch: 3  loss: 0.00432661\n",
      "epoch: 76  batch: 4  loss: 0.00894193\n",
      "epoch: 76  batch: 5  loss: 0.00325373\n",
      "epoch: 76  batch: 6  loss: 0.03061451\n",
      "epoch: 76  batch: 7  loss: 0.00140194\n",
      "epoch: 76  batch: 8  loss: 0.00192145\n",
      "epoch: 76  batch: 9  loss: 0.00706326\n",
      "epoch: 76  batch: 10  loss: 0.00184950\n",
      "epoch: 76  batch: 11  loss: 0.00360395\n",
      "epoch: 76  batch: 12  loss: 0.00891639\n",
      "epoch: 76  batch: 13  loss: 0.00234072\n",
      "epoch: 76  batch: 14  loss: 0.00341260\n",
      "epoch: 76  batch: 15  loss: 0.00742698\n",
      "epoch: 76  batch: 16  loss: 0.00227929\n",
      "epoch: 76  batch: 17  loss: 0.00517300\n",
      "epoch: 76  batch: 18  loss: 0.00222123\n",
      "epoch: 76  batch: 19  loss: 0.00268419\n",
      "epoch: 76  batch: 20  loss: 0.00334873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 76  batch: 21  loss: 0.00586104\n",
      "epoch: 76  batch: 22  loss: 0.00187598\n",
      "epoch: 76  batch: 23  loss: 0.01188638\n",
      "epoch: 76  batch: 24  loss: 0.00440509\n",
      "epoch: 76  batch: 25  loss: 0.00401269\n",
      "epoch: 76  batch: 26  loss: 0.02499672\n",
      "epoch: 76  batch: 27  loss: 0.00391500\n",
      "epoch: 76  batch: 28  loss: 0.00526127\n",
      "epoch: 77  batch: 1  loss: 0.00603982\n",
      "epoch: 77  batch: 2  loss: 0.00342333\n",
      "epoch: 77  batch: 3  loss: 0.00234981\n",
      "epoch: 77  batch: 4  loss: 0.00461140\n",
      "epoch: 77  batch: 5  loss: 0.00546116\n",
      "epoch: 77  batch: 6  loss: 0.00757484\n",
      "epoch: 77  batch: 7  loss: 0.00384418\n",
      "epoch: 77  batch: 8  loss: 0.00645573\n",
      "epoch: 77  batch: 9  loss: 0.00179800\n",
      "epoch: 77  batch: 10  loss: 0.00272523\n",
      "epoch: 77  batch: 11  loss: 0.00730286\n",
      "epoch: 77  batch: 12  loss: 0.00183278\n",
      "epoch: 77  batch: 13  loss: 0.00162431\n",
      "epoch: 77  batch: 14  loss: 0.00261608\n",
      "epoch: 77  batch: 15  loss: 0.00272264\n",
      "epoch: 77  batch: 16  loss: 0.00284028\n",
      "epoch: 77  batch: 17  loss: 0.00351240\n",
      "epoch: 77  batch: 18  loss: 0.00385931\n",
      "epoch: 77  batch: 19  loss: 0.00221025\n",
      "epoch: 77  batch: 20  loss: 0.00279832\n",
      "epoch: 77  batch: 21  loss: 0.03074940\n",
      "epoch: 77  batch: 22  loss: 0.00391486\n",
      "epoch: 77  batch: 23  loss: 0.00301207\n",
      "epoch: 77  batch: 24  loss: 0.01264576\n",
      "epoch: 77  batch: 25  loss: 0.00520561\n",
      "epoch: 77  batch: 26  loss: 0.00539324\n",
      "epoch: 77  batch: 27  loss: 0.02513489\n",
      "epoch: 77  batch: 28  loss: 0.00387697\n",
      "epoch: 78  batch: 1  loss: 0.00230707\n",
      "epoch: 78  batch: 2  loss: 0.00406087\n",
      "epoch: 78  batch: 3  loss: 0.00258342\n",
      "epoch: 78  batch: 4  loss: 0.00230709\n",
      "epoch: 78  batch: 5  loss: 0.00288019\n",
      "epoch: 78  batch: 6  loss: 0.00476010\n",
      "epoch: 78  batch: 7  loss: 0.00072965\n",
      "epoch: 78  batch: 8  loss: 0.00801225\n",
      "epoch: 78  batch: 9  loss: 0.00428360\n",
      "epoch: 78  batch: 10  loss: 0.00547945\n",
      "epoch: 78  batch: 11  loss: 0.00637093\n",
      "epoch: 78  batch: 12  loss: 0.00142517\n",
      "epoch: 78  batch: 13  loss: 0.02359895\n",
      "epoch: 78  batch: 14  loss: 0.00403053\n",
      "epoch: 78  batch: 15  loss: 0.01618924\n",
      "epoch: 78  batch: 16  loss: 0.00553055\n",
      "epoch: 78  batch: 17  loss: 0.00279432\n",
      "epoch: 78  batch: 18  loss: 0.00507104\n",
      "epoch: 78  batch: 19  loss: 0.00783471\n",
      "epoch: 78  batch: 20  loss: 0.01507485\n",
      "epoch: 78  batch: 21  loss: 0.00316477\n",
      "epoch: 78  batch: 22  loss: 0.00343244\n",
      "epoch: 78  batch: 23  loss: 0.00552186\n",
      "epoch: 78  batch: 24  loss: 0.00199697\n",
      "epoch: 78  batch: 25  loss: 0.00682578\n",
      "epoch: 78  batch: 26  loss: 0.00883110\n",
      "epoch: 78  batch: 27  loss: 0.00142349\n",
      "epoch: 78  batch: 28  loss: 0.00312096\n",
      "epoch: 79  batch: 1  loss: 0.00249147\n",
      "epoch: 79  batch: 2  loss: 0.02325227\n",
      "epoch: 79  batch: 3  loss: 0.00324698\n",
      "epoch: 79  batch: 4  loss: 0.00391985\n",
      "epoch: 79  batch: 5  loss: 0.00359679\n",
      "epoch: 79  batch: 6  loss: 0.00425929\n",
      "epoch: 79  batch: 7  loss: 0.00131107\n",
      "epoch: 79  batch: 8  loss: 0.00405251\n",
      "epoch: 79  batch: 9  loss: 0.00265069\n",
      "epoch: 79  batch: 10  loss: 0.00129152\n",
      "epoch: 79  batch: 11  loss: 0.00672753\n",
      "epoch: 79  batch: 12  loss: 0.00332275\n",
      "epoch: 79  batch: 13  loss: 0.00239847\n",
      "epoch: 79  batch: 14  loss: 0.00411799\n",
      "epoch: 79  batch: 15  loss: 0.01037645\n",
      "epoch: 79  batch: 16  loss: 0.01021882\n",
      "epoch: 79  batch: 17  loss: 0.00396645\n",
      "epoch: 79  batch: 18  loss: 0.00498734\n",
      "epoch: 79  batch: 19  loss: 0.00138517\n",
      "epoch: 79  batch: 20  loss: 0.00329696\n",
      "epoch: 79  batch: 21  loss: 0.00925020\n",
      "epoch: 79  batch: 22  loss: 0.00734870\n",
      "epoch: 79  batch: 23  loss: 0.00755905\n",
      "epoch: 79  batch: 24  loss: 0.00192964\n",
      "epoch: 79  batch: 25  loss: 0.00543801\n",
      "epoch: 79  batch: 26  loss: 0.00681226\n",
      "epoch: 79  batch: 27  loss: 0.00281117\n",
      "epoch: 79  batch: 28  loss: 0.00642440\n",
      "epoch: 80  batch: 1  loss: 0.02140006\n",
      "epoch: 80  batch: 2  loss: 0.00856688\n",
      "epoch: 80  batch: 3  loss: 0.00295331\n",
      "epoch: 80  batch: 4  loss: 0.00343633\n",
      "epoch: 80  batch: 5  loss: 0.01040366\n",
      "epoch: 80  batch: 6  loss: 0.02318119\n",
      "epoch: 80  batch: 7  loss: 0.00383065\n",
      "epoch: 80  batch: 8  loss: 0.00118549\n",
      "epoch: 80  batch: 9  loss: 0.00499517\n",
      "epoch: 80  batch: 10  loss: 0.04068734\n",
      "epoch: 80  batch: 11  loss: 0.00303379\n",
      "epoch: 80  batch: 12  loss: 0.00503769\n",
      "epoch: 80  batch: 13  loss: 0.00402421\n",
      "epoch: 80  batch: 14  loss: 0.00103613\n",
      "epoch: 80  batch: 15  loss: 0.01126846\n",
      "epoch: 80  batch: 16  loss: 0.00549838\n",
      "epoch: 80  batch: 17  loss: 0.00315424\n",
      "epoch: 80  batch: 18  loss: 0.00676562\n",
      "epoch: 80  batch: 19  loss: 0.00204615\n",
      "epoch: 80  batch: 20  loss: 0.00822983\n",
      "epoch: 80  batch: 21  loss: 0.00557748\n",
      "epoch: 80  batch: 22  loss: 0.00586239\n",
      "epoch: 80  batch: 23  loss: 0.00206592\n",
      "epoch: 80  batch: 24  loss: 0.00583196\n",
      "epoch: 80  batch: 25  loss: 0.01386239\n",
      "epoch: 80  batch: 26  loss: 0.00089585\n",
      "epoch: 80  batch: 27  loss: 0.00174006\n",
      "epoch: 80  batch: 28  loss: 0.00272564\n",
      "epoch: 81  batch: 1  loss: 0.00116977\n",
      "epoch: 81  batch: 2  loss: 0.00274561\n",
      "epoch: 81  batch: 3  loss: 0.00709625\n",
      "epoch: 81  batch: 4  loss: 0.00907483\n",
      "epoch: 81  batch: 5  loss: 0.01034945\n",
      "epoch: 81  batch: 6  loss: 0.00332297\n",
      "epoch: 81  batch: 7  loss: 0.00171004\n",
      "epoch: 81  batch: 8  loss: 0.00397488\n",
      "epoch: 81  batch: 9  loss: 0.00601944\n",
      "epoch: 81  batch: 10  loss: 0.01742323\n",
      "epoch: 81  batch: 11  loss: 0.00353694\n",
      "epoch: 81  batch: 12  loss: 0.00453914\n",
      "epoch: 81  batch: 13  loss: 0.00528489\n",
      "epoch: 81  batch: 14  loss: 0.00500016\n",
      "epoch: 81  batch: 15  loss: 0.00369855\n",
      "epoch: 81  batch: 16  loss: 0.00609620\n",
      "epoch: 81  batch: 17  loss: 0.00175751\n",
      "epoch: 81  batch: 18  loss: 0.00725602\n",
      "epoch: 81  batch: 19  loss: 0.00518939\n",
      "epoch: 81  batch: 20  loss: 0.00590576\n",
      "epoch: 81  batch: 21  loss: 0.01760559\n",
      "epoch: 81  batch: 22  loss: 0.00267947\n",
      "epoch: 81  batch: 23  loss: 0.00826746\n",
      "epoch: 81  batch: 24  loss: 0.00513654\n",
      "epoch: 81  batch: 25  loss: 0.00337425\n",
      "epoch: 81  batch: 26  loss: 0.00073434\n",
      "epoch: 81  batch: 27  loss: 0.00485587\n",
      "epoch: 81  batch: 28  loss: 0.00233437\n",
      "epoch: 82  batch: 1  loss: 0.01163947\n",
      "epoch: 82  batch: 2  loss: 0.00199825\n",
      "epoch: 82  batch: 3  loss: 0.02549491\n",
      "epoch: 82  batch: 4  loss: 0.00184348\n",
      "epoch: 82  batch: 5  loss: 0.01491259\n",
      "epoch: 82  batch: 6  loss: 0.00426447\n",
      "epoch: 82  batch: 7  loss: 0.01037223\n",
      "epoch: 82  batch: 8  loss: 0.00272242\n",
      "epoch: 82  batch: 9  loss: 0.00503271\n",
      "epoch: 82  batch: 10  loss: 0.00580873\n",
      "epoch: 82  batch: 11  loss: 0.00209765\n",
      "epoch: 82  batch: 12  loss: 0.00196390\n",
      "epoch: 82  batch: 13  loss: 0.00267416\n",
      "epoch: 82  batch: 14  loss: 0.00224864\n",
      "epoch: 82  batch: 15  loss: 0.00131112\n",
      "epoch: 82  batch: 16  loss: 0.00219560\n",
      "epoch: 82  batch: 17  loss: 0.00395321\n",
      "epoch: 82  batch: 18  loss: 0.00985295\n",
      "epoch: 82  batch: 19  loss: 0.00795419\n",
      "epoch: 82  batch: 20  loss: 0.00214748\n",
      "epoch: 82  batch: 21  loss: 0.00300253\n",
      "epoch: 82  batch: 22  loss: 0.00230718\n",
      "epoch: 82  batch: 23  loss: 0.00381028\n",
      "epoch: 82  batch: 24  loss: 0.00217589\n",
      "epoch: 82  batch: 25  loss: 0.00496469\n",
      "epoch: 82  batch: 26  loss: 0.00529960\n",
      "epoch: 82  batch: 27  loss: 0.00913254\n",
      "epoch: 82  batch: 28  loss: 0.00895389\n",
      "epoch: 83  batch: 1  loss: 0.00550501\n",
      "epoch: 83  batch: 2  loss: 0.00794721\n",
      "epoch: 83  batch: 3  loss: 0.00399680\n",
      "epoch: 83  batch: 4  loss: 0.00481382\n",
      "epoch: 83  batch: 5  loss: 0.00230341\n",
      "epoch: 83  batch: 6  loss: 0.00664854\n",
      "epoch: 83  batch: 7  loss: 0.00791164\n",
      "epoch: 83  batch: 8  loss: 0.00209209\n",
      "epoch: 83  batch: 9  loss: 0.00273866\n",
      "epoch: 83  batch: 10  loss: 0.00519002\n",
      "epoch: 83  batch: 11  loss: 0.00582976\n",
      "epoch: 83  batch: 12  loss: 0.00209645\n",
      "epoch: 83  batch: 13  loss: 0.00239035\n",
      "epoch: 83  batch: 14  loss: 0.00115497\n",
      "epoch: 83  batch: 15  loss: 0.01295063\n",
      "epoch: 83  batch: 16  loss: 0.01080171\n",
      "epoch: 83  batch: 17  loss: 0.00263964\n",
      "epoch: 83  batch: 18  loss: 0.00500772\n",
      "epoch: 83  batch: 19  loss: 0.00650916\n",
      "epoch: 83  batch: 20  loss: 0.01043752\n",
      "epoch: 83  batch: 21  loss: 0.00370997\n",
      "epoch: 83  batch: 22  loss: 0.00245700\n",
      "epoch: 83  batch: 23  loss: 0.00228701\n",
      "epoch: 83  batch: 24  loss: 0.00770249\n",
      "epoch: 83  batch: 25  loss: 0.00467978\n",
      "epoch: 83  batch: 26  loss: 0.00104425\n",
      "epoch: 83  batch: 27  loss: 0.02254790\n",
      "epoch: 83  batch: 28  loss: 0.00168728\n",
      "epoch: 84  batch: 1  loss: 0.00292961\n",
      "epoch: 84  batch: 2  loss: 0.00513921\n",
      "epoch: 84  batch: 3  loss: 0.00712405\n",
      "epoch: 84  batch: 4  loss: 0.00276781\n",
      "epoch: 84  batch: 5  loss: 0.00233811\n",
      "epoch: 84  batch: 6  loss: 0.00654590\n",
      "epoch: 84  batch: 7  loss: 0.01533622\n",
      "epoch: 84  batch: 8  loss: 0.00655214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84  batch: 9  loss: 0.01675901\n",
      "epoch: 84  batch: 10  loss: 0.00144385\n",
      "epoch: 84  batch: 11  loss: 0.00231220\n",
      "epoch: 84  batch: 12  loss: 0.00109607\n",
      "epoch: 84  batch: 13  loss: 0.00465169\n",
      "epoch: 84  batch: 14  loss: 0.00806170\n",
      "epoch: 84  batch: 15  loss: 0.00423431\n",
      "epoch: 84  batch: 16  loss: 0.00932396\n",
      "epoch: 84  batch: 17  loss: 0.00563385\n",
      "epoch: 84  batch: 18  loss: 0.00143258\n",
      "epoch: 84  batch: 19  loss: 0.00242556\n",
      "epoch: 84  batch: 20  loss: 0.00080230\n",
      "epoch: 84  batch: 21  loss: 0.00460717\n",
      "epoch: 84  batch: 22  loss: 0.00095662\n",
      "epoch: 84  batch: 23  loss: 0.00164855\n",
      "epoch: 84  batch: 24  loss: 0.00279567\n",
      "epoch: 84  batch: 25  loss: 0.00134991\n",
      "epoch: 84  batch: 26  loss: 0.00890042\n",
      "epoch: 84  batch: 27  loss: 0.00192919\n",
      "epoch: 84  batch: 28  loss: 0.00141923\n",
      "epoch: 85  batch: 1  loss: 0.00109542\n",
      "epoch: 85  batch: 2  loss: 0.00912761\n",
      "epoch: 85  batch: 3  loss: 0.00355384\n",
      "epoch: 85  batch: 4  loss: 0.00413050\n",
      "epoch: 85  batch: 5  loss: 0.00436473\n",
      "epoch: 85  batch: 6  loss: 0.00903617\n",
      "epoch: 85  batch: 7  loss: 0.00517347\n",
      "epoch: 85  batch: 8  loss: 0.00705307\n",
      "epoch: 85  batch: 9  loss: 0.00779799\n",
      "epoch: 85  batch: 10  loss: 0.00155423\n",
      "epoch: 85  batch: 11  loss: 0.00274775\n",
      "epoch: 85  batch: 12  loss: 0.01155217\n",
      "epoch: 85  batch: 13  loss: 0.01021116\n",
      "epoch: 85  batch: 14  loss: 0.02868876\n",
      "epoch: 85  batch: 15  loss: 0.00385347\n",
      "epoch: 85  batch: 16  loss: 0.00440249\n",
      "epoch: 85  batch: 17  loss: 0.00473102\n",
      "epoch: 85  batch: 18  loss: 0.00335802\n",
      "epoch: 85  batch: 19  loss: 0.00133597\n",
      "epoch: 85  batch: 20  loss: 0.00429113\n",
      "epoch: 85  batch: 21  loss: 0.00520077\n",
      "epoch: 85  batch: 22  loss: 0.00626482\n",
      "epoch: 85  batch: 23  loss: 0.00249743\n",
      "epoch: 85  batch: 24  loss: 0.00463545\n",
      "epoch: 85  batch: 25  loss: 0.00825946\n",
      "epoch: 85  batch: 26  loss: 0.00860354\n",
      "epoch: 85  batch: 27  loss: 0.00110917\n",
      "epoch: 85  batch: 28  loss: 0.00247588\n",
      "epoch: 86  batch: 1  loss: 0.00248402\n",
      "epoch: 86  batch: 2  loss: 0.00150312\n",
      "epoch: 86  batch: 3  loss: 0.00283895\n",
      "epoch: 86  batch: 4  loss: 0.00074856\n",
      "epoch: 86  batch: 5  loss: 0.00572453\n",
      "epoch: 86  batch: 6  loss: 0.00586433\n",
      "epoch: 86  batch: 7  loss: 0.00218628\n",
      "epoch: 86  batch: 8  loss: 0.00042002\n",
      "epoch: 86  batch: 9  loss: 0.00953873\n",
      "epoch: 86  batch: 10  loss: 0.00163652\n",
      "epoch: 86  batch: 11  loss: 0.00558240\n",
      "epoch: 86  batch: 12  loss: 0.00209431\n",
      "epoch: 86  batch: 13  loss: 0.00509690\n",
      "epoch: 86  batch: 14  loss: 0.00147201\n",
      "epoch: 86  batch: 15  loss: 0.00583957\n",
      "epoch: 86  batch: 16  loss: 0.01257451\n",
      "epoch: 86  batch: 17  loss: 0.00568661\n",
      "epoch: 86  batch: 18  loss: 0.00143461\n",
      "epoch: 86  batch: 19  loss: 0.00302972\n",
      "epoch: 86  batch: 20  loss: 0.00208665\n",
      "epoch: 86  batch: 21  loss: 0.00523557\n",
      "epoch: 86  batch: 22  loss: 0.00231412\n",
      "epoch: 86  batch: 23  loss: 0.00651540\n",
      "epoch: 86  batch: 24  loss: 0.00357602\n",
      "epoch: 86  batch: 25  loss: 0.00597827\n",
      "epoch: 86  batch: 26  loss: 0.01632587\n",
      "epoch: 86  batch: 27  loss: 0.00407311\n",
      "epoch: 86  batch: 28  loss: 0.00352016\n",
      "epoch: 87  batch: 1  loss: 0.00553063\n",
      "epoch: 87  batch: 2  loss: 0.00256941\n",
      "epoch: 87  batch: 3  loss: 0.00425293\n",
      "epoch: 87  batch: 4  loss: 0.00337467\n",
      "epoch: 87  batch: 5  loss: 0.00600540\n",
      "epoch: 87  batch: 6  loss: 0.00228983\n",
      "epoch: 87  batch: 7  loss: 0.00287144\n",
      "epoch: 87  batch: 8  loss: 0.00461703\n",
      "epoch: 87  batch: 9  loss: 0.00210471\n",
      "epoch: 87  batch: 10  loss: 0.00542580\n",
      "epoch: 87  batch: 11  loss: 0.00422463\n",
      "epoch: 87  batch: 12  loss: 0.00573699\n",
      "epoch: 87  batch: 13  loss: 0.00309495\n",
      "epoch: 87  batch: 14  loss: 0.01047978\n",
      "epoch: 87  batch: 15  loss: 0.00225083\n",
      "epoch: 87  batch: 16  loss: 0.00155988\n",
      "epoch: 87  batch: 17  loss: 0.02732016\n",
      "epoch: 87  batch: 18  loss: 0.00121667\n",
      "epoch: 87  batch: 19  loss: 0.00219298\n",
      "epoch: 87  batch: 20  loss: 0.00551178\n",
      "epoch: 87  batch: 21  loss: 0.00416282\n",
      "epoch: 87  batch: 22  loss: 0.00759832\n",
      "epoch: 87  batch: 23  loss: 0.00507914\n",
      "epoch: 87  batch: 24  loss: 0.00267808\n",
      "epoch: 87  batch: 25  loss: 0.00531455\n",
      "epoch: 87  batch: 26  loss: 0.00550267\n",
      "epoch: 87  batch: 27  loss: 0.00391244\n",
      "epoch: 87  batch: 28  loss: 0.01081483\n",
      "epoch: 88  batch: 1  loss: 0.00589418\n",
      "epoch: 88  batch: 2  loss: 0.00072415\n",
      "epoch: 88  batch: 3  loss: 0.02372559\n",
      "epoch: 88  batch: 4  loss: 0.00485225\n",
      "epoch: 88  batch: 5  loss: 0.00860068\n",
      "epoch: 88  batch: 6  loss: 0.00170564\n",
      "epoch: 88  batch: 7  loss: 0.00146197\n",
      "epoch: 88  batch: 8  loss: 0.00454287\n",
      "epoch: 88  batch: 9  loss: 0.00387730\n",
      "epoch: 88  batch: 10  loss: 0.00273992\n",
      "epoch: 88  batch: 11  loss: 0.00232642\n",
      "epoch: 88  batch: 12  loss: 0.00622583\n",
      "epoch: 88  batch: 13  loss: 0.01202270\n",
      "epoch: 88  batch: 14  loss: 0.00384161\n",
      "epoch: 88  batch: 15  loss: 0.00256181\n",
      "epoch: 88  batch: 16  loss: 0.00492077\n",
      "epoch: 88  batch: 17  loss: 0.00387187\n",
      "epoch: 88  batch: 18  loss: 0.00386232\n",
      "epoch: 88  batch: 19  loss: 0.01576819\n",
      "epoch: 88  batch: 20  loss: 0.00625732\n",
      "epoch: 88  batch: 21  loss: 0.00155736\n",
      "epoch: 88  batch: 22  loss: 0.00459258\n",
      "epoch: 88  batch: 23  loss: 0.00770194\n",
      "epoch: 88  batch: 24  loss: 0.00299695\n",
      "epoch: 88  batch: 25  loss: 0.00097306\n",
      "epoch: 88  batch: 26  loss: 0.00478767\n",
      "epoch: 88  batch: 27  loss: 0.00605922\n",
      "epoch: 88  batch: 28  loss: 0.00180694\n",
      "epoch: 89  batch: 1  loss: 0.00359043\n",
      "epoch: 89  batch: 2  loss: 0.00977701\n",
      "epoch: 89  batch: 3  loss: 0.00502560\n",
      "epoch: 89  batch: 4  loss: 0.00384570\n",
      "epoch: 89  batch: 5  loss: 0.00279227\n",
      "epoch: 89  batch: 6  loss: 0.01456360\n",
      "epoch: 89  batch: 7  loss: 0.00114190\n",
      "epoch: 89  batch: 8  loss: 0.00099496\n",
      "epoch: 89  batch: 9  loss: 0.00557425\n",
      "epoch: 89  batch: 10  loss: 0.00076575\n",
      "epoch: 89  batch: 11  loss: 0.00394328\n",
      "epoch: 89  batch: 12  loss: 0.00186207\n",
      "epoch: 89  batch: 13  loss: 0.00679405\n",
      "epoch: 89  batch: 14  loss: 0.01406343\n",
      "epoch: 89  batch: 15  loss: 0.01000760\n",
      "epoch: 89  batch: 16  loss: 0.00120505\n",
      "epoch: 89  batch: 17  loss: 0.00254806\n",
      "epoch: 89  batch: 18  loss: 0.00437166\n",
      "epoch: 89  batch: 19  loss: 0.00421279\n",
      "epoch: 89  batch: 20  loss: 0.00139593\n",
      "epoch: 89  batch: 21  loss: 0.00705157\n",
      "epoch: 89  batch: 22  loss: 0.00309316\n",
      "epoch: 89  batch: 23  loss: 0.00872279\n",
      "epoch: 89  batch: 24  loss: 0.01307213\n",
      "epoch: 89  batch: 25  loss: 0.00354934\n",
      "epoch: 89  batch: 26  loss: 0.00516188\n",
      "epoch: 89  batch: 27  loss: 0.00846172\n",
      "epoch: 89  batch: 28  loss: 0.00447223\n",
      "epoch: 90  batch: 1  loss: 0.00425946\n",
      "epoch: 90  batch: 2  loss: 0.00575649\n",
      "epoch: 90  batch: 3  loss: 0.00211938\n",
      "epoch: 90  batch: 4  loss: 0.00231936\n",
      "epoch: 90  batch: 5  loss: 0.00365635\n",
      "epoch: 90  batch: 6  loss: 0.00149769\n",
      "epoch: 90  batch: 7  loss: 0.00356303\n",
      "epoch: 90  batch: 8  loss: 0.00338302\n",
      "epoch: 90  batch: 9  loss: 0.01145150\n",
      "epoch: 90  batch: 10  loss: 0.00821293\n",
      "epoch: 90  batch: 11  loss: 0.00308310\n",
      "epoch: 90  batch: 12  loss: 0.00510122\n",
      "epoch: 90  batch: 13  loss: 0.00254725\n",
      "epoch: 90  batch: 14  loss: 0.00281798\n",
      "epoch: 90  batch: 15  loss: 0.01838685\n",
      "epoch: 90  batch: 16  loss: 0.00508562\n",
      "epoch: 90  batch: 17  loss: 0.01331341\n",
      "epoch: 90  batch: 18  loss: 0.00341928\n",
      "epoch: 90  batch: 19  loss: 0.00230322\n",
      "epoch: 90  batch: 20  loss: 0.00166530\n",
      "epoch: 90  batch: 21  loss: 0.00573931\n",
      "epoch: 90  batch: 22  loss: 0.02239160\n",
      "epoch: 90  batch: 23  loss: 0.00178606\n",
      "epoch: 90  batch: 24  loss: 0.00512328\n",
      "epoch: 90  batch: 25  loss: 0.00348273\n",
      "epoch: 90  batch: 26  loss: 0.03036279\n",
      "epoch: 90  batch: 27  loss: 0.00109217\n",
      "epoch: 90  batch: 28  loss: 0.00206078\n",
      "epoch: 91  batch: 1  loss: 0.00186504\n",
      "epoch: 91  batch: 2  loss: 0.00389366\n",
      "epoch: 91  batch: 3  loss: 0.00609087\n",
      "epoch: 91  batch: 4  loss: 0.00803122\n",
      "epoch: 91  batch: 5  loss: 0.00627934\n",
      "epoch: 91  batch: 6  loss: 0.00484047\n",
      "epoch: 91  batch: 7  loss: 0.00167070\n",
      "epoch: 91  batch: 8  loss: 0.00183391\n",
      "epoch: 91  batch: 9  loss: 0.00717471\n",
      "epoch: 91  batch: 10  loss: 0.00160381\n",
      "epoch: 91  batch: 11  loss: 0.00129410\n",
      "epoch: 91  batch: 12  loss: 0.00510707\n",
      "epoch: 91  batch: 13  loss: 0.00585626\n",
      "epoch: 91  batch: 14  loss: 0.00633307\n",
      "epoch: 91  batch: 15  loss: 0.00417995\n",
      "epoch: 91  batch: 16  loss: 0.00716088\n",
      "epoch: 91  batch: 17  loss: 0.00454260\n",
      "epoch: 91  batch: 18  loss: 0.00296936\n",
      "epoch: 91  batch: 19  loss: 0.00267857\n",
      "epoch: 91  batch: 20  loss: 0.00275134\n",
      "epoch: 91  batch: 21  loss: 0.01519119\n",
      "epoch: 91  batch: 22  loss: 0.00828612\n",
      "epoch: 91  batch: 23  loss: 0.00213641\n",
      "epoch: 91  batch: 24  loss: 0.00205102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91  batch: 25  loss: 0.01920279\n",
      "epoch: 91  batch: 26  loss: 0.01138839\n",
      "epoch: 91  batch: 27  loss: 0.00696591\n",
      "epoch: 91  batch: 28  loss: 0.00227154\n",
      "epoch: 92  batch: 1  loss: 0.00281146\n",
      "epoch: 92  batch: 2  loss: 0.00086020\n",
      "epoch: 92  batch: 3  loss: 0.01144700\n",
      "epoch: 92  batch: 4  loss: 0.00271062\n",
      "epoch: 92  batch: 5  loss: 0.00101651\n",
      "epoch: 92  batch: 6  loss: 0.00236637\n",
      "epoch: 92  batch: 7  loss: 0.01052010\n",
      "epoch: 92  batch: 8  loss: 0.01326492\n",
      "epoch: 92  batch: 9  loss: 0.00609394\n",
      "epoch: 92  batch: 10  loss: 0.00219254\n",
      "epoch: 92  batch: 11  loss: 0.00266868\n",
      "epoch: 92  batch: 12  loss: 0.00171614\n",
      "epoch: 92  batch: 13  loss: 0.00136480\n",
      "epoch: 92  batch: 14  loss: 0.00396087\n",
      "epoch: 92  batch: 15  loss: 0.00438533\n",
      "epoch: 92  batch: 16  loss: 0.00823150\n",
      "epoch: 92  batch: 17  loss: 0.00696047\n",
      "epoch: 92  batch: 18  loss: 0.00584631\n",
      "epoch: 92  batch: 19  loss: 0.00273301\n",
      "epoch: 92  batch: 20  loss: 0.00673860\n",
      "epoch: 92  batch: 21  loss: 0.00393938\n",
      "epoch: 92  batch: 22  loss: 0.00402163\n",
      "epoch: 92  batch: 23  loss: 0.00249179\n",
      "epoch: 92  batch: 24  loss: 0.02826374\n",
      "epoch: 92  batch: 25  loss: 0.00339363\n",
      "epoch: 92  batch: 26  loss: 0.00424027\n",
      "epoch: 92  batch: 27  loss: 0.00217612\n",
      "epoch: 92  batch: 28  loss: 0.00293816\n",
      "epoch: 93  batch: 1  loss: 0.00387723\n",
      "epoch: 93  batch: 2  loss: 0.00630743\n",
      "epoch: 93  batch: 3  loss: 0.00588605\n",
      "epoch: 93  batch: 4  loss: 0.00321813\n",
      "epoch: 93  batch: 5  loss: 0.00177849\n",
      "epoch: 93  batch: 6  loss: 0.00685291\n",
      "epoch: 93  batch: 7  loss: 0.00602019\n",
      "epoch: 93  batch: 8  loss: 0.00224581\n",
      "epoch: 93  batch: 9  loss: 0.01646916\n",
      "epoch: 93  batch: 10  loss: 0.00490219\n",
      "epoch: 93  batch: 11  loss: 0.00164331\n",
      "epoch: 93  batch: 12  loss: 0.00081509\n",
      "epoch: 93  batch: 13  loss: 0.01376938\n",
      "epoch: 93  batch: 14  loss: 0.02221948\n",
      "epoch: 93  batch: 15  loss: 0.00231231\n",
      "epoch: 93  batch: 16  loss: 0.00135566\n",
      "epoch: 93  batch: 17  loss: 0.00343144\n",
      "epoch: 93  batch: 18  loss: 0.00400533\n",
      "epoch: 93  batch: 19  loss: 0.00680968\n",
      "epoch: 93  batch: 20  loss: 0.00277297\n",
      "epoch: 93  batch: 21  loss: 0.01181339\n",
      "epoch: 93  batch: 22  loss: 0.00344632\n",
      "epoch: 93  batch: 23  loss: 0.00289671\n",
      "epoch: 93  batch: 24  loss: 0.00119573\n",
      "epoch: 93  batch: 25  loss: 0.00326521\n",
      "epoch: 93  batch: 26  loss: 0.00136930\n",
      "epoch: 93  batch: 27  loss: 0.00259234\n",
      "epoch: 93  batch: 28  loss: 0.00274088\n",
      "epoch: 94  batch: 1  loss: 0.00726621\n",
      "epoch: 94  batch: 2  loss: 0.01036994\n",
      "epoch: 94  batch: 3  loss: 0.00705546\n",
      "epoch: 94  batch: 4  loss: 0.00126732\n",
      "epoch: 94  batch: 5  loss: 0.00312953\n",
      "epoch: 94  batch: 6  loss: 0.00164606\n",
      "epoch: 94  batch: 7  loss: 0.00907120\n",
      "epoch: 94  batch: 8  loss: 0.00570783\n",
      "epoch: 94  batch: 9  loss: 0.00489913\n",
      "epoch: 94  batch: 10  loss: 0.00940092\n",
      "epoch: 94  batch: 11  loss: 0.00263708\n",
      "epoch: 94  batch: 12  loss: 0.00579153\n",
      "epoch: 94  batch: 13  loss: 0.00416547\n",
      "epoch: 94  batch: 14  loss: 0.00349598\n",
      "epoch: 94  batch: 15  loss: 0.00170434\n",
      "epoch: 94  batch: 16  loss: 0.00286493\n",
      "epoch: 94  batch: 17  loss: 0.00200489\n",
      "epoch: 94  batch: 18  loss: 0.00693885\n",
      "epoch: 94  batch: 19  loss: 0.01323751\n",
      "epoch: 94  batch: 20  loss: 0.00090415\n",
      "epoch: 94  batch: 21  loss: 0.02566532\n",
      "epoch: 94  batch: 22  loss: 0.00762466\n",
      "epoch: 94  batch: 23  loss: 0.00418430\n",
      "epoch: 94  batch: 24  loss: 0.00619847\n",
      "epoch: 94  batch: 25  loss: 0.00508066\n",
      "epoch: 94  batch: 26  loss: 0.00136405\n",
      "epoch: 94  batch: 27  loss: 0.00285929\n",
      "epoch: 94  batch: 28  loss: 0.00460808\n",
      "epoch: 95  batch: 1  loss: 0.00267038\n",
      "epoch: 95  batch: 2  loss: 0.01286236\n",
      "epoch: 95  batch: 3  loss: 0.00429675\n",
      "epoch: 95  batch: 4  loss: 0.00340055\n",
      "epoch: 95  batch: 5  loss: 0.00289071\n",
      "epoch: 95  batch: 6  loss: 0.00249490\n",
      "epoch: 95  batch: 7  loss: 0.00597680\n",
      "epoch: 95  batch: 8  loss: 0.00476030\n",
      "epoch: 95  batch: 9  loss: 0.00133103\n",
      "epoch: 95  batch: 10  loss: 0.00524959\n",
      "epoch: 95  batch: 11  loss: 0.00648688\n",
      "epoch: 95  batch: 12  loss: 0.00098015\n",
      "epoch: 95  batch: 13  loss: 0.00116881\n",
      "epoch: 95  batch: 14  loss: 0.00238673\n",
      "epoch: 95  batch: 15  loss: 0.00323407\n",
      "epoch: 95  batch: 16  loss: 0.00303298\n",
      "epoch: 95  batch: 17  loss: 0.01903354\n",
      "epoch: 95  batch: 18  loss: 0.00603121\n",
      "epoch: 95  batch: 19  loss: 0.00162134\n",
      "epoch: 95  batch: 20  loss: 0.01466559\n",
      "epoch: 95  batch: 21  loss: 0.02186531\n",
      "epoch: 95  batch: 22  loss: 0.00318310\n",
      "epoch: 95  batch: 23  loss: 0.00457859\n",
      "epoch: 95  batch: 24  loss: 0.00233652\n",
      "epoch: 95  batch: 25  loss: 0.00840918\n",
      "epoch: 95  batch: 26  loss: 0.00376927\n",
      "epoch: 95  batch: 27  loss: 0.00428887\n",
      "epoch: 95  batch: 28  loss: 0.00235074\n",
      "epoch: 96  batch: 1  loss: 0.00218110\n",
      "epoch: 96  batch: 2  loss: 0.00255060\n",
      "epoch: 96  batch: 3  loss: 0.00738182\n",
      "epoch: 96  batch: 4  loss: 0.00343606\n",
      "epoch: 96  batch: 5  loss: 0.00398288\n",
      "epoch: 96  batch: 6  loss: 0.00564984\n",
      "epoch: 96  batch: 7  loss: 0.00827067\n",
      "epoch: 96  batch: 8  loss: 0.00410040\n",
      "epoch: 96  batch: 9  loss: 0.00551390\n",
      "epoch: 96  batch: 10  loss: 0.00514122\n",
      "epoch: 96  batch: 11  loss: 0.00359037\n",
      "epoch: 96  batch: 12  loss: 0.00115242\n",
      "epoch: 96  batch: 13  loss: 0.00581825\n",
      "epoch: 96  batch: 14  loss: 0.00101262\n",
      "epoch: 96  batch: 15  loss: 0.00200118\n",
      "epoch: 96  batch: 16  loss: 0.01556105\n",
      "epoch: 96  batch: 17  loss: 0.00069868\n",
      "epoch: 96  batch: 18  loss: 0.02212012\n",
      "epoch: 96  batch: 19  loss: 0.00098065\n",
      "epoch: 96  batch: 20  loss: 0.00817514\n",
      "epoch: 96  batch: 21  loss: 0.00606463\n",
      "epoch: 96  batch: 22  loss: 0.00384982\n",
      "epoch: 96  batch: 23  loss: 0.00195904\n",
      "epoch: 96  batch: 24  loss: 0.00349657\n",
      "epoch: 96  batch: 25  loss: 0.00224122\n",
      "epoch: 96  batch: 26  loss: 0.01907292\n",
      "epoch: 96  batch: 27  loss: 0.00564925\n",
      "epoch: 96  batch: 28  loss: 0.00303580\n",
      "epoch: 97  batch: 1  loss: 0.00121692\n",
      "epoch: 97  batch: 2  loss: 0.00682909\n",
      "epoch: 97  batch: 3  loss: 0.01242729\n",
      "epoch: 97  batch: 4  loss: 0.00356571\n",
      "epoch: 97  batch: 5  loss: 0.00365616\n",
      "epoch: 97  batch: 6  loss: 0.00503917\n",
      "epoch: 97  batch: 7  loss: 0.00429136\n",
      "epoch: 97  batch: 8  loss: 0.00251758\n",
      "epoch: 97  batch: 9  loss: 0.00309642\n",
      "epoch: 97  batch: 10  loss: 0.00632576\n",
      "epoch: 97  batch: 11  loss: 0.00434518\n",
      "epoch: 97  batch: 12  loss: 0.00315827\n",
      "epoch: 97  batch: 13  loss: 0.00850022\n",
      "epoch: 97  batch: 14  loss: 0.01062821\n",
      "epoch: 97  batch: 15  loss: 0.00422318\n",
      "epoch: 97  batch: 16  loss: 0.00242608\n",
      "epoch: 97  batch: 17  loss: 0.00234321\n",
      "epoch: 97  batch: 18  loss: 0.00427732\n",
      "epoch: 97  batch: 19  loss: 0.00525859\n",
      "epoch: 97  batch: 20  loss: 0.00607467\n",
      "epoch: 97  batch: 21  loss: 0.00282580\n",
      "epoch: 97  batch: 22  loss: 0.00601687\n",
      "epoch: 97  batch: 23  loss: 0.00496902\n",
      "epoch: 97  batch: 24  loss: 0.00204898\n",
      "epoch: 97  batch: 25  loss: 0.00070899\n",
      "epoch: 97  batch: 26  loss: 0.00648375\n",
      "epoch: 97  batch: 27  loss: 0.00120569\n",
      "epoch: 97  batch: 28  loss: 0.01998652\n",
      "epoch: 98  batch: 1  loss: 0.01383062\n",
      "epoch: 98  batch: 2  loss: 0.00340454\n",
      "epoch: 98  batch: 3  loss: 0.00598064\n",
      "epoch: 98  batch: 4  loss: 0.00317684\n",
      "epoch: 98  batch: 5  loss: 0.00184917\n",
      "epoch: 98  batch: 6  loss: 0.00358935\n",
      "epoch: 98  batch: 7  loss: 0.00468783\n",
      "epoch: 98  batch: 8  loss: 0.00399847\n",
      "epoch: 98  batch: 9  loss: 0.00197702\n",
      "epoch: 98  batch: 10  loss: 0.00127859\n",
      "epoch: 98  batch: 11  loss: 0.00545272\n",
      "epoch: 98  batch: 12  loss: 0.00283318\n",
      "epoch: 98  batch: 13  loss: 0.12169152\n",
      "epoch: 98  batch: 14  loss: 0.00225651\n",
      "epoch: 98  batch: 15  loss: 0.00747263\n",
      "epoch: 98  batch: 16  loss: 0.00665021\n",
      "epoch: 98  batch: 17  loss: 0.00596495\n",
      "epoch: 98  batch: 18  loss: 0.00990833\n",
      "epoch: 98  batch: 19  loss: 0.00285841\n",
      "epoch: 98  batch: 20  loss: 0.00760979\n",
      "epoch: 98  batch: 21  loss: 0.00312296\n",
      "epoch: 98  batch: 22  loss: 0.00499244\n",
      "epoch: 98  batch: 23  loss: 0.00792477\n",
      "epoch: 98  batch: 24  loss: 0.01922605\n",
      "epoch: 98  batch: 25  loss: 0.00379014\n",
      "epoch: 98  batch: 26  loss: 0.00456568\n",
      "epoch: 98  batch: 27  loss: 0.00520041\n",
      "epoch: 98  batch: 28  loss: 0.00429953\n",
      "epoch: 99  batch: 1  loss: 0.00772122\n",
      "epoch: 99  batch: 2  loss: 0.00524376\n",
      "epoch: 99  batch: 3  loss: 0.00183029\n",
      "epoch: 99  batch: 4  loss: 0.00330758\n",
      "epoch: 99  batch: 5  loss: 0.00520250\n",
      "epoch: 99  batch: 6  loss: 0.01625202\n",
      "epoch: 99  batch: 7  loss: 0.00434890\n",
      "epoch: 99  batch: 8  loss: 0.00188060\n",
      "epoch: 99  batch: 9  loss: 0.00338512\n",
      "epoch: 99  batch: 10  loss: 0.00136873\n",
      "epoch: 99  batch: 11  loss: 0.00386492\n",
      "epoch: 99  batch: 12  loss: 0.00706113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99  batch: 13  loss: 0.00509529\n",
      "epoch: 99  batch: 14  loss: 0.00346363\n",
      "epoch: 99  batch: 15  loss: 0.00452232\n",
      "epoch: 99  batch: 16  loss: 0.00331137\n",
      "epoch: 99  batch: 17  loss: 0.00186720\n",
      "epoch: 99  batch: 18  loss: 0.02041185\n",
      "epoch: 99  batch: 19  loss: 0.00133640\n",
      "epoch: 99  batch: 20  loss: 0.00421229\n",
      "epoch: 99  batch: 21  loss: 0.00228180\n",
      "epoch: 99  batch: 22  loss: 0.00283300\n",
      "epoch: 99  batch: 23  loss: 0.00301277\n",
      "epoch: 99  batch: 24  loss: 0.00507246\n",
      "epoch: 99  batch: 25  loss: 0.00364106\n",
      "epoch: 99  batch: 26  loss: 0.00638569\n",
      "epoch: 99  batch: 27  loss: 0.00743264\n",
      "epoch: 99  batch: 28  loss: 0.00282645\n",
      "epoch: 100  batch: 1  loss: 0.00381650\n",
      "epoch: 100  batch: 2  loss: 0.01082819\n",
      "epoch: 100  batch: 3  loss: 0.00286844\n",
      "epoch: 100  batch: 4  loss: 0.01619374\n",
      "epoch: 100  batch: 5  loss: 0.00449108\n",
      "epoch: 100  batch: 6  loss: 0.00329164\n",
      "epoch: 100  batch: 7  loss: 0.00558647\n",
      "epoch: 100  batch: 8  loss: 0.00285734\n",
      "epoch: 100  batch: 9  loss: 0.00718769\n",
      "epoch: 100  batch: 10  loss: 0.00791205\n",
      "epoch: 100  batch: 11  loss: 0.01063211\n",
      "epoch: 100  batch: 12  loss: 0.01522746\n",
      "epoch: 100  batch: 13  loss: 0.00415191\n",
      "epoch: 100  batch: 14  loss: 0.00230034\n",
      "epoch: 100  batch: 15  loss: 0.00608892\n",
      "epoch: 100  batch: 16  loss: 0.00050903\n",
      "epoch: 100  batch: 17  loss: 0.00244801\n",
      "epoch: 100  batch: 18  loss: 0.00188458\n",
      "epoch: 100  batch: 19  loss: 0.00452761\n",
      "epoch: 100  batch: 20  loss: 0.00172736\n",
      "epoch: 100  batch: 21  loss: 0.00420352\n",
      "epoch: 100  batch: 22  loss: 0.00354690\n",
      "epoch: 100  batch: 23  loss: 0.01953457\n",
      "epoch: 100  batch: 24  loss: 0.00993294\n",
      "epoch: 100  batch: 25  loss: 0.00329171\n",
      "epoch: 100  batch: 26  loss: 0.00474537\n",
      "epoch: 100  batch: 27  loss: 0.00493157\n",
      "epoch: 100  batch: 28  loss: 0.00254638\n",
      "epoch: 101  batch: 1  loss: 0.00330459\n",
      "epoch: 101  batch: 2  loss: 0.00526467\n",
      "epoch: 101  batch: 3  loss: 0.01556586\n",
      "epoch: 101  batch: 4  loss: 0.00196825\n",
      "epoch: 101  batch: 5  loss: 0.00513732\n",
      "epoch: 101  batch: 6  loss: 0.00858524\n",
      "epoch: 101  batch: 7  loss: 0.00732696\n",
      "epoch: 101  batch: 8  loss: 0.00162022\n",
      "epoch: 101  batch: 9  loss: 0.00437638\n",
      "epoch: 101  batch: 10  loss: 0.00233293\n",
      "epoch: 101  batch: 11  loss: 0.00263392\n",
      "epoch: 101  batch: 12  loss: 0.00336515\n",
      "epoch: 101  batch: 13  loss: 0.00690207\n",
      "epoch: 101  batch: 14  loss: 0.00541830\n",
      "epoch: 101  batch: 15  loss: 0.00118017\n",
      "epoch: 101  batch: 16  loss: 0.00548171\n",
      "epoch: 101  batch: 17  loss: 0.00505337\n",
      "epoch: 101  batch: 18  loss: 0.00079603\n",
      "epoch: 101  batch: 19  loss: 0.00310666\n",
      "epoch: 101  batch: 20  loss: 0.02075671\n",
      "epoch: 101  batch: 21  loss: 0.00242990\n",
      "epoch: 101  batch: 22  loss: 0.04234794\n",
      "epoch: 101  batch: 23  loss: 0.00328065\n",
      "epoch: 101  batch: 24  loss: 0.00073482\n",
      "epoch: 101  batch: 25  loss: 0.00468958\n",
      "epoch: 101  batch: 26  loss: 0.00535156\n",
      "epoch: 101  batch: 27  loss: 0.00345117\n",
      "epoch: 101  batch: 28  loss: 0.00444756\n",
      "epoch: 102  batch: 1  loss: 0.00165157\n",
      "epoch: 102  batch: 2  loss: 0.00409335\n",
      "epoch: 102  batch: 3  loss: 0.00560666\n",
      "epoch: 102  batch: 4  loss: 0.00182992\n",
      "epoch: 102  batch: 5  loss: 0.00239367\n",
      "epoch: 102  batch: 6  loss: 0.00313226\n",
      "epoch: 102  batch: 7  loss: 0.00817982\n",
      "epoch: 102  batch: 8  loss: 0.00201740\n",
      "epoch: 102  batch: 9  loss: 0.02020445\n",
      "epoch: 102  batch: 10  loss: 0.01534104\n",
      "epoch: 102  batch: 11  loss: 0.00495675\n",
      "epoch: 102  batch: 12  loss: 0.00849212\n",
      "epoch: 102  batch: 13  loss: 0.00316468\n",
      "epoch: 102  batch: 14  loss: 0.00466221\n",
      "epoch: 102  batch: 15  loss: 0.00208386\n",
      "epoch: 102  batch: 16  loss: 0.00185998\n",
      "epoch: 102  batch: 17  loss: 0.00267686\n",
      "epoch: 102  batch: 18  loss: 0.00445406\n",
      "epoch: 102  batch: 19  loss: 0.00728372\n",
      "epoch: 102  batch: 20  loss: 0.00282618\n",
      "epoch: 102  batch: 21  loss: 0.00483850\n",
      "epoch: 102  batch: 22  loss: 0.00238811\n",
      "epoch: 102  batch: 23  loss: 0.00930230\n",
      "epoch: 102  batch: 24  loss: 0.00296776\n",
      "epoch: 102  batch: 25  loss: 0.00546701\n",
      "epoch: 102  batch: 26  loss: 0.00170125\n",
      "epoch: 102  batch: 27  loss: 0.00155101\n",
      "epoch: 102  batch: 28  loss: 0.01303074\n",
      "epoch: 103  batch: 1  loss: 0.00168418\n",
      "epoch: 103  batch: 2  loss: 0.00527420\n",
      "epoch: 103  batch: 3  loss: 0.00485594\n",
      "epoch: 103  batch: 4  loss: 0.00980641\n",
      "epoch: 103  batch: 5  loss: 0.00306387\n",
      "epoch: 103  batch: 6  loss: 0.00760582\n",
      "epoch: 103  batch: 7  loss: 0.00131929\n",
      "epoch: 103  batch: 8  loss: 0.00229189\n",
      "epoch: 103  batch: 9  loss: 0.00524539\n",
      "epoch: 103  batch: 10  loss: 0.00233072\n",
      "epoch: 103  batch: 11  loss: 0.00380756\n",
      "epoch: 103  batch: 12  loss: 0.00718734\n",
      "epoch: 103  batch: 13  loss: 0.00392284\n",
      "epoch: 103  batch: 14  loss: 0.00650962\n",
      "epoch: 103  batch: 15  loss: 0.04165611\n",
      "epoch: 103  batch: 16  loss: 0.00183276\n",
      "epoch: 103  batch: 17  loss: 0.00668093\n",
      "epoch: 103  batch: 18  loss: 0.00205786\n",
      "epoch: 103  batch: 19  loss: 0.00308407\n",
      "epoch: 103  batch: 20  loss: 0.00190351\n",
      "epoch: 103  batch: 21  loss: 0.00300486\n",
      "epoch: 103  batch: 22  loss: 0.00415637\n",
      "epoch: 103  batch: 23  loss: 0.00206601\n",
      "epoch: 103  batch: 24  loss: 0.00332927\n",
      "epoch: 103  batch: 25  loss: 0.00835990\n",
      "epoch: 103  batch: 26  loss: 0.00502924\n",
      "epoch: 103  batch: 27  loss: 0.00251303\n",
      "epoch: 103  batch: 28  loss: 0.00309418\n",
      "epoch: 104  batch: 1  loss: 0.00477904\n",
      "epoch: 104  batch: 2  loss: 0.00571442\n",
      "epoch: 104  batch: 3  loss: 0.00422419\n",
      "epoch: 104  batch: 4  loss: 0.00894774\n",
      "epoch: 104  batch: 5  loss: 0.00166926\n",
      "epoch: 104  batch: 6  loss: 0.02136631\n",
      "epoch: 104  batch: 7  loss: 0.00382298\n",
      "epoch: 104  batch: 8  loss: 0.00425729\n",
      "epoch: 104  batch: 9  loss: 0.00331704\n",
      "epoch: 104  batch: 10  loss: 0.00237329\n",
      "epoch: 104  batch: 11  loss: 0.01033670\n",
      "epoch: 104  batch: 12  loss: 0.00165282\n",
      "epoch: 104  batch: 13  loss: 0.01127823\n",
      "epoch: 104  batch: 14  loss: 0.00212005\n",
      "epoch: 104  batch: 15  loss: 0.00160856\n",
      "epoch: 104  batch: 16  loss: 0.00574579\n",
      "epoch: 104  batch: 17  loss: 0.00376350\n",
      "epoch: 104  batch: 18  loss: 0.00788429\n",
      "epoch: 104  batch: 19  loss: 0.00237522\n",
      "epoch: 104  batch: 20  loss: 0.00332662\n",
      "epoch: 104  batch: 21  loss: 0.00755643\n",
      "epoch: 104  batch: 22  loss: 0.00068297\n",
      "epoch: 104  batch: 23  loss: 0.00624381\n",
      "epoch: 104  batch: 24  loss: 0.00538290\n",
      "epoch: 104  batch: 25  loss: 0.00069331\n",
      "epoch: 104  batch: 26  loss: 0.00704311\n",
      "epoch: 104  batch: 27  loss: 0.00417870\n",
      "epoch: 104  batch: 28  loss: 0.00627698\n",
      "epoch: 105  batch: 1  loss: 0.00193746\n",
      "epoch: 105  batch: 2  loss: 0.00181912\n",
      "epoch: 105  batch: 3  loss: 0.00301876\n",
      "epoch: 105  batch: 4  loss: 0.03467652\n",
      "epoch: 105  batch: 5  loss: 0.00385439\n",
      "epoch: 105  batch: 6  loss: 0.01132435\n",
      "epoch: 105  batch: 7  loss: 0.00314838\n",
      "epoch: 105  batch: 8  loss: 0.00265537\n",
      "epoch: 105  batch: 9  loss: 0.00400304\n",
      "epoch: 105  batch: 10  loss: 0.00424823\n",
      "epoch: 105  batch: 11  loss: 0.00267348\n",
      "epoch: 105  batch: 12  loss: 0.00296084\n",
      "epoch: 105  batch: 13  loss: 0.00445051\n",
      "epoch: 105  batch: 14  loss: 0.00184363\n",
      "epoch: 105  batch: 15  loss: 0.00268548\n",
      "epoch: 105  batch: 16  loss: 0.02001364\n",
      "epoch: 105  batch: 17  loss: 0.00249719\n",
      "epoch: 105  batch: 18  loss: 0.00416727\n",
      "epoch: 105  batch: 19  loss: 0.00503015\n",
      "epoch: 105  batch: 20  loss: 0.00474082\n",
      "epoch: 105  batch: 21  loss: 0.00411963\n",
      "epoch: 105  batch: 22  loss: 0.00463358\n",
      "epoch: 105  batch: 23  loss: 0.02973680\n",
      "epoch: 105  batch: 24  loss: 0.00413585\n",
      "epoch: 105  batch: 25  loss: 0.00820506\n",
      "epoch: 105  batch: 26  loss: 0.00482293\n",
      "epoch: 105  batch: 27  loss: 0.00506467\n",
      "epoch: 105  batch: 28  loss: 0.00699865\n",
      "epoch: 106  batch: 1  loss: 0.00751091\n",
      "epoch: 106  batch: 2  loss: 0.00578796\n",
      "epoch: 106  batch: 3  loss: 0.00799596\n",
      "epoch: 106  batch: 4  loss: 0.00347514\n",
      "epoch: 106  batch: 5  loss: 0.00408185\n",
      "epoch: 106  batch: 6  loss: 0.00500480\n",
      "epoch: 106  batch: 7  loss: 0.00640872\n",
      "epoch: 106  batch: 8  loss: 0.00700237\n",
      "epoch: 106  batch: 9  loss: 0.02622978\n",
      "epoch: 106  batch: 10  loss: 0.00172506\n",
      "epoch: 106  batch: 11  loss: 0.00368665\n",
      "epoch: 106  batch: 12  loss: 0.00270290\n",
      "epoch: 106  batch: 13  loss: 0.00495488\n",
      "epoch: 106  batch: 14  loss: 0.00758436\n",
      "epoch: 106  batch: 15  loss: 0.00265730\n",
      "epoch: 106  batch: 16  loss: 0.00256891\n",
      "epoch: 106  batch: 17  loss: 0.00155725\n",
      "epoch: 106  batch: 18  loss: 0.00254968\n",
      "epoch: 106  batch: 19  loss: 0.08697595\n",
      "epoch: 106  batch: 20  loss: 0.00347943\n",
      "epoch: 106  batch: 21  loss: 0.00223595\n",
      "epoch: 106  batch: 22  loss: 0.00960696\n",
      "epoch: 106  batch: 23  loss: 0.00313988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106  batch: 24  loss: 0.00277173\n",
      "epoch: 106  batch: 25  loss: 0.01487436\n",
      "epoch: 106  batch: 26  loss: 0.00778734\n",
      "epoch: 106  batch: 27  loss: 0.01606144\n",
      "epoch: 106  batch: 28  loss: 0.00646652\n",
      "epoch: 107  batch: 1  loss: 0.00501340\n",
      "epoch: 107  batch: 2  loss: 0.00529428\n",
      "epoch: 107  batch: 3  loss: 0.00812664\n",
      "epoch: 107  batch: 4  loss: 0.00694290\n",
      "epoch: 107  batch: 5  loss: 0.00333715\n",
      "epoch: 107  batch: 6  loss: 0.02610985\n",
      "epoch: 107  batch: 7  loss: 0.00724509\n",
      "epoch: 107  batch: 8  loss: 0.00357293\n",
      "epoch: 107  batch: 9  loss: 0.00143576\n",
      "epoch: 107  batch: 10  loss: 0.00455629\n",
      "epoch: 107  batch: 11  loss: 0.00365466\n",
      "epoch: 107  batch: 12  loss: 0.00291636\n",
      "epoch: 107  batch: 13  loss: 0.00204988\n",
      "epoch: 107  batch: 14  loss: 0.01111590\n",
      "epoch: 107  batch: 15  loss: 0.00660811\n",
      "epoch: 107  batch: 16  loss: 0.00485716\n",
      "epoch: 107  batch: 17  loss: 0.00480672\n",
      "epoch: 107  batch: 18  loss: 0.00236820\n",
      "epoch: 107  batch: 19  loss: 0.00305879\n",
      "epoch: 107  batch: 20  loss: 0.00220062\n",
      "epoch: 107  batch: 21  loss: 0.00222992\n",
      "epoch: 107  batch: 22  loss: 0.00537042\n",
      "epoch: 107  batch: 23  loss: 0.00108009\n",
      "epoch: 107  batch: 24  loss: 0.00689022\n",
      "epoch: 107  batch: 25  loss: 0.00204887\n",
      "epoch: 107  batch: 26  loss: 0.00267732\n",
      "epoch: 107  batch: 27  loss: 0.00050287\n",
      "epoch: 107  batch: 28  loss: 0.00704884\n",
      "epoch: 108  batch: 1  loss: 0.00302091\n",
      "epoch: 108  batch: 2  loss: 0.00797962\n",
      "epoch: 108  batch: 3  loss: 0.00279373\n",
      "epoch: 108  batch: 4  loss: 0.00445865\n",
      "epoch: 108  batch: 5  loss: 0.00126956\n",
      "epoch: 108  batch: 6  loss: 0.00642104\n",
      "epoch: 108  batch: 7  loss: 0.00469626\n",
      "epoch: 108  batch: 8  loss: 0.00530631\n",
      "epoch: 108  batch: 9  loss: 0.00522207\n",
      "epoch: 108  batch: 10  loss: 0.01788919\n",
      "epoch: 108  batch: 11  loss: 0.01552654\n",
      "epoch: 108  batch: 12  loss: 0.00557188\n",
      "epoch: 108  batch: 13  loss: 0.00536238\n",
      "epoch: 108  batch: 14  loss: 0.00327588\n",
      "epoch: 108  batch: 15  loss: 0.00292952\n",
      "epoch: 108  batch: 16  loss: 0.00237112\n",
      "epoch: 108  batch: 17  loss: 0.00337213\n",
      "epoch: 108  batch: 18  loss: 0.00086069\n",
      "epoch: 108  batch: 19  loss: 0.00613198\n",
      "epoch: 108  batch: 20  loss: 0.02253516\n",
      "epoch: 108  batch: 21  loss: 0.00201631\n",
      "epoch: 108  batch: 22  loss: 0.00179463\n",
      "epoch: 108  batch: 23  loss: 0.00448132\n",
      "epoch: 108  batch: 24  loss: 0.00121627\n",
      "epoch: 108  batch: 25  loss: 0.00254225\n",
      "epoch: 108  batch: 26  loss: 0.00540973\n",
      "epoch: 108  batch: 27  loss: 0.00462814\n",
      "epoch: 108  batch: 28  loss: 0.00952676\n",
      "epoch: 109  batch: 1  loss: 0.00582405\n",
      "epoch: 109  batch: 2  loss: 0.00473459\n",
      "epoch: 109  batch: 3  loss: 0.00150516\n",
      "epoch: 109  batch: 4  loss: 0.00771342\n",
      "epoch: 109  batch: 5  loss: 0.00365080\n",
      "epoch: 109  batch: 6  loss: 0.00566698\n",
      "epoch: 109  batch: 7  loss: 0.00282311\n",
      "epoch: 109  batch: 8  loss: 0.00401500\n",
      "epoch: 109  batch: 9  loss: 0.01930528\n",
      "epoch: 109  batch: 10  loss: 0.00317283\n",
      "epoch: 109  batch: 11  loss: 0.00667017\n",
      "epoch: 109  batch: 12  loss: 0.00122509\n",
      "epoch: 109  batch: 13  loss: 0.00371088\n",
      "epoch: 109  batch: 14  loss: 0.00431880\n",
      "epoch: 109  batch: 15  loss: 0.00272811\n",
      "epoch: 109  batch: 16  loss: 0.00365544\n",
      "epoch: 109  batch: 17  loss: 0.00148330\n",
      "epoch: 109  batch: 18  loss: 0.00473633\n",
      "epoch: 109  batch: 19  loss: 0.03351776\n",
      "epoch: 109  batch: 20  loss: 0.00228421\n",
      "epoch: 109  batch: 21  loss: 0.00869636\n",
      "epoch: 109  batch: 22  loss: 0.00353325\n",
      "epoch: 109  batch: 23  loss: 0.00191887\n",
      "epoch: 109  batch: 24  loss: 0.03499290\n",
      "epoch: 109  batch: 25  loss: 0.00367810\n",
      "epoch: 109  batch: 26  loss: 0.00366821\n",
      "epoch: 109  batch: 27  loss: 0.00356264\n",
      "epoch: 109  batch: 28  loss: 0.00702159\n",
      "epoch: 110  batch: 1  loss: 0.00307778\n",
      "epoch: 110  batch: 2  loss: 0.00280750\n",
      "epoch: 110  batch: 3  loss: 0.00214635\n",
      "epoch: 110  batch: 4  loss: 0.00369369\n",
      "epoch: 110  batch: 5  loss: 0.00226957\n",
      "epoch: 110  batch: 6  loss: 0.00196478\n",
      "epoch: 110  batch: 7  loss: 0.00936498\n",
      "epoch: 110  batch: 8  loss: 0.00310155\n",
      "epoch: 110  batch: 9  loss: 0.01211551\n",
      "epoch: 110  batch: 10  loss: 0.00799773\n",
      "epoch: 110  batch: 11  loss: 0.00262857\n",
      "epoch: 110  batch: 12  loss: 0.00229977\n",
      "epoch: 110  batch: 13  loss: 0.00243879\n",
      "epoch: 110  batch: 14  loss: 0.00211897\n",
      "epoch: 110  batch: 15  loss: 0.00143916\n",
      "epoch: 110  batch: 16  loss: 0.00105194\n",
      "epoch: 110  batch: 17  loss: 0.00550506\n",
      "epoch: 110  batch: 18  loss: 0.00116423\n",
      "epoch: 110  batch: 19  loss: 0.00303141\n",
      "epoch: 110  batch: 20  loss: 0.02350806\n",
      "epoch: 110  batch: 21  loss: 0.00128239\n",
      "epoch: 110  batch: 22  loss: 0.00421799\n",
      "epoch: 110  batch: 23  loss: 0.00151500\n",
      "epoch: 110  batch: 24  loss: 0.00624832\n",
      "epoch: 110  batch: 25  loss: 0.02405905\n",
      "epoch: 110  batch: 26  loss: 0.01481574\n",
      "epoch: 110  batch: 27  loss: 0.00236343\n",
      "epoch: 110  batch: 28  loss: 0.00802447\n",
      "epoch: 111  batch: 1  loss: 0.00114260\n",
      "epoch: 111  batch: 2  loss: 0.00377652\n",
      "epoch: 111  batch: 3  loss: 0.00628417\n",
      "epoch: 111  batch: 4  loss: 0.00086654\n",
      "epoch: 111  batch: 5  loss: 0.00500569\n",
      "epoch: 111  batch: 6  loss: 0.00481615\n",
      "epoch: 111  batch: 7  loss: 0.00339610\n",
      "epoch: 111  batch: 8  loss: 0.00563185\n",
      "epoch: 111  batch: 9  loss: 0.00551637\n",
      "epoch: 111  batch: 10  loss: 0.02024592\n",
      "epoch: 111  batch: 11  loss: 0.00753164\n",
      "epoch: 111  batch: 12  loss: 0.00106821\n",
      "epoch: 111  batch: 13  loss: 0.00318038\n",
      "epoch: 111  batch: 14  loss: 0.01591786\n",
      "epoch: 111  batch: 15  loss: 0.00252336\n",
      "epoch: 111  batch: 16  loss: 0.01381091\n",
      "epoch: 111  batch: 17  loss: 0.00191386\n",
      "epoch: 111  batch: 18  loss: 0.00375180\n",
      "epoch: 111  batch: 19  loss: 0.00382869\n",
      "epoch: 111  batch: 20  loss: 0.00376278\n",
      "epoch: 111  batch: 21  loss: 0.00183338\n",
      "epoch: 111  batch: 22  loss: 0.00828706\n",
      "epoch: 111  batch: 23  loss: 0.00320837\n",
      "epoch: 111  batch: 24  loss: 0.00508713\n",
      "epoch: 111  batch: 25  loss: 0.00149321\n",
      "epoch: 111  batch: 26  loss: 0.00143997\n",
      "epoch: 111  batch: 27  loss: 0.00254493\n",
      "epoch: 111  batch: 28  loss: 0.00404266\n",
      "epoch: 112  batch: 1  loss: 0.00650018\n",
      "epoch: 112  batch: 2  loss: 0.02590420\n",
      "epoch: 112  batch: 3  loss: 0.01179180\n",
      "epoch: 112  batch: 4  loss: 0.00572803\n",
      "epoch: 112  batch: 5  loss: 0.00683635\n",
      "epoch: 112  batch: 6  loss: 0.00283319\n",
      "epoch: 112  batch: 7  loss: 0.00355195\n",
      "epoch: 112  batch: 8  loss: 0.00464469\n",
      "epoch: 112  batch: 9  loss: 0.00362913\n",
      "epoch: 112  batch: 10  loss: 0.00327438\n",
      "epoch: 112  batch: 11  loss: 0.02976003\n",
      "epoch: 112  batch: 12  loss: 0.00901413\n",
      "epoch: 112  batch: 13  loss: 0.01611388\n",
      "epoch: 112  batch: 14  loss: 0.00227844\n",
      "epoch: 112  batch: 15  loss: 0.00177647\n",
      "epoch: 112  batch: 16  loss: 0.00259662\n",
      "epoch: 112  batch: 17  loss: 0.00231728\n",
      "epoch: 112  batch: 18  loss: 0.00550910\n",
      "epoch: 112  batch: 19  loss: 0.00381508\n",
      "epoch: 112  batch: 20  loss: 0.00651849\n",
      "epoch: 112  batch: 21  loss: 0.00666509\n",
      "epoch: 112  batch: 22  loss: 0.00295506\n",
      "epoch: 112  batch: 23  loss: 0.00350308\n",
      "epoch: 112  batch: 24  loss: 0.00273895\n",
      "epoch: 112  batch: 25  loss: 0.00192595\n",
      "epoch: 112  batch: 26  loss: 0.00283000\n",
      "epoch: 112  batch: 27  loss: 0.01336757\n",
      "epoch: 112  batch: 28  loss: 0.00364838\n",
      "epoch: 113  batch: 1  loss: 0.01086941\n",
      "epoch: 113  batch: 2  loss: 0.01128934\n",
      "epoch: 113  batch: 3  loss: 0.00975012\n",
      "epoch: 113  batch: 4  loss: 0.02688394\n",
      "epoch: 113  batch: 5  loss: 0.00575606\n",
      "epoch: 113  batch: 6  loss: 0.00238956\n",
      "epoch: 113  batch: 7  loss: 0.00141116\n",
      "epoch: 113  batch: 8  loss: 0.00098654\n",
      "epoch: 113  batch: 9  loss: 0.00297390\n",
      "epoch: 113  batch: 10  loss: 0.00325391\n",
      "epoch: 113  batch: 11  loss: 0.00461270\n",
      "epoch: 113  batch: 12  loss: 0.00229116\n",
      "epoch: 113  batch: 13  loss: 0.00417103\n",
      "epoch: 113  batch: 14  loss: 0.00358842\n",
      "epoch: 113  batch: 15  loss: 0.00419662\n",
      "epoch: 113  batch: 16  loss: 0.00518992\n",
      "epoch: 113  batch: 17  loss: 0.00233557\n",
      "epoch: 113  batch: 18  loss: 0.00218961\n",
      "epoch: 113  batch: 19  loss: 0.00179442\n",
      "epoch: 113  batch: 20  loss: 0.00891642\n",
      "epoch: 113  batch: 21  loss: 0.00436763\n",
      "epoch: 113  batch: 22  loss: 0.00342636\n",
      "epoch: 113  batch: 23  loss: 0.00216598\n",
      "epoch: 113  batch: 24  loss: 0.00644585\n",
      "epoch: 113  batch: 25  loss: 0.00402710\n",
      "epoch: 113  batch: 26  loss: 0.00203486\n",
      "epoch: 113  batch: 27  loss: 0.00282095\n",
      "epoch: 113  batch: 28  loss: 0.00541813\n",
      "epoch: 114  batch: 1  loss: 0.00198648\n",
      "epoch: 114  batch: 2  loss: 0.00347423\n",
      "epoch: 114  batch: 3  loss: 0.00796106\n",
      "epoch: 114  batch: 4  loss: 0.00553091\n",
      "epoch: 114  batch: 5  loss: 0.00164130\n",
      "epoch: 114  batch: 6  loss: 0.00215218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 114  batch: 7  loss: 0.01283375\n",
      "epoch: 114  batch: 8  loss: 0.00214468\n",
      "epoch: 114  batch: 9  loss: 0.00320999\n",
      "epoch: 114  batch: 10  loss: 0.00686347\n",
      "epoch: 114  batch: 11  loss: 0.03332075\n",
      "epoch: 114  batch: 12  loss: 0.00426674\n",
      "epoch: 114  batch: 13  loss: 0.00446182\n",
      "epoch: 114  batch: 14  loss: 0.00709551\n",
      "epoch: 114  batch: 15  loss: 0.00508754\n",
      "epoch: 114  batch: 16  loss: 0.00507665\n",
      "epoch: 114  batch: 17  loss: 0.00233556\n",
      "epoch: 114  batch: 18  loss: 0.02183567\n",
      "epoch: 114  batch: 19  loss: 0.00345576\n",
      "epoch: 114  batch: 20  loss: 0.00264109\n",
      "epoch: 114  batch: 21  loss: 0.00953281\n",
      "epoch: 114  batch: 22  loss: 0.00530715\n",
      "epoch: 114  batch: 23  loss: 0.01133305\n",
      "epoch: 114  batch: 24  loss: 0.00343965\n",
      "epoch: 114  batch: 25  loss: 0.00200918\n",
      "epoch: 114  batch: 26  loss: 0.00289861\n",
      "epoch: 114  batch: 27  loss: 0.00446053\n",
      "epoch: 114  batch: 28  loss: 0.00373773\n",
      "epoch: 115  batch: 1  loss: 0.00266231\n",
      "epoch: 115  batch: 2  loss: 0.00596082\n",
      "epoch: 115  batch: 3  loss: 0.00429270\n",
      "epoch: 115  batch: 4  loss: 0.00285418\n",
      "epoch: 115  batch: 5  loss: 0.00465446\n",
      "epoch: 115  batch: 6  loss: 0.00157873\n",
      "epoch: 115  batch: 7  loss: 0.00226961\n",
      "epoch: 115  batch: 8  loss: 0.00369605\n",
      "epoch: 115  batch: 9  loss: 0.00336180\n",
      "epoch: 115  batch: 10  loss: 0.00303203\n",
      "epoch: 115  batch: 11  loss: 0.00275050\n",
      "epoch: 115  batch: 12  loss: 0.00883719\n",
      "epoch: 115  batch: 13  loss: 0.00393096\n",
      "epoch: 115  batch: 14  loss: 0.00298810\n",
      "epoch: 115  batch: 15  loss: 0.01207383\n",
      "epoch: 115  batch: 16  loss: 0.00651755\n",
      "epoch: 115  batch: 17  loss: 0.00241826\n",
      "epoch: 115  batch: 18  loss: 0.00967230\n",
      "epoch: 115  batch: 19  loss: 0.00314321\n",
      "epoch: 115  batch: 20  loss: 0.00083641\n",
      "epoch: 115  batch: 21  loss: 0.00797375\n",
      "epoch: 115  batch: 22  loss: 0.00379121\n",
      "epoch: 115  batch: 23  loss: 0.00242448\n",
      "epoch: 115  batch: 24  loss: 0.01623376\n",
      "epoch: 115  batch: 25  loss: 0.00184563\n",
      "epoch: 115  batch: 26  loss: 0.00271074\n",
      "epoch: 115  batch: 27  loss: 0.01439060\n",
      "epoch: 115  batch: 28  loss: 0.00114414\n",
      "epoch: 116  batch: 1  loss: 0.00172413\n",
      "epoch: 116  batch: 2  loss: 0.00340274\n",
      "epoch: 116  batch: 3  loss: 0.00711604\n",
      "epoch: 116  batch: 4  loss: 0.00171717\n",
      "epoch: 116  batch: 5  loss: 0.00400145\n",
      "epoch: 116  batch: 6  loss: 0.00754227\n",
      "epoch: 116  batch: 7  loss: 0.00812372\n",
      "epoch: 116  batch: 8  loss: 0.00664940\n",
      "epoch: 116  batch: 9  loss: 0.00525637\n",
      "epoch: 116  batch: 10  loss: 0.00286196\n",
      "epoch: 116  batch: 11  loss: 0.00422126\n",
      "epoch: 116  batch: 12  loss: 0.02101967\n",
      "epoch: 116  batch: 13  loss: 0.00143936\n",
      "epoch: 116  batch: 14  loss: 0.01763891\n",
      "epoch: 116  batch: 15  loss: 0.01524782\n",
      "epoch: 116  batch: 16  loss: 0.00237374\n",
      "epoch: 116  batch: 17  loss: 0.00402656\n",
      "epoch: 116  batch: 18  loss: 0.00207071\n",
      "epoch: 116  batch: 19  loss: 0.00308635\n",
      "epoch: 116  batch: 20  loss: 0.00165638\n",
      "epoch: 116  batch: 21  loss: 0.00184171\n",
      "epoch: 116  batch: 22  loss: 0.00378715\n",
      "epoch: 116  batch: 23  loss: 0.00250354\n",
      "epoch: 116  batch: 24  loss: 0.00360502\n",
      "epoch: 116  batch: 25  loss: 0.00260869\n",
      "epoch: 116  batch: 26  loss: 0.00186539\n",
      "epoch: 116  batch: 27  loss: 0.00330811\n",
      "epoch: 116  batch: 28  loss: 0.00157741\n",
      "epoch: 117  batch: 1  loss: 0.01761734\n",
      "epoch: 117  batch: 2  loss: 0.00694240\n",
      "epoch: 117  batch: 3  loss: 0.00309184\n",
      "epoch: 117  batch: 4  loss: 0.00263599\n",
      "epoch: 117  batch: 5  loss: 0.00277930\n",
      "epoch: 117  batch: 6  loss: 0.00228911\n",
      "epoch: 117  batch: 7  loss: 0.00354543\n",
      "epoch: 117  batch: 8  loss: 0.00099390\n",
      "epoch: 117  batch: 9  loss: 0.00764105\n",
      "epoch: 117  batch: 10  loss: 0.00203097\n",
      "epoch: 117  batch: 11  loss: 0.00266358\n",
      "epoch: 117  batch: 12  loss: 0.00244146\n",
      "epoch: 117  batch: 13  loss: 0.00346851\n",
      "epoch: 117  batch: 14  loss: 0.00497392\n",
      "epoch: 117  batch: 15  loss: 0.01219916\n",
      "epoch: 117  batch: 16  loss: 0.00425549\n",
      "epoch: 117  batch: 17  loss: 0.00340755\n",
      "epoch: 117  batch: 18  loss: 0.00158895\n",
      "epoch: 117  batch: 19  loss: 0.00305318\n",
      "epoch: 117  batch: 20  loss: 0.00268886\n",
      "epoch: 117  batch: 21  loss: 0.02737089\n",
      "epoch: 117  batch: 22  loss: 0.00285678\n",
      "epoch: 117  batch: 23  loss: 0.00745624\n",
      "epoch: 117  batch: 24  loss: 0.00315393\n",
      "epoch: 117  batch: 25  loss: 0.00486564\n",
      "epoch: 117  batch: 26  loss: 0.00785462\n",
      "epoch: 117  batch: 27  loss: 0.00233275\n",
      "epoch: 117  batch: 28  loss: 0.00089847\n",
      "epoch: 118  batch: 1  loss: 0.00430671\n",
      "epoch: 118  batch: 2  loss: 0.00337481\n",
      "epoch: 118  batch: 3  loss: 0.00417742\n",
      "epoch: 118  batch: 4  loss: 0.00534225\n",
      "epoch: 118  batch: 5  loss: 0.02562065\n",
      "epoch: 118  batch: 6  loss: 0.00315550\n",
      "epoch: 118  batch: 7  loss: 0.00476625\n",
      "epoch: 118  batch: 8  loss: 0.00278659\n",
      "epoch: 118  batch: 9  loss: 0.00219964\n",
      "epoch: 118  batch: 10  loss: 0.00514239\n",
      "epoch: 118  batch: 11  loss: 0.00496445\n",
      "epoch: 118  batch: 12  loss: 0.00296931\n",
      "epoch: 118  batch: 13  loss: 0.00304745\n",
      "epoch: 118  batch: 14  loss: 0.00551533\n",
      "epoch: 118  batch: 15  loss: 0.00204897\n",
      "epoch: 118  batch: 16  loss: 0.00584131\n",
      "epoch: 118  batch: 17  loss: 0.00171754\n",
      "epoch: 118  batch: 18  loss: 0.00676806\n",
      "epoch: 118  batch: 19  loss: 0.00421349\n",
      "epoch: 118  batch: 20  loss: 0.01263175\n",
      "epoch: 118  batch: 21  loss: 0.00841826\n",
      "epoch: 118  batch: 22  loss: 0.01217119\n",
      "epoch: 118  batch: 23  loss: 0.00559249\n",
      "epoch: 118  batch: 24  loss: 0.00472176\n",
      "epoch: 118  batch: 25  loss: 0.00410145\n",
      "epoch: 118  batch: 26  loss: 0.00352646\n",
      "epoch: 118  batch: 27  loss: 0.00281935\n",
      "epoch: 118  batch: 28  loss: 0.00266623\n",
      "epoch: 119  batch: 1  loss: 0.00269019\n",
      "epoch: 119  batch: 2  loss: 0.00132029\n",
      "epoch: 119  batch: 3  loss: 0.00330912\n",
      "epoch: 119  batch: 4  loss: 0.00381047\n",
      "epoch: 119  batch: 5  loss: 0.00179462\n",
      "epoch: 119  batch: 6  loss: 0.00413896\n",
      "epoch: 119  batch: 7  loss: 0.00421027\n",
      "epoch: 119  batch: 8  loss: 0.01515682\n",
      "epoch: 119  batch: 9  loss: 0.00445825\n",
      "epoch: 119  batch: 10  loss: 0.00374033\n",
      "epoch: 119  batch: 11  loss: 0.00449739\n",
      "epoch: 119  batch: 12  loss: 0.03542057\n",
      "epoch: 119  batch: 13  loss: 0.00278831\n",
      "epoch: 119  batch: 14  loss: 0.00995960\n",
      "epoch: 119  batch: 15  loss: 0.00441593\n",
      "epoch: 119  batch: 16  loss: 0.00457233\n",
      "epoch: 119  batch: 17  loss: 0.00625805\n",
      "epoch: 119  batch: 18  loss: 0.00207219\n",
      "epoch: 119  batch: 19  loss: 0.00175304\n",
      "epoch: 119  batch: 20  loss: 0.00403250\n",
      "epoch: 119  batch: 21  loss: 0.00123495\n",
      "epoch: 119  batch: 22  loss: 0.00433815\n",
      "epoch: 119  batch: 23  loss: 0.00564135\n",
      "epoch: 119  batch: 24  loss: 0.00177290\n",
      "epoch: 119  batch: 25  loss: 0.00148740\n",
      "epoch: 119  batch: 26  loss: 0.00602745\n",
      "epoch: 119  batch: 27  loss: 0.00669932\n",
      "epoch: 119  batch: 28  loss: 0.00997318\n",
      "epoch: 120  batch: 1  loss: 0.00243506\n",
      "epoch: 120  batch: 2  loss: 0.02032163\n",
      "epoch: 120  batch: 3  loss: 0.00589456\n",
      "epoch: 120  batch: 4  loss: 0.00320473\n",
      "epoch: 120  batch: 5  loss: 0.00686166\n",
      "epoch: 120  batch: 6  loss: 0.00978209\n",
      "epoch: 120  batch: 7  loss: 0.00304948\n",
      "epoch: 120  batch: 8  loss: 0.00266918\n",
      "epoch: 120  batch: 9  loss: 0.00156877\n",
      "epoch: 120  batch: 10  loss: 0.01280926\n",
      "epoch: 120  batch: 11  loss: 0.00073699\n",
      "epoch: 120  batch: 12  loss: 0.00482926\n",
      "epoch: 120  batch: 13  loss: 0.00425773\n",
      "epoch: 120  batch: 14  loss: 0.00417630\n",
      "epoch: 120  batch: 15  loss: 0.00298225\n",
      "epoch: 120  batch: 16  loss: 0.00414467\n",
      "epoch: 120  batch: 17  loss: 0.00235386\n",
      "epoch: 120  batch: 18  loss: 0.00265628\n",
      "epoch: 120  batch: 19  loss: 0.00314465\n",
      "epoch: 120  batch: 20  loss: 0.00117617\n",
      "epoch: 120  batch: 21  loss: 0.00523861\n",
      "epoch: 120  batch: 22  loss: 0.00314151\n",
      "epoch: 120  batch: 23  loss: 0.01558591\n",
      "epoch: 120  batch: 24  loss: 0.00606287\n",
      "epoch: 120  batch: 25  loss: 0.00557405\n",
      "epoch: 120  batch: 26  loss: 0.00324892\n",
      "epoch: 120  batch: 27  loss: 0.00309450\n",
      "epoch: 120  batch: 28  loss: 0.00666696\n",
      "epoch: 121  batch: 1  loss: 0.00233414\n",
      "epoch: 121  batch: 2  loss: 0.02177827\n",
      "epoch: 121  batch: 3  loss: 0.00418232\n",
      "epoch: 121  batch: 4  loss: 0.00890926\n",
      "epoch: 121  batch: 5  loss: 0.00454967\n",
      "epoch: 121  batch: 6  loss: 0.00238757\n",
      "epoch: 121  batch: 7  loss: 0.00195530\n",
      "epoch: 121  batch: 8  loss: 0.00144979\n",
      "epoch: 121  batch: 9  loss: 0.00118790\n",
      "epoch: 121  batch: 10  loss: 0.00594464\n",
      "epoch: 121  batch: 11  loss: 0.01034830\n",
      "epoch: 121  batch: 12  loss: 0.00784005\n",
      "epoch: 121  batch: 13  loss: 0.00495167\n",
      "epoch: 121  batch: 14  loss: 0.00538854\n",
      "epoch: 121  batch: 15  loss: 0.03814610\n",
      "epoch: 121  batch: 16  loss: 0.00442666\n",
      "epoch: 121  batch: 17  loss: 0.00514561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 121  batch: 18  loss: 0.00460192\n",
      "epoch: 121  batch: 19  loss: 0.00429834\n",
      "epoch: 121  batch: 20  loss: 0.00337144\n",
      "epoch: 121  batch: 21  loss: 0.00675612\n",
      "epoch: 121  batch: 22  loss: 0.00390243\n",
      "epoch: 121  batch: 23  loss: 0.00308335\n",
      "epoch: 121  batch: 24  loss: 0.00398126\n",
      "epoch: 121  batch: 25  loss: 0.00842862\n",
      "epoch: 121  batch: 26  loss: 0.00625966\n",
      "epoch: 121  batch: 27  loss: 0.00406267\n",
      "epoch: 121  batch: 28  loss: 0.00519278\n",
      "epoch: 122  batch: 1  loss: 0.00232296\n",
      "epoch: 122  batch: 2  loss: 0.00364715\n",
      "epoch: 122  batch: 3  loss: 0.00325110\n",
      "epoch: 122  batch: 4  loss: 0.00310315\n",
      "epoch: 122  batch: 5  loss: 0.00281167\n",
      "epoch: 122  batch: 6  loss: 0.00131193\n",
      "epoch: 122  batch: 7  loss: 0.00227107\n",
      "epoch: 122  batch: 8  loss: 0.01964162\n",
      "epoch: 122  batch: 9  loss: 0.00234713\n",
      "epoch: 122  batch: 10  loss: 0.00684764\n",
      "epoch: 122  batch: 11  loss: 0.00201492\n",
      "epoch: 122  batch: 12  loss: 0.00980014\n",
      "epoch: 122  batch: 13  loss: 0.00520404\n",
      "epoch: 122  batch: 14  loss: 0.02089509\n",
      "epoch: 122  batch: 15  loss: 0.00287832\n",
      "epoch: 122  batch: 16  loss: 0.00411638\n",
      "epoch: 122  batch: 17  loss: 0.01106303\n",
      "epoch: 122  batch: 18  loss: 0.00970794\n",
      "epoch: 122  batch: 19  loss: 0.01204507\n",
      "epoch: 122  batch: 20  loss: 0.00314415\n",
      "epoch: 122  batch: 21  loss: 0.00122177\n",
      "epoch: 122  batch: 22  loss: 0.00309001\n",
      "epoch: 122  batch: 23  loss: 0.00320769\n",
      "epoch: 122  batch: 24  loss: 0.00074991\n",
      "epoch: 122  batch: 25  loss: 0.00690711\n",
      "epoch: 122  batch: 26  loss: 0.00623780\n",
      "epoch: 122  batch: 27  loss: 0.02382943\n",
      "epoch: 122  batch: 28  loss: 0.00260167\n",
      "epoch: 123  batch: 1  loss: 0.00290996\n",
      "epoch: 123  batch: 2  loss: 0.00741595\n",
      "epoch: 123  batch: 3  loss: 0.00633292\n",
      "epoch: 123  batch: 4  loss: 0.00413440\n",
      "epoch: 123  batch: 5  loss: 0.00292363\n",
      "epoch: 123  batch: 6  loss: 0.00145377\n",
      "epoch: 123  batch: 7  loss: 0.00399126\n",
      "epoch: 123  batch: 8  loss: 0.00528708\n",
      "epoch: 123  batch: 9  loss: 0.00431626\n",
      "epoch: 123  batch: 10  loss: 0.01184383\n",
      "epoch: 123  batch: 11  loss: 0.00372787\n",
      "epoch: 123  batch: 12  loss: 0.02244314\n",
      "epoch: 123  batch: 13  loss: 0.00223916\n",
      "epoch: 123  batch: 14  loss: 0.00215009\n",
      "epoch: 123  batch: 15  loss: 0.00847803\n",
      "epoch: 123  batch: 16  loss: 0.00433129\n",
      "epoch: 123  batch: 17  loss: 0.00277409\n",
      "epoch: 123  batch: 18  loss: 0.01009561\n",
      "epoch: 123  batch: 19  loss: 0.00503663\n",
      "epoch: 123  batch: 20  loss: 0.00543510\n",
      "epoch: 123  batch: 21  loss: 0.00254072\n",
      "epoch: 123  batch: 22  loss: 0.01172594\n",
      "epoch: 123  batch: 23  loss: 0.00427697\n",
      "epoch: 123  batch: 24  loss: 0.01778915\n",
      "epoch: 123  batch: 25  loss: 0.00141417\n",
      "epoch: 123  batch: 26  loss: 0.00730849\n",
      "epoch: 123  batch: 27  loss: 0.00369914\n",
      "epoch: 123  batch: 28  loss: 0.00189684\n",
      "epoch: 124  batch: 1  loss: 0.00190913\n",
      "epoch: 124  batch: 2  loss: 0.00375813\n",
      "epoch: 124  batch: 3  loss: 0.00388392\n",
      "epoch: 124  batch: 4  loss: 0.00310848\n",
      "epoch: 124  batch: 5  loss: 0.01549419\n",
      "epoch: 124  batch: 6  loss: 0.00261170\n",
      "epoch: 124  batch: 7  loss: 0.00507868\n",
      "epoch: 124  batch: 8  loss: 0.00248635\n",
      "epoch: 124  batch: 9  loss: 0.00272941\n",
      "epoch: 124  batch: 10  loss: 0.00740494\n",
      "epoch: 124  batch: 11  loss: 0.00251428\n",
      "epoch: 124  batch: 12  loss: 0.00150017\n",
      "epoch: 124  batch: 13  loss: 0.00598086\n",
      "epoch: 124  batch: 14  loss: 0.00187783\n",
      "epoch: 124  batch: 15  loss: 0.00187308\n",
      "epoch: 124  batch: 16  loss: 0.00289292\n",
      "epoch: 124  batch: 17  loss: 0.00157044\n",
      "epoch: 124  batch: 18  loss: 0.00564827\n",
      "epoch: 124  batch: 19  loss: 0.00272764\n",
      "epoch: 124  batch: 20  loss: 0.00841213\n",
      "epoch: 124  batch: 21  loss: 0.00380681\n",
      "epoch: 124  batch: 22  loss: 0.00428569\n",
      "epoch: 124  batch: 23  loss: 0.01065346\n",
      "epoch: 124  batch: 24  loss: 0.02211476\n",
      "epoch: 124  batch: 25  loss: 0.00392631\n",
      "epoch: 124  batch: 26  loss: 0.00616073\n",
      "epoch: 124  batch: 27  loss: 0.01297633\n",
      "epoch: 124  batch: 28  loss: 0.00386730\n",
      "epoch: 125  batch: 1  loss: 0.00189536\n",
      "epoch: 125  batch: 2  loss: 0.00129932\n",
      "epoch: 125  batch: 3  loss: 0.00230627\n",
      "epoch: 125  batch: 4  loss: 0.00337797\n",
      "epoch: 125  batch: 5  loss: 0.00590449\n",
      "epoch: 125  batch: 6  loss: 0.00161861\n",
      "epoch: 125  batch: 7  loss: 0.01509547\n",
      "epoch: 125  batch: 8  loss: 0.00701451\n",
      "epoch: 125  batch: 9  loss: 0.00202467\n",
      "epoch: 125  batch: 10  loss: 0.00445825\n",
      "epoch: 125  batch: 11  loss: 0.01795550\n",
      "epoch: 125  batch: 12  loss: 0.00178775\n",
      "epoch: 125  batch: 13  loss: 0.01358691\n",
      "epoch: 125  batch: 14  loss: 0.00815814\n",
      "epoch: 125  batch: 15  loss: 0.00572393\n",
      "epoch: 125  batch: 16  loss: 0.00432931\n",
      "epoch: 125  batch: 17  loss: 0.00484981\n",
      "epoch: 125  batch: 18  loss: 0.00467762\n",
      "epoch: 125  batch: 19  loss: 0.00733501\n",
      "epoch: 125  batch: 20  loss: 0.00496992\n",
      "epoch: 125  batch: 21  loss: 0.00180626\n",
      "epoch: 125  batch: 22  loss: 0.00266563\n",
      "epoch: 125  batch: 23  loss: 0.00212050\n",
      "epoch: 125  batch: 24  loss: 0.01341725\n",
      "epoch: 125  batch: 25  loss: 0.01099397\n",
      "epoch: 125  batch: 26  loss: 0.00291987\n",
      "epoch: 125  batch: 27  loss: 0.00255513\n",
      "epoch: 125  batch: 28  loss: 0.00124867\n",
      "epoch: 126  batch: 1  loss: 0.00222661\n",
      "epoch: 126  batch: 2  loss: 0.00163719\n",
      "epoch: 126  batch: 3  loss: 0.00524901\n",
      "epoch: 126  batch: 4  loss: 0.00434439\n",
      "epoch: 126  batch: 5  loss: 0.00521259\n",
      "epoch: 126  batch: 6  loss: 0.00337035\n",
      "epoch: 126  batch: 7  loss: 0.00236771\n",
      "epoch: 126  batch: 8  loss: 0.00453289\n",
      "epoch: 126  batch: 9  loss: 0.00341086\n",
      "epoch: 126  batch: 10  loss: 0.00154193\n",
      "epoch: 126  batch: 11  loss: 0.00436486\n",
      "epoch: 126  batch: 12  loss: 0.00335297\n",
      "epoch: 126  batch: 13  loss: 0.00457274\n",
      "epoch: 126  batch: 14  loss: 0.04520813\n",
      "epoch: 126  batch: 15  loss: 0.00877249\n",
      "epoch: 126  batch: 16  loss: 0.01875193\n",
      "epoch: 126  batch: 17  loss: 0.00624895\n",
      "epoch: 126  batch: 18  loss: 0.00278554\n",
      "epoch: 126  batch: 19  loss: 0.00550055\n",
      "epoch: 126  batch: 20  loss: 0.00459571\n",
      "epoch: 126  batch: 21  loss: 0.00803213\n",
      "epoch: 126  batch: 22  loss: 0.00234990\n",
      "epoch: 126  batch: 23  loss: 0.00309150\n",
      "epoch: 126  batch: 24  loss: 0.00203547\n",
      "epoch: 126  batch: 25  loss: 0.01047237\n",
      "epoch: 126  batch: 26  loss: 0.00384205\n",
      "epoch: 126  batch: 27  loss: 0.00525317\n",
      "epoch: 126  batch: 28  loss: 0.00167720\n",
      "epoch: 127  batch: 1  loss: 0.00565688\n",
      "epoch: 127  batch: 2  loss: 0.00328202\n",
      "epoch: 127  batch: 3  loss: 0.00967686\n",
      "epoch: 127  batch: 4  loss: 0.00157960\n",
      "epoch: 127  batch: 5  loss: 0.00359596\n",
      "epoch: 127  batch: 6  loss: 0.02159609\n",
      "epoch: 127  batch: 7  loss: 0.00216458\n",
      "epoch: 127  batch: 8  loss: 0.00669121\n",
      "epoch: 127  batch: 9  loss: 0.00475634\n",
      "epoch: 127  batch: 10  loss: 0.01170226\n",
      "epoch: 127  batch: 11  loss: 0.00378288\n",
      "epoch: 127  batch: 12  loss: 0.00655705\n",
      "epoch: 127  batch: 13  loss: 0.00322743\n",
      "epoch: 127  batch: 14  loss: 0.00455576\n",
      "epoch: 127  batch: 15  loss: 0.00201922\n",
      "epoch: 127  batch: 16  loss: 0.00126483\n",
      "epoch: 127  batch: 17  loss: 0.00684879\n",
      "epoch: 127  batch: 18  loss: 0.00228800\n",
      "epoch: 127  batch: 19  loss: 0.00342668\n",
      "epoch: 127  batch: 20  loss: 0.00206337\n",
      "epoch: 127  batch: 21  loss: 0.00677453\n",
      "epoch: 127  batch: 22  loss: 0.00207748\n",
      "epoch: 127  batch: 23  loss: 0.00247644\n",
      "epoch: 127  batch: 24  loss: 0.00307226\n",
      "epoch: 127  batch: 25  loss: 0.00273013\n",
      "epoch: 127  batch: 26  loss: 0.00621255\n",
      "epoch: 127  batch: 27  loss: 0.00423957\n",
      "epoch: 127  batch: 28  loss: 0.00245705\n",
      "epoch: 128  batch: 1  loss: 0.00531494\n",
      "epoch: 128  batch: 2  loss: 0.00489560\n",
      "epoch: 128  batch: 3  loss: 0.00711780\n",
      "epoch: 128  batch: 4  loss: 0.00512215\n",
      "epoch: 128  batch: 5  loss: 0.00187679\n",
      "epoch: 128  batch: 6  loss: 0.00234421\n",
      "epoch: 128  batch: 7  loss: 0.02532196\n",
      "epoch: 128  batch: 8  loss: 0.00337051\n",
      "epoch: 128  batch: 9  loss: 0.00497343\n",
      "epoch: 128  batch: 10  loss: 0.00654300\n",
      "epoch: 128  batch: 11  loss: 0.00519678\n",
      "epoch: 128  batch: 12  loss: 0.00704268\n",
      "epoch: 128  batch: 13  loss: 0.00115976\n",
      "epoch: 128  batch: 14  loss: 0.00085048\n",
      "epoch: 128  batch: 15  loss: 0.00202076\n",
      "epoch: 128  batch: 16  loss: 0.00131195\n",
      "epoch: 128  batch: 17  loss: 0.00193278\n",
      "epoch: 128  batch: 18  loss: 0.00126189\n",
      "epoch: 128  batch: 19  loss: 0.00393943\n",
      "epoch: 128  batch: 20  loss: 0.00252491\n",
      "epoch: 128  batch: 21  loss: 0.01617275\n",
      "epoch: 128  batch: 22  loss: 0.00553223\n",
      "epoch: 128  batch: 23  loss: 0.00578632\n",
      "epoch: 128  batch: 24  loss: 0.00463925\n",
      "epoch: 128  batch: 25  loss: 0.00430282\n",
      "epoch: 128  batch: 26  loss: 0.00340743\n",
      "epoch: 128  batch: 27  loss: 0.02757730\n",
      "epoch: 128  batch: 28  loss: 0.00184087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 129  batch: 1  loss: 0.00343619\n",
      "epoch: 129  batch: 2  loss: 0.00535840\n",
      "epoch: 129  batch: 3  loss: 0.01687443\n",
      "epoch: 129  batch: 4  loss: 0.00285096\n",
      "epoch: 129  batch: 5  loss: 0.00265339\n",
      "epoch: 129  batch: 6  loss: 0.00111544\n",
      "epoch: 129  batch: 7  loss: 0.00168272\n",
      "epoch: 129  batch: 8  loss: 0.01712511\n",
      "epoch: 129  batch: 9  loss: 0.00237027\n",
      "epoch: 129  batch: 10  loss: 0.00363151\n",
      "epoch: 129  batch: 11  loss: 0.00249726\n",
      "epoch: 129  batch: 12  loss: 0.00379322\n",
      "epoch: 129  batch: 13  loss: 0.00331148\n",
      "epoch: 129  batch: 14  loss: 0.00633012\n",
      "epoch: 129  batch: 15  loss: 0.00633982\n",
      "epoch: 129  batch: 16  loss: 0.00161761\n",
      "epoch: 129  batch: 17  loss: 0.00817306\n",
      "epoch: 129  batch: 18  loss: 0.00332125\n",
      "epoch: 129  batch: 19  loss: 0.00154419\n",
      "epoch: 129  batch: 20  loss: 0.00152545\n",
      "epoch: 129  batch: 21  loss: 0.00646288\n",
      "epoch: 129  batch: 22  loss: 0.00288229\n",
      "epoch: 129  batch: 23  loss: 0.00524431\n",
      "epoch: 129  batch: 24  loss: 0.00356393\n",
      "epoch: 129  batch: 25  loss: 0.01581565\n",
      "epoch: 129  batch: 26  loss: 0.00640497\n",
      "epoch: 129  batch: 27  loss: 0.00135310\n",
      "epoch: 129  batch: 28  loss: 0.00160279\n",
      "epoch: 130  batch: 1  loss: 0.00158473\n",
      "epoch: 130  batch: 2  loss: 0.00205787\n",
      "epoch: 130  batch: 3  loss: 0.00422467\n",
      "epoch: 130  batch: 4  loss: 0.00534272\n",
      "epoch: 130  batch: 5  loss: 0.00161604\n",
      "epoch: 130  batch: 6  loss: 0.01190215\n",
      "epoch: 130  batch: 7  loss: 0.00652693\n",
      "epoch: 130  batch: 8  loss: 0.02314206\n",
      "epoch: 130  batch: 9  loss: 0.00246310\n",
      "epoch: 130  batch: 10  loss: 0.00543396\n",
      "epoch: 130  batch: 11  loss: 0.00386546\n",
      "epoch: 130  batch: 12  loss: 0.00238962\n",
      "epoch: 130  batch: 13  loss: 0.00439989\n",
      "epoch: 130  batch: 14  loss: 0.01576175\n",
      "epoch: 130  batch: 15  loss: 0.00547835\n",
      "epoch: 130  batch: 16  loss: 0.00491501\n",
      "epoch: 130  batch: 17  loss: 0.00362443\n",
      "epoch: 130  batch: 18  loss: 0.00346995\n",
      "epoch: 130  batch: 19  loss: 0.00384754\n",
      "epoch: 130  batch: 20  loss: 0.01263842\n",
      "epoch: 130  batch: 21  loss: 0.00307061\n",
      "epoch: 130  batch: 22  loss: 0.00154798\n",
      "epoch: 130  batch: 23  loss: 0.00191196\n",
      "epoch: 130  batch: 24  loss: 0.00324430\n",
      "epoch: 130  batch: 25  loss: 0.00291391\n",
      "epoch: 130  batch: 26  loss: 0.00574839\n",
      "epoch: 130  batch: 27  loss: 0.01182741\n",
      "epoch: 130  batch: 28  loss: 0.00226120\n",
      "epoch: 131  batch: 1  loss: 0.00492848\n",
      "epoch: 131  batch: 2  loss: 0.00206791\n",
      "epoch: 131  batch: 3  loss: 0.00731633\n",
      "epoch: 131  batch: 4  loss: 0.00451099\n",
      "epoch: 131  batch: 5  loss: 0.00352702\n",
      "epoch: 131  batch: 6  loss: 0.00299852\n",
      "epoch: 131  batch: 7  loss: 0.00084714\n",
      "epoch: 131  batch: 8  loss: 0.00729043\n",
      "epoch: 131  batch: 9  loss: 0.00189954\n",
      "epoch: 131  batch: 10  loss: 0.00346031\n",
      "epoch: 131  batch: 11  loss: 0.00570820\n",
      "epoch: 131  batch: 12  loss: 0.00578127\n",
      "epoch: 131  batch: 13  loss: 0.00162499\n",
      "epoch: 131  batch: 14  loss: 0.02187773\n",
      "epoch: 131  batch: 15  loss: 0.00811344\n",
      "epoch: 131  batch: 16  loss: 0.00059538\n",
      "epoch: 131  batch: 17  loss: 0.00463850\n",
      "epoch: 131  batch: 18  loss: 0.00664494\n",
      "epoch: 131  batch: 19  loss: 0.00256371\n",
      "epoch: 131  batch: 20  loss: 0.00353520\n",
      "epoch: 131  batch: 21  loss: 0.00213717\n",
      "epoch: 131  batch: 22  loss: 0.00707370\n",
      "epoch: 131  batch: 23  loss: 0.00518219\n",
      "epoch: 131  batch: 24  loss: 0.00268091\n",
      "epoch: 131  batch: 25  loss: 0.00417238\n",
      "epoch: 131  batch: 26  loss: 0.00538364\n",
      "epoch: 131  batch: 27  loss: 0.00461690\n",
      "epoch: 131  batch: 28  loss: 0.00102749\n",
      "epoch: 132  batch: 1  loss: 0.01071809\n",
      "epoch: 132  batch: 2  loss: 0.00305110\n",
      "epoch: 132  batch: 3  loss: 0.00360028\n",
      "epoch: 132  batch: 4  loss: 0.00148026\n",
      "epoch: 132  batch: 5  loss: 0.01001096\n",
      "epoch: 132  batch: 6  loss: 0.00125027\n",
      "epoch: 132  batch: 7  loss: 0.00295609\n",
      "epoch: 132  batch: 8  loss: 0.00292246\n",
      "epoch: 132  batch: 9  loss: 0.00254587\n",
      "epoch: 132  batch: 10  loss: 0.02721822\n",
      "epoch: 132  batch: 11  loss: 0.03642264\n",
      "epoch: 132  batch: 12  loss: 0.00464021\n",
      "epoch: 132  batch: 13  loss: 0.00436202\n",
      "epoch: 132  batch: 14  loss: 0.00481435\n",
      "epoch: 132  batch: 15  loss: 0.00605696\n",
      "epoch: 132  batch: 16  loss: 0.00608488\n",
      "epoch: 132  batch: 17  loss: 0.00155104\n",
      "epoch: 132  batch: 18  loss: 0.00600518\n",
      "epoch: 132  batch: 19  loss: 0.00393744\n",
      "epoch: 132  batch: 20  loss: 0.00319395\n",
      "epoch: 132  batch: 21  loss: 0.00554629\n",
      "epoch: 132  batch: 22  loss: 0.00830122\n",
      "epoch: 132  batch: 23  loss: 0.00176136\n",
      "epoch: 132  batch: 24  loss: 0.00060159\n",
      "epoch: 132  batch: 25  loss: 0.00214807\n",
      "epoch: 132  batch: 26  loss: 0.00710657\n",
      "epoch: 132  batch: 27  loss: 0.00127431\n",
      "epoch: 132  batch: 28  loss: 0.00306708\n",
      "epoch: 133  batch: 1  loss: 0.00409992\n",
      "epoch: 133  batch: 2  loss: 0.00569126\n",
      "epoch: 133  batch: 3  loss: 0.00262362\n",
      "epoch: 133  batch: 4  loss: 0.00799460\n",
      "epoch: 133  batch: 5  loss: 0.00326554\n",
      "epoch: 133  batch: 6  loss: 0.00252332\n",
      "epoch: 133  batch: 7  loss: 0.00259865\n",
      "epoch: 133  batch: 8  loss: 0.00318998\n",
      "epoch: 133  batch: 9  loss: 0.00402026\n",
      "epoch: 133  batch: 10  loss: 0.00581474\n",
      "epoch: 133  batch: 11  loss: 0.00541481\n",
      "epoch: 133  batch: 12  loss: 0.00493017\n",
      "epoch: 133  batch: 13  loss: 0.00254705\n",
      "epoch: 133  batch: 14  loss: 0.00727960\n",
      "epoch: 133  batch: 15  loss: 0.03086996\n",
      "epoch: 133  batch: 16  loss: 0.02221421\n",
      "epoch: 133  batch: 17  loss: 0.00856119\n",
      "epoch: 133  batch: 18  loss: 0.06097936\n",
      "epoch: 133  batch: 19  loss: 0.00654996\n",
      "epoch: 133  batch: 20  loss: 0.00221039\n",
      "epoch: 133  batch: 21  loss: 0.00234346\n",
      "epoch: 133  batch: 22  loss: 0.00556046\n",
      "epoch: 133  batch: 23  loss: 0.00132350\n",
      "epoch: 133  batch: 24  loss: 0.00222643\n",
      "epoch: 133  batch: 25  loss: 0.00469721\n",
      "epoch: 133  batch: 26  loss: 0.00791061\n",
      "epoch: 133  batch: 27  loss: 0.00833030\n",
      "epoch: 133  batch: 28  loss: 0.00283737\n",
      "epoch: 134  batch: 1  loss: 0.00594684\n",
      "epoch: 134  batch: 2  loss: 0.00284180\n",
      "epoch: 134  batch: 3  loss: 0.00465132\n",
      "epoch: 134  batch: 4  loss: 0.00646611\n",
      "epoch: 134  batch: 5  loss: 0.01361816\n",
      "epoch: 134  batch: 6  loss: 0.00204387\n",
      "epoch: 134  batch: 7  loss: 0.00340476\n",
      "epoch: 134  batch: 8  loss: 0.00581752\n",
      "epoch: 134  batch: 9  loss: 0.00313184\n",
      "epoch: 134  batch: 10  loss: 0.00397231\n",
      "epoch: 134  batch: 11  loss: 0.00459180\n",
      "epoch: 134  batch: 12  loss: 0.00178755\n",
      "epoch: 134  batch: 13  loss: 0.00643764\n",
      "epoch: 134  batch: 14  loss: 0.01408722\n",
      "epoch: 134  batch: 15  loss: 0.00136651\n",
      "epoch: 134  batch: 16  loss: 0.00268569\n",
      "epoch: 134  batch: 17  loss: 0.00429557\n",
      "epoch: 134  batch: 18  loss: 0.00348483\n",
      "epoch: 134  batch: 19  loss: 0.00277750\n",
      "epoch: 134  batch: 20  loss: 0.00456807\n",
      "epoch: 134  batch: 21  loss: 0.00211136\n",
      "epoch: 134  batch: 22  loss: 0.00298645\n",
      "epoch: 134  batch: 23  loss: 0.00135441\n",
      "epoch: 134  batch: 24  loss: 0.02377026\n",
      "epoch: 134  batch: 25  loss: 0.00467630\n",
      "epoch: 134  batch: 26  loss: 0.00424217\n",
      "epoch: 134  batch: 27  loss: 0.00625158\n",
      "epoch: 134  batch: 28  loss: 0.00698331\n",
      "epoch: 135  batch: 1  loss: 0.00285631\n",
      "epoch: 135  batch: 2  loss: 0.00137777\n",
      "epoch: 135  batch: 3  loss: 0.00621704\n",
      "epoch: 135  batch: 4  loss: 0.01319996\n",
      "epoch: 135  batch: 5  loss: 0.00187159\n",
      "epoch: 135  batch: 6  loss: 0.00242843\n",
      "epoch: 135  batch: 7  loss: 0.00441632\n",
      "epoch: 135  batch: 8  loss: 0.00435605\n",
      "epoch: 135  batch: 9  loss: 0.00297870\n",
      "epoch: 135  batch: 10  loss: 0.00483381\n",
      "epoch: 135  batch: 11  loss: 0.00127172\n",
      "epoch: 135  batch: 12  loss: 0.00278940\n",
      "epoch: 135  batch: 13  loss: 0.01100083\n",
      "epoch: 135  batch: 14  loss: 0.00367194\n",
      "epoch: 135  batch: 15  loss: 0.00661787\n",
      "epoch: 135  batch: 16  loss: 0.00238187\n",
      "epoch: 135  batch: 17  loss: 0.02675779\n",
      "epoch: 135  batch: 18  loss: 0.00705559\n",
      "epoch: 135  batch: 19  loss: 0.00162171\n",
      "epoch: 135  batch: 20  loss: 0.00491982\n",
      "epoch: 135  batch: 21  loss: 0.00679317\n",
      "epoch: 135  batch: 22  loss: 0.00432410\n",
      "epoch: 135  batch: 23  loss: 0.00461131\n",
      "epoch: 135  batch: 24  loss: 0.00303814\n",
      "epoch: 135  batch: 25  loss: 0.00419759\n",
      "epoch: 135  batch: 26  loss: 0.00287215\n",
      "epoch: 135  batch: 27  loss: 0.00523493\n",
      "epoch: 135  batch: 28  loss: 0.01097518\n",
      "epoch: 136  batch: 1  loss: 0.00144457\n",
      "epoch: 136  batch: 2  loss: 0.01718183\n",
      "epoch: 136  batch: 3  loss: 0.00082353\n",
      "epoch: 136  batch: 4  loss: 0.00094099\n",
      "epoch: 136  batch: 5  loss: 0.00178041\n",
      "epoch: 136  batch: 6  loss: 0.00184861\n",
      "epoch: 136  batch: 7  loss: 0.01666395\n",
      "epoch: 136  batch: 8  loss: 0.02198936\n",
      "epoch: 136  batch: 9  loss: 0.00775319\n",
      "epoch: 136  batch: 10  loss: 0.00093941\n",
      "epoch: 136  batch: 11  loss: 0.00135817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 136  batch: 12  loss: 0.00334623\n",
      "epoch: 136  batch: 13  loss: 0.00284733\n",
      "epoch: 136  batch: 14  loss: 0.00259497\n",
      "epoch: 136  batch: 15  loss: 0.00212701\n",
      "epoch: 136  batch: 16  loss: 0.00498746\n",
      "epoch: 136  batch: 17  loss: 0.01333829\n",
      "epoch: 136  batch: 18  loss: 0.00381670\n",
      "epoch: 136  batch: 19  loss: 0.00461509\n",
      "epoch: 136  batch: 20  loss: 0.00212902\n",
      "epoch: 136  batch: 21  loss: 0.00525870\n",
      "epoch: 136  batch: 22  loss: 0.00226432\n",
      "epoch: 136  batch: 23  loss: 0.00233431\n",
      "epoch: 136  batch: 24  loss: 0.00278073\n",
      "epoch: 136  batch: 25  loss: 0.00450077\n",
      "epoch: 136  batch: 26  loss: 0.00380504\n",
      "epoch: 136  batch: 27  loss: 0.00350356\n",
      "epoch: 136  batch: 28  loss: 0.00198718\n",
      "epoch: 137  batch: 1  loss: 0.00331358\n",
      "epoch: 137  batch: 2  loss: 0.00178232\n",
      "epoch: 137  batch: 3  loss: 0.00680232\n",
      "epoch: 137  batch: 4  loss: 0.00169383\n",
      "epoch: 137  batch: 5  loss: 0.00215490\n",
      "epoch: 137  batch: 6  loss: 0.00220461\n",
      "epoch: 137  batch: 7  loss: 0.02134942\n",
      "epoch: 137  batch: 8  loss: 0.00193842\n",
      "epoch: 137  batch: 9  loss: 0.00602092\n",
      "epoch: 137  batch: 10  loss: 0.01100220\n",
      "epoch: 137  batch: 11  loss: 0.00137930\n",
      "epoch: 137  batch: 12  loss: 0.00412294\n",
      "epoch: 137  batch: 13  loss: 0.00643737\n",
      "epoch: 137  batch: 14  loss: 0.01246864\n",
      "epoch: 137  batch: 15  loss: 0.00305182\n",
      "epoch: 137  batch: 16  loss: 0.00342150\n",
      "epoch: 137  batch: 17  loss: 0.00522139\n",
      "epoch: 137  batch: 18  loss: 0.00251281\n",
      "epoch: 137  batch: 19  loss: 0.00394981\n",
      "epoch: 137  batch: 20  loss: 0.00143080\n",
      "epoch: 137  batch: 21  loss: 0.00278865\n",
      "epoch: 137  batch: 22  loss: 0.00375187\n",
      "epoch: 137  batch: 23  loss: 0.01356080\n",
      "epoch: 137  batch: 24  loss: 0.00511169\n",
      "epoch: 137  batch: 25  loss: 0.00152553\n",
      "epoch: 137  batch: 26  loss: 0.00648858\n",
      "epoch: 137  batch: 27  loss: 0.00494452\n",
      "epoch: 137  batch: 28  loss: 0.00482127\n",
      "epoch: 138  batch: 1  loss: 0.00446891\n",
      "epoch: 138  batch: 2  loss: 0.00678752\n",
      "epoch: 138  batch: 3  loss: 0.00217448\n",
      "epoch: 138  batch: 4  loss: 0.00618387\n",
      "epoch: 138  batch: 5  loss: 0.00167916\n",
      "epoch: 138  batch: 6  loss: 0.00198158\n",
      "epoch: 138  batch: 7  loss: 0.00117534\n",
      "epoch: 138  batch: 8  loss: 0.00510582\n",
      "epoch: 138  batch: 9  loss: 0.00096154\n",
      "epoch: 138  batch: 10  loss: 0.00129471\n",
      "epoch: 138  batch: 11  loss: 0.00112432\n",
      "epoch: 138  batch: 12  loss: 0.00221859\n",
      "epoch: 138  batch: 13  loss: 0.01419396\n",
      "epoch: 138  batch: 14  loss: 0.01674341\n",
      "epoch: 138  batch: 15  loss: 0.00214445\n",
      "epoch: 138  batch: 16  loss: 0.00556764\n",
      "epoch: 138  batch: 17  loss: 0.00152035\n",
      "epoch: 138  batch: 18  loss: 0.00512098\n",
      "epoch: 138  batch: 19  loss: 0.00343517\n",
      "epoch: 138  batch: 20  loss: 0.00966108\n",
      "epoch: 138  batch: 21  loss: 0.00103439\n",
      "epoch: 138  batch: 22  loss: 0.00236520\n",
      "epoch: 138  batch: 23  loss: 0.00459402\n",
      "epoch: 138  batch: 24  loss: 0.00248732\n",
      "epoch: 138  batch: 25  loss: 0.00426496\n",
      "epoch: 138  batch: 26  loss: 0.00196368\n",
      "epoch: 138  batch: 27  loss: 0.00509955\n",
      "epoch: 138  batch: 28  loss: 0.00259205\n",
      "epoch: 139  batch: 1  loss: 0.00154471\n",
      "epoch: 139  batch: 2  loss: 0.00284728\n",
      "epoch: 139  batch: 3  loss: 0.00438588\n",
      "epoch: 139  batch: 4  loss: 0.00595217\n",
      "epoch: 139  batch: 5  loss: 0.00516414\n",
      "epoch: 139  batch: 6  loss: 0.00259253\n",
      "epoch: 139  batch: 7  loss: 0.00067431\n",
      "epoch: 139  batch: 8  loss: 0.00346741\n",
      "epoch: 139  batch: 9  loss: 0.00582009\n",
      "epoch: 139  batch: 10  loss: 0.00572151\n",
      "epoch: 139  batch: 11  loss: 0.00954045\n",
      "epoch: 139  batch: 12  loss: 0.00257866\n",
      "epoch: 139  batch: 13  loss: 0.01079561\n",
      "epoch: 139  batch: 14  loss: 0.00196805\n",
      "epoch: 139  batch: 15  loss: 0.00182150\n",
      "epoch: 139  batch: 16  loss: 0.00554732\n",
      "epoch: 139  batch: 17  loss: 0.00643396\n",
      "epoch: 139  batch: 18  loss: 0.00275929\n",
      "epoch: 139  batch: 19  loss: 0.01863398\n",
      "epoch: 139  batch: 20  loss: 0.00432503\n",
      "epoch: 139  batch: 21  loss: 0.00961193\n",
      "epoch: 139  batch: 22  loss: 0.00427187\n",
      "epoch: 139  batch: 23  loss: 0.00133654\n",
      "epoch: 139  batch: 24  loss: 0.00311218\n",
      "epoch: 139  batch: 25  loss: 0.00352595\n",
      "epoch: 139  batch: 26  loss: 0.00339371\n",
      "epoch: 139  batch: 27  loss: 0.00157547\n",
      "epoch: 139  batch: 28  loss: 0.00504354\n",
      "epoch: 140  batch: 1  loss: 0.00432075\n",
      "epoch: 140  batch: 2  loss: 0.00335698\n",
      "epoch: 140  batch: 3  loss: 0.00287310\n",
      "epoch: 140  batch: 4  loss: 0.00267879\n",
      "epoch: 140  batch: 5  loss: 0.01008161\n",
      "epoch: 140  batch: 6  loss: 0.00329890\n",
      "epoch: 140  batch: 7  loss: 0.00296086\n",
      "epoch: 140  batch: 8  loss: 0.00623363\n",
      "epoch: 140  batch: 9  loss: 0.00441046\n",
      "epoch: 140  batch: 10  loss: 0.00425577\n",
      "epoch: 140  batch: 11  loss: 0.00631067\n",
      "epoch: 140  batch: 12  loss: 0.00914026\n",
      "epoch: 140  batch: 13  loss: 0.00245858\n",
      "epoch: 140  batch: 14  loss: 0.00420659\n",
      "epoch: 140  batch: 15  loss: 0.00264068\n",
      "epoch: 140  batch: 16  loss: 0.00174277\n",
      "epoch: 140  batch: 17  loss: 0.00750495\n",
      "epoch: 140  batch: 18  loss: 0.00436002\n",
      "epoch: 140  batch: 19  loss: 0.00326306\n",
      "epoch: 140  batch: 20  loss: 0.00519099\n",
      "epoch: 140  batch: 21  loss: 0.02886438\n",
      "epoch: 140  batch: 22  loss: 0.00120607\n",
      "epoch: 140  batch: 23  loss: 0.01269002\n",
      "epoch: 140  batch: 24  loss: 0.00394976\n",
      "epoch: 140  batch: 25  loss: 0.00304147\n",
      "epoch: 140  batch: 26  loss: 0.00930215\n",
      "epoch: 140  batch: 27  loss: 0.00305834\n",
      "epoch: 140  batch: 28  loss: 0.00560026\n",
      "epoch: 141  batch: 1  loss: 0.00167929\n",
      "epoch: 141  batch: 2  loss: 0.00477174\n",
      "epoch: 141  batch: 3  loss: 0.00436032\n",
      "epoch: 141  batch: 4  loss: 0.00843091\n",
      "epoch: 141  batch: 5  loss: 0.00156884\n",
      "epoch: 141  batch: 6  loss: 0.00199523\n",
      "epoch: 141  batch: 7  loss: 0.01901229\n",
      "epoch: 141  batch: 8  loss: 0.00475517\n",
      "epoch: 141  batch: 9  loss: 0.00148885\n",
      "epoch: 141  batch: 10  loss: 0.00449446\n",
      "epoch: 141  batch: 11  loss: 0.00223974\n",
      "epoch: 141  batch: 12  loss: 0.00763615\n",
      "epoch: 141  batch: 13  loss: 0.00273646\n",
      "epoch: 141  batch: 14  loss: 0.00462918\n",
      "epoch: 141  batch: 15  loss: 0.00195530\n",
      "epoch: 141  batch: 16  loss: 0.00806562\n",
      "epoch: 141  batch: 17  loss: 0.00233777\n",
      "epoch: 141  batch: 18  loss: 0.00552950\n",
      "epoch: 141  batch: 19  loss: 0.00508302\n",
      "epoch: 141  batch: 20  loss: 0.00284756\n",
      "epoch: 141  batch: 21  loss: 0.00429542\n",
      "epoch: 141  batch: 22  loss: 0.00308251\n",
      "epoch: 141  batch: 23  loss: 0.01703263\n",
      "epoch: 141  batch: 24  loss: 0.00214955\n",
      "epoch: 141  batch: 25  loss: 0.00690532\n",
      "epoch: 141  batch: 26  loss: 0.00261455\n",
      "epoch: 141  batch: 27  loss: 0.08109763\n",
      "epoch: 141  batch: 28  loss: 0.00578187\n",
      "epoch: 142  batch: 1  loss: 0.00271917\n",
      "epoch: 142  batch: 2  loss: 0.00424977\n",
      "epoch: 142  batch: 3  loss: 0.00845319\n",
      "epoch: 142  batch: 4  loss: 0.00149114\n",
      "epoch: 142  batch: 5  loss: 0.01023934\n",
      "epoch: 142  batch: 6  loss: 0.00164595\n",
      "epoch: 142  batch: 7  loss: 0.02551991\n",
      "epoch: 142  batch: 8  loss: 0.00420078\n",
      "epoch: 142  batch: 9  loss: 0.00405745\n",
      "epoch: 142  batch: 10  loss: 0.00626213\n",
      "epoch: 142  batch: 11  loss: 0.00336366\n",
      "epoch: 142  batch: 12  loss: 0.00545103\n",
      "epoch: 142  batch: 13  loss: 0.00591831\n",
      "epoch: 142  batch: 14  loss: 0.00745718\n",
      "epoch: 142  batch: 15  loss: 0.00181648\n",
      "epoch: 142  batch: 16  loss: 0.00449151\n",
      "epoch: 142  batch: 17  loss: 0.00888766\n",
      "epoch: 142  batch: 18  loss: 0.00359712\n",
      "epoch: 142  batch: 19  loss: 0.00391188\n",
      "epoch: 142  batch: 20  loss: 0.01751294\n",
      "epoch: 142  batch: 21  loss: 0.00136922\n",
      "epoch: 142  batch: 22  loss: 0.00608843\n",
      "epoch: 142  batch: 23  loss: 0.00502560\n",
      "epoch: 142  batch: 24  loss: 0.00313725\n",
      "epoch: 142  batch: 25  loss: 0.00532401\n",
      "epoch: 142  batch: 26  loss: 0.00840940\n",
      "epoch: 142  batch: 27  loss: 0.00117348\n",
      "epoch: 142  batch: 28  loss: 0.00338016\n",
      "epoch: 143  batch: 1  loss: 0.00788692\n",
      "epoch: 143  batch: 2  loss: 0.00472108\n",
      "epoch: 143  batch: 3  loss: 0.00611652\n",
      "epoch: 143  batch: 4  loss: 0.00134925\n",
      "epoch: 143  batch: 5  loss: 0.00435620\n",
      "epoch: 143  batch: 6  loss: 0.00402153\n",
      "epoch: 143  batch: 7  loss: 0.00393175\n",
      "epoch: 143  batch: 8  loss: 0.00225374\n",
      "epoch: 143  batch: 9  loss: 0.00230462\n",
      "epoch: 143  batch: 10  loss: 0.00580349\n",
      "epoch: 143  batch: 11  loss: 0.00616820\n",
      "epoch: 143  batch: 12  loss: 0.00844318\n",
      "epoch: 143  batch: 13  loss: 0.00396412\n",
      "epoch: 143  batch: 14  loss: 0.02108631\n",
      "epoch: 143  batch: 15  loss: 0.02485359\n",
      "epoch: 143  batch: 16  loss: 0.00480333\n",
      "epoch: 143  batch: 17  loss: 0.00259594\n",
      "epoch: 143  batch: 18  loss: 0.00517214\n",
      "epoch: 143  batch: 19  loss: 0.00140890\n",
      "epoch: 143  batch: 20  loss: 0.00119378\n",
      "epoch: 143  batch: 21  loss: 0.00387728\n",
      "epoch: 143  batch: 22  loss: 0.00218945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 143  batch: 23  loss: 0.00284842\n",
      "epoch: 143  batch: 24  loss: 0.00429032\n",
      "epoch: 143  batch: 25  loss: 0.00276147\n",
      "epoch: 143  batch: 26  loss: 0.00405249\n",
      "epoch: 143  batch: 27  loss: 0.00775520\n",
      "epoch: 143  batch: 28  loss: 0.00536492\n",
      "epoch: 144  batch: 1  loss: 0.00156705\n",
      "epoch: 144  batch: 2  loss: 0.00251963\n",
      "epoch: 144  batch: 3  loss: 0.00062412\n",
      "epoch: 144  batch: 4  loss: 0.00380820\n",
      "epoch: 144  batch: 5  loss: 0.00281605\n",
      "epoch: 144  batch: 6  loss: 0.00944375\n",
      "epoch: 144  batch: 7  loss: 0.01798381\n",
      "epoch: 144  batch: 8  loss: 0.00133262\n",
      "epoch: 144  batch: 9  loss: 0.00185799\n",
      "epoch: 144  batch: 10  loss: 0.00235114\n",
      "epoch: 144  batch: 11  loss: 0.00606359\n",
      "epoch: 144  batch: 12  loss: 0.01220179\n",
      "epoch: 144  batch: 13  loss: 0.00114561\n",
      "epoch: 144  batch: 14  loss: 0.00234336\n",
      "epoch: 144  batch: 15  loss: 0.00536424\n",
      "epoch: 144  batch: 16  loss: 0.00735407\n",
      "epoch: 144  batch: 17  loss: 0.00806700\n",
      "epoch: 144  batch: 18  loss: 0.00643826\n",
      "epoch: 144  batch: 19  loss: 0.00209478\n",
      "epoch: 144  batch: 20  loss: 0.01059287\n",
      "epoch: 144  batch: 21  loss: 0.00190818\n",
      "epoch: 144  batch: 22  loss: 0.00125649\n",
      "epoch: 144  batch: 23  loss: 0.01284912\n",
      "epoch: 144  batch: 24  loss: 0.00616994\n",
      "epoch: 144  batch: 25  loss: 0.01054985\n",
      "epoch: 144  batch: 26  loss: 0.00084513\n",
      "epoch: 144  batch: 27  loss: 0.00280607\n",
      "epoch: 144  batch: 28  loss: 0.02670540\n",
      "epoch: 145  batch: 1  loss: 0.00396317\n",
      "epoch: 145  batch: 2  loss: 0.00138436\n",
      "epoch: 145  batch: 3  loss: 0.00154268\n",
      "epoch: 145  batch: 4  loss: 0.00323678\n",
      "epoch: 145  batch: 5  loss: 0.00543691\n",
      "epoch: 145  batch: 6  loss: 0.00893214\n",
      "epoch: 145  batch: 7  loss: 0.00302116\n",
      "epoch: 145  batch: 8  loss: 0.00406595\n",
      "epoch: 145  batch: 9  loss: 0.00620207\n",
      "epoch: 145  batch: 10  loss: 0.00160478\n",
      "epoch: 145  batch: 11  loss: 0.00300256\n",
      "epoch: 145  batch: 12  loss: 0.00248399\n",
      "epoch: 145  batch: 13  loss: 0.00715858\n",
      "epoch: 145  batch: 14  loss: 0.00193940\n",
      "epoch: 145  batch: 15  loss: 0.00266340\n",
      "epoch: 145  batch: 16  loss: 0.00483305\n",
      "epoch: 145  batch: 17  loss: 0.00133809\n",
      "epoch: 145  batch: 18  loss: 0.00249368\n",
      "epoch: 145  batch: 19  loss: 0.03055194\n",
      "epoch: 145  batch: 20  loss: 0.00468069\n",
      "epoch: 145  batch: 21  loss: 0.00124443\n",
      "epoch: 145  batch: 22  loss: 0.00146046\n",
      "epoch: 145  batch: 23  loss: 0.00140199\n",
      "epoch: 145  batch: 24  loss: 0.00662968\n",
      "epoch: 145  batch: 25  loss: 0.00176287\n",
      "epoch: 145  batch: 26  loss: 0.02171751\n",
      "epoch: 145  batch: 27  loss: 0.00644579\n",
      "epoch: 145  batch: 28  loss: 0.00485020\n",
      "epoch: 146  batch: 1  loss: 0.00462766\n",
      "epoch: 146  batch: 2  loss: 0.00794645\n",
      "epoch: 146  batch: 3  loss: 0.00244581\n",
      "epoch: 146  batch: 4  loss: 0.00457464\n",
      "epoch: 146  batch: 5  loss: 0.00587772\n",
      "epoch: 146  batch: 6  loss: 0.00707274\n",
      "epoch: 146  batch: 7  loss: 0.00539855\n",
      "epoch: 146  batch: 8  loss: 0.00507032\n",
      "epoch: 146  batch: 9  loss: 0.00521956\n",
      "epoch: 146  batch: 10  loss: 0.00971796\n",
      "epoch: 146  batch: 11  loss: 0.00228703\n",
      "epoch: 146  batch: 12  loss: 0.00605463\n",
      "epoch: 146  batch: 13  loss: 0.00399164\n",
      "epoch: 146  batch: 14  loss: 0.02328441\n",
      "epoch: 146  batch: 15  loss: 0.00839787\n",
      "epoch: 146  batch: 16  loss: 0.00552543\n",
      "epoch: 146  batch: 17  loss: 0.00611387\n",
      "epoch: 146  batch: 18  loss: 0.00618718\n",
      "epoch: 146  batch: 19  loss: 0.00098059\n",
      "epoch: 146  batch: 20  loss: 0.00251725\n",
      "epoch: 146  batch: 21  loss: 0.00365801\n",
      "epoch: 146  batch: 22  loss: 0.00281582\n",
      "epoch: 146  batch: 23  loss: 0.01094561\n",
      "epoch: 146  batch: 24  loss: 0.00424955\n",
      "epoch: 146  batch: 25  loss: 0.00602666\n",
      "epoch: 146  batch: 26  loss: 0.00433224\n",
      "epoch: 146  batch: 27  loss: 0.00801090\n",
      "epoch: 146  batch: 28  loss: 0.00088120\n",
      "epoch: 147  batch: 1  loss: 0.00072924\n",
      "epoch: 147  batch: 2  loss: 0.00566122\n",
      "epoch: 147  batch: 3  loss: 0.00624874\n",
      "epoch: 147  batch: 4  loss: 0.00859674\n",
      "epoch: 147  batch: 5  loss: 0.00174977\n",
      "epoch: 147  batch: 6  loss: 0.00261787\n",
      "epoch: 147  batch: 7  loss: 0.00586253\n",
      "epoch: 147  batch: 8  loss: 0.00448269\n",
      "epoch: 147  batch: 9  loss: 0.01027944\n",
      "epoch: 147  batch: 10  loss: 0.01216846\n",
      "epoch: 147  batch: 11  loss: 0.00160216\n",
      "epoch: 147  batch: 12  loss: 0.00693945\n",
      "epoch: 147  batch: 13  loss: 0.00076958\n",
      "epoch: 147  batch: 14  loss: 0.00244128\n",
      "epoch: 147  batch: 15  loss: 0.00273399\n",
      "epoch: 147  batch: 16  loss: 0.00258914\n",
      "epoch: 147  batch: 17  loss: 0.00779995\n",
      "epoch: 147  batch: 18  loss: 0.00455049\n",
      "epoch: 147  batch: 19  loss: 0.01700222\n",
      "epoch: 147  batch: 20  loss: 0.00242851\n",
      "epoch: 147  batch: 21  loss: 0.00713864\n",
      "epoch: 147  batch: 22  loss: 0.00384608\n",
      "epoch: 147  batch: 23  loss: 0.00224300\n",
      "epoch: 147  batch: 24  loss: 0.00290951\n",
      "epoch: 147  batch: 25  loss: 0.00311958\n",
      "epoch: 147  batch: 26  loss: 0.00431344\n",
      "epoch: 147  batch: 27  loss: 0.02713525\n",
      "epoch: 147  batch: 28  loss: 0.00364996\n",
      "epoch: 148  batch: 1  loss: 0.00444005\n",
      "epoch: 148  batch: 2  loss: 0.00534754\n",
      "epoch: 148  batch: 3  loss: 0.00438764\n",
      "epoch: 148  batch: 4  loss: 0.00986608\n",
      "epoch: 148  batch: 5  loss: 0.00599760\n",
      "epoch: 148  batch: 6  loss: 0.00194906\n",
      "epoch: 148  batch: 7  loss: 0.00287601\n",
      "epoch: 148  batch: 8  loss: 0.00158391\n",
      "epoch: 148  batch: 9  loss: 0.00176988\n",
      "epoch: 148  batch: 10  loss: 0.00294408\n",
      "epoch: 148  batch: 11  loss: 0.00319261\n",
      "epoch: 148  batch: 12  loss: 0.00153994\n",
      "epoch: 148  batch: 13  loss: 0.00100142\n",
      "epoch: 148  batch: 14  loss: 0.00377907\n",
      "epoch: 148  batch: 15  loss: 0.00475608\n",
      "epoch: 148  batch: 16  loss: 0.00247742\n",
      "epoch: 148  batch: 17  loss: 0.00395978\n",
      "epoch: 148  batch: 18  loss: 0.01553718\n",
      "epoch: 148  batch: 19  loss: 0.00133900\n",
      "epoch: 148  batch: 20  loss: 0.02161986\n",
      "epoch: 148  batch: 21  loss: 0.00643686\n",
      "epoch: 148  batch: 22  loss: 0.00550172\n",
      "epoch: 148  batch: 23  loss: 0.00186266\n",
      "epoch: 148  batch: 24  loss: 0.05244683\n",
      "epoch: 148  batch: 25  loss: 0.01741956\n",
      "epoch: 148  batch: 26  loss: 0.00697124\n",
      "epoch: 148  batch: 27  loss: 0.00461495\n",
      "epoch: 148  batch: 28  loss: 0.00256529\n",
      "epoch: 149  batch: 1  loss: 0.00366936\n",
      "epoch: 149  batch: 2  loss: 0.01067864\n",
      "epoch: 149  batch: 3  loss: 0.00694783\n",
      "epoch: 149  batch: 4  loss: 0.00353192\n",
      "epoch: 149  batch: 5  loss: 0.00630572\n",
      "epoch: 149  batch: 6  loss: 0.00155493\n",
      "epoch: 149  batch: 7  loss: 0.00798769\n",
      "epoch: 149  batch: 8  loss: 0.00207522\n",
      "epoch: 149  batch: 9  loss: 0.00126541\n",
      "epoch: 149  batch: 10  loss: 0.00241526\n",
      "epoch: 149  batch: 11  loss: 0.00552336\n",
      "epoch: 149  batch: 12  loss: 0.01648322\n",
      "epoch: 149  batch: 13  loss: 0.00367398\n",
      "epoch: 149  batch: 14  loss: 0.00387665\n",
      "epoch: 149  batch: 15  loss: 0.00410166\n",
      "epoch: 149  batch: 16  loss: 0.00559788\n",
      "epoch: 149  batch: 17  loss: 0.00386077\n",
      "epoch: 149  batch: 18  loss: 0.00708730\n",
      "epoch: 149  batch: 19  loss: 0.00616739\n",
      "epoch: 149  batch: 20  loss: 0.01007701\n",
      "epoch: 149  batch: 21  loss: 0.00638083\n",
      "epoch: 149  batch: 22  loss: 0.00702921\n",
      "epoch: 149  batch: 23  loss: 0.00186739\n",
      "epoch: 149  batch: 24  loss: 0.01001693\n",
      "epoch: 149  batch: 25  loss: 0.00224946\n",
      "epoch: 149  batch: 26  loss: 0.00160809\n",
      "epoch: 149  batch: 27  loss: 0.02872705\n",
      "epoch: 149  batch: 28  loss: 0.00160293\n",
      "epoch: 150  batch: 1  loss: 0.00387175\n",
      "epoch: 150  batch: 2  loss: 0.00562188\n",
      "epoch: 150  batch: 3  loss: 0.00606763\n",
      "epoch: 150  batch: 4  loss: 0.00216097\n",
      "epoch: 150  batch: 5  loss: 0.00292643\n",
      "epoch: 150  batch: 6  loss: 0.00150930\n",
      "epoch: 150  batch: 7  loss: 0.00146865\n",
      "epoch: 150  batch: 8  loss: 0.00176573\n",
      "epoch: 150  batch: 9  loss: 0.00161264\n",
      "epoch: 150  batch: 10  loss: 0.00312566\n",
      "epoch: 150  batch: 11  loss: 0.00351645\n",
      "epoch: 150  batch: 12  loss: 0.00518091\n",
      "epoch: 150  batch: 13  loss: 0.00260781\n",
      "epoch: 150  batch: 14  loss: 0.00300165\n",
      "epoch: 150  batch: 15  loss: 0.00319143\n",
      "epoch: 150  batch: 16  loss: 0.00206375\n",
      "epoch: 150  batch: 17  loss: 0.00353010\n",
      "epoch: 150  batch: 18  loss: 0.00697037\n",
      "epoch: 150  batch: 19  loss: 0.01483359\n",
      "epoch: 150  batch: 20  loss: 0.02488998\n",
      "epoch: 150  batch: 21  loss: 0.00146370\n",
      "epoch: 150  batch: 22  loss: 0.01504494\n",
      "epoch: 150  batch: 23  loss: 0.00605483\n",
      "epoch: 150  batch: 24  loss: 0.00220864\n",
      "epoch: 150  batch: 25  loss: 0.00265905\n",
      "epoch: 150  batch: 26  loss: 0.00779429\n",
      "epoch: 150  batch: 27  loss: 0.02004143\n",
      "epoch: 150  batch: 28  loss: 0.01540570\n",
      "epoch: 151  batch: 1  loss: 0.00452758\n",
      "epoch: 151  batch: 2  loss: 0.00229430\n",
      "epoch: 151  batch: 3  loss: 0.00212564\n",
      "epoch: 151  batch: 4  loss: 0.00202443\n",
      "epoch: 151  batch: 5  loss: 0.00321781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 151  batch: 6  loss: 0.00374786\n",
      "epoch: 151  batch: 7  loss: 0.00222573\n",
      "epoch: 151  batch: 8  loss: 0.00229754\n",
      "epoch: 151  batch: 9  loss: 0.00164711\n",
      "epoch: 151  batch: 10  loss: 0.00127863\n",
      "epoch: 151  batch: 11  loss: 0.00592621\n",
      "epoch: 151  batch: 12  loss: 0.00214311\n",
      "epoch: 151  batch: 13  loss: 0.00123432\n",
      "epoch: 151  batch: 14  loss: 0.00929856\n",
      "epoch: 151  batch: 15  loss: 0.00146576\n",
      "epoch: 151  batch: 16  loss: 0.00166697\n",
      "epoch: 151  batch: 17  loss: 0.00490740\n",
      "epoch: 151  batch: 18  loss: 0.00509938\n",
      "epoch: 151  batch: 19  loss: 0.00074131\n",
      "epoch: 151  batch: 20  loss: 0.00245778\n",
      "epoch: 151  batch: 21  loss: 0.00581743\n",
      "epoch: 151  batch: 22  loss: 0.00347978\n",
      "epoch: 151  batch: 23  loss: 0.00669208\n",
      "epoch: 151  batch: 24  loss: 0.00555242\n",
      "epoch: 151  batch: 25  loss: 0.01137585\n",
      "epoch: 151  batch: 26  loss: 0.00432497\n",
      "epoch: 151  batch: 27  loss: 0.01407775\n",
      "epoch: 151  batch: 28  loss: 0.00575106\n",
      "epoch: 152  batch: 1  loss: 0.00650188\n",
      "epoch: 152  batch: 2  loss: 0.00901834\n",
      "epoch: 152  batch: 3  loss: 0.00128144\n",
      "epoch: 152  batch: 4  loss: 0.00257967\n",
      "epoch: 152  batch: 5  loss: 0.00339817\n",
      "epoch: 152  batch: 6  loss: 0.01755284\n",
      "epoch: 152  batch: 7  loss: 0.00573203\n",
      "epoch: 152  batch: 8  loss: 0.00359560\n",
      "epoch: 152  batch: 9  loss: 0.00292046\n",
      "epoch: 152  batch: 10  loss: 0.00140683\n",
      "epoch: 152  batch: 11  loss: 0.00414887\n",
      "epoch: 152  batch: 12  loss: 0.00654963\n",
      "epoch: 152  batch: 13  loss: 0.00556964\n",
      "epoch: 152  batch: 14  loss: 0.00365366\n",
      "epoch: 152  batch: 15  loss: 0.00398977\n",
      "epoch: 152  batch: 16  loss: 0.00512054\n",
      "epoch: 152  batch: 17  loss: 0.00831068\n",
      "epoch: 152  batch: 18  loss: 0.00247820\n",
      "epoch: 152  batch: 19  loss: 0.00280083\n",
      "epoch: 152  batch: 20  loss: 0.02033161\n",
      "epoch: 152  batch: 21  loss: 0.00801062\n",
      "epoch: 152  batch: 22  loss: 0.00150158\n",
      "epoch: 152  batch: 23  loss: 0.00320755\n",
      "epoch: 152  batch: 24  loss: 0.00315072\n",
      "epoch: 152  batch: 25  loss: 0.00385082\n",
      "epoch: 152  batch: 26  loss: 0.00455523\n",
      "epoch: 152  batch: 27  loss: 0.00223740\n",
      "epoch: 152  batch: 28  loss: 0.00498819\n",
      "epoch: 153  batch: 1  loss: 0.00391017\n",
      "epoch: 153  batch: 2  loss: 0.00431771\n",
      "epoch: 153  batch: 3  loss: 0.00198076\n",
      "epoch: 153  batch: 4  loss: 0.00556573\n",
      "epoch: 153  batch: 5  loss: 0.00826678\n",
      "epoch: 153  batch: 6  loss: 0.00834531\n",
      "epoch: 153  batch: 7  loss: 0.00762156\n",
      "epoch: 153  batch: 8  loss: 0.00201994\n",
      "epoch: 153  batch: 9  loss: 0.00384796\n",
      "epoch: 153  batch: 10  loss: 0.01743563\n",
      "epoch: 153  batch: 11  loss: 0.00690432\n",
      "epoch: 153  batch: 12  loss: 0.00255277\n",
      "epoch: 153  batch: 13  loss: 0.00292920\n",
      "epoch: 153  batch: 14  loss: 0.00487909\n",
      "epoch: 153  batch: 15  loss: 0.00238928\n",
      "epoch: 153  batch: 16  loss: 0.00184708\n",
      "epoch: 153  batch: 17  loss: 0.00493508\n",
      "epoch: 153  batch: 18  loss: 0.00200203\n",
      "epoch: 153  batch: 19  loss: 0.00189579\n",
      "epoch: 153  batch: 20  loss: 0.00865522\n",
      "epoch: 153  batch: 21  loss: 0.00497254\n",
      "epoch: 153  batch: 22  loss: 0.00649945\n",
      "epoch: 153  batch: 23  loss: 0.00267852\n",
      "epoch: 153  batch: 24  loss: 0.00174788\n",
      "epoch: 153  batch: 25  loss: 0.00606408\n",
      "epoch: 153  batch: 26  loss: 0.00234201\n",
      "epoch: 153  batch: 27  loss: 0.02164142\n",
      "epoch: 153  batch: 28  loss: 0.00166437\n",
      "epoch: 154  batch: 1  loss: 0.00436001\n",
      "epoch: 154  batch: 2  loss: 0.00605818\n",
      "epoch: 154  batch: 3  loss: 0.00395722\n",
      "epoch: 154  batch: 4  loss: 0.00345413\n",
      "epoch: 154  batch: 5  loss: 0.00455103\n",
      "epoch: 154  batch: 6  loss: 0.00447678\n",
      "epoch: 154  batch: 7  loss: 0.00078737\n",
      "epoch: 154  batch: 8  loss: 0.00694690\n",
      "epoch: 154  batch: 9  loss: 0.00104834\n",
      "epoch: 154  batch: 10  loss: 0.00343134\n",
      "epoch: 154  batch: 11  loss: 0.00174989\n",
      "epoch: 154  batch: 12  loss: 0.00473679\n",
      "epoch: 154  batch: 13  loss: 0.01080855\n",
      "epoch: 154  batch: 14  loss: 0.00157535\n",
      "epoch: 154  batch: 15  loss: 0.02845091\n",
      "epoch: 154  batch: 16  loss: 0.00525312\n",
      "epoch: 154  batch: 17  loss: 0.00256141\n",
      "epoch: 154  batch: 18  loss: 0.00764172\n",
      "epoch: 154  batch: 19  loss: 0.00638016\n",
      "epoch: 154  batch: 20  loss: 0.01462566\n",
      "epoch: 154  batch: 21  loss: 0.00157439\n",
      "epoch: 154  batch: 22  loss: 0.00213655\n",
      "epoch: 154  batch: 23  loss: 0.00092028\n",
      "epoch: 154  batch: 24  loss: 0.00446368\n",
      "epoch: 154  batch: 25  loss: 0.00152623\n",
      "epoch: 154  batch: 26  loss: 0.00218259\n",
      "epoch: 154  batch: 27  loss: 0.00213721\n",
      "epoch: 154  batch: 28  loss: 0.00433039\n",
      "epoch: 155  batch: 1  loss: 0.00296670\n",
      "epoch: 155  batch: 2  loss: 0.00292327\n",
      "epoch: 155  batch: 3  loss: 0.00346552\n",
      "epoch: 155  batch: 4  loss: 0.00313389\n",
      "epoch: 155  batch: 5  loss: 0.00882086\n",
      "epoch: 155  batch: 6  loss: 0.00435691\n",
      "epoch: 155  batch: 7  loss: 0.00601280\n",
      "epoch: 155  batch: 8  loss: 0.00593171\n",
      "epoch: 155  batch: 9  loss: 0.00318184\n",
      "epoch: 155  batch: 10  loss: 0.00384985\n",
      "epoch: 155  batch: 11  loss: 0.00384030\n",
      "epoch: 155  batch: 12  loss: 0.00676311\n",
      "epoch: 155  batch: 13  loss: 0.00430689\n",
      "epoch: 155  batch: 14  loss: 0.00712184\n",
      "epoch: 155  batch: 15  loss: 0.00110675\n",
      "epoch: 155  batch: 16  loss: 0.00253333\n",
      "epoch: 155  batch: 17  loss: 0.00341392\n",
      "epoch: 155  batch: 18  loss: 0.00299926\n",
      "epoch: 155  batch: 19  loss: 0.02717795\n",
      "epoch: 155  batch: 20  loss: 0.00338104\n",
      "epoch: 155  batch: 21  loss: 0.02671041\n",
      "epoch: 155  batch: 22  loss: 0.00157036\n",
      "epoch: 155  batch: 23  loss: 0.00142251\n",
      "epoch: 155  batch: 24  loss: 0.01189124\n",
      "epoch: 155  batch: 25  loss: 0.00088902\n",
      "epoch: 155  batch: 26  loss: 0.00149182\n",
      "epoch: 155  batch: 27  loss: 0.00280888\n",
      "epoch: 155  batch: 28  loss: 0.00197635\n",
      "epoch: 156  batch: 1  loss: 0.01679962\n",
      "epoch: 156  batch: 2  loss: 0.01084781\n",
      "epoch: 156  batch: 3  loss: 0.00238371\n",
      "epoch: 156  batch: 4  loss: 0.00290967\n",
      "epoch: 156  batch: 5  loss: 0.00447135\n",
      "epoch: 156  batch: 6  loss: 0.00299622\n",
      "epoch: 156  batch: 7  loss: 0.00722214\n",
      "epoch: 156  batch: 8  loss: 0.00804225\n",
      "epoch: 156  batch: 9  loss: 0.01952333\n",
      "epoch: 156  batch: 10  loss: 0.00241623\n",
      "epoch: 156  batch: 11  loss: 0.00318014\n",
      "epoch: 156  batch: 12  loss: 0.02986777\n",
      "epoch: 156  batch: 13  loss: 0.00529109\n",
      "epoch: 156  batch: 14  loss: 0.00257357\n",
      "epoch: 156  batch: 15  loss: 0.00421096\n",
      "epoch: 156  batch: 16  loss: 0.00163400\n",
      "epoch: 156  batch: 17  loss: 0.00325659\n",
      "epoch: 156  batch: 18  loss: 0.00275145\n",
      "epoch: 156  batch: 19  loss: 0.00392266\n",
      "epoch: 156  batch: 20  loss: 0.00387630\n",
      "epoch: 156  batch: 21  loss: 0.00434767\n",
      "epoch: 156  batch: 22  loss: 0.00636325\n",
      "epoch: 156  batch: 23  loss: 0.00570300\n",
      "epoch: 156  batch: 24  loss: 0.00182560\n",
      "epoch: 156  batch: 25  loss: 0.00542870\n",
      "epoch: 156  batch: 26  loss: 0.00314258\n",
      "epoch: 156  batch: 27  loss: 0.00657161\n",
      "epoch: 156  batch: 28  loss: 0.00176803\n",
      "epoch: 157  batch: 1  loss: 0.00160830\n",
      "epoch: 157  batch: 2  loss: 0.00903518\n",
      "epoch: 157  batch: 3  loss: 0.00339072\n",
      "epoch: 157  batch: 4  loss: 0.00387711\n",
      "epoch: 157  batch: 5  loss: 0.00456149\n",
      "epoch: 157  batch: 6  loss: 0.00183966\n",
      "epoch: 157  batch: 7  loss: 0.00262100\n",
      "epoch: 157  batch: 8  loss: 0.01282092\n",
      "epoch: 157  batch: 9  loss: 0.00227147\n",
      "epoch: 157  batch: 10  loss: 0.00424442\n",
      "epoch: 157  batch: 11  loss: 0.00326297\n",
      "epoch: 157  batch: 12  loss: 0.00211424\n",
      "epoch: 157  batch: 13  loss: 0.00124966\n",
      "epoch: 157  batch: 14  loss: 0.00564714\n",
      "epoch: 157  batch: 15  loss: 0.00439428\n",
      "epoch: 157  batch: 16  loss: 0.00809534\n",
      "epoch: 157  batch: 17  loss: 0.00376813\n",
      "epoch: 157  batch: 18  loss: 0.00927166\n",
      "epoch: 157  batch: 19  loss: 0.00103409\n",
      "epoch: 157  batch: 20  loss: 0.00566780\n",
      "epoch: 157  batch: 21  loss: 0.01161999\n",
      "epoch: 157  batch: 22  loss: 0.00249805\n",
      "epoch: 157  batch: 23  loss: 0.00381398\n",
      "epoch: 157  batch: 24  loss: 0.00754209\n",
      "epoch: 157  batch: 25  loss: 0.00263975\n",
      "epoch: 157  batch: 26  loss: 0.00250203\n",
      "epoch: 157  batch: 27  loss: 0.02011894\n",
      "epoch: 157  batch: 28  loss: 0.00377099\n",
      "epoch: 158  batch: 1  loss: 0.00472605\n",
      "epoch: 158  batch: 2  loss: 0.00338411\n",
      "epoch: 158  batch: 3  loss: 0.03834167\n",
      "epoch: 158  batch: 4  loss: 0.00595040\n",
      "epoch: 158  batch: 5  loss: 0.00389287\n",
      "epoch: 158  batch: 6  loss: 0.00331468\n",
      "epoch: 158  batch: 7  loss: 0.00415331\n",
      "epoch: 158  batch: 8  loss: 0.00284295\n",
      "epoch: 158  batch: 9  loss: 0.00242104\n",
      "epoch: 158  batch: 10  loss: 0.01604318\n",
      "epoch: 158  batch: 11  loss: 0.00942934\n",
      "epoch: 158  batch: 12  loss: 0.00195895\n",
      "epoch: 158  batch: 13  loss: 0.00161099\n",
      "epoch: 158  batch: 14  loss: 0.00214810\n",
      "epoch: 158  batch: 15  loss: 0.00059928\n",
      "epoch: 158  batch: 16  loss: 0.00816660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 158  batch: 17  loss: 0.00207977\n",
      "epoch: 158  batch: 18  loss: 0.00775211\n",
      "epoch: 158  batch: 19  loss: 0.00621784\n",
      "epoch: 158  batch: 20  loss: 0.01056100\n",
      "epoch: 158  batch: 21  loss: 0.00244698\n",
      "epoch: 158  batch: 22  loss: 0.00318478\n",
      "epoch: 158  batch: 23  loss: 0.00392020\n",
      "epoch: 158  batch: 24  loss: 0.01710017\n",
      "epoch: 158  batch: 25  loss: 0.00366205\n",
      "epoch: 158  batch: 26  loss: 0.00275046\n",
      "epoch: 158  batch: 27  loss: 0.00465060\n",
      "epoch: 158  batch: 28  loss: 0.00882904\n",
      "epoch: 159  batch: 1  loss: 0.00567884\n",
      "epoch: 159  batch: 2  loss: 0.00435251\n",
      "epoch: 159  batch: 3  loss: 0.01993708\n",
      "epoch: 159  batch: 4  loss: 0.00506807\n",
      "epoch: 159  batch: 5  loss: 0.00387960\n",
      "epoch: 159  batch: 6  loss: 0.00128910\n",
      "epoch: 159  batch: 7  loss: 0.00094756\n",
      "epoch: 159  batch: 8  loss: 0.00101556\n",
      "epoch: 159  batch: 9  loss: 0.00405334\n",
      "epoch: 159  batch: 10  loss: 0.00522464\n",
      "epoch: 159  batch: 11  loss: 0.00189907\n",
      "epoch: 159  batch: 12  loss: 0.00133621\n",
      "epoch: 159  batch: 13  loss: 0.02112888\n",
      "epoch: 159  batch: 14  loss: 0.00315846\n",
      "epoch: 159  batch: 15  loss: 0.01248075\n",
      "epoch: 159  batch: 16  loss: 0.00920257\n",
      "epoch: 159  batch: 17  loss: 0.00302740\n",
      "epoch: 159  batch: 18  loss: 0.03238631\n",
      "epoch: 159  batch: 19  loss: 0.00172401\n",
      "epoch: 159  batch: 20  loss: 0.00337572\n",
      "epoch: 159  batch: 21  loss: 0.01877993\n",
      "epoch: 159  batch: 22  loss: 0.00759697\n",
      "epoch: 159  batch: 23  loss: 0.00262743\n",
      "epoch: 159  batch: 24  loss: 0.00224546\n",
      "epoch: 159  batch: 25  loss: 0.00525309\n",
      "epoch: 159  batch: 26  loss: 0.00453077\n",
      "epoch: 159  batch: 27  loss: 0.00870665\n",
      "epoch: 159  batch: 28  loss: 0.00800380\n",
      "epoch: 160  batch: 1  loss: 0.00216409\n",
      "epoch: 160  batch: 2  loss: 0.00263227\n",
      "epoch: 160  batch: 3  loss: 0.00441978\n",
      "epoch: 160  batch: 4  loss: 0.00313632\n",
      "epoch: 160  batch: 5  loss: 0.00164059\n",
      "epoch: 160  batch: 6  loss: 0.00406331\n",
      "epoch: 160  batch: 7  loss: 0.00516667\n",
      "epoch: 160  batch: 8  loss: 0.00512063\n",
      "epoch: 160  batch: 9  loss: 0.00939074\n",
      "epoch: 160  batch: 10  loss: 0.00404729\n",
      "epoch: 160  batch: 11  loss: 0.00423438\n",
      "epoch: 160  batch: 12  loss: 0.00560375\n",
      "epoch: 160  batch: 13  loss: 0.00400768\n",
      "epoch: 160  batch: 14  loss: 0.00227415\n",
      "epoch: 160  batch: 15  loss: 0.02493876\n",
      "epoch: 160  batch: 16  loss: 0.03158922\n",
      "epoch: 160  batch: 17  loss: 0.00236198\n",
      "epoch: 160  batch: 18  loss: 0.01194067\n",
      "epoch: 160  batch: 19  loss: 0.00557925\n",
      "epoch: 160  batch: 20  loss: 0.00225261\n",
      "epoch: 160  batch: 21  loss: 0.00216402\n",
      "epoch: 160  batch: 22  loss: 0.00330011\n",
      "epoch: 160  batch: 23  loss: 0.00635531\n",
      "epoch: 160  batch: 24  loss: 0.00121410\n",
      "epoch: 160  batch: 25  loss: 0.00683870\n",
      "epoch: 160  batch: 26  loss: 0.00155470\n",
      "epoch: 160  batch: 27  loss: 0.00758736\n",
      "epoch: 160  batch: 28  loss: 0.01919308\n",
      "epoch: 161  batch: 1  loss: 0.00172766\n",
      "epoch: 161  batch: 2  loss: 0.00185847\n",
      "epoch: 161  batch: 3  loss: 0.00126685\n",
      "epoch: 161  batch: 4  loss: 0.00589493\n",
      "epoch: 161  batch: 5  loss: 0.00804108\n",
      "epoch: 161  batch: 6  loss: 0.00464755\n",
      "epoch: 161  batch: 7  loss: 0.00589334\n",
      "epoch: 161  batch: 8  loss: 0.00295497\n",
      "epoch: 161  batch: 9  loss: 0.00329106\n",
      "epoch: 161  batch: 10  loss: 0.00252179\n",
      "epoch: 161  batch: 11  loss: 0.00209069\n",
      "epoch: 161  batch: 12  loss: 0.00334327\n",
      "epoch: 161  batch: 13  loss: 0.01658791\n",
      "epoch: 161  batch: 14  loss: 0.00428455\n",
      "epoch: 161  batch: 15  loss: 0.00288229\n",
      "epoch: 161  batch: 16  loss: 0.00693182\n",
      "epoch: 161  batch: 17  loss: 0.00838423\n",
      "epoch: 161  batch: 18  loss: 0.00824177\n",
      "epoch: 161  batch: 19  loss: 0.00874515\n",
      "epoch: 161  batch: 20  loss: 0.01008130\n",
      "epoch: 161  batch: 21  loss: 0.00491137\n",
      "epoch: 161  batch: 22  loss: 0.00228020\n",
      "epoch: 161  batch: 23  loss: 0.00374644\n",
      "epoch: 161  batch: 24  loss: 0.00602150\n",
      "epoch: 161  batch: 25  loss: 0.01745843\n",
      "epoch: 161  batch: 26  loss: 0.00290292\n",
      "epoch: 161  batch: 27  loss: 0.00550046\n",
      "epoch: 161  batch: 28  loss: 0.00399484\n",
      "epoch: 162  batch: 1  loss: 0.00520105\n",
      "epoch: 162  batch: 2  loss: 0.00351528\n",
      "epoch: 162  batch: 3  loss: 0.00466770\n",
      "epoch: 162  batch: 4  loss: 0.01731118\n",
      "epoch: 162  batch: 5  loss: 0.00126014\n",
      "epoch: 162  batch: 6  loss: 0.00437720\n",
      "epoch: 162  batch: 7  loss: 0.00291353\n",
      "epoch: 162  batch: 8  loss: 0.00301480\n",
      "epoch: 162  batch: 9  loss: 0.00186459\n",
      "epoch: 162  batch: 10  loss: 0.00635220\n",
      "epoch: 162  batch: 11  loss: 0.00138647\n",
      "epoch: 162  batch: 12  loss: 0.00516912\n",
      "epoch: 162  batch: 13  loss: 0.00570084\n",
      "epoch: 162  batch: 14  loss: 0.01627231\n",
      "epoch: 162  batch: 15  loss: 0.00247909\n",
      "epoch: 162  batch: 16  loss: 0.00230684\n",
      "epoch: 162  batch: 17  loss: 0.00550759\n",
      "epoch: 162  batch: 18  loss: 0.00692600\n",
      "epoch: 162  batch: 19  loss: 0.00660275\n",
      "epoch: 162  batch: 20  loss: 0.00531072\n",
      "epoch: 162  batch: 21  loss: 0.00163289\n",
      "epoch: 162  batch: 22  loss: 0.00312914\n",
      "epoch: 162  batch: 23  loss: 0.01469795\n",
      "epoch: 162  batch: 24  loss: 0.00243793\n",
      "epoch: 162  batch: 25  loss: 0.00656260\n",
      "epoch: 162  batch: 26  loss: 0.00264756\n",
      "epoch: 162  batch: 27  loss: 0.00352190\n",
      "epoch: 162  batch: 28  loss: 0.00167438\n",
      "epoch: 163  batch: 1  loss: 0.00555712\n",
      "epoch: 163  batch: 2  loss: 0.00431018\n",
      "epoch: 163  batch: 3  loss: 0.00369334\n",
      "epoch: 163  batch: 4  loss: 0.00511113\n",
      "epoch: 163  batch: 5  loss: 0.02164502\n",
      "epoch: 163  batch: 6  loss: 0.00360737\n",
      "epoch: 163  batch: 7  loss: 0.00273072\n",
      "epoch: 163  batch: 8  loss: 0.00160685\n",
      "epoch: 163  batch: 9  loss: 0.00251476\n",
      "epoch: 163  batch: 10  loss: 0.03350931\n",
      "epoch: 163  batch: 11  loss: 0.00144544\n",
      "epoch: 163  batch: 12  loss: 0.00477212\n",
      "epoch: 163  batch: 13  loss: 0.00547957\n",
      "epoch: 163  batch: 14  loss: 0.00353399\n",
      "epoch: 163  batch: 15  loss: 0.00479994\n",
      "epoch: 163  batch: 16  loss: 0.00184889\n",
      "epoch: 163  batch: 17  loss: 0.00255318\n",
      "epoch: 163  batch: 18  loss: 0.00464354\n",
      "epoch: 163  batch: 19  loss: 0.00870662\n",
      "epoch: 163  batch: 20  loss: 0.01188634\n",
      "epoch: 163  batch: 21  loss: 0.00321471\n",
      "epoch: 163  batch: 22  loss: 0.00256703\n",
      "epoch: 163  batch: 23  loss: 0.00710904\n",
      "epoch: 163  batch: 24  loss: 0.00159165\n",
      "epoch: 163  batch: 25  loss: 0.00540934\n",
      "epoch: 163  batch: 26  loss: 0.00245730\n",
      "epoch: 163  batch: 27  loss: 0.00344259\n",
      "epoch: 163  batch: 28  loss: 0.00953654\n",
      "epoch: 164  batch: 1  loss: 0.00449313\n",
      "epoch: 164  batch: 2  loss: 0.00786833\n",
      "epoch: 164  batch: 3  loss: 0.00220715\n",
      "epoch: 164  batch: 4  loss: 0.00372166\n",
      "epoch: 164  batch: 5  loss: 0.00098301\n",
      "epoch: 164  batch: 6  loss: 0.00306024\n",
      "epoch: 164  batch: 7  loss: 0.00207485\n",
      "epoch: 164  batch: 8  loss: 0.00267878\n",
      "epoch: 164  batch: 9  loss: 0.00311787\n",
      "epoch: 164  batch: 10  loss: 0.00181577\n",
      "epoch: 164  batch: 11  loss: 0.00259754\n",
      "epoch: 164  batch: 12  loss: 0.00733753\n",
      "epoch: 164  batch: 13  loss: 0.00483419\n",
      "epoch: 164  batch: 14  loss: 0.00393040\n",
      "epoch: 164  batch: 15  loss: 0.00535044\n",
      "epoch: 164  batch: 16  loss: 0.00569526\n",
      "epoch: 164  batch: 17  loss: 0.01349982\n",
      "epoch: 164  batch: 18  loss: 0.00522929\n",
      "epoch: 164  batch: 19  loss: 0.02555988\n",
      "epoch: 164  batch: 20  loss: 0.00135764\n",
      "epoch: 164  batch: 21  loss: 0.00198009\n",
      "epoch: 164  batch: 22  loss: 0.00436657\n",
      "epoch: 164  batch: 23  loss: 0.00466621\n",
      "epoch: 164  batch: 24  loss: 0.00841487\n",
      "epoch: 164  batch: 25  loss: 0.00256528\n",
      "epoch: 164  batch: 26  loss: 0.00181042\n",
      "epoch: 164  batch: 27  loss: 0.00296676\n",
      "epoch: 164  batch: 28  loss: 0.00214683\n",
      "epoch: 165  batch: 1  loss: 0.00355027\n",
      "epoch: 165  batch: 2  loss: 0.00369595\n",
      "epoch: 165  batch: 3  loss: 0.00116895\n",
      "epoch: 165  batch: 4  loss: 0.02169201\n",
      "epoch: 165  batch: 5  loss: 0.00259391\n",
      "epoch: 165  batch: 6  loss: 0.02060156\n",
      "epoch: 165  batch: 7  loss: 0.00294304\n",
      "epoch: 165  batch: 8  loss: 0.00480225\n",
      "epoch: 165  batch: 9  loss: 0.00349564\n",
      "epoch: 165  batch: 10  loss: 0.00249655\n",
      "epoch: 165  batch: 11  loss: 0.00412908\n",
      "epoch: 165  batch: 12  loss: 0.00488684\n",
      "epoch: 165  batch: 13  loss: 0.00091417\n",
      "epoch: 165  batch: 14  loss: 0.00813126\n",
      "epoch: 165  batch: 15  loss: 0.00975700\n",
      "epoch: 165  batch: 16  loss: 0.00306930\n",
      "epoch: 165  batch: 17  loss: 0.00421041\n",
      "epoch: 165  batch: 18  loss: 0.00286809\n",
      "epoch: 165  batch: 19  loss: 0.00148401\n",
      "epoch: 165  batch: 20  loss: 0.00618144\n",
      "epoch: 165  batch: 21  loss: 0.01416212\n",
      "epoch: 165  batch: 22  loss: 0.00572551\n",
      "epoch: 165  batch: 23  loss: 0.00144891\n",
      "epoch: 165  batch: 24  loss: 0.00237830\n",
      "epoch: 165  batch: 25  loss: 0.00346942\n",
      "epoch: 165  batch: 26  loss: 0.00401642\n",
      "epoch: 165  batch: 27  loss: 0.00635505\n",
      "epoch: 165  batch: 28  loss: 0.00307752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166  batch: 1  loss: 0.00103051\n",
      "epoch: 166  batch: 2  loss: 0.00157034\n",
      "epoch: 166  batch: 3  loss: 0.00309841\n",
      "epoch: 166  batch: 4  loss: 0.00155655\n",
      "epoch: 166  batch: 5  loss: 0.00296015\n",
      "epoch: 166  batch: 6  loss: 0.00353720\n",
      "epoch: 166  batch: 7  loss: 0.00115784\n",
      "epoch: 166  batch: 8  loss: 0.00200631\n",
      "epoch: 166  batch: 9  loss: 0.01832648\n",
      "epoch: 166  batch: 10  loss: 0.00695322\n",
      "epoch: 166  batch: 11  loss: 0.01454894\n",
      "epoch: 166  batch: 12  loss: 0.00356486\n",
      "epoch: 166  batch: 13  loss: 0.00222739\n",
      "epoch: 166  batch: 14  loss: 0.00255991\n",
      "epoch: 166  batch: 15  loss: 0.00212681\n",
      "epoch: 166  batch: 16  loss: 0.00368794\n",
      "epoch: 166  batch: 17  loss: 0.00601977\n",
      "epoch: 166  batch: 18  loss: 0.00530006\n",
      "epoch: 166  batch: 19  loss: 0.00280116\n",
      "epoch: 166  batch: 20  loss: 0.00323224\n",
      "epoch: 166  batch: 21  loss: 0.00265100\n",
      "epoch: 166  batch: 22  loss: 0.00553639\n",
      "epoch: 166  batch: 23  loss: 0.00300054\n",
      "epoch: 166  batch: 24  loss: 0.00510846\n",
      "epoch: 166  batch: 25  loss: 0.00333284\n",
      "epoch: 166  batch: 26  loss: 0.00669873\n",
      "epoch: 166  batch: 27  loss: 0.00267595\n",
      "epoch: 166  batch: 28  loss: 0.00700894\n",
      "epoch: 167  batch: 1  loss: 0.00415833\n",
      "epoch: 167  batch: 2  loss: 0.01142133\n",
      "epoch: 167  batch: 3  loss: 0.00407781\n",
      "epoch: 167  batch: 4  loss: 0.00298659\n",
      "epoch: 167  batch: 5  loss: 0.00725258\n",
      "epoch: 167  batch: 6  loss: 0.00363602\n",
      "epoch: 167  batch: 7  loss: 0.00470216\n",
      "epoch: 167  batch: 8  loss: 0.00183222\n",
      "epoch: 167  batch: 9  loss: 0.00708619\n",
      "epoch: 167  batch: 10  loss: 0.00328336\n",
      "epoch: 167  batch: 11  loss: 0.00243077\n",
      "epoch: 167  batch: 12  loss: 0.00231106\n",
      "epoch: 167  batch: 13  loss: 0.00949553\n",
      "epoch: 167  batch: 14  loss: 0.00220247\n",
      "epoch: 167  batch: 15  loss: 0.00326948\n",
      "epoch: 167  batch: 16  loss: 0.00491137\n",
      "epoch: 167  batch: 17  loss: 0.00130322\n",
      "epoch: 167  batch: 18  loss: 0.00132368\n",
      "epoch: 167  batch: 19  loss: 0.00500875\n",
      "epoch: 167  batch: 20  loss: 0.00490703\n",
      "epoch: 167  batch: 21  loss: 0.00213127\n",
      "epoch: 167  batch: 22  loss: 0.00229291\n",
      "epoch: 167  batch: 23  loss: 0.00127294\n",
      "epoch: 167  batch: 24  loss: 0.00076601\n",
      "epoch: 167  batch: 25  loss: 0.02201167\n",
      "epoch: 167  batch: 26  loss: 0.00173597\n",
      "epoch: 167  batch: 27  loss: 0.00111648\n",
      "epoch: 167  batch: 28  loss: 0.00670593\n",
      "epoch: 168  batch: 1  loss: 0.00389461\n",
      "epoch: 168  batch: 2  loss: 0.00168801\n",
      "epoch: 168  batch: 3  loss: 0.00380118\n",
      "epoch: 168  batch: 4  loss: 0.00513771\n",
      "epoch: 168  batch: 5  loss: 0.00229244\n",
      "epoch: 168  batch: 6  loss: 0.00475477\n",
      "epoch: 168  batch: 7  loss: 0.00674229\n",
      "epoch: 168  batch: 8  loss: 0.01504683\n",
      "epoch: 168  batch: 9  loss: 0.00145330\n",
      "epoch: 168  batch: 10  loss: 0.02110765\n",
      "epoch: 168  batch: 11  loss: 0.00458374\n",
      "epoch: 168  batch: 12  loss: 0.00374700\n",
      "epoch: 168  batch: 13  loss: 0.00373159\n",
      "epoch: 168  batch: 14  loss: 0.00467694\n",
      "epoch: 168  batch: 15  loss: 0.00444613\n",
      "epoch: 168  batch: 16  loss: 0.00264930\n",
      "epoch: 168  batch: 17  loss: 0.00940591\n",
      "epoch: 168  batch: 18  loss: 0.00224844\n",
      "epoch: 168  batch: 19  loss: 0.00228722\n",
      "epoch: 168  batch: 20  loss: 0.00138364\n",
      "epoch: 168  batch: 21  loss: 0.01100050\n",
      "epoch: 168  batch: 22  loss: 0.00752117\n",
      "epoch: 168  batch: 23  loss: 0.00791220\n",
      "epoch: 168  batch: 24  loss: 0.00354215\n",
      "epoch: 168  batch: 25  loss: 0.00228792\n",
      "epoch: 168  batch: 26  loss: 0.00219677\n",
      "epoch: 168  batch: 27  loss: 0.00240822\n",
      "epoch: 168  batch: 28  loss: 0.00233539\n",
      "epoch: 169  batch: 1  loss: 0.00135702\n",
      "epoch: 169  batch: 2  loss: 0.00343638\n",
      "epoch: 169  batch: 3  loss: 0.01317149\n",
      "epoch: 169  batch: 4  loss: 0.00477151\n",
      "epoch: 169  batch: 5  loss: 0.00562876\n",
      "epoch: 169  batch: 6  loss: 0.00259215\n",
      "epoch: 169  batch: 7  loss: 0.00245610\n",
      "epoch: 169  batch: 8  loss: 0.01296733\n",
      "epoch: 169  batch: 9  loss: 0.00345626\n",
      "epoch: 169  batch: 10  loss: 0.00209092\n",
      "epoch: 169  batch: 11  loss: 0.01315441\n",
      "epoch: 169  batch: 12  loss: 0.00265337\n",
      "epoch: 169  batch: 13  loss: 0.00354429\n",
      "epoch: 169  batch: 14  loss: 0.00759335\n",
      "epoch: 169  batch: 15  loss: 0.00350331\n",
      "epoch: 169  batch: 16  loss: 0.00540683\n",
      "epoch: 169  batch: 17  loss: 0.00509212\n",
      "epoch: 169  batch: 18  loss: 0.00510238\n",
      "epoch: 169  batch: 19  loss: 0.00771236\n",
      "epoch: 169  batch: 20  loss: 0.02848630\n",
      "epoch: 169  batch: 21  loss: 0.00375402\n",
      "epoch: 169  batch: 22  loss: 0.00456296\n",
      "epoch: 169  batch: 23  loss: 0.00154970\n",
      "epoch: 169  batch: 24  loss: 0.00199468\n",
      "epoch: 169  batch: 25  loss: 0.00402766\n",
      "epoch: 169  batch: 26  loss: 0.00406058\n",
      "epoch: 169  batch: 27  loss: 0.00238977\n",
      "epoch: 169  batch: 28  loss: 0.00340431\n",
      "epoch: 170  batch: 1  loss: 0.00168715\n",
      "epoch: 170  batch: 2  loss: 0.00318246\n",
      "epoch: 170  batch: 3  loss: 0.00257648\n",
      "epoch: 170  batch: 4  loss: 0.01255742\n",
      "epoch: 170  batch: 5  loss: 0.00270536\n",
      "epoch: 170  batch: 6  loss: 0.00381871\n",
      "epoch: 170  batch: 7  loss: 0.00251795\n",
      "epoch: 170  batch: 8  loss: 0.00456982\n",
      "epoch: 170  batch: 9  loss: 0.01117202\n",
      "epoch: 170  batch: 10  loss: 0.00373473\n",
      "epoch: 170  batch: 11  loss: 0.00745010\n",
      "epoch: 170  batch: 12  loss: 0.00145352\n",
      "epoch: 170  batch: 13  loss: 0.00497433\n",
      "epoch: 170  batch: 14  loss: 0.00538348\n",
      "epoch: 170  batch: 15  loss: 0.00324228\n",
      "epoch: 170  batch: 16  loss: 0.00580555\n",
      "epoch: 170  batch: 17  loss: 0.00371165\n",
      "epoch: 170  batch: 18  loss: 0.00461701\n",
      "epoch: 170  batch: 19  loss: 0.00258601\n",
      "epoch: 170  batch: 20  loss: 0.00286480\n",
      "epoch: 170  batch: 21  loss: 0.01609881\n",
      "epoch: 170  batch: 22  loss: 0.02414787\n",
      "epoch: 170  batch: 23  loss: 0.00292568\n",
      "epoch: 170  batch: 24  loss: 0.00314209\n",
      "epoch: 170  batch: 25  loss: 0.00229804\n",
      "epoch: 170  batch: 26  loss: 0.00125114\n",
      "epoch: 170  batch: 27  loss: 0.00366498\n",
      "epoch: 170  batch: 28  loss: 0.00310807\n",
      "epoch: 171  batch: 1  loss: 0.00629362\n",
      "epoch: 171  batch: 2  loss: 0.00390190\n",
      "epoch: 171  batch: 3  loss: 0.00860551\n",
      "epoch: 171  batch: 4  loss: 0.00320156\n",
      "epoch: 171  batch: 5  loss: 0.00322090\n",
      "epoch: 171  batch: 6  loss: 0.00455905\n",
      "epoch: 171  batch: 7  loss: 0.00069737\n",
      "epoch: 171  batch: 8  loss: 0.02992246\n",
      "epoch: 171  batch: 9  loss: 0.00429122\n",
      "epoch: 171  batch: 10  loss: 0.00227633\n",
      "epoch: 171  batch: 11  loss: 0.01163167\n",
      "epoch: 171  batch: 12  loss: 0.00211123\n",
      "epoch: 171  batch: 13  loss: 0.00090324\n",
      "epoch: 171  batch: 14  loss: 0.00232447\n",
      "epoch: 171  batch: 15  loss: 0.00344087\n",
      "epoch: 171  batch: 16  loss: 0.00349875\n",
      "epoch: 171  batch: 17  loss: 0.00226479\n",
      "epoch: 171  batch: 18  loss: 0.00319434\n",
      "epoch: 171  batch: 19  loss: 0.00779480\n",
      "epoch: 171  batch: 20  loss: 0.00349778\n",
      "epoch: 171  batch: 21  loss: 0.00186198\n",
      "epoch: 171  batch: 22  loss: 0.00258011\n",
      "epoch: 171  batch: 23  loss: 0.00388750\n",
      "epoch: 171  batch: 24  loss: 0.00471797\n",
      "epoch: 171  batch: 25  loss: 0.00641760\n",
      "epoch: 171  batch: 26  loss: 0.00711346\n",
      "epoch: 171  batch: 27  loss: 0.00197263\n",
      "epoch: 171  batch: 28  loss: 0.01131063\n",
      "epoch: 172  batch: 1  loss: 0.01031922\n",
      "epoch: 172  batch: 2  loss: 0.00356957\n",
      "epoch: 172  batch: 3  loss: 0.00567526\n",
      "epoch: 172  batch: 4  loss: 0.00255382\n",
      "epoch: 172  batch: 5  loss: 0.00159038\n",
      "epoch: 172  batch: 6  loss: 0.00659889\n",
      "epoch: 172  batch: 7  loss: 0.02190194\n",
      "epoch: 172  batch: 8  loss: 0.00308500\n",
      "epoch: 172  batch: 9  loss: 0.00356979\n",
      "epoch: 172  batch: 10  loss: 0.00281539\n",
      "epoch: 172  batch: 11  loss: 0.00829746\n",
      "epoch: 172  batch: 12  loss: 0.00215695\n",
      "epoch: 172  batch: 13  loss: 0.00490397\n",
      "epoch: 172  batch: 14  loss: 0.00814303\n",
      "epoch: 172  batch: 15  loss: 0.00213344\n",
      "epoch: 172  batch: 16  loss: 0.00152456\n",
      "epoch: 172  batch: 17  loss: 0.00411530\n",
      "epoch: 172  batch: 18  loss: 0.00770325\n",
      "epoch: 172  batch: 19  loss: 0.00494945\n",
      "epoch: 172  batch: 20  loss: 0.00217525\n",
      "epoch: 172  batch: 21  loss: 0.00295752\n",
      "epoch: 172  batch: 22  loss: 0.00140280\n",
      "epoch: 172  batch: 23  loss: 0.00730703\n",
      "epoch: 172  batch: 24  loss: 0.00781706\n",
      "epoch: 172  batch: 25  loss: 0.00161636\n",
      "epoch: 172  batch: 26  loss: 0.03155326\n",
      "epoch: 172  batch: 27  loss: 0.00212786\n",
      "epoch: 172  batch: 28  loss: 0.00267478\n",
      "epoch: 173  batch: 1  loss: 0.00331199\n",
      "epoch: 173  batch: 2  loss: 0.00158988\n",
      "epoch: 173  batch: 3  loss: 0.00132927\n",
      "epoch: 173  batch: 4  loss: 0.00419958\n",
      "epoch: 173  batch: 5  loss: 0.00396357\n",
      "epoch: 173  batch: 6  loss: 0.00153396\n",
      "epoch: 173  batch: 7  loss: 0.02309571\n",
      "epoch: 173  batch: 8  loss: 0.01022028\n",
      "epoch: 173  batch: 9  loss: 0.00273425\n",
      "epoch: 173  batch: 10  loss: 0.00291967\n",
      "epoch: 173  batch: 11  loss: 0.00356048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 173  batch: 12  loss: 0.00465865\n",
      "epoch: 173  batch: 13  loss: 0.00512879\n",
      "epoch: 173  batch: 14  loss: 0.00299319\n",
      "epoch: 173  batch: 15  loss: 0.00530923\n",
      "epoch: 173  batch: 16  loss: 0.02180788\n",
      "epoch: 173  batch: 17  loss: 0.00099596\n",
      "epoch: 173  batch: 18  loss: 0.00127197\n",
      "epoch: 173  batch: 19  loss: 0.00293399\n",
      "epoch: 173  batch: 20  loss: 0.00437767\n",
      "epoch: 173  batch: 21  loss: 0.00457370\n",
      "epoch: 173  batch: 22  loss: 0.00146990\n",
      "epoch: 173  batch: 23  loss: 0.00172328\n",
      "epoch: 173  batch: 24  loss: 0.00737618\n",
      "epoch: 173  batch: 25  loss: 0.00163112\n",
      "epoch: 173  batch: 26  loss: 0.00214101\n",
      "epoch: 173  batch: 27  loss: 0.00456694\n",
      "epoch: 173  batch: 28  loss: 0.00625858\n",
      "epoch: 174  batch: 1  loss: 0.00209795\n",
      "epoch: 174  batch: 2  loss: 0.00209142\n",
      "epoch: 174  batch: 3  loss: 0.00158171\n",
      "epoch: 174  batch: 4  loss: 0.02248824\n",
      "epoch: 174  batch: 5  loss: 0.00281043\n",
      "epoch: 174  batch: 6  loss: 0.01280332\n",
      "epoch: 174  batch: 7  loss: 0.00427098\n",
      "epoch: 174  batch: 8  loss: 0.00247918\n",
      "epoch: 174  batch: 9  loss: 0.00271683\n",
      "epoch: 174  batch: 10  loss: 0.00367354\n",
      "epoch: 174  batch: 11  loss: 0.01544266\n",
      "epoch: 174  batch: 12  loss: 0.00286707\n",
      "epoch: 174  batch: 13  loss: 0.00373985\n",
      "epoch: 174  batch: 14  loss: 0.00289511\n",
      "epoch: 174  batch: 15  loss: 0.00404533\n",
      "epoch: 174  batch: 16  loss: 0.00150393\n",
      "epoch: 174  batch: 17  loss: 0.00617289\n",
      "epoch: 174  batch: 18  loss: 0.00853532\n",
      "epoch: 174  batch: 19  loss: 0.00195322\n",
      "epoch: 174  batch: 20  loss: 0.00398855\n",
      "epoch: 174  batch: 21  loss: 0.00240207\n",
      "epoch: 174  batch: 22  loss: 0.00616195\n",
      "epoch: 174  batch: 23  loss: 0.00616788\n",
      "epoch: 174  batch: 24  loss: 0.01407069\n",
      "epoch: 174  batch: 25  loss: 0.00272378\n",
      "epoch: 174  batch: 26  loss: 0.00902522\n",
      "epoch: 174  batch: 27  loss: 0.00790474\n",
      "epoch: 174  batch: 28  loss: 0.00492330\n",
      "epoch: 175  batch: 1  loss: 0.01214234\n",
      "epoch: 175  batch: 2  loss: 0.00272770\n",
      "epoch: 175  batch: 3  loss: 0.00255537\n",
      "epoch: 175  batch: 4  loss: 0.00202416\n",
      "epoch: 175  batch: 5  loss: 0.00097391\n",
      "epoch: 175  batch: 6  loss: 0.00168787\n",
      "epoch: 175  batch: 7  loss: 0.00908776\n",
      "epoch: 175  batch: 8  loss: 0.02078333\n",
      "epoch: 175  batch: 9  loss: 0.00403131\n",
      "epoch: 175  batch: 10  loss: 0.00661111\n",
      "epoch: 175  batch: 11  loss: 0.00233640\n",
      "epoch: 175  batch: 12  loss: 0.00689708\n",
      "epoch: 175  batch: 13  loss: 0.00282713\n",
      "epoch: 175  batch: 14  loss: 0.00334489\n",
      "epoch: 175  batch: 15  loss: 0.00660940\n",
      "epoch: 175  batch: 16  loss: 0.00201826\n",
      "epoch: 175  batch: 17  loss: 0.00189549\n",
      "epoch: 175  batch: 18  loss: 0.00445690\n",
      "epoch: 175  batch: 19  loss: 0.01707821\n",
      "epoch: 175  batch: 20  loss: 0.01094275\n",
      "epoch: 175  batch: 21  loss: 0.00349155\n",
      "epoch: 175  batch: 22  loss: 0.00200616\n",
      "epoch: 175  batch: 23  loss: 0.00441430\n",
      "epoch: 175  batch: 24  loss: 0.00523545\n",
      "epoch: 175  batch: 25  loss: 0.00336778\n",
      "epoch: 175  batch: 26  loss: 0.00392121\n",
      "epoch: 175  batch: 27  loss: 0.00673654\n",
      "epoch: 175  batch: 28  loss: 0.03242064\n",
      "epoch: 176  batch: 1  loss: 0.00543416\n",
      "epoch: 176  batch: 2  loss: 0.00306239\n",
      "epoch: 176  batch: 3  loss: 0.00290051\n",
      "epoch: 176  batch: 4  loss: 0.00352512\n",
      "epoch: 176  batch: 5  loss: 0.00247694\n",
      "epoch: 176  batch: 6  loss: 0.00867844\n",
      "epoch: 176  batch: 7  loss: 0.00511009\n",
      "epoch: 176  batch: 8  loss: 0.01294328\n",
      "epoch: 176  batch: 9  loss: 0.00791849\n",
      "epoch: 176  batch: 10  loss: 0.00157019\n",
      "epoch: 176  batch: 11  loss: 0.00268634\n",
      "epoch: 176  batch: 12  loss: 0.00374545\n",
      "epoch: 176  batch: 13  loss: 0.00502746\n",
      "epoch: 176  batch: 14  loss: 0.00330315\n",
      "epoch: 176  batch: 15  loss: 0.00130469\n",
      "epoch: 176  batch: 16  loss: 0.00382478\n",
      "epoch: 176  batch: 17  loss: 0.01814411\n",
      "epoch: 176  batch: 18  loss: 0.00115628\n",
      "epoch: 176  batch: 19  loss: 0.00631847\n",
      "epoch: 176  batch: 20  loss: 0.00643984\n",
      "epoch: 176  batch: 21  loss: 0.00233067\n",
      "epoch: 176  batch: 22  loss: 0.00138755\n",
      "epoch: 176  batch: 23  loss: 0.00131286\n",
      "epoch: 176  batch: 24  loss: 0.00580768\n",
      "epoch: 176  batch: 25  loss: 0.00334371\n",
      "epoch: 176  batch: 26  loss: 0.00485385\n",
      "epoch: 176  batch: 27  loss: 0.00705046\n",
      "epoch: 176  batch: 28  loss: 0.00185824\n",
      "epoch: 177  batch: 1  loss: 0.00105366\n",
      "epoch: 177  batch: 2  loss: 0.00154287\n",
      "epoch: 177  batch: 3  loss: 0.00402010\n",
      "epoch: 177  batch: 4  loss: 0.00310119\n",
      "epoch: 177  batch: 5  loss: 0.00229252\n",
      "epoch: 177  batch: 6  loss: 0.00452760\n",
      "epoch: 177  batch: 7  loss: 0.00261026\n",
      "epoch: 177  batch: 8  loss: 0.01777073\n",
      "epoch: 177  batch: 9  loss: 0.00774687\n",
      "epoch: 177  batch: 10  loss: 0.00307167\n",
      "epoch: 177  batch: 11  loss: 0.00227274\n",
      "epoch: 177  batch: 12  loss: 0.00654520\n",
      "epoch: 177  batch: 13  loss: 0.00669398\n",
      "epoch: 177  batch: 14  loss: 0.00572003\n",
      "epoch: 177  batch: 15  loss: 0.00797574\n",
      "epoch: 177  batch: 16  loss: 0.00585276\n",
      "epoch: 177  batch: 17  loss: 0.00440789\n",
      "epoch: 177  batch: 18  loss: 0.00651691\n",
      "epoch: 177  batch: 19  loss: 0.00406189\n",
      "epoch: 177  batch: 20  loss: 0.00421407\n",
      "epoch: 177  batch: 21  loss: 0.00541795\n",
      "epoch: 177  batch: 22  loss: 0.00294410\n",
      "epoch: 177  batch: 23  loss: 0.00176873\n",
      "epoch: 177  batch: 24  loss: 0.00905704\n",
      "epoch: 177  batch: 25  loss: 0.00372258\n",
      "epoch: 177  batch: 26  loss: 0.00522245\n",
      "epoch: 177  batch: 27  loss: 0.01851227\n",
      "epoch: 177  batch: 28  loss: 0.00396873\n",
      "epoch: 178  batch: 1  loss: 0.00747115\n",
      "epoch: 178  batch: 2  loss: 0.01068592\n",
      "epoch: 178  batch: 3  loss: 0.00370425\n",
      "epoch: 178  batch: 4  loss: 0.00070530\n",
      "epoch: 178  batch: 5  loss: 0.00359573\n",
      "epoch: 178  batch: 6  loss: 0.00324515\n",
      "epoch: 178  batch: 7  loss: 0.00832375\n",
      "epoch: 178  batch: 8  loss: 0.00265480\n",
      "epoch: 178  batch: 9  loss: 0.00361788\n",
      "epoch: 178  batch: 10  loss: 0.02162046\n",
      "epoch: 178  batch: 11  loss: 0.01058119\n",
      "epoch: 178  batch: 12  loss: 0.00191546\n",
      "epoch: 178  batch: 13  loss: 0.00224609\n",
      "epoch: 178  batch: 14  loss: 0.01215063\n",
      "epoch: 178  batch: 15  loss: 0.00452075\n",
      "epoch: 178  batch: 16  loss: 0.00555773\n",
      "epoch: 178  batch: 17  loss: 0.00375395\n",
      "epoch: 178  batch: 18  loss: 0.02508572\n",
      "epoch: 178  batch: 19  loss: 0.00500421\n",
      "epoch: 178  batch: 20  loss: 0.00128912\n",
      "epoch: 178  batch: 21  loss: 0.00878598\n",
      "epoch: 178  batch: 22  loss: 0.01384194\n",
      "epoch: 178  batch: 23  loss: 0.00127829\n",
      "epoch: 178  batch: 24  loss: 0.00175436\n",
      "epoch: 178  batch: 25  loss: 0.00161757\n",
      "epoch: 178  batch: 26  loss: 0.00453666\n",
      "epoch: 178  batch: 27  loss: 0.00602889\n",
      "epoch: 178  batch: 28  loss: 0.00230391\n",
      "epoch: 179  batch: 1  loss: 0.00269999\n",
      "epoch: 179  batch: 2  loss: 0.00297066\n",
      "epoch: 179  batch: 3  loss: 0.00750618\n",
      "epoch: 179  batch: 4  loss: 0.00789685\n",
      "epoch: 179  batch: 5  loss: 0.02128538\n",
      "epoch: 179  batch: 6  loss: 0.00240686\n",
      "epoch: 179  batch: 7  loss: 0.00115846\n",
      "epoch: 179  batch: 8  loss: 0.00327652\n",
      "epoch: 179  batch: 9  loss: 0.00512899\n",
      "epoch: 179  batch: 10  loss: 0.00805586\n",
      "epoch: 179  batch: 11  loss: 0.00716308\n",
      "epoch: 179  batch: 12  loss: 0.00262353\n",
      "epoch: 179  batch: 13  loss: 0.00777575\n",
      "epoch: 179  batch: 14  loss: 0.00517989\n",
      "epoch: 179  batch: 15  loss: 0.00283779\n",
      "epoch: 179  batch: 16  loss: 0.00223391\n",
      "epoch: 179  batch: 17  loss: 0.00355159\n",
      "epoch: 179  batch: 18  loss: 0.00573460\n",
      "epoch: 179  batch: 19  loss: 0.00587046\n",
      "epoch: 179  batch: 20  loss: 0.00317777\n",
      "epoch: 179  batch: 21  loss: 0.00634530\n",
      "epoch: 179  batch: 22  loss: 0.00371206\n",
      "epoch: 179  batch: 23  loss: 0.01583385\n",
      "epoch: 179  batch: 24  loss: 0.00224301\n",
      "epoch: 179  batch: 25  loss: 0.00265848\n",
      "epoch: 179  batch: 26  loss: 0.00461560\n",
      "epoch: 179  batch: 27  loss: 0.00173088\n",
      "epoch: 179  batch: 28  loss: 0.00233097\n",
      "epoch: 180  batch: 1  loss: 0.00862044\n",
      "epoch: 180  batch: 2  loss: 0.00231752\n",
      "epoch: 180  batch: 3  loss: 0.00940741\n",
      "epoch: 180  batch: 4  loss: 0.00585991\n",
      "epoch: 180  batch: 5  loss: 0.00239305\n",
      "epoch: 180  batch: 6  loss: 0.00732600\n",
      "epoch: 180  batch: 7  loss: 0.00286543\n",
      "epoch: 180  batch: 8  loss: 0.00385381\n",
      "epoch: 180  batch: 9  loss: 0.00573024\n",
      "epoch: 180  batch: 10  loss: 0.00335850\n",
      "epoch: 180  batch: 11  loss: 0.00157640\n",
      "epoch: 180  batch: 12  loss: 0.00153780\n",
      "epoch: 180  batch: 13  loss: 0.00559058\n",
      "epoch: 180  batch: 14  loss: 0.00605921\n",
      "epoch: 180  batch: 15  loss: 0.00416343\n",
      "epoch: 180  batch: 16  loss: 0.00325443\n",
      "epoch: 180  batch: 17  loss: 0.00380832\n",
      "epoch: 180  batch: 18  loss: 0.00391945\n",
      "epoch: 180  batch: 19  loss: 0.01233112\n",
      "epoch: 180  batch: 20  loss: 0.00289877\n",
      "epoch: 180  batch: 21  loss: 0.01092907\n",
      "epoch: 180  batch: 22  loss: 0.00444975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 180  batch: 23  loss: 0.00191690\n",
      "epoch: 180  batch: 24  loss: 0.00217396\n",
      "epoch: 180  batch: 25  loss: 0.00523293\n",
      "epoch: 180  batch: 26  loss: 0.01147476\n",
      "epoch: 180  batch: 27  loss: 0.01890212\n",
      "epoch: 180  batch: 28  loss: 0.00467308\n",
      "epoch: 181  batch: 1  loss: 0.00257196\n",
      "epoch: 181  batch: 2  loss: 0.00698272\n",
      "epoch: 181  batch: 3  loss: 0.00225818\n",
      "epoch: 181  batch: 4  loss: 0.00393159\n",
      "epoch: 181  batch: 5  loss: 0.01828599\n",
      "epoch: 181  batch: 6  loss: 0.00922867\n",
      "epoch: 181  batch: 7  loss: 0.00959687\n",
      "epoch: 181  batch: 8  loss: 0.00307638\n",
      "epoch: 181  batch: 9  loss: 0.00619453\n",
      "epoch: 181  batch: 10  loss: 0.00175985\n",
      "epoch: 181  batch: 11  loss: 0.00609161\n",
      "epoch: 181  batch: 12  loss: 0.00647321\n",
      "epoch: 181  batch: 13  loss: 0.00854537\n",
      "epoch: 181  batch: 14  loss: 0.00786505\n",
      "epoch: 181  batch: 15  loss: 0.00269808\n",
      "epoch: 181  batch: 16  loss: 0.00380868\n",
      "epoch: 181  batch: 17  loss: 0.00360632\n",
      "epoch: 181  batch: 18  loss: 0.00446095\n",
      "epoch: 181  batch: 19  loss: 0.00192924\n",
      "epoch: 181  batch: 20  loss: 0.00128112\n",
      "epoch: 181  batch: 21  loss: 0.00089192\n",
      "epoch: 181  batch: 22  loss: 0.00331298\n",
      "epoch: 181  batch: 23  loss: 0.00985636\n",
      "epoch: 181  batch: 24  loss: 0.00199036\n",
      "epoch: 181  batch: 25  loss: 0.01534078\n",
      "epoch: 181  batch: 26  loss: 0.00588220\n",
      "epoch: 181  batch: 27  loss: 0.00243644\n",
      "epoch: 181  batch: 28  loss: 0.00157511\n",
      "epoch: 182  batch: 1  loss: 0.00216463\n",
      "epoch: 182  batch: 2  loss: 0.00255020\n",
      "epoch: 182  batch: 3  loss: 0.00469034\n",
      "epoch: 182  batch: 4  loss: 0.00162283\n",
      "epoch: 182  batch: 5  loss: 0.00447485\n",
      "epoch: 182  batch: 6  loss: 0.02070419\n",
      "epoch: 182  batch: 7  loss: 0.00869722\n",
      "epoch: 182  batch: 8  loss: 0.00194017\n",
      "epoch: 182  batch: 9  loss: 0.00275550\n",
      "epoch: 182  batch: 10  loss: 0.00167941\n",
      "epoch: 182  batch: 11  loss: 0.00361111\n",
      "epoch: 182  batch: 12  loss: 0.00401415\n",
      "epoch: 182  batch: 13  loss: 0.00179899\n",
      "epoch: 182  batch: 14  loss: 0.00477074\n",
      "epoch: 182  batch: 15  loss: 0.02133554\n",
      "epoch: 182  batch: 16  loss: 0.00594463\n",
      "epoch: 182  batch: 17  loss: 0.00475033\n",
      "epoch: 182  batch: 18  loss: 0.00374801\n",
      "epoch: 182  batch: 19  loss: 0.00302313\n",
      "epoch: 182  batch: 20  loss: 0.00493459\n",
      "epoch: 182  batch: 21  loss: 0.01282217\n",
      "epoch: 182  batch: 22  loss: 0.00437999\n",
      "epoch: 182  batch: 23  loss: 0.00127892\n",
      "epoch: 182  batch: 24  loss: 0.00388382\n",
      "epoch: 182  batch: 25  loss: 0.00366204\n",
      "epoch: 182  batch: 26  loss: 0.00497445\n",
      "epoch: 182  batch: 27  loss: 0.00669225\n",
      "epoch: 182  batch: 28  loss: 0.00636729\n",
      "epoch: 183  batch: 1  loss: 0.00204587\n",
      "epoch: 183  batch: 2  loss: 0.00223224\n",
      "epoch: 183  batch: 3  loss: 0.00313577\n",
      "epoch: 183  batch: 4  loss: 0.00764389\n",
      "epoch: 183  batch: 5  loss: 0.00392498\n",
      "epoch: 183  batch: 6  loss: 0.00243457\n",
      "epoch: 183  batch: 7  loss: 0.00359294\n",
      "epoch: 183  batch: 8  loss: 0.00433064\n",
      "epoch: 183  batch: 9  loss: 0.00238989\n",
      "epoch: 183  batch: 10  loss: 0.00941238\n",
      "epoch: 183  batch: 11  loss: 0.00248378\n",
      "epoch: 183  batch: 12  loss: 0.00296978\n",
      "epoch: 183  batch: 13  loss: 0.00183749\n",
      "epoch: 183  batch: 14  loss: 0.00251555\n",
      "epoch: 183  batch: 15  loss: 0.00754657\n",
      "epoch: 183  batch: 16  loss: 0.00084837\n",
      "epoch: 183  batch: 17  loss: 0.00188477\n",
      "epoch: 183  batch: 18  loss: 0.00113613\n",
      "epoch: 183  batch: 19  loss: 0.00143394\n",
      "epoch: 183  batch: 20  loss: 0.00633407\n",
      "epoch: 183  batch: 21  loss: 0.01438655\n",
      "epoch: 183  batch: 22  loss: 0.00619633\n",
      "epoch: 183  batch: 23  loss: 0.00437372\n",
      "epoch: 183  batch: 24  loss: 0.00556507\n",
      "epoch: 183  batch: 25  loss: 0.00384953\n",
      "epoch: 183  batch: 26  loss: 0.00529158\n",
      "epoch: 183  batch: 27  loss: 0.01748694\n",
      "epoch: 183  batch: 28  loss: 0.02605855\n",
      "epoch: 184  batch: 1  loss: 0.00391980\n",
      "epoch: 184  batch: 2  loss: 0.00244858\n",
      "epoch: 184  batch: 3  loss: 0.00718698\n",
      "epoch: 184  batch: 4  loss: 0.00239345\n",
      "epoch: 184  batch: 5  loss: 0.01256715\n",
      "epoch: 184  batch: 6  loss: 0.00645715\n",
      "epoch: 184  batch: 7  loss: 0.00453740\n",
      "epoch: 184  batch: 8  loss: 0.00351652\n",
      "epoch: 184  batch: 9  loss: 0.00316638\n",
      "epoch: 184  batch: 10  loss: 0.00232367\n",
      "epoch: 184  batch: 11  loss: 0.00200631\n",
      "epoch: 184  batch: 12  loss: 0.00287861\n",
      "epoch: 184  batch: 13  loss: 0.00180065\n",
      "epoch: 184  batch: 14  loss: 0.00419806\n",
      "epoch: 184  batch: 15  loss: 0.00134624\n",
      "epoch: 184  batch: 16  loss: 0.00193270\n",
      "epoch: 184  batch: 17  loss: 0.00462017\n",
      "epoch: 184  batch: 18  loss: 0.00779116\n",
      "epoch: 184  batch: 19  loss: 0.00254647\n",
      "epoch: 184  batch: 20  loss: 0.00428386\n",
      "epoch: 184  batch: 21  loss: 0.00216568\n",
      "epoch: 184  batch: 22  loss: 0.00333315\n",
      "epoch: 184  batch: 23  loss: 0.01878308\n",
      "epoch: 184  batch: 24  loss: 0.00462454\n",
      "epoch: 184  batch: 25  loss: 0.00198368\n",
      "epoch: 184  batch: 26  loss: 0.00202051\n",
      "epoch: 184  batch: 27  loss: 0.00186469\n",
      "epoch: 184  batch: 28  loss: 0.00268267\n",
      "epoch: 185  batch: 1  loss: 0.00457867\n",
      "epoch: 185  batch: 2  loss: 0.00420452\n",
      "epoch: 185  batch: 3  loss: 0.00178225\n",
      "epoch: 185  batch: 4  loss: 0.00340922\n",
      "epoch: 185  batch: 5  loss: 0.00176967\n",
      "epoch: 185  batch: 6  loss: 0.00216637\n",
      "epoch: 185  batch: 7  loss: 0.01556515\n",
      "epoch: 185  batch: 8  loss: 0.00911245\n",
      "epoch: 185  batch: 9  loss: 0.00507496\n",
      "epoch: 185  batch: 10  loss: 0.00205690\n",
      "epoch: 185  batch: 11  loss: 0.00862110\n",
      "epoch: 185  batch: 12  loss: 0.00765203\n",
      "epoch: 185  batch: 13  loss: 0.00604503\n",
      "epoch: 185  batch: 14  loss: 0.00566900\n",
      "epoch: 185  batch: 15  loss: 0.00283588\n",
      "epoch: 185  batch: 16  loss: 0.00535511\n",
      "epoch: 185  batch: 17  loss: 0.00117423\n",
      "epoch: 185  batch: 18  loss: 0.00193553\n",
      "epoch: 185  batch: 19  loss: 0.00554217\n",
      "epoch: 185  batch: 20  loss: 0.01923474\n",
      "epoch: 185  batch: 21  loss: 0.00659784\n",
      "epoch: 185  batch: 22  loss: 0.00306797\n",
      "epoch: 185  batch: 23  loss: 0.00614168\n",
      "epoch: 185  batch: 24  loss: 0.00350392\n",
      "epoch: 185  batch: 25  loss: 0.00636327\n",
      "epoch: 185  batch: 26  loss: 0.00176277\n",
      "epoch: 185  batch: 27  loss: 0.00335077\n",
      "epoch: 185  batch: 28  loss: 0.00432464\n",
      "epoch: 186  batch: 1  loss: 0.00785676\n",
      "epoch: 186  batch: 2  loss: 0.00294081\n",
      "epoch: 186  batch: 3  loss: 0.00434286\n",
      "epoch: 186  batch: 4  loss: 0.00267579\n",
      "epoch: 186  batch: 5  loss: 0.00324467\n",
      "epoch: 186  batch: 6  loss: 0.00623357\n",
      "epoch: 186  batch: 7  loss: 0.00275248\n",
      "epoch: 186  batch: 8  loss: 0.00183214\n",
      "epoch: 186  batch: 9  loss: 0.00238850\n",
      "epoch: 186  batch: 10  loss: 0.00240487\n",
      "epoch: 186  batch: 11  loss: 0.00510743\n",
      "epoch: 186  batch: 12  loss: 0.00167620\n",
      "epoch: 186  batch: 13  loss: 0.00638067\n",
      "epoch: 186  batch: 14  loss: 0.00710155\n",
      "epoch: 186  batch: 15  loss: 0.00390373\n",
      "epoch: 186  batch: 16  loss: 0.01006978\n",
      "epoch: 186  batch: 17  loss: 0.00248955\n",
      "epoch: 186  batch: 18  loss: 0.00365036\n",
      "epoch: 186  batch: 19  loss: 0.00386257\n",
      "epoch: 186  batch: 20  loss: 0.02301575\n",
      "epoch: 186  batch: 21  loss: 0.00324578\n",
      "epoch: 186  batch: 22  loss: 0.01235650\n",
      "epoch: 186  batch: 23  loss: 0.00411638\n",
      "epoch: 186  batch: 24  loss: 0.00238898\n",
      "epoch: 186  batch: 25  loss: 0.00127788\n",
      "epoch: 186  batch: 26  loss: 0.00329396\n",
      "epoch: 186  batch: 27  loss: 0.00374420\n",
      "epoch: 186  batch: 28  loss: 0.00552573\n",
      "epoch: 187  batch: 1  loss: 0.00374181\n",
      "epoch: 187  batch: 2  loss: 0.00281313\n",
      "epoch: 187  batch: 3  loss: 0.00424101\n",
      "epoch: 187  batch: 4  loss: 0.00348047\n",
      "epoch: 187  batch: 5  loss: 0.00346852\n",
      "epoch: 187  batch: 6  loss: 0.00150720\n",
      "epoch: 187  batch: 7  loss: 0.00405288\n",
      "epoch: 187  batch: 8  loss: 0.01870863\n",
      "epoch: 187  batch: 9  loss: 0.00268307\n",
      "epoch: 187  batch: 10  loss: 0.01055758\n",
      "epoch: 187  batch: 11  loss: 0.00330072\n",
      "epoch: 187  batch: 12  loss: 0.00412488\n",
      "epoch: 187  batch: 13  loss: 0.00236712\n",
      "epoch: 187  batch: 14  loss: 0.00278260\n",
      "epoch: 187  batch: 15  loss: 0.00645478\n",
      "epoch: 187  batch: 16  loss: 0.00252253\n",
      "epoch: 187  batch: 17  loss: 0.00573850\n",
      "epoch: 187  batch: 18  loss: 0.01459778\n",
      "epoch: 187  batch: 19  loss: 0.00087958\n",
      "epoch: 187  batch: 20  loss: 0.01569771\n",
      "epoch: 187  batch: 21  loss: 0.00906527\n",
      "epoch: 187  batch: 22  loss: 0.00187924\n",
      "epoch: 187  batch: 23  loss: 0.00375866\n",
      "epoch: 187  batch: 24  loss: 0.00294165\n",
      "epoch: 187  batch: 25  loss: 0.00198659\n",
      "epoch: 187  batch: 26  loss: 0.00474529\n",
      "epoch: 187  batch: 27  loss: 0.00373348\n",
      "epoch: 187  batch: 28  loss: 0.00761414\n",
      "epoch: 188  batch: 1  loss: 0.00582808\n",
      "epoch: 188  batch: 2  loss: 0.00401597\n",
      "epoch: 188  batch: 3  loss: 0.00247457\n",
      "epoch: 188  batch: 4  loss: 0.00476556\n",
      "epoch: 188  batch: 5  loss: 0.00190568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 188  batch: 6  loss: 0.00345494\n",
      "epoch: 188  batch: 7  loss: 0.00363656\n",
      "epoch: 188  batch: 8  loss: 0.00398313\n",
      "epoch: 188  batch: 9  loss: 0.00512556\n",
      "epoch: 188  batch: 10  loss: 0.00429054\n",
      "epoch: 188  batch: 11  loss: 0.01784040\n",
      "epoch: 188  batch: 12  loss: 0.00470186\n",
      "epoch: 188  batch: 13  loss: 0.00414327\n",
      "epoch: 188  batch: 14  loss: 0.00480407\n",
      "epoch: 188  batch: 15  loss: 0.01321133\n",
      "epoch: 188  batch: 16  loss: 0.00620391\n",
      "epoch: 188  batch: 17  loss: 0.00076493\n",
      "epoch: 188  batch: 18  loss: 0.00274350\n",
      "epoch: 188  batch: 19  loss: 0.00505291\n",
      "epoch: 188  batch: 20  loss: 0.00496565\n",
      "epoch: 188  batch: 21  loss: 0.00347638\n",
      "epoch: 188  batch: 22  loss: 0.00873775\n",
      "epoch: 188  batch: 23  loss: 0.00236414\n",
      "epoch: 188  batch: 24  loss: 0.00280515\n",
      "epoch: 188  batch: 25  loss: 0.00541081\n",
      "epoch: 188  batch: 26  loss: 0.00335616\n",
      "epoch: 188  batch: 27  loss: 0.01221576\n",
      "epoch: 188  batch: 28  loss: 0.00783827\n",
      "epoch: 189  batch: 1  loss: 0.01503680\n",
      "epoch: 189  batch: 2  loss: 0.00114878\n",
      "epoch: 189  batch: 3  loss: 0.00392807\n",
      "epoch: 189  batch: 4  loss: 0.00456322\n",
      "epoch: 189  batch: 5  loss: 0.00658996\n",
      "epoch: 189  batch: 6  loss: 0.00166489\n",
      "epoch: 189  batch: 7  loss: 0.01819176\n",
      "epoch: 189  batch: 8  loss: 0.00642235\n",
      "epoch: 189  batch: 9  loss: 0.00528287\n",
      "epoch: 189  batch: 10  loss: 0.00080514\n",
      "epoch: 189  batch: 11  loss: 0.00889640\n",
      "epoch: 189  batch: 12  loss: 0.00159140\n",
      "epoch: 189  batch: 13  loss: 0.00289794\n",
      "epoch: 189  batch: 14  loss: 0.00185866\n",
      "epoch: 189  batch: 15  loss: 0.00270296\n",
      "epoch: 189  batch: 16  loss: 0.00508521\n",
      "epoch: 189  batch: 17  loss: 0.00918629\n",
      "epoch: 189  batch: 18  loss: 0.00319295\n",
      "epoch: 189  batch: 19  loss: 0.00294501\n",
      "epoch: 189  batch: 20  loss: 0.00210635\n",
      "epoch: 189  batch: 21  loss: 0.00141873\n",
      "epoch: 189  batch: 22  loss: 0.00621542\n",
      "epoch: 189  batch: 23  loss: 0.00443887\n",
      "epoch: 189  batch: 24  loss: 0.00332695\n",
      "epoch: 189  batch: 25  loss: 0.00383201\n",
      "epoch: 189  batch: 26  loss: 0.00227015\n",
      "epoch: 189  batch: 27  loss: 0.00114429\n",
      "epoch: 189  batch: 28  loss: 0.00259348\n",
      "epoch: 190  batch: 1  loss: 0.00419027\n",
      "epoch: 190  batch: 2  loss: 0.00533371\n",
      "epoch: 190  batch: 3  loss: 0.00396144\n",
      "epoch: 190  batch: 4  loss: 0.00223525\n",
      "epoch: 190  batch: 5  loss: 0.00290948\n",
      "epoch: 190  batch: 6  loss: 0.00722871\n",
      "epoch: 190  batch: 7  loss: 0.01468926\n",
      "epoch: 190  batch: 8  loss: 0.00645450\n",
      "epoch: 190  batch: 9  loss: 0.02060308\n",
      "epoch: 190  batch: 10  loss: 0.00232260\n",
      "epoch: 190  batch: 11  loss: 0.00609613\n",
      "epoch: 190  batch: 12  loss: 0.00253000\n",
      "epoch: 190  batch: 13  loss: 0.00161266\n",
      "epoch: 190  batch: 14  loss: 0.00507719\n",
      "epoch: 190  batch: 15  loss: 0.00381623\n",
      "epoch: 190  batch: 16  loss: 0.00143253\n",
      "epoch: 190  batch: 17  loss: 0.00273901\n",
      "epoch: 190  batch: 18  loss: 0.00264030\n",
      "epoch: 190  batch: 19  loss: 0.00189085\n",
      "epoch: 190  batch: 20  loss: 0.00774377\n",
      "epoch: 190  batch: 21  loss: 0.00504977\n",
      "epoch: 190  batch: 22  loss: 0.00845282\n",
      "epoch: 190  batch: 23  loss: 0.00231138\n",
      "epoch: 190  batch: 24  loss: 0.00585304\n",
      "epoch: 190  batch: 25  loss: 0.00370873\n",
      "epoch: 190  batch: 26  loss: 0.00582153\n",
      "epoch: 190  batch: 27  loss: 0.01602221\n",
      "epoch: 190  batch: 28  loss: 0.00843301\n",
      "epoch: 191  batch: 1  loss: 0.00345285\n",
      "epoch: 191  batch: 2  loss: 0.02672504\n",
      "epoch: 191  batch: 3  loss: 0.00124758\n",
      "epoch: 191  batch: 4  loss: 0.00239376\n",
      "epoch: 191  batch: 5  loss: 0.00478165\n",
      "epoch: 191  batch: 6  loss: 0.00251462\n",
      "epoch: 191  batch: 7  loss: 0.00611969\n",
      "epoch: 191  batch: 8  loss: 0.00070757\n",
      "epoch: 191  batch: 9  loss: 0.00523984\n",
      "epoch: 191  batch: 10  loss: 0.00096226\n",
      "epoch: 191  batch: 11  loss: 0.00286901\n",
      "epoch: 191  batch: 12  loss: 0.00234294\n",
      "epoch: 191  batch: 13  loss: 0.00370036\n",
      "epoch: 191  batch: 14  loss: 0.00366669\n",
      "epoch: 191  batch: 15  loss: 0.00221764\n",
      "epoch: 191  batch: 16  loss: 0.00333816\n",
      "epoch: 191  batch: 17  loss: 0.00871155\n",
      "epoch: 191  batch: 18  loss: 0.00240648\n",
      "epoch: 191  batch: 19  loss: 0.00534067\n",
      "epoch: 191  batch: 20  loss: 0.00189843\n",
      "epoch: 191  batch: 21  loss: 0.01763322\n",
      "epoch: 191  batch: 22  loss: 0.00079260\n",
      "epoch: 191  batch: 23  loss: 0.00288799\n",
      "epoch: 191  batch: 24  loss: 0.00439729\n",
      "epoch: 191  batch: 25  loss: 0.00515328\n",
      "epoch: 191  batch: 26  loss: 0.00289993\n",
      "epoch: 191  batch: 27  loss: 0.01294901\n",
      "epoch: 191  batch: 28  loss: 0.00299866\n",
      "epoch: 192  batch: 1  loss: 0.00539165\n",
      "epoch: 192  batch: 2  loss: 0.00501600\n",
      "epoch: 192  batch: 3  loss: 0.00270492\n",
      "epoch: 192  batch: 4  loss: 0.00406339\n",
      "epoch: 192  batch: 5  loss: 0.00179115\n",
      "epoch: 192  batch: 6  loss: 0.00767317\n",
      "epoch: 192  batch: 7  loss: 0.00114595\n",
      "epoch: 192  batch: 8  loss: 0.00596110\n",
      "epoch: 192  batch: 9  loss: 0.00805888\n",
      "epoch: 192  batch: 10  loss: 0.01509678\n",
      "epoch: 192  batch: 11  loss: 0.00768708\n",
      "epoch: 192  batch: 12  loss: 0.00136832\n",
      "epoch: 192  batch: 13  loss: 0.00112261\n",
      "epoch: 192  batch: 14  loss: 0.00341829\n",
      "epoch: 192  batch: 15  loss: 0.00894563\n",
      "epoch: 192  batch: 16  loss: 0.00341938\n",
      "epoch: 192  batch: 17  loss: 0.01483712\n",
      "epoch: 192  batch: 18  loss: 0.00335076\n",
      "epoch: 192  batch: 19  loss: 0.00190987\n",
      "epoch: 192  batch: 20  loss: 0.00815755\n",
      "epoch: 192  batch: 21  loss: 0.01770100\n",
      "epoch: 192  batch: 22  loss: 0.00216146\n",
      "epoch: 192  batch: 23  loss: 0.00712768\n",
      "epoch: 192  batch: 24  loss: 0.00551237\n",
      "epoch: 192  batch: 25  loss: 0.00319103\n",
      "epoch: 192  batch: 26  loss: 0.00154916\n",
      "epoch: 192  batch: 27  loss: 0.00333039\n",
      "epoch: 192  batch: 28  loss: 0.00226017\n",
      "epoch: 193  batch: 1  loss: 0.00722428\n",
      "epoch: 193  batch: 2  loss: 0.01301390\n",
      "epoch: 193  batch: 3  loss: 0.00723736\n",
      "epoch: 193  batch: 4  loss: 0.00136280\n",
      "epoch: 193  batch: 5  loss: 0.00114753\n",
      "epoch: 193  batch: 6  loss: 0.00217294\n",
      "epoch: 193  batch: 7  loss: 0.00500305\n",
      "epoch: 193  batch: 8  loss: 0.00304572\n",
      "epoch: 193  batch: 9  loss: 0.00221077\n",
      "epoch: 193  batch: 10  loss: 0.00169630\n",
      "epoch: 193  batch: 11  loss: 0.00209832\n",
      "epoch: 193  batch: 12  loss: 0.00652113\n",
      "epoch: 193  batch: 13  loss: 0.02482018\n",
      "epoch: 193  batch: 14  loss: 0.00271799\n",
      "epoch: 193  batch: 15  loss: 0.00198667\n",
      "epoch: 193  batch: 16  loss: 0.00226484\n",
      "epoch: 193  batch: 17  loss: 0.00144430\n",
      "epoch: 193  batch: 18  loss: 0.00453756\n",
      "epoch: 193  batch: 19  loss: 0.00192225\n",
      "epoch: 193  batch: 20  loss: 0.01284153\n",
      "epoch: 193  batch: 21  loss: 0.00425258\n",
      "epoch: 193  batch: 22  loss: 0.00245775\n",
      "epoch: 193  batch: 23  loss: 0.00282788\n",
      "epoch: 193  batch: 24  loss: 0.00757718\n",
      "epoch: 193  batch: 25  loss: 0.00496796\n",
      "epoch: 193  batch: 26  loss: 0.00204764\n",
      "epoch: 193  batch: 27  loss: 0.00717266\n",
      "epoch: 193  batch: 28  loss: 0.00121717\n",
      "epoch: 194  batch: 1  loss: 0.00247636\n",
      "epoch: 194  batch: 2  loss: 0.00305072\n",
      "epoch: 194  batch: 3  loss: 0.01183469\n",
      "epoch: 194  batch: 4  loss: 0.01074067\n",
      "epoch: 194  batch: 5  loss: 0.00188909\n",
      "epoch: 194  batch: 6  loss: 0.00635090\n",
      "epoch: 194  batch: 7  loss: 0.00255577\n",
      "epoch: 194  batch: 8  loss: 0.02155662\n",
      "epoch: 194  batch: 9  loss: 0.00702925\n",
      "epoch: 194  batch: 10  loss: 0.00451097\n",
      "epoch: 194  batch: 11  loss: 0.00146935\n",
      "epoch: 194  batch: 12  loss: 0.00296097\n",
      "epoch: 194  batch: 13  loss: 0.00168428\n",
      "epoch: 194  batch: 14  loss: 0.00316590\n",
      "epoch: 194  batch: 15  loss: 0.00287645\n",
      "epoch: 194  batch: 16  loss: 0.00761139\n",
      "epoch: 194  batch: 17  loss: 0.00304542\n",
      "epoch: 194  batch: 18  loss: 0.00870510\n",
      "epoch: 194  batch: 19  loss: 0.00427295\n",
      "epoch: 194  batch: 20  loss: 0.00126920\n",
      "epoch: 194  batch: 21  loss: 0.00878052\n",
      "epoch: 194  batch: 22  loss: 0.00401219\n",
      "epoch: 194  batch: 23  loss: 0.00271869\n",
      "epoch: 194  batch: 24  loss: 0.01731233\n",
      "epoch: 194  batch: 25  loss: 0.00228053\n",
      "epoch: 194  batch: 26  loss: 0.00118218\n",
      "epoch: 194  batch: 27  loss: 0.00411571\n",
      "epoch: 194  batch: 28  loss: 0.00936848\n",
      "epoch: 195  batch: 1  loss: 0.00486447\n",
      "epoch: 195  batch: 2  loss: 0.00314812\n",
      "epoch: 195  batch: 3  loss: 0.00231091\n",
      "epoch: 195  batch: 4  loss: 0.00623675\n",
      "epoch: 195  batch: 5  loss: 0.00316876\n",
      "epoch: 195  batch: 6  loss: 0.00172082\n",
      "epoch: 195  batch: 7  loss: 0.00387414\n",
      "epoch: 195  batch: 8  loss: 0.00288063\n",
      "epoch: 195  batch: 9  loss: 0.00641455\n",
      "epoch: 195  batch: 10  loss: 0.02278817\n",
      "epoch: 195  batch: 11  loss: 0.00255392\n",
      "epoch: 195  batch: 12  loss: 0.00440096\n",
      "epoch: 195  batch: 13  loss: 0.00362381\n",
      "epoch: 195  batch: 14  loss: 0.00399906\n",
      "epoch: 195  batch: 15  loss: 0.00283815\n",
      "epoch: 195  batch: 16  loss: 0.00132292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 195  batch: 17  loss: 0.00183538\n",
      "epoch: 195  batch: 18  loss: 0.00559759\n",
      "epoch: 195  batch: 19  loss: 0.00481666\n",
      "epoch: 195  batch: 20  loss: 0.00347295\n",
      "epoch: 195  batch: 21  loss: 0.00818957\n",
      "epoch: 195  batch: 22  loss: 0.00201218\n",
      "epoch: 195  batch: 23  loss: 0.00219526\n",
      "epoch: 195  batch: 24  loss: 0.00937866\n",
      "epoch: 195  batch: 25  loss: 0.00776727\n",
      "epoch: 195  batch: 26  loss: 0.00422685\n",
      "epoch: 195  batch: 27  loss: 0.00570830\n",
      "epoch: 195  batch: 28  loss: 0.01671702\n",
      "epoch: 196  batch: 1  loss: 0.00639903\n",
      "epoch: 196  batch: 2  loss: 0.00563642\n",
      "epoch: 196  batch: 3  loss: 0.00584184\n",
      "epoch: 196  batch: 4  loss: 0.00736135\n",
      "epoch: 196  batch: 5  loss: 0.00214780\n",
      "epoch: 196  batch: 6  loss: 0.01025454\n",
      "epoch: 196  batch: 7  loss: 0.01580467\n",
      "epoch: 196  batch: 8  loss: 0.00649423\n",
      "epoch: 196  batch: 9  loss: 0.00450439\n",
      "epoch: 196  batch: 10  loss: 0.00607103\n",
      "epoch: 196  batch: 11  loss: 0.00211576\n",
      "epoch: 196  batch: 12  loss: 0.00451549\n",
      "epoch: 196  batch: 13  loss: 0.00224715\n",
      "epoch: 196  batch: 14  loss: 0.00133824\n",
      "epoch: 196  batch: 15  loss: 0.00673530\n",
      "epoch: 196  batch: 16  loss: 0.00500839\n",
      "epoch: 196  batch: 17  loss: 0.00558355\n",
      "epoch: 196  batch: 18  loss: 0.00231159\n",
      "epoch: 196  batch: 19  loss: 0.00177626\n",
      "epoch: 196  batch: 20  loss: 0.01747083\n",
      "epoch: 196  batch: 21  loss: 0.00229186\n",
      "epoch: 196  batch: 22  loss: 0.00295364\n",
      "epoch: 196  batch: 23  loss: 0.00150321\n",
      "epoch: 196  batch: 24  loss: 0.00523326\n",
      "epoch: 196  batch: 25  loss: 0.00473478\n",
      "epoch: 196  batch: 26  loss: 0.00276949\n",
      "epoch: 196  batch: 27  loss: 0.00196042\n",
      "epoch: 196  batch: 28  loss: 0.00158457\n",
      "epoch: 197  batch: 1  loss: 0.00150233\n",
      "epoch: 197  batch: 2  loss: 0.00539860\n",
      "epoch: 197  batch: 3  loss: 0.00153531\n",
      "epoch: 197  batch: 4  loss: 0.01672724\n",
      "epoch: 197  batch: 5  loss: 0.00210273\n",
      "epoch: 197  batch: 6  loss: 0.01477883\n",
      "epoch: 197  batch: 7  loss: 0.08411691\n",
      "epoch: 197  batch: 8  loss: 0.00426346\n",
      "epoch: 197  batch: 9  loss: 0.00293544\n",
      "epoch: 197  batch: 10  loss: 0.00285261\n",
      "epoch: 197  batch: 11  loss: 0.00275268\n",
      "epoch: 197  batch: 12  loss: 0.00721117\n",
      "epoch: 197  batch: 13  loss: 0.00339641\n",
      "epoch: 197  batch: 14  loss: 0.00834511\n",
      "epoch: 197  batch: 15  loss: 0.00698482\n",
      "epoch: 197  batch: 16  loss: 0.01698942\n",
      "epoch: 197  batch: 17  loss: 0.00427633\n",
      "epoch: 197  batch: 18  loss: 0.00443450\n",
      "epoch: 197  batch: 19  loss: 0.00842916\n",
      "epoch: 197  batch: 20  loss: 0.00246197\n",
      "epoch: 197  batch: 21  loss: 0.00484013\n",
      "epoch: 197  batch: 22  loss: 0.00152095\n",
      "epoch: 197  batch: 23  loss: 0.01843610\n",
      "epoch: 197  batch: 24  loss: 0.00168123\n",
      "epoch: 197  batch: 25  loss: 0.00162591\n",
      "epoch: 197  batch: 26  loss: 0.00598772\n",
      "epoch: 197  batch: 27  loss: 0.00913137\n",
      "epoch: 197  batch: 28  loss: 0.00468264\n",
      "epoch: 198  batch: 1  loss: 0.02079120\n",
      "epoch: 198  batch: 2  loss: 0.00311727\n",
      "epoch: 198  batch: 3  loss: 0.01050962\n",
      "epoch: 198  batch: 4  loss: 0.02812115\n",
      "epoch: 198  batch: 5  loss: 0.00579852\n",
      "epoch: 198  batch: 6  loss: 0.00942416\n",
      "epoch: 198  batch: 7  loss: 0.00213369\n",
      "epoch: 198  batch: 8  loss: 0.00161851\n",
      "epoch: 198  batch: 9  loss: 0.00128986\n",
      "epoch: 198  batch: 10  loss: 0.00753211\n",
      "epoch: 198  batch: 11  loss: 0.00329331\n",
      "epoch: 198  batch: 12  loss: 0.01749483\n",
      "epoch: 198  batch: 13  loss: 0.00331420\n",
      "epoch: 198  batch: 14  loss: 0.00206072\n",
      "epoch: 198  batch: 15  loss: 0.00200519\n",
      "epoch: 198  batch: 16  loss: 0.00238660\n",
      "epoch: 198  batch: 17  loss: 0.00128514\n",
      "epoch: 198  batch: 18  loss: 0.00198652\n",
      "epoch: 198  batch: 19  loss: 0.00239241\n",
      "epoch: 198  batch: 20  loss: 0.00311342\n",
      "epoch: 198  batch: 21  loss: 0.00048054\n",
      "epoch: 198  batch: 22  loss: 0.00548331\n",
      "epoch: 198  batch: 23  loss: 0.04465807\n",
      "epoch: 198  batch: 24  loss: 0.00256926\n",
      "epoch: 198  batch: 25  loss: 0.00317615\n",
      "epoch: 198  batch: 26  loss: 0.00696919\n",
      "epoch: 198  batch: 27  loss: 0.00230241\n",
      "epoch: 198  batch: 28  loss: 0.00594752\n",
      "epoch: 199  batch: 1  loss: 0.00377908\n",
      "epoch: 199  batch: 2  loss: 0.00122902\n",
      "epoch: 199  batch: 3  loss: 0.00171754\n",
      "epoch: 199  batch: 4  loss: 0.00324605\n",
      "epoch: 199  batch: 5  loss: 0.00302368\n",
      "epoch: 199  batch: 6  loss: 0.00295819\n",
      "epoch: 199  batch: 7  loss: 0.00244109\n",
      "epoch: 199  batch: 8  loss: 0.01447503\n",
      "epoch: 199  batch: 9  loss: 0.00794310\n",
      "epoch: 199  batch: 10  loss: 0.00354278\n",
      "epoch: 199  batch: 11  loss: 0.00238798\n",
      "epoch: 199  batch: 12  loss: 0.00350404\n",
      "epoch: 199  batch: 13  loss: 0.01005984\n",
      "epoch: 199  batch: 14  loss: 0.00318739\n",
      "epoch: 199  batch: 15  loss: 0.00939545\n",
      "epoch: 199  batch: 16  loss: 0.00690157\n",
      "epoch: 199  batch: 17  loss: 0.00247284\n",
      "epoch: 199  batch: 18  loss: 0.00623936\n",
      "epoch: 199  batch: 19  loss: 0.00246733\n",
      "epoch: 199  batch: 20  loss: 0.06432047\n",
      "epoch: 199  batch: 21  loss: 0.01788830\n",
      "epoch: 199  batch: 22  loss: 0.00832958\n",
      "epoch: 199  batch: 23  loss: 0.00176950\n",
      "epoch: 199  batch: 24  loss: 0.00381666\n",
      "epoch: 199  batch: 25  loss: 0.00387112\n",
      "epoch: 199  batch: 26  loss: 0.00158191\n",
      "epoch: 199  batch: 27  loss: 0.00885813\n",
      "epoch: 199  batch: 28  loss: 0.00328409\n",
      "epoch: 200  batch: 1  loss: 0.00269291\n",
      "epoch: 200  batch: 2  loss: 0.00794821\n",
      "epoch: 200  batch: 3  loss: 0.00189332\n",
      "epoch: 200  batch: 4  loss: 0.00136069\n",
      "epoch: 200  batch: 5  loss: 0.00341717\n",
      "epoch: 200  batch: 6  loss: 0.00622424\n",
      "epoch: 200  batch: 7  loss: 0.00282336\n",
      "epoch: 200  batch: 8  loss: 0.00643153\n",
      "epoch: 200  batch: 9  loss: 0.00111117\n",
      "epoch: 200  batch: 10  loss: 0.00116643\n",
      "epoch: 200  batch: 11  loss: 0.00406336\n",
      "epoch: 200  batch: 12  loss: 0.00238707\n",
      "epoch: 200  batch: 13  loss: 0.00128943\n",
      "epoch: 200  batch: 14  loss: 0.01769252\n",
      "epoch: 200  batch: 15  loss: 0.00525758\n",
      "epoch: 200  batch: 16  loss: 0.00295405\n",
      "epoch: 200  batch: 17  loss: 0.00350794\n",
      "epoch: 200  batch: 18  loss: 0.00651393\n",
      "epoch: 200  batch: 19  loss: 0.00649204\n",
      "epoch: 200  batch: 20  loss: 0.00226821\n",
      "epoch: 200  batch: 21  loss: 0.00203640\n",
      "epoch: 200  batch: 22  loss: 0.00219912\n",
      "epoch: 200  batch: 23  loss: 0.00861957\n",
      "epoch: 200  batch: 24  loss: 0.00267045\n",
      "epoch: 200  batch: 25  loss: 0.00193747\n",
      "epoch: 200  batch: 26  loss: 0.00329417\n",
      "epoch: 200  batch: 27  loss: 0.00709460\n",
      "epoch: 200  batch: 28  loss: 0.00560065\n",
      "epoch: 201  batch: 1  loss: 0.00465442\n",
      "epoch: 201  batch: 2  loss: 0.01240124\n",
      "epoch: 201  batch: 3  loss: 0.00171526\n",
      "epoch: 201  batch: 4  loss: 0.00214513\n",
      "epoch: 201  batch: 5  loss: 0.00146134\n",
      "epoch: 201  batch: 6  loss: 0.00162814\n",
      "epoch: 201  batch: 7  loss: 0.00486425\n",
      "epoch: 201  batch: 8  loss: 0.00658469\n",
      "epoch: 201  batch: 9  loss: 0.00789436\n",
      "epoch: 201  batch: 10  loss: 0.00163613\n",
      "epoch: 201  batch: 11  loss: 0.00318416\n",
      "epoch: 201  batch: 12  loss: 0.00284227\n",
      "epoch: 201  batch: 13  loss: 0.00610956\n",
      "epoch: 201  batch: 14  loss: 0.00307993\n",
      "epoch: 201  batch: 15  loss: 0.00577372\n",
      "epoch: 201  batch: 16  loss: 0.01543260\n",
      "epoch: 201  batch: 17  loss: 0.00527321\n",
      "epoch: 201  batch: 18  loss: 0.00655791\n",
      "epoch: 201  batch: 19  loss: 0.00362962\n",
      "epoch: 201  batch: 20  loss: 0.02490382\n",
      "epoch: 201  batch: 21  loss: 0.00189134\n",
      "epoch: 201  batch: 22  loss: 0.00329948\n",
      "epoch: 201  batch: 23  loss: 0.01622938\n",
      "epoch: 201  batch: 24  loss: 0.00348904\n",
      "epoch: 201  batch: 25  loss: 0.00276291\n",
      "epoch: 201  batch: 26  loss: 0.00971962\n",
      "epoch: 201  batch: 27  loss: 0.00192067\n",
      "epoch: 201  batch: 28  loss: 0.00722446\n",
      "epoch: 202  batch: 1  loss: 0.00284956\n",
      "epoch: 202  batch: 2  loss: 0.00256769\n",
      "epoch: 202  batch: 3  loss: 0.00391088\n",
      "epoch: 202  batch: 4  loss: 0.00206823\n",
      "epoch: 202  batch: 5  loss: 0.00516177\n",
      "epoch: 202  batch: 6  loss: 0.02748014\n",
      "epoch: 202  batch: 7  loss: 0.00247987\n",
      "epoch: 202  batch: 8  loss: 0.00220422\n",
      "epoch: 202  batch: 9  loss: 0.00309465\n",
      "epoch: 202  batch: 10  loss: 0.01082987\n",
      "epoch: 202  batch: 11  loss: 0.00378309\n",
      "epoch: 202  batch: 12  loss: 0.01093780\n",
      "epoch: 202  batch: 13  loss: 0.00323629\n",
      "epoch: 202  batch: 14  loss: 0.01491802\n",
      "epoch: 202  batch: 15  loss: 0.00253150\n",
      "epoch: 202  batch: 16  loss: 0.00582509\n",
      "epoch: 202  batch: 17  loss: 0.00264210\n",
      "epoch: 202  batch: 18  loss: 0.00172588\n",
      "epoch: 202  batch: 19  loss: 0.00711440\n",
      "epoch: 202  batch: 20  loss: 0.00414903\n",
      "epoch: 202  batch: 21  loss: 0.01274075\n",
      "epoch: 202  batch: 22  loss: 0.00250735\n",
      "epoch: 202  batch: 23  loss: 0.00838351\n",
      "epoch: 202  batch: 24  loss: 0.00407393\n",
      "epoch: 202  batch: 25  loss: 0.00264326\n",
      "epoch: 202  batch: 26  loss: 0.00388286\n",
      "epoch: 202  batch: 27  loss: 0.00294549\n",
      "epoch: 202  batch: 28  loss: 0.00544694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 203  batch: 1  loss: 0.00474118\n",
      "epoch: 203  batch: 2  loss: 0.02228550\n",
      "epoch: 203  batch: 3  loss: 0.00264210\n",
      "epoch: 203  batch: 4  loss: 0.00411468\n",
      "epoch: 203  batch: 5  loss: 0.00190903\n",
      "epoch: 203  batch: 6  loss: 0.02348201\n",
      "epoch: 203  batch: 7  loss: 0.00360638\n",
      "epoch: 203  batch: 8  loss: 0.00153996\n",
      "epoch: 203  batch: 9  loss: 0.00329842\n",
      "epoch: 203  batch: 10  loss: 0.00544254\n",
      "epoch: 203  batch: 11  loss: 0.00476652\n",
      "epoch: 203  batch: 12  loss: 0.00199273\n",
      "epoch: 203  batch: 13  loss: 0.00232144\n",
      "epoch: 203  batch: 14  loss: 0.00234711\n",
      "epoch: 203  batch: 15  loss: 0.00487207\n",
      "epoch: 203  batch: 16  loss: 0.00205338\n",
      "epoch: 203  batch: 17  loss: 0.00409488\n",
      "epoch: 203  batch: 18  loss: 0.00270345\n",
      "epoch: 203  batch: 19  loss: 0.00547857\n",
      "epoch: 203  batch: 20  loss: 0.00351307\n",
      "epoch: 203  batch: 21  loss: 0.00093060\n",
      "epoch: 203  batch: 22  loss: 0.00246333\n",
      "epoch: 203  batch: 23  loss: 0.00572000\n",
      "epoch: 203  batch: 24  loss: 0.01042640\n",
      "epoch: 203  batch: 25  loss: 0.00876263\n",
      "epoch: 203  batch: 26  loss: 0.00470851\n",
      "epoch: 203  batch: 27  loss: 0.00666061\n",
      "epoch: 203  batch: 28  loss: 0.02536031\n",
      "epoch: 204  batch: 1  loss: 0.00774749\n",
      "epoch: 204  batch: 2  loss: 0.00376829\n",
      "epoch: 204  batch: 3  loss: 0.00444325\n",
      "epoch: 204  batch: 4  loss: 0.01032796\n",
      "epoch: 204  batch: 5  loss: 0.01257986\n",
      "epoch: 204  batch: 6  loss: 0.00474613\n",
      "epoch: 204  batch: 7  loss: 0.00200564\n",
      "epoch: 204  batch: 8  loss: 0.00872901\n",
      "epoch: 204  batch: 9  loss: 0.00271819\n",
      "epoch: 204  batch: 10  loss: 0.00332667\n",
      "epoch: 204  batch: 11  loss: 0.00673970\n",
      "epoch: 204  batch: 12  loss: 0.00232509\n",
      "epoch: 204  batch: 13  loss: 0.00399407\n",
      "epoch: 204  batch: 14  loss: 0.00683588\n",
      "epoch: 204  batch: 15  loss: 0.00316737\n",
      "epoch: 204  batch: 16  loss: 0.01122862\n",
      "epoch: 204  batch: 17  loss: 0.01326840\n",
      "epoch: 204  batch: 18  loss: 0.01464516\n",
      "epoch: 204  batch: 19  loss: 0.00061500\n",
      "epoch: 204  batch: 20  loss: 0.00139237\n",
      "epoch: 204  batch: 21  loss: 0.00338374\n",
      "epoch: 204  batch: 22  loss: 0.01268585\n",
      "epoch: 204  batch: 23  loss: 0.00438856\n",
      "epoch: 204  batch: 24  loss: 0.00147599\n",
      "epoch: 204  batch: 25  loss: 0.00354611\n",
      "epoch: 204  batch: 26  loss: 0.00134838\n",
      "epoch: 204  batch: 27  loss: 0.01272829\n",
      "epoch: 204  batch: 28  loss: 0.00194809\n",
      "epoch: 205  batch: 1  loss: 0.00135331\n",
      "epoch: 205  batch: 2  loss: 0.00339058\n",
      "epoch: 205  batch: 3  loss: 0.00324211\n",
      "epoch: 205  batch: 4  loss: 0.00539737\n",
      "epoch: 205  batch: 5  loss: 0.00195591\n",
      "epoch: 205  batch: 6  loss: 0.00527188\n",
      "epoch: 205  batch: 7  loss: 0.00145969\n",
      "epoch: 205  batch: 8  loss: 0.00157738\n",
      "epoch: 205  batch: 9  loss: 0.01321284\n",
      "epoch: 205  batch: 10  loss: 0.00136947\n",
      "epoch: 205  batch: 11  loss: 0.00809479\n",
      "epoch: 205  batch: 12  loss: 0.03010929\n",
      "epoch: 205  batch: 13  loss: 0.00617730\n",
      "epoch: 205  batch: 14  loss: 0.00227858\n",
      "epoch: 205  batch: 15  loss: 0.00183289\n",
      "epoch: 205  batch: 16  loss: 0.00237222\n",
      "epoch: 205  batch: 17  loss: 0.00417797\n",
      "epoch: 205  batch: 18  loss: 0.00707152\n",
      "epoch: 205  batch: 19  loss: 0.00524839\n",
      "epoch: 205  batch: 20  loss: 0.00267194\n",
      "epoch: 205  batch: 21  loss: 0.00656897\n",
      "epoch: 205  batch: 22  loss: 0.00757367\n",
      "epoch: 205  batch: 23  loss: 0.00365228\n",
      "epoch: 205  batch: 24  loss: 0.00297813\n",
      "epoch: 205  batch: 25  loss: 0.00261260\n",
      "epoch: 205  batch: 26  loss: 0.01501283\n",
      "epoch: 205  batch: 27  loss: 0.00243532\n",
      "epoch: 205  batch: 28  loss: 0.00442821\n",
      "epoch: 206  batch: 1  loss: 0.00240730\n",
      "epoch: 206  batch: 2  loss: 0.00225090\n",
      "epoch: 206  batch: 3  loss: 0.00197155\n",
      "epoch: 206  batch: 4  loss: 0.00240624\n",
      "epoch: 206  batch: 5  loss: 0.00422175\n",
      "epoch: 206  batch: 6  loss: 0.00244015\n",
      "epoch: 206  batch: 7  loss: 0.00235206\n",
      "epoch: 206  batch: 8  loss: 0.00561559\n",
      "epoch: 206  batch: 9  loss: 0.02935232\n",
      "epoch: 206  batch: 10  loss: 0.00453536\n",
      "epoch: 206  batch: 11  loss: 0.00765098\n",
      "epoch: 206  batch: 12  loss: 0.00295894\n",
      "epoch: 206  batch: 13  loss: 0.00340709\n",
      "epoch: 206  batch: 14  loss: 0.00419538\n",
      "epoch: 206  batch: 15  loss: 0.00438019\n",
      "epoch: 206  batch: 16  loss: 0.02091079\n",
      "epoch: 206  batch: 17  loss: 0.00370657\n",
      "epoch: 206  batch: 18  loss: 0.00783744\n",
      "epoch: 206  batch: 19  loss: 0.00165715\n",
      "epoch: 206  batch: 20  loss: 0.00508742\n",
      "epoch: 206  batch: 21  loss: 0.00715796\n",
      "epoch: 206  batch: 22  loss: 0.00245294\n",
      "epoch: 206  batch: 23  loss: 0.00209566\n",
      "epoch: 206  batch: 24  loss: 0.00565959\n",
      "epoch: 206  batch: 25  loss: 0.00464414\n",
      "epoch: 206  batch: 26  loss: 0.00548022\n",
      "epoch: 206  batch: 27  loss: 0.00928183\n",
      "epoch: 206  batch: 28  loss: 0.01290332\n",
      "epoch: 207  batch: 1  loss: 0.00369803\n",
      "epoch: 207  batch: 2  loss: 0.00460337\n",
      "epoch: 207  batch: 3  loss: 0.00293708\n",
      "epoch: 207  batch: 4  loss: 0.00754278\n",
      "epoch: 207  batch: 5  loss: 0.00354158\n",
      "epoch: 207  batch: 6  loss: 0.00228999\n",
      "epoch: 207  batch: 7  loss: 0.00589720\n",
      "epoch: 207  batch: 8  loss: 0.00242831\n",
      "epoch: 207  batch: 9  loss: 0.00613968\n",
      "epoch: 207  batch: 10  loss: 0.00227773\n",
      "epoch: 207  batch: 11  loss: 0.00404993\n",
      "epoch: 207  batch: 12  loss: 0.00291074\n",
      "epoch: 207  batch: 13  loss: 0.03140542\n",
      "epoch: 207  batch: 14  loss: 0.00417092\n",
      "epoch: 207  batch: 15  loss: 0.00675362\n",
      "epoch: 207  batch: 16  loss: 0.01285454\n",
      "epoch: 207  batch: 17  loss: 0.00420333\n",
      "epoch: 207  batch: 18  loss: 0.00664904\n",
      "epoch: 207  batch: 19  loss: 0.00225388\n",
      "epoch: 207  batch: 20  loss: 0.00670776\n",
      "epoch: 207  batch: 21  loss: 0.00384541\n",
      "epoch: 207  batch: 22  loss: 0.00316599\n",
      "epoch: 207  batch: 23  loss: 0.00075769\n",
      "epoch: 207  batch: 24  loss: 0.00383829\n",
      "epoch: 207  batch: 25  loss: 0.00472395\n",
      "epoch: 207  batch: 26  loss: 0.00107111\n",
      "epoch: 207  batch: 27  loss: 0.00471682\n",
      "epoch: 207  batch: 28  loss: 0.01044551\n",
      "epoch: 208  batch: 1  loss: 0.00069675\n",
      "epoch: 208  batch: 2  loss: 0.00284987\n",
      "epoch: 208  batch: 3  loss: 0.00260050\n",
      "epoch: 208  batch: 4  loss: 0.01958717\n",
      "epoch: 208  batch: 5  loss: 0.01107074\n",
      "epoch: 208  batch: 6  loss: 0.00784576\n",
      "epoch: 208  batch: 7  loss: 0.00598940\n",
      "epoch: 208  batch: 8  loss: 0.00394534\n",
      "epoch: 208  batch: 9  loss: 0.00458701\n",
      "epoch: 208  batch: 10  loss: 0.00284365\n",
      "epoch: 208  batch: 11  loss: 0.00403295\n",
      "epoch: 208  batch: 12  loss: 0.00761343\n",
      "epoch: 208  batch: 13  loss: 0.00153209\n",
      "epoch: 208  batch: 14  loss: 0.00381218\n",
      "epoch: 208  batch: 15  loss: 0.00091159\n",
      "epoch: 208  batch: 16  loss: 0.00121017\n",
      "epoch: 208  batch: 17  loss: 0.00197699\n",
      "epoch: 208  batch: 18  loss: 0.00394463\n",
      "epoch: 208  batch: 19  loss: 0.00542416\n",
      "epoch: 208  batch: 20  loss: 0.00438281\n",
      "epoch: 208  batch: 21  loss: 0.00192269\n",
      "epoch: 208  batch: 22  loss: 0.00143907\n",
      "epoch: 208  batch: 23  loss: 0.01098763\n",
      "epoch: 208  batch: 24  loss: 0.00114574\n",
      "epoch: 208  batch: 25  loss: 0.00391775\n",
      "epoch: 208  batch: 26  loss: 0.01201474\n",
      "epoch: 208  batch: 27  loss: 0.00650987\n",
      "epoch: 208  batch: 28  loss: 0.00224996\n",
      "epoch: 209  batch: 1  loss: 0.00575266\n",
      "epoch: 209  batch: 2  loss: 0.00543195\n",
      "epoch: 209  batch: 3  loss: 0.00440155\n",
      "epoch: 209  batch: 4  loss: 0.00237526\n",
      "epoch: 209  batch: 5  loss: 0.00275743\n",
      "epoch: 209  batch: 6  loss: 0.00690782\n",
      "epoch: 209  batch: 7  loss: 0.00457305\n",
      "epoch: 209  batch: 8  loss: 0.00119738\n",
      "epoch: 209  batch: 9  loss: 0.00764529\n",
      "epoch: 209  batch: 10  loss: 0.00203299\n",
      "epoch: 209  batch: 11  loss: 0.01098088\n",
      "epoch: 209  batch: 12  loss: 0.01564230\n",
      "epoch: 209  batch: 13  loss: 0.00689360\n",
      "epoch: 209  batch: 14  loss: 0.00534905\n",
      "epoch: 209  batch: 15  loss: 0.00402472\n",
      "epoch: 209  batch: 16  loss: 0.00847380\n",
      "epoch: 209  batch: 17  loss: 0.00189395\n",
      "epoch: 209  batch: 18  loss: 0.00243147\n",
      "epoch: 209  batch: 19  loss: 0.00894069\n",
      "epoch: 209  batch: 20  loss: 0.01696582\n",
      "epoch: 209  batch: 21  loss: 0.00278536\n",
      "epoch: 209  batch: 22  loss: 0.00428173\n",
      "epoch: 209  batch: 23  loss: 0.00256506\n",
      "epoch: 209  batch: 24  loss: 0.00281570\n",
      "epoch: 209  batch: 25  loss: 0.00404089\n",
      "epoch: 209  batch: 26  loss: 0.00265762\n",
      "epoch: 209  batch: 27  loss: 0.00371260\n",
      "epoch: 209  batch: 28  loss: 0.01453903\n",
      "epoch: 210  batch: 1  loss: 0.00104722\n",
      "epoch: 210  batch: 2  loss: 0.00667937\n",
      "epoch: 210  batch: 3  loss: 0.00982451\n",
      "epoch: 210  batch: 4  loss: 0.00698705\n",
      "epoch: 210  batch: 5  loss: 0.00083327\n",
      "epoch: 210  batch: 6  loss: 0.00155750\n",
      "epoch: 210  batch: 7  loss: 0.01353124\n",
      "epoch: 210  batch: 8  loss: 0.00148277\n",
      "epoch: 210  batch: 9  loss: 0.00254127\n",
      "epoch: 210  batch: 10  loss: 0.00769716\n",
      "epoch: 210  batch: 11  loss: 0.00366113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 210  batch: 12  loss: 0.00266710\n",
      "epoch: 210  batch: 13  loss: 0.00610555\n",
      "epoch: 210  batch: 14  loss: 0.00405738\n",
      "epoch: 210  batch: 15  loss: 0.00515872\n",
      "epoch: 210  batch: 16  loss: 0.00857773\n",
      "epoch: 210  batch: 17  loss: 0.00422919\n",
      "epoch: 210  batch: 18  loss: 0.00237130\n",
      "epoch: 210  batch: 19  loss: 0.02358142\n",
      "epoch: 210  batch: 20  loss: 0.00416427\n",
      "epoch: 210  batch: 21  loss: 0.00510885\n",
      "epoch: 210  batch: 22  loss: 0.00292818\n",
      "epoch: 210  batch: 23  loss: 0.00232503\n",
      "epoch: 210  batch: 24  loss: 0.01154174\n",
      "epoch: 210  batch: 25  loss: 0.02182749\n",
      "epoch: 210  batch: 26  loss: 0.00216792\n",
      "epoch: 210  batch: 27  loss: 0.00247769\n",
      "epoch: 210  batch: 28  loss: 0.00225156\n",
      "epoch: 211  batch: 1  loss: 0.00642724\n",
      "epoch: 211  batch: 2  loss: 0.00533446\n",
      "epoch: 211  batch: 3  loss: 0.00784175\n",
      "epoch: 211  batch: 4  loss: 0.00194356\n",
      "epoch: 211  batch: 5  loss: 0.00326909\n",
      "epoch: 211  batch: 6  loss: 0.00481241\n",
      "epoch: 211  batch: 7  loss: 0.00370709\n",
      "epoch: 211  batch: 8  loss: 0.00496689\n",
      "epoch: 211  batch: 9  loss: 0.00242786\n",
      "epoch: 211  batch: 10  loss: 0.00233189\n",
      "epoch: 211  batch: 11  loss: 0.00125370\n",
      "epoch: 211  batch: 12  loss: 0.00334233\n",
      "epoch: 211  batch: 13  loss: 0.00200240\n",
      "epoch: 211  batch: 14  loss: 0.00269427\n",
      "epoch: 211  batch: 15  loss: 0.00531336\n",
      "epoch: 211  batch: 16  loss: 0.00299484\n",
      "epoch: 211  batch: 17  loss: 0.01904881\n",
      "epoch: 211  batch: 18  loss: 0.00153332\n",
      "epoch: 211  batch: 19  loss: 0.00193408\n",
      "epoch: 211  batch: 20  loss: 0.00117807\n",
      "epoch: 211  batch: 21  loss: 0.02291391\n",
      "epoch: 211  batch: 22  loss: 0.00318580\n",
      "epoch: 211  batch: 23  loss: 0.00740395\n",
      "epoch: 211  batch: 24  loss: 0.00639057\n",
      "epoch: 211  batch: 25  loss: 0.00242661\n",
      "epoch: 211  batch: 26  loss: 0.00314487\n",
      "epoch: 211  batch: 27  loss: 0.00261324\n",
      "epoch: 211  batch: 28  loss: 0.00562834\n",
      "epoch: 212  batch: 1  loss: 0.00212750\n",
      "epoch: 212  batch: 2  loss: 0.00544970\n",
      "epoch: 212  batch: 3  loss: 0.00546428\n",
      "epoch: 212  batch: 4  loss: 0.01223146\n",
      "epoch: 212  batch: 5  loss: 0.00251529\n",
      "epoch: 212  batch: 6  loss: 0.00430063\n",
      "epoch: 212  batch: 7  loss: 0.00125716\n",
      "epoch: 212  batch: 8  loss: 0.02560449\n",
      "epoch: 212  batch: 9  loss: 0.00449172\n",
      "epoch: 212  batch: 10  loss: 0.00701442\n",
      "epoch: 212  batch: 11  loss: 0.00546817\n",
      "epoch: 212  batch: 12  loss: 0.00327167\n",
      "epoch: 212  batch: 13  loss: 0.00117362\n",
      "epoch: 212  batch: 14  loss: 0.00483023\n",
      "epoch: 212  batch: 15  loss: 0.01458791\n",
      "epoch: 212  batch: 16  loss: 0.00383714\n",
      "epoch: 212  batch: 17  loss: 0.00517078\n",
      "epoch: 212  batch: 18  loss: 0.00912223\n",
      "epoch: 212  batch: 19  loss: 0.00436492\n",
      "epoch: 212  batch: 20  loss: 0.00304495\n",
      "epoch: 212  batch: 21  loss: 0.00527875\n",
      "epoch: 212  batch: 22  loss: 0.00234716\n",
      "epoch: 212  batch: 23  loss: 0.00336488\n",
      "epoch: 212  batch: 24  loss: 0.00432501\n",
      "epoch: 212  batch: 25  loss: 0.00194657\n",
      "epoch: 212  batch: 26  loss: 0.00276806\n",
      "epoch: 212  batch: 27  loss: 0.00343542\n",
      "epoch: 212  batch: 28  loss: 0.00188148\n",
      "epoch: 213  batch: 1  loss: 0.00551332\n",
      "epoch: 213  batch: 2  loss: 0.00680660\n",
      "epoch: 213  batch: 3  loss: 0.00303637\n",
      "epoch: 213  batch: 4  loss: 0.00256863\n",
      "epoch: 213  batch: 5  loss: 0.02113654\n",
      "epoch: 213  batch: 6  loss: 0.00344841\n",
      "epoch: 213  batch: 7  loss: 0.00811178\n",
      "epoch: 213  batch: 8  loss: 0.00522338\n",
      "epoch: 213  batch: 9  loss: 0.00703092\n",
      "epoch: 213  batch: 10  loss: 0.00272198\n",
      "epoch: 213  batch: 11  loss: 0.00539360\n",
      "epoch: 213  batch: 12  loss: 0.00249823\n",
      "epoch: 213  batch: 13  loss: 0.02480282\n",
      "epoch: 213  batch: 14  loss: 0.00287065\n",
      "epoch: 213  batch: 15  loss: 0.00778854\n",
      "epoch: 213  batch: 16  loss: 0.00568635\n",
      "epoch: 213  batch: 17  loss: 0.00551469\n",
      "epoch: 213  batch: 18  loss: 0.00633264\n",
      "epoch: 213  batch: 19  loss: 0.01013629\n",
      "epoch: 213  batch: 20  loss: 0.00955509\n",
      "epoch: 213  batch: 21  loss: 0.03303003\n",
      "epoch: 213  batch: 22  loss: 0.00896473\n",
      "epoch: 213  batch: 23  loss: 0.00570564\n",
      "epoch: 213  batch: 24  loss: 0.00126192\n",
      "epoch: 213  batch: 25  loss: 0.00546178\n",
      "epoch: 213  batch: 26  loss: 0.00138829\n",
      "epoch: 213  batch: 27  loss: 0.00274860\n",
      "epoch: 213  batch: 28  loss: 0.00414824\n",
      "epoch: 214  batch: 1  loss: 0.00249938\n",
      "epoch: 214  batch: 2  loss: 0.00549015\n",
      "epoch: 214  batch: 3  loss: 0.00588618\n",
      "epoch: 214  batch: 4  loss: 0.00984273\n",
      "epoch: 214  batch: 5  loss: 0.00149792\n",
      "epoch: 214  batch: 6  loss: 0.01940002\n",
      "epoch: 214  batch: 7  loss: 0.00216815\n",
      "epoch: 214  batch: 8  loss: 0.00113537\n",
      "epoch: 214  batch: 9  loss: 0.00319326\n",
      "epoch: 214  batch: 10  loss: 0.00249020\n",
      "epoch: 214  batch: 11  loss: 0.00260788\n",
      "epoch: 214  batch: 12  loss: 0.00091489\n",
      "epoch: 214  batch: 13  loss: 0.00481417\n",
      "epoch: 214  batch: 14  loss: 0.00217891\n",
      "epoch: 214  batch: 15  loss: 0.00255663\n",
      "epoch: 214  batch: 16  loss: 0.00439724\n",
      "epoch: 214  batch: 17  loss: 0.00198290\n",
      "epoch: 214  batch: 18  loss: 0.00208323\n",
      "epoch: 214  batch: 19  loss: 0.00077125\n",
      "epoch: 214  batch: 20  loss: 0.00074062\n",
      "epoch: 214  batch: 21  loss: 0.00628777\n",
      "epoch: 214  batch: 22  loss: 0.00495150\n",
      "epoch: 214  batch: 23  loss: 0.00228817\n",
      "epoch: 214  batch: 24  loss: 0.00150080\n",
      "epoch: 214  batch: 25  loss: 0.00971333\n",
      "epoch: 214  batch: 26  loss: 0.09727366\n",
      "epoch: 214  batch: 27  loss: 0.01398967\n",
      "epoch: 214  batch: 28  loss: 0.00690776\n",
      "epoch: 215  batch: 1  loss: 0.01226986\n",
      "epoch: 215  batch: 2  loss: 0.00260203\n",
      "epoch: 215  batch: 3  loss: 0.01524442\n",
      "epoch: 215  batch: 4  loss: 0.00251485\n",
      "epoch: 215  batch: 5  loss: 0.00190772\n",
      "epoch: 215  batch: 6  loss: 0.00109171\n",
      "epoch: 215  batch: 7  loss: 0.01131922\n",
      "epoch: 215  batch: 8  loss: 0.00601941\n",
      "epoch: 215  batch: 9  loss: 0.00840063\n",
      "epoch: 215  batch: 10  loss: 0.00594265\n",
      "epoch: 215  batch: 11  loss: 0.00098449\n",
      "epoch: 215  batch: 12  loss: 0.00484140\n",
      "epoch: 215  batch: 13  loss: 0.00527087\n",
      "epoch: 215  batch: 14  loss: 0.00336764\n",
      "epoch: 215  batch: 15  loss: 0.00977174\n",
      "epoch: 215  batch: 16  loss: 0.00159827\n",
      "epoch: 215  batch: 17  loss: 0.00436376\n",
      "epoch: 215  batch: 18  loss: 0.00532916\n",
      "epoch: 215  batch: 19  loss: 0.00400082\n",
      "epoch: 215  batch: 20  loss: 0.00680835\n",
      "epoch: 215  batch: 21  loss: 0.00523585\n",
      "epoch: 215  batch: 22  loss: 0.00301299\n",
      "epoch: 215  batch: 23  loss: 0.00150170\n",
      "epoch: 215  batch: 24  loss: 0.01733590\n",
      "epoch: 215  batch: 25  loss: 0.00144616\n",
      "epoch: 215  batch: 26  loss: 0.00971218\n",
      "epoch: 215  batch: 27  loss: 0.00555670\n",
      "epoch: 215  batch: 28  loss: 0.00480414\n",
      "epoch: 216  batch: 1  loss: 0.00272702\n",
      "epoch: 216  batch: 2  loss: 0.00495111\n",
      "epoch: 216  batch: 3  loss: 0.00178977\n",
      "epoch: 216  batch: 4  loss: 0.01086600\n",
      "epoch: 216  batch: 5  loss: 0.00337805\n",
      "epoch: 216  batch: 6  loss: 0.00328008\n",
      "epoch: 216  batch: 7  loss: 0.00531389\n",
      "epoch: 216  batch: 8  loss: 0.02247683\n",
      "epoch: 216  batch: 9  loss: 0.00720489\n",
      "epoch: 216  batch: 10  loss: 0.08948305\n",
      "epoch: 216  batch: 11  loss: 0.00700158\n",
      "epoch: 216  batch: 12  loss: 0.00539652\n",
      "epoch: 216  batch: 13  loss: 0.00258382\n",
      "epoch: 216  batch: 14  loss: 0.00071384\n",
      "epoch: 216  batch: 15  loss: 0.00379956\n",
      "epoch: 216  batch: 16  loss: 0.00215093\n",
      "epoch: 216  batch: 17  loss: 0.00415390\n",
      "epoch: 216  batch: 18  loss: 0.00245669\n",
      "epoch: 216  batch: 19  loss: 0.00332347\n",
      "epoch: 216  batch: 20  loss: 0.00287532\n",
      "epoch: 216  batch: 21  loss: 0.02375965\n",
      "epoch: 216  batch: 22  loss: 0.00179057\n",
      "epoch: 216  batch: 23  loss: 0.00511012\n",
      "epoch: 216  batch: 24  loss: 0.00268989\n",
      "epoch: 216  batch: 25  loss: 0.00168123\n",
      "epoch: 216  batch: 26  loss: 0.00265516\n",
      "epoch: 216  batch: 27  loss: 0.00491869\n",
      "epoch: 216  batch: 28  loss: 0.00356341\n",
      "epoch: 217  batch: 1  loss: 0.00171562\n",
      "epoch: 217  batch: 2  loss: 0.01876517\n",
      "epoch: 217  batch: 3  loss: 0.00132753\n",
      "epoch: 217  batch: 4  loss: 0.00692608\n",
      "epoch: 217  batch: 5  loss: 0.00940882\n",
      "epoch: 217  batch: 6  loss: 0.00196095\n",
      "epoch: 217  batch: 7  loss: 0.00395818\n",
      "epoch: 217  batch: 8  loss: 0.00636943\n",
      "epoch: 217  batch: 9  loss: 0.00227216\n",
      "epoch: 217  batch: 10  loss: 0.00431823\n",
      "epoch: 217  batch: 11  loss: 0.00557307\n",
      "epoch: 217  batch: 12  loss: 0.00447688\n",
      "epoch: 217  batch: 13  loss: 0.00269280\n",
      "epoch: 217  batch: 14  loss: 0.00324043\n",
      "epoch: 217  batch: 15  loss: 0.01581261\n",
      "epoch: 217  batch: 16  loss: 0.00363004\n",
      "epoch: 217  batch: 17  loss: 0.00176839\n",
      "epoch: 217  batch: 18  loss: 0.00516041\n",
      "epoch: 217  batch: 19  loss: 0.00770834\n",
      "epoch: 217  batch: 20  loss: 0.00773555\n",
      "epoch: 217  batch: 21  loss: 0.00440627\n",
      "epoch: 217  batch: 22  loss: 0.00399452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 217  batch: 23  loss: 0.00138590\n",
      "epoch: 217  batch: 24  loss: 0.00400470\n",
      "epoch: 217  batch: 25  loss: 0.00082338\n",
      "epoch: 217  batch: 26  loss: 0.00242047\n",
      "epoch: 217  batch: 27  loss: 0.00621947\n",
      "epoch: 217  batch: 28  loss: 0.00913760\n",
      "epoch: 218  batch: 1  loss: 0.01364012\n",
      "epoch: 218  batch: 2  loss: 0.00246996\n",
      "epoch: 218  batch: 3  loss: 0.00555656\n",
      "epoch: 218  batch: 4  loss: 0.00240500\n",
      "epoch: 218  batch: 5  loss: 0.00589209\n",
      "epoch: 218  batch: 6  loss: 0.00372585\n",
      "epoch: 218  batch: 7  loss: 0.00521355\n",
      "epoch: 218  batch: 8  loss: 0.00158989\n",
      "epoch: 218  batch: 9  loss: 0.00363951\n",
      "epoch: 218  batch: 10  loss: 0.00365461\n",
      "epoch: 218  batch: 11  loss: 0.00257936\n",
      "epoch: 218  batch: 12  loss: 0.00173797\n",
      "epoch: 218  batch: 13  loss: 0.00311718\n",
      "epoch: 218  batch: 14  loss: 0.00333543\n",
      "epoch: 218  batch: 15  loss: 0.00542112\n",
      "epoch: 218  batch: 16  loss: 0.00737910\n",
      "epoch: 218  batch: 17  loss: 0.00332221\n",
      "epoch: 218  batch: 18  loss: 0.00386110\n",
      "epoch: 218  batch: 19  loss: 0.00173345\n",
      "epoch: 218  batch: 20  loss: 0.00182027\n",
      "epoch: 218  batch: 21  loss: 0.00135954\n",
      "epoch: 218  batch: 22  loss: 0.01970012\n",
      "epoch: 218  batch: 23  loss: 0.00820265\n",
      "epoch: 218  batch: 24  loss: 0.00474819\n",
      "epoch: 218  batch: 25  loss: 0.00058243\n",
      "epoch: 218  batch: 26  loss: 0.00523680\n",
      "epoch: 218  batch: 27  loss: 0.00228927\n",
      "epoch: 218  batch: 28  loss: 0.00370114\n",
      "epoch: 219  batch: 1  loss: 0.00153320\n",
      "epoch: 219  batch: 2  loss: 0.00129942\n",
      "epoch: 219  batch: 3  loss: 0.00173703\n",
      "epoch: 219  batch: 4  loss: 0.00185321\n",
      "epoch: 219  batch: 5  loss: 0.00430500\n",
      "epoch: 219  batch: 6  loss: 0.00571658\n",
      "epoch: 219  batch: 7  loss: 0.00339506\n",
      "epoch: 219  batch: 8  loss: 0.00956795\n",
      "epoch: 219  batch: 9  loss: 0.00954638\n",
      "epoch: 219  batch: 10  loss: 0.00258523\n",
      "epoch: 219  batch: 11  loss: 0.00291215\n",
      "epoch: 219  batch: 12  loss: 0.01771298\n",
      "epoch: 219  batch: 13  loss: 0.00241779\n",
      "epoch: 219  batch: 14  loss: 0.00931072\n",
      "epoch: 219  batch: 15  loss: 0.00080514\n",
      "epoch: 219  batch: 16  loss: 0.00187168\n",
      "epoch: 219  batch: 17  loss: 0.00143317\n",
      "epoch: 219  batch: 18  loss: 0.00467155\n",
      "epoch: 219  batch: 19  loss: 0.01043006\n",
      "epoch: 219  batch: 20  loss: 0.00196414\n",
      "epoch: 219  batch: 21  loss: 0.00187894\n",
      "epoch: 219  batch: 22  loss: 0.00666188\n",
      "epoch: 219  batch: 23  loss: 0.00587030\n",
      "epoch: 219  batch: 24  loss: 0.00360944\n",
      "epoch: 219  batch: 25  loss: 0.00201248\n",
      "epoch: 219  batch: 26  loss: 0.00815109\n",
      "epoch: 219  batch: 27  loss: 0.00355009\n",
      "epoch: 219  batch: 28  loss: 0.01029595\n",
      "epoch: 220  batch: 1  loss: 0.00872736\n",
      "epoch: 220  batch: 2  loss: 0.00219179\n",
      "epoch: 220  batch: 3  loss: 0.00693744\n",
      "epoch: 220  batch: 4  loss: 0.00529156\n",
      "epoch: 220  batch: 5  loss: 0.00363696\n",
      "epoch: 220  batch: 6  loss: 0.01814977\n",
      "epoch: 220  batch: 7  loss: 0.00228429\n",
      "epoch: 220  batch: 8  loss: 0.00881462\n",
      "epoch: 220  batch: 9  loss: 0.00099687\n",
      "epoch: 220  batch: 10  loss: 0.00513806\n",
      "epoch: 220  batch: 11  loss: 0.00248656\n",
      "epoch: 220  batch: 12  loss: 0.00498562\n",
      "epoch: 220  batch: 13  loss: 0.00073249\n",
      "epoch: 220  batch: 14  loss: 0.00452995\n",
      "epoch: 220  batch: 15  loss: 0.00427073\n",
      "epoch: 220  batch: 16  loss: 0.01186948\n",
      "epoch: 220  batch: 17  loss: 0.00544273\n",
      "epoch: 220  batch: 18  loss: 0.00144530\n",
      "epoch: 220  batch: 19  loss: 0.00520940\n",
      "epoch: 220  batch: 20  loss: 0.00130524\n",
      "epoch: 220  batch: 21  loss: 0.00214761\n",
      "epoch: 220  batch: 22  loss: 0.01277418\n",
      "epoch: 220  batch: 23  loss: 0.00711284\n",
      "epoch: 220  batch: 24  loss: 0.00181615\n",
      "epoch: 220  batch: 25  loss: 0.00416290\n",
      "epoch: 220  batch: 26  loss: 0.00521591\n",
      "epoch: 220  batch: 27  loss: 0.00507070\n",
      "epoch: 220  batch: 28  loss: 0.00803099\n",
      "epoch: 221  batch: 1  loss: 0.03639117\n",
      "epoch: 221  batch: 2  loss: 0.00274101\n",
      "epoch: 221  batch: 3  loss: 0.00221210\n",
      "epoch: 221  batch: 4  loss: 0.00706997\n",
      "epoch: 221  batch: 5  loss: 0.00167295\n",
      "epoch: 221  batch: 6  loss: 0.00319041\n",
      "epoch: 221  batch: 7  loss: 0.00281644\n",
      "epoch: 221  batch: 8  loss: 0.00105036\n",
      "epoch: 221  batch: 9  loss: 0.00219141\n",
      "epoch: 221  batch: 10  loss: 0.00933785\n",
      "epoch: 221  batch: 11  loss: 0.00087704\n",
      "epoch: 221  batch: 12  loss: 0.00241374\n",
      "epoch: 221  batch: 13  loss: 0.00251469\n",
      "epoch: 221  batch: 14  loss: 0.00669090\n",
      "epoch: 221  batch: 15  loss: 0.00244277\n",
      "epoch: 221  batch: 16  loss: 0.00907434\n",
      "epoch: 221  batch: 17  loss: 0.00516205\n",
      "epoch: 221  batch: 18  loss: 0.00222710\n",
      "epoch: 221  batch: 19  loss: 0.00613742\n",
      "epoch: 221  batch: 20  loss: 0.00300418\n",
      "epoch: 221  batch: 21  loss: 0.00426200\n",
      "epoch: 221  batch: 22  loss: 0.00476779\n",
      "epoch: 221  batch: 23  loss: 0.02406150\n",
      "epoch: 221  batch: 24  loss: 0.00712764\n",
      "epoch: 221  batch: 25  loss: 0.00712396\n",
      "epoch: 221  batch: 26  loss: 0.00287267\n",
      "epoch: 221  batch: 27  loss: 0.00126773\n",
      "epoch: 221  batch: 28  loss: 0.00483681\n",
      "epoch: 222  batch: 1  loss: 0.00094413\n",
      "epoch: 222  batch: 2  loss: 0.00188005\n",
      "epoch: 222  batch: 3  loss: 0.00288936\n",
      "epoch: 222  batch: 4  loss: 0.00221283\n",
      "epoch: 222  batch: 5  loss: 0.05255626\n",
      "epoch: 222  batch: 6  loss: 0.02146248\n",
      "epoch: 222  batch: 7  loss: 0.00461792\n",
      "epoch: 222  batch: 8  loss: 0.00627644\n",
      "epoch: 222  batch: 9  loss: 0.00424797\n",
      "epoch: 222  batch: 10  loss: 0.01472552\n",
      "epoch: 222  batch: 11  loss: 0.00315201\n",
      "epoch: 222  batch: 12  loss: 0.00257795\n",
      "epoch: 222  batch: 13  loss: 0.00528081\n",
      "epoch: 222  batch: 14  loss: 0.00127042\n",
      "epoch: 222  batch: 15  loss: 0.00357860\n",
      "epoch: 222  batch: 16  loss: 0.00210395\n",
      "epoch: 222  batch: 17  loss: 0.00146250\n",
      "epoch: 222  batch: 18  loss: 0.00579240\n",
      "epoch: 222  batch: 19  loss: 0.00250746\n",
      "epoch: 222  batch: 20  loss: 0.01047779\n",
      "epoch: 222  batch: 21  loss: 0.00744463\n",
      "epoch: 222  batch: 22  loss: 0.00181795\n",
      "epoch: 222  batch: 23  loss: 0.02511564\n",
      "epoch: 222  batch: 24  loss: 0.00354089\n",
      "epoch: 222  batch: 25  loss: 0.00265718\n",
      "epoch: 222  batch: 26  loss: 0.00307453\n",
      "epoch: 222  batch: 27  loss: 0.00766519\n",
      "epoch: 222  batch: 28  loss: 0.00136618\n",
      "epoch: 223  batch: 1  loss: 0.00562782\n",
      "epoch: 223  batch: 2  loss: 0.00254600\n",
      "epoch: 223  batch: 3  loss: 0.00347529\n",
      "epoch: 223  batch: 4  loss: 0.00265207\n",
      "epoch: 223  batch: 5  loss: 0.00591234\n",
      "epoch: 223  batch: 6  loss: 0.00152549\n",
      "epoch: 223  batch: 7  loss: 0.00763914\n",
      "epoch: 223  batch: 8  loss: 0.00222680\n",
      "epoch: 223  batch: 9  loss: 0.00215933\n",
      "epoch: 223  batch: 10  loss: 0.00095038\n",
      "epoch: 223  batch: 11  loss: 0.02617520\n",
      "epoch: 223  batch: 12  loss: 0.00213293\n",
      "epoch: 223  batch: 13  loss: 0.00231993\n",
      "epoch: 223  batch: 14  loss: 0.00459884\n",
      "epoch: 223  batch: 15  loss: 0.00354220\n",
      "epoch: 223  batch: 16  loss: 0.00676587\n",
      "epoch: 223  batch: 17  loss: 0.00374939\n",
      "epoch: 223  batch: 18  loss: 0.00485567\n",
      "epoch: 223  batch: 19  loss: 0.00971477\n",
      "epoch: 223  batch: 20  loss: 0.02393805\n",
      "epoch: 223  batch: 21  loss: 0.00194788\n",
      "epoch: 223  batch: 22  loss: 0.00291242\n",
      "epoch: 223  batch: 23  loss: 0.00395959\n",
      "epoch: 223  batch: 24  loss: 0.00340793\n",
      "epoch: 223  batch: 25  loss: 0.00484231\n",
      "epoch: 223  batch: 26  loss: 0.00553123\n",
      "epoch: 223  batch: 27  loss: 0.00272338\n",
      "epoch: 223  batch: 28  loss: 0.00411725\n",
      "epoch: 224  batch: 1  loss: 0.00321431\n",
      "epoch: 224  batch: 2  loss: 0.00227792\n",
      "epoch: 224  batch: 3  loss: 0.00164985\n",
      "epoch: 224  batch: 4  loss: 0.00167358\n",
      "epoch: 224  batch: 5  loss: 0.00708106\n",
      "epoch: 224  batch: 6  loss: 0.00315614\n",
      "epoch: 224  batch: 7  loss: 0.01170340\n",
      "epoch: 224  batch: 8  loss: 0.00569448\n",
      "epoch: 224  batch: 9  loss: 0.00498134\n",
      "epoch: 224  batch: 10  loss: 0.00331561\n",
      "epoch: 224  batch: 11  loss: 0.00601142\n",
      "epoch: 224  batch: 12  loss: 0.00124430\n",
      "epoch: 224  batch: 13  loss: 0.00917688\n",
      "epoch: 224  batch: 14  loss: 0.00440588\n",
      "epoch: 224  batch: 15  loss: 0.00116876\n",
      "epoch: 224  batch: 16  loss: 0.00305209\n",
      "epoch: 224  batch: 17  loss: 0.00194738\n",
      "epoch: 224  batch: 18  loss: 0.00591902\n",
      "epoch: 224  batch: 19  loss: 0.00147246\n",
      "epoch: 224  batch: 20  loss: 0.00416169\n",
      "epoch: 224  batch: 21  loss: 0.00314386\n",
      "epoch: 224  batch: 22  loss: 0.00449666\n",
      "epoch: 224  batch: 23  loss: 0.00190232\n",
      "epoch: 224  batch: 24  loss: 0.00569904\n",
      "epoch: 224  batch: 25  loss: 0.00410233\n",
      "epoch: 224  batch: 26  loss: 0.02175758\n",
      "epoch: 224  batch: 27  loss: 0.00263778\n",
      "epoch: 224  batch: 28  loss: 0.02955476\n",
      "epoch: 225  batch: 1  loss: 0.00688619\n",
      "epoch: 225  batch: 2  loss: 0.00777856\n",
      "epoch: 225  batch: 3  loss: 0.00183774\n",
      "epoch: 225  batch: 4  loss: 0.00355322\n",
      "epoch: 225  batch: 5  loss: 0.00425726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 225  batch: 6  loss: 0.00468394\n",
      "epoch: 225  batch: 7  loss: 0.02123985\n",
      "epoch: 225  batch: 8  loss: 0.01476820\n",
      "epoch: 225  batch: 9  loss: 0.00700381\n",
      "epoch: 225  batch: 10  loss: 0.00455163\n",
      "epoch: 225  batch: 11  loss: 0.00757772\n",
      "epoch: 225  batch: 12  loss: 0.00569533\n",
      "epoch: 225  batch: 13  loss: 0.00197219\n",
      "epoch: 225  batch: 14  loss: 0.00316611\n",
      "epoch: 225  batch: 15  loss: 0.00454642\n",
      "epoch: 225  batch: 16  loss: 0.00437483\n",
      "epoch: 225  batch: 17  loss: 0.00973735\n",
      "epoch: 225  batch: 18  loss: 0.00739588\n",
      "epoch: 225  batch: 19  loss: 0.00288890\n",
      "epoch: 225  batch: 20  loss: 0.00969771\n",
      "epoch: 225  batch: 21  loss: 0.00201379\n",
      "epoch: 225  batch: 22  loss: 0.00234213\n",
      "epoch: 225  batch: 23  loss: 0.00435830\n",
      "epoch: 225  batch: 24  loss: 0.00125655\n",
      "epoch: 225  batch: 25  loss: 0.00043669\n",
      "epoch: 225  batch: 26  loss: 0.00442627\n",
      "epoch: 225  batch: 27  loss: 0.00435637\n",
      "epoch: 225  batch: 28  loss: 0.00388112\n",
      "epoch: 226  batch: 1  loss: 0.00681695\n",
      "epoch: 226  batch: 2  loss: 0.00926599\n",
      "epoch: 226  batch: 3  loss: 0.00657666\n",
      "epoch: 226  batch: 4  loss: 0.01470578\n",
      "epoch: 226  batch: 5  loss: 0.00218450\n",
      "epoch: 226  batch: 6  loss: 0.00324658\n",
      "epoch: 226  batch: 7  loss: 0.00282192\n",
      "epoch: 226  batch: 8  loss: 0.00861583\n",
      "epoch: 226  batch: 9  loss: 0.00191947\n",
      "epoch: 226  batch: 10  loss: 0.00261739\n",
      "epoch: 226  batch: 11  loss: 0.00297079\n",
      "epoch: 226  batch: 12  loss: 0.02198533\n",
      "epoch: 226  batch: 13  loss: 0.00352540\n",
      "epoch: 226  batch: 14  loss: 0.01725559\n",
      "epoch: 226  batch: 15  loss: 0.00334023\n",
      "epoch: 226  batch: 16  loss: 0.00370260\n",
      "epoch: 226  batch: 17  loss: 0.00361698\n",
      "epoch: 226  batch: 18  loss: 0.00184746\n",
      "epoch: 226  batch: 19  loss: 0.00771481\n",
      "epoch: 226  batch: 20  loss: 0.00131052\n",
      "epoch: 226  batch: 21  loss: 0.00465284\n",
      "epoch: 226  batch: 22  loss: 0.00452042\n",
      "epoch: 226  batch: 23  loss: 0.00055996\n",
      "epoch: 226  batch: 24  loss: 0.01003845\n",
      "epoch: 226  batch: 25  loss: 0.00268173\n",
      "epoch: 226  batch: 26  loss: 0.00152744\n",
      "epoch: 226  batch: 27  loss: 0.00184098\n",
      "epoch: 226  batch: 28  loss: 0.00473319\n",
      "epoch: 227  batch: 1  loss: 0.00368048\n",
      "epoch: 227  batch: 2  loss: 0.00244081\n",
      "epoch: 227  batch: 3  loss: 0.00323116\n",
      "epoch: 227  batch: 4  loss: 0.00198622\n",
      "epoch: 227  batch: 5  loss: 0.00522883\n",
      "epoch: 227  batch: 6  loss: 0.02632345\n",
      "epoch: 227  batch: 7  loss: 0.09041345\n",
      "epoch: 227  batch: 8  loss: 0.00350839\n",
      "epoch: 227  batch: 9  loss: 0.00501813\n",
      "epoch: 227  batch: 10  loss: 0.00284188\n",
      "epoch: 227  batch: 11  loss: 0.00589413\n",
      "epoch: 227  batch: 12  loss: 0.00155606\n",
      "epoch: 227  batch: 13  loss: 0.00366147\n",
      "epoch: 227  batch: 14  loss: 0.00359826\n",
      "epoch: 227  batch: 15  loss: 0.00359373\n",
      "epoch: 227  batch: 16  loss: 0.00511950\n",
      "epoch: 227  batch: 17  loss: 0.00633522\n",
      "epoch: 227  batch: 18  loss: 0.00195716\n",
      "epoch: 227  batch: 19  loss: 0.00484398\n",
      "epoch: 227  batch: 20  loss: 0.00246998\n",
      "epoch: 227  batch: 21  loss: 0.01088627\n",
      "epoch: 227  batch: 22  loss: 0.00275590\n",
      "epoch: 227  batch: 23  loss: 0.01448584\n",
      "epoch: 227  batch: 24  loss: 0.00292412\n",
      "epoch: 227  batch: 25  loss: 0.00425461\n",
      "epoch: 227  batch: 26  loss: 0.00396267\n",
      "epoch: 227  batch: 27  loss: 0.00617213\n",
      "epoch: 227  batch: 28  loss: 0.00338489\n",
      "epoch: 228  batch: 1  loss: 0.00515627\n",
      "epoch: 228  batch: 2  loss: 0.00132406\n",
      "epoch: 228  batch: 3  loss: 0.00195141\n",
      "epoch: 228  batch: 4  loss: 0.00573018\n",
      "epoch: 228  batch: 5  loss: 0.00243174\n",
      "epoch: 228  batch: 6  loss: 0.00272917\n",
      "epoch: 228  batch: 7  loss: 0.00450345\n",
      "epoch: 228  batch: 8  loss: 0.00397676\n",
      "epoch: 228  batch: 9  loss: 0.00424389\n",
      "epoch: 228  batch: 10  loss: 0.02459729\n",
      "epoch: 228  batch: 11  loss: 0.01425267\n",
      "epoch: 228  batch: 12  loss: 0.00630629\n",
      "epoch: 228  batch: 13  loss: 0.00214019\n",
      "epoch: 228  batch: 14  loss: 0.00247558\n",
      "epoch: 228  batch: 15  loss: 0.00134909\n",
      "epoch: 228  batch: 16  loss: 0.00298159\n",
      "epoch: 228  batch: 17  loss: 0.00638797\n",
      "epoch: 228  batch: 18  loss: 0.00445149\n",
      "epoch: 228  batch: 19  loss: 0.00544508\n",
      "epoch: 228  batch: 20  loss: 0.01913865\n",
      "epoch: 228  batch: 21  loss: 0.00679319\n",
      "epoch: 228  batch: 22  loss: 0.00296924\n",
      "epoch: 228  batch: 23  loss: 0.00518033\n",
      "epoch: 228  batch: 24  loss: 0.00446747\n",
      "epoch: 228  batch: 25  loss: 0.00101397\n",
      "epoch: 228  batch: 26  loss: 0.00295171\n",
      "epoch: 228  batch: 27  loss: 0.00280492\n",
      "epoch: 228  batch: 28  loss: 0.01138148\n",
      "epoch: 229  batch: 1  loss: 0.01493686\n",
      "epoch: 229  batch: 2  loss: 0.00818190\n",
      "epoch: 229  batch: 3  loss: 0.00330683\n",
      "epoch: 229  batch: 4  loss: 0.00371473\n",
      "epoch: 229  batch: 5  loss: 0.00606471\n",
      "epoch: 229  batch: 6  loss: 0.00155531\n",
      "epoch: 229  batch: 7  loss: 0.00727490\n",
      "epoch: 229  batch: 8  loss: 0.00377048\n",
      "epoch: 229  batch: 9  loss: 0.00224639\n",
      "epoch: 229  batch: 10  loss: 0.02310867\n",
      "epoch: 229  batch: 11  loss: 0.00279326\n",
      "epoch: 229  batch: 12  loss: 0.00120350\n",
      "epoch: 229  batch: 13  loss: 0.00313000\n",
      "epoch: 229  batch: 14  loss: 0.00104913\n",
      "epoch: 229  batch: 15  loss: 0.00981271\n",
      "epoch: 229  batch: 16  loss: 0.00478653\n",
      "epoch: 229  batch: 17  loss: 0.00464464\n",
      "epoch: 229  batch: 18  loss: 0.00525575\n",
      "epoch: 229  batch: 19  loss: 0.01697682\n",
      "epoch: 229  batch: 20  loss: 0.00290097\n",
      "epoch: 229  batch: 21  loss: 0.00449324\n",
      "epoch: 229  batch: 22  loss: 0.00207804\n",
      "epoch: 229  batch: 23  loss: 0.00140482\n",
      "epoch: 229  batch: 24  loss: 0.00825959\n",
      "epoch: 229  batch: 25  loss: 0.00572011\n",
      "epoch: 229  batch: 26  loss: 0.00657329\n",
      "epoch: 229  batch: 27  loss: 0.00551968\n",
      "epoch: 229  batch: 28  loss: 0.00212720\n",
      "epoch: 230  batch: 1  loss: 0.00437903\n",
      "epoch: 230  batch: 2  loss: 0.00260708\n",
      "epoch: 230  batch: 3  loss: 0.00290093\n",
      "epoch: 230  batch: 4  loss: 0.00372531\n",
      "epoch: 230  batch: 5  loss: 0.00241747\n",
      "epoch: 230  batch: 6  loss: 0.00597815\n",
      "epoch: 230  batch: 7  loss: 0.00094964\n",
      "epoch: 230  batch: 8  loss: 0.00958560\n",
      "epoch: 230  batch: 9  loss: 0.00314723\n",
      "epoch: 230  batch: 10  loss: 0.02876302\n",
      "epoch: 230  batch: 11  loss: 0.00798468\n",
      "epoch: 230  batch: 12  loss: 0.00904423\n",
      "epoch: 230  batch: 13  loss: 0.00668514\n",
      "epoch: 230  batch: 14  loss: 0.00383102\n",
      "epoch: 230  batch: 15  loss: 0.00407951\n",
      "epoch: 230  batch: 16  loss: 0.00154220\n",
      "epoch: 230  batch: 17  loss: 0.00266328\n",
      "epoch: 230  batch: 18  loss: 0.00416933\n",
      "epoch: 230  batch: 19  loss: 0.01544158\n",
      "epoch: 230  batch: 20  loss: 0.00418573\n",
      "epoch: 230  batch: 21  loss: 0.00974181\n",
      "epoch: 230  batch: 22  loss: 0.00161876\n",
      "epoch: 230  batch: 23  loss: 0.00225583\n",
      "epoch: 230  batch: 24  loss: 0.00534105\n",
      "epoch: 230  batch: 25  loss: 0.00261659\n",
      "epoch: 230  batch: 26  loss: 0.00446284\n",
      "epoch: 230  batch: 27  loss: 0.00512823\n",
      "epoch: 230  batch: 28  loss: 0.00389662\n",
      "epoch: 231  batch: 1  loss: 0.02485416\n",
      "epoch: 231  batch: 2  loss: 0.00246856\n",
      "epoch: 231  batch: 3  loss: 0.00446674\n",
      "epoch: 231  batch: 4  loss: 0.00311923\n",
      "epoch: 231  batch: 5  loss: 0.00393309\n",
      "epoch: 231  batch: 6  loss: 0.00377037\n",
      "epoch: 231  batch: 7  loss: 0.00876830\n",
      "epoch: 231  batch: 8  loss: 0.00990894\n",
      "epoch: 231  batch: 9  loss: 0.00473015\n",
      "epoch: 231  batch: 10  loss: 0.00130590\n",
      "epoch: 231  batch: 11  loss: 0.00668778\n",
      "epoch: 231  batch: 12  loss: 0.00415406\n",
      "epoch: 231  batch: 13  loss: 0.01245339\n",
      "epoch: 231  batch: 14  loss: 0.00224475\n",
      "epoch: 231  batch: 15  loss: 0.00560125\n",
      "epoch: 231  batch: 16  loss: 0.00212650\n",
      "epoch: 231  batch: 17  loss: 0.00184282\n",
      "epoch: 231  batch: 18  loss: 0.00510931\n",
      "epoch: 231  batch: 19  loss: 0.02069975\n",
      "epoch: 231  batch: 20  loss: 0.00865470\n",
      "epoch: 231  batch: 21  loss: 0.00311245\n",
      "epoch: 231  batch: 22  loss: 0.00873667\n",
      "epoch: 231  batch: 23  loss: 0.00470984\n",
      "epoch: 231  batch: 24  loss: 0.00143327\n",
      "epoch: 231  batch: 25  loss: 0.00090924\n",
      "epoch: 231  batch: 26  loss: 0.00153541\n",
      "epoch: 231  batch: 27  loss: 0.00305120\n",
      "epoch: 231  batch: 28  loss: 0.00320590\n",
      "epoch: 232  batch: 1  loss: 0.00193907\n",
      "epoch: 232  batch: 2  loss: 0.00714697\n",
      "epoch: 232  batch: 3  loss: 0.00114747\n",
      "epoch: 232  batch: 4  loss: 0.00415792\n",
      "epoch: 232  batch: 5  loss: 0.00260622\n",
      "epoch: 232  batch: 6  loss: 0.00400064\n",
      "epoch: 232  batch: 7  loss: 0.00307108\n",
      "epoch: 232  batch: 8  loss: 0.00500708\n",
      "epoch: 232  batch: 9  loss: 0.00097122\n",
      "epoch: 232  batch: 10  loss: 0.00339574\n",
      "epoch: 232  batch: 11  loss: 0.00338913\n",
      "epoch: 232  batch: 12  loss: 0.00165444\n",
      "epoch: 232  batch: 13  loss: 0.00536421\n",
      "epoch: 232  batch: 14  loss: 0.00138830\n",
      "epoch: 232  batch: 15  loss: 0.01354609\n",
      "epoch: 232  batch: 16  loss: 0.02435243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 232  batch: 17  loss: 0.00273762\n",
      "epoch: 232  batch: 18  loss: 0.01251213\n",
      "epoch: 232  batch: 19  loss: 0.00159747\n",
      "epoch: 232  batch: 20  loss: 0.00451995\n",
      "epoch: 232  batch: 21  loss: 0.00402270\n",
      "epoch: 232  batch: 22  loss: 0.00423519\n",
      "epoch: 232  batch: 23  loss: 0.00243320\n",
      "epoch: 232  batch: 24  loss: 0.00180809\n",
      "epoch: 232  batch: 25  loss: 0.00287524\n",
      "epoch: 232  batch: 26  loss: 0.01089550\n",
      "epoch: 232  batch: 27  loss: 0.00390047\n",
      "epoch: 232  batch: 28  loss: 0.00720427\n",
      "epoch: 233  batch: 1  loss: 0.00362789\n",
      "epoch: 233  batch: 2  loss: 0.00851104\n",
      "epoch: 233  batch: 3  loss: 0.00361556\n",
      "epoch: 233  batch: 4  loss: 0.00240242\n",
      "epoch: 233  batch: 5  loss: 0.00460789\n",
      "epoch: 233  batch: 6  loss: 0.00467869\n",
      "epoch: 233  batch: 7  loss: 0.02385299\n",
      "epoch: 233  batch: 8  loss: 0.00996107\n",
      "epoch: 233  batch: 9  loss: 0.00090099\n",
      "epoch: 233  batch: 10  loss: 0.00430845\n",
      "epoch: 233  batch: 11  loss: 0.00267027\n",
      "epoch: 233  batch: 12  loss: 0.00236450\n",
      "epoch: 233  batch: 13  loss: 0.00385709\n",
      "epoch: 233  batch: 14  loss: 0.00152142\n",
      "epoch: 233  batch: 15  loss: 0.00219852\n",
      "epoch: 233  batch: 16  loss: 0.00319620\n",
      "epoch: 233  batch: 17  loss: 0.00373541\n",
      "epoch: 233  batch: 18  loss: 0.00127140\n",
      "epoch: 233  batch: 19  loss: 0.00377650\n",
      "epoch: 233  batch: 20  loss: 0.00510418\n",
      "epoch: 233  batch: 21  loss: 0.00930748\n",
      "epoch: 233  batch: 22  loss: 0.00344222\n",
      "epoch: 233  batch: 23  loss: 0.00657907\n",
      "epoch: 233  batch: 24  loss: 0.01107971\n",
      "epoch: 233  batch: 25  loss: 0.00647188\n",
      "epoch: 233  batch: 26  loss: 0.00416601\n",
      "epoch: 233  batch: 27  loss: 0.00487484\n",
      "epoch: 233  batch: 28  loss: 0.00312987\n",
      "epoch: 234  batch: 1  loss: 0.00175166\n",
      "epoch: 234  batch: 2  loss: 0.00729547\n",
      "epoch: 234  batch: 3  loss: 0.00583207\n",
      "epoch: 234  batch: 4  loss: 0.00244801\n",
      "epoch: 234  batch: 5  loss: 0.00127960\n",
      "epoch: 234  batch: 6  loss: 0.00692402\n",
      "epoch: 234  batch: 7  loss: 0.00247737\n",
      "epoch: 234  batch: 8  loss: 0.00363561\n",
      "epoch: 234  batch: 9  loss: 0.00737906\n",
      "epoch: 234  batch: 10  loss: 0.00189399\n",
      "epoch: 234  batch: 11  loss: 0.00266217\n",
      "epoch: 234  batch: 12  loss: 0.01078700\n",
      "epoch: 234  batch: 13  loss: 0.00990548\n",
      "epoch: 234  batch: 14  loss: 0.00480590\n",
      "epoch: 234  batch: 15  loss: 0.01409237\n",
      "epoch: 234  batch: 16  loss: 0.00549613\n",
      "epoch: 234  batch: 17  loss: 0.00250460\n",
      "epoch: 234  batch: 18  loss: 0.00266337\n",
      "epoch: 234  batch: 19  loss: 0.00105979\n",
      "epoch: 234  batch: 20  loss: 0.00402491\n",
      "epoch: 234  batch: 21  loss: 0.00530590\n",
      "epoch: 234  batch: 22  loss: 0.00271567\n",
      "epoch: 234  batch: 23  loss: 0.02369622\n",
      "epoch: 234  batch: 24  loss: 0.00459869\n",
      "epoch: 234  batch: 25  loss: 0.00263032\n",
      "epoch: 234  batch: 26  loss: 0.00152824\n",
      "epoch: 234  batch: 27  loss: 0.00320004\n",
      "epoch: 234  batch: 28  loss: 0.01425684\n",
      "epoch: 235  batch: 1  loss: 0.00068914\n",
      "epoch: 235  batch: 2  loss: 0.00254522\n",
      "epoch: 235  batch: 3  loss: 0.00207721\n",
      "epoch: 235  batch: 4  loss: 0.00540480\n",
      "epoch: 235  batch: 5  loss: 0.00272026\n",
      "epoch: 235  batch: 6  loss: 0.00273016\n",
      "epoch: 235  batch: 7  loss: 0.00206479\n",
      "epoch: 235  batch: 8  loss: 0.00557997\n",
      "epoch: 235  batch: 9  loss: 0.00535477\n",
      "epoch: 235  batch: 10  loss: 0.00932713\n",
      "epoch: 235  batch: 11  loss: 0.00584640\n",
      "epoch: 235  batch: 12  loss: 0.00606456\n",
      "epoch: 235  batch: 13  loss: 0.00614826\n",
      "epoch: 235  batch: 14  loss: 0.00238620\n",
      "epoch: 235  batch: 15  loss: 0.00366466\n",
      "epoch: 235  batch: 16  loss: 0.00392888\n",
      "epoch: 235  batch: 17  loss: 0.00964641\n",
      "epoch: 235  batch: 18  loss: 0.00309145\n",
      "epoch: 235  batch: 19  loss: 0.00313745\n",
      "epoch: 235  batch: 20  loss: 0.00233056\n",
      "epoch: 235  batch: 21  loss: 0.00758397\n",
      "epoch: 235  batch: 22  loss: 0.02126285\n",
      "epoch: 235  batch: 23  loss: 0.00332849\n",
      "epoch: 235  batch: 24  loss: 0.01364495\n",
      "epoch: 235  batch: 25  loss: 0.00485553\n",
      "epoch: 235  batch: 26  loss: 0.00195629\n",
      "epoch: 235  batch: 27  loss: 0.00414528\n",
      "epoch: 235  batch: 28  loss: 0.00179723\n",
      "epoch: 236  batch: 1  loss: 0.00409814\n",
      "epoch: 236  batch: 2  loss: 0.00705009\n",
      "epoch: 236  batch: 3  loss: 0.00545843\n",
      "epoch: 236  batch: 4  loss: 0.00267869\n",
      "epoch: 236  batch: 5  loss: 0.00364254\n",
      "epoch: 236  batch: 6  loss: 0.00852738\n",
      "epoch: 236  batch: 7  loss: 0.00584604\n",
      "epoch: 236  batch: 8  loss: 0.00168644\n",
      "epoch: 236  batch: 9  loss: 0.00435399\n",
      "epoch: 236  batch: 10  loss: 0.01785230\n",
      "epoch: 236  batch: 11  loss: 0.00158445\n",
      "epoch: 236  batch: 12  loss: 0.00368889\n",
      "epoch: 236  batch: 13  loss: 0.00819774\n",
      "epoch: 236  batch: 14  loss: 0.00229382\n",
      "epoch: 236  batch: 15  loss: 0.00459353\n",
      "epoch: 236  batch: 16  loss: 0.00311460\n",
      "epoch: 236  batch: 17  loss: 0.00315993\n",
      "epoch: 236  batch: 18  loss: 0.00162263\n",
      "epoch: 236  batch: 19  loss: 0.00891600\n",
      "epoch: 236  batch: 20  loss: 0.00446833\n",
      "epoch: 236  batch: 21  loss: 0.00457743\n",
      "epoch: 236  batch: 22  loss: 0.01365484\n",
      "epoch: 236  batch: 23  loss: 0.02013263\n",
      "epoch: 236  batch: 24  loss: 0.00232971\n",
      "epoch: 236  batch: 25  loss: 0.00534045\n",
      "epoch: 236  batch: 26  loss: 0.00300507\n",
      "epoch: 236  batch: 27  loss: 0.00908466\n",
      "epoch: 236  batch: 28  loss: 0.00349893\n",
      "epoch: 237  batch: 1  loss: 0.00170094\n",
      "epoch: 237  batch: 2  loss: 0.00160201\n",
      "epoch: 237  batch: 3  loss: 0.00472652\n",
      "epoch: 237  batch: 4  loss: 0.00139467\n",
      "epoch: 237  batch: 5  loss: 0.00141849\n",
      "epoch: 237  batch: 6  loss: 0.00315307\n",
      "epoch: 237  batch: 7  loss: 0.00539919\n",
      "epoch: 237  batch: 8  loss: 0.00268169\n",
      "epoch: 237  batch: 9  loss: 0.00133972\n",
      "epoch: 237  batch: 10  loss: 0.00574612\n",
      "epoch: 237  batch: 11  loss: 0.00626011\n",
      "epoch: 237  batch: 12  loss: 0.00124366\n",
      "epoch: 237  batch: 13  loss: 0.00274690\n",
      "epoch: 237  batch: 14  loss: 0.00477435\n",
      "epoch: 237  batch: 15  loss: 0.00330740\n",
      "epoch: 237  batch: 16  loss: 0.00437888\n",
      "epoch: 237  batch: 17  loss: 0.00268205\n",
      "epoch: 237  batch: 18  loss: 0.00629490\n",
      "epoch: 237  batch: 19  loss: 0.02482582\n",
      "epoch: 237  batch: 20  loss: 0.00469849\n",
      "epoch: 237  batch: 21  loss: 0.00318662\n",
      "epoch: 237  batch: 22  loss: 0.01690978\n",
      "epoch: 237  batch: 23  loss: 0.00222429\n",
      "epoch: 237  batch: 24  loss: 0.01425579\n",
      "epoch: 237  batch: 25  loss: 0.00391129\n",
      "epoch: 237  batch: 26  loss: 0.00372836\n",
      "epoch: 237  batch: 27  loss: 0.00907423\n",
      "epoch: 237  batch: 28  loss: 0.00279493\n",
      "epoch: 238  batch: 1  loss: 0.00349932\n",
      "epoch: 238  batch: 2  loss: 0.00116095\n",
      "epoch: 238  batch: 3  loss: 0.00187622\n",
      "epoch: 238  batch: 4  loss: 0.00188082\n",
      "epoch: 238  batch: 5  loss: 0.00290471\n",
      "epoch: 238  batch: 6  loss: 0.00213536\n",
      "epoch: 238  batch: 7  loss: 0.01629037\n",
      "epoch: 238  batch: 8  loss: 0.00672006\n",
      "epoch: 238  batch: 9  loss: 0.01908145\n",
      "epoch: 238  batch: 10  loss: 0.00682552\n",
      "epoch: 238  batch: 11  loss: 0.00480207\n",
      "epoch: 238  batch: 12  loss: 0.00408235\n",
      "epoch: 238  batch: 13  loss: 0.01376516\n",
      "epoch: 238  batch: 14  loss: 0.00122204\n",
      "epoch: 238  batch: 15  loss: 0.01084808\n",
      "epoch: 238  batch: 16  loss: 0.00358603\n",
      "epoch: 238  batch: 17  loss: 0.00300723\n",
      "epoch: 238  batch: 18  loss: 0.00548659\n",
      "epoch: 238  batch: 19  loss: 0.00445948\n",
      "epoch: 238  batch: 20  loss: 0.00269888\n",
      "epoch: 238  batch: 21  loss: 0.00523549\n",
      "epoch: 238  batch: 22  loss: 0.07060067\n",
      "epoch: 238  batch: 23  loss: 0.01062196\n",
      "epoch: 238  batch: 24  loss: 0.00632389\n",
      "epoch: 238  batch: 25  loss: 0.00213909\n",
      "epoch: 238  batch: 26  loss: 0.00178212\n",
      "epoch: 238  batch: 27  loss: 0.00445797\n",
      "epoch: 238  batch: 28  loss: 0.00302410\n",
      "epoch: 239  batch: 1  loss: 0.00353294\n",
      "epoch: 239  batch: 2  loss: 0.01291090\n",
      "epoch: 239  batch: 3  loss: 0.00217256\n",
      "epoch: 239  batch: 4  loss: 0.00985709\n",
      "epoch: 239  batch: 5  loss: 0.00855726\n",
      "epoch: 239  batch: 6  loss: 0.00096814\n",
      "epoch: 239  batch: 7  loss: 0.00140311\n",
      "epoch: 239  batch: 8  loss: 0.00417474\n",
      "epoch: 239  batch: 9  loss: 0.00249583\n",
      "epoch: 239  batch: 10  loss: 0.00517194\n",
      "epoch: 239  batch: 11  loss: 0.00089381\n",
      "epoch: 239  batch: 12  loss: 0.00128180\n",
      "epoch: 239  batch: 13  loss: 0.00486587\n",
      "epoch: 239  batch: 14  loss: 0.00083573\n",
      "epoch: 239  batch: 15  loss: 0.00216844\n",
      "epoch: 239  batch: 16  loss: 0.00859059\n",
      "epoch: 239  batch: 17  loss: 0.00263930\n",
      "epoch: 239  batch: 18  loss: 0.01031637\n",
      "epoch: 239  batch: 19  loss: 0.02209805\n",
      "epoch: 239  batch: 20  loss: 0.01258906\n",
      "epoch: 239  batch: 21  loss: 0.00203936\n",
      "epoch: 239  batch: 22  loss: 0.00619388\n",
      "epoch: 239  batch: 23  loss: 0.00456493\n",
      "epoch: 239  batch: 24  loss: 0.00531697\n",
      "epoch: 239  batch: 25  loss: 0.00283727\n",
      "epoch: 239  batch: 26  loss: 0.00355621\n",
      "epoch: 239  batch: 27  loss: 0.00174480\n",
      "epoch: 239  batch: 28  loss: 0.00298831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 240  batch: 1  loss: 0.00155367\n",
      "epoch: 240  batch: 2  loss: 0.01246096\n",
      "epoch: 240  batch: 3  loss: 0.00448113\n",
      "epoch: 240  batch: 4  loss: 0.00168005\n",
      "epoch: 240  batch: 5  loss: 0.00371817\n",
      "epoch: 240  batch: 6  loss: 0.00327788\n",
      "epoch: 240  batch: 7  loss: 0.00697038\n",
      "epoch: 240  batch: 8  loss: 0.00306899\n",
      "epoch: 240  batch: 9  loss: 0.00861995\n",
      "epoch: 240  batch: 10  loss: 0.00462668\n",
      "epoch: 240  batch: 11  loss: 0.00379119\n",
      "epoch: 240  batch: 12  loss: 0.02998002\n",
      "epoch: 240  batch: 13  loss: 0.00394808\n",
      "epoch: 240  batch: 14  loss: 0.00580151\n",
      "epoch: 240  batch: 15  loss: 0.00456455\n",
      "epoch: 240  batch: 16  loss: 0.00108965\n",
      "epoch: 240  batch: 17  loss: 0.00750567\n",
      "epoch: 240  batch: 18  loss: 0.00497876\n",
      "epoch: 240  batch: 19  loss: 0.00953124\n",
      "epoch: 240  batch: 20  loss: 0.00641900\n",
      "epoch: 240  batch: 21  loss: 0.00816988\n",
      "epoch: 240  batch: 22  loss: 0.00945110\n",
      "epoch: 240  batch: 23  loss: 0.00332543\n",
      "epoch: 240  batch: 24  loss: 0.00541315\n",
      "epoch: 240  batch: 25  loss: 0.00557011\n",
      "epoch: 240  batch: 26  loss: 0.00084424\n",
      "epoch: 240  batch: 27  loss: 0.00102704\n",
      "epoch: 240  batch: 28  loss: 0.00132947\n",
      "epoch: 241  batch: 1  loss: 0.00604661\n",
      "epoch: 241  batch: 2  loss: 0.00487949\n",
      "epoch: 241  batch: 3  loss: 0.00161172\n",
      "epoch: 241  batch: 4  loss: 0.00205403\n",
      "epoch: 241  batch: 5  loss: 0.00658858\n",
      "epoch: 241  batch: 6  loss: 0.00502529\n",
      "epoch: 241  batch: 7  loss: 0.00233378\n",
      "epoch: 241  batch: 8  loss: 0.00403850\n",
      "epoch: 241  batch: 9  loss: 0.00197499\n",
      "epoch: 241  batch: 10  loss: 0.00442339\n",
      "epoch: 241  batch: 11  loss: 0.02502728\n",
      "epoch: 241  batch: 12  loss: 0.00741221\n",
      "epoch: 241  batch: 13  loss: 0.00327102\n",
      "epoch: 241  batch: 14  loss: 0.00517364\n",
      "epoch: 241  batch: 15  loss: 0.00249704\n",
      "epoch: 241  batch: 16  loss: 0.00164027\n",
      "epoch: 241  batch: 17  loss: 0.00328191\n",
      "epoch: 241  batch: 18  loss: 0.00654325\n",
      "epoch: 241  batch: 19  loss: 0.00539033\n",
      "epoch: 241  batch: 20  loss: 0.00542216\n",
      "epoch: 241  batch: 21  loss: 0.00306090\n",
      "epoch: 241  batch: 22  loss: 0.00929646\n",
      "epoch: 241  batch: 23  loss: 0.00416901\n",
      "epoch: 241  batch: 24  loss: 0.00523288\n",
      "epoch: 241  batch: 25  loss: 0.00272110\n",
      "epoch: 241  batch: 26  loss: 0.00910474\n",
      "epoch: 241  batch: 27  loss: 0.00386198\n",
      "epoch: 241  batch: 28  loss: 0.00080100\n",
      "epoch: 242  batch: 1  loss: 0.00599611\n",
      "epoch: 242  batch: 2  loss: 0.00199747\n",
      "epoch: 242  batch: 3  loss: 0.00565964\n",
      "epoch: 242  batch: 4  loss: 0.00471554\n",
      "epoch: 242  batch: 5  loss: 0.00772745\n",
      "epoch: 242  batch: 6  loss: 0.00211958\n",
      "epoch: 242  batch: 7  loss: 0.00637611\n",
      "epoch: 242  batch: 8  loss: 0.01668354\n",
      "epoch: 242  batch: 9  loss: 0.00523285\n",
      "epoch: 242  batch: 10  loss: 0.01105813\n",
      "epoch: 242  batch: 11  loss: 0.00215041\n",
      "epoch: 242  batch: 12  loss: 0.00287048\n",
      "epoch: 242  batch: 13  loss: 0.00089907\n",
      "epoch: 242  batch: 14  loss: 0.00075769\n",
      "epoch: 242  batch: 15  loss: 0.00340402\n",
      "epoch: 242  batch: 16  loss: 0.03036836\n",
      "epoch: 242  batch: 17  loss: 0.00508020\n",
      "epoch: 242  batch: 18  loss: 0.00747645\n",
      "epoch: 242  batch: 19  loss: 0.00300913\n",
      "epoch: 242  batch: 20  loss: 0.00278235\n",
      "epoch: 242  batch: 21  loss: 0.00395922\n",
      "epoch: 242  batch: 22  loss: 0.00674082\n",
      "epoch: 242  batch: 23  loss: 0.00289538\n",
      "epoch: 242  batch: 24  loss: 0.00477346\n",
      "epoch: 242  batch: 25  loss: 0.00142270\n",
      "epoch: 242  batch: 26  loss: 0.00048175\n",
      "epoch: 242  batch: 27  loss: 0.00123749\n",
      "epoch: 242  batch: 28  loss: 0.00155237\n",
      "epoch: 243  batch: 1  loss: 0.01075465\n",
      "epoch: 243  batch: 2  loss: 0.00186268\n",
      "epoch: 243  batch: 3  loss: 0.00773889\n",
      "epoch: 243  batch: 4  loss: 0.00095982\n",
      "epoch: 243  batch: 5  loss: 0.00454723\n",
      "epoch: 243  batch: 6  loss: 0.00464526\n",
      "epoch: 243  batch: 7  loss: 0.01552561\n",
      "epoch: 243  batch: 8  loss: 0.00330935\n",
      "epoch: 243  batch: 9  loss: 0.02636987\n",
      "epoch: 243  batch: 10  loss: 0.00648565\n",
      "epoch: 243  batch: 11  loss: 0.00205589\n",
      "epoch: 243  batch: 12  loss: 0.00460007\n",
      "epoch: 243  batch: 13  loss: 0.00607757\n",
      "epoch: 243  batch: 14  loss: 0.00314243\n",
      "epoch: 243  batch: 15  loss: 0.00849984\n",
      "epoch: 243  batch: 16  loss: 0.00559121\n",
      "epoch: 243  batch: 17  loss: 0.00451368\n",
      "epoch: 243  batch: 18  loss: 0.00508160\n",
      "epoch: 243  batch: 19  loss: 0.00221134\n",
      "epoch: 243  batch: 20  loss: 0.00197341\n",
      "epoch: 243  batch: 21  loss: 0.00182955\n",
      "epoch: 243  batch: 22  loss: 0.00289249\n",
      "epoch: 243  batch: 23  loss: 0.00657662\n",
      "epoch: 243  batch: 24  loss: 0.00249818\n",
      "epoch: 243  batch: 25  loss: 0.00312998\n",
      "epoch: 243  batch: 26  loss: 0.00283350\n",
      "epoch: 243  batch: 27  loss: 0.00382913\n",
      "epoch: 243  batch: 28  loss: 0.01492654\n",
      "epoch: 244  batch: 1  loss: 0.00148016\n",
      "epoch: 244  batch: 2  loss: 0.00377100\n",
      "epoch: 244  batch: 3  loss: 0.00120598\n",
      "epoch: 244  batch: 4  loss: 0.00569404\n",
      "epoch: 244  batch: 5  loss: 0.00507492\n",
      "epoch: 244  batch: 6  loss: 0.01538403\n",
      "epoch: 244  batch: 7  loss: 0.00049475\n",
      "epoch: 244  batch: 8  loss: 0.00599988\n",
      "epoch: 244  batch: 9  loss: 0.00860369\n",
      "epoch: 244  batch: 10  loss: 0.00124215\n",
      "epoch: 244  batch: 11  loss: 0.00625678\n",
      "epoch: 244  batch: 12  loss: 0.00955956\n",
      "epoch: 244  batch: 13  loss: 0.00287798\n",
      "epoch: 244  batch: 14  loss: 0.00309222\n",
      "epoch: 244  batch: 15  loss: 0.02385157\n",
      "epoch: 244  batch: 16  loss: 0.11860394\n",
      "epoch: 244  batch: 17  loss: 0.00153159\n",
      "epoch: 244  batch: 18  loss: 0.00330168\n",
      "epoch: 244  batch: 19  loss: 0.00237398\n",
      "epoch: 244  batch: 20  loss: 0.00094217\n",
      "epoch: 244  batch: 21  loss: 0.00677469\n",
      "epoch: 244  batch: 22  loss: 0.00453445\n",
      "epoch: 244  batch: 23  loss: 0.00277891\n",
      "epoch: 244  batch: 24  loss: 0.00175062\n",
      "epoch: 244  batch: 25  loss: 0.00589470\n",
      "epoch: 244  batch: 26  loss: 0.00121722\n",
      "epoch: 244  batch: 27  loss: 0.00889388\n",
      "epoch: 244  batch: 28  loss: 0.00430106\n",
      "epoch: 245  batch: 1  loss: 0.00777994\n",
      "epoch: 245  batch: 2  loss: 0.00252436\n",
      "epoch: 245  batch: 3  loss: 0.00687226\n",
      "epoch: 245  batch: 4  loss: 0.00315362\n",
      "epoch: 245  batch: 5  loss: 0.00287080\n",
      "epoch: 245  batch: 6  loss: 0.00281607\n",
      "epoch: 245  batch: 7  loss: 0.00441892\n",
      "epoch: 245  batch: 8  loss: 0.00268543\n",
      "epoch: 245  batch: 9  loss: 0.02088411\n",
      "epoch: 245  batch: 10  loss: 0.01062570\n",
      "epoch: 245  batch: 11  loss: 0.00350845\n",
      "epoch: 245  batch: 12  loss: 0.00300496\n",
      "epoch: 245  batch: 13  loss: 0.00279071\n",
      "epoch: 245  batch: 14  loss: 0.00324126\n",
      "epoch: 245  batch: 15  loss: 0.00585500\n",
      "epoch: 245  batch: 16  loss: 0.00415310\n",
      "epoch: 245  batch: 17  loss: 0.00612189\n",
      "epoch: 245  batch: 18  loss: 0.00245660\n",
      "epoch: 245  batch: 19  loss: 0.00433839\n",
      "epoch: 245  batch: 20  loss: 0.00462721\n",
      "epoch: 245  batch: 21  loss: 0.00347417\n",
      "epoch: 245  batch: 22  loss: 0.00240423\n",
      "epoch: 245  batch: 23  loss: 0.00762994\n",
      "epoch: 245  batch: 24  loss: 0.00616255\n",
      "epoch: 245  batch: 25  loss: 0.00448109\n",
      "epoch: 245  batch: 26  loss: 0.00529838\n",
      "epoch: 245  batch: 27  loss: 0.00150326\n",
      "epoch: 245  batch: 28  loss: 0.00721820\n",
      "epoch: 246  batch: 1  loss: 0.00192508\n",
      "epoch: 246  batch: 2  loss: 0.00496930\n",
      "epoch: 246  batch: 3  loss: 0.00251581\n",
      "epoch: 246  batch: 4  loss: 0.00444384\n",
      "epoch: 246  batch: 5  loss: 0.00590674\n",
      "epoch: 246  batch: 6  loss: 0.00253765\n",
      "epoch: 246  batch: 7  loss: 0.00312047\n",
      "epoch: 246  batch: 8  loss: 0.00256367\n",
      "epoch: 246  batch: 9  loss: 0.00220952\n",
      "epoch: 246  batch: 10  loss: 0.00493126\n",
      "epoch: 246  batch: 11  loss: 0.00284047\n",
      "epoch: 246  batch: 12  loss: 0.00155247\n",
      "epoch: 246  batch: 13  loss: 0.00113880\n",
      "epoch: 246  batch: 14  loss: 0.01868499\n",
      "epoch: 246  batch: 15  loss: 0.00054586\n",
      "epoch: 246  batch: 16  loss: 0.00253089\n",
      "epoch: 246  batch: 17  loss: 0.00309821\n",
      "epoch: 246  batch: 18  loss: 0.02730123\n",
      "epoch: 246  batch: 19  loss: 0.00327024\n",
      "epoch: 246  batch: 20  loss: 0.00703506\n",
      "epoch: 246  batch: 21  loss: 0.00652805\n",
      "epoch: 246  batch: 22  loss: 0.00390187\n",
      "epoch: 246  batch: 23  loss: 0.00527868\n",
      "epoch: 246  batch: 24  loss: 0.01438821\n",
      "epoch: 246  batch: 25  loss: 0.00184305\n",
      "epoch: 246  batch: 26  loss: 0.00620323\n",
      "epoch: 246  batch: 27  loss: 0.00958204\n",
      "epoch: 246  batch: 28  loss: 0.01856618\n",
      "epoch: 247  batch: 1  loss: 0.00384606\n",
      "epoch: 247  batch: 2  loss: 0.00256838\n",
      "epoch: 247  batch: 3  loss: 0.00329401\n",
      "epoch: 247  batch: 4  loss: 0.00260339\n",
      "epoch: 247  batch: 5  loss: 0.01251655\n",
      "epoch: 247  batch: 6  loss: 0.01147317\n",
      "epoch: 247  batch: 7  loss: 0.00312422\n",
      "epoch: 247  batch: 8  loss: 0.00093929\n",
      "epoch: 247  batch: 9  loss: 0.00436032\n",
      "epoch: 247  batch: 10  loss: 0.00300565\n",
      "epoch: 247  batch: 11  loss: 0.00398427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 247  batch: 12  loss: 0.01356728\n",
      "epoch: 247  batch: 13  loss: 0.02968577\n",
      "epoch: 247  batch: 14  loss: 0.00126482\n",
      "epoch: 247  batch: 15  loss: 0.00650626\n",
      "epoch: 247  batch: 16  loss: 0.00304634\n",
      "epoch: 247  batch: 17  loss: 0.01316819\n",
      "epoch: 247  batch: 18  loss: 0.00413135\n",
      "epoch: 247  batch: 19  loss: 0.01058752\n",
      "epoch: 247  batch: 20  loss: 0.01179434\n",
      "epoch: 247  batch: 21  loss: 0.00350121\n",
      "epoch: 247  batch: 22  loss: 0.00791127\n",
      "epoch: 247  batch: 23  loss: 0.00420343\n",
      "epoch: 247  batch: 24  loss: 0.00116851\n",
      "epoch: 247  batch: 25  loss: 0.00375016\n",
      "epoch: 247  batch: 26  loss: 0.00206638\n",
      "epoch: 247  batch: 27  loss: 0.00332132\n",
      "epoch: 247  batch: 28  loss: 0.00939127\n",
      "epoch: 248  batch: 1  loss: 0.00514365\n",
      "epoch: 248  batch: 2  loss: 0.00188521\n",
      "epoch: 248  batch: 3  loss: 0.00483537\n",
      "epoch: 248  batch: 4  loss: 0.00095546\n",
      "epoch: 248  batch: 5  loss: 0.00269765\n",
      "epoch: 248  batch: 6  loss: 0.01010516\n",
      "epoch: 248  batch: 7  loss: 0.00569417\n",
      "epoch: 248  batch: 8  loss: 0.01076002\n",
      "epoch: 248  batch: 9  loss: 0.00413060\n",
      "epoch: 248  batch: 10  loss: 0.01383968\n",
      "epoch: 248  batch: 11  loss: 0.00283281\n",
      "epoch: 248  batch: 12  loss: 0.00273692\n",
      "epoch: 248  batch: 13  loss: 0.00506251\n",
      "epoch: 248  batch: 14  loss: 0.00047323\n",
      "epoch: 248  batch: 15  loss: 0.00090002\n",
      "epoch: 248  batch: 16  loss: 0.00539300\n",
      "epoch: 248  batch: 17  loss: 0.00403216\n",
      "epoch: 248  batch: 18  loss: 0.00919374\n",
      "epoch: 248  batch: 19  loss: 0.00309804\n",
      "epoch: 248  batch: 20  loss: 0.00359614\n",
      "epoch: 248  batch: 21  loss: 0.00467687\n",
      "epoch: 248  batch: 22  loss: 0.00786524\n",
      "epoch: 248  batch: 23  loss: 0.00155076\n",
      "epoch: 248  batch: 24  loss: 0.02966307\n",
      "epoch: 248  batch: 25  loss: 0.00511300\n",
      "epoch: 248  batch: 26  loss: 0.00329532\n",
      "epoch: 248  batch: 27  loss: 0.00232894\n",
      "epoch: 248  batch: 28  loss: 0.00322957\n",
      "epoch: 249  batch: 1  loss: 0.00335388\n",
      "epoch: 249  batch: 2  loss: 0.00366420\n",
      "epoch: 249  batch: 3  loss: 0.00487931\n",
      "epoch: 249  batch: 4  loss: 0.00674177\n",
      "epoch: 249  batch: 5  loss: 0.00715740\n",
      "epoch: 249  batch: 6  loss: 0.00092505\n",
      "epoch: 249  batch: 7  loss: 0.00492297\n",
      "epoch: 249  batch: 8  loss: 0.00289710\n",
      "epoch: 249  batch: 9  loss: 0.01121061\n",
      "epoch: 249  batch: 10  loss: 0.00514004\n",
      "epoch: 249  batch: 11  loss: 0.00132866\n",
      "epoch: 249  batch: 12  loss: 0.00128492\n",
      "epoch: 249  batch: 13  loss: 0.00288180\n",
      "epoch: 249  batch: 14  loss: 0.00728610\n",
      "epoch: 249  batch: 15  loss: 0.00531425\n",
      "epoch: 249  batch: 16  loss: 0.00202342\n",
      "epoch: 249  batch: 17  loss: 0.00209435\n",
      "epoch: 249  batch: 18  loss: 0.00624031\n",
      "epoch: 249  batch: 19  loss: 0.00153064\n",
      "epoch: 249  batch: 20  loss: 0.00661711\n",
      "epoch: 249  batch: 21  loss: 0.00693906\n",
      "epoch: 249  batch: 22  loss: 0.02317553\n",
      "epoch: 249  batch: 23  loss: 0.00639093\n",
      "epoch: 249  batch: 24  loss: 0.00275055\n",
      "epoch: 249  batch: 25  loss: 0.01455991\n",
      "epoch: 249  batch: 26  loss: 0.00341988\n",
      "epoch: 249  batch: 27  loss: 0.00730129\n",
      "epoch: 249  batch: 28  loss: 0.00200953\n",
      "epoch: 250  batch: 1  loss: 0.00167932\n",
      "epoch: 250  batch: 2  loss: 0.00287808\n",
      "epoch: 250  batch: 3  loss: 0.00198695\n",
      "epoch: 250  batch: 4  loss: 0.00400419\n",
      "epoch: 250  batch: 5  loss: 0.00167130\n",
      "epoch: 250  batch: 6  loss: 0.00224983\n",
      "epoch: 250  batch: 7  loss: 0.00437381\n",
      "epoch: 250  batch: 8  loss: 0.00440784\n",
      "epoch: 250  batch: 9  loss: 0.00624425\n",
      "epoch: 250  batch: 10  loss: 0.00457717\n",
      "epoch: 250  batch: 11  loss: 0.00271704\n",
      "epoch: 250  batch: 12  loss: 0.00324956\n",
      "epoch: 250  batch: 13  loss: 0.00686865\n",
      "epoch: 250  batch: 14  loss: 0.00944195\n",
      "epoch: 250  batch: 15  loss: 0.00286616\n",
      "epoch: 250  batch: 16  loss: 0.00457773\n",
      "epoch: 250  batch: 17  loss: 0.00265375\n",
      "epoch: 250  batch: 18  loss: 0.00115219\n",
      "epoch: 250  batch: 19  loss: 0.00220274\n",
      "epoch: 250  batch: 20  loss: 0.00955952\n",
      "epoch: 250  batch: 21  loss: 0.00157074\n",
      "epoch: 250  batch: 22  loss: 0.00269406\n",
      "epoch: 250  batch: 23  loss: 0.00889058\n",
      "epoch: 250  batch: 24  loss: 0.01893762\n",
      "epoch: 250  batch: 25  loss: 0.00310083\n",
      "epoch: 250  batch: 26  loss: 0.01960717\n",
      "epoch: 250  batch: 27  loss: 0.00981138\n",
      "epoch: 250  batch: 28  loss: 0.00235535\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        # Apply the model\n",
    "        y_pred = Model(X_train.cuda())\n",
    "        loss = criterion(y_pred, y_train.cuda())\n",
    "#         torch.cuda.empty_cache()\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%1 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    scheduler.step(loss)\n",
    "    \n",
    "    # Run the validationing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "            # Apply the model\n",
    "            y_val = Model(X_validation.cuda())\n",
    "    loss = criterion(y_val, y_validation.cuda())\n",
    "    validation_losses.append(loss.cpu().detach().numpy())\n",
    "#     validation_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad22f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:45:19.062350Z",
     "start_time": "2022-12-07T23:45:18.825803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(Model.state_dict(), 'AoR_MODEL6D_NEW2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7796f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:02:03.667976Z",
     "start_time": "2022-12-08T14:02:03.186037Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(validation_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend();\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(validation_losses, label='validation loss')\n",
    "plt.legend();\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fce3df",
   "metadata": {},
   "source": [
    "# Cheking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb8d7322",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:02:08.028376Z",
     "start_time": "2022-12-08T14:02:08.022006Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(color_im)\n",
    "    depth_raw = o3d.geometry.Image(depth_im)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "    PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,1,0]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e456c1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:02:08.957180Z",
     "start_time": "2022-12-08T14:02:08.949839Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                     std=[1/0.229, 1/0.224, 1/0.225])\n",
    "\n",
    "inv_resize = transforms.Resize(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c474164f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:03:46.987278Z",
     "start_time": "2022-12-08T14:02:26.461170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.26318,      0.66734,     -1.58974], [    -0.23421,     -0.74804,     -1.64120]]\n",
      "REAL:\n",
      "[[    -0.10797,      0.54656,     -1.41700], [    -0.09271,     -0.63447,     -1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.15521,      0.12079,      0.17274], [     0.14150,      0.11357,      0.12020]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.02949,      0.66142,     -3.11824], [     0.07687,     -1.10354,     -2.71482]]\n",
      "REAL:\n",
      "[[    -0.00797,      0.61028,     -2.77400], [     0.03546,     -1.03771,     -2.48200]]\n",
      "DIFFERENCE:\n",
      "[[     0.03746,      0.05114,      0.34424], [     0.04142,      0.06583,      0.23282]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.36805,      0.73013,     -1.76877], [    -0.34213,     -0.74554,     -1.74618]]\n",
      "REAL:\n",
      "[[    -0.40718,      0.68764,     -1.77400], [    -0.35904,     -0.70196,     -1.69050]]\n",
      "DIFFERENCE:\n",
      "[[     0.03913,      0.04250,      0.00523], [     0.01691,      0.04358,      0.05568]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.10209,      0.36562,     -1.29180], [     0.10836,     -0.23635,     -1.42266]]\n",
      "REAL:\n",
      "[[     0.09985,      0.33770,     -1.17800], [     0.10780,     -0.15744,     -1.30100]]\n",
      "DIFFERENCE:\n",
      "[[     0.00224,      0.02792,      0.11380], [     0.00056,      0.07891,      0.12166]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.35945,      0.63617,     -2.14115], [    -0.30843,     -0.72586,     -1.70822]]\n",
      "REAL:\n",
      "[[    -0.29337,      0.60727,     -1.96200], [    -0.26306,     -0.69510,     -1.67400]]\n",
      "DIFFERENCE:\n",
      "[[     0.06608,      0.02890,      0.17915], [     0.04537,      0.03076,      0.03422]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.31597,      0.76033,     -1.92753], [    -0.26265,     -0.78027,     -1.86675]]\n",
      "REAL:\n",
      "[[    -0.19092,      0.68764,     -1.77400], [    -0.13623,     -0.76245,     -1.83600]]\n",
      "DIFFERENCE:\n",
      "[[     0.12505,      0.07269,      0.15353], [     0.12642,      0.01782,      0.03075]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.09880,      0.36782,     -1.26651], [     0.10493,     -0.17880,     -1.42389]]\n",
      "REAL:\n",
      "[[     0.09985,      0.33770,     -1.17800], [     0.10780,     -0.15744,     -1.30100]]\n",
      "DIFFERENCE:\n",
      "[[     0.00105,      0.03012,      0.08851], [     0.00286,      0.02136,      0.12289]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 8 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.19443,      0.73557,     -1.88872], [    -0.17901,     -0.81562,     -1.95309]]\n",
      "REAL:\n",
      "[[    -0.40449,      0.78571,     -2.03200], [    -0.40372,     -0.85402,     -2.03800]]\n",
      "DIFFERENCE:\n",
      "[[     0.21005,      0.05014,      0.14328], [     0.22471,      0.03840,      0.08491]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 9 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.20425,      0.20215,     -1.88223], [     0.21838,     -0.44417,     -1.74537]]\n",
      "REAL:\n",
      "[[     0.22801,      0.17823,     -1.68600], [     0.23168,     -0.33602,     -1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.02377,      0.02392,      0.19623], [     0.01329,      0.10816,      0.13437]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 10 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.62316,      0.01771,     -1.30663], [     0.60450,     -0.27830,     -1.33132]]\n",
      "REAL:\n",
      "[[     0.44540,      0.13033,     -1.19000], [     0.44683,     -0.33906,     -1.24450]]\n",
      "DIFFERENCE:\n",
      "[[     0.17775,      0.11263,      0.11663], [     0.15768,      0.06076,      0.08682]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 11 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.35357,      0.92848,     -2.46168], [    -0.34467,     -0.94302,     -2.44992]]\n",
      "REAL:\n",
      "[[    -0.35608,      0.78571,     -2.03200], [    -0.35593,     -0.85225,     -2.02000]]\n",
      "DIFFERENCE:\n",
      "[[     0.00251,      0.14277,      0.42968], [     0.01126,      0.09077,      0.42992]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 12 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.03753,      0.62978,     -2.19478], [     0.01872,     -0.92415,     -2.20556]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.05780,      0.01642,      0.06778], [     0.05252,      0.00253,      0.01094]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 13 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01380,      0.49142,     -1.97335], [     0.01939,     -0.75481,     -1.93524]]\n",
      "REAL:\n",
      "[[     0.00538,      0.48417,     -1.89700], [     0.03751,     -0.77899,     -1.87600]]\n",
      "DIFFERENCE:\n",
      "[[     0.01918,      0.00725,      0.07635], [     0.01812,      0.02418,      0.05924]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 14 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01764,      0.52085,     -2.03133], [     0.00934,     -0.81432,     -1.98249]]\n",
      "REAL:\n",
      "[[     0.02836,      0.48563,     -1.86100], [     0.06203,     -0.77453,     -1.86100]]\n",
      "DIFFERENCE:\n",
      "[[     0.04600,      0.03522,      0.17033], [     0.05269,      0.03979,      0.12149]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 15 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.26697,      0.77940,     -1.85090], [    -0.22453,     -0.79058,     -1.90878]]\n",
      "REAL:\n",
      "[[    -0.19092,      0.68764,     -1.77400], [    -0.13623,     -0.76245,     -1.83600]]\n",
      "DIFFERENCE:\n",
      "[[     0.07605,      0.09176,      0.07690], [     0.08829,      0.02813,      0.07278]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 16 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.66832,     -0.02169,     -1.26542], [     0.66035,     -0.26473,     -1.30080]]\n",
      "REAL:\n",
      "[[     0.44540,      0.13033,     -1.19000], [     0.44683,     -0.33906,     -1.24450]]\n",
      "DIFFERENCE:\n",
      "[[     0.22291,      0.15202,      0.07542], [     0.21352,      0.07433,      0.05630]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('AoR_MODEL6D_NEW2.pt'))\n",
    "Model.eval()\n",
    "\n",
    "# torch.manual_seed(101)\n",
    "with torch.no_grad():\n",
    "    for b, (X_validation, y_validation) in enumerate(validation_loader):\n",
    "#         Apply the model\n",
    "        y_val = Model(X_validation)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_validation[j])\n",
    "            RGB_buff = inv_normalize(torch.stack((X_invNorm[0],X_invNorm[1],X_invNorm[2]))).numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "            RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "            DEPTH_buff = X_invNorm[3].numpy()*65535\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_validation[j][0].cpu().numpy(), y_validation[j][1].cpu().numpy(), y_validation[j][2].cpu().numpy()],\n",
    "                    [y_validation[j][3].cpu().numpy(), y_validation[j][4].cpu().numpy(), y_validation[j][5].cpu().numpy()]]\n",
    "            draw_arrow(PC, REAL, PREDICTED)\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_validation[j][0]:12.5f}, {y_validation[j][1]:12.5f}, {y_validation[j][2]:12.5f}], [{y_validation[j][3]:12.5f}, {y_validation[j][4]:12.5f}, {y_validation[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "# loss = criterion(y_val, y_validation.cuda())\n",
    "# diff = np.abs(y_val.cpu().numpy()-y_validation.cpu().numpy())\n",
    "# print(f'RMSE: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80527311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:24:54.658379Z",
     "start_time": "2022-12-07T01:24:54.651930Z"
    }
   },
   "outputs": [],
   "source": [
    "Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d673a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T01:23:02.960717Z",
     "start_time": "2022-12-07T01:23:02.957955Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49c8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351666d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28057c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b361d4100cabf439e872d27edcfc9e968620b5cc1a2991a8793a2beed62efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
