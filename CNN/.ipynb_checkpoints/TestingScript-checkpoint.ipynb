{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d70ecdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:34.718247Z",
     "start_time": "2022-12-07T23:46:34.711937Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import open3d as o3d\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2190b7",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c4c59bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:34.974790Z",
     "start_time": "2022-12-07T23:46:34.957311Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./testFiles/data.csv') \n",
    "df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17c7a87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.110701Z",
     "start_time": "2022-12-07T23:46:35.099159Z"
    }
   },
   "outputs": [],
   "source": [
    "TrasformData = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "ResizeData = transforms.Resize(480)\n",
    "\n",
    "\n",
    "def load_rgb_dataset(top_dir='./files/images/rgb_img_I'):\n",
    "    images_dataset = []\n",
    "    for root, dirs, files in os.walk(top_dir):\n",
    "        for name in files:\n",
    "            # print(os.path.join(root, name))\n",
    "            img = np.array(Image.open(os.path.join(root, name)))\n",
    "            np.array(images_dataset.append(img))\n",
    "    return np.array(images_dataset)\n",
    "\n",
    "def load_depth_dataset(depth_series, row=0):    \n",
    "    depth_dataset = []\n",
    "    for n in range(depth_series.shape[0]):\n",
    "        depth = np.array(np.load(depth_series.iloc[n,row]))\n",
    "        np.array(depth_dataset.append(depth))\n",
    "    \n",
    "    return np.array(depth_dataset)\n",
    "\n",
    "def NormImage(img,div_val,reshape=False,transform=False):\n",
    "    if reshape == True:\n",
    "        img = img.reshape((img.shape[0], img.shape[1], img.shape[2], 1))\n",
    "                    \n",
    "    img = img.transpose(0,3,1,2)\n",
    "    img = torch.FloatTensor(img).div(div_val)\n",
    "    if transform == True:\n",
    "        img = TrasformData(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Functions \n",
    "def CreatePointCloud(color_im, depth_im):\n",
    "    color_raw = o3d.geometry.Image(color_im)\n",
    "    depth_raw = o3d.geometry.Image(depth_im)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw, 1000) # \n",
    "    PointCloud = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "      rgbd_image,o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)) # Creates Point Cloud from rgbd image\n",
    "    PointCloud.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]) # Flip it, otherwise the pointcloud will be upside down\n",
    "    return PointCloud\n",
    "\n",
    "def pick_points(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    numpy_array=np.asarray(pcd.points)\n",
    "    point_id=vis.get_picked_points()\n",
    "\n",
    "    return [numpy_array[point_id[0]],numpy_array[point_id[1]]]\n",
    "\n",
    "def draw_arrow(pcd, points_real, points_extimated):\n",
    "    lines=[[0,1],[2,3]]\n",
    "    points = np.concatenate((points_real, points_extimated), axis=0)\n",
    "    colors = [[1,0,0],[0,1,0]] # Red is REAL and Green is ESTIMATED\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(points),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "\n",
    "    )\n",
    "    line_set.colors=o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd,line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2c8f3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.556133Z",
     "start_time": "2022-12-07T23:46:35.245137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 3, 480, 640])\n",
      "torch.Size([7, 6, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "RGBimg_begin = load_rgb_dataset('./testFiles/images/rgb_img_I')\n",
    "RGBimg_end = load_rgb_dataset('./testFiles/images/rgb_img_II')\n",
    "DEPTHimg_begin = load_depth_dataset(df_INPUT_DEPTH,0)\n",
    "DEPTHimg_end = load_depth_dataset(df_INPUT_DEPTH,1)\n",
    "\n",
    "# Taking first rgb image\n",
    "rgb_in = NormImage(RGBimg_begin,255,transform=True)\n",
    "\n",
    "# Taking depth beginning state of the movement\n",
    "depthBeg_in = NormImage(DEPTHimg_begin,65535,reshape=True)\n",
    "\n",
    "# Taking depth end state of the movement\n",
    "depthEnd_in = NormImage(DEPTHimg_end,65535,reshape=True)\n",
    "\n",
    "# Taking depth difference between movements\n",
    "depthDiff_in = NormImage(abs(DEPTHimg_begin - DEPTHimg_end),65535,reshape=True)\n",
    "\n",
    "# Taking outputs\n",
    "y_test = df_OUTPUT.values\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# Connected input for model\n",
    "DDD_in = torch.cat((depthBeg_in, depthEnd_in, depthDiff_in),axis=1)\n",
    "# DDD_in = TrasformData(DDD_in)\n",
    "print(DDD_in.shape)\n",
    "\n",
    "X_test = ResizeData(torch.cat((rgb_in, DDD_in),axis=1))\n",
    "print(X_test.shape)\n",
    "# RGBD_input = DDD_in\n",
    "# RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47692263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.559869Z",
     "start_time": "2022-12-07T23:46:35.557928Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_testDataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52529293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.572468Z",
     "start_time": "2022-12-07T23:46:35.561488Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(depthDiff_in[2].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "495f9e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.672926Z",
     "start_time": "2022-12-07T23:46:35.670659Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(rgb_in[6].numpy(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96bf10d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:35.843787Z",
     "start_time": "2022-12-07T23:46:35.838402Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=6, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c1d2be74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:36.418506Z",
     "start_time": "2022-12-07T23:46:36.021486Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AoRNet(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = AoRNet()\n",
    "Model.load_state_dict(torch.load('AoR_MODEL6D_NEW2.pt'))\n",
    "Model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "239873d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:36.422302Z",
     "start_time": "2022-12-07T23:46:36.419858Z"
    }
   },
   "outputs": [],
   "source": [
    "inv_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                     std=[1/0.229, 1/0.224, 1/0.225])\n",
    "\n",
    "inv_resize = transforms.Resize(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89c86646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:46:55.834867Z",
     "start_time": "2022-12-07T23:46:36.576593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.16437,      0.67278,     -2.10925], [    -0.15724,     -0.77394,     -2.17099]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.28912,      0.03011,      0.45125], [     0.26262,      0.26503,      0.71499]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.12742,      0.60368,     -1.97150], [    -0.11926,     -0.71322,     -1.97476]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.25216,      0.03899,      0.31350], [     0.22465,      0.20432,      0.51876]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07774,      0.66530,     -2.10178], [    -0.11002,     -0.77316,     -2.11058]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.20249,      0.02263,      0.44378], [     0.21541,      0.26426,      0.65458]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.05863,      0.62930,     -2.07545], [    -0.08592,     -0.74467,     -2.07677]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.18337,      0.01337,      0.41745], [     0.19131,      0.23576,      0.62077]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 5 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.16618,      0.64943,     -2.09865], [    -0.15431,     -0.74887,     -2.12993]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.29093,      0.00676,      0.44065], [     0.25970,      0.23996,      0.67393]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 6 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.06483,      0.63288,     -2.07346], [    -0.09168,     -0.74449,     -2.07185]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.18957,      0.00980,      0.41546], [     0.19707,      0.23558,      0.61585]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 7 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07363,      0.65099,     -2.05501], [    -0.10193,     -0.75256,     -2.08201]]\n",
      "REAL:\n",
      "[[     0.12474,      0.64267,     -1.65800], [     0.10539,     -0.50891,     -1.45600]]\n",
      "DIFFERENCE:\n",
      "[[     0.19837,      0.00832,      0.39701], [     0.20731,      0.24365,      0.62601]]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(101)\n",
    "test_loader = DataLoader(AoRD_testDataset,batch_size=1, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(test_loader):\n",
    "#         Apply the model\n",
    "        y_val = Model(X_test)\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            X_invNorm = inv_resize(X_test[j])\n",
    "            RGB_buff = inv_normalize(torch.stack((X_invNorm[0],X_invNorm[1],X_invNorm[2]))).numpy()*255\n",
    "#             RGB_buff = np.stack((X_invNorm[0].numpy(),X_invNorm[1].numpy(),X_invNorm[2].numpy()))*255\n",
    "            RGB_buff = np.transpose(RGB_buff, (1,2,0))\n",
    "            RGB_buff = np.ascontiguousarray(RGB_buff, dtype=np.uint8)\n",
    "\n",
    "            DEPTH_buff = X_invNorm[3].numpy()*65535\n",
    "            PC = CreatePointCloud(RGB_buff, DEPTH_buff)\n",
    "            PREDICTED = [[y_val[j][0].cpu().numpy(), y_val[j][1].cpu().numpy(), y_val[j][2].cpu().numpy()],\n",
    "                         [y_val[j][3].cpu().numpy(), y_val[j][4].cpu().numpy(), y_val[j][5].cpu().numpy()]]\n",
    "            REAL = [[y_test[j][0].cpu().numpy(), y_test[j][1].cpu().numpy(), y_test[j][2].cpu().numpy()],\n",
    "                    [y_test[j][3].cpu().numpy(), y_test[j][4].cpu().numpy(), y_test[j][5].cpu().numpy()]]\n",
    "            draw_arrow(PC, REAL, PREDICTED)\n",
    "\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_test[j][0]:12.5f}, {y_test[j][1]:12.5f}, {y_test[j][2]:12.5f}], [{y_test[j][3]:12.5f}, {y_test[j][4]:12.5f}, {y_test[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_test.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "# loss = criterion(y_val, y_test.cuda())\n",
    "# diff = np.abs(y_val.cpu().numpy()-y_test.cpu().numpy())\n",
    "# print(f'RMSE: {loss:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac8d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "qqqqqqqqqqqqqqq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
