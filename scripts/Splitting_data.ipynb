{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1329c18e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:38:58.879709Z",
     "start_time": "2022-11-27T19:38:57.633962Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms, models # add models to the list\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Filter harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf2dd0",
   "metadata": {},
   "source": [
    "# Wczytanie pliku .csv\n",
    "Zaczynamy od wczytania pliku csv w którym są zapisane ścieżki do poszczególnych zdjęć oraz współrzędne punktów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6818c902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:38:58.886937Z",
     "start_time": "2022-11-27T19:38:58.880896Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./files/data.csv') \n",
    "df_INPUT_DEPTH = df[['depth_img_I', 'depth_img_II']]\n",
    "df_INPUT_RGB = df[['rgb_img_I', 'rgb_img_II']]\n",
    "df_OUTPUT = df[['x1','y1','z1','x2','y2','z2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ce45e",
   "metadata": {},
   "source": [
    "# Funkcje\n",
    "Stworzenie fukncji, które tłumaczą pliki na język matematyczny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb2102a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:38:58.899256Z",
     "start_time": "2022-11-27T19:38:58.887896Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_rgb_dataset(top_dir='./files/images/rgb_img_I'):\n",
    "    images_dataset = []\n",
    "    for root, dirs, files in os.walk(top_dir):\n",
    "        for name in files:\n",
    "            # print(os.path.join(root, name))\n",
    "            img = np.array(Image.open(os.path.join(root, name)))\n",
    "            np.array(images_dataset.append(img))\n",
    "    return np.array(images_dataset)\n",
    "\n",
    "def load_depth_dataset(depth_series, row=0):    \n",
    "    depth_dataset = []\n",
    "    for n in range(depth_series.shape[0]):\n",
    "        depth = np.array(np.load(depth_series.iloc[n,row]))\n",
    "        np.array(depth_dataset.append(depth))\n",
    "    \n",
    "    return np.array(depth_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68719e44",
   "metadata": {},
   "source": [
    "# Załadowanie danych\n",
    "Ładujemy dane do zmiennych a następnie odpowiednio przekształcamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b130e12a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:00.431502Z",
     "start_time": "2022-11-27T19:38:58.900663Z"
    }
   },
   "outputs": [],
   "source": [
    "RGBimg_begin = load_rgb_dataset('./files/images/rgb_img_I')\n",
    "RGBimg_end = load_rgb_dataset('./files/images/rgb_img_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201c2d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:00.659736Z",
     "start_time": "2022-11-27T19:39:00.432652Z"
    }
   },
   "outputs": [],
   "source": [
    "DEPTHimg_begin = load_depth_dataset(df_INPUT_DEPTH,0)\n",
    "DEPTHimg_end = load_depth_dataset(df_INPUT_DEPTH,1)\n",
    "# print(DEPTHimg_end[30][400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e31d631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.755562Z",
     "start_time": "2022-11-27T19:39:00.660810Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([149, 3, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "# Creating input for model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Taking first rgb image\n",
    "rgb_in = RGBimg_begin    \n",
    "rgb_in = rgb_in.transpose(0,3,1,2)\n",
    "rgb_in = torch.FloatTensor(rgb_in).div(255)\n",
    "rgb_in = transform(rgb_in)\n",
    "\n",
    "# Taking depth beginning state of the movement\n",
    "depthBeg_in = DEPTHimg_begin\n",
    "depthBeg_in = depthBeg_in.reshape((depthBeg_in.shape[0], depthBeg_in.shape[1], depthBeg_in.shape[2], 1))\n",
    "depthBeg_in = depthBeg_in.transpose(0,3,1,2)\n",
    "depthBeg_in = torch.FloatTensor(depthBeg_in).div(65535)\n",
    "\n",
    "# Taking depth end state of the movement\n",
    "depthEnd_in = DEPTHimg_end\n",
    "depthEnd_in = depthEnd_in.reshape((depthEnd_in.shape[0], depthEnd_in.shape[1], depthEnd_in.shape[2], 1))\n",
    "depthEnd_in = depthEnd_in.transpose(0,3,1,2)\n",
    "depthEnd_in = torch.Tensor(depthEnd_in).div(65535)\n",
    "\n",
    "# Taking depth difference between movements\n",
    "depthDiff_in = abs(DEPTHimg_begin - DEPTHimg_end)\n",
    "depthDiff_in = depthDiff_in.reshape((depthDiff_in.shape[0], depthDiff_in.shape[1], depthDiff_in.shape[2], 1))\n",
    "depthDiff_in = depthDiff_in.transpose(0,3,1,2)\n",
    "depthDiff_in = torch.Tensor(depthDiff_in).div(65535)\n",
    "\n",
    "# Taking outputs\n",
    "axis_out = df_OUTPUT.values\n",
    "axis_out = torch.Tensor(axis_out)\n",
    "\n",
    "# Koncowe wejście do modelu\n",
    "DDD_in = torch.cat((depthBeg_in, depthEnd_in, depthDiff_in),axis=1)\n",
    "DDD_in = transform(DDD_in)\n",
    "print(DDD_in.shape)\n",
    "\n",
    "RGBD_input = torch.cat((rgb_in, DDD_in),axis=1)\n",
    "# RGBD_input = DDD_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0844fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.760504Z",
     "start_time": "2022-11-27T19:39:01.756593Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149, 6, 480, 640])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RGBD_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d92a",
   "metadata": {},
   "source": [
    "# RGB + D \n",
    "Na wejście do modelu zostanie podany tensor zawieający kombinację RGB + D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2280a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.897577Z",
     "start_time": "2022-11-27T19:39:01.761504Z"
    }
   },
   "outputs": [],
   "source": [
    "# rgb_inTensor = torch.tensor(rgb_in.astype(float), dtype=torch.float)\n",
    "# depth_inTensor = torch.tensor(depth_in.astype(float), dtype=torch.float)\n",
    "# axis_outTensor = torch.tensor(axis_out.astype(float), dtype=torch.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(RGBD_input, axis_out, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce8d4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.900746Z",
     "start_time": "2022-11-27T19:39:01.899207Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.cuda()\n",
    "# X_test = X_test.cuda()\n",
    "# y_train = y_train.cuda()\n",
    "# y_test = y_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23db3ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.914480Z",
     "start_time": "2022-11-27T19:39:01.902909Z"
    }
   },
   "outputs": [],
   "source": [
    "AoRD_trainDataset = TensorDataset(X_train, y_train)\n",
    "AoRD_trainDataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f756c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.927542Z",
     "start_time": "2022-11-27T19:39:01.915721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(AoRD_trainDataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(AoRD_trainDataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a3ccde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.940444Z",
     "start_time": "2022-11-27T19:39:01.928544Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(depth_in[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23f0d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.953735Z",
     "start_time": "2022-11-27T19:39:01.941516Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(rgb_in[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e61e9bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.968854Z",
     "start_time": "2022-11-27T19:39:01.955016Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResNetModel = models.resnet101(pretrained=False)\n",
    "# ResNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "962968f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:01.985566Z",
     "start_time": "2022-11-27T19:39:01.970465Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResNetModel.conv1 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159076ba",
   "metadata": {},
   "source": [
    "# Wyciąganie pojedyńczego elementu z batcha\n",
    "Można zrobić to na kilka sposobów, ale ten jest najszybszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab99ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:02.093624Z",
     "start_time": "2022-11-27T19:39:01.987847Z"
    }
   },
   "outputs": [],
   "source": [
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f83ac1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:02.098261Z",
     "start_time": "2022-11-27T19:39:02.095134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 480, 640])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404cd6",
   "metadata": {},
   "source": [
    "# Stworzenie modelu\n",
    "Nazwałem model AoRNet od angielsiego **A**xis **o**f **R**rotation oraz od nazwy modelu matki Res**Net**`u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e0db1ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:02.115209Z",
     "start_time": "2022-11-27T19:39:02.099670Z"
    }
   },
   "outputs": [],
   "source": [
    "class AoRNet(nn.Module):\n",
    "    def __init__(self,pretrained=False ,input_channels=6, output_size=6):\n",
    "        super().__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        self.resnet50.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet50.fc = nn.Linear(in_features=2048, out_features=output_size, bias=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.resnet50(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9a67d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:03.704860Z",
     "start_time": "2022-11-27T19:39:02.116830Z"
    }
   },
   "outputs": [],
   "source": [
    "Model = AoRNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0f079a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:03.709448Z",
     "start_time": "2022-11-27T19:39:03.706268Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7793f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:39:03.719229Z",
     "start_time": "2022-11-27T19:39:03.710550Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>8}')\n",
    "    print(f'________\\n{sum(params):>8}')\n",
    "# count_parameters(My_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad777bc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:42:01.189852Z",
     "start_time": "2022-11-27T19:39:03.720530Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  batch: 1  loss: 2.28012943\n",
      "epoch:  1  batch: 2  loss: 2.30933261\n",
      "epoch:  1  batch: 3  loss: 0.26234064\n",
      "epoch:  1  batch: 4  loss: 0.43855420\n",
      "epoch:  2  batch: 1  loss: 0.24291277\n",
      "epoch:  2  batch: 2  loss: 0.06675425\n",
      "epoch:  2  batch: 3  loss: 0.28166404\n",
      "epoch:  2  batch: 4  loss: 0.07097908\n",
      "epoch:  3  batch: 1  loss: 0.12232298\n",
      "epoch:  3  batch: 2  loss: 0.16730392\n",
      "epoch:  3  batch: 3  loss: 0.11016083\n",
      "epoch:  3  batch: 4  loss: 0.06787626\n",
      "epoch:  4  batch: 1  loss: 0.11063676\n",
      "epoch:  4  batch: 2  loss: 0.04443929\n",
      "epoch:  4  batch: 3  loss: 0.03561527\n",
      "epoch:  4  batch: 4  loss: 0.06023783\n",
      "epoch:  5  batch: 1  loss: 0.04449012\n",
      "epoch:  5  batch: 2  loss: 0.08317773\n",
      "epoch:  5  batch: 3  loss: 0.05097241\n",
      "epoch:  5  batch: 4  loss: 0.04311935\n",
      "epoch:  6  batch: 1  loss: 0.04305856\n",
      "epoch:  6  batch: 2  loss: 0.05106083\n",
      "epoch:  6  batch: 3  loss: 0.04642919\n",
      "epoch:  6  batch: 4  loss: 0.02326172\n",
      "epoch:  7  batch: 1  loss: 0.02222460\n",
      "epoch:  7  batch: 2  loss: 0.02867869\n",
      "epoch:  7  batch: 3  loss: 0.01726387\n",
      "epoch:  7  batch: 4  loss: 0.02089296\n",
      "epoch:  8  batch: 1  loss: 0.03226591\n",
      "epoch:  8  batch: 2  loss: 0.01622670\n",
      "epoch:  8  batch: 3  loss: 0.01720605\n",
      "epoch:  8  batch: 4  loss: 0.03895645\n",
      "epoch:  9  batch: 1  loss: 0.02275548\n",
      "epoch:  9  batch: 2  loss: 0.01742277\n",
      "epoch:  9  batch: 3  loss: 0.05389444\n",
      "epoch:  9  batch: 4  loss: 0.01608560\n",
      "epoch: 10  batch: 1  loss: 0.02360422\n",
      "epoch: 10  batch: 2  loss: 0.01607120\n",
      "epoch: 10  batch: 3  loss: 0.02481145\n",
      "epoch: 10  batch: 4  loss: 0.02577805\n",
      "epoch: 11  batch: 1  loss: 0.01974931\n",
      "epoch: 11  batch: 2  loss: 0.02119945\n",
      "epoch: 11  batch: 3  loss: 0.01608299\n",
      "epoch: 11  batch: 4  loss: 0.02743771\n",
      "epoch: 12  batch: 1  loss: 0.00549799\n",
      "epoch: 12  batch: 2  loss: 0.01508353\n",
      "epoch: 12  batch: 3  loss: 0.02009378\n",
      "epoch: 12  batch: 4  loss: 0.02274165\n",
      "epoch: 13  batch: 1  loss: 0.01811753\n",
      "epoch: 13  batch: 2  loss: 0.01660562\n",
      "epoch: 13  batch: 3  loss: 0.00907478\n",
      "epoch: 13  batch: 4  loss: 0.01820386\n",
      "epoch: 14  batch: 1  loss: 0.01505549\n",
      "epoch: 14  batch: 2  loss: 0.01564137\n",
      "epoch: 14  batch: 3  loss: 0.01234889\n",
      "epoch: 14  batch: 4  loss: 0.01551785\n",
      "epoch: 15  batch: 1  loss: 0.01398635\n",
      "epoch: 15  batch: 2  loss: 0.01239953\n",
      "epoch: 15  batch: 3  loss: 0.01693403\n",
      "epoch: 15  batch: 4  loss: 0.00963033\n",
      "epoch: 16  batch: 1  loss: 0.01086278\n",
      "epoch: 16  batch: 2  loss: 0.01956925\n",
      "epoch: 16  batch: 3  loss: 0.01074849\n",
      "epoch: 16  batch: 4  loss: 0.00969456\n",
      "epoch: 17  batch: 1  loss: 0.01340962\n",
      "epoch: 17  batch: 2  loss: 0.00915145\n",
      "epoch: 17  batch: 3  loss: 0.01390621\n",
      "epoch: 17  batch: 4  loss: 0.01582445\n",
      "epoch: 18  batch: 1  loss: 0.00763795\n",
      "epoch: 18  batch: 2  loss: 0.01600688\n",
      "epoch: 18  batch: 3  loss: 0.00564023\n",
      "epoch: 18  batch: 4  loss: 0.01829054\n",
      "epoch: 19  batch: 1  loss: 0.01112244\n",
      "epoch: 19  batch: 2  loss: 0.00676901\n",
      "epoch: 19  batch: 3  loss: 0.01460310\n",
      "epoch: 19  batch: 4  loss: 0.00989913\n",
      "epoch: 20  batch: 1  loss: 0.00690401\n",
      "epoch: 20  batch: 2  loss: 0.01562293\n",
      "epoch: 20  batch: 3  loss: 0.01635692\n",
      "epoch: 20  batch: 4  loss: 0.02025802\n",
      "epoch: 21  batch: 1  loss: 0.01043625\n",
      "epoch: 21  batch: 2  loss: 0.00523655\n",
      "epoch: 21  batch: 3  loss: 0.02329953\n",
      "epoch: 21  batch: 4  loss: 0.02893890\n",
      "epoch: 22  batch: 1  loss: 0.01628315\n",
      "epoch: 22  batch: 2  loss: 0.01450118\n",
      "epoch: 22  batch: 3  loss: 0.03149971\n",
      "epoch: 22  batch: 4  loss: 0.01819278\n",
      "epoch: 23  batch: 1  loss: 0.00783694\n",
      "epoch: 23  batch: 2  loss: 0.01810205\n",
      "epoch: 23  batch: 3  loss: 0.01469582\n",
      "epoch: 23  batch: 4  loss: 0.01763065\n",
      "epoch: 24  batch: 1  loss: 0.00999766\n",
      "epoch: 24  batch: 2  loss: 0.00803768\n",
      "epoch: 24  batch: 3  loss: 0.01219082\n",
      "epoch: 24  batch: 4  loss: 0.03247563\n",
      "epoch: 25  batch: 1  loss: 0.00698773\n",
      "epoch: 25  batch: 2  loss: 0.00480917\n",
      "epoch: 25  batch: 3  loss: 0.01731873\n",
      "epoch: 25  batch: 4  loss: 0.00741989\n",
      "epoch: 26  batch: 1  loss: 0.01140521\n",
      "epoch: 26  batch: 2  loss: 0.00544478\n",
      "epoch: 26  batch: 3  loss: 0.01052443\n",
      "epoch: 26  batch: 4  loss: 0.00730738\n",
      "epoch: 27  batch: 1  loss: 0.00608929\n",
      "epoch: 27  batch: 2  loss: 0.01129563\n",
      "epoch: 27  batch: 3  loss: 0.01440529\n",
      "epoch: 27  batch: 4  loss: 0.02237923\n",
      "epoch: 28  batch: 1  loss: 0.01018931\n",
      "epoch: 28  batch: 2  loss: 0.00906193\n",
      "epoch: 28  batch: 3  loss: 0.00925399\n",
      "epoch: 28  batch: 4  loss: 0.01188019\n",
      "epoch: 29  batch: 1  loss: 0.00724301\n",
      "epoch: 29  batch: 2  loss: 0.01315454\n",
      "epoch: 29  batch: 3  loss: 0.01183198\n",
      "epoch: 29  batch: 4  loss: 0.01218775\n",
      "epoch: 30  batch: 1  loss: 0.00995849\n",
      "epoch: 30  batch: 2  loss: 0.00799127\n",
      "epoch: 30  batch: 3  loss: 0.01983524\n",
      "epoch: 30  batch: 4  loss: 0.01324821\n",
      "epoch: 31  batch: 1  loss: 0.00835886\n",
      "epoch: 31  batch: 2  loss: 0.00731451\n",
      "epoch: 31  batch: 3  loss: 0.03449723\n",
      "epoch: 31  batch: 4  loss: 0.01840660\n",
      "epoch: 32  batch: 1  loss: 0.00368649\n",
      "epoch: 32  batch: 2  loss: 0.02251658\n",
      "epoch: 32  batch: 3  loss: 0.01656824\n",
      "epoch: 32  batch: 4  loss: 0.01846721\n",
      "epoch: 33  batch: 1  loss: 0.01178605\n",
      "epoch: 33  batch: 2  loss: 0.01016359\n",
      "epoch: 33  batch: 3  loss: 0.03194150\n",
      "epoch: 33  batch: 4  loss: 0.02308475\n",
      "epoch: 34  batch: 1  loss: 0.00780639\n",
      "epoch: 34  batch: 2  loss: 0.01763741\n",
      "epoch: 34  batch: 3  loss: 0.01541242\n",
      "epoch: 34  batch: 4  loss: 0.03055315\n",
      "epoch: 35  batch: 1  loss: 0.00671332\n",
      "epoch: 35  batch: 2  loss: 0.00766256\n",
      "epoch: 35  batch: 3  loss: 0.00747484\n",
      "epoch: 35  batch: 4  loss: 0.01172376\n",
      "epoch: 36  batch: 1  loss: 0.01578071\n",
      "epoch: 36  batch: 2  loss: 0.00382189\n",
      "epoch: 36  batch: 3  loss: 0.00554347\n",
      "epoch: 36  batch: 4  loss: 0.01165863\n",
      "epoch: 37  batch: 1  loss: 0.00364053\n",
      "epoch: 37  batch: 2  loss: 0.01493436\n",
      "epoch: 37  batch: 3  loss: 0.01029010\n",
      "epoch: 37  batch: 4  loss: 0.01318939\n",
      "epoch: 38  batch: 1  loss: 0.00799345\n",
      "epoch: 38  batch: 2  loss: 0.00348101\n",
      "epoch: 38  batch: 3  loss: 0.00403310\n",
      "epoch: 38  batch: 4  loss: 0.01129682\n",
      "epoch: 39  batch: 1  loss: 0.00454042\n",
      "epoch: 39  batch: 2  loss: 0.00330099\n",
      "epoch: 39  batch: 3  loss: 0.00349710\n",
      "epoch: 39  batch: 4  loss: 0.01416735\n",
      "epoch: 40  batch: 1  loss: 0.00216005\n",
      "epoch: 40  batch: 2  loss: 0.00184804\n",
      "epoch: 40  batch: 3  loss: 0.00306688\n",
      "epoch: 40  batch: 4  loss: 0.00334884\n",
      "epoch: 41  batch: 1  loss: 0.00491406\n",
      "epoch: 41  batch: 2  loss: 0.00174295\n",
      "epoch: 41  batch: 3  loss: 0.00312893\n",
      "epoch: 41  batch: 4  loss: 0.00217010\n",
      "epoch: 42  batch: 1  loss: 0.00555383\n",
      "epoch: 42  batch: 2  loss: 0.00159682\n",
      "epoch: 42  batch: 3  loss: 0.00354383\n",
      "epoch: 42  batch: 4  loss: 0.00133526\n",
      "epoch: 43  batch: 1  loss: 0.00247840\n",
      "epoch: 43  batch: 2  loss: 0.00103465\n",
      "epoch: 43  batch: 3  loss: 0.00148084\n",
      "epoch: 43  batch: 4  loss: 0.00379173\n",
      "epoch: 44  batch: 1  loss: 0.00204602\n",
      "epoch: 44  batch: 2  loss: 0.00150569\n",
      "epoch: 44  batch: 3  loss: 0.00165610\n",
      "epoch: 44  batch: 4  loss: 0.00056394\n",
      "epoch: 45  batch: 1  loss: 0.00135371\n",
      "epoch: 45  batch: 2  loss: 0.00181395\n",
      "epoch: 45  batch: 3  loss: 0.00305293\n",
      "epoch: 45  batch: 4  loss: 0.00390634\n",
      "epoch: 46  batch: 1  loss: 0.00159719\n",
      "epoch: 46  batch: 2  loss: 0.00111255\n",
      "epoch: 46  batch: 3  loss: 0.00315268\n",
      "epoch: 46  batch: 4  loss: 0.00104086\n",
      "epoch: 47  batch: 1  loss: 0.00135013\n",
      "epoch: 47  batch: 2  loss: 0.00190469\n",
      "epoch: 47  batch: 3  loss: 0.00341486\n",
      "epoch: 47  batch: 4  loss: 0.00373412\n",
      "epoch: 48  batch: 1  loss: 0.00140274\n",
      "epoch: 48  batch: 2  loss: 0.00150203\n",
      "epoch: 48  batch: 3  loss: 0.00071036\n",
      "epoch: 48  batch: 4  loss: 0.00253897\n",
      "epoch: 49  batch: 1  loss: 0.00169431\n",
      "epoch: 49  batch: 2  loss: 0.00114516\n",
      "epoch: 49  batch: 3  loss: 0.00477045\n",
      "epoch: 49  batch: 4  loss: 0.00459924\n",
      "epoch: 50  batch: 1  loss: 0.00152263\n",
      "epoch: 50  batch: 2  loss: 0.00186717\n",
      "epoch: 50  batch: 3  loss: 0.00181767\n",
      "epoch: 50  batch: 4  loss: 0.00302905\n",
      "epoch: 51  batch: 1  loss: 0.00200166\n",
      "epoch: 51  batch: 2  loss: 0.00144218\n",
      "epoch: 51  batch: 3  loss: 0.00114432\n",
      "epoch: 51  batch: 4  loss: 0.00225318\n",
      "epoch: 52  batch: 1  loss: 0.00426831\n",
      "epoch: 52  batch: 2  loss: 0.00149731\n",
      "epoch: 52  batch: 3  loss: 0.00211361\n",
      "epoch: 52  batch: 4  loss: 0.00256921\n",
      "epoch: 53  batch: 1  loss: 0.00159934\n",
      "epoch: 53  batch: 2  loss: 0.00103227\n",
      "epoch: 53  batch: 3  loss: 0.00415033\n",
      "epoch: 53  batch: 4  loss: 0.00109230\n",
      "epoch: 54  batch: 1  loss: 0.00689488\n",
      "epoch: 54  batch: 2  loss: 0.00173135\n",
      "epoch: 54  batch: 3  loss: 0.00110904\n",
      "epoch: 54  batch: 4  loss: 0.00290905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 55  batch: 1  loss: 0.00165912\n",
      "epoch: 55  batch: 2  loss: 0.00187966\n",
      "epoch: 55  batch: 3  loss: 0.00320377\n",
      "epoch: 55  batch: 4  loss: 0.00229757\n",
      "epoch: 56  batch: 1  loss: 0.00236661\n",
      "epoch: 56  batch: 2  loss: 0.00194661\n",
      "epoch: 56  batch: 3  loss: 0.00231464\n",
      "epoch: 56  batch: 4  loss: 0.00233607\n",
      "epoch: 57  batch: 1  loss: 0.00143554\n",
      "epoch: 57  batch: 2  loss: 0.00094277\n",
      "epoch: 57  batch: 3  loss: 0.00161178\n",
      "epoch: 57  batch: 4  loss: 0.00132834\n",
      "epoch: 58  batch: 1  loss: 0.00475737\n",
      "epoch: 58  batch: 2  loss: 0.00152072\n",
      "epoch: 58  batch: 3  loss: 0.00124423\n",
      "epoch: 58  batch: 4  loss: 0.00263727\n",
      "epoch: 59  batch: 1  loss: 0.00197322\n",
      "epoch: 59  batch: 2  loss: 0.00197280\n",
      "epoch: 59  batch: 3  loss: 0.00199588\n",
      "epoch: 59  batch: 4  loss: 0.00160673\n",
      "epoch: 60  batch: 1  loss: 0.00063304\n",
      "epoch: 60  batch: 2  loss: 0.00126428\n",
      "epoch: 60  batch: 3  loss: 0.00128885\n",
      "epoch: 60  batch: 4  loss: 0.00248227\n",
      "epoch: 61  batch: 1  loss: 0.00149921\n",
      "epoch: 61  batch: 2  loss: 0.00109977\n",
      "epoch: 61  batch: 3  loss: 0.00231829\n",
      "epoch: 61  batch: 4  loss: 0.00294247\n",
      "epoch: 62  batch: 1  loss: 0.00204617\n",
      "epoch: 62  batch: 2  loss: 0.00112431\n",
      "epoch: 62  batch: 3  loss: 0.00240654\n",
      "epoch: 62  batch: 4  loss: 0.00517178\n",
      "epoch: 63  batch: 1  loss: 0.00232528\n",
      "epoch: 63  batch: 2  loss: 0.00288226\n",
      "epoch: 63  batch: 3  loss: 0.00272422\n",
      "epoch: 63  batch: 4  loss: 0.00201437\n",
      "epoch: 64  batch: 1  loss: 0.00270509\n",
      "epoch: 64  batch: 2  loss: 0.00232987\n",
      "epoch: 64  batch: 3  loss: 0.00242666\n",
      "epoch: 64  batch: 4  loss: 0.00127967\n",
      "epoch: 65  batch: 1  loss: 0.00203358\n",
      "epoch: 65  batch: 2  loss: 0.00140914\n",
      "epoch: 65  batch: 3  loss: 0.00241269\n",
      "epoch: 65  batch: 4  loss: 0.00295944\n",
      "epoch: 66  batch: 1  loss: 0.00282713\n",
      "epoch: 66  batch: 2  loss: 0.00360111\n",
      "epoch: 66  batch: 3  loss: 0.00198051\n",
      "epoch: 66  batch: 4  loss: 0.00138394\n",
      "epoch: 67  batch: 1  loss: 0.00306319\n",
      "epoch: 67  batch: 2  loss: 0.00126744\n",
      "epoch: 67  batch: 3  loss: 0.00209720\n",
      "epoch: 67  batch: 4  loss: 0.00297898\n",
      "epoch: 68  batch: 1  loss: 0.00125914\n",
      "epoch: 68  batch: 2  loss: 0.00131856\n",
      "epoch: 68  batch: 3  loss: 0.00190311\n",
      "epoch: 68  batch: 4  loss: 0.00440563\n",
      "epoch: 69  batch: 1  loss: 0.00107350\n",
      "epoch: 69  batch: 2  loss: 0.00319353\n",
      "epoch: 69  batch: 3  loss: 0.00247682\n",
      "epoch: 69  batch: 4  loss: 0.00396043\n",
      "epoch: 70  batch: 1  loss: 0.00235917\n",
      "epoch: 70  batch: 2  loss: 0.00135395\n",
      "epoch: 70  batch: 3  loss: 0.00400018\n",
      "epoch: 70  batch: 4  loss: 0.00131647\n",
      "epoch: 71  batch: 1  loss: 0.00168146\n",
      "epoch: 71  batch: 2  loss: 0.00139583\n",
      "epoch: 71  batch: 3  loss: 0.00248114\n",
      "epoch: 71  batch: 4  loss: 0.00113768\n",
      "epoch: 72  batch: 1  loss: 0.00290974\n",
      "epoch: 72  batch: 2  loss: 0.00471997\n",
      "epoch: 72  batch: 3  loss: 0.00093861\n",
      "epoch: 72  batch: 4  loss: 0.00243197\n",
      "epoch: 73  batch: 1  loss: 0.00130994\n",
      "epoch: 73  batch: 2  loss: 0.00084289\n",
      "epoch: 73  batch: 3  loss: 0.00173047\n",
      "epoch: 73  batch: 4  loss: 0.00180735\n",
      "epoch: 74  batch: 1  loss: 0.00128346\n",
      "epoch: 74  batch: 2  loss: 0.00158450\n",
      "epoch: 74  batch: 3  loss: 0.00114443\n",
      "epoch: 74  batch: 4  loss: 0.00310196\n",
      "epoch: 75  batch: 1  loss: 0.00276602\n",
      "epoch: 75  batch: 2  loss: 0.00096995\n",
      "epoch: 75  batch: 3  loss: 0.00209291\n",
      "epoch: 75  batch: 4  loss: 0.00610483\n",
      "epoch: 76  batch: 1  loss: 0.00124487\n",
      "epoch: 76  batch: 2  loss: 0.00177452\n",
      "epoch: 76  batch: 3  loss: 0.00262563\n",
      "epoch: 76  batch: 4  loss: 0.00411941\n",
      "epoch: 77  batch: 1  loss: 0.00601086\n",
      "epoch: 77  batch: 2  loss: 0.00252260\n",
      "epoch: 77  batch: 3  loss: 0.00180727\n",
      "epoch: 77  batch: 4  loss: 0.00367845\n",
      "epoch: 78  batch: 1  loss: 0.00234177\n",
      "epoch: 78  batch: 2  loss: 0.00364119\n",
      "epoch: 78  batch: 3  loss: 0.00120151\n",
      "epoch: 78  batch: 4  loss: 0.01004297\n",
      "epoch: 79  batch: 1  loss: 0.00144191\n",
      "epoch: 79  batch: 2  loss: 0.00101905\n",
      "epoch: 79  batch: 3  loss: 0.00216580\n",
      "epoch: 79  batch: 4  loss: 0.00395288\n",
      "epoch: 80  batch: 1  loss: 0.00286339\n",
      "epoch: 80  batch: 2  loss: 0.00561043\n",
      "epoch: 80  batch: 3  loss: 0.00672067\n",
      "epoch: 80  batch: 4  loss: 0.00138706\n",
      "epoch: 81  batch: 1  loss: 0.00155202\n",
      "epoch: 81  batch: 2  loss: 0.00210906\n",
      "epoch: 81  batch: 3  loss: 0.00429121\n",
      "epoch: 81  batch: 4  loss: 0.00105356\n",
      "epoch: 82  batch: 1  loss: 0.00124384\n",
      "epoch: 82  batch: 2  loss: 0.00097832\n",
      "epoch: 82  batch: 3  loss: 0.00087826\n",
      "epoch: 82  batch: 4  loss: 0.00325353\n",
      "epoch: 83  batch: 1  loss: 0.00215179\n",
      "epoch: 83  batch: 2  loss: 0.00318559\n",
      "epoch: 83  batch: 3  loss: 0.00146528\n",
      "epoch: 83  batch: 4  loss: 0.00088047\n",
      "epoch: 84  batch: 1  loss: 0.00104120\n",
      "epoch: 84  batch: 2  loss: 0.00134856\n",
      "epoch: 84  batch: 3  loss: 0.00132764\n",
      "epoch: 84  batch: 4  loss: 0.00237766\n",
      "epoch: 85  batch: 1  loss: 0.00068682\n",
      "epoch: 85  batch: 2  loss: 0.00075839\n",
      "epoch: 85  batch: 3  loss: 0.00066782\n",
      "epoch: 85  batch: 4  loss: 0.00147928\n",
      "epoch: 86  batch: 1  loss: 0.00146412\n",
      "epoch: 86  batch: 2  loss: 0.00256747\n",
      "epoch: 86  batch: 3  loss: 0.00208878\n",
      "epoch: 86  batch: 4  loss: 0.00280158\n",
      "epoch: 87  batch: 1  loss: 0.00140859\n",
      "epoch: 87  batch: 2  loss: 0.00245720\n",
      "epoch: 87  batch: 3  loss: 0.00338617\n",
      "epoch: 87  batch: 4  loss: 0.00233625\n",
      "epoch: 88  batch: 1  loss: 0.00241120\n",
      "epoch: 88  batch: 2  loss: 0.00568459\n",
      "epoch: 88  batch: 3  loss: 0.00129040\n",
      "epoch: 88  batch: 4  loss: 0.00348714\n",
      "epoch: 89  batch: 1  loss: 0.00275946\n",
      "epoch: 89  batch: 2  loss: 0.00391247\n",
      "epoch: 89  batch: 3  loss: 0.00217300\n",
      "epoch: 89  batch: 4  loss: 0.00228954\n",
      "epoch: 90  batch: 1  loss: 0.00403047\n",
      "epoch: 90  batch: 2  loss: 0.00040931\n",
      "epoch: 90  batch: 3  loss: 0.00077169\n",
      "epoch: 90  batch: 4  loss: 0.00227005\n",
      "epoch: 91  batch: 1  loss: 0.00102010\n",
      "epoch: 91  batch: 2  loss: 0.00148005\n",
      "epoch: 91  batch: 3  loss: 0.00152935\n",
      "epoch: 91  batch: 4  loss: 0.00236524\n",
      "epoch: 92  batch: 1  loss: 0.00151428\n",
      "epoch: 92  batch: 2  loss: 0.00235508\n",
      "epoch: 92  batch: 3  loss: 0.00151115\n",
      "epoch: 92  batch: 4  loss: 0.00268000\n",
      "epoch: 93  batch: 1  loss: 0.00542352\n",
      "epoch: 93  batch: 2  loss: 0.00270483\n",
      "epoch: 93  batch: 3  loss: 0.00129215\n",
      "epoch: 93  batch: 4  loss: 0.00084792\n",
      "epoch: 94  batch: 1  loss: 0.00174912\n",
      "epoch: 94  batch: 2  loss: 0.00219130\n",
      "epoch: 94  batch: 3  loss: 0.00080678\n",
      "epoch: 94  batch: 4  loss: 0.00331038\n",
      "epoch: 95  batch: 1  loss: 0.00315823\n",
      "epoch: 95  batch: 2  loss: 0.00202989\n",
      "epoch: 95  batch: 3  loss: 0.00232175\n",
      "epoch: 95  batch: 4  loss: 0.00173689\n",
      "epoch: 96  batch: 1  loss: 0.00273726\n",
      "epoch: 96  batch: 2  loss: 0.00215152\n",
      "epoch: 96  batch: 3  loss: 0.00098994\n",
      "epoch: 96  batch: 4  loss: 0.00510114\n",
      "epoch: 97  batch: 1  loss: 0.00210834\n",
      "epoch: 97  batch: 2  loss: 0.00203688\n",
      "epoch: 97  batch: 3  loss: 0.00121730\n",
      "epoch: 97  batch: 4  loss: 0.00282127\n",
      "epoch: 98  batch: 1  loss: 0.00159724\n",
      "epoch: 98  batch: 2  loss: 0.00281447\n",
      "epoch: 98  batch: 3  loss: 0.00198815\n",
      "epoch: 98  batch: 4  loss: 0.00141590\n",
      "epoch: 99  batch: 1  loss: 0.00153704\n",
      "epoch: 99  batch: 2  loss: 0.00157513\n",
      "epoch: 99  batch: 3  loss: 0.00160127\n",
      "epoch: 99  batch: 4  loss: 0.00161460\n",
      "epoch: 100  batch: 1  loss: 0.00329044\n",
      "epoch: 100  batch: 2  loss: 0.00088505\n",
      "epoch: 100  batch: 3  loss: 0.00325074\n",
      "epoch: 100  batch: 4  loss: 0.00230864\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        # Apply the model\n",
    "        y_pred = Model(X_train.cuda())\n",
    "        loss = criterion(y_pred, y_train.cuda())\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print interim results\n",
    "        if b%1 == 0:\n",
    "            print(f'epoch: {i+1:2}  batch: {b}  loss: {loss.item():10.8f}')\n",
    "    \n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    scheduler.step(loss)\n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            # Apply the model\n",
    "            y_val = Model(X_test.cuda())\n",
    "    loss = criterion(y_val, y_test.cuda())\n",
    "    test_losses.append(loss.cpu().detach().numpy())\n",
    "#     test_correct.append(tst_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7796f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:42:01.309014Z",
     "start_time": "2022-11-27T19:42:01.191179Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='testing loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f35dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:42:01.817099Z",
     "start_time": "2022-11-27T19:42:01.310640Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> BATCH: 1 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01801,      0.64195,     -2.05990], [    -0.02660,     -0.87560,     -2.19280]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.00226,      0.00426,      0.06711], [     0.00719,      0.05108,      0.02370]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.01357,      0.64336,     -2.09214], [    -0.01341,     -0.90831,     -2.19223]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.00670,      0.00285,      0.03486], [     0.02038,      0.01837,      0.02427]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.40935,      0.70453,     -1.75258], [    -0.35640,     -0.69333,     -1.71841]]\n",
      "REAL:\n",
      "[[    -0.40718,      0.68764,     -1.77400], [    -0.35904,     -0.70196,     -1.69050]]\n",
      "DIFFERENCE:\n",
      "[[     0.00218,      0.01689,      0.02142], [     0.00264,      0.00863,      0.02791]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.25850,      0.61181,     -1.91537], [    -0.23166,     -0.65940,     -1.71034]]\n",
      "REAL:\n",
      "[[    -0.29337,      0.60727,     -1.96200], [    -0.26306,     -0.69510,     -1.67400]]\n",
      "DIFFERENCE:\n",
      "[[     0.03487,      0.00454,      0.04663], [     0.03140,      0.03571,      0.03634]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.24790,      0.19969,     -1.67932], [     0.25905,     -0.34244,     -1.65826]]\n",
      "REAL:\n",
      "[[     0.22801,      0.17823,     -1.68600], [     0.23168,     -0.33602,     -1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.01989,      0.02145,      0.00668], [     0.02738,      0.00642,      0.04726]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.27438,      0.83025,     -2.40116], [    -0.25629,     -0.92635,     -2.42561]]\n",
      "REAL:\n",
      "[[    -0.30037,      0.81899,     -2.46400], [    -0.28544,     -0.94018,     -2.43750]]\n",
      "DIFFERENCE:\n",
      "[[     0.02599,      0.01126,      0.06284], [     0.02914,      0.01383,      0.01189]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.09168,      0.53668,     -1.41387], [    -0.06201,     -0.63164,     -1.52889]]\n",
      "REAL:\n",
      "[[    -0.10797,      0.54656,     -1.41700], [    -0.09271,     -0.63447,     -1.52100]]\n",
      "DIFFERENCE:\n",
      "[[     0.01629,      0.00988,      0.00313], [     0.03069,      0.00284,      0.00789]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 1 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.14817,      0.76461,     -2.13564], [    -0.13374,     -0.84324,     -2.10650]]\n",
      "REAL:\n",
      "[[    -0.14587,      0.80852,     -2.18800], [    -0.14697,     -0.88385,     -2.11400]]\n",
      "DIFFERENCE:\n",
      "[[     0.00230,      0.04392,      0.05236], [     0.01323,      0.04062,      0.00750]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.17767,      0.68655,     -1.75019], [    -0.14104,     -0.73031,     -1.77980]]\n",
      "REAL:\n",
      "[[    -0.19092,      0.68764,     -1.77400], [    -0.13623,     -0.76245,     -1.83600]]\n",
      "DIFFERENCE:\n",
      "[[     0.01325,      0.00108,      0.02381], [     0.00481,      0.03214,      0.05620]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.02039,      0.52056,     -1.90359], [    -0.00791,     -0.77025,     -1.86357]]\n",
      "REAL:\n",
      "[[     0.00538,      0.48417,     -1.89700], [     0.03751,     -0.77899,     -1.87600]]\n",
      "DIFFERENCE:\n",
      "[[     0.02577,      0.03639,      0.00659], [     0.04542,      0.00874,      0.01243]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.20351,      0.18360,     -1.66881], [     0.21041,     -0.34845,     -1.56105]]\n",
      "REAL:\n",
      "[[     0.22801,      0.17823,     -1.68600], [     0.23168,     -0.33602,     -1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.02450,      0.00536,      0.01719], [     0.02126,      0.01243,      0.04995]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.39338,      0.69042,     -1.76033], [    -0.36193,     -0.68491,     -1.67275]]\n",
      "REAL:\n",
      "[[    -0.39655,      0.66889,     -1.73400], [    -0.34362,     -0.69997,     -1.67800]]\n",
      "DIFFERENCE:\n",
      "[[     0.00317,      0.02153,      0.02633], [     0.01831,      0.01507,      0.00525]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.10456,      0.32724,     -1.14044], [     0.10713,     -0.16722,     -1.24248]]\n",
      "REAL:\n",
      "[[     0.09985,      0.33770,     -1.17800], [     0.10780,     -0.15744,     -1.30100]]\n",
      "DIFFERENCE:\n",
      "[[     0.00471,      0.01045,      0.03756], [     0.00067,      0.00978,      0.05852]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.45443,      0.11354,     -1.12347], [     0.45434,     -0.29679,     -1.17202]]\n",
      "REAL:\n",
      "[[     0.44540,      0.13033,     -1.19000], [     0.44683,     -0.33906,     -1.24450]]\n",
      "DIFFERENCE:\n",
      "[[     0.00902,      0.01679,      0.06653], [     0.00751,      0.04227,      0.07248]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.28247,      0.81139,     -2.08057], [    -0.24135,     -0.81569,     -2.07567]]\n",
      "REAL:\n",
      "[[    -0.30735,      0.79714,     -2.05650], [    -0.25493,     -0.82605,     -2.07500]]\n",
      "DIFFERENCE:\n",
      "[[     0.02489,      0.01425,      0.02407], [     0.01358,      0.01036,      0.00067]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 2 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.33957,      0.81515,     -2.03576], [    -0.34442,     -0.92456,     -2.25765]]\n",
      "REAL:\n",
      "[[    -0.28700,      0.79462,     -2.05000], [    -0.28483,     -0.92407,     -2.28300]]\n",
      "DIFFERENCE:\n",
      "[[     0.05257,      0.02053,      0.01424], [     0.05958,      0.00049,      0.02535]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.08742,      0.68832,     -2.12892], [    -0.09814,     -0.93730,     -2.22622]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.06715,      0.04212,      0.00192], [     0.06434,      0.01062,      0.00972]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.07565,      0.66916,     -2.13455], [    -0.07906,     -0.95639,     -2.20774]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.05538,      0.02295,      0.00755], [     0.04526,      0.02972,      0.00876]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.36115,      0.79980,     -2.02506], [    -0.31078,     -0.83085,     -2.03007]]\n",
      "REAL:\n",
      "[[    -0.30735,      0.79714,     -2.05650], [    -0.25493,     -0.82605,     -2.07500]]\n",
      "DIFFERENCE:\n",
      "[[     0.05380,      0.00266,      0.03144], [     0.05585,      0.00480,      0.04493]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.44518,      0.16946,     -1.26306], [     0.43512,     -0.42239,     -1.30901]]\n",
      "REAL:\n",
      "[[     0.44540,      0.13033,     -1.19000], [     0.44683,     -0.33906,     -1.24450]]\n",
      "DIFFERENCE:\n",
      "[[     0.00022,      0.03913,      0.07306], [     0.01171,      0.08333,      0.06451]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.19410,      0.21029,     -1.71934], [     0.19296,     -0.36671,     -1.64790]]\n",
      "REAL:\n",
      "[[     0.22801,      0.17823,     -1.68600], [     0.23168,     -0.33602,     -1.61100]]\n",
      "DIFFERENCE:\n",
      "[[     0.03391,      0.03205,      0.03334], [     0.03871,      0.03070,      0.03690]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.35706,      0.85471,     -2.39855], [    -0.33623,     -0.96384,     -2.38996]]\n",
      "REAL:\n",
      "[[    -0.30037,      0.81899,     -2.46400], [    -0.28544,     -0.94018,     -2.43750]]\n",
      "DIFFERENCE:\n",
      "[[     0.05668,      0.03572,      0.06545], [     0.05079,      0.02366,      0.04754]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 6 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.16996,      0.88980,     -2.19200], [    -0.16109,     -0.83457,     -2.21043]]\n",
      "REAL:\n",
      "[[    -0.10820,      0.86478,     -2.23100], [    -0.09656,     -0.80679,     -2.25300]]\n",
      "DIFFERENCE:\n",
      "[[     0.06177,      0.02502,      0.03900], [     0.06453,      0.02779,      0.04257]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 3 <-- | --> ROW: 7 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.05087,      0.39260,     -1.21966], [     0.05959,     -0.21176,     -1.34890]]\n",
      "REAL:\n",
      "[[     0.09985,      0.33770,     -1.17800], [     0.10780,     -0.15744,     -1.30100]]\n",
      "DIFFERENCE:\n",
      "[[     0.04899,      0.05490,      0.04166], [     0.04820,      0.05432,      0.04790]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 0 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    -0.05311,      0.50977,     -1.49543], [    -0.01631,     -0.62991,     -1.55345]]\n",
      "REAL:\n",
      "[[    -0.03914,      0.54791,     -1.41700], [    -0.02323,     -0.63012,     -1.52450]]\n",
      "DIFFERENCE:\n",
      "[[     0.01397,      0.03814,      0.07843], [     0.00692,      0.00021,      0.02895]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 1 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.31921,      0.62732,     -1.75007], [    -0.28684,     -0.70444,     -1.69418]]\n",
      "REAL:\n",
      "[[    -0.39655,      0.66889,     -1.73400], [    -0.34362,     -0.69997,     -1.67800]]\n",
      "DIFFERENCE:\n",
      "[[     0.07734,      0.04157,      0.01607], [     0.05678,      0.00447,      0.01618]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 2 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.08715,      0.76933,     -2.26928], [    -0.07883,     -0.88482,     -2.16704]]\n",
      "REAL:\n",
      "[[    -0.14587,      0.80852,     -2.18800], [    -0.14697,     -0.88385,     -2.11400]]\n",
      "DIFFERENCE:\n",
      "[[     0.05872,      0.03919,      0.08128], [     0.06814,      0.00097,      0.05304]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 3 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[    -0.26771,      0.72370,     -2.12137], [    -0.25554,     -0.92685,     -2.29249]]\n",
      "REAL:\n",
      "[[    -0.28700,      0.79462,     -2.05000], [    -0.28483,     -0.92407,     -2.28300]]\n",
      "DIFFERENCE:\n",
      "[[     0.01929,      0.07092,      0.07137], [     0.02929,      0.00278,      0.00949]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 4 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.12055,      0.30110,     -1.21422], [     0.13151,     -0.13334,     -1.32518]]\n",
      "REAL:\n",
      "[[     0.09985,      0.33770,     -1.17800], [     0.10780,     -0.15744,     -1.30100]]\n",
      "DIFFERENCE:\n",
      "[[     0.02069,      0.03659,      0.03622], [     0.02371,      0.02410,      0.02418]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "--> BATCH: 4 <-- | --> ROW: 5 <--\n",
      "----------------------------------------------------------------------------------------------\n",
      "          X1           Y1           Z1           X2           Y2           Z2\n",
      "PREDICTED:\n",
      "[[     0.04272,      0.58548,     -2.16701], [     0.02898,     -0.93040,     -2.20548]]\n",
      "REAL:\n",
      "[[    -0.02027,      0.64620,     -2.12700], [    -0.03380,     -0.92668,     -2.21650]]\n",
      "DIFFERENCE:\n",
      "[[     0.06299,      0.06072,      0.04001], [     0.06278,      0.00372,      0.01102]]\n",
      "----------------------------------------------------------------------------------------------\n",
      "RMSE: 0.00191103\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(test_loader):\n",
    "#         Apply the model\n",
    "        y_val = Model(X_test.cuda())\n",
    "#         print(y_val.shape)\n",
    "        for j in range(y_val.shape[0]):\n",
    "            print(f'--> BATCH: {b+1} <-- | --> ROW: {j} <--')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "            print(f'{\"X1\":>12} {\"Y1\":>12} {\"Z1\":>12} {\"X2\":>12} {\"Y2\":>12} {\"Z2\":>12}')\n",
    "            print(f'{\"PREDICTED:\"}')\n",
    "            print(f'[[{y_val[j][0]:12.5f}, {y_val[j][1]:12.5f}, {y_val[j][2]:12.5f}], [{y_val[j][3]:12.5f}, {y_val[j][4]:12.5f}, {y_val[j][5]:12.5f}]]')\n",
    "            print(f'{\"REAL:\"}')\n",
    "            print(f'[[{y_test[j][0]:12.5f}, {y_test[j][1]:12.5f}, {y_test[j][2]:12.5f}], [{y_test[j][3]:12.5f}, {y_test[j][4]:12.5f}, {y_test[j][5]:12.5f}]]')\n",
    "            print(f'{\"DIFFERENCE:\"}')\n",
    "            diff = np.abs(y_val.cpu().numpy()-y_test.cpu().numpy())\n",
    "            print(f'[[{diff[j][0]:12.5f}, {diff[j][1]:12.5f}, {diff[j][2]:12.5f}], [{diff[j][3]:12.5f}, {diff[j][4]:12.5f}, {diff[j][5]:12.5f}]]')\n",
    "            print(f'----------------------------------------------------------------------------------------------')\n",
    "loss = criterion(y_val, y_test.cuda())\n",
    "# diff = np.abs(y_val.cpu().numpy()-y_test.cpu().numpy())\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f488246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T18:24:09.373928Z",
     "start_time": "2022-11-05T18:24:09.369916Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52fa1bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T19:42:01.822463Z",
     "start_time": "2022-11-27T19:42:01.818417Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2645487774.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [25], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    diff = np.abs(y_val[i].item()-y_test[i][k].item())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "        diff = np.abs(y_val[i].item()-y_test[i][k].item())\n",
    "            print(diff)\n",
    "#     print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a7c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474164f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80527311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d673a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db49c8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351666d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398c7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28057c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2bac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AoR_CNN]",
   "language": "python",
   "name": "conda-env-AoR_CNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "75b361d4100cabf439e872d27edcfc9e968620b5cc1a2991a8793a2beed62efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
